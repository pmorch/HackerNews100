<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 10 Oct 2023 16:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[GitHub Copilot loses an average of $20 per user per month (102 pts)]]></title>
            <link>https://www.thurrott.com/cloud/290661/report-github-copilot-loses-an-average-of-20-per-user-per-month</link>
            <guid>37831780</guid>
            <pubDate>Tue, 10 Oct 2023 13:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thurrott.com/cloud/290661/report-github-copilot-loses-an-average-of-20-per-user-per-month">https://www.thurrott.com/cloud/290661/report-github-copilot-loses-an-average-of-20-per-user-per-month</a>, See on <a href="https://news.ycombinator.com/item?id=37831780">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-thurrott-section="content" data-thurrott-interaction-state="available">
              <p><img decoding="async" src="https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot.jpg" alt="GitHub Copilot" width="1066" height="600" srcset="https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot.jpg 1066w, https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot-450x253.jpg 450w, https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot-1024x576.jpg 1024w, https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot-768x432.jpg 768w, https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot-900x507.jpg 900w, https://thurrott-assets.nyc3.digitaloceanspaces.com/web/wp-content/uploads/sites/2/2023/10/github-copilot-600x338.jpg 600w" sizes="(max-width: 1066px) 100vw, 1066px"></p>
<p>A new report in the Wall Street Journal highlights the stratospheric costs that Big Tech faces delivering AI capabilities to their customers. And it seems that even the paid services are losing money.</p>
<p>“Microsoft used AI from its partner OpenAI to launch GitHub Copilot, a service that helps programmers create, fix, and translate code,” <a href="https://www.wsj.com/tech/ai/ais-costly-buildup-could-make-early-products-a-hard-sell-bdd29b9f">the publication notes</a>. “It has been popular with coders—more than 1.5 million people have used it and it is helping build nearly half of Copilot users’ code—because it slashes the time and effort needed to program. It has also been a money loser because it is so expensive to run.”</p><div data-thurrott-section="inline-form"><h2>Windows Intelligence In Your Inbox</h2><p>Sign up for our new free newsletter to get three time-saving tips each Friday — <i>and</i> get free copies of Paul Thurrott's Windows 11 and Windows 10 Field Guides (normally $9.99) as a special welcome gift!</p>
                <div data-form-theme="gravity-theme" data-form-index="0" id="gform_wrapper_5">
                        <p>"<span>*</span>" indicates required fields</p>
                        </div>
		                
		                
</div>
<p>As the WSJ notes, individuals pay $10 per month for GitHub Copilot, but multiple sources told it that the service loses an average of $20 per user per month, with some users costing Microsoft as much as $80 per month. So it’s likely that this situation played a role in the company’s decision to charge a lot more for the AI capabilities it will soon provide via Microsoft 365 Copilot. That service will cost customers $30 per user per month on top of the normal monthly Microsoft 365 subscription fee (which varies by tier). It’s not coincidental that <a href="https://www.thurrott.com/cloud/287822/google-duet-ai-to-cost-30-per-user-per-month-just-like-microsoft-365-copilot">Google will charge an identical additional per-user fee</a> for <a href="https://www.thurrott.com/cloud/282958/google-workspace-duet-ai">its similar Duet AI offering</a>.</p>
<p>The extravagant cost of AI also explains why <a href="https://www.thurrott.com/cloud/290645/microsoft-first-ai-chip-could-be-revealed-november-2023">Microsoft is working to develop its own in-house AI chipsets for use in its datacenters</a> and is pushing the PC industry to adopt what it calls NPUs—Neural Processing Units that accelerate AI operations independently of the CPU—that will usher in <a href="https://www.thurrott.com/hardware/290462/hp-ai-will-transform-the-pc-into-a-personal-companion">the new era of PC computing that HP discussed last week</a>: These coming PCs will be able to offload some AI tasks from the cloud and process them locally, reducing the expenses on the backend.</p>
<p>Microsoft is also looking at shorter-term solutions for the costs of AI, especially for services like Bing Chat, Bing Image Creator, and Microsoft Copilot which are free to users. One possible solution is to use less powerful backend services that don’t cost as much to run, according to some reports.</p>
<p>Interestingly, it appears that Adobe—which charges Creative Cloud customers astonishing sums each month for its suite of artistic tools—has solved this problem with its Firefly generative AI tools, which are profitable: It simply slows down the service’s performance on a per-user basis once that user has gone over their monthly credit allotment, an allotment that is no doubt based on the price they pay Adobe each month. “We are trying to protect ourselves on the cost side,” Adobe CEO Shantanu Narayen told the WSJ.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google mitigated the largest DDoS attack to date, peaking above 398M rps (341 pts)]]></title>
            <link>https://cloud.google.com/blog/products/identity-security/google-cloud-mitigated-largest-ddos-attack-peaking-above-398-million-rps/</link>
            <guid>37831062</guid>
            <pubDate>Tue, 10 Oct 2023 12:10:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/identity-security/google-cloud-mitigated-largest-ddos-attack-peaking-above-398-million-rps/">https://cloud.google.com/blog/products/identity-security/google-cloud-mitigated-largest-ddos-attack-peaking-above-398-million-rps/</a>, See on <a href="https://news.ycombinator.com/item?id=37831062">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Over the last few years, Google's DDoS Response Team <a href="https://cloud.google.com/blog/products/identity-security/identifying-and-protecting-against-the-largest-ddos-attacks">has observed</a> the trend that distributed denial-of-service (DDoS) attacks are increasing exponentially in size. Last year, we blocked the <a href="https://cloud.google.com/blog/products/identity-security/how-google-cloud-blocked-largest-layer-7-ddos-attack-at-46-million-rps">largest DDoS attack</a> recorded at the time. This August, we stopped an even larger DDoS attack — 7½ times larger — that also used new techniques to try to disrupt websites and Internet services.</p><p>This new series of DDoS attacks reached a peak of 398 million requests per second (rps), and relied on a novel HTTP/2 “Rapid Reset” technique based on stream multiplexing that has affected multiple Internet infrastructure companies. By contrast, last year’s largest-recorded DDoS attack peaked at 46 million rps.</p><p>For a sense of scale, this two minute attack generated more requests than the total number of article views reported by Wikipedia during the entire month of September 2023.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/2023_worlds_largest_--_peak_graph.max-1467x824.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/2023_worlds_largest_--_peak_graph.max-1467x824.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Google mitigated a DDoS attack which peaked at 398 million requests per second</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>The most recent wave of attacks started in late August and continue to this day, targeting major infrastructure providers including Google services, Google Cloud infrastructure, and our customers. Although these attacks are among the largest attacks Google has seen, our global load-balancing and DDoS mitigation infrastructure helped keep our services running. In order to protect Google, our customers, and the rest of the Internet, we helped lead a coordinated effort with industry partners to understand the attack mechanics and collaborate on mitigations that can be deployed in response to these attacks.</p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>Generally, DDoS attacks attempt to disrupt internet-facing websites and services, making them unreachable. Attackers direct overwhelming amounts of Internet traffic to targets, which can exhaust their ability to process incoming requests.</p><p>DDoS attacks can have wide-ranging impacts to victim organizations, including loss of business and unavailability of mission critical applications, which often cost victims time and money. Time to recover from DDoS attacks can stretch well beyond the end of an attack.</p><h3>Our investigation and response</h3><p>Our investigation revealed that the attack was using a novel “Rapid Reset” technique that leverages stream multiplexing, a feature of the widely-adopted HTTP/2 protocol. We provide further analysis of this new Rapid Reset technique and discuss the evolution of Layer 7 attacks in a <a href="https://cloud.google.com/blog/products/identity-security/how-it-works-the-novel-http2-rapid-reset-ddos-attack">companion blog</a>.</p></span></section><section><figure><section jscontroller="SCGBie" jsaction="rcuQ6b:npT2md"><img src="https://storage.googleapis.com/gweb-cloudblog-publish/images/2023_worlds_largest_--_september_incidents.max-1501x844.png" alt="https://storage.googleapis.com/gweb-cloudblog-publish/images/2023_worlds_largest_--_september_incidents.max-1501x844.png" jsname="P3Vluc" jsaction="click:HTIlC" loading="lazy"></section></figure><p><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>We observed the attack campaign continued over the course of September 2023</p></span></p></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>We were able to mitigate the attack at the edge of Google's network, leveraging our significant investment in edge capacity to ensure our services and our customers’ services remained largely unaffected. As we understood more details about the attack methodology, we developed a set of mitigations and updated our proxies and denial-of-service defense systems to efficiently mitigate this technique. Since Google Cloud’s <a href="https://cloud.google.com/load-balancing?hl=en">Application Load Balancer</a> and <a href="https://cloud.google.com/armor/?hl=en">Cloud Armor</a> use the same hardware and software infrastructure that Google relies on to serve its own internet-facing services, the Cloud customers who use those services have their Internet-facing web apps and services similarly protected.</p><h3>Industry coordination and response for CVE-2023-44487</h3><p>Soon after detecting the earliest of these attacks in August, Google applied additional mitigation strategies and coordinated a cross-industry response with other cloud providers and software maintainers who implement the HTTP/2 protocol stack. We shared intelligence about the attack and mitigation methodologies in real time as the attacks were underway.</p><p>This cross-industry collaboration has resulted in patches and other mitigation techniques used by many large infrastructure providers. The collaboration helped to pave the way for today’s coordinated responsible disclosure of the new attack methodology and potential susceptibility across a multitude of common open source and commercial proxies, application servers, and load balancers.</p><p>The collective susceptibility to this attack is being tracked as <a href="https://nvd.nist.gov/vuln/detail/CVE-2023-44487" target="_blank">CVE-2023-44487</a> and has been designated a High severity vulnerability with a <a href="https://nvd.nist.gov/vuln-metrics/cvss" target="_blank">CVSS</a> score of 7.5 (out of 10).</p><p>Google expresses sincere gratitude to all of the cross-industry stakeholders who have collaborated, shared information, accelerated patching of their infrastructure, and rapidly made patches available to their customers.</p><h3>Who is susceptible and what to do about it</h3><p>Any enterprise or individual that is serving an HTTP-based workload to the Internet may be at risk from this attack. Web applications, services, and APIs on a server or proxy able to communicate using the HTTP/2 protocol could be vulnerable. Organizations should verify that any servers they run that support HTTP/2 are not vulnerable, or apply vendor patches for CVE-2023-44487 to limit impact from this attack vector. If you are managing or operating your own HTTP/2-capable server (open source or commercial) you should immediately apply a patch from the relevant vendor when available.</p><h3>Next steps</h3><p>Defending against massive DDoS attacks such as those described here is difficult. With or without patches, organizations would need to make significant infrastructure investments to keep services running in the face of attacks of any moderate size and larger. Instead of bearing that expense themselves, organizations running services on Google Cloud can take advantage of our investment in capacity at global scale in our <a href="https://cloud.google.com/solutions/cross-cloud-network">Cross-Cloud Network</a> to deliver and protect their applications.</p><p>Google Cloud customers exposing their services using the global or regional Application Load Balancer benefit from <a href="https://cloud.google.com/armor">Cloud Armor always-on DDoS protection</a>, where attacks exploiting vulnerabilities such as CVE-2023-44487 are quickly mitigated.</p><p>Even though with Cloud Armor always-on DDoS protection we are able to efficiently absorb most of the hundreds of millions of requests per second at the edge of Google’s network, millions of unwelcome requests per second can still make it through. To protect against this and other layer 7 attacks, we also recommend deployment of Cloud Armor <a href="https://cloud.google.com/armor/docs/best-practices">custom security policies</a> with proactive <a href="https://cloud.google.com/armor/docs/rate-limiting-overview">rate limiting</a> rules and AI-powered <a href="https://cloud.google.com/armor/docs/adaptive-protection-overview">Adaptive Protection</a> to more comprehensively detect, analyze, and mitigate attack traffic.</p><p>We provide more technical information on this <a href="https://cloud.google.com/blog/products/identity-security/how-it-works-the-novel-http2-rapid-reset-ddos-attack">current wave of DDoS attacks here</a>, and you can learn more about Google Cloud Armor’s DDoS protection <a href="https://cloud.google.com/armor">here</a>.</p></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/identity-security" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/identity-security" track-metadata-module="tag list" track-metadata-module_headline="posted in">Security &amp; Identity</a></li><li><a href="https://cloud.google.com/blog/products/networking" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/networking" track-metadata-module="tag list" track-metadata-module_headline="posted in">Networking</a></li><li><a href="https://cloud.google.com/blog/products/gcp" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/gcp" track-metadata-module="tag list" track-metadata-module_headline="posted in">Google Cloud</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTTP/2 Zero-Day Vulnerability Results in Record-Breaking DDoS Attacks (132 pts)]]></title>
            <link>https://blog.cloudflare.com/zero-day-rapid-reset-http2-record-breaking-ddos-attack/</link>
            <guid>37830998</guid>
            <pubDate>Tue, 10 Oct 2023 12:02:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.cloudflare.com/zero-day-rapid-reset-http2-record-breaking-ddos-attack/">https://blog.cloudflare.com/zero-day-rapid-reset-http2-record-breaking-ddos-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=37830998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">
    <article>
        


        <p localize="" datetime="2023-10-10T13:02:09+01:00">Loading...</p>
        

        <ul>
            <li>
                <a href="https://blog.cloudflare.com/author/grant/">
                    <img src="https://blog.cloudflare.com/cdn-cgi/image/format=auto,dpr=3,width=62,height=62/http://blog.cloudflare.com/content/images/2023/04/Headshot---GB_LinkedIn.jpg" alt="Grant Bourzikas" width="62" height="62">
                </a>
                
            </li>
        </ul>

        <section>
            <p>7 min read</p>
            <div>
                <figure><img src="https://blog.cloudflare.com/content/images/2023/10/Screenshot-2023-10-09-at-10.41.56-PM.png" alt="" loading="lazy" width="1150" height="612"></figure><p>Earlier today, Cloudflare, along with Google and Amazon AWS, disclosed the existence of a novel zero-day vulnerability dubbed the “HTTP/2 Rapid Reset” attack. This attack exploits a weakness in the HTTP/2 protocol to generate enormous, hyper-volumetric Distributed Denial of Service (DDoS) attacks. Cloudflare has mitigated a barrage of these attacks in recent months, including an attack three times larger than <a href="https://blog.cloudflare.com/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack/">any previous attack we’ve observed</a>, which exceeded 201 million requests per second (rps). Since the end of August 2023, Cloudflare has mitigated more than 1,100 other attacks with over 10 million rps — and 184 attacks that were greater than our previous DDoS record of 71 million rps. </p><p>This zero-day provided threat actors with a critical new tool in their Swiss Army knife of vulnerabilities to exploit and attack their victims at a magnitude that has never been seen before. While at times complex and challenging to combat, these attacks allowed Cloudflare the opportunity to develop purpose-built technology to mitigate the effects of the zero-day vulnerability.</p><p>If you are using Cloudflare for HTTP DDoS mitigation, you are protected. And below, we’ve included more information on this vulnerability, and resources and recommendations on what you can do to secure yourselves.</p><h3 id="deconstructing-the-attack-what-every-cso-needs-to-know">Deconstructing the attack: What every CSO needs to know</h3><p>In late August 2023, our team at Cloudflare noticed a new zero-day vulnerability, developed by an unknown threat actor, that exploits the standard HTTP/2 protocol — a fundamental protocol that is critical to how the Internet and all websites work. This novel zero-day vulnerability attack, dubbed Rapid Reset, leverages HTTP/2’s stream cancellation feature by sending a request and immediately canceling it over and over. &nbsp;</p><p>By automating this trivial “request, cancel, request, cancel” pattern at scale, threat actors are able to create a denial of service and take down any server or application running the standard implementation of HTTP/2. Furthermore, one crucial thing to note about the record-breaking attack is that it involved a modestly-sized botnet, consisting of roughly 20,000 machines. Cloudflare regularly detects botnets that are orders of magnitude larger than this — comprising hundreds of thousands and even millions of machines. For a relatively small botnet to output such a large volume of requests, with the potential to incapacitate nearly any server or application supporting HTTP/2, underscores how menacing this vulnerability is for unprotected networks.</p><p>Threat actors used botnets in tandem with the HTTP/2 vulnerability to amplify requests at rates we have never seen before. As a result, our team at Cloudflare experienced some intermittent edge instability. While our systems were able to mitigate the overwhelming majority of incoming attacks, the volume overloaded some components in our network, impacting a small number of customers’ performance with intermittent 4xx and 5xx errors — all of which were quickly resolved. </p><p>Once we successfully mitigated these issues and halted potential attacks for all customers, our team immediately kicked off a responsible disclosure process. We entered into conversations with industry peers to see how we could work together to help move our mission forward and safeguard the large percentage of the Internet that relies on our network prior to releasing this vulnerability to the general public. </p><p>We cover the technical details of the attack in more detail in a separate blog post: <a href="https://cfl.re/rapid-reset-breakdown">HTTP/2 Rapid Reset: deconstructing the record-breaking attack</a>.</p><h3 id="how-is-cloudflare-and-the-industry-thwarting-this-attack">How is Cloudflare and the industry thwarting this attack?</h3><p>There is no such thing as a “perfect disclosure.” Thwarting attacks and responding to emerging incidents requires organizations and security teams to live by an assume-breach mindset — because there will always be another zero-day, new evolving threat actor groups, and never-before-seen novel attacks and techniques. </p><p>This “assume-breach” mindset is a key foundation towards information sharing and ensuring in instances such as this that the Internet remains safe. While Cloudflare was experiencing and mitigating these attacks, we were also working with industry partners to guarantee that the industry at-large could withstand this attack. &nbsp;</p><p>During the process of mitigating this attack, our Cloudflare team developed and purpose-built new technology to stop these DDoS attacks and further improve our own mitigations for this and other future attacks of massive scale. These efforts have significantly increased our overall mitigation capabilities and resiliency. If you are using Cloudflare, we are confident that you are protected. </p><p>Our team also alerted web server software partners who are developing patches to ensure this vulnerability cannot be exploited — check their websites for more information.</p><figure><img src="https://blog.cloudflare.com/content/images/2023/10/Zero-Day-protection-4.png" alt="" loading="lazy" width="1600" height="416"></figure><p>Disclosures are never one and done. The lifeblood of Cloudflare is to ensure a better Internet, which stems from instances such as these. When we have the opportunity to work with our industry partners and governments to ensure there are no widespread impacts on the Internet, we are doing our part in increasing the cyber resiliency of every organization no matter the size or vertical.</p><p>To gain more of an understanding around mitigation tactics and next steps on patching, <a href="https://event.on24.com/wcc/r/4378646/EC4EB4A6CE2B363BC6378891E495BEBF">register for our webinar</a>.</p><h3 id="what-are-the-origins-of-the-http2-rapid-reset-and-these-record-breaking-attacks-on-cloudflare">What are the origins of the HTTP/2 Rapid Reset and these record-breaking attacks on Cloudflare?</h3><p>It may seem odd that Cloudflare was one of the first companies to witness these attacks. Why would threat actors attack a company that has some of the most robust defenses against DDoS attacks in the world? &nbsp;</p><p>The reality is that Cloudflare often sees attacks before they are turned on more vulnerable targets. Threat actors need to develop and test their tools before they deploy them in the wild. Threat actors who possess record-shattering attack methods can have an extremely difficult time testing and understanding how large and effective they are, because they don't have the infrastructure to absorb the attacks they are launching. Because of the transparency that we share on our network performance, and the measurements of attacks they could glean from our public performance charts, this threat actor was likely targeting us to understand the capabilities of the exploit.</p><p>But that testing, and the ability to see the attack early, helps us develop mitigations for the attack that benefit both our customers and industry as a whole.</p><h3 id="from-cso-to-cso-what-should-you-do">From CSO to CSO: What should you do?</h3><p>I have been a CSO for over 20 years, on the receiving end of countless disclosures and &nbsp;announcements like this. But whether it was <a href="https://blog.cloudflare.com/exploitation-of-cve-2021-44228-before-public-disclosure-and-evolution-of-waf-evasion-patterns/">Log4J</a>, <a href="https://blog.cloudflare.com/solarwinds-orion-compromise-trend-data/">Solarwinds</a>, <a href="https://www.cloudflare.com/learning/security/ransomware/how-to-prevent-ransomware/">EternalBlue</a> <a href="https://www.cloudflare.com/learning/security/ransomware/petya-notpetya-ransomware/">WannaCry/NotPetya</a>, <a href="https://blog.cloudflare.com/heartbleed-revisited/">Heartbleed</a>, or <a href="https://blog.cloudflare.com/inside-shellshock/">Shellshock</a>, all of these security incidents have a commonality. A tremendous explosion that ripples across the world and creates an opportunity to completely disrupt any of the organizations that I have led — regardless of the industry or the size. </p><p>Many of these were attacks or vulnerabilities that we may have not been able to control. But regardless of whether the issue arose from something that was in my control or not, what has set any successful initiative I have led apart from those that did not lean in our favor was the ability to respond when zero-day vulnerabilities and exploits like this are identified. &nbsp; &nbsp;</p><p>While I wish I could say that Rapid Reset may be different this time around, it is not. I am calling all CSOs — no matter if you’ve lived through the decades of security incidents that I have, or this is your first day on the job — this is the time to ensure you are protected and stand up your cyber incident response team. </p><p>We’ve kept the information restricted until today to give as many security vendors as possible the opportunity to react. However, at some point, the responsible thing becomes to publicly disclose zero-day threats like this. Today is that day. That means that after today, threat actors will be largely aware of the HTTP/2 vulnerability; and it will inevitably become trivial to exploit and kickoff the race between defenders and attacks — first to patch vs. first to exploit. Organizations should assume that systems will be tested, and take proactive measures to ensure protection.</p><p>To me, this is reminiscent of a vulnerability like Log4J, due to the many variants that are emerging daily, and will continue to come to fruition in the weeks, months, and years to come. As more researchers and threat actors experiment with the vulnerability, we may find different variants with even shorter exploit cycles that contain even more advanced bypasses. &nbsp;</p><p>And just like Log4J, managing incidents like this isn’t as simple as “run the patch, now you’re done”. You need to turn incident management, patching, and evolving your security protections into ongoing processes — because the patches for each variant of a vulnerability reduce your risk, but they don’t eliminate it.</p><p>I don’t mean to be alarmist, but I will be direct: you must take this seriously. Treat this as a full active incident to ensure nothing happens to your organization.</p><h3 id="recommendations-for-a-new-standard-of-change">Recommendations for a New Standard of Change</h3><p>While no one security event is ever identical to the next, there are lessons that can be learned. CSOs, here are my recommendations that must be implemented immediately. Not only in this instance, but for years to come:</p><ul><li>Understand your external and partner network’s external connectivity to remediate any Internet facing systems with the mitigations below.</li><li>Understand your existing security protection and capabilities you have to protect, detect and respond to an attack and immediately remediate any issues you have in your network.</li><li>Ensure your DDoS Protection resides outside of your data center because if the traffic gets to your datacenter, it will be difficult to mitigate the DDoS attack.</li><li>Ensure you have DDoS protection for Applications (Layer 7) and ensure you have Web Application Firewalls. Additionally as a best practice, ensure you have complete DDoS protection for DNS, Network Traffic (Layer 3) and API Firewalls</li><li>Ensure web server and operating system patches are deployed across all Internet Facing Web Servers. Also, ensure all automation like Terraform builds and images are fully patched so older versions of web servers are not deployed into production over the secure images by accident.</li><li>As a last resort, consider turning off HTTP/2 and HTTP/3 (likely also vulnerable) to mitigate the threat. &nbsp;This is a last resort only, because there will be a significant performance issues if you downgrade to HTTP/1.1</li><li>Consider a secondary, cloud-based DDoS L7 provider at perimeter for resilience.</li></ul><p>Cloudflare’s mission is to help build a better Internet. If you are concerned with your current state of DDoS protection, we are more than happy to provide you with our DDoS capabilities and resilience for free to mitigate any attempts of a successful DDoS attack. &nbsp;We know the stress that you are facing as we have fought off these attacks for the last 30 days and made our already best in class systems, even better. </p><p>If you’re interested in finding out more, we have a webinar coming up with more details on the zero-day and how to respond; you can <a href="https://event.on24.com/wcc/r/4378646/EC4EB4A6CE2B363BC6378891E495BEBF">register here</a>. We also have more technical details of the attack in more detail in a separate blog post: <a href="https://cfl.re/rapid-reset-breakdown">HTTP/2 Rapid Reset: deconstructing the record-breaking attack</a>. Finally, if you’re being targeted or need immediate protection, please contact your local Cloudflare representative or visit <a href="https://www.cloudflare.com/under-attack-hotline/">https://www.cloudflare.com/under-attack-hotline/</a>.</p>
            </div>
        </section>
    
        









    <div>
            <p>We protect
                <a target="_blank" href="https://www.cloudflare.com/network-services/">entire corporate networks</a>,
                    help customers build
                    <a target="_blank" href="https://workers.cloudflare.com/">Internet-scale applications efficiently</a>,
                    accelerate any
                    <a target="_blank" href="https://www.cloudflare.com/performance/accelerate-internet-applications/">website
                    or Internet application</a>,
                    <a target="_blank" href="https://www.cloudflare.com/ddos/">ward off DDoS
                    attacks</a>, keep
                    <a target="_blank" href="https://www.cloudflare.com/application-security/">hackers at
                    bay</a>,
                    and can help you on
                    <a target="_blank" href="https://www.cloudflare.com/products/zero-trust/">your journey to Zero Trust</a>.</p>
            <p>Visit <a target="_blank" href="https://1.1.1.1/">1.1.1.1</a> from any device to get started with
                our free app that makes your Internet faster and safer.</p>
            <p>To learn more about our mission to help build a better Internet, <a target="_blank" href="https://www.cloudflare.com/learning/what-is-cloudflare/">start here</a>. If you're looking for a
                new career direction, check out <a target="_blank" href="https://cloudflare.com/careers">our open
                    positions</a>.</p>
        </div>

        

        
        

        <a href="https://blog.cloudflare.com/tag/security/">Security</a>
        <a href="https://blog.cloudflare.com/tag/vulnerabilities/">Vulnerabilities</a>
        <a href="https://blog.cloudflare.com/tag/attacks/">Attacks</a>
        <a href="https://blog.cloudflare.com/tag/ddos/">DDoS</a>
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Samsung expected to report 80% profit plunge as losses mount at chip business (130 pts)]]></title>
            <link>https://www.cnbc.com/2023/10/10/samsung-earnings-preview-q3-2023-chip-losses-weigh-on-profit.html</link>
            <guid>37830303</guid>
            <pubDate>Tue, 10 Oct 2023 10:16:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/10/10/samsung-earnings-preview-q3-2023-chip-losses-weigh-on-profit.html">https://www.cnbc.com/2023/10/10/samsung-earnings-preview-q3-2023-chip-losses-weigh-on-profit.html</a>, See on <a href="https://news.ycombinator.com/item?id=37830303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-107314192" data-test="InlineImage"><p>Customers experience Samsung's new flagship fold-screen phone Galaxy Z Fold5 at a Samsung sales store in Hangzhou, East China's Zhejiang province, Aug. 14, 2023.</p><p>Costfoto | Nurphoto | Getty Images</p></div><div><p>Samsung Electronics earnings are expected to plunge nearly 80% in the third quarter, according to analyst forecasts, as the company's biggest profit-driving segment — semiconductors — continues to come under pressure.</p><p>The South Korean technology giant will issue earnings guidance on Wednesday. Analysts polled by LSEG expect operating profit of 2.3 trillion Korean won ($1.7 billion) for the September quarter, a 78.7% year-on-year decline. Revenue is expected to come in at 67.8 trillion won, a fall of 11.6%, according to LSEG consensus forecasts.</p><p>Samsung is the world's largest maker of memory chips, used in products ranging from laptops to servers. It is also the world's biggest smartphone player.</p><p>Samsung's semiconductor business — typically the company's cash cow — is expected to post a more than 3 trillion won loss for the third quarter, according to analyst forecasts, as it continues to face headwinds.</p></div><div><p><a href="https://www.cnbc.com/2023/07/28/how-the-world-went-from-a-semiconductor-shortage-to-a-major-glut.html">Memory chip prices have fallen dramatically this year</a> due to a glut caused by oversupply and low demand for end products like smartphones and laptops.</p><p>This has <a href="https://www.cnbc.com/2023/07/27/samsung-earnings-report-q2-2023.html">hit Samsung's profits hard</a>. In its last earnings reports in July, the company predicted a pick-up in demand for chips in the second half of the year, although this does not appear to be playing out as fast as many had hoped.</p><p>The tech giant has cut production in a bid to help shore up prices, though the effect is not likely to be seen in the third-quarter results.</p><p>Daiwa Capital Markets said in a note earlier this month that it expects Samsung earnings to miss consensus estimates "due to the higher cost burden from the memory production cut and ongoing soft demand" for its chip manufacturing unit, known as the foundry business.</p><p>Daiwa analyst SK Kim sees operating profit for the third quarter at 1.65 trillion won, much lower than the average analyst estimate of 2.3 trillion won.</p><p>There could be two potential bright spots for Samsung in the September quarter, however.</p><p>Firstly, its display business could see quarter-on-quarter growth due to the release of <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-3"><a href="https://www.cnbc.com/quotes/AAPL/">Apple</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>'s iPhone 15 series; Samsung sells displays to Apple for iPhones.</p><p>Secondly, Samsung's smartphone unit could see improving margins <a href="https://www.cnbc.com/2023/07/26/samsung-galaxy-z-flip-5-and-galaxy-fold-specs-price-details.html">due to the high-end foldable phones it launched in July.</a></p></div><h2><a id="headline0"></a>Recovery ahead?</h2><div><p>Investors will be looking for signs that Samsung's core chip division will stabilize in the current quarter.</p><p>Looking ahead to the fourth quarter, analysts expect operating profit of 3.8 trillion won, according to consensus estimates. That would represent an 11.5% year-on-year decline, much smaller than the profit drops recorded in the first and second quarters of this year. Revenue is seen flat, arresting the declining sales the company has seen this year so far.</p><p>Daiwa's Kim sees the inventory glut easing and memory prices rising in the fourth quarter. Meanwhile, a Citi note in August suggested that Samsung will begin supplying advanced memory chips for U.S. semiconductor giant <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-5"><a href="https://www.cnbc.com/quotes/NVDA/">Nvidia</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>'s graphics processing units, which are used for artificial intelligence.</p><p>Kim suggests this will also be a boost for Samsung, adding: "We expect growing opportunities related to AI demand in 2024."</p><p><em>Correction: The key points of this article have been updated to reflect that 3 trillion won is equivalent to $2.2 billion.</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wayfire 0.8 (111 pts)]]></title>
            <link>https://wayfire.org/2023/10/07/Wayfire-0-8.html</link>
            <guid>37830186</guid>
            <pubDate>Tue, 10 Oct 2023 09:57:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wayfire.org/2023/10/07/Wayfire-0-8.html">https://wayfire.org/2023/10/07/Wayfire-0-8.html</a>, See on <a href="https://news.ycombinator.com/item?id=37830186">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    <p>Hello everyone! It has been nearly three years since I last wrote to this blog. Fortunately, that does not mean Wayfire’s development has stopped! Quite the opposite, in fact I am happy to announce the release of Wayfire 0.8.0. There have been many changes and plugin API breakages since the Wayfire 0.7.x series, so I will try to summarize the important changes in the following paragraphs.</p>

<h3 id="user-facing-changes">User-facing changes</h3>

<p>First, let us take a look at the user-facing changes and new features that were added in this release:</p>

<h4 id="workspace-sets-wayfire-pr-1797">Workspace sets (Wayfire <a href="https://github.com/WayfireWM/wayfire/pull/1797">PR #1797</a>)</h4>

<p>Workspace sets are a new feature provided by the <code>wsets</code> plugin. A workspace set is the grid of workspaces on one output. Up until now, Wayfire always had one workspace set (albeit it wasn’t called like this) per output. With the recent changes, it is possible to have multiple workspace sets on each output and switch between them. The end result is very similar to how Sway’s workspaces work: the plugin numbers them from 1 to N, and at any given moment you can display any of the workspace sets on any of your outputs (however, each workspace set can be visible on at most one output at a time). Check the YouTube video to get a better sense of what they provide (the recording contains two Wayfire outputs side-by-side):</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/QhGqlLK8Elo?si=Kf7Z8Uv5SR7N4ujr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>The purpose of workspace sets is to have a dedicated set of normal workspaces for different activities the user does on their computer. For example, I have one workspace set (containing a 2x2 workspace grid) dedicated to Wayfire, where I have Wayfire’s source code, GitHub issues, wlroots, etc. There is another workspace set dedicated to a project I am working on for university, and so on. Of course, a similar effect could be achieved with a single bigger workspace grid, but having a 5x5 workspace grid quickly becomes difficult to navigate.</p>

<p>It should also be noted that workspace sets can be moved between outputs, which is something generally impossible with normal workspaces. I use this for example when switching between working on my laptop and an external monitor - it is just a matter of showing the workspace set on the new monitor.</p>

<h4 id="ipc-socket-wayfire-pr-1472-pr-1821">IPC socket (Wayfire <a href="https://github.com/WayfireWM/wayfire/pull/1472">PR #1472</a>, <a href="https://github.com/WayfireWM/wayfire/pull/1821">PR #1821</a>)</h4>

<p>A frequent request for Wayfire was the ability to control it via IPC commands. With this release, Wayfire now provides a socket that clients can use for this purpose. To use it, make sure to enable the <code>ipc</code> plugin (it should be first in the list of plugins). The <code>ipc</code> plugin itself does not implement any IPC commands, instead, it only provides a generic framework for other plugins to extend. The <code>ipc-rules</code> plugin provides a few basic window-management commands and can be used to substitute the <code>window-rules</code> plugin with a custom user-provided script, see <a href="https://github.com/WayfireWM/wayfire/blob/master/ipc-scripts/ipc-rules-demo.py">the Python example</a> for more information.</p>

<p>The plan for the future is to extend the <code>ipc-rules</code> plugin to support more commands and to report more events to the IPC clients. In addition, some other plugins provide their functionality as IPC commands, for example <code>wm-actions</code> and <code>grid</code>. Lastly, there is a new framework to allow all plugin bindings to be callable from an IPC script - for example after <a href="https://github.com/WayfireWM/wayfire/pull/1864/commits/48c30481afe47c8235885d2a2c7378091e6293f2">this commit</a>, the <code>scale</code> plugin can be activated from the IPC socket.</p>

<p>If you want to use the IPC socket, but the currently provided commands are not enough for your use-case (which is likely!), feel free to reach out to discuss how to extend the existing IPC support.</p>

<h4 id="smaller-changes">Smaller changes</h4>

<p>Some smaller, but important items from the git log:</p>

<ul>
  <li>Expo workspaces can now be navigated with the keyboard: <a href="https://github.com/WayfireWM/wayfire/pull/1156">PR #1156</a></li>
  <li>Animations for the simple-tile plugin: <a href="https://github.com/WayfireWM/wayfire/pull/1071">PR #1071</a></li>
  <li>Vswitch plugin has bindings for moving to a particular workspace and to last workspace: <a href="https://github.com/WayfireWM/wayfire/pull/1199">PR #1199</a>, <a href="https://github.com/WayfireWM/wayfire/pull/1371">PR #1371</a></li>
  <li>Multiple protocols which <strong>were previously provided by core have been moved to plugins</strong>: <code>wayfire-shell</code> (<a href="https://github.com/WayfireWM/wayfire/pull/1715">PR #1715</a>), <code>foreign-toplevel</code>, <code>gtk-shell</code> (<a href="https://github.com/WayfireWM/wayfire/pull/1678">PR #1678</a>). Most likely, you will want to enable those in your <code>wayfire.ini</code>.</li>
  <li>Added support for the xdg-activation-v1 protocol: <a href="https://github.com/WayfireWM/wayfire/pull/1898">PR #1898</a></li>
</ul>

<p>There were of course many, many other small fixes and added options and PRs, which cannot be all presented here. See the full git changelog for details :)</p>

<h4 id="wf-shell">wf-shell</h4>

<p>Thanks to multiple contributors, there have also been numerous improvements to the default panel, <code>wf-panel</code>, part of wf-shell:</p>

<ul>
  <li>Huge thanks to a new contributor @NamorNiradnug, who implemented:
    <ul>
      <li>A notifications widget: <a href="https://github.com/WayfireWM/wf-shell/pull/132">PR #132</a></li>
      <li>Command output widget for displaying the output of a shell command: <a href="https://github.com/WayfireWM/wf-shell/pull/148">PR #148</a></li>
      <li>A tray widget: <a href="https://github.com/WayfireWM/wf-shell/pull/153">PR #153</a></li>
    </ul>
  </li>
  <li>Thanks to @soreau for implementing a logout interface: <a href="https://github.com/WayfireWM/wf-shell/pull/100">PR #100</a></li>
</ul>

<h3 id="plugin-api-changes">Plugin API changes</h3>

<p>The focus of the 0.8.0 release was to clear the technical debt which has accumulated in core over the time. As a result, many APIs were refactored and some were completely rewritten, resulting in many breaking changes for plugins. On the upside, with most of the glaring problems in the API fixed, plugin authors can expect less (at the very least, much less severe) API changes in the future.</p>

<p>The following is a summary of the big items, many of which also provide new or improved capabilities for plugins (and, unfortunately, expose more of the complexity at times).</p>

<h4 id="scenegraph-wayfire-pr-1501">Scenegraph (Wayfire <a href="https://github.com/WayfireWM/wayfire/pull/1501">PR #1501</a>)</h4>

<p>Until now, Wayfire has had very simple algorithm for rendering and input handling. Core had a list of outputs, and each output had a list of layers and views in them. While the basic structure has remained roughly the same, Wayfire 0.8.0 has a single structure called the scenegraph, which organizes all of these in a structure with a single interface. The scenegraph can also be used to repalce custom renderers and input grabs used in previous versions of Wayfire. See the <a href="https://github.com/WayfireWM/wayfire/wiki/Scenegraph">wiki page</a> on this topic for an introduction into the technical aspects of it.</p>

<h4 id="view-interface-wayfire-pr-1370-pr-1704">View Interface (Wayfire <a href="https://github.com/WayfireWM/wayfire/pull/1370">PR #1370</a>, <a href="https://github.com/WayfireWM/wayfire/pull/1704">PR #1704</a>)</h4>

<p>Over time, Wayfire’s central type - views, which represent application windows - has accumulated too many methods, fields and responsibilities. As a part of the refactoring effort, the input and rendering aspects of this interface have been moved to the scenegraph nodes associated with a given view. The view interface itself has been split in two - ‘generic’ views, which represent any type of window, including backgrounds, panels, etc. and a specialized subclass toplevel views, which represent toplevel windows, which can be moved, resized, maximized, etc. See the <a href="https://github.com/WayfireWM/wayfire/wiki/Views,-Toplevels-and-Transactions#views">wiki</a> for more details.</p>

<h4 id="transactions-wayfire-pr-1704">Transactions (Wayfire <a href="https://github.com/WayfireWM/wayfire/pull/1704">PR #1704</a>)</h4>

<p>Tiling plugins like <code>simple-tile</code> need a way to resize multiple toplevels synchronously. In addition, certain changes in toplevel states (for example fullscreening and resizing to the full output size) belong logically together. In the Wayland protocol, these concepts usually are represented by using commits which group together related changes to an object. In Wayfire 0.8, we also have a similar system on the server side - transactions. They can be used to update multiple toplevels (or in general, transaction objects) and their properties atomically.</p>

<p>Another possible application of transactions is providing out-of-compositor decorations, like Emerald for Compiz: with transactions, a plugin can synchronize the state of the decoration and the main window. However, support for this has only barely reached the proof-of-concept stage. For the interested in continuing this development, a starting point can be found <a href="https://github.com/ammen99/wf-basic-deco">here</a>.</p>

<h4 id="smaller-changes-1">Smaller changes</h4>

<p>There were also multiple smaller fixes and updates to the API, a non-exhaustive list of which is here:</p>

<ul>
  <li>Plugins now have one single instance, instead of one instance per output (use <code>wf::per_output_plugin_t&lt;&gt;</code> as a helper for achieving the old behavior): <a href="https://github.com/WayfireWM/wayfire/pull/1674">PR #1674</a></li>
  <li>Keyboard focus is now tracked globally, instead of per-output: <a href="https://github.com/WayfireWM/wayfire/pull/1913">PR #1913</a></li>
  <li>The signals API has been rewritten, so that it operates on types instead of strings for the signal names, reducing their overhead: <a href="https://github.com/WayfireWM/wayfire/pull/1495">PR #1495</a></li>
</ul>

<h3 id="conclusion">Conclusion</h3>

<p>Thank you for reading the blog to the end :) The latest Wayfire 0.8.0 release contains many breaking changes, but also some exciting new features. Do not hesitate to open bug reports if you notice any regressions if you are upgrading from the 0.7.x series. Last but not least, many thanks to everyone who has contributed code or has tested the git version of Wayfire!</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[C uses "&" for the address-operator because 'ampersand sounds like "address"' (142 pts)]]></title>
            <link>https://softwareengineering.stackexchange.com/questions/252023/why-does-c-use-the-asterisk-for-pointers</link>
            <guid>37830079</guid>
            <pubDate>Tue, 10 Oct 2023 09:37:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://softwareengineering.stackexchange.com/questions/252023/why-does-c-use-the-asterisk-for-pointers">https://softwareengineering.stackexchange.com/questions/252023/why-does-c-use-the-asterisk-for-pointers</a>, See on <a href="https://news.ycombinator.com/item?id=37830079">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
<blockquote>
  <p>Why does C use the asterisk for pointers?</p>
</blockquote>

<p>Simply - because <a href="http://en.wikipedia.org/wiki/B_(programming_language)" rel="noreferrer">B</a> did.</p>

<blockquote>
  <p>Because memory is a linear array, it is possible to interpret the value in a cell as an index in this array, and BCPL supplies an operator for this purpose. In the original language it was spelled <code>rv</code>, and later <code>!</code>, while B uses the unary <code>*</code>. Thus, if <code>p</code> is a cell containing the index of (or address of), or pointer to) another cell, <code>*p</code> refers to the contents of the pointed-to cell, either as a value in an expression or as the target of an assignment.</p>
</blockquote>

<p><sup>From <a href="http://cm.bell-labs.com/cm/cs/who/dmr/chist.pdf" rel="noreferrer">The Development of the C Language</a> </sup></p>

<p>Thats it.  At this point, the question is as uninteresting as "why does python 3 use <code>.</code> to call a method? Why not <code>-&gt;</code>?"  Well... because Python 2 uses <code>.</code> to call a method.</p>

<p>Rarely does a language exist from nothing.  It has influences and is based on something that came before.</p>

<hr>

<p>So, why didn't B use <code>!</code> for derefrencing a pointer like its predecessor BCPL did?</p>

<p>Well, BCPL was a bit wordy.  Instead of <code>&amp;&amp;</code> or <code>||</code> BCPL used <code>logand</code> and <code>logor</code>.  This was because most keyboards din't have <code>∧</code> or <code>∨</code> keys and not equal was actually the word <code>NEQV</code> (see <a href="https://www.bell-labs.com/usr/dmr/www/bcpl.pdf" rel="noreferrer">The BCPL Reference Manual</a>).</p>

<p>B appears to have been partially inspired to tighten up the syntax rather than have long words for all these logical operators that programmers did fairly frequently.  And thus <code>!</code> for dereference became <code>*</code> so that <code>!</code> could be used for logical negation.  Note there's a difference between the unary <code>*</code> operator and the binary <code>*</code> operator (multiplication).</p>

<hr>

<blockquote>
  <p>Well, what about <em>other</em> options, like <code>-&gt;</code>?</p>
</blockquote>

<p>The <code>-&gt;</code> was taken for syntactic sugar around field derefrences <code>struct_pointer-&gt;field</code> which is <code>(*struct_pointer).field</code></p>

<p>Other options like <code>&lt;-</code> could create ambiguous parsings.  For example:</p>

<pre><code> foo &lt;- bar
</code></pre>

<p>Is that to be read as:</p>

<pre><code>(foo) &lt;- (bar)
</code></pre>

<p>or</p>

<pre><code>(foo) &lt; (-bar)
</code></pre>

<p>Making a unary operator that is composed of a binary operator and another unary operator is quite likely to have problems as the second unary operator may be a prefix for another expression.</p>

<p>Furthermore, it is again important to try to keep the things being typed frequently to a minimum.  I would <em>hate</em> to have to write:</p>

<pre><code>int main(int argc, char-&gt;-&gt; argv, char-&gt;-&gt; envp)
</code></pre>

<p>This also becomes difficult to read.</p>

<p>Other characters might have been possible (the <code>@</code> wasn't used until <a href="https://stackoverflow.com/q/25749/289086">Objective C appropriated it</a>).  Though again, this goes to the core of 'C uses <code>*</code> because B did'.  Why didn't B use <code>@</code>?  Well, B didn't use all the characters.  There was no <code>bpp</code> program (compare <a href="http://en.wikipedia.org/wiki/C_preprocessor" rel="noreferrer">cpp</a>) and other characters were available in B (such as <code>#</code> which was later used by cpp).</p>

<p>If I may hazard a guess as to why - its because of where the keys are.  From a <a href="https://www.bell-labs.com/usr/dmr/www/btut.pdf" rel="noreferrer">manual on B</a>:</p>

<blockquote>
  <p>To facilitate manipulation of addresses when it seems advisable, B provides two unary address operators, <code>*</code> and <code>&amp;</code>. <code>&amp;</code> is the address operator so <code>&amp;x</code> is the address of <code>x</code>, assuming it has one. <code>*</code> is the indirection operator; <code>*x</code> means "use the content of x as an address."</p>
</blockquote>

<p>Note that <code>&amp;</code> is shift-7 and <code>*</code> is shift-8.  Their proximity to each other may have been a hint to the programmer as to what they do... but that's only a guess. One would <a href="https://softwareengineering.stackexchange.com/questions/252023/why-does-c-use-the-asterisk-for-pointers/273268#273268">have to ask Ken Thompson</a> about why that choice was made.</p>

<hr>

<p>So, there you have it.  C is that way because B was.  B is that way because it wanted to change from how BCPL was.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[350,757 coin flips show coins tend to land the same-side up they started (287 pts)]]></title>
            <link>https://arxiv.org/abs/2310.04153</link>
            <guid>37829926</guid>
            <pubDate>Tue, 10 Oct 2023 09:06:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2310.04153">https://arxiv.org/abs/2310.04153</a>, See on <a href="https://news.ycombinator.com/item?id=37829926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/math?searchtype=author&amp;query=Barto%C5%A1,+F">František Bartoš</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sarafoglou,+A">Alexandra Sarafoglou</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Godmann,+H+R">Henrik R. Godmann</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sahrani,+A">Amir Sahrani</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Leunk,+D+K">David Klein Leunk</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Gui,+P+Y">Pierre Y. Gui</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Voss,+D">David Voss</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ullah,+K">Kaleem Ullah</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zoubek,+M+J">Malte J. Zoubek</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nippold,+F">Franziska Nippold</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Aust,+F">Frederik Aust</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Vieira,+F+F">Felipe F. Vieira</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Islam,+C">Chris-Gabriel Islam</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zoubek,+A+J">Anton J. Zoubek</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Shabani,+S">Sara Shabani</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Petter,+J">Jonas Petter</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Roos,+I+B">Ingeborg B. Roos</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Finnemann,+A">Adam Finnemann</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lob,+A+B">Aaron B. Lob</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Hoffstadt,+M+F">Madlen F. Hoffstadt</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Nak,+J">Jason Nak</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=de+Ron,+J">Jill de Ron</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Derks,+K">Koen Derks</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Huth,+K">Karoline Huth</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Terpstra,+S">Sjoerd Terpstra</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bastelica5,+T">Thomas Bastelica5</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Matetovici,+M">Magda Matetovici</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Ott,+V+L">Vincent L. Ott</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zetea,+A+S">Andreea S. Zetea</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Karnbach,+K">Katharina Karnbach</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Donzallaz,+M+C">Michelle C. Donzallaz</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=John,+A">Arne John</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Moore,+R+M">Roy M. Moore</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Assion,+F">Franziska Assion</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=van+Bork,+R">Riet van Bork</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Leidinger,+T+E">Theresa E. Leidinger</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Zhao,+X">Xiaochang Zhao</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Motaghi,+A+K">Adrian Karami Motaghi</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pang,+T">Ting Pang</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Armstrong,+H">Hannah Armstrong</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Peng,+T">Tianqi Peng</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bialas,+M">Mara Bialas</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Pang,+J+Y">Joyce Y.-C. Pang</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Fu,+B">Bohan Fu</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Yang,+S">Shujun Yang</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Lin,+X">Xiaoyi Lin</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Sleiffer,+D">Dana Sleiffer</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Bognar,+M">Miklos Bognar</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Aczel,+B">Balazs Aczel</a>, <a href="https://arxiv.org/search/math?searchtype=author&amp;query=Wagenmakers,+E">Eric-Jan Wagenmakers</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2310.04153.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Many people have flipped coins but few have stopped to ponder the statistical and physical intricacies of the process. In a preregistered study we collected 350,757 coin flips to test the counterintuitive prediction from a physics model of human coin tossing developed by Persi Diaconis. The model asserts that when people flip an ordinary coin, it tends to land on the same side it started -- Diaconis estimated the probability of a same-side outcome to be about 51%. Our data lend strong support to this precise prediction: the coins landed on the same side more often than not, $\text{Pr}(\text{same side}) = 0.508$, 95% credible interval (CI) [$0.506$, $0.509$], $\text{BF}_{\text{same-side bias}} = 2364$. Furthermore, the data revealed considerable between-people variation in the degree of this same-side bias. Our data also confirmed the generic prediction that when people flip an ordinary coin -- with the initial side-up randomly determined -- it is equally likely to land heads or tails: $\text{Pr}(\text{heads}) = 0.500$, 95% CI [$0.498$, $0.502$], $\text{BF}_{\text{heads-tails bias}} = 0.183$. Furthermore, this lack of heads-tails bias does not appear to vary across coins. Our data therefore provide strong evidence that when some (but not all) people flip a fair coin, it tends to land on the same side it started. Our data provide compelling statistical support for Diaconis' physics model of coin tossing.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: František Bartoš [<a href="https://arxiv.org/show-email/8331a914/2310.04153">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 6 Oct 2023 11:00:15 UTC (138 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simulation Islands (170 pts)]]></title>
            <link>https://box2d.org/posts/2023/10/simulation-islands/</link>
            <guid>37829551</guid>
            <pubDate>Tue, 10 Oct 2023 07:55:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://box2d.org/posts/2023/10/simulation-islands/">https://box2d.org/posts/2023/10/simulation-islands/</a>, See on <a href="https://news.ycombinator.com/item?id=37829551">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            

            

            <div>
                <p>Island management is a fundamental low level feature of physics engines and can have a big impact on solver design and performance. This was one of the first problems I decided to work on for Box2D version 3 (v3).</p>
<p>Since I began working on v3 I've been comparing several algorithms for island management. My goal has been to make island building scale better with multiple CPU cores. Here are the three approaches I've considered:</p>
<ul>
<li>Depth-first search (DFS)</li>
<li>Parallel union-find</li>
<li>Persistent islands</li>
</ul>
<p>Let's dive in!</p>
<h2 id="what-are-islands">What are islands?</h2>
<p>You can view a rigid body simulation as a graph where bodies are nodes and constraints are edges. Constraints consist of contacts (shapes touching) and joints (hinges, sliders, etc). From the graph point of view contacts and joints are the same.</p>
<p>In graph theory islands are called <a href="https://en.wikipedia.org/wiki/Component_(graph_theory)">connected components</a>. In rigid body simulation static bodies are not part of the graph. For example, this image shows three islands.</p>
<p><img src="https://box2d.org/images/islands.svg" alt="islands"><em>Islands</em></p>
<p>Static bodies are not part of the island graph because they can be shared among multiple islands. They <strong>need</strong> to shared because in a video game lots of bodies will be touching the static ground. Without sharing the static bodies among multiple islands there will be far fewer islands. Islands then lose their value. Islands are not required for correctness. They are an optimization (as we shall see) and they only work well as an optimization if there are many islands. Static bodies <strong>can</strong> be shared because nothing in the simulation affects their position or velocity. Sharing static bodies among multiple islands requires a little bit of care in the algorithms, but this is straight forward and for simplicity I will not include such logic in my examples.</p>
<p>In practice an island is a data structure that keeps track of a set of bodies and a set of constraints. This is the island data structure in Box2D v2.4:</p>
<div><pre><code data-lang="cpp"><span>class</span> <span>b2Island</span>
{
    b2Body<span>*</span><span>*</span> bodies;
    b2Contact<span>*</span><span>*</span> contacts;
    b2Joint<span>*</span><span>*</span> joints;
    <span>int</span> bodyCount;
    <span>int</span> contactCount;
    <span>int</span> jointCount;
};
</code></pre></div><p>
The island uses arrays of pointers because the island does not own the bodies or constraints. An island is a subset of the simulation world.</p>
<p>Users of Box2D don't interact with islands. They are an implementation detail of the solver. Box2D v2.4 does not retain islands across time steps, so there is no way to access them.</p>
<h3 id="sleeping-and-waking">Sleeping and waking</h3>
<p>Islands are very useful in game physics. The most important aspect is sleeping. Sleeping rigid bodies are removed from the solver and this drastically reduces their CPU load. The engine checks islands during simulation for low energy. If all bodies in an island have low energy for several time steps, then all the bodies in the island are flagged as sleeping and no longer added to the active simulation. The Box2D debug display shows sleeping bodies as gray.</p>
<p><img src="https://box2d.org/images/sleep.png" alt="sleep"></p>
<p>Sleeping must be done per island, not per body. I made this mistake early in my work on game physics. If you put a body to sleep but not the whole island then you will see shapes begin to overlap and joints begin to dislodge.</p>
<p>Sleep has a flip side as well: waking.</p>
<p>Bodies wake other sleeping bodies through constraints and this must propagate through all touching bodies immediately. Otherwise you get those nasty overlapping shapes and dislodged joints. Islands are just as important for waking as for sleeping.</p>
<h3 id="parallel-islands">Parallel islands</h3>
<p>Islands work well for multicore simulation. Game worlds often have many separate islands of bodies. A ragdoll over here. A pile of debris over there. This relates to the concept of <em>spatial coherence</em> as described by Gino van den Bergen in his book <a href="http://dtecta.com/publications">Collision Detection in Interactive 3D Environments</a>. Spatial conherence says that rigid bodies tend to spread out and we can take advantage of this to improve performance and lower memory usage.</p>
<p>An island can be simulated indepedently from other islands. Therefore an island can be simulated on a thread and you can send multiple islands to multiple threads using a task system such as <a href="https://github.com/dougbinks/enkiTS">enkiTS</a>. This scales very well with CPU core count as long as there are a sufficient number of islands. This is also cache efficient because the core is doing significant work on a subset of the simulation world.</p>
<p>Parallel islands simulation is not a silver bullet. There may not be enough islands to span all the CPU cores. In some games there may be a large pile or tower of rigid bodies that are in a single island. This large single island can dominate performance even with multithreading. It can lead to a situation where many cores are sitting idle. I plan to discuss large islands in a future post.</p>
<p><img src="https://box2d.org/images/tower.jpg" alt="tower"><em>Large Island</em></p>
<h2 id="depth-first-search">Depth-first search</h2>
<p>Box2D v2.4 uses depth-first search <a href="https://en.wikipedia.org/wiki/Depth-first_search">DFS</a> to build islands from scratch every time step. Version 2.4 does not have multithreading support, so islands are only used for sleeping and waking.</p>
<p>The <code>SolveIslands</code> function takes all the bodies and constraints of the simulation world and finds their simulation islands. Before finding the islands, it clears a mark (visitation flag) on every body and constraint. These marks ensure that a body or constraint is only added to a single island.</p>
<p>The algorithm has a simulation island <em>G</em> that is reused for each island found. The island finder loops over all bodies and looks for awake dynamic bodies to be the <em>seed</em> for the island. Starting from the <em>seed</em>, connected bodies and constraints are added to <em>G</em>. Once all the connected bodies have been traversed the island <em>G</em> is simulated, updating the constraint forces and the body velocities and positions. Then the algorithm continues looking for the next seed body that hasn't already been simulated in the current time step.</p>
<pre><code>function SolveIslands(bodies, constraints)
    ClearMarks(bodies)
    ClearMarks(constraints)
    let G be an island

    for seed in bodies
        if seed not marked and seed is dynamic and seed is awake
            Clear(G)
            Mark(seed)
            let S be a stack
            S.Push(seed)
            while S not empty
                b = S.Pop()
                G.Add(b)
                for c in b.GetConstraints()
                    if c not marked
                        G.Add(c)
                        Mark(c)
                        other = OtherBody(c)
                        if other not marked
                            S.Push(other)
            G.Simulate()
</code></pre><p>DFS has linear time complexity in the number of bodies. It can be made faster by only using awake bodies as seeds. This can be done by keeping an array of awake dynamic bodies.</p>
<p>Traversal mark management can also be expensive. At the cost of more memory, each body and constraint can hold a time step counter. The DFS can then compare a body's time step counter with the current time step count of the physics world. Marking a body or constraint is done by setting the local time step counter equal to the world time step count.</p>
<p>The DFS naturally wakes bodies. When a body is added to an island it is flagged as awake. A body can only be flagged as sleeping with another routine called <code>IslandSleep</code>.</p>
<p>Part of island simulation is checking for sleeping. Every body has velocity and a sleep timer. If the velocity is greater than a velocity threshold then sleep timer is reset. Otherwise it is advanced by the time step. If the minimum sleep timer of all bodies in an island is greater than a <em>time to sleep</em> threshold then the entire island is marked as sleeping.</p>
<pre><code>function IslandSleep(islandBodies, timeStep)
    minSleepTime = MAX_FLOAT
    for b in islandBodies
        if b velocity &gt; velocityThreshold
            b.sleepTime = 0
            minSleepTime = 0
        else
            b.sleepTime += timeStep
            minSleepTime = Min(minSleepTime, b.sleepTime)

    if minSleepTime &gt; timeToSleep
        for b in islandBodies
            MarkSleeping(b)
</code></pre><p>Then the next time step no collisions between sleeping bodies are updated and sleeping bodies are not added to simulation islands unless an awake body begins interacting with a sleeping body. This is a huge win for performance in large game worlds.</p>
<p>Watch this video if you want more details on DFS:

</p><p>
  <iframe src="https://www.youtube.com/embed/7fujbpJ0LB4" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="union-find">Union-find</h2>
<p>Union-find (UF) is a competitor to DFS for game physics island simulation. This algorithm is also called a <a href="https://en.wikipedia.org/wiki/Disjoint-set_data_structure">Disjoint-set data structure</a>.</p>
<p>UF focuses on merging sets (islands). Each dynamic body starts alone in its own set. As constraints are added to the world the sets are merged. Within each set a single body is considered the root body and uniquely identifies the set. After all constraints have been added the union-find is complete.</p>
<p>This video series explains union-find very well: <a href="https://youtube.com/playlist?list=PLDV1Zeh2NRsBI1C-mR6ZhHTyfoEJWlxvq&amp;si=brluQ5CldgIXFMhv">https://youtube.com/playlist?list=PLDV1Zeh2NRsBI1C-mR6ZhHTyfoEJWlxvq&amp;si=brluQ5CldgIXFMhv</a>. If you are not familiar with union-find and/or path compression, please go watch this and come back.</p>
<p>Like DFS, union-find (with path compression) has linear time complexity for building islands. Union-find can be a drop-in replacement for DFS. However, some additional care must be used to ensure that all touching bodies are woke up.</p>
<h2 id="the-amdahl-problem">The Amdahl problem</h2>
<p>DFS and UF are fast but they are not parallel algorithms. So when I began multithreading Box2D I started to get timing results like this:</p>
<p><img src="https://box2d.org/images/dfs_island.png" alt="island gap"></p>
<p>This is <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's law</a> in action. Multi-core scaling is limited by single-threaded processing. You will also notice a single-threaded broadphase section which I'll discuss in a future post.</p>
<h2 id="parallel-union-find">Parallel union-find</h2>
<p>At the GDC 2022, Jorrit Rouwe introduced a parallel union-find algorithm. The slides are <a href="https://gdcvault.com/play/1027560/Architecting-Jolt-Physics-for-Horizon">here</a>. You can also find an implementation in <a href="https://github.com/jrouwe/JoltPhysics">Jolt Physics</a>.</p>
<p>I implemented this algorithm in Box2D v3. In the process I learned a lot about using atomics and lock-free algorithms. If you want to learn more about atomics and the C/C++ memory model, I highly recommend this two-part video by Herb Sutter:</p>

<p>
  <iframe src="https://www.youtube.com/embed/A8eCGOqgvH4" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>The first challenge I faced was making the algorithm recursive so that it would wake entire islands in one time step. I needed to add some additional iteration to ensure that all touching bodies are woken up. After fumbling with atomics a bit, I got something working.</p>
<p>However, I quickly ran into a problem and did a lot of head scratching trying to figure out the problem. Fortunately I still have plenty of hair.</p>
<p>Parallel union-find uses atomic compare-and-swap (<a href="https://en.wikipedia.org/wiki/Compare-and-swap">CAS</a>) when merging islands. This means the order of constraints in the resulting islands is non-deterministic. The final order depends on which core happens to be faster at completing the CAS. This can change dramatically across time steps and repeated runs of the application.</p>
<p>This is a serious problem for the solver used in game physics because the constraints are solved one at a time, sequentially. The results from each constraint propagate to the next constraint. This contraint solver algorithm is formally called the <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method">Gauss-Seidel method</a>. The problem is magnified because Box2D uses <em>warm starting</em> for contacts, which gets confused when the contraint order varies each time step. You can read more about Gauss-Seidel and warm starting <a href="http://box2d.org/files/ErinCatto_IterativeDynamics_GDC2005.pdf">here</a>.</p>
<p>The constraints can be sorted after union-find and they can be sorted for each island independently. However, I could not find a faster way to do this than by using quicksort which is O(n log n). For large islands this added cost is significant, even when sorting a minimal index array. This video shows the effect of a parallel union-find and the resulting non-deterministic constraint order.</p>

<p>
  <iframe src="https://www.youtube.com/embed/3hMYUx6bIZ8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>The serial DFS and UF do not have this problem. They generate constraints in a deterministic order. The loss of determinism is due to multithreading and the use of atomic CAS. If you want to learn more about determinism and multithreading, I recommend this video:</p>

<p>
  <iframe src="https://www.youtube.com/embed/mXkPCaZUXhg" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h2 id="whats-next">What's next?</h2>
<p>After implementing the parallel union-find I took a step back and reconsidered my options and tried to look at the big picture.</p>
<p>First, I decided that I did not want to sacrifice determinism. As a programmer I value predictability in the software I write. Determinism affects my ability to debug and any Box2D user's ability to debug. I'm willing to give up performance for my software to be debuggable.</p>
<p>Second, Amdahl says that the serial part of a program dominates scaling. However, having a very fast serial part might be okay. Not every algorithm needs to be parallel if it is fast enough. So maybe I can find something faster than DFS or serial UF.</p>
<p>Third, Gino also describes <em>temporal coherence</em> in his book. Temporal coherence says the configuration of rigid bodies in a simulation does not change much across a single time step. How often do islands change? I suspect islands change slowly.</p>
<p>Fourth, maybe the cost of islands can be spread out in other ways. For example, it is urgent that islands are merged within the current time step. This is necessary to wake islands immediately. On the other hand it is not urgent to put islands to sleep or to split islands when bodies stop interacting. Delayed sleep is a minor performance loss.</p>
<h2 id="persistent-islands">Persistent islands</h2>
<p>The points above led to me investigate persistent islands. Persistent islands are retained across time steps. They need to support adding and removing bodies and contraints incrementally.</p>
<p>When a dynamic body is created it also creates a new island: an island of a single body. Static bodies do not get islands.</p>
<p>When a constraint between two dynamic bodies is created the two associated islands are merged. It may be the case that the bodies are already in the same island and this is an early out in the island merger.</p>
<p>When a dynamic body is destroyed it is removed from its island. If that island is now empty then the island is also destroyed.</p>
<p>When a constraint is destroyed then it is removed from the island. The island becomes a candidate for splitting.</p>
<p>I need to merge persistent islands immediately. This is necessary to ensure that all bodies that should be awake are added to the active simulation.</p>
<p>Persistent island splitting can be deferred. I can put a quota on island splitting. For example, one island per time step can split. Maybe I can choose to split the largest island first. Or maybe I can choose to split the island with the most constraints removed. Some heuristic can be used. I suspect any reasonable heuristic is fine.</p>
<p>I modified the v2.4 island structure to support adding and removing bodies and constraints quickly using linked lists. This also makes it fast to merge islands. Linked lists are slow to traverse because of cache misses, but I suspect I will not need to traverse them often. I also added a flag <code>maySplit</code> to indicate that the island has had contacts or joints removed and it may be possible to split the island into two or more islands.</p>
<div><pre><code data-lang="c"><span>struct</span> b2Island
{
	<span>int</span> index;
	<span>int</span> parentIsland;

	<span>int</span> headBody;
	<span>int</span> tailBody;

	<span>int</span> headContact;
	<span>int</span> tailContact;

	<span>int</span> headJoint;
	<span>int</span> tailJoint;

	<span>bool</span> maySplit;
};</code></pre></div>
<p>If I have an existing set of islands I can add an edge and this may lead to two islands merging. Island merging should be fast and it has to be deterministic. I decided to stick with serial union-find for merging islands.</p>
<p>Here is the code for adding a contact constraint. Joints are similar. I abbreviated the code a bit and left out path compression. You can see the full version <a href="https://github.com/erincatto/box2c/blob/a0a9c6e72c9f2174fdf6582c5d4ba60f5343b2ba/src/island.c#L193">here</a>. Notice that islands are flagged as awake when they are merged.</p>
<div><pre><code data-lang="c"><span>void</span> <span>b2LinkContact</span>(b2Island<span>*</span> islands, b2Body<span>*</span> bodyA, b2Body<span>*</span> bodyB, b2Contact<span>*</span> contact)
{
	<span>int</span> islandIndexA <span>=</span> bodyA<span>-</span><span>&gt;</span>islandIndex;
	<span>int</span> islandIndexB <span>=</span> bodyB<span>-</span><span>&gt;</span>islandIndex;

	<span>if</span> (islandIndexA <span>=</span><span>=</span> islandIndexB)
	{
        <span>// bodyA and bodyB are already in the same island
</span><span></span>		b2AddContactToIsland(<span>&amp;</span>islands[islandIndexA], contact);
		<span>return</span>;
	}

	<span>// Find root of islandA
</span><span></span>	b2Island<span>*</span> rootA <span>=</span> <span>&amp;</span>islands[islandIndexA];
	b2WakeIsland(rootA);
    <span>while</span> (rootA<span>-</span><span>&gt;</span>parentIsland <span>!</span><span>=</span> B2_NULL_INDEX)
    {
        rootA <span>=</span> <span>&amp;</span>islands[rootA<span>-</span><span>&gt;</span>parentIsland];
        b2WakeIsland(rootA);
    }

	<span>// Find root of islandB
</span><span></span>	b2Island<span>*</span> rootB <span>=</span> <span>&amp;</span>islands[islandIndexB];
	b2WakeIsland(rootB);
    <span>while</span> (rootB<span>-</span><span>&gt;</span>parentIsland <span>!</span><span>=</span> B2_NULL_INDEX)
    {
        rootB <span>=</span> <span>&amp;</span>islands[rootB<span>-</span><span>&gt;</span>parentIsland];
        b2WakeIsland(rootB);
    }

	<span>// Make islandB a child of islandA
</span><span></span>	<span>if</span> (rootA <span>!</span><span>=</span> rootB)
	{
		rootB<span>-</span><span>&gt;</span>parentIsland <span>=</span> rootA<span>-</span><span>&gt;</span>index;
	}

	b2AddContactToIsland(rootA, contact);
}</code></pre></div>
<p>Removing a contact from an island involves linked list bookkeeping and flagging the island for spitting (<code>maySplit</code>). Union-find is not involved.</p>
<p>Once all the new constraints have been added to all islands, there is a serial merge step. Here is an abbreviated version of the code. The full version is <a href="https://github.com/erincatto/box2c/blob/a0a9c6e72c9f2174fdf6582c5d4ba60f5343b2ba/src/island.c#L578">here</a>. The function <code>b2MergeIslandWithParent</code> is just some boring bookkeeping code. Note that <code>b2DestroyIsland</code> invalidates the current island, so tread carefully.</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>b2MergeIslands</span>(b2Island<span>*</span> islands, <span>int</span> count)
{
	<span>// Step 1: ensure every child island points directly to its root island
</span><span></span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> count; <span>+</span><span>+</span>i)
	{
		b2Island<span>*</span> island <span>=</span> <span>&amp;</span>islands[i];
		b2Island<span>*</span> rootIsland <span>=</span> island;

		<span>while</span> (rootIsland<span>-</span><span>&gt;</span>parentIsland <span>!</span><span>=</span> B2_NULL_INDEX)
		{
			rootIsland <span>=</span> <span>&amp;</span>islands[rootIsland<span>-</span><span>&gt;</span>parentIsland];
		}

		<span>if</span> (rootIsland <span>!</span><span>=</span> island)
		{
			island<span>-</span><span>&gt;</span>parentIsland <span>=</span> rootIsland<span>-</span><span>&gt;</span>index;
		}
	}

	<span>// Step 2: merge every awake island into its parent
</span><span></span>	<span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> count; <span>+</span><span>+</span>i)
	{
		b2Island<span>*</span> island <span>=</span> <span>&amp;</span>islands[i];
		<span>if</span> (island<span>-</span><span>&gt;</span>parentIsland <span>!</span><span>=</span> B2_NULL_INDEX)
		{
            b2MergeIslandWithParent(island);
            b2DestroyIsland(island);
		}
    }
}
</code></pre></div>
<p>These code snippets show that union-find builds multiple island trees then collapses each island tree into its root island. With persistence this process can occur incrementally as shapes come into contact.</p>
<h2 id="island-splitting">Island splitting</h2>
<p>I handle island splitting by taking an island and using all of its bodies as seeds for the DFS algorithm. This could be done with union-find as well. Any island finding algorithm will do. I'm not really splitting the island, I just building new islands from the original island.</p>
<p>Because the island is guaranteed not to connect to other islands, the depth-first traversal is guaranteed to stay within the original island. This is critical to allow the original island to be split concurrently with other work.</p>
<p>Here is the pseudo-code for island splitting. It is very similar to the DFS algorithm above. Instead of dealing with all the bodies and constraints in the entire simulation world, it is limited to the bodies and constraints of a single island. After a new island is built, it is added to the world as a new persistent islands. After the island is split the original island is destroyed. This is fine because nothing should refer to the original island at this point.</p>
<pre><code>function SplitIsland(world, island)
    bodies = GetIslandBodies(island)
    constraints = GetIslandConstraints(island)
    ClearMarks(bodies)
    ClearMarks(constraints)

    let G be an island

    for seed in bodies
        if seed not marked and seed is dynamic and seed is awake
            Clear(G)
            Mark(seed)
            let S be a stack
            S.Push(seed)
            while S not empty
                b = S.Pop()
                G.Add(b)
                for c in b.GetConstraints()
                    if c not marked
                        G.Add(c)
                        Mark(c)
                        other = OtherBody(c)
                        if other not marked
                            S.Push(other)
            world.AddIsland(G)

    world.DestroyIsland(island)
</code></pre><p>The result of splitting the island is one or more new islands. It is a little sad if only one new island results, but it would be the correct result. Removing a constraint may or may not cause and island to split into two islands. Determining whether an island will split or not is similar to the work of doing the DFS, so I might as well optimistically attempt to split the island.</p>
<h2 id="making-persistent-islands-fast">Making persistent islands fast</h2>
<p>While working on parallel union-find I learned that the narrow-phase can drive island management. The narrow-phase is the simulation stage where contact points are computed between colliding shapes. The contact pairs that manage potentially colliding shapes are persisted across time steps. Each contact pair holds the current contact points. The number of contact points is 0, 1, or 2. If the number of contact points changes from zero to non-zero or vice-versa then there is an edge that should be added or removed from the island graph.</p>
<p>Scalability requires the narrow-phase to be executed in parallel. This is a naturally parallel algorithm because the contact points between one shape pair are not affected by other shape pairs. This is the easiest part of a physics engine to spread across multiple cores. Like butter on bread.</p>
<p>When a contact pair is updated there are three outcomes relevant to persistent islands:</p>
<ol>
<li>edge added</li>
<li>edge removed</li>
<li>unchanged</li>
</ol>
<p>The gambit is that most pairs fall in the third camp in a typical game scenario. This seems to be the case so far in my testing.</p>
<p>Edge additions need to be processed right away, before the islands are solved. I handle this with serial union-find as described above. Edge removals are less urgent. The contact constraint needs to be removed right away, but the island doesn't need to be split. Removing and edge doesn't mean the island will split. There may be other edges holding the island together. However, the island might split. So I flag the island as potentially splitting.</p>
<p>I can defer island splitting to later. For example, I can split an island after it has been solved, in the same task. This works because island A doesn't care if island B is split. Island A only cares if island B wants to merge with it. And merging is handled serially.</p>
<p>How about determinism? Determinism is maintained if the edge additions and removals are processed in deterministic order. It turns out in Box2D that the order of contact pairs in the world is deterministic, so I just need to process the edge changes according to the order of the contact pairs. However, there can be a huge number of contact pairs and looping over all the pairs serially looking for changes is going to be very slow.</p>
<p>There is one data structure that can have an large number of entries and still be fast to iterate across. The bit array! Modern CPUs help us do this quickly with bit scanning intrinsics. See <a href="https://en.wikipedia.org/wiki/Find_first_set">this</a> and <a href="https://lemire.me/blog/2018/02/21/iterating-over-set-bits-quickly/">this</a>.</p>
<p>The bit array can also work well with multithreading. Each narrow-phase worker can access a thread context that holds a local bit array. When the contact pair has an edge add or remove outcome, it flips a bit in the thread context bit array. Then after the narrow phase is complete, the main thread can bit-wise OR all the bit arrays together. This is quite fast using a bit array built on 64-bit words. And no atomics are needed.</p>
<p>Putting this all together I have the program flow shown below. This example has three threads in the narrow phase. Each thread gets its own bit array which is initially all zeros. When a contact pair is processed it checks if the number of contact points went from 0 to non-zero or vice-versa. In either case it sets the thread's bit array at the index associated with the contact pair. After all contact pairs are processed the bits from each thread are combined into a global bit array using bit-wise OR. Then a loop iterates over the global bit array looking for set bits. If a set bit is found, the code looks up the contact pair and determines if an edge should be added or removed from the island graph and then does that work. These additions and removals are done serially in the main thread. This retains a deterministic constraint order.</p>
<p><img src="https://box2d.org/images/persistent_island_bits.svg" alt="persistent island flow"><em>Persistent island program flow</em></p>
<p>In practice the number of set bits is very small. Bit traversal is very fast, even for a large number of contact pairs.</p>
<h2 id="results">Results</h2>
<p>And performance? Performance is good. Gino was right!</p>
<p>This image shows a typical timing result. The blue bars are the contact pairs and the yellow bars are the island constraint solvers. The gap in between is the serial island management. The gap also includes island solver preparation and task system overhead.</p>
<p><img src="https://box2d.org/images/persistent_islands.png" alt="persistent island performance"></p>
<p>Let's look at some benchmarks.</p>
<p>The first test is 182 pyramids with a base of 10 boxes, so 55 bodies each and a total of 10010 bodies. These pyramids are not moving and so this test favors persistent islands.</p>
<p><img src="https://box2d.org/images/pyramid_benchmark.png" alt="pyramid benchmark"></p>
<p>The tumbler test has 2000 boxes inside a hollow box that is constantly rotating on a revolute joint. This test should be difficult for persistent islands because constraints are constantly being added and removed. The darker boxes are colored that way because Box2D considers them fast enough to engage continuous collision checks.</p>
<p><img src="https://box2d.org/images/tumbler_benchmark.png" alt="tumbler benchmark"></p>
<p>Here are the results for the two tests. Times are in milliseconds. The first time value is the average and the value in parentheses is the maximum. For DFS I'm using <a href="https://github.com/erincatto/box2c/commit/e105c0c3787d485ae3796f83cef301664dd88911">commit #32</a> of Box2D v3. For persistent islands I'm using <a href="https://github.com/erincatto/box2c/commit/96c9978577d21d856b09e6a775d4e63d5643a24f">commit #36</a>.</p>
<p>For persistent islands there can be many frames in a row where the island management has no work, making it tricky to benchmark. Persistent islands are strangly fast. I had to verify the code was working a few times. Indeed it is doing real work as I have tested island merging and splitting as well as sleeping and waking.</p>
<p>Take the maximums with a grain of salt. They could be due to anything. I include them because the persistent island has a heavier load when the bodies are created and this is relevant to avoid frame rate dips.</p>
<table>
<thead>
<tr>
<th>Test</th>
<th>DFS</th>
<th>Persistent</th>
</tr>
</thead>
<tbody>
<tr>
<td>pyramids</td>
<td>0.69 (0.98)</td>
<td>0.01 (0.45)</td>
</tr>
<tr>
<td>tumbler</td>
<td>0.43 (0.87)</td>
<td>0.08 (0.43)</td>
</tr>
</tbody>
</table>
<p>Persistent islands are roughly an order of magnitude faster than DFS.</p>
<h2 id="what-about-splitting">What about splitting?</h2>
<p>The current implementation uses DFS to split at most one island per time step. My current heuristic is to split the largest island that has had one or more constraints removed.</p>
<p>Island splitting isn't free but it is usually easy to hide the cost. I have experimented with putting the island splitting at the end of an island solve task. When there are many islands and multiple cores then this time is almost completely hidden and insignificant, amounting to a few microseconds on a single core.</p>
<p>If there are a small number of large islands then the cost of splitting can be significant. Nevertheless, island splitting can be done in parallel with other work and this is a significant gain over the traditional serial DFS/UF.</p>
<h2 id="summary">Summary</h2>
<p>I covered a lot of material in this post and there are a lot of references and auxilliary knowledge. Simulation islands touch a lot of systems, so it is challenging to fully understand islands without understanding how a physics engine is put together. Hopefully I've provided enough background knowledge so you can understand the scope of island mangement. If not, please let me know!</p>
<p>These are the main takeaways I have learned or reinforced while working on islands:</p>
<ul>
<li>island management can become a bottleneck in multicore simulation</li>
<li>determinism is important for game physics</li>
<li>spatial and temporal coherence provide many opportunities for improving performance</li>
<li>sometimes a fast serial algorithm may be better than a parallel algorithm</li>
<li>bit arrays are awesome!</li>
</ul>
<h2 id="whats-next-1">What's next?</h2>
<p>At the end of this journey I have many tools to work with islands. This will help me as I explore other aspects of improving Box2D.</p>
<p>There is more work to do on Box2D and more to write up. I plan to post more in the future on broad-phase improvements and dealing with large islands. Stay tuned!</p>

            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Netflix uses Java (134 pts)]]></title>
            <link>https://www.infoq.com/news/2023/10/java-at-netflix-bakker/</link>
            <guid>37829395</guid>
            <pubDate>Tue, 10 Oct 2023 07:25:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.infoq.com/news/2023/10/java-at-netflix-bakker/">https://www.infoq.com/news/2023/10/java-at-netflix-bakker/</a>, See on <a href="https://news.ycombinator.com/item?id=37829395">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<p><a href="https://qconsf.com/speakers/paulbakker">Paul Bakker</a>, Java Platform at Netflix, Java Champion, and Co-Author of "Java 9 Modularity," presented <a href="https://qconsf.com/presentation/oct2023/how-netflix-really-uses-java">How Netflix Really Uses Java</a> at the 2023 <a href="https://qconsf.com/">QCon San Francisco</a> conference.</p>

<p>Bakker put an end to the myth that "Netflix is all RxJava microservices with Hystrix and Spring Cloud and Chaos Monkeys running the show."</p>

<p>Bakker described the original architecture behind the familiar Netflix movie application, accessed via television and other devices, that connects to their Groovy-enabled API server using REST and gRPC connections to their various services.</p>

<p><img alt="" data-src="news/2023/10/java-at-netflix-bakker/en/resources/1infoq-netflix-architecture-01-1696877032453.png" src="https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/10/java-at-netflix-bakker/en/resources/1infoq-netflix-architecture-01-1696877032453.png" rel="share"></p>

<p>The first upgrades featured multiple remote calls, parallel computing and fault tolerance implemented with RxJava and Hystrix. However, there were limitations such as: a script required for each endpoint, UI developers who generally don't like Groovy and Java; and the fact that reactive programming is hard.</p>

<p><img alt="" data-src="news/2023/10/java-at-netflix-bakker/en/resources/1infoq-netflix-architecture-02-1696877032453.png" src="https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/10/java-at-netflix-bakker/en/resources/1infoq-netflix-architecture-02-1696877032453.png" rel="share"></p>

<p>Bakker then introduced the GraphQL Federation, an architecture model that allows multiple GraphQL services, known as subgraphs or federated services, to be combined into a single schema or API, and the concept behind GraphQL as an alternative to the over-fetching and under-fetching issues inherent in REST.</p>

<p>Their GraphQL Federated Gateway connecting to Domain Graph Services (DGS) essentially replaced the original API server to communicate with the various services via gRPC. Benefits included: no API duplication; no server-side development for the UI developers; a shared GraphQL schema; and no Java client libraries.</p>

<p><img alt="" data-src="news/2023/10/java-at-netflix-bakker/en/resources/1infoq-netflix-architecture-03-1696877032453.png" src="https://imgopt.infoq.com/fit-in/1200x2400/filters:quality(80)/filters:no_upscale()/news/2023/10/java-at-netflix-bakker/en/resources/1infoq-netflix-architecture-03-1696877032453.png" rel="share"></p>

<p>Java remains in active development at Netflix. They support Azul Zulu 17, Azul's downstream distribution of OpenJDK, with active testing on JDK 21, running approximately 2800 applications built with approximately 1500 libraries. Gradle along with <a href="http://nebula-plugins.github.io/">Nebula</a>, a collection of Gradle plugins built by Netflix, and IntelliJ IDEA are their preferred build tools.</p>

<p>Bakker provided a retrospective of their JDK 17 upgrade that provided performance benefits, especially since they were running JDK 8 as recently as this year. Netflix observed a 20% increase of CPU usage on JDK 17 compared to JDK 8. This was mostly due to the improvements in the G1 garbage collector.</p>

<p>Netflix is actively testing on JDK 21, and Bakker feels that a subsequent upgrade to JDK 21 will be much easier and faster. The use of Generational ZGC will be a much better fit for a variety of workloads at Netflix and they will ultimately replace their thread pools with virtual threads. But "virtual threads are not a free lunch," Bakker maintained, as he warned that simply adding virtual threads to an application can actually decrease performance if the libraries are CPU intensive.</p>

<p>Netflix also supports Spring Cloud with <a href="https://spring.io/projects/spring-cloud-netflix">Spring Cloud Netflix</a>, a subproject that provides Netflix open-source software integrations for Spring Boot apps.</p>

								









  
    <div> <!-- main wrapper for authors section -->
        <h2>About the Author</h2> <!-- section title -->

        
            
                
            
            <div data-id="author-Michael-Redlich">
                    <h4><strong>Michael Redlich</strong></h4>
                    
                </div>
        
    </div>

							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A real-time 3D digital map of Tokyo's public transport system (167 pts)]]></title>
            <link>https://minitokyo3d.com</link>
            <guid>37829061</guid>
            <pubDate>Tue, 10 Oct 2023 06:20:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minitokyo3d.com">https://minitokyo3d.com</a>, See on <a href="https://news.ycombinator.com/item?id=37829061">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Chuck Feeney has died (138 pts)]]></title>
            <link>https://www.cnn.com/2023/10/09/business/billionaire-duty-free-shoppers-founder-charles-feeney-dead/index.html</link>
            <guid>37828322</guid>
            <pubDate>Tue, 10 Oct 2023 03:46:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/10/09/business/billionaire-duty-free-shoppers-founder-charles-feeney-dead/index.html">https://www.cnn.com/2023/10/09/business/billionaire-duty-free-shoppers-founder-charles-feeney-dead/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=37828322">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/lede-71eef364df43f494b83a2840318aa520@published" data-name="Charles Feeney 2014 FILE RESTRICTED" data-component-name="image" data-observe-resizes="" data-original-ratio="0.66625" data-original-height="1066" data-original-width="1600" data-url="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="720" width="1280" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill/f_webp" type="image/webp"><source height="540" width="960" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_540,w_960,c_fill/f_webp" type="image/webp"><source height="270" width="480" media="(-webkit-min-device-pixel-ratio: 2)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_270,w_480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/231009161036-charles-feeney-2014-file-restricted.jpg?c=16x9&amp;q=h_720,w_1280,c_fill" alt="Charles Feeney, founder of the Atlantic Philanthropies, in San Francisco on Oct. 30, 2014. " onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1066" width="1600"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">Los Angeles</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_5C5CDF17-8F2C-6AFA-881D-160B0D81DAA1@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Charles “Chuck” Feeney, a retail entrepreneur and investor who amassed a multibillion-dollar fortune and then gave it all away, has died. He was 92.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_F0CAE2EF-B2E0-D023-AF06-165502A0E565@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      He died peacefully in San Francisco on Monday, the Atlantic Philanthropies, Feeney’s foundation, said on <a href="https://www.atlanticphilanthropies.org/news/the-atlantic-philanthropies-community-mourn-the-loss-of-founder-charles-f-feeney" target="_blank">its website</a>.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_8EF97CE7-3A0F-ED22-BFE6-161AF1D7FB79@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney made much of his fortune after co-founding Duty Free Shoppers, a chain of duty-free airport stores specializing in luxury goods, in 1960 with an undergraduate classmate from Cornell University. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_7D260FD5-DE02-DF84-EC30-16706895B183@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In 1996, Feeney sold his shares in DFS to French luxury goods conglomerate LVMH, which now owns a majority stake in the retailer. DFS has more than 850 boutiques spanning multiple continents, <a href="https://www.dfs.com/en/los-angeles/who-we-are" target="_blank">according</a> to the brand’s website.  
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_40DE81D7-8F8F-E4E6-CAF1-162A69E92234@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney was a proponent of “Giving While Living,” believing he could make more of a difference in causes he cared about while he was alive, rather than setting up a foundation after he died, according to the Atlantic Philanthropies. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_6527BDC2-1C0C-F13C-46AD-162D524D6D3D@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “It’s much more fun to give while you are alive than to give when you are dead,” Feeney said in a biography about him, “The Billionaire Who Wasn’t.” 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_15217409-D73D-8899-A15D-1630C1C2643E@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney set up the Atlantic Philanthropies in 1982, transferring all of his business assets to it two years later, according to the foundation. In 2020, the foundation closed its doors after it said it had successfully given away all of its funds.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_0FDA56F0-7636-1733-F4E8-16338AD94049@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In total, the Atlantic Philanthropies made grants totaling $8 billion across five continents — much of it anonymously, the foundation said. Donations supported education, health care, human rights and more. Feeney’s foundation donated to infrastructure in Vietnam, universities in Ireland and medical centers devoted to finding cures for cancer and cardiovascular disease, according to the foundation’s<a href="https://www.atlanticphilanthropies.org/our-story" target="_blank"> website</a>. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_0DE1396B-6D43-D2A4-44C8-163AE3988F11@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney chose to live the last three decades of his life frugally, his foundation said: He did not own a car or home, preferring to live in a rented apartment in San Francisco, according to the foundation.  
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_7819CCB1-3D95-F319-5C8D-164200775F08@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney was born into a working-class Irish-American family during the Great Depression in Elizabeth, New Jersey, enrolling in Cornell University in 1952 with support from the GI Bill. He was the first in his family to go to college. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_582BA497-208A-B777-C7B0-163F75D68077@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Feeney has been referred to as Cornell’s “third founder” due to the magnitude of his investment in the university. He gave nearly $1 billion to Cornell through his foundation since 1982, according to an obituary on <a href="https://news.cornell.edu/stories/2023/10/chuck-feeney-cornells-third-founder-dies-92" target="_blank">Cornell’s website</a>. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_4E007A90-D1B2-1AD2-0F01-16412525956C@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In 2011, Feeney signed the “Giving Pledge,” a commitment started by Bill and Melinda Gates and Warren Buffett that encourages America’s wealthiest families and individuals to dedicate their wealth to philanthropic endeavors. 
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/paragraph_4E3BB549-6ECC-CBE4-28A2-164574EB118A@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “I cannot think of a more personally rewarding and appropriate use of wealth than to give while one is living — to personally devote oneself to meaningful efforts to improve the human condition,” Feeney <a href="https://givingpledge.org/pledger?pledgerId=195" target="_blank">wrote</a> in his pledge letter. 
  </p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox tooltip bug fixed after 22 years (759 pts)]]></title>
            <link>https://bugzilla.mozilla.org/show_bug.cgi?id=148624</link>
            <guid>37827995</guid>
            <pubDate>Tue, 10 Oct 2023 02:43:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=148624">https://bugzilla.mozilla.org/show_bug.cgi?id=148624</a>, See on <a href="https://news.ycombinator.com/item?id=37827995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">

 


<main id="bugzilla-body" tabindex="-1">



<div id="main-inner">










<div id="summary-container">


  
    <p><span id="field-value-status_summary">
      <span data-status="closed">Closed</span>
      <span id="field-value-bug_id">
        <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=148624">Bug 148624</a>
      </span>
      <span>
        <span>Opened <span title="2002-06-02 08:27 PDT" data-time="1023031675">22 years ago</span></span>
          <span>Closed <span title="2023-09-07 14:35 PDT" data-time="1694122541">1 month ago</span></span>
      </span>
        </span>
    </p>

  
</div>





<div id="module-tracking">
    <table>
        <tbody><tr>
          <th></th>
          <th>Tracking</th>
          <th>Status</th>
        </tr>
        <tr>
          <td>firefox119</td>
            <td>---
            </td>
          <td>
              <a href="https://bugzilla.mozilla.org/buglist.cgi?f1=cf_status_firefox119&amp;o1=equals&amp;v1=fixed">fixed</a>
          </td>
        </tr>
    </tbody></table>
  </div>


























<div id="module-attachments"><table role="table" id="attachments">
    <tbody><tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=101434" title="Tooltip over another app, Mozilla minimized">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Tooltip over another app, Mozilla minimized
            </a>
        </p></div>
        <div>
            <p><a href="#c3"><span title="2002-10-02 12:27 PDT" data-time="1033586863">21 years ago</span></a>
          
        </p></div>
        <p>1.90 KB,
          image/png        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=101434&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=342606" title="Task tooltip over reminder window, which was focused">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Task tooltip over reminder window, which was focused
            </a>
        </p></div>
        <div>
            <p><a href="#c24"><span title="2008-10-10 12:03 PDT" data-time="1223665415">15 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=268633"> <span>Emerson Prado</span></a>
</p></div></span>
        </p></div>
        <p>64.50 KB,
          image/gif        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=342606&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=495197" title="Still happens in Fx4 nightly.">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Still happens in Fx4 nightly.
            </a>
        </p></div>
        <div>
            <p><a href="#c27"><span title="2010-12-03 17:52 PST" data-time="1291427540">13 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=396243"> <span>Richard Newman [:rnewman]</span></a>
</p></div></span>
        </p></div>
        <p>20.46 KB,
          image/png        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=495197&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=548429" title="Screenshot showing Firefox 5.0.1 tooltip intruding into foreground">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Screenshot showing Firefox 5.0.1 tooltip intruding into foreground
            </a>
        </p></div>
        <div>
            <p><a href="#c32"><span title="2011-07-26 05:53 PDT" data-time="1311684834">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>55.82 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=548429&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=550978" title="Adblock Plus tooltip intrudes into Transmission.">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Adblock Plus tooltip intrudes into Transmission.
            </a>
        </p></div>
        <div>
            <p><a href="#c34"><span title="2011-08-05 02:08 PDT" data-time="1312535302">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>76.35 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=550978&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=550980" title="Google search tooltip intrudes into Transmission">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Google search tooltip intrudes into Transmission
            </a>
        </p></div>
        <div>
            <p><a href="#c35"><span title="2011-08-05 02:11 PDT" data-time="1312535500">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>66.90 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=550980&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=550986" title="Bookmark tool bar item's &quot;mouse over&quot; state has been triggered">
              <img src="https://bugzilla.mozilla.org/extensions/BugModal/web/image.png" width="16" height="16">Bookmark tool bar item's "mouse over" state has been triggered
            </a>
        </p></div>
        <div>
            <p><a href="#c36"><span title="2011-08-05 02:39 PDT" data-time="1312537194">12 years ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=420961"> <span>edrazeba</span></a>
</p></div></span>
        </p></div>
        <p>70.14 KB,
          image/jpeg        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=550986&amp;action=edit">Details</a>
    </td></tr>
    <tr>
      <td>
        <div>
            <p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511">Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin</a>
        </p></div>
        <div>
            <p><a href="#c46"><span title="2023-09-04 21:22 PDT" data-time="1693887740">1 month ago</span></a>
          <span><div><p><a href="https://bugzilla.mozilla.org/user_profile?user_id=733734"> <span>fanzhuyifan+github</span></a>
</p></div></span>
        </p></div>
        <p>48 bytes,
          text/x-phabricator-request        </p>
      </td>
      <td>
      </td>
      <td>
        <a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511&amp;action=edit">Details</a>  |
  <a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511">Review</a>
    </td></tr>
</tbody></table>


  </div>







<meta name="firefox-versions" content="{&quot;FIREFOX_AURORA&quot;:&quot;&quot;,&quot;FIREFOX_DEVEDITION&quot;:&quot;119.0b7&quot;,&quot;FIREFOX_ESR&quot;:&quot;115.3.1esr&quot;,&quot;FIREFOX_ESR_NEXT&quot;:&quot;&quot;,&quot;FIREFOX_NIGHTLY&quot;:&quot;120.0a1&quot;,&quot;LAST_MERGE_DATE&quot;:&quot;2023-09-25&quot;,&quot;LAST_RELEASE_DATE&quot;:&quot;2023-09-26&quot;,&quot;LAST_SOFTFREEZE_DATE&quot;:&quot;2023-09-21&quot;,&quot;LAST_STRINGFREEZE_DATE&quot;:&quot;2023-09-22&quot;,&quot;LATEST_FIREFOX_DEVEL_VERSION&quot;:&quot;119.0b7&quot;,&quot;LATEST_FIREFOX_OLDER_VERSION&quot;:&quot;3.6.28&quot;,&quot;LATEST_FIREFOX_RELEASED_DEVEL_VERSION&quot;:&quot;119.0b7&quot;,&quot;LATEST_FIREFOX_VERSION&quot;:&quot;118.0.1&quot;,&quot;NEXT_MERGE_DATE&quot;:&quot;2023-10-23&quot;,&quot;NEXT_RELEASE_DATE&quot;:&quot;2023-10-24&quot;,&quot;NEXT_SOFTFREEZE_DATE&quot;:&quot;2023-10-19&quot;,&quot;NEXT_STRINGFREEZE_DATE&quot;:&quot;2023-10-20&quot;}">



<div id="c1"><p>Assignee: Matti → jaggernaut</p><p>Status: UNCONFIRMED → NEW</p><p>Component: Browser-General → XP Toolkit/Widgets</p><p>Ever confirmed: true</p><p>QA Contact: imajes-qa → jrgm</p></div><div id="c2"><p>OS: MacOS X → All</p><p>Hardware: Macintosh → All</p></div><div id="c39"><div id="ct-39" data-comment-id="16115496" data-ismarkdown="true"><p>The severity field for this bug is relatively low, S3. However, the bug has 8 duplicates and 15 votes.<br>
:enndeakin, could you consider increasing the bug severity?</p>
<p>For more information, please visit <a href="https://wiki.mozilla.org/Release_Management/autonag#severity_underestimated.py" rel="nofollow">auto_nag documentation</a>.</p>
</div><div><p>Flags: needinfo?(enndeakin)</p></div></div><div id="c40"><p>The last needinfo from me was triggered in error by recent activity on the bug. I'm clearing the needinfo since this is a very old bug and I don't know if it's still relevant.</p><div><p>Flags: <span>needinfo?(enndeakin)</span></p></div></div><div id="c41" data-comment-id="16134528" data-ismarkdown="true"><p>Still reproducible (and still extremely annoying) with Thunderbird 102.4.1 (64-bit) and Firefox 106.0.1 (64-bit) on GNU/Linux.  When I'm multitasking, I need to manually minimize Thunderbird in order to prevent its tooltips from interfering from my work in other windows.</p>
<p>Not reproducible with SeaMonkey 2.53.14, so maybe this isn't a Core product issue after all, or maybe SeaMonkey has done something to override the bad behaviour.  Maybe the Firefox and Thunderbird developers can see what SeaMonkey has done to fix the issue and implement the same fix.</p>
</div><div id="c42" data-comment-id="16209122" data-ismarkdown="true"><p>This 21 year old bug is still open. It is quite annoying, to be frank -- happens to me at least once per day.</p>
<p>That said, given its longevity, I'm kinda partial to let it be forever. It feels like a relic from the past.</p>
</div><div id="c43"><p>Hi, still happening to me too (OS: KDE Neon 22.04).<br>
Firefox v113.0.2</p></div><div id="c44" data-comment-id="16513999" data-ismarkdown="true"><p>Still happening on Firefox 115.0.2 + GNOME 44.</p>
<p>I just browser-hopped back to firefox this week and this was one of the larger annoyances, as I trigger it constantly.</p>
<p>For people who find this page via search engine, like me, the solution I'm using is to disable tooltips entirely, with the setting <code>browser.chrome.toolbar_tips</code>. It's a weird thing to have to resort to, but I don't think there's really any situation where I'll miss them.</p>
</div><div id="c45" data-comment-id="16560274" data-ismarkdown="true"><p>I am also experiencing this bug.</p>
<p>Version: firefox 117.0, clean profile; also thunderbird 115.2.0. Using xfce with xfwm.</p>
<p>Steps to reproduce:</p>
<pre><code>Hover mouse over element that will generate tooltip.
Just as the tooltip is a about to appear, but before the tooltip appears, use hotkey to switch to another workspace.
</code></pre>
<p>Symptoms:<br>
The tooltip will appear in the other workspace, and will not disappear until I switch back to firefox and move my mouse.</p>
</div><div id="a670856065_600971"><p>Assignee: nobody → fanzhuyifan+github</p><p>Status: NEW → ASSIGNED</p></div><div id="c47" data-comment-id="16563191" data-ismarkdown="true"><p>(In reply to fanzhuyifan+github from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=148624#c45" title="RESOLVED FIXED - Tooltips persist in foreground when Firefox is in background">comment #45</a>)</p>
<blockquote>
<p>I am also experiencing this bug.</p>
<p>Version: firefox 117.0, clean profile; also thunderbird 115.2.0. Using xfce with xfwm.</p>
<p>Steps to reproduce:</p>
<pre><code>Hover mouse over element that will generate tooltip.
Just as the tooltip is a about to appear, but before the tooltip appears, use hotkey to switch to another workspace.
</code></pre>
<p>Symptoms:<br>
The tooltip will appear in the other workspace, and will not disappear until I switch back to firefox and move my mouse.</p>
</blockquote>
<p>Reproducing the bug on firefox-nightly, on linux, xorg, xfce with xfwm.</p>
<p>Updated Steps to reproduce:</p>
<ul>
<li>Hover mouse over browser element that will generate tooltip (e.g., task bar. not webpage elements with tooltips)</li>
<li>alt-tab to another window or use quick key to switch to another workspace</li>
</ul>
</div><div id="c48"><p>I think a better fix would be for widget to send a window-level mouse exit event when the workspace switch happens. But I'm not sure where that code would go or how we would detect this situation.</p></div><div id="c49"><p>The nodes are already getting focusout events when workspace switches. This means some part of the code must already be detecting this situation, right?</p></div><div id="a671069636_600971"><p><a href="https://bugzilla.mozilla.org/attachment.cgi?id=9351511&amp;action=edit" title="Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin">Attachment #9351511</a> -
        Attachment description: Bug 148624 - cancel tooltip timer on focusout. r=mstange,cmartin → Bug 148624 - only show tooltip when document has focus. r=mstange,cmartin</p></div><div id="c52"><p>Status: ASSIGNED → RESOLVED</p><p>Closed: <span title="2023-09-07 14:35 PDT" data-time="1694122541">1 month ago</span></p><p>Resolution: --- → FIXED</p><p>Target Milestone: --- → 119 Branch</p></div><div id="c53"><p>For me the bug only shows up when <code>MOZ_ENV_XINPUT2</code> is set to 1. The bug disappears as soon as <code>MOZ_ENV_XINPUT2</code> is set to 0.</p></div><div id="a673661673_495955"><p>Summary: Tooltips persist in foreground when Mozilla is in background → Tooltips persist in foreground when Firefox is in background</p></div>



</div> 
</main> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google wins reprieve from $32M verdict in Sonos patent fight (123 pts)]]></title>
            <link>https://www.reuters.com/legal/litigation/google-wins-reprieve-325-mln-verdict-sonos-patent-fight-2023-10-09/</link>
            <guid>37827758</guid>
            <pubDate>Tue, 10 Oct 2023 01:57:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/legal/litigation/google-wins-reprieve-325-mln-verdict-sonos-patent-fight-2023-10-09/">https://www.reuters.com/legal/litigation/google-wins-reprieve-325-mln-verdict-sonos-patent-fight-2023-10-09/</a>, See on <a href="https://news.ycombinator.com/item?id=37827758">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="primary-image" role="figure" aria-describedby="primary-image-caption"><figure><div data-testid="Image"><p><img src="https://cloudfront-us-east-2.images.arcpublishing.com/reuters/STZK46JLCZP65OYJ2NV5PHPRXI.jpg" srcset="https://www.reuters.com/resizer/Q1vsD3lJF_nhjLSG7qoT35d47Ok=/480x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/STZK46JLCZP65OYJ2NV5PHPRXI.jpg 480w,https://www.reuters.com/resizer/pfrmTjtqANWyGltbZIrGUZiU_wA=/728x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/STZK46JLCZP65OYJ2NV5PHPRXI.jpg 960w,https://www.reuters.com/resizer/pfrmTjtqANWyGltbZIrGUZiU_wA=/728x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/STZK46JLCZP65OYJ2NV5PHPRXI.jpg 1080w,https://www.reuters.com/resizer/pfrmTjtqANWyGltbZIrGUZiU_wA=/728x0/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/STZK46JLCZP65OYJ2NV5PHPRXI.jpg 1200w" sizes="(min-width: 1024px) 560px, (min-width: 1440px) 700px, 100vw" width="728" height="486" alt="The logo for Google LLC is seen at the Google Store Chelsea in Manhattan, New York City"></p></div><p data-testid="Body"><span>The logo for Google LLC is seen at the Google Store Chelsea in Manhattan, New York City, U.S., November 17, 2021. REUTERS/Andrew Kelly/File Photo <a data-testid="Link" href="https://www.reutersagency.com/en/licensereuterscontent/?utm_medium=rcom-article-media&amp;utm_campaign=rcom-rcp-lead" target="_blank" referrerpolicy="no-referrer-when-downgrade">Acquire Licensing Rights</a></span></p></figure></div><div><div><div><ul role="tablist"><li data-testid="Text" role="tab" aria-selected="true" tabindex="0">Summary</li><li data-testid="Text" role="tab" aria-selected="false" tabindex="-1">Companies</li><li data-testid="Text" role="tab" aria-selected="false" tabindex="-1">Law Firms</li></ul></div><div><ul><li data-testid="Body">Sonos patent underlying jury verdict is invalid, judge says</li><li data-testid="Body">Judge said patent used to 'enrich a pretender' by 'sleight of hand'</li></ul></div></div><p data-testid="paragraph-0">Oct 9 (Reuters) - A California federal judge has thrown out a $32.5 million verdict for wireless-audio company Sonos <a data-testid="Link" href="https://www.reuters.com/markets/companies/SONO.O" target="_blank" referrerpolicy="no-referrer-when-downgrade">(SONO.O)</a> against rival Google <a data-testid="Link" href="https://www.reuters.com/markets/companies/GOOGL.O" target="_blank" referrerpolicy="no-referrer-when-downgrade">(GOOGL.O)</a> after finding that the Sonos patents at the heart of the case were unenforceable.</p><p data-testid="paragraph-1">U.S. District Judge William Alsup <a data-testid="Link" href="https://tmsnrt.rs/3LUoOHD" target="_blank" referrerpolicy="no-referrer-when-downgrade">said</a> on Friday that Sonos had improperly tried to connect its patents for multi-room audio technology to a 2006 application to claim that its inventions predated Google's devices.</p><p data-testid="paragraph-2">"This was not a case of an inventor leading the industry to something new," Alsup said. "This was a case of the industry leading with something new and, only then, an inventor coming out of the woodwork to say that he had come up with the idea first."</p><p data-testid="paragraph-3">A Sonos spokesperson said on Monday that the ruling was "wrong on both the facts and law" and that the company would appeal. Representatives for Google did not immediately respond to a request for comment on the decision on Monday.</p><p data-testid="paragraph-4">The case is part of a sprawling intellectual property dispute between the former collaborators that includes other lawsuits in the U.S., Canada, France, Germany and the Netherlands.</p><p data-testid="paragraph-5">Sonos also <a data-testid="Link" href="https://www.reuters.com/markets/europe/sonos-wins-google-import-ban-ruling-us-patent-fight-2022-01-07/" referrerpolicy="no-referrer-when-downgrade">won</a> a limited import ban on some Google devices from the U.S. International Trade Commission last year based on different Sonos patents, which Google has appealed. Google has countered with its own patent lawsuits in California and at the ITC.</p><p data-testid="paragraph-6">The companies previously worked together to integrate Mountain View, California-based Google's streaming music service into Sonos products. Sonos first sued Google in 2020, accusing the tech giant of copying its technology in wireless audio devices including Google Home and Chromecast Audio.</p><p data-testid="paragraph-7">Sonos <a data-testid="Link" href="https://www.reuters.com/legal/us-jury-says-google-owes-sonos-325-million-smart-speaker-patent-case-2023-05-26/" referrerpolicy="no-referrer-when-downgrade">won</a> $32.5 million in damages from Google in San Francisco in May after a federal jury found that Google's devices infringed one of the company's patents. Google asked Alsup to toss the verdict on several grounds, including that Sonos strategically held off on applying for the patents for more than a decade until the tech giant had introduced its allegedly infringing devices.</p><p data-testid="paragraph-8">Alsup agreed with Google on Friday that Sonos had connected its 2019 patent applications to an application from 2006 to receive artificially early priority dates. Google began selling its competing devices in 2015, and the judge said Google's products "anticipated" the 2019 patents and made them invalid.</p><p data-testid="paragraph-9">The case is Sonos Inc v. Google LLC, U.S. District Court for the Northern District of California, No. 3:20-cv-06754.</p><p data-testid="paragraph-10">For Google: Sean Pak of Quinn Emanuel Urquhart &amp; Sullivan</p><p data-testid="paragraph-11">For Sonos: Clement Roberts of Orrick Herrington &amp; Sutcliffe</p><p data-testid="paragraph-12">Read more:</p><p data-testid="paragraph-13"><a data-testid="Link" href="https://www.reuters.com/legal/us-jury-says-google-owes-sonos-325-million-smart-speaker-patent-case-2023-05-26/" referrerpolicy="no-referrer-when-downgrade">US jury says Google owes Sonos $32.5 million in smart-speaker patent case</a></p><p data-testid="paragraph-14"><a data-testid="Link" href="https://www.reuters.com/legal/google-sonos-head-trial-contentious-smart-speaker-patent-fight-2023-05-05/" referrerpolicy="no-referrer-when-downgrade">Google, Sonos head to trial in contentious smart speaker patent fight</a></p><p data-testid="Body">Reporting by Blake Brittain</p><p data-testid="Body">Our Standards: <a data-testid="Link" href="https://www.thomsonreuters.com/en/about-us/trust-principles.html" target="_blank" referrerpolicy="no-referrer-when-downgrade">The Thomson Reuters Trust Principles.</a></p><div><address><p data-testid="Body">Blake Brittain reports on intellectual property law, including patents, trademarks, copyrights and trade secrets, for Reuters Legal. He has previously written for Bloomberg Law and Thomson Reuters Practical Law and practiced as an attorney. 
Contact: +12029385713</p></address></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTX – The fraud was in the code (124 pts)]]></title>
            <link>https://newsletter.mollywhite.net/p/the-fraud-was-in-the-code</link>
            <guid>37827070</guid>
            <pubDate>Tue, 10 Oct 2023 00:14:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsletter.mollywhite.net/p/the-fraud-was-in-the-code">https://newsletter.mollywhite.net/p/the-fraud-was-in-the-code</a>, See on <a href="https://news.ycombinator.com/item?id=37827070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>We got our first glance at the FTX codebase on Friday. The prosecution brought out Github screenshots as they questioned cooperating witness </span><a href="https://newsletter.mollywhite.net/i/137602559/gary-wang" rel="">Gary Wang</a><span>, the former CTO of FTX who at various times was responsible for the codebases powering both FTX and Alameda Research. Wang has pleaded guilty to four charges.</span></p><p><span>Although there is some risk of confusing the jury when presenting them with code snippets, prosecutors had Wang step through what the code is doing in a way that seemed pretty clear to me.</span></p><p><span> It probably helped that FTX’s engineers wrote decently clean code, with descriptive variable names and concise functions, and chose a very human-readable language (Python).</span></p><p>Note to self: if you’re going to write code to do fraud, make it messy and unreadable to reduce the chances it’s later put in front of a jury as evidence.</p><p><span>Much of the conversation revolved around the </span><code>allow_negative</code><span> flag that was introduced to the FTX codebase on August 1, 2019. Wang testified that Sam Bankman-Fried had asked him and </span><a href="https://newsletter.mollywhite.net/i/137602559/nishad-singh" rel="">Nishad Singh</a><span> (former FTX engineering director, who has also pleaded guilty) to add the flag. Github screenshots show Singh making a code change to add the column in the database, and adding logic to exempt accounts with the flag from checks that would otherwise determine if they had sufficient funds to withdraw.</span></p><p> A later change by Wang himself also exempted accounts with this flag from ever being liquidated.</p><p>Prosecutors took this opportunity to point out that practically the same day this change was being made at Bankman-Fried’s direction, Bankman-Fried was out on Twitter claiming that “[Alameda’s] account is just like everyone else’s”.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png" width="1022" height="1168" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1168,&quot;width&quot;:1022,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:284475,&quot;alt&quot;:&quot;Tweet conversation:  Bitshine @bitshine_ Jul 31, 2019 @SBF_Alameda How are you going to resolve the conflict of interest of running your own derivative exchange, AND actively trading against the market at the same time?  People complain that @CryptoHayes trades against the market, yet FTX and your shop is out there.  SBF @SBF_FTX Jul 31, 2019 Alameda is a liquidity provider on FTX but their account is just like everyone else's.  Alameda's incentive is just for FTX to do as well as possible; by far the dominant factor is helping to make the trading experience as good as possible.  Bitshine @bitshine_ I guess we're just suppose to trust that you wont get preferential treatment on your own platform. Don't get me wrong, as a semi quant trader, I enjoyed your videos and FTX is a step in the right direction. BUT, i think there needs to be a bigger discussion about this issue.&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Tweet conversation:  Bitshine @bitshine_ Jul 31, 2019 @SBF_Alameda How are you going to resolve the conflict of interest of running your own derivative exchange, AND actively trading against the market at the same time?  People complain that @CryptoHayes trades against the market, yet FTX and your shop is out there.  SBF @SBF_FTX Jul 31, 2019 Alameda is a liquidity provider on FTX but their account is just like everyone else's.  Alameda's incentive is just for FTX to do as well as possible; by far the dominant factor is helping to make the trading experience as good as possible.  Bitshine @bitshine_ I guess we're just suppose to trust that you wont get preferential treatment on your own platform. Don't get me wrong, as a semi quant trader, I enjoyed your videos and FTX is a step in the right direction. BUT, i think there needs to be a bigger discussion about this issue." title="Tweet conversation:  Bitshine @bitshine_ Jul 31, 2019 @SBF_Alameda How are you going to resolve the conflict of interest of running your own derivative exchange, AND actively trading against the market at the same time?  People complain that @CryptoHayes trades against the market, yet FTX and your shop is out there.  SBF @SBF_FTX Jul 31, 2019 Alameda is a liquidity provider on FTX but their account is just like everyone else's.  Alameda's incentive is just for FTX to do as well as possible; by far the dominant factor is helping to make the trading experience as good as possible.  Bitshine @bitshine_ I guess we're just suppose to trust that you wont get preferential treatment on your own platform. Don't get me wrong, as a semi quant trader, I enjoyed your videos and FTX is a step in the right direction. BUT, i think there needs to be a bigger discussion about this issue." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F803791c2-b7bb-43a1-9f76-162e5bc58d6d_1022x1168.png 1456w" sizes="100vw"></picture></div></a><figcaption><span>Only the first tweet and Bankman-Fried’s reply were included in the government’s exhibit, but I think the reply is worth including too. (</span><a href="https://twitter.com/SBF_FTX/status/1156696100729806849" rel="">Tweets</a><span>)</span></figcaption></figure></div><p><span>Wang testified that this </span><code>allow_negative</code><span> flag was a special privilege given only to Alameda Research’s trading accounts, and a database screenshot also showed the effectively unlimited line of credit that Alameda Research could dip into:</span></p><p><span>Wang explained that Alameda had not started out with such a high credit limit, but that periodically the trading firm had run into issues placing trades because they didn’t have enough collateral, and Sam Bankman-Fried kept asking him to increase their credit limit to prevent it from happening. According to Wang, the limit was originally set to “a few million dollars”, but was then increased to $1 billion. After they ran up against that limit, too, Bankman-Fried asked him to set it to a number so large that they wouldn’t likely hit the limit. At that point, Wang set it to around $65 billion.</span></p><p>Finally, prosecutors questioned Wang about the FTX “insurance fund”, which was ostensibly supposed to protect both FTX and its customers from trades that went badly even more quickly than the exchange’s risk engine could account for. FTX published the fund’s supposed balance on their website, and bragged widely about its existence, including in testimony to U.S. Congress. However, according to Wang, the number shown on the website was falsified.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png" width="514" height="314.3883495145631" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b6448891-80fd-446a-b739-bb72b186f84c_1030x630.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:630,&quot;width&quot;:1030,&quot;resizeWidth&quot;:514,&quot;bytes&quot;:138239,&quot;alt&quot;:&quot;Tweet: FTX @FTX_Official The 5.25 million FTT we put in our insurance fund in 2019 now makes the fund worth over 100 million USD  Screenshot: Backstop Fund Size: 5,478,274.51613972 USD, 5,250,000.00000000 FTT Last updated: 14/02/2021, 08:05:00&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Tweet: FTX @FTX_Official The 5.25 million FTT we put in our insurance fund in 2019 now makes the fund worth over 100 million USD  Screenshot: Backstop Fund Size: 5,478,274.51613972 USD, 5,250,000.00000000 FTT Last updated: 14/02/2021, 08:05:00" title="Tweet: FTX @FTX_Official The 5.25 million FTT we put in our insurance fund in 2019 now makes the fund worth over 100 million USD  Screenshot: Backstop Fund Size: 5,478,274.51613972 USD, 5,250,000.00000000 FTT Last updated: 14/02/2021, 08:05:00" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb6448891-80fd-446a-b739-bb72b186f84c_1030x630.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Tweet, exhibit GX-751</figcaption></figure></div><blockquote><p>AUSA: Is it a real number?</p><p>Wang: No.</p><p>AUSA: So it’s a fake number?</p><p>Wang: Yes.</p><p>AUSA: Was the real number higher or lower than the fake number?</p><p>Wang: Lower.</p></blockquote><p>Code snippets shown to the jury demonstrated how Nishad Singh wrote some code that would update the insurance fund amount by adding to it the daily trading volume, multiplied by a randomish number around 7,500, and dividing it by a billion, thus making it appear as though the website was referencing a real account balance that was fluctuating as the exchange added funds or withdrew from it to cover losses. In reality, it was all made up.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png" width="1444" height="1146" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1146,&quot;width&quot;:1444,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1087068,&quot;alt&quot;:&quot;Github diff showing addition of code:  def _get_change()-> Decimal:     daily_volume = current_session().query(func.sum(Trade.size * Trade.price)).filter(         Trade.created_at > datetime.now() - timedelta(days=1)).scalar() or Decimal()         return f2d(numpy.random.normal(7500, 3000))* daily_volume / Decimal('1e9')  @always_run_in_transaction(ro=False) def update_public_insurance_fund():     change = _get_change() sess = current_session() +     public_insurance_fund = Public InsuranceFund.get(sess)  sess.add(Public InsuranceFundChange(public_insurance_fund-public_insurance_fund, size-change))     public_insurance_fund.size += change     sess.commit()&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Github diff showing addition of code:  def _get_change()-> Decimal:     daily_volume = current_session().query(func.sum(Trade.size * Trade.price)).filter(         Trade.created_at > datetime.now() - timedelta(days=1)).scalar() or Decimal()         return f2d(numpy.random.normal(7500, 3000))* daily_volume / Decimal('1e9')  @always_run_in_transaction(ro=False) def update_public_insurance_fund():     change = _get_change() sess = current_session() +     public_insurance_fund = Public InsuranceFund.get(sess)  sess.add(Public InsuranceFundChange(public_insurance_fund-public_insurance_fund, size-change))     public_insurance_fund.size += change     sess.commit()" title="Github diff showing addition of code:  def _get_change()-> Decimal:     daily_volume = current_session().query(func.sum(Trade.size * Trade.price)).filter(         Trade.created_at > datetime.now() - timedelta(days=1)).scalar() or Decimal()         return f2d(numpy.random.normal(7500, 3000))* daily_volume / Decimal('1e9')  @always_run_in_transaction(ro=False) def update_public_insurance_fund():     change = _get_change() sess = current_session() +     public_insurance_fund = Public InsuranceFund.get(sess)  sess.add(Public InsuranceFundChange(public_insurance_fund-public_insurance_fund, size-change))     public_insurance_fund.size += change     sess.commit()" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33b15ea1-a6e3-4342-9410-34f8eea18393_1444x1146.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>From exhibit </span><a href="https://mollywhite.net/storage/sbf-trial/GX-600.pdf" rel="">GX-600</a><span>. The falsified account balance change is primarily calculated in line 19.</span></figcaption></figure></div><p><span>This is pretty damning. One could possibly explain away an inaccurate number — say, one that was hardcoded into the website and never changed to reflect the true fund balance — by saying that they had   correctly represented it at one point in time and forgot to change it. But it’s really hard to come up with a good explanation for why the fund was being incremented by a </span><em>random</em><span> fluctuating number that was in no way tied to any actual account balance, besides the obvious: that FTX was trying to present a falsified but convincing number to customers. That would be fraud.</span></p><p>Elsewhere in the code, it’s possible to observe that the amount of FTT in the fund was actually represented by a hardcoded value in the user interface, and was not pulling from an external datasource to get a real number. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png" width="1414" height="1742" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1742,&quot;width&quot;:1414,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1363503,&quot;alt&quot;:&quot;function InsuranceFundInformation() {   let insuranceFund = useData('/stats/insurance_fund');   let classes = useStyles();   if (!insuranceFund) {     return null;   }   return (     <Card className={classes.card}>       <CardContent>         <Typography variant=\&quot;h5\&quot; gutterBottom>           <Trans>Insurance Fund</Trans>         </Typography>         <Typography>           <Trans>             Size: {{ usdSize: coinSizeFormat.format(insuranceFund.size) }} USD,{' '} {{ fttSize: coinSizeFormat.format(5250000) }} FTT           </Trans>         </Typography>       <Typography>         <Trans>           Last updated: {{ lastUpdated: new Date(insuranceFund.updatedAt).toLocaleString() }}         </Trans>       </Typography>       </CardContent>     </Card>   ); }&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="function InsuranceFundInformation() {   let insuranceFund = useData('/stats/insurance_fund');   let classes = useStyles();   if (!insuranceFund) {     return null;   }   return (     <Card className={classes.card}>       <CardContent>         <Typography variant=&quot;h5&quot; gutterBottom>           <Trans>Insurance Fund</Trans>         </Typography>         <Typography>           <Trans>             Size: {{ usdSize: coinSizeFormat.format(insuranceFund.size) }} USD,{' '} {{ fttSize: coinSizeFormat.format(5250000) }} FTT           </Trans>         </Typography>       <Typography>         <Trans>           Last updated: {{ lastUpdated: new Date(insuranceFund.updatedAt).toLocaleString() }}         </Trans>       </Typography>       </CardContent>     </Card>   ); }" title="function InsuranceFundInformation() {   let insuranceFund = useData('/stats/insurance_fund');   let classes = useStyles();   if (!insuranceFund) {     return null;   }   return (     <Card className={classes.card}>       <CardContent>         <Typography variant=&quot;h5&quot; gutterBottom>           <Trans>Insurance Fund</Trans>         </Typography>         <Typography>           <Trans>             Size: {{ usdSize: coinSizeFormat.format(insuranceFund.size) }} USD,{' '} {{ fttSize: coinSizeFormat.format(5250000) }} FTT           </Trans>         </Typography>       <Typography>         <Trans>           Last updated: {{ lastUpdated: new Date(insuranceFund.updatedAt).toLocaleString() }}         </Trans>       </Typography>       </CardContent>     </Card>   ); }" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F44f41549-76a4-4aa3-96cd-de22f5319e15_1414x1742.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>From exhibit </span><a href="https://mollywhite.net/storage/sbf-trial/GX-600.pdf" rel="">GX-600</a><span>. The hardcoded FTT value is in line 64.</span></figcaption></figure></div><p>This wasn’t highlighted to jurors, though, probably because the randomized number is far more damning.</p><p>As prosecutors continued to question Wang, he explained that there were repeated incidents in which FTX suffered losses that exceeded the real, smaller amount of assets that had been set aside in an insurance fund. One such example was in 2021, when a trader was able to exploit a bug in FTX’s margin system that allowed them to take out a massive position in the MobileCoin cryptocurrency. They were eventually liquidated, and FTX suffered a loss of “several hundred million dollars,” according to Wang.</p><p>Prosecutors haven’t mentioned it, but Sam Bankman-Fried would go on to testify under oath in front of the U.S. Congress in May 2022 that “the insurance fund has paid out a net total of $9.5 million” in the preceding three years, and that “the single biggest daily drawdown from the FTX.com insurance fund was $4.7 million.”</p><p><span>They did, however, play a clip from the </span><em>Odd Lots</em><span> podcast in which Sam Bankman-Fried lied to interviewer Matt Levine, saying that FTX’s risk management engine was so good that they had “never had a day … where there’s more money that we lost in blowouts to revenue that we made just from trading fees”.</span></p><p><audio src="https://newsletter.mollywhite.net/api/v1/audio/upload/7d7885a6-92ae-42b7-89ba-22ea6dfbaa12/src">Audio playback is not supported on your browser. Please upgrade.</audio></p><p>Wang went on to testify that the MobileCoin losses, and other similar losses that exceeded the amounts available in the insurance fund, were “taken on” by Alameda — that is, Alameda took over the account’s positions and collateral, effectively absorbing the loss as its own. Wang said that Bankman-Fried reasoned “that FTX’s balance sheets are more public than Alameda’s balance sheets, that investors have access to FTX’s finances but not Alameda’s finances.”</p><p>Indeed, just the previous day we had heard testimony from Paradigm venture capitalist Matt Huang, during which balance sheets were shown to the jury that showed $63 million in estimated trading expenses and $63 million in estimated other expenses for all of 2021 — clearly omitting the “several hundred million dollars” lost to the MobileCoin incident.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png" width="1200" height="20" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:20,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5633,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd126406b-d72b-467c-ac2b-9237b4c4849a_1200x20.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The defense team only briefly questioned Wang before the court session ended, but began by suggesting to the jury that he might be saying what the government wants to hear in the hopes of receiving a lighter sentence (he faces a maximum of 50 years in prison, but will likely receive a substantially shorter or even no custodial sentence due to his cooperation). They also tried to offer an alternative explanation for the </span><code>allow_negative</code><span> flag: that Alameda was in charge of doing conversions from US dollars to stablecoins, and for a brief period in this transaction they needed to borrow the funds from FTX before returning them in stablecoin form. Why they would need a $65 billion ceiling to do so, however, was not addressed, and seems likely to come up in redirect when court resumes on Tuesday.</span></p><p><span>Tuesday will also bring the testimony of </span><a href="https://newsletter.mollywhite.net/i/137602559/caroline-ellison" rel="">Caroline Ellison</a><span>, former Alameda Research CEO and on-and-off girlfriend of Sam Bankman-Fried. She is expected to be a star witness in this case, and the defense team has already teased their “blame Caroline” defense in opening statements.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ECC RAM on AMD Ryzen 7000 Desktop CPUs (307 pts)]]></title>
            <link>https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/</link>
            <guid>37826842</guid>
            <pubDate>Mon, 09 Oct 2023 23:39:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/">https://sunshowers.io/posts/am5-ryzen-7000-ecc-ram/</a>, See on <a href="https://news.ycombinator.com/item?id=37826842">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction<a href="#introduction" arialabel="Anchor">⌗</a></h2><p>One of the coolest features of AMD’s Ryzen desktop CPUs, and historically a great reason to get them
over the competition, was the official support for error-corrected memory (ECC RAM)<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. With most Ryzen
1000 through 5000 series CPUs and the right motherboards, ordinary users could get ECC RAM going
without having to spring for more expensive workstation-grade CPUs.</p><figure><a href="https://sunshowers.io/images/b550-specs.png"><img src="https://sunshowers.io/images/b550-specs.png" alt="Screenshot of B550 Steel Legend specification page, showing support for ECC &amp; non-ECC, unbuffered memory"></a><figcaption>Specification page for the B550 Steel Legend motherboard.</figcaption></figure><p>For example, here’s the <a href="https://www.asrock.com/mb/AMD/B550%20Steel%20Legend/index.asp#Specification">specification
page</a> for the ASRock
B550 Steel Legend motherboard. This is a mainstream “B” series motherboard which lists detailed
compatibility information for ECC RAM by processor generation.</p><p>(To my knowledge ASRock has had the best support for ECC RAM in Ryzen motherboards, and I’ve been
very happy with their motherboards in general.)</p><hr><figure><a href="https://sunshowers.io/images/x670e-specs.png"><img src="https://sunshowers.io/images/x670e-specs.png" alt="Screenshot of X670E Taichi specification page, without support for ECC memory"></a><figcaption>Specification page for the X670E Taichi motherboard, with no mention of ECC support.</figcaption></figure><p>Unfortunately, when the AMD Ryzen 7000 “Raphael” CPUs were launched along with the brand new <a href="https://en.wikipedia.org/wiki/Socket_AM5">Socket
AM5</a>, all mention of ECC support was gone. The
<a href="https://www.asrock.com/mb/AMD/X670E%20Taichi/index.asp#Specification">specification page</a> for the
ASRock X670E Taichi, one of the most expensive AM5 motherboards you can buy, has <strong>no mention of ECC
support</strong> as of the date of writing this.</p><p>I still decided to upgrade to a Ryzen 7950X, and overall I’ve been happy with the performance of the new processor. But the lack of ECC was a huge bummer at the time of purchasing my system.</p><h2 id="finding-a-forum-link">Finding a forum link<a href="#finding-a-forum-link" arialabel="Anchor">⌗</a></h2><p>A couple months ago I came across <a href="https://forum.asrock.com/forum_posts.asp?TID=24901">a topic on the ASRock
forums</a> talking about ECC support on AM5
motherboards, in which a user called ApplesOfEpicness said that they’d worked with an AMD engineer
to get ECC RAM going within AMD’s AGESA firmware. They’d claimed to have tested it on an ASRock
motherboard with an updated UEFI, by shorting ground and data pins, and seeing errors be reported up
to the OS.</p><p>I was intrigued by this! Even though I didn’t have the same motherboard that ApplesOfEpicness did, I
had chosen an ASRock board (the <a href="https://pg.asrock.com/mb/AMD/B650E%20PG%20Riptide%20WiFi/index.asp">B650E PG
Riptide</a>)—I had figured that
if ECC was possible on any AM5 board at all, it would be supported on ASRock. So based on the forum
post, last week I ordered <a href="https://v-color.net/products/ddr5-ecc-udimm-servermemory?variant=43445581906087">a pair of 32 GB server-grade ECC sticks from
v-color</a>.</p><p>I updated my motherboard’s UEFI to the latest version (version 1.28 with AGESA 1.0.0.7b), and then
replaced my existing RAM with the new sticks. I started up the system, and after a very long <a href="https://www.allaboutcircuits.com/news/boosing-memory-performance-age-ddr5-introduction-ddr-training-modes/">link
training</a>
process<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>… it booted up!</p><h2 id="does-the-os-recognize-ecc">Does the OS recognize ECC?<a href="#does-the-os-recognize-ecc" arialabel="Anchor">⌗</a></h2><p>On the Linux side, all indications were that the ECC memory was functioning correctly. <code>sudo dmidecode -t memory</code> reported:</p><pre tabindex="0"><code>% sudo dmidecode -t memory
Physical Memory Array
	Location: System Board Or Motherboard
	Use: System Memory
	Error Correction Type: Multi-bit ECC

... &lt;snip&gt; ...

Handle 0x0033, DMI type 17, 92 bytes
Memory Device
        Array Handle: 0x002E
        Error Information Handle: 0x0032
        Total Width: 72 bits
        Data Width: 64 bits
</code></pre><p>(The “Total Width” field is the important one here. For non-ECC RAM it read 64 bits, but in my case it was 72 bits because 64-bit ECC RAM has an <a href="https://www.anandtech.com/show/43/6">extra 8 bits</a> of parity data.)</p><p>Also, the Linux kernel reported that its error detection and correction subsystem,
<a href="https://docs.kernel.org/driver-api/edac.html">EDAC</a>, was enabled:</p><pre tabindex="0"><code>% sudo dmesg | grep -i EDAC
[    0.444842] EDAC MC: Ver: 3.0.0
[   25.042690] EDAC MC0: Giving out device to module amd64_edac controller F19h_M60h: DEV 0000:00:18.3 (INTERRUPT)
[   25.042693] EDAC amd64: F19h_M60h detected (node 0).
[   25.042696] EDAC MC: UMC0 chip selects:
[   25.042697] EDAC amd64: MC: 0:     0MB 1:     0MB
[   25.042699] EDAC amd64: MC: 2: 16384MB 3: 16384MB
[   25.042702] EDAC MC: UMC1 chip selects:
[   25.042703] EDAC amd64: MC: 0:     0MB 1:     0MB
[   25.042704] EDAC amd64: MC: 2: 16384MB 3: 16384MB
</code></pre><p>Looking good so far!</p><h2 id="wheres-this-data-coming-from">Where’s this data coming from?<a href="#wheres-this-data-coming-from" arialabel="Anchor">⌗</a></h2><p>At this point it’s worth asking about the source of these messages. Where is the data coming from
and why should we believe it?</p><p>Let’s look at <code>dmidecode</code> first. <code>man dmidecode</code> <a href="https://linux.die.net/man/8/dmidecode">starts with</a>:</p><blockquote><p>dmidecode is a tool for dumping a computer’s DMI (some say SMBIOS) table contents in a human‐readable format. This table contains a description of the system’s hardware components, as well as other useful pieces of information such as serial numbers and BIOS revision. Thanks to this table, you can retrieve this information without having to probe for the actual hardware. While this is a good point in terms of report speed and safeness, this also makes the presented information possibly unreliable.</p></blockquote><p>Oh, interesting, “possibly unreliable” is a little concerning! What is this SMBIOS thing anyway? <a href="https://en.wikipedia.org/wiki/System_Management_BIOS">Wikipedia says</a>:</p><blockquote><p>In computing, the System Management BIOS (SMBIOS) specification defines data structures (and access methods) that can be used to read management information produced by the BIOS of a computer. This eliminates the need for the operating system to probe hardware directly to discover what devices are present in the computer.</p></blockquote><p>So the data presented by <code>dmidecode</code> is coming from the <em>UEFI</em>, not from the processor<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. What this means is that the memory is ECC-<em>capable</em>, but not necessarily that it is <em>active</em>. Whether ECC is active is ultimately determined by the <a href="https://en.wikipedia.org/wiki/Memory_controller">memory controller</a> on the system.</p><h2 id="querying-the-memory-controller">Querying the memory controller<a href="#querying-the-memory-controller" arialabel="Anchor">⌗</a></h2><p>When I mentioned setting up ECC at <a href="https://oxide.computer/">work</a>, <a href="https://fingolfin.org/blog/">Robert
Mustacchi</a> pointed me to the excellent <a href="https://github.com/oxidecomputer/illumos-gate/blob/5f01ecd8941eadb64bc15b1a02c468604c1a503e/usr/src/uts/intel/sys/amdzen/umc.h#L22">illumos documentation about
AMD’s Unified Memory
Controller</a>.
I did some reading and learned that essentially, AMD processors expose a bus called the System
Management Network (SMN). Among other things, this bus can be used to query and configure the AMD
Unified Memory Controller (UMC).</p><div><p><strong>NOTE:</strong> The information in the rest of this section is not part of the public AMD Processor
Programming Reference, but can be gleaned from the source code for the open-source Linux and
illumos kernels.</p><p><strong>WARNING:</strong> Accessing the SMN directly, and especially sending write commands to it, is dangerous
and can <strong>severely damage</strong> your computer. Do not write to the SMN unless you know what you’re
doing.</p></div><p>The idea is that we can ask the UMC the question “is ECC enabled” directly, by sending a read
request over the SMN to what is called the <code>UmcCapHi</code> register. The exact addresses involved are a
little bit magical, but on illumos with a Ryzen 7000 processor, here’s how you would query the UMC
over the SMN bus (channel 0 and channel 1 are the two memory channels on the system, and each
channel has one of the 32GB sticks plugged into it.)</p><div><pre tabindex="0"><code data-lang="sh"><span><span><span># Query the UMC at address 0x50df4, representing channel 0</span>
</span></span><span><span>$ pfexec /usr/lib/usmn -d /devices/pseudo/amdzen@0/usmn@2:usmn.0 0x50df4
</span></span><span><span>0x50df4: 0x40000030
</span></span><span><span>
</span></span><span><span><span># Query the UMC at address 0x150df4, representing channel 1</span>
</span></span><span><span>$ pfexec /usr/lib/usmn -d /devices/pseudo/amdzen@0/usmn@2:usmn.0 0x150df4
</span></span><span><span>0x150df4: 0x40000030
</span></span></code></pre></div><p>(<code>pfexec</code> is the illumos equivalent to <code>sudo</code>.)</p><p>Also, illumos comes with a really nice way to break up a hex value into bits:</p><pre tabindex="0"><code>$ mdb -e '0x40000030=j'
                1000000000000000000000000110000
                |                        ||
                |                        |+------ bit 4  mask 0x00000010
                |                        +------- bit 5  mask 0x00000020
                +-------------------------------- bit 30 mask 0x40000000
</code></pre><p>The bit we’re interested in here is bit 30. If it’s set, then ECC is enabled in the memory controller.</p><h2 id="accessing-the-smn-on-linux-with-the-ryzen_smu-driver">Accessing the SMN on Linux with the <code>ryzen_smu</code> driver<a href="#accessing-the-smn-on-linux-with-the-ryzen_smu-driver" arialabel="Anchor">⌗</a></h2><p>Can we replicate this query on Linux? Turns out we can! There’s a neat little driver called
<a href="https://gitlab.com/leogx9r/ryzen_smu"><code>ryzen_smu</code></a> which provides access to the SMN bus. It’s easy
to download and install (though on my system I needed to <a href="https://gitlab.com/leogx9r/ryzen_smu/-/merge_requests/10">apply a
patch</a>).</p><p>The driver exposes a <a href="https://gitlab.com/leogx9r/ryzen_smu#syskernelryzen_smu_drvsmn">file called
<code>/sys/kernel/ryzen_smu_drv/smn</code></a>
which can be used to perform a query over the SMN bus. The documentation says that to perform a
query, we must write 4 bytes to the file in <a href="https://www.section.io/engineering-education/what-is-little-endian-and-big-endian/">little-endian
format</a>, and
then read 4 bytes from the output in little-endian format. This isn’t convenient to do via the
command line, so let’s write a small Python script:</p><div><pre tabindex="0"><code data-lang="python"><span><span><span># smn-query-ecc.py</span>
</span></span><span><span><span># Licensed under CC0-1.0</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>query</span>(hex_str):
</span></span><span><span>    <span># Convert hex string to bytes in little-endian</span>
</span></span><span><span>    decoded <span>=</span> int(hex_str, <span>16</span>)<span>.</span>to_bytes(<span>4</span>, byteorder<span>=</span><span>'little'</span>)
</span></span><span><span>    <span>assert</span> len(decoded) <span>==</span> <span>4</span>
</span></span><span><span>
</span></span><span><span>    <span># Write 4 bytes to the SMN file</span>
</span></span><span><span>    open(<span>"/sys/kernel/ryzen_smu_drv/smn"</span>, <span>"wb"</span>)<span>.</span>write(decoded)
</span></span><span><span>
</span></span><span><span>    <span># Read 4 bytes from the SMN file, representing the return value</span>
</span></span><span><span>    ret <span>=</span> open(<span>"/sys/kernel/ryzen_smu_drv/smn"</span>, <span>"rb"</span>)<span>.</span>read(<span>4</span>)
</span></span><span><span>
</span></span><span><span>    <span># Print ret as a hex string in little-endian order</span>
</span></span><span><span>    ret_hex_str <span>=</span> hex(int<span>.</span>from_bytes(ret, byteorder<span>=</span><span>'little'</span>))
</span></span><span><span>    print(<span>f</span><span>"returned value for </span><span>{</span>hex_str<span>}</span><span> is </span><span>{</span>ret_hex_str<span>}</span><span>"</span>)
</span></span><span><span>
</span></span><span><span><span>def</span> <span>main</span>():
</span></span><span><span>    hex_str <span>=</span> <span>"0x00050df4"</span>
</span></span><span><span>    query(<span>"0x00050df4"</span>)  <span># channel 0</span>
</span></span><span><span>    query(<span>"0x00150df4"</span>)  <span># channel 1</span>
</span></span><span><span>
</span></span><span><span><span>if</span> __name__ <span>==</span> <span>'__main__'</span>:
</span></span><span><span>    main()
</span></span></code></pre></div><p>Running this script, I got:</p><pre tabindex="0"><code>$ sudo python3 smn-query-ecc.py
return value for 0x00050df4 is 0x40000000
return value for 0x00150df4 is 0x40000000
</code></pre><p>Bit 30 (the first nibble’s <code>4</code>) is set, which means the memory controller is reporting that ECC is
enabled.</p><p>This query should also be possible on Windows, perhaps using <a href="https://github.com/irusanov/SMUDebugTool">this
tool</a>, though I can’t vouch for it.</p><div><h2 id="but-is-ecc-_really_-working">But is ECC <em>really</em> working?<a href="#but-is-ecc-_really_-working" arialabel="Anchor">⌗</a></h2><p>The most foolproof way to test whether ECC is working is to introduce an error somehow.</p><ul><li>ApplesOfEpicness did so by shorting a data and ground pin on their motherboard.</li><li>Another way would be to try and overclock the RAM until it gets to an unstable point.</li></ul><p>I don’t quite have the courage to physically short pins, nor the patience to slowly overclock my
RAM, waiting multiple minutes for DDR5 link training each time. So instead, I’m content with knowing that the memory controller is reporting that ECC is enabled.</p><p>Organically, I haven’t seen any errors so far. If a correctable or uncorrectable error does occur at
some point, I’ll update this post with that information.</p></div><h2 id="about-those-edac-messages">About those EDAC messages<a href="#about-those-edac-messages" arialabel="Anchor">⌗</a></h2><p>Earlier in this post I’d mentioned that the Linux kernel reported that EDAC was enabled. I was
curious what the data source for <em>that</em> was, so I dug into the Linux kernel source code.</p><p>Being generally unfamiliar with the Linux codebase, I used the tried and tested strategy of
searching for strings that get logged. In this case:</p><ul><li>Searching for <code>Giving out device to module</code> led me to find <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/edac_mc.c#L665-L668">this line</a> inside <code>edac_mc_add_mc_with_groups</code>.</li><li>This function is called <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L4212">here</a> inside <code>init_one_instance</code>.</li><li><code>init_one_instance</code> <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L4285">is only called</a> if <code>pvt-&gt;ops-&gt;ecc_enabled</code> returns true.</li><li>What is <code>ecc_enabled</code>? It is set to a function called <code>umc_ecc_enabled</code> in <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L3985-L3991">this code</a>. And <code>pvt-&gt;ops</code> is set to <code>umc_ops</code> <a href="https://github.com/torvalds/linux/blob/82714078aee4ccbd6ee7579d5a21f8a72155d0fb/drivers/edac/amd64_edac.c#L4023-L4024">when the processor family is &gt;= 0x17</a>. Ryzen 7000 (Zen 4) is <a href="https://en.wikipedia.org/wiki/List_of_AMD_CPU_microarchitectures#Nomenclature">family 0x19</a>.</li></ul><p>Going by just the name, <code>umc_ecc_enabled</code> sounds like it would be querying the UMC. So let’s look at <a href="https://github.com/torvalds/linux/blob/94f6f0550c625fab1f373bb86a6669b45e9748b3/drivers/edac/amd64_edac.c#L3619C51-L3619C51">what it does</a>. It looks like it’s checking that <code>umc_cap_hi</code>’s <code>UMC_ECC_ENABLED</code> bit is set.</p><p>And what is <code>UMC_ECC_ENABLED</code>? It’s <a href="https://github.com/torvalds/linux/blob/94f6f0550c625fab1f373bb86a6669b45e9748b3/drivers/edac/amd64_edac.h#L272">bit 30</a>!</p><p>So it looks like the <code>EDAC</code> messages are only shown if the UMC reports that ECC is enabled. This
means that, at least on AMD processors, the Linux kernel message <code>EDAC MC0: Giving out device to module amd64_edac</code> is a reliable indicator that ECC is enabled.</p><h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">⌗</a></h2><p>ECC RAM is great, and you can easily get it working on Ryzen 7000 desktop CPUs, at least with ASRock
motherboards. I learned a ton of low-level processor interface details along the way.</p><h2 id="acknowledgements">Acknowledgements<a href="#acknowledgements" arialabel="Anchor">⌗</a></h2><p>Thanks again to <a href="https://fingolfin.org/blog/">Robert</a> for teaching me about a lot of the details here!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop EU Chat Control (184 pts)]]></title>
            <link>https://stopchatcontrol.eu/</link>
            <guid>37826775</guid>
            <pubDate>Mon, 09 Oct 2023 23:31:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stopchatcontrol.eu/">https://stopchatcontrol.eu/</a>, See on <a href="https://news.ycombinator.com/item?id=37826775">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

		
					<main id="main">
				<article class="page" id="post-11" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
	
	
	 <!-- .entry-header -->


<div ast-blocks-layout="true" itemprop="text">

	
	
<div><div>




<p>In order to put pressure on the policy makers we need to come together and contact all of our European friends and our national members of the European Parliament to convince them that the chat control contradicts our fundamental rights. <br>With the help of GPT-3 we will support you in your political opposition.</p>




</div><figure><img decoding="async" fetchpriority="high" width="251" height="260" src="https://stopchatcontrol.eu/wp-content/uploads/2023/05/uberwachung.svg" alt=""></figure></div>



<div id="about">
<h2 id="arguments">Our Arguments</h2>



<figure><video controls="" poster="https://stopchatcontrol.eu/wp-content/uploads/2023/07/WhatsApp-Image-2023-07-03-at-15.28.30.jpeg" src="https://stopchatcontrol.eu/wp-content/uploads/2023/07/30F154C9-067E-4FAB-8EB7-DBF98ABF529F.mov"></video></figure>



<p>Ursula von der Leyen and the European Commission 🇪🇺 launch an <strong>attack on our civil rights</strong> with chat control.🚩🚩🚩 </p>



<p>With the chat control, the European Commission wants to prevent the spread of child abuse depictions and grooming. You can find out <strong>why chat control</strong> is unfortunately <strong>the wrong tool</strong> here:</p>



<p>If the chat control detects suspicious content 🚨 – it will be forwarded to an authority. The two problems here:</p>



<p>1️⃣ Completely normal photos, such as holiday pictures 🏞️ are considered suspicious. The chat control therefore produces too <strong>many false results and overloads the authorities</strong>. This will lead to fewer investigation successes.</p>



<p>2️⃣ So our <strong>private family photos or the chats </strong>and pictures from your sexting yesterday 🍑🍆 also end up on an official table. So we can throw privacy in the bin 🚮</p>



<hr>



<div>
<p>The chat control is not in line with the Charter of Fundamental Rights⛔️ The digital secrecy of letters is thus going into the digital wastebasket 🚮 The chat control would read and screen all our WhatsApp messages, emails, photos and videos on our cell phone in real time 🔦</p>



<p>Minors are <strong>prohibited from accessing apps</strong> where there is a risk that adults could write to children illegally. So basically all common social media apps. Look for a leisure activity without an app 🙃</p>
</div>



<hr>



<div>
<p>WhatsApp, Snapchat etc. are forced to <strong>check the age</strong> of their users with chat control. The apps will have to do this with a photo and proof of <strong>passport</strong>. So you can forget about being anonymous on a dating app 🙅🙅‍♂️</p>



<div>
<p>The EU Data Protection Board, the European Parliament’s Research Service and the EU Council’s Legal Service say they are warning of chat controls. Ursula von der Leyen is not interested in these opinions </p>



<p>🤡 🚩</p>
</div>



<div>
<p>The <strong>chat control destroys the encryption infrastructure</strong> 🔐 Because it must always be possible to read the encrypted messages unencrypted. That’s the only way to check what’s inside. This means full monitoring of all news, including journalists, lawyers and political opponents in exile.</p>
</div>
</div>



<hr>



<div>
<p>Child protection can also be improved without chat control. Instead, investments must be made in equipping and training the judiciary, the police, Europol and in cooperation between the authorities 💶⚖️</p>



<p>EU member states already have sufficient powers to monitor criminal suspects on a case-by-case basis and to secure evidence 🚔</p>



<p>A general surveillance of our digital communication is more reminiscent of China than European values 👁️</p>
</div>
</div>



<div id="reviews">
<h2 id="testimonials">testimonials</h2>



<figure><img decoding="async" src="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-1024x1024.jpeg" alt="" width="200" height="200" srcset="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-1024x1024.jpeg 1024w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-300x300.jpeg 300w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-150x150.jpeg 150w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-768x768.jpeg 768w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15-1536x1536.jpeg 1536w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-05-23-at-13.47.15.jpeg 1600w" sizes="(max-width: 200px) 100vw, 200px"></figure>



<p>“Commission President Von der Leyen’s planned chat control is a Big Brother agency that would monitor EU citizens’ private communications. We must prevent this massive state surveillance.”</p>



<p><strong>Moritz Körner</strong> <br>Member of the European Parliament</p>



<hr>



<figure><img decoding="async" src="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited.jpeg" alt="" width="200" height="200" srcset="https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited.jpeg 1066w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-300x300.jpeg 300w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-1024x1024.jpeg 1024w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-150x150.jpeg 150w, https://stopchatcontrol.eu/wp-content/uploads/2023/06/WhatsApp-Image-2023-06-13-at-11.35.20-edited-768x768.jpeg 768w" sizes="(max-width: 200px) 100vw, 200px"></figure>



<p>“Chat control is dangerous for us as it threatens our privacy and freedom of expression. Through the monitoring and censorship of our online communication, we are restricted in our freedom to form opinions. It also opens the door to abuse and manipulation by governments and authoritarian organizations. It is important that we defend our rights to privacy and freedom of expression in order to maintain an open and democratic society.”</p>



<p><strong>Franziska Brandmann</strong><br>Federal Chair of the Young Liberals Germany</p>
</div>



<div id="mitmachen">
<h2 id="contact-mep">Now it’s your turn! </h2>



<p>Send your local member of the European Parliament an e-mail with the drafting help of GPT-3!</p>



<p>All you need to do is to choose your country of origin:</p>




    
    
    
    



<p><strong>Please note that the drafts generated by Large Language Models can still contain errors. Read the draft carefully and eventually correct mistakes prior to sending your e-Mail!</strong></p>
</div>



<div id="whyus">
<h2 id="contact-friends">Contact your european friends</h2>



<p>Chances are high that most of your <span>European </span>friends have never heard of chat control. So let them know about the danger and what you think about the chat control proposal.</p>



<div>
<div>
<h3>Messenger services</h3>



<pre><code>Hey, 
the European Commission launched an attack on our civil rights with chat control. But we can still stop the proposal. Let us contact all our friends and also the members of the European Parliament to make sure that they vote against it.
This Website I found will help you do that using A.I.:
www.Stop-Chat-Control.eu
Check it out!</code></pre>








</div>



<div>
<h3>Twitter &amp; Facebook</h3>



<pre><code>The European Commission launched an attack on our civil rights with chat control. I contacted my local MEP to tell him that I oppose the proposal. You can do so too! This Website I found will help you write an e-mail to an MEP using A.I.: www.Stop-Chat-Control.eu #StopChatControl</code></pre>








</div>



<div>
<h3>Instagram<br> </h3>







<figure>
<figure><a href="https://www.instagram.com/moritz_koerner/"><img decoding="async" loading="lazy" width="565" height="903" src="https://stopchatcontrol.eu/wp-content/uploads/2023/07/mk_insta_eu.png" alt="" srcset="https://stopchatcontrol.eu/wp-content/uploads/2023/07/mk_insta_eu.png 565w, https://stopchatcontrol.eu/wp-content/uploads/2023/07/mk_insta_eu-188x300.png 188w" sizes="(max-width: 565px) 100vw, 565px"></a></figure>
</figure>
</div>
</div>
</div>







<div id="reviews">
<h2 id="petition">Sign our Petition!</h2>



<p>Using petitions we can put further pressure onto the lawmakers. Support us by signing our petition today! </p>




</div>

	
	
</div><!-- .entry-content .clear -->

	
	
</article><!-- #post-## -->

			</main><!-- #main -->
			
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DSLinux – Linux for the Nintendo DS (278 pts)]]></title>
            <link>https://www.dslinux.org/</link>
            <guid>37826357</guid>
            <pubDate>Mon, 09 Oct 2023 22:41:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dslinux.org/">https://www.dslinux.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37826357">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<p>The DSLinux project has ported the
	<a href="http://en.wikipedia.org/wiki/Linux">Linux</a>
	operating system to the
	<a href="http://en.wikipedia.org/wiki/Nintendo_DS">Nintendo DS</a>
        and
	<a href="http://en.wikipedia.org/wiki/Nintendo_DS_Lite">Nintendo DS Lite</a>.
	Newer models such as DSi and 3DS might work in DS-compatibility mode.
	Apart from real hardware, DSLinux also runs on some NDS emulators,
	like <a href="http://desmume.org/">desmume</a>.
	</p>

	<p>DSLinux is functional, has excellent
	<a href="https://www.dslinux.org/wiki/UsingDSLinux.html">documentation</a>,
	and brings a <a href="https://www.dslinux.org/wiki/AppDir.html">wealth of useful
	Linux programs</a> to the DS.
	See the <a href="https://www.dslinux.org/wiki/DSLinuxFAQ.html">FAQ</a> to get started.
	</p>
	<p>There are no active
	<a href="https://www.dslinux.org/wiki/ContactingDevelopers.html">developers</a>
	at the moment.
	New <a href="https://www.dslinux.org/wiki/HowToHelp.html">contributors</a> are welcome
	to pick up the ball and make use of resources provided here.
	There is plenty of documentation for new developers in the
	<a href="https://www.dslinux.org/wiki">wiki</a>.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of CSS: Easy Light-Dark Mode Color Switching with Light-Dark() (123 pts)]]></title>
            <link>https://www.bram.us/2023/10/09/the-future-of-css-easy-light-dark-mode-color-switching-with-light-dark/</link>
            <guid>37826082</guid>
            <pubDate>Mon, 09 Oct 2023 22:08:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bram.us/2023/10/09/the-future-of-css-easy-light-dark-mode-color-switching-with-light-dark/">https://www.bram.us/2023/10/09/the-future-of-css-easy-light-dark-mode-color-switching-with-light-dark/</a>, See on <a href="https://news.ycombinator.com/item?id=37826082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><img decoding="async" fetchpriority="high" src="https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark.png" alt="" width="4162" height="1996" srcset="https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark.png 4162w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-560x269.png 560w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-1120x537.png 1120w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-768x368.png 768w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-1536x737.png 1536w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-2048x982.png 2048w, https://www.bram.us/wordpress/wp-content/uploads/2023/10/css-light-dark-1568x752.png 1568w" sizes="(max-width: 4162px) 100vw, 4162px"></p>
<p>To change a color based on whether Light Mode or Dark Mode used, you’d typically use a <code>prefers-color-scheme</code> Media Query. To make things easier, CSS now comes with a utility function named <code>light-dark()</code>. The function accepts two color values as its arguments. Based on which color scheme you are actively using, it will output the first or the second argument.</p>
<p>~</p>
<h3><a name="mq" href="#mq">#</a> Responding to Light or Dark Mode</h3>
<p>To change a color value – or any other value for that matter – based on Light Mode or Dark Mode being used, you’d typically use a <code>prefers-color-scheme</code> Media Query to change the value of a Custom Property:</p>
<pre><code>:root {
  --text-color: #333; /* Value for Light Mode */
}

@media (prefers-color-scheme: dark) {
  --text-color: #ccc; /* Value for Dark Mode */
}</code></pre>
<p>When <a href="https://www.bram.us/2019/12/10/how-to-add-dark-mode-to-a-javascript-app-react-angular-vue-etc/">implementing Dark Mode</a>, you typically end up with a bunch of duplicated CSS variables that set the values for each mode. The rest of your CSS then uses these custom properties for the actual declarations.</p>
<pre><code>body {
  color: var(--text-color);
}</code></pre>
<p>~</p>
<h3><a name="light-dark" href="#light-dark">#</a> Responding to Light or Dark Mode with <code>light-dark()</code></h3>
<p>A new addition to the <a href="https://drafts.csswg.org/css-color-5/">CSS Color Module Level 5 Specification</a> is the <code>light-dark()</code> function. The function accepts two color values as its arguments. Based on which color scheme you are actively using, it will output the first or the second color argument.</p>
<pre><code>light-dark(&lt;color&gt;, &lt;color&gt;);</code></pre>
<p>As <a href="https://drafts.csswg.org/css-color-5/#light-dark">per spec</a>:</p>
<blockquote><p>This function computes to the computed value of the first color, if the used color scheme is <code>light</code> or unknown, or to the computed value of the second color, if the used color scheme is <code>dark</code>.</p></blockquote>
<p>The used color scheme is not only based on the users Light/Dark Mode setting, but also on the value of the <code>color-scheme</code> property. This similar to how <a href="https://blog.jim-nielsen.com/2021/css-system-colors/">System Colors</a> get computed.</p>
<blockquote><p>The <code>color-scheme</code> property allows an element to indicate which color schemes it is designed to be rendered with. These values are negotiated with the user’s preferences, resulting in a used color scheme […].</p></blockquote>
<p>That means, for <code>light-dark()</code> to work, you <strong>must</strong> also include a <code>color-scheme</code> declaration.</p>
<pre><code>:root {
  color-scheme: light dark;
}

:root {
  --text-color: light-dark(#333, #ccc); /* In Light Mode = return 1st value. In Dark Mode = return 2nd value. */
}</code></pre>
<p>Because <code>color-scheme</code> is taken into account, that also means that you can override its value per element, to force it into a certain mode:</p>
<pre><code>.dark {
  color-scheme: dark; /* light-dark() on this element and its children will always return dark */
}</code></pre>
<div>
<p>🤔 If this <code>light-dark()</code> seems familiar: Chromium internally sports a <code>-internal-light-dark()</code> which <a href="https://www.bram.us/2022/01/11/customize-the-password-hide-reveal-button-in-microsoft-edge/#light-dark">I wrote about before</a>. Based on this functionality, <a href="https://github.com/w3c/csswg-drafts/issues/7561">the proposal was made within the CSS Working Group</a> to expose a similar function to authors. The result is <code>light-dark()</code>.</p>
<p>Unlike <code>-internal-light-dark()</code> which is for any type of value, <code>light-dark()</code> can only be used for colors.</p></div>
<p>~</p>
<h3><a name="schemed-value" href="#schemed-value">#</a> What about other non-<code>&lt;color&gt;</code> values and responding to other color schemes?</h3>
<p>Yes, <code>light-dark()</code> is fairly limited in what it can do: it can only do light/dark and only return <code>&lt;color&gt;</code> values. But that’s intentional, as it is an intermediary step towards a final solution.</p>
<p>As proposed in <a href="https://github.com/w3c/csswg-drafts/issues/7561">the CSS Working Group issue</a>, the end goal is to have a function <em>(tentatively)</em> named <code>schemed-value()</code> in the future. That function can:</p>
<ul>
<li>Respond to any value of <code>color-scheme</code>.</li>
<li>Return more than <code>&lt;color&gt;</code> values</li>
</ul>
<p>It <em>could</em> look something like this:</p>
<pre><code>:root {
  color-scheme: dark light custom;
}

body {
  color: schemed-value(light hotpink, dark lime, custom rebeccapurple);
}</code></pre>
<p>But, for now, we “only” have <code>light-dark()</code> and I personally think that’s fine, as it rhymes with today’s reality of what browsers can do:</p>
<ul>
<li>It only supports <code>light</code> or <code>dark</code> because browsers right now <a href="https://drafts.csswg.org/css-color-adjust/#color-scheme-prop:~:text=%3Ccustom%2Dident%3E%20values%20are%20meaningless%2C%20and%20exist%20only%20for%20future%20compatibility%2C%20so%20that%20future%20added%20color%20schemes%20do%20not%20invalidate%20the%20color%2Dscheme%20declaration%20in%20legacy%20user%20agents">don’t support <code>&lt;custom-ident&gt;</code> in <code>color-scheme</code></a>, so there’s no use in supporting other values right now.</li>
<li>It can only do <code>&lt;color&gt;</code> values because <a href="https://www.w3.org/TR/css-syntax-3/#parse-grammar">the parser needs to know the value type of what it is parsing</a> ahead of time. <code>light-dark()</code> is <a href="https://drafts.csswg.org/css-color-5/#color-syntax">explicitly defined to be a <code>&lt;color&gt;</code></a>.</li>
</ul>
<p>Narrowing things down in scope/things it can do, allowed <code>light-dark()</code> to be defined now, instead of putting it on the long track. The name and syntax of <code>light-dark()</code> that was resolved on is very memorable, easy to use, and offers a solution to a common use-case.</p>
<div>
<p>When <code>schemed-value()</code> ever becomes a thing, <code>light-dark()</code> would become <a href="https://en.wikipedia.org/wiki/Syntactic_sugar">syntactic sugar</a> for it.</p>
<pre><code>light-dark(&lt;color&gt;, &lt;color&gt;); = schemed-value(light &lt;color&gt;, dark &lt;color&gt;);</code></pre>
</div>
<p>~</p>
<h3><a href="#browser-support" name="browser-support">#</a> Browser Support</h3>
<p>💡 Although this post was originally published in October 2023, the section below is constantly being updated. <em>Last update: October 09, 2023</em>.</p>
<p>Here is an up-to-date list of browser support for CSS <code>light-dark()</code>:</p>
<dl>
<dt>Chromium <em>(Blink)</em></dt>
<dd>
<p>❌ No support</p>
</dd>
<dt>Firefox <em>(Gecko)</em></dt>
<dd>
<p>✅ Supported in Firefox 120.</p>
</dd>
<dt>Safari <em>(WebKit)</em></dt>
<dd>
<p>❌ No support</p>
</dd>
</dl>
<p>The pen embedded below will indicate if the browser you are currently using supports CSS <code>light-dark()</code> or not:</p>
<p data-height="470" data-default-tab="result" data-slug-hash="ExGrNVx" data-user="bramus" data-token="8087f9a9706b4efd52ef87f16f504ef2">
  <span>See the Pen <a href="https://codepen.io/bramus/pen/ExGrNVx/8087f9a9706b4efd52ef87f16f504ef2"><br>
  CSS light-dark() Support test</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>To stay up-to-date regarding browser support, you can follow these tracking issues:</p>
<ul>
<li>Chromium/Blink: <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1490618">Issue #1490618</a> — Assigned (Open)</li>
<li>Firefox/Gecko: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1856999">Issue #1856999</a> — RESOLVED FIXED</li>
<li>Safari/WebKit: <a href="https://bugs.webkit.org/show_bug.cgi?id=262914">Issue #262914</a> — NEW</li>
</ul>
<p>~</p>
<h3><a href="#demo" name="demo">#</a> Demo</h3>
<p>If your browser supports <code>light-dark()</code>, the demo below will show a few <code>&lt;div&gt;</code>s labeled <code>.auto</code> that respond to Light/Dark mode being toggled. The <code>&lt;div&gt;</code>s with the class <code>.light</code> or <code>.dark</code> are forced into their proper mode.</p>
<p data-height="700" data-default-tab="result" data-slug-hash="LYMqRqV" data-user="bramus" data-token="8704297cfbc9e0a6bf843726a928c0e2">
  <span>See the Pen <a href="https://codepen.io/bramus/pen/LYMqRqV/8704297cfbc9e0a6bf843726a928c0e2"><br>
  light-dark() Demo</a> by Bramus (<a href="https://codepen.io/bramus">@bramus</a>)<br>
  on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>~</p>
<h3><a href="#spread-the-word name=" spread-the-word"="">#</a> Spread the word</h3>
<p>To help spread the contents of this post, feel free to retweet its announcement <del>tweet</del><ins>post</ins>/<del>toot</del><ins>post</ins>:</p>
<blockquote>
<p lang="en" dir="ltr">To change a color based on Light Mode or Dark Mode, you’d typically use a `prefers-color-scheme` Media Query.</p>
<p>To make things easier, CSS now comes with a `light-dark()` utility function.</p>
<p>Read <a href="https://t.co/uzcTGPo8dY">https://t.co/uzcTGPo8dY</a> to get to know the details.</p>
<p>Browser Support: Firefox 120. <a href="https://t.co/1rmGkKy2yl">pic.twitter.com/1rmGkKy2yl</a></p>
<p>— Bramus (@bramus) <a href="https://twitter.com/bramus/status/1711488907014021267?ref_src=twsrc%5Etfw">October 9, 2023</a></p></blockquote>


<p>~</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Brother printers sending ink data to Amazon? (141 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=37825653</link>
            <guid>37825653</guid>
            <pubDate>Mon, 09 Oct 2023 21:19:51 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=37825653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="37826099"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826099" href="https://news.ycombinator.com/vote?id=37826099&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>If you have the printer on your network, and any Amazon device on your network, the Amazon device could easily query the printer for ink levels. My Home Assistant does this and I never connected HA to the printer. It’s just part of the status information the printer seems to make available on the network.<p>It’s not surprising to me that Amazon would do this using one of their devices, as everyone seems to be grabbing as much data as they can. It’s probably described in the T&amp;Cs somewhere (that they can scan your network and use data from it).
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826498"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826498" href="https://news.ycombinator.com/vote?id=37826498&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>This is why IoT devices on my network get their own subnet and they are blocked from communicating with anything but what I allow them to communicate with, including the Internet.<p>Also I want to make it clear, it shouldn't have to be this way.  Devices should be transparent about how they function, but sadly they are not.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826672"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826672" href="https://news.ycombinator.com/vote?id=37826672&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Is your printer an IoT device? Is your Echo an IoT device?<p>I'd say yes to both, and so the problem would persist.</p><p>One way to solve this would be to put every single device on a separate vlan (like some public networks do). Just like NAT, that approach certainly has its advantages for the average user from a security perspective, but forces centralization and usage of third-party servers where it shouldn't be required.</p><p>Maybe what we need is a "network administration protocol" that would give you pop-ups on your phone when devices tried to discover what's on your network.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826984"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826984" href="https://news.ycombinator.com/vote?id=37826984&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>&gt; Is your printer an IoT device? Is your Echo an IoT device?<p>&gt;I'd say yes to both, and so the problem would persist.</p><p>My IoT LAN is configured to keep each device within the subnet isolated from one another.  So while they might share a subnet, they aren't able to snoop on each other.  They also do not share the same switch.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37827746"><td></td></tr>
                  <tr id="37826829"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826829" href="https://news.ycombinator.com/vote?id=37826829&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I keep seeing this suggestion (put devices on a subnet, lock them out of everything else)...<p>Do you have a link or guide to help me understand how to set this up. It seems like a great idea!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826869"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826869" href="https://news.ycombinator.com/vote?id=37826869&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>The cheapest way would be to go to your WiFi router and look for "Guest WiFi" settings, hope it's not too cheap that this functionality isn't included, activate said network, and put the devices on the guest WiFi.<p>More complicated settings involve the keyword "VLAN", afaik most home routers don't have this.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37827007"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37827007" href="https://news.ycombinator.com/vote?id=37827007&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Unfortunately I do not have a guide, perhaps this would be a good idea for a blog post?  I'll write something up when I have a free weekend.<p>Keep in mind that a lot of this will be heavily dependent on what kind of router and LAN configuration you have.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37827392"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37827392" href="https://news.ycombinator.com/vote?id=37827392&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>This is a good idea that’s inaccessible to &gt;99% of customers. That’s the part that frustrates me. We save ourselves but these companies just couldn’t care less about our teeny tiny slice of the pie.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37827366"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37827366" href="https://news.ycombinator.com/vote?id=37827366&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>This is a smart idea now you mention it. Those internet of sh!t devices are back doors onto your network.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826456"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826456" href="https://news.ycombinator.com/vote?id=37826456&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Whilst it might be in the T&amp;Cs somewhere, it’s the not-good variety of surprise that a company should really try to avoid.<p>I don’t have Alexa devices on my network, and I’m glad. I do have other vendor smart things, and I’d absolutely expect a notification if they were going to be poking around at my other devices to send information off to a company for <i>their</i> benefit.</p><p>Poor play, Amazon
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826141"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826141" href="https://news.ycombinator.com/vote?id=37826141&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span><i>It’s probably described in the T&amp;Cs somewhere</i><p>Which.. I never read but I concur with your theory.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826123"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826123" href="https://news.ycombinator.com/vote?id=37826123&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Time to learn everything they scan for, and set up a honeypot that makes people's Amazon devices fill with dummy devices.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826175"><td></td></tr>
                <tr id="37826631"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826631" href="https://news.ycombinator.com/vote?id=37826631&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Or disconnect the printer completely, attach a rpi to the printer's USB port, and install CUPS.<p>Network level security is already difficult enough even for professionals, it's nearly impossible to really "secure" consumer grade home networks with tons of random consumer grade devices by trusting one brand and distrusting another.</p><p>Personally, I don't see my printer's ink level as some sensitive information. But if I do, I would put it behind auth/encryption.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37827629"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37827629" href="https://news.ycombinator.com/vote?id=37827629&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I connect my printer via USB for this exact reason. Connecting it to Wifi is convenient but just poses too many potential attack vectors.  I agree that ink levels are not sensitive information, but a lot of things that you print (or scan if your printer has a scanner too) is sensitive.  Given that so many printers are inadvertently accessible on the Internet [1], I'd rather just connect my printer via USB and avoid that issue entirely.<p>[1] <a href="https://darknetdiaries.com/episode/31/" rel="nofollow noreferrer">https://darknetdiaries.com/episode/31/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826195"><td></td></tr>
                <tr id="37826453"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826453" href="https://news.ycombinator.com/vote?id=37826453&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>That should be the solution for everything but unfortunately I'm dealing with containers that advertise their IP via Bonjour (or whatever the new thing is). But since they run in a container they get their 172.19.0.0/24 IP, so they broadcast the wrong one.<p>Then there is the issue of certain devices only accepting things like HomeKit via a barcode and/or discovery, and not via IP addresses.</p><p>If I could just do IP addresses it would be so much more easy to cordon off things. IPs can talk across networks with ease, no hacks required, but at least I control it.</p><p>Inside of a network it's very hard to selectively allow / deny traffic.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826234"><td></td></tr>
                <tr id="37826696"><td></td></tr>
                <tr id="37826901"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_37826901" href="https://news.ycombinator.com/vote?id=37826901&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>SNMP is completely different than SNTP. SNTP is basically just a minimal NTP client that just queries the time and doesn't attempt to do anything like compensate for network latency or use multiple NTP servers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826531"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826531" href="https://news.ycombinator.com/vote?id=37826531&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>This is the real solution. Pretty much all printers accept read/write from public by default and share a lot of info about themselves. Any program on your computer could do this if it wants, the only surprise here is that it took this long for anyone to bother.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826213"><td></td></tr>
                <tr id="37826704"><td></td></tr>
                              <tr id="37826217"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826217" href="https://news.ycombinator.com/vote?id=37826217&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I've recently changed my home network to ensure all IoT devices are on their own VLAN where they can't talk to each-other and only have access to the internet.<p>I see my paranoia was not unwarranted.</p><p>That being said, if I had a network printer, I would've connected it to yet another VLAN I have set up which does not even have access to the internet.</p><p>Setting all this up required quite a bit of time, effort and networking/firewall knowledge. I wonder if there's a market for providing such capabilities out of the box for the less tech-inclined privacy-conscious consumers.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826620"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826620" href="https://news.ycombinator.com/vote?id=37826620&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>&gt; less tech-inclined privacy-conscious consumers<p>That group is much smaller than most tech-conscious people imagine (at least outside of Germany).</p><p>My experience with people outside of the tech bubble is that people care a lot more about privacy from their bosses / exes / partners / parents (and very occasionally law enforcement), but almost never about privacy from big companies.</p><p>The only thing that actually makes people scared is seeing ads for products that they were recently discussing in person, and that's actually due to coincidence and search history, not, as they think, devices listening on them. I keep pointing this out every time the same thing happens on (linear) TV.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826885"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826885" href="https://news.ycombinator.com/vote?id=37826885&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>What makes you so sure that devices aren't listening?  Apparently there used to be (maybe still is) a loophole where apps can listen for specific keywords the same way the phone listens for "hey siri" or "ok google" ... apps can stuff a whole bunch of keywords into the list and listen for them that way without explicitly processing all of the audio from your device.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37826896"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826896" href="https://news.ycombinator.com/vote?id=37826896&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Sorry I can't remember where I read it, I think it was actually in a comment thread here on hacker news.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37826444"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826444" href="https://news.ycombinator.com/vote?id=37826444&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>I for one would pay for such a thing. I hate spending hours tinkering with network/firewall rules. It's dull as hell and a huge time sink to get everything right. And I have three decades of Linux knowledge. How is man-on-the-street supposed to do any of this stuff? :(</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="37826426"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826426" href="https://news.ycombinator.com/vote?id=37826426&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Amazon does the same thing if you link a Samsung Smartthings hub and those little sensors have a low battery.<p>This is basically the 'promise' of all this smart home junk: your fridge automatically adds milk to your Amazon cart when it scans the contents and sees the level is low. A dubious convenience for users, but an excellent way for companies to ensure you keep buying things from them.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826831"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826831" href="https://news.ycombinator.com/vote?id=37826831&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>I have an HP multi-function laster printer and got a similar message yesterday about my black toner running low.  Got the same email with the same useless instructions to opt-out.  I have and would never opt-into this feature.<p>I have a feeling this is alexa searching your network and helping itself to your devices.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826033"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826033" href="https://news.ycombinator.com/vote?id=37826033&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>The feature seems perfectly fine for those who want it, but the idea that you never opted in is troubling.<p>So the question is, how did your printer get linked to your Amazon account?</p><p>Possibilities:</p><p>1) You registered your printer with Brother (possibly when setting up wireless or cloud services) and put in your email address which is also the one associated with Amazon. Did you opt in without realizing (via a dark pattern? hidden in TOS?)? Or did they opt you in without any consent at all?</p><p>2) You bought the printer from Amazon and they already knew the printer serial number (common with certain electronics brands) and that's how it got associated. Perhaps there's a notice on the add-to-cart or checkout page that you'll be enrolled, or an opt-in checkbox? Or maybe it is without consent?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826070"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826070" href="https://news.ycombinator.com/vote?id=37826070&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>See my other comment on this. I did not register it with Brother, and have no account with Brother. Given this is Amazon, I cannot help but feel pessimistic that this was done without consent.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37826121"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826121" href="https://news.ycombinator.com/vote?id=37826121&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Ah ha, it turns out there's a third option -- Alexa automatically finds printers on your network and checks their ink levels:<p><a href="https://www.amazon.com/b?ie=UTF8&amp;node=19820259011" rel="nofollow noreferrer">https://www.amazon.com/b?ie=UTF8&amp;node=19820259011</a></p><p>So it doesn't seem to have anything to do specifically with Brother at all.</p><p>Mystery solved. It's an Alexa feature ("feature").</p><p>So feel free to be angry at Amazon, but it's not Brother doing anything wrong. It's just reporting ink levels to anybody on your local network who asks, just like every other printer.</p><p>You might want to change your headline since it accuses Brother rather than Amazon.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826305"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826305" href="https://news.ycombinator.com/vote?id=37826305&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>You can turn this off in the Alexa app.  I went looking for it after reading that page.<p>It's under Settings &gt; Device Discovery (near the bottom of the settings).  It's on by default of course.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37826012"><td></td></tr>
                <tr id="37826187"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826187" href="https://news.ycombinator.com/vote?id=37826187&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span><i>removes glasses</i>... MOG... That is INTERESTING.<p>Here is an image of the email I received</p><p><a href="https://imgur.com/a/fhvZlsd" rel="nofollow noreferrer">https://imgur.com/a/fhvZlsd</a></p><p>and the current status of the web page:</p><p><a href="https://imgur.com/jkTD4Xp" rel="nofollow noreferrer">https://imgur.com/jkTD4Xp</a></p><p>I am speechless. This link brought up a narrow page of blue. Is there any way to recover that? Firefox browser. I would love to capture that .. oh I kick myself now for not grabbing a SS.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826461"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826461" href="https://news.ycombinator.com/vote?id=37826461&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>When you found that page originally you must have either got there from a POST from another page, or a prior page set a cookie which this page gobbled.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37826372"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826372" href="https://news.ycombinator.com/vote?id=37826372&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>"You are receiving this message because you connected your Brother MFC-J485DW to Alexa on 5/4/21"<p>What happened on 5/4/21?  You say you bought the printer after July 2019, so it probably wasn't the printer purchase date.  Does that line up with the date you bought or installed an ink cartridge from Amazon, or set up Alexa?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="37826140"><td></td></tr>
                <tr id="37827353"><td></td></tr>
                  <tr id="37826548"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826548" href="https://news.ycombinator.com/vote?id=37826548&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Related is that Alexa seems to like to add any HP printers nearby with WiFi direct still on, and relentlessly remind you when the neighbor's printer ink is low. I have ~20 random printers in my Alexa account that I don't own and keep reappearing whenever Alexa scans for new devices.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37825967"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37825967" href="https://news.ycombinator.com/vote?id=37825967&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>How has it linked with your Amazon account then? Just because you bought the printer from Amazon? (As they do with their own devices, e.g. Fire TV Sticks, of course.)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="37826055"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_37826055" href="https://news.ycombinator.com/vote?id=37826055&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>The printer was purchased at a store called Best Buy.<p>The only interaction that it has ever had with my Amazon account was that I ordered a single purchase of replacement ink cartridges. The idea of it monitoring their status is abhorrent to me and I don't think I would have ever opted in for such thing. Perhaps there was something requiring me to opt out, but ...it was not apparent.</p><p>When my Alexa searched for devices connected to my network, it must have noted this printer, then compared it to the fact I ordered ink for it, and <i>just to be extra helpful</i> decided to monitor its levels for me. I can think of no other way...
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826330"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826330" href="https://news.ycombinator.com/vote?id=37826330&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>Maybe Amazon tags the serial number of the cartridge and correlates it to your printer with the data Brother gives them. Fucking crazy.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="37826162"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37826162" href="https://news.ycombinator.com/vote?id=37826162&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>I would not rule out some connection via the credit/debit card, like how every shop now emails you even though you never gave them your email.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="37825691"><td></td></tr>
                <tr id="37825719"><td></td></tr>
                <tr id="37825842"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_37825842" href="https://news.ycombinator.com/vote?id=37825842&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>What year was it manufactured? Manuals seem to be from 2016. That's a bit earlier than I'd expect this kind of behavior (not conclusive of anything. Just an observation).<p>Do you have a firmware date?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="37826030"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_37826030" href="https://news.ycombinator.com/vote?id=37826030&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>Current firmware is N1901041316<p>I do not have a manufacturer date but it would have been purchased in 2019 or later.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                              <tr id="37826185"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826185" href="https://news.ycombinator.com/vote?id=37826185&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><p><span>You backdoored your own network by putting an Alexa on it.  I wouldn't be surprised if Ring cameras pulled the same shit.<p>If you really must have this trash on your lan, you have to isolate it at the network level.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="37826249"><td></td></tr>
            <tr id="37826607"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_37826607" href="https://news.ycombinator.com/vote?id=37826607&amp;how=up&amp;goto=item%3Fid%3D37825653"></a></center>    </td><td><br><div>
                  <p><span>People realizing shit in their homes has an API because smart devices started poking it will never not be funny.</span></p></div></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[John Riccitiello steps down as CEO of Unity after pricing battle (867 pts)]]></title>
            <link>https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/</link>
            <guid>37825292</guid>
            <pubDate>Mon, 09 Oct 2023 20:46:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/">https://venturebeat.com/games/john-riccitiello-steps-down-as-ceo-of-unity-after-pricing-battle/</a>, See on <a href="https://news.ycombinator.com/item?id=37825292">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<section>
			
			<p><time title="2023-10-09T20:37:01+00:00" datetime="2023-10-09T20:37:01+00:00">October 9, 2023 1:37 PM</time>
			</p>
			
		</section>
		<div>
					<p><img width="750" height="563" src="https://venturebeat.com/wp-content/uploads/2019/03/jr-3.jpg?fit=750%2C563&amp;strip=all" alt="John Riccitiello, CEO of Unity Technologies, has nearly 7 million developers for the Unity  3D engine."></p><div><p><span>John Riccitiello, CEO of Unity Technologies.</span></p><p><em>Image Credit: Dean Takahashi</em></p></div>		</div><!-- .article-media-header -->
	</div><div id="primary" role="main">

			<article id="post-2902288">
				<div>
					<div id="boilerplate_2567078"><div dir="auto" data-qa="virtual-list-item" role="listitem" data-qa-hover="true" data-qa-unprocessed="false" data-qa-placeholder="false" id="1695760337.229209" data-item-key="1695760337.229209">
<p><em>GamesBeat Next unites gaming industry leaders for exceptional content, networking, and deal-making opportunities. Join us on Oct 23-24 in San Francisco.&nbsp; <a href="https://gamesbeatnext.com/"><strong>Register Now</strong></a></em></p>
</div>
<hr>



</div><p>John Riccitiello, CEO of <a href="https://venturebeat.com/games/unity-adds-fee-for-installs-for-successful-developers-triggering-a-backlash/">Unity</a>, has resigned from the company in the wake of a pricing controversy that left developers in open revolt. </p>



<p>Unity said in a press release that James M. Whitehurst has been appointed interim CEO and president of the company. </p>



<p>Meanwhile, hoping to avoid a stock panic, Unity said that it is reaffirming its previous guidance for its fiscal third quarter financial results, which will be reported on November 9. </p>



<p>Roelof Botha, lead independent director of the Unity board, has been appointed chairman. Riccitiello will continue to advise Unity to ensure a smooth transition, the company said. The news isn’t a surprise as Unity angered a lot of its loyal game developers a few weeks ago after pushing through a price increase based on numbers of downloads — and then retracted it after an uproar.</p>



<div id="boilerplate_2707617">
        <h3>Event</h3>
                <div><p>GamesBeat Next 2023</p>
<p>Join the GamesBeat community in San Francisco this October 24-25. You’ll hear from the brightest minds within the gaming industry on latest developments and their take on the future of gaming.</p>
</div>
                        
                                        <p><a href="https://gamesbeatnext.com/">
                Learn More            </a>
                        </p></div><p>Unity said the board will initiate a comprehensive search process, with the assistance of a leading executive search firm, to identify a permanent CEO.</p>



<p>“Working with Unity under John’s leadership has been one of the highlights of my career. John joined the Unity Board in 2013 and stepped in to lead the company in 2014, at a time when we faced significant challenges,” Botha said, in a statement. “John has led Unity through incredible growth over the last nearly 10 years, helping us transition from a perpetual license to a subscription model, enabling developers to monetize, building other game services to serve our creator community, leading us through an IPO and positioning us as a pioneer in the developer community. Unity would not be where it is today without the impact of his contributions. I remain excited for the future of Unity.”</p>



<p>“It’s been a privilege to lead Unity for nearly a decade and serve our employees, customers, developers and partners, all of whom have been instrumental to the company’s growth,” Riccitiello said in a statement. “I look forward to supporting Unity through this transition and following the company’s future success.”</p>



<p>Whitehurst is a seasoned technology and public company executive. He previously served as senior advisor and president at IBM, after joining through IBM’s acquisition of Red Hat, a leading provider of open-source enterprise IT products and services, where he served as president and CEO from 2008 to 2020.</p>



<p>“I am honored to join Unity as interim CEO and President at this important time in its evolution,” Whitehurst said in a statement. “With the company’s experienced leadership and passionate employees, I am confident that Unity is well-positioned to continue enhancing its platform, strengthening its community of customers, developers and partners, and focusing on its growth and profitability goals. I look forward to working closely with the Board and our talented global team to execute on our strategy, and I anticipate a seamless transition.”</p>



<p>Unity will release third quarter 2023 financial results after the market close on Thursday, November 9, 2023, with a webcast to follow at 2 p.m. PT. </p>
<p><strong>GamesBeat's creed</strong> when covering the game industry is "where passion meets business." What does this mean? We want to tell you how the news matters to you -- not just as a decision-maker at a game studio, but also as a fan of games. Whether you read our articles, listen to our podcasts, or watch our videos, GamesBeat will help you learn about the industry and enjoy engaging with it. <a href="https://venturebeat.com/newsletters/?utm_source=VBsite&amp;utm_medium=bottomBoilerplate">Discover our Briefings.</a></p><!-- Boilerplate CSS for "after" -->				</div><!-- .article-content -->

									
				
			</article><!-- #post-2902288 .article-wrapper -->


		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RAG at scale: Synchronizing and ingesting billions of text embeddings (143 pts)]]></title>
            <link>https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521</link>
            <guid>37824547</guid>
            <pubDate>Mon, 09 Oct 2023 19:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521">https://medium.com/@neum_ai/retrieval-augmented-generation-at-scale-building-a-distributed-system-for-synchronizing-and-eaa29162521</a>, See on <a href="https://news.ycombinator.com/item?id=37824547">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@neum_ai?source=post_page-----eaa29162521--------------------------------"><div aria-hidden="false"><p><img alt="Neum AI" src="https://miro.medium.com/v2/resize:fill:88:88/1*dmbNkD5D-u45r44go_cf0g.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="f3de"><em>Disclaimer: We will go into some technical and architectural details of how we do this at </em><a href="https://neum.ai/" rel="noopener ugc nofollow" target="_blank"><em>Neum AI</em></a><em> — A data platform for embeddings management, optimization, and synchronization at large scale, essentially helping with large-scale RAG.</em></p><p id="a98c">As we’ve shared in other blogs in the past, getting a <a href="https://research.ibm.com/blog/retrieval-augmented-generation-RAG" rel="noopener ugc nofollow" target="_blank">Retrieval Augmented Generation (RAG)</a> application started is pretty straightforward. The problem comes when trying to scale it and making it production-ready. In this blog we will go into some technical and architectural details of how we do this at Neum AI, specifically on how we did this for a pipeline syncing 1 billion vectors.</p><p id="84c5">First off, What exactlty is RAG?</p><p id="bd83">RAG helps finding data quickly by performing search in a “natural way” and use that information/knowledge to power a more accurate AI application that needs such information! It is a recent methodology employed by lots of people when building accurate and up-to-date AI applications!</p><p id="8477">This is what a typical RAG system looks like</p><figure><figcaption><em>Fig. 1 — High level RAG — both ingestion and application layer</em></figcaption></figure><ol><li id="1284">Data is extracted, processed, embedded and stored in a vector database for fast semantic search lookup</li><li id="e710">User submits input, generate embeddings of input, searches across vector database to find most relevant information and passes that down as context to an AI application for accurate responses.</li></ol><p id="985c">Now, let’s talk about the problem at hand — how to effectively ingest and synchronize billions of text embeddings to be used in a RAG workflow?</p><h2 id="8f91">Problem</h2><p id="a21d">RAG is straightforward, but when dealing with lots of source data a couple of complex problems arise.</p><ol><li id="f15d">Ingestion at large scale — One thing is to ingest a couple of PDFs, chunk them, embed and store in a vector db. When you have billions of records, general data infrastructure and engineering problems arise. How to effectively parallelize requests, how to handle retry mechanisms, how to spin up the right infrastructure and distributed systems, and more. It is also very important to understand the volume of data, ingestion time requirement, search latency, cost, and more to properly plan and deploy the right infra/compute. All of these are core engineering problems that, albeit solved, are daunting to implement.</li><li id="b237">Embedding (transforming it into vector format for low-latency semantic search) — generating embeddings is not a problem except when you have large data and have to deal with rate limits, retry logic, self hosted models, and more. Not to mention, but <strong>syncing data</strong> becomes crucial here. If something changed at the source and not at the downstream vector database — where the AI application typically queries from — then the response from the AI application will be stale and inaccurate. Embeddings can be costly if not done efficiently. There will always be a one-time cost of embedding all the data, but for an application that relies on new/changed data, embedding all of the source data can be very expensive, and so, there has to be a mechanism to detect whether or not data needs to be re-embedded.</li></ol><p id="adfc">In this specific case, our data pipeline is responsible for 3 operations.</p><p id="e1f2">a) Reading data</p><p id="2f15">b) Processing data</p><p id="ac67">c) Embedding data</p><p id="1c73">d) Storing data in a vector database — in this case Weaviate!</p><p id="89f4">Each of the points above have their own challenges.</p><ol><li id="5c91">Reading data needs to be done efficiently and attempt to maximize parallelization to meet ingestion time requirements</li><li id="b5a3">Once data is read, it needs to be processed, we can’t just dump everything to an embedding model. It needs to carefully be chunked depending on the source type, extract the relevant metadata fields, and clean any anomalies.</li><li id="bd7b">Embedding data as mentioned on #1 needs to be done only if required and parallelized in terms of requests/compute as per the constraints of the system and external api limits if applicable.</li><li id="3ae1">Storing in the vector database has its own limitations<br>What are the compute resources in the Vector Database?<br>Is it self hosted, managed? is there monitoring?<br>Is data sharded, what is the latency? What about compression?<br>Did you know that HNSW algorithm is pretty inefficient when trying to store identical vectors? (more on this later)<br>Could the ingestion into the database be the bottleneck of our system?</li></ol><p id="fd32">In addition to that, the system itself must have great monitoring, cancellation options, logging and alerting in place, all of the things you would expect from a robust distributed system.</p><p id="6407">For the rest of the blog we will explore solutions and share a bit into our architectural diagram for how we tested, benchmarked and ran the pipeline moving 1 billion vectors.</p><h2 id="fd1b">High-level architecture</h2><p id="b378">Let’s talk about the high level architecture and break down each of the components.</p><p id="2922">As mentioned before, this distributed system has the responsibility of four main tasks, and each of them dance together in harmony.</p><figure><figcaption><em>Fig. 2 — Distributed RAG pipeline— A bit more complex than the diagram we showed, and this is only point #1 on our first diagram!</em></figcaption></figure><p id="8702">In plain English, this is what’s happening when a user request comes in through our FastAPI service:</p><ol><li id="120e">Create a pipeline and store its metadata in our system, immediately return to the user to acknowledge their request.</li><li id="64a0">Send an event to our first processing queue — <code>requests</code> where workers will be dequeuing events from. This queue is responsible for taking in the request, figuring out the source type, in this specific case we were processing lots of files from an S3 bucket.</li><li id="418f">For each of the file in the S3 bucket, send an event to <code>process_document</code> queue with the file name where other consumers will read messages from. These workers will read the file and start processing it.</li><li id="19ea">For each of the processed files we will split it into chunks (if the file is large) so that we can fit within memory and other resource constraints. Each of these chunks will be sent to <code>embed_store</code> - our final one queue, promise ;) - where other consumers will be dequeuing.</li><li id="7a80">Of course we have set up logs and monitoring in place for us to detect issues and be able to surface any important status messages/codes to the user upon requested. Additionally, we care about analytics and metrics such as average time taken, number of tasks, etc. and we display those as well upon request.</li></ol><h2 id="f051">A note on distributed queueing in Python</h2><p id="f736">While FastAPI has support for <a href="https://fastapi.tiangolo.com/tutorial/background-tasks/" rel="noopener ugc nofollow" target="_blank">BackgroundTasks</a>, we chose <a href="https://docs.celeryq.dev/en/stable/getting-started/introduction.html" rel="noopener ugc nofollow" target="_blank">Celery</a> to help us handle the abstractions between our Message Broker and our workers because this is a more intense-heavy operation which requires distributed logging, monitoring, and further parallelization. Because the work is distributed across multiple machines, having a message broker and an event-driven system is vital for the processing and monitoring of tasks.</p><figure><figcaption>Celery Task Queue — great intro <a rel="noopener" href="https://medium.com/analytics-vidhya/python-celery-distributed-task-queue-demystified-for-beginners-to-professionals-part-1-b27030912fea">here</a></figcaption></figure><p id="219b">Celery is a vegetable ;), and it’s also an asynchronous task queue written in Python. It provides great abstractions from dealing with message brokers, producers, and consumers in a distributed system. There’s a lot of inner things about Celery that we could spend time talking about but we will leave those for another post. For example, took us a couple of debugging sessions to understand that our consumers were picking up jobs even though our message broker was empty… and it’s because Celery’s <code>prefetch_count</code>.</p><h2 id="18d3">Let’s go a bit in depth</h2><h2 id="4a41">Reading</h2><p id="4da5">As mentioned above, the first part of our system is the one in charge of determining the source type and distributing the files in this case for parallel reading. These tasks are sent to the <code>process_document</code> queue. Then, because the files might be large, we process each of them individually and sub divide it into chunks. These per-file chunks are then sent to the <code>embed_store</code> .</p><p id="395c">There’s a couple of important aspects here</p><ol><li id="b991">Because we process lots of data and files, our distributed queueing system built with Celery allows us to properly distribute tasks, monitor and retry them if needed. Along the way we have checkpointing mechanisms to understand what has been processed, which worker has picked up a task, what’s left, what succeeded and what failed.</li><li id="b3d8">Second, we need to be smart about how we chunk, how we assign metadata, and more. We give the user the ability to select how they want to chunk and assign metadata to their source data, but we also have incorporated smart chunking mechanisms to properly split the data accordingly. The data for this pipeline is json-based and so chunking is based on property field, same with the metadata to be used in the vector database for each of the vectors.</li></ol><p id="3f1b">Once we have finished distributing all the files and their respective subtasks we are ready for our final list of “heavy-consumers” to dequeue messages from our last queue depicted above and perform the <code>embeddings</code> and the <code>vector db storing</code></p><h2 id="a8c1">Embeddings and Vector DB storing</h2><p id="a886">Our final stage (which runs for every subtask mentioned above) is the one that will embed our chunks of data and store them into the vector database.</p><p id="2e47">For the case study we are talking about here, we chose two main technologies to assist with this.</p><ol><li id="2a18"><a href="https://replicate.com/" rel="noopener ugc nofollow" target="_blank">Replicate</a> for embeddings</li><li id="397f"><a href="https://weaviate.io/" rel="noopener ugc nofollow" target="_blank">Weaviate</a> for Vector Database</li></ol><p id="6f54">While we ended up using Replicate — specifically <a href="https://replicate.com/replicate/all-mpnet-base-v2" rel="noopener ugc nofollow" target="_blank">mpnet’s embedding model </a>— it is important to note that we did start with OpenAI embeddings and their <code>text-ada-002</code> model. This worked seamlessly and it took about 3-5 seconds to embed about 1500 different documents each with about 30 tokens each. Also, their <a href="https://openai.com/pricing" rel="noopener ugc nofollow" target="_blank">cost</a> was acceptable as well.</p><p id="4971">One thing to note is that storing vectors in a vector database has implications on a lot of things like latency for querying, storing, memory needed to manage it, and more. Because we are dealing with a large scale number of vectors, it was imperative to try and reduce the 1536 dimensions into a smaller dimensional model to avoid unnecessary memory storage and usage in the Weaviate cluster. Reducing the dimensions in half leads to huge $$ savings. While there are techniques to do <a href="https://elitedatascience.com/dimensionality-reduction-algorithms" rel="noopener ugc nofollow" target="_blank">Dimensionality Reduction algorithms</a>, Neum also offers integration with Replicate where customers can choose their embeddings model of their choice to be hosted and we simply connect to it, which is what we did for this run. Replicate has great customer support and were able to handle this load seamlessly.</p><p id="683a">We need a powerful and efficient vector database capable of storing <strong>b</strong>illions of vectors. Weaviate is a popular one that has great support and very technical capabilities, for those who are interested and know, Weaviate is also built using Cassandra’s architecture for sharding and replication. Having had experience with this in the past and it being open-source, it was a good choice as we needed a lot of deep customization and integration like being able to deploy on a kubernetes cluster and choose the number of nodes and shards, adjust the number of workers and ingestion batch size, and more. There’s tons of great documentation on Weaviate <a href="https://weaviate.io/developers/weaviate" rel="noopener ugc nofollow" target="_blank">here</a>.</p><p id="128e">The core here is to have a vector database that will be fast upon doing semantic search and also allowing parallelization of ingestion requests via multi-node cluster while offering logging and retry capabilities.</p><h2 id="3773">Storing in-depth</h2><p id="405e">So, going back to the beginning of this section, we had our chunks that needed to be embedded, we used Replicate to do so, with Dead-Letter-Queue and retry mechanisms in place. After we got our embeddings, we used Weaviate to store the data with all the configurations mentioned above and more. Again, logging and handling errors accordingly.</p><p id="4d72">To share some numbers, we ran benchmarks with different levels of parallelization from both our infra and Weaviate’s, as well as played with the number of CPUs in the Weaviate cluster. This is not a super extensive benchmark and was done at the beginning with OpenAI where the dimensions would be greater so as to plan for a “worst case” scenario. Also, there’s some other improvements we are in the process of trying out as well like using Weaviate’s <a href="https://github.com/weaviate/weaviate/tree/master/grpc" rel="noopener ugc nofollow" target="_blank">GRPC client</a> — which claims to have significantly faster ingestion times.</p><figure><figcaption>Fig 3 - some raw quick benchmarks of Neum and Weaviate ingestion</figcaption></figure><p id="6ab1">One key insight we had to pay attention to was on how to parallelize the writes to Weaviate.</p><p id="8091">So far we shared how we parallelized the requests, the files, the chunking and the embeddings, but when we get to the storing we have a choice of how much further to parallelize ingestion, specifically for Weaviate, as they have an option for users to specify <code>num_workers</code> when ingesting data, which essentially parallelizes the request on their end further.</p><p id="ce7b">Because we had a number of consumers dequeuing from <code>embed_store</code> (remember our queues and consumers ;) I know, lots of moving pieces, it isn’t trivial!) we were already parallelizing the ingestion requests to Weaviate, and so, we had to do benchmarks to understand the “magic number” of ingestion threads from our end and worker parallelization from Weaviate’s end.</p><p id="3386">The most important thing was to understand how many CPU cores does the Weaviate cluster have and how many parallel threads/number of workers are you actively using. We got hit initially by a number of “connection errors” and large ingestion times because we were over-parallelizing the requests. As long as you maximize but don’t go over your Weaviate cluster’s resources limits, you should be good.</p><p id="1115">There’s a lot of other learnings from the Weaviate side of things like Product Quantization, increased latency because identical vectors and how HNSW stores data, parallelization of Weaviate workers via sharding, and more. Let us know if you are interested in such an analysis and we’ll share some of those learnings in another post!</p><p id="2f62">As a side note, Neum’s platform works great with Weaviate with its deep integration but we support other vector DBs as well if the user prefers it.</p><h2 id="35f9">Conclusion</h2><p id="c772">Building distributed data pipelines have lots of moving pieces, and now with the rise of Generative AI and RAG-based applications, things can get complicated very fast. We keep learning and keep delving ourselves into all these new ideas and technologies popping up to ensure we stay up to date with the latest trends. However, having a robust system with retry, logging, monitoring and ease-of-use remains top priorities for us when supporting large-scale data pipelines for embeddings.</p><p id="ac6e">There’s a bunch of moving pieces as you probably figured out. The beautiful thing about this is that all of this happens within a single API request to our Neum AI platform :). If you are interested and have large-scale data requirements, sign up <a href="https://www.neum.ai/" rel="noopener ugc nofollow" target="_blank">here</a> or <a href="mailto:founders@tryneum.com" rel="noopener ugc nofollow" target="_blank">contact us</a>!</p><p id="beb7">As mentioned, let us know if you are interested in going even more in depth to some of our Weaviate and embeddings learnings!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs can't self-correct in reasoning tasks, DeepMind study finds (160 pts)]]></title>
            <link>https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/</link>
            <guid>37823543</guid>
            <pubDate>Mon, 09 Oct 2023 18:28:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/">https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/</a>, See on <a href="https://news.ycombinator.com/item?id=37823543">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
<figure><a href="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17440" data-permalink="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/confused-robot-2/" data-orig-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?fit=1024%2C968&amp;ssl=1" data-orig-size="1024,968" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Confused robot" data-image-description="" data-image-caption="<p>Image generated with Bing Image Creator</p>
" data-medium-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?fit=300%2C284&amp;ssl=1" data-large-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?fit=696%2C658&amp;ssl=1" decoding="async" fetchpriority="high" width="696" height="658" src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;ssl=1" alt="Confused robot" srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=300%2C284&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=768%2C726&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=444%2C420&amp;ssl=1 444w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=300%2C284&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=768%2C726&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=444%2C420&amp;ssl=1 444w" data-lazy-src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/Confused-robot.jpg?resize=696%2C658&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Image generated with Bing Image Creator</figcaption></figure>



<p><em>This article is part of our&nbsp;coverage of the latest in&nbsp;<a href="https://bdtechtalks.com/tag/ai-research-papers/" target="_blank" rel="noreferrer noopener">AI research</a>.</em></p>



<p>Scientists are inventing various strategies to enhance the accuracy and reasoning abilities of large language models (<a href="https://bdtechtalks.com/tag/large-language-models/">LLM</a>) such as <a href="https://bdtechtalks.com/2023/04/03/augmented-language-models/" title="">retrieval augmentation</a> and chain-of-thought reasoning.</p>



<p>Among these, “self-correction”—a technique where an LLM refines its own responses—has gained significant traction, demonstrating efficacy across numerous applications. However, the mechanics behind its success remain elusive.&nbsp;</p>



<p>A <a href="https://arxiv.org/abs/2310.01798">recent study</a> conducted by Google DeepMind in collaboration with the University of Illinois at Urbana-Champaign reveals that LLMs often falter when self-correcting their responses without external feedback. In fact, the study suggests that self-correction can sometimes impair the performance of these models, challenging the prevailing understanding of this popular technique.</p>



<h2>What is self-correction?</h2>



<div>




<p>Self-correction is predicated on the idea that LLMs can assess the accuracy of their outputs and refine their responses. For instance, an LLM might initially fail a math problem but correct its answer after reviewing its own output and reasoning.</p>
</div>



<p>Several studies have observed this process, also known as “self-critique,” “self-refine,” or “self-improve.”</p>



<p>However, the effectiveness of self-correction is not universal across all tasks. The paper from DeepMind and University of Illinois reveals that the success of self-correction is largely contingent on the nature of the task at hand. In reasoning tasks, self-correction techniques typically succeed only when they can leverage external sources, such as human feedback, an external tool like a calculator or code executor, or a knowledge base.</p>



<p>The researchers underscore the fact that high-quality feedback is not always accessible in many applications. This makes it crucial to understand the inherent capabilities of LLMs and to discern how much of the self-correction can be attributed to the model’s internal knowledge. They introduce the concept of “intrinsic self-correction,” which refers to a scenario where the model attempts to correct its initial responses based solely on its built-in capabilities, without any external feedback.&nbsp;</p>


<div>
<figure><a href="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17437" data-permalink="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/llm-self-correction-techniques/" data-orig-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?fit=1762%2C776&amp;ssl=1" data-orig-size="1762,776" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="LLM self-correction techniques" data-image-description="<p>Different LLM self-correction techniques (source: <a href=&quot;https://github.com/teacherpeterpan/self-correction-llm-papers&quot;>GitHub</a>)</p>
" data-image-caption="<p>Different LLM self-correction techniques (source: <a href=&quot;https://github.com/teacherpeterpan/self-correction-llm-papers&quot;>GitHub</a>)</p>
" data-medium-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?fit=300%2C132&amp;ssl=1" data-large-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?fit=696%2C307&amp;ssl=1" decoding="async" width="696" height="307" src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;ssl=1" alt="LLM self-correction techniques" srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1024%2C451&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=300%2C132&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=768%2C338&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1536%2C676&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1068%2C470&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=954%2C420&amp;ssl=1 954w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1762&amp;ssl=1 1762w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1392&amp;ssl=1 1392w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1024%2C451&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=300%2C132&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=768%2C338&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1536%2C676&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=1068%2C470&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=954%2C420&amp;ssl=1 954w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1762&amp;ssl=1 1762w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?w=1392&amp;ssl=1 1392w" data-lazy-src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-techniques.png?resize=696%2C307&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>Different LLM self-correction techniques (source: <a href="https://github.com/teacherpeterpan/self-correction-llm-papers">GitHub</a>)</figcaption></figure></div>


<h2>Testing self-correction on reasoning tasks</h2>



<p>The researchers put self-correction to the test on several benchmarks that measure model performance in solving math word problems, answering multiple-choice questions, and tackling question-answering problems that require reasoning. They employed a three-step process for self-correction. First, they prompt the model for an answer. Next, they prompt it to review its previous response. Finally, they prompt it a third time to answer the original question based on its self-generated feedback.</p>



<p>Their findings reveal that self-correction works effectively when the models have access to the ground-truth labels included in the benchmark datasets. This is because the algorithm can accurately determine when to halt the reasoning process and avoid changing the answer when it is already correct. As the researchers state, “These results use ground-truth labels to prevent the model from altering a correct answer to an incorrect one. However, determining how to prevent such mischanges is, in fact, the key to ensuring the success of self-correction.”</p>



<p>However, this assumption does not reflect real-world scenarios, where access to the ground truth is not always available. If the ground truth were readily accessible, there would be no need to employ a machine learning model to predict it. The researchers demonstrate that when they remove the labels from the self-correction process, the performance of the models begins to decline significantly.</p>



<p>Interestingly, the models often produce the correct answer initially, but switch to an incorrect response after self-correction. For instance, in GPT-3.5-Turbo (the model used in the free version of <a href="https://bdtechtalks.com/2022/12/05/openai-chatgpt/">ChatGPT</a>), the performance dropped by almost half on the CommonSenseQA question-answering dataset when self-correction was applied. <a href="https://bdtechtalks.com/2023/03/20/gpt-4-applications-limits/">GPT-4</a> also exhibited a performance drop, albeit by a smaller margin.</p>


<div>
<figure><a href="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?ssl=1"><img data-lazy-fallback="1" data-attachment-id="17432" data-permalink="https://bdtechtalks.com/2023/10/09/llm-self-correction-reasoning-failures/llm-self-correction-errors/" data-orig-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?fit=2798%2C972&amp;ssl=1" data-orig-size="2798,972" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="LLM self-correction errors" data-image-description="<p>In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer</p>
" data-image-caption="<p>In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer</p>
" data-medium-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?fit=300%2C104&amp;ssl=1" data-large-file="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?fit=696%2C242&amp;ssl=1" decoding="async" loading="lazy" width="696" height="242" src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors-1024x356.jpg?resize=696%2C242&amp;ssl=1" alt="LLM self-correction errors" srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1024%2C356&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=300%2C104&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=768%2C267&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1536%2C534&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=2048%2C711&amp;ssl=1 2048w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=696%2C242&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1068%2C371&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1209%2C420&amp;ssl=1 1209w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1920%2C667&amp;ssl=1 1920w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?w=1392&amp;ssl=1 1392w" sizes="(max-width: 696px) 100vw, 696px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1024%2C356&amp;ssl=1 1024w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=300%2C104&amp;ssl=1 300w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=768%2C267&amp;ssl=1 768w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1536%2C534&amp;ssl=1 1536w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=2048%2C711&amp;ssl=1 2048w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=696%2C242&amp;ssl=1 696w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1068%2C371&amp;ssl=1 1068w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1209%2C420&amp;ssl=1 1209w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?resize=1920%2C667&amp;ssl=1 1920w, https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors.jpg?w=1392&amp;ssl=1 1392w" data-lazy-src="https://i0.wp.com/bdtechtalks.com/wp-content/uploads/2023/10/LLM-self-correction-errors-1024x356.jpg?resize=696%2C242&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a><figcaption>In many cases, intrinsic self-correction causes models to switch from the right answer to the wrong answer</figcaption></figure></div>


<p>According to the researchers, if the model is well-aligned and paired with a thoughtfully designed initial prompt, “the initial response should already be optimal given the conditions of the prompt and the specific decoding algorithm.” In this case, introducing feedback can be viewed as adding an additional prompt, potentially skewing the model’s response away from the optimal prompt. “In an intrinsic self-correction setting, on the reasoning tasks, this supplementary prompt may not offer any extra advantage for answering the question. In fact, it might even bias the model away from producing an optimal response to the initial prompt, resulting in a decrease in performance,” the researchers write.</p>



<p>Self-correction is also prevalent in multi-agent LLM applications. In these scenarios, multiple instances of an LLM, such as ChatGPT, are given different instructions to perform distinct roles in a multi-sided debate. For instance, one agent might be tasked with generating code, while another is instructed to review the code for errors.</p>



<p>In these applications, self-correction is implemented by instructing agents to critique each other’s responses. However, the researchers found that this multi-agent critique does not lead to any form of improvement through debate. Instead, it results in a form of “self-consistency,” where the different agents generate multiple responses and then engage in a form of majority voting to select an answer.&nbsp;</p>



<p>“Rather than labeling the multi-agent debate as a form of “debate” or “critique”, it is more appropriate to perceive it as a means to achieve “consistency” across multiple model generations,” the researchers write.</p>



<h2>Post-hoc vs pre-hoc prompting</h2>



<p>While self-correction may not enhance reasoning, the researchers found that it can be effective in tasks such as modifying the style of the LLM’s output or making the response safer. They refer to these tasks as “post-hoc prompting,” where the prompting is applied after the responses have been generated. They write, “Scenarios in which self-correction enhances model responses occur when it can provide valuable instruction or feedback that pre-hoc prompting cannot.”</p>



<p>Another key finding of the paper is that the improvement attributed to self-correction in certain tasks may be due to an inadequately crafted initial instruction that is outperformed by a carefully constructed feedback prompt. In such cases, incorporating the feedback into the initial instruction, referred to as the “pre-hoc prompt,” can yield better results and reduce inference costs. The researchers state, “It is meaningless to employ a well-crafted post-hoc prompt to guide the model in ‘self-correcting’ a response generated through a poorly constructed pre-hoc prompt. For a fair comparison, equal effort should be invested in both pre-hoc and post-hoc prompting.”</p>



<p>The researchers conclude by urging the community to approach the concept of self-correction with skepticism and to apply it judiciously.&nbsp;</p>



<p>“It is imperative for researchers and practitioners to approach the concept of self-correction with a discerning perspective, acknowledging its potential and recognizing its boundaries,” the researchers write. “By doing so, we can better equip this technique to address the limitations of LLMs, steering their evolution towards enhanced accuracy and reliability.”</p>




        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Extreme Parkour with Legged Robots (131 pts)]]></title>
            <link>https://extreme-parkour.github.io/</link>
            <guid>37823440</guid>
            <pubDate>Mon, 09 Oct 2023 18:19:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://extreme-parkour.github.io/">https://extreme-parkour.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=37823440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <h2>Abstract</h2>
        <p>
            Humans can perform parkour by traversing obstacles in a highly dynamic fashion requiring precise eyemuscle coordination and movement. Getting robots to do the same task requires overcoming similar challenges. Classically, this is done by independently engineering perception, actuation, and control systems to very low tolerances. This restricts them to tightly controlled settings such as a predetermined obstacle course in labs. In contrast, humans are able to learn parkour through practice without significantly changing their underlying biology. In this paper, we take a similar approach to developing robot parkour on a small low-cost robot with imprecise actuation and a single front-facing depth camera for perception which is low-frequency, jittery, and prone to artifacts. We show how a single neural net policy operating directly from a camera image, trained in simulation with largescale RL, can overcome imprecise sensing and actuation to output highly precise control behavior end-to-end. We show our robot can perform a high jump on obstacles 2x its height, long jump across gaps 2x its length, do a handstand and run across tilted ramps, and generalize to novel obstacle courses with different physical properties.
          </p>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bare-metal Rust in Android (258 pts)]]></title>
            <link>https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html</link>
            <guid>37823377</guid>
            <pubDate>Mon, 09 Oct 2023 18:13:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html">https://security.googleblog.com/2023/10/bare-metal-rust-in-android.html</a>, See on <a href="https://news.ycombinator.com/item?id=37823377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Video streaming at scale with Kubernetes and RabbitMQ (259 pts)]]></title>
            <link>https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb</link>
            <guid>37823160</guid>
            <pubDate>Mon, 09 Oct 2023 17:51:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb">https://alexandreolive.medium.com/video-streaming-at-scale-with-kubernetes-and-rabbitmq-6e23fd0e75fb</a>, See on <a href="https://news.ycombinator.com/item?id=37823160">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="7967" aria-label="kicker paragraph">Architecture Deep Dive</h2><div><h2 id="d0b0">Deep dive into the problems video streaming sites face and how they can architect their infrastructure to manage the load.</h2><div><a rel="noopener follow" href="https://alexandreolive.medium.com/"><div aria-hidden="false"><p><img alt="Alexandre Olive" src="https://miro.medium.com/v2/resize:fill:88:88/1*gAvdsn07JpXS8dvJsfPFhw.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><figure><figcaption>Photo by <a href="https://unsplash.com/@popcornmatch?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Marques Kaspbrak</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="8f42"><span>S</span>treaming. That’s a word we hear a lot nowadays. Most of us use Netflix or YouTube daily. So much it has become part of everyone’s life, maybe too much for our own sake.</p><p id="5f2e">But people rarely stop and wonder: how does it even work? From my developer’s point of view, it’s pure madness. There’s so much data to store and pass through the network, people worldwide should be able to access it without lag or issues, and it needs to work on all devices.</p><p id="1309">I will not pretend I know how those apps work internally. They probably use concepts I never dreamed of to optimize every inch possible.</p><p id="06f6">But don’t leave just yet; there’s still a reason I’m writing this article. I want to use my direct experience working as a technical lead on a streaming solution at <a href="https://skeepers.io/fr/" rel="noopener ugc nofollow" target="_blank">Skeepers</a> to explain how we manage to produce high-quality videos and stream those videos directly onto our client’s website, just like you would watch a video on YouTube.</p><p id="1e78">I will discuss technical subjects like <a href="https://kubernetes.io/docs/concepts/overview/" rel="noopener ugc nofollow" target="_blank">Kubernetes</a>, <a href="https://www.rabbitmq.com/" rel="noopener ugc nofollow" target="_blank">RabbitMQ</a>, and <a href="https://www.nginx.com/resources/glossary/load-balancing/" rel="noopener ugc nofollow" target="_blank">load balancers</a>. A basic knowledge of those topics is necessary to follow the article.</p><p id="b6c3"><em>To clarify, I’m talking about streaming as watching a video online that is not a live stream. A regular video on YouTube is still called video streaming.</em></p></div><div><h2 id="39ab">The video’s life: from upload to playback</h2><p id="a81b">I will take you on a journey from when a user uploads a video on our site to when you play it on your device and the challenges that come with it.</p><figure><figcaption>Photo by <a href="https://unsplash.com/@jakobowens1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Jakob Owens</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><h2 id="6549">First step: Video upload</h2><p id="cfac">Alright, the first step is when the video is uploaded. We have yet to determine what format, codec, or even which resolution the video will be.</p><p id="c6cd">First, it will be normalized, which means we will transform all the videos in the same format (first mp4), <a href="https://github.com/georgmartius/vid.stab" rel="noopener ugc nofollow" target="_blank">stabilize the video</a>, and <a href="http://ffmpeg.org/ffmpeg-filters.html#loudnorm" rel="noopener ugc nofollow" target="_blank">harmonize the sound</a> to mitigate shaking or loud sounds.</p><p id="4c80">We then break the video into multiple small chunks; the resulting format will be an adaptive bitrate streaming format called MPEG-Dash or HLS.</p><p id="ae70"><em>You can read more about Adaptative bitrate streaming here.</em></p><p id="d519">This task is time-consuming, so the user cannot just wait for the API’s response synchronously. It needs to be asynchronous.</p><figure><figcaption>Custom-made schema representing the simplified architecture.</figcaption></figure><p id="0444">You can see the asynchronous implementation using RabbitMQ on this schema. When a user uploads a new video, it first gets uploaded to a cloud storage. We use Google Cloud Storage, but it could be any storage. Once the upload finishes, we create a processing task in the database and send the task ID to the queue. The user screens update with a message that says the processing is ongoing and please wait a few minutes.</p><p id="0401">A NodeJS worker is constantly polling the queue, waiting for new tasks like a good soldier. When a new one is available, it gets the processing task information from the database. It uses <a href="https://ffmpeg.org/" rel="noopener ugc nofollow" target="_blank">FFmpeg</a> under the hood to do the required job (normalization or adaptative bitrate streaming format creation, for example), store the resulting files in storage, and update the task’s status in the database.</p><p id="96b6">You’re probably thinking: “Hang on, there’s <strong>Kubernetes </strong>in your article title but not in the schema”, or “It’s not scalable as is. If there are a lot of videos, it will crash.”</p><p id="fe39">I’m getting there! The schema I presented was just an introduction. I am gradually introducing each concept.</p><p id="0e6c">There are indeed a couple of issues here. If there is only one API and one worker, it will quickly overload. Primarily since FFmpeg requires a lot of resources. Let’s<strong> spice it up!</strong></p><figure><figcaption>Custom-made schema representing the more complex architecture with Kubernetes.</figcaption></figure><p id="42ce">Alright, we introduced <strong>Kubernetes</strong> in the mix. The NodeJS API handling user calls will receive many HTTP calls with user files. So, instead of having one API instance, it’s now an unlimited number of Kubernetes pods. We have set it up to auto-scale in a way that if the RAM or CPU of the pods reaches a specific limit (70% of their capacity), it will launch a new pod for this same API.</p><p id="1eed">There is no “Kubernetes node“ reference to simplify the schema, but it can also scale across nodes. If the number of pods (<a href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/" rel="noopener ugc nofollow" target="_blank">actually the required capacity of the pods</a>) reaches the capacity limit for the current node, it will auto-scale a new node and start launching new pods inside that node.</p><p id="843d">The load balancer in front of the API will share the HTTP calls randomly between all the existing pods to split the load.</p><p id="65a7">The worker polling the RabbitMQ is also auto-scaling, but it’s not on resources; it is scaling on the number of messages waiting in the queue. The more messages await, the faster we need to process them, so launching new workers is the way to go.</p><p id="181c">It’s much better, but we want to save costs when possible, so let me introduce <em>preemptible nodes</em>!</p><blockquote><p id="e0c7">Preemptible VMs are Compute Engine <a href="https://cloud.google.com/compute/docs/instances/preemptible" rel="noopener ugc nofollow" target="_blank">VM instances</a> that are priced lower than standard VMs and provide no guarantee of availability — <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms" rel="noopener ugc nofollow" target="_blank">Google Cloud documentation</a>.</p></blockquote><figure><figcaption>Custom-made schema representing the more complex architecture with Kubernetes and preemptible nodes.</figcaption></figure><p id="7098">We want our user to have the best experience, but it’s perfectly fine for us if they don’t have access to the best video quality in adaptative bitrate streaming format right as they upload their content. It can take a few minutes for a preemptible node to be available, but they are cheaper than a normal node.</p><p id="c20f">In this new schema, we transformed our NodeJS worker with FFmpeg to what we call internally a “spawner”. It still polls the RabbitMQ queue, but instead of processing the video itself, it will launch a new Kubernetes pod in a preemptible node, and this new pod will do the processing.</p><p id="bd2e">This way is cheaper. We switched all our resource-intensive tasks in a preemptible node, so we don’t need to scale our spawner as much in a normal-priced node.</p><p id="e538">Google Cloud can kill preemptible nodes if a normal node needs the resources. We must ensure a failed task goes back to the queue and starts again by another node later.</p><blockquote><p id="6026">Terminated when Compute Engine requires the resources to run standard VMs — <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/preemptible-vms#comparison_to" rel="noopener ugc nofollow" target="_blank">Google cloud documentation</a></p></blockquote><p id="87f2">This new setup with preemptible nodes brings more overhead in the implementation but a significant price improvement. We reached a point where we could scale vertically indefinitely.</p></div><div><h2 id="6d42">Second step: Video playback</h2><p id="7539">Alright, at this point in the process, we uploaded and transformed our user video to stream it on our site. A video could be hundreds of megabytes split into thousands of chunks.</p><p id="eeed">The video HTML tag does not support adaptative bitrate streaming formats like HLS or MPEG-Dash by default, so we must use a custom player. The two most used players to handle streaming are <a href="https://github.com/video-dev/hls.js" rel="noopener ugc nofollow" target="_blank">HLS.js</a> and <a href="https://github.com/shaka-project/shaka-player" rel="noopener ugc nofollow" target="_blank">Skaka Player</a>. They both use <a href="https://www.w3.org/TR/media-source/" rel="noopener ugc nofollow" target="_blank">Media Source Extension</a> to be able to handle this format. <em>I won’t go into more detail about players and MSE as it’s not the goal of this article; you can read more by clicking on the link I provided.</em></p><p id="476c">To prevent loading the video files from the cloud storage each time someone tries to play the video, and therefore pay a lot of money to the cloud provider, we use a <a href="https://www.cloudflare.com/learning/cdn/what-is-a-cdn/" rel="noopener ugc nofollow" target="_blank">Content Delivery Network (CDN)</a>.</p><figure><figcaption>Custom schema showing the process of using a CDN</figcaption></figure><p id="3bcd">The user lands on the site to stream the video. All calls to retrieve the video go through our CDN provider, Cloudflare. A CDN will cache the content at the edges, which means if the content you are requesting is not present in their cache, it will demand it to the URL you provided.</p><p id="7437">The “edge” part means that depending on where you are in the world, it will store it in a server close to you (regionally) so that if a user in your region asks for the same content, he gets it blazingly fast. If a user from another side of the world asks for the same content, it will do the same process and store it close to that user.</p><p id="6d56">Each video chunk is a separate file, so the waiting time for the unlucky user who has to create the cache is still relatively low. Not thousands of megabytes to download at once.</p></div><div><p id="beb3">I skipped some essential parts of our architecture like micro-services, WebSockets, Redis pub/sub, or webhooks to keep the focus on Kubernetes’ auto-scaling capabilities in combination with RabbitMQ asynchronous queues. I’ll probably write another article about “communication” in our architecture soon.</p><p id="23bd">YouTube probably has an implementation that differs significantly from ours, but it’s already a good look into what a complex system with Kubernetes might look like.</p><p id="25aa">I would love to be a little mouse and peek at YouTube’s complete architecture to see how far we are from them. I might want to contact Ratatouille’s movie creator to do so; it’s a real story right?</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Feds find "substantial'' safety issue at SC nuclear plant (115 pts)]]></title>
            <link>https://www.thestate.com/news/local/environment/article280228714.html</link>
            <guid>37823141</guid>
            <pubDate>Mon, 09 Oct 2023 17:49:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thestate.com/news/local/environment/article280228714.html">https://www.thestate.com/news/local/environment/article280228714.html</a>, See on <a href="https://news.ycombinator.com/item?id=37823141">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="primary-content"><!----><!----><!----><figure><div>
        
                








    
        <div>
            <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_1140/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 992px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_960/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 768px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_768/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 601px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_640/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 441px)">
                <source srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_480/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" media="(min-width: 320px)">
                <!--[if IE 9]></video><![endif]-->
                
                <img srcset="https://www.thestate.com/latest-news/d7ukvk/picture215953320/alternates/LANDSCAPE_1140/VC%20Summer%20May%2026%202017%20DSC00186-sm.jpg" alt="V.C. Summer nuclear site in Fairfield County. SCANA abandoned plans to build two new reactors in 2017. They would have complemented the existing reactor." title="V.C. Summer nuclear site in Fairfield County. SCANA abandoned plans to build two new reactors in 2017. They would have complemented the existing reactor." loading="lazy">
                
            </picture>

            
        </div>
    

            
        

                 
                
                    
                        <figcaption>
                            
    
        V.C. Summer nuclear site in Fairfield County. SCANA abandoned plans to build two new reactors in 2017. They would have complemented the existing reactor.
    
    
        
            
        
        
    

                        </figcaption>
                    
                
        
    </div></figure><!----><!----><!----><!----><!--[--><!--[--><p>Federal regulators have cited Dominion Energy for what they say is a substantial safety violation after finding that utility workers failed for 20 years to resolve cracking problems at the company’s V.C. Summer nuclear power plant northwest of Columbia.</p><!----><!--]--><!--[--><p>This past week, the U.S. Nuclear Regulatory Commission issued what’s known as a preliminary “yellow’’ safety assessment, a measure of how serious an atomic safety problem is considered at a power plant. Yellow assessments are the second most serious on an NRC scale of severity.</p><!----><!--]--><!--[--><p>The NRC, which rarely issues yellow findings, said nuclear plant operators <a href="https://www.thestate.com/news/local/environment/article279283589.html" target="_blank" rel="Follow">did not resolve cracking </a>problems from 2003 to 2022 in V.C. Summer’s diesel generator system, one of the most important backup safety systems at an atomic power plant.</p><!--]--><!--[--><p>NRC officials were not available Friday to explain their concerns with the backup diesel generator system, but an Oct. 4 enforcement letter to Dominion nuclear operations president Eric Carr said the utility violated an atomic safety standard that could result in more scrutiny of the power plant. </p><!----><!--]--><!--[--><p>“We are considering escalated enforcement for the apparent violation,’’ according to the letter signed by LaDonna Suggs, acting director of the NRC’s division of reactor projects.</p><!--]--><!--[--><p>That’s no surprise to one nuclear safety advocate. Yellow designations often spark additional investigation and scrutiny of atomic power plants like the one in Fairfield County, said David Lochbaum, a national expert on the inner workings of nuclear plants and NRC oversight.</p><!----><!--]--><!--[--><p>“The NRC feels this was avoidable,’’ Lochbaum said, when asked why the agency issued a yellow finding. “There were signs of problems that were overlooked. Because of that, the problem grew to a point where the diesel generator’’ system did not work during testing.</p><!----><!--]--><!--[--><p>“You’re supposed to find and fix problems that occur,’’ he said.</p><!--]--><!--[--><p>Since 2009, the NRC has issued seven yellow findings against the nation’s nuclear power plants, Lochbaum said, after reviewing agency records. Only a red designation is considered worse, with white and green findings less significant. The United States has nearly 100 nuclear plants.</p><!----><!--]--><!--[--><p>The NRC’s determination is not final and is listed as an “apparent’’ violation. Dominion will have an opportunity to explain more about the diesel generator system issues, according to the NRC. Dominion spokesman Darryl Huger said the company “has implemented a plan to improve the system’s reliability.’’</p><!----><!--]--><!--[--><p>Huger, in an email to The State, said V.C. Summer has a history of operating safely, maintaining what he said was an “exemplary’’ record. The recent NRC concern centers on a pipe that delivers fuel to one of the power plant’s two emergency diesel generators, he said. Dominion found problems after testing the piping system, according to the NRC. </p><!--]--><!--[--><p>The power company, which acquired former V.C. Summer plant owner SCE&amp;G after a failed effort to build two additional reactors at the site, plans to install thicker piping in the generator system, Huger said.</p><!----><!--]--><!--[--><figure>                      <div>            <picture>                <!--[if IE 9]><video style="display: none;"><![endif]-->                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_1140/ReactorsFretwellPix5x2.8" media="(min-width: 992px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_960/ReactorsFretwellPix5x2.8" media="(min-width: 768px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_768/ReactorsFretwellPix5x2.8" media="(min-width: 601px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_640/ReactorsFretwellPix5x2.8" media="(min-width: 441px)">                <source srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_480/ReactorsFretwellPix5x2.8" media="(min-width: 320px)">                <!--[if IE 9]></video><![endif]-->                                <img srcset="https://www.thestate.com/opinion/opn-columns-blogs/cindi-ross-scoppe/wb0uqx/picture215586825/alternates/FREE_1140/ReactorsFretwellPix5x2.8" alt="V.C. Summer nuclear plant in Fairfield County, S.C. The site has one reactor. Two other reactors planned for the site were never completed." title="ReactorsFretwellPix5x2.8" loading="lazy">                            </picture>                            <figcaption>                                            V.C. Summer nuclear plant in Fairfield County, S.C. The site has one reactor. Two other reactors planned for the site were never completed.                                                                                            Sammy Fretwell/The State                                                                                    </figcaption>                    </div>        </figure><!----><!--]--><!--[--><p>Dominion’s backup diesel generator system, like those at other nuclear plants, is designed to provide power to parts of the plant that need electricity in the event power is knocked out during an emergency, such as a storm or earthquake.</p><!--]--><!--[--><p>That’s important because power is needed to keep water running through the nuclear reactor core to prevent it from overheating. If power is lost, the nuclear fuel can melt, causing radiation to be released into the surrounding community.</p><!----><!--]--><!--[--><p>In this case, officials at the V.C. Summer plant learned about cracks in fuel pipes in the facility’s diesel generator system in 2003. Utility workers fixed the initial crack, as well as other cracks four different times in the years after the initial work was done. </p><!----><!--]--><!--[--><p>But the NRC says the utility never adequately assessed what could be done to make sure the diesel piping system did not experience more cracking. The most recent cracks were identified in November 2022 during a 24-hour test of the system. Workers found a small leak on one of two diesel generator systems. The leak increased over time and workers discovered a 140-degree crack around a pipe, records show.</p><!--]--><!--[--><p>The cracking occurred mostly in the power plant’s “A” diesel generator system, although one problem occurred in the plant’s “B” generator system. The plant has two backup diesel generators. </p><!----><!--]--><!--[--><p>The cracking that led to the yellow safety finding follows separate, electrical problems with the plant’s diesel generator system in 2022. The NRC said the company, in that case, also <a href="https://www.thestate.com/news/local/environment/article268772222.html" target="_blank" rel="Follow">failed to promptly resolve</a> problems, issuing a white finding last year. White is lower in safety significant than yellow, but still considered notable.</p><!----><!--]--><!--[--><p>Tom Clements, a long-time nuclear safety advocate, said the NRC’s recent yellow safety assessment reveals a violation “too egregious to ignore.’’ He called for a “severe monetary fine’’ against Dominion, which he said ignored preventative maintenance through the years.</p><!--]--><!--[--><p>Dominion’s problems are noteworthy in light of the company’s recent request to renew its V.C. Summer operating license another 40 years, Clements said. The power plant, which cranked up operations in the early 1980s, is about 25 miles northwest of Columbia in rural Fairfield County.</p><!----><!--]--><!--[--><p>“Hopefully, serious safety problems don’t lurk in other reactor safety systems at the reactor,’’ Clements said in an email to The State. “This incident serves as a wake-up call to fully analyze all such systems prior to a license-renewal determination.’’</p><!----><!--]--><!--[--><figure>                      <div>            <picture>                <!--[if IE 9]><video style="display: none;"><![endif]-->                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_1140/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 992px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_960/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 768px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_768/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 601px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_640/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 441px)">                <source srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_480/photo-plant-nuclear,%20from%20SCEG.jpg" media="(min-width: 320px)">                <!--[if IE 9]></video><![endif]-->                                <img srcset="https://www.thestate.com/latest-news/7jilfu/picture279284539/alternates/FREE_1140/photo-plant-nuclear,%20from%20SCEG.jpg" alt="The V.C. Summer Nuclear power plant is in Fairfield County, SC. It is operated by Dominion Energy." title="photo-plant-nuclear, from SCEG.jpg" loading="lazy">                            </picture>                            <figcaption>                                            The V.C. Summer Nuclear power plant is in Fairfield County, SC. It is operated by Dominion Energy.                                                                                                                                                                        <span>Dominion Energy photo</span>                                                            </figcaption>                    </div>        </figure><!--]--><!--]--><!----><p>This story was originally published <span>October 7, 2023, 10:17 AM.</span></p><!----><!----><div><article> 
        
            
    
    

<div>
    <p><a href="https://www.thestate.com/profile/218308580">
                <img src="https://www.thestate.com/latest-news/kbyrpl/picture222581940/alternates/FREE_480/FretwellMug.jpg" alt="Profile Image of Sammy Fretwell" loading="lazy">
            </a>
    </p>

    

    
    
        <p><span>Sammy Fretwell has covered the environment beat for The State since 1995. He writes about an array of issues, including wildlife, climate change, energy, state environmental policy, nuclear waste and coastal development. He has won numerous awards, including Journalist of the Year by the S.C. Press Association in 2017. Fretwell is a University of South Carolina graduate who grew up in Anderson County. Reach him at 803 771 8537.</span>
        <a href="https://account.thestate.com/subscribe/create?param=f3JBCko=&amp;offer=NmEfaxcUb3lSCUJAfRIiaSA8CncoYyc3BA9BG15QPgoUG0hQeHNFCkBKb29STx0HLisVS1BIbwA%2FdUtLAAxCdD1QMA%3D%3D&amp;cid=news_author-card_fretwell-.99mo-2mo-15.99_202007">Support my work with a digital subscription</a></p>
</div>

        
    </article></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linuxatemyram.com (236 pts)]]></title>
            <link>https://www.linuxatemyram.com/</link>
            <guid>37822927</guid>
            <pubDate>Mon, 09 Oct 2023 17:31:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.linuxatemyram.com/">https://www.linuxatemyram.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37822927">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

      <center>
        <img src="https://www.linuxatemyram.com/atemyram.png" alt="Linux ate my RAM!">
        <p id="blinkyblink">
          <h2>
            Don't Panic!<br>Your ram is fine!
          </h2>
        </p>
      </center>

        <h2>What's going on?</h2>
        <p>Linux is borrowing unused memory for disk caching. This makes it look like you are low on memory, but you are not! Everything is fine!</p>

        <h2>Why is it doing this?</h2>
        <p>Disk caching makes the system much faster and more responsive! There are no downsides, except for confusing newbies. It does not take memory away from applications in any way, ever!</p>

        <h2>What if I want to run more applications?</h2>
        <p>If your applications want more memory, they just take back a chunk that the disk cache borrowed. Disk cache can always be given back to applications immediately! You are not low on ram!</p>

        <h2>Do I need more swap?</h2>
        <p>No, disk caching only borrows the ram that applications don't currently want. It will not use swap. If applications want more memory, they just take it back from the disk cache. They will not start swapping.</p>

        <h2>How do I stop Linux from doing this?</h2>
        <p>You can't disable disk caching. The only reason anyone ever wants to disable disk caching is because they think it takes memory away from their applications, which it doesn't! Disk cache makes applications load faster and run smoother, but it NEVER EVER takes memory away from them! Therefore, there's absolutely no reason to disable it!</p>
        <p>If, however, you find yourself needing to clear some RAM quickly to workaround another issue, like a VM misbehaving, you can force linux to nondestructively <a href="https://linux-mm.org/Drop_Caches">drop caches</a> using <code>echo 3 | sudo tee /proc/sys/vm/drop_caches</code>.</p>

        <h2>Why does top and free say all my ram is used if it isn't?</h2>
        <p>This is just a difference in terminology. Both you and Linux agree that memory taken by applications is "used", while memory that isn't used for anything is "free".</p>
        <p>But how do you count memory that is currently used for something, but can still be made available to applications?</p>
        <p>You might count that memory as "free" and/or "available". Linux instead counts it as "used", but also "available":</p>
        <table>
          <thead>
            <tr>
              <th>Memory that is</th>
              <th>You'd call it</th>
              <th>Linux calls it</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>used by applications</td>
              <td>Used</td>
              <td>Used</td>
            </tr>
            <tr>
              <td>used, but can be made available</td>
              <td>Free (or Available)</td>
              <td>Used (and Available)</td>
            </tr>
            <tr>
              <td>not used for anything</td>
              <td>Free</td>
              <td>Free</td>
            </tr>
          </tbody>
        </table>
        <p>This "something" is (roughly) what top and free calls "buffers" and "cached". Since your and Linux's terminology differs, you might think you are low on ram when you're not.</p>

        <h2>How do I see how much free ram I really have?</h2>
        <p>To see how much ram your applications could use without swapping, run <code>free -m</code> and look at the "available" column:</p>
        <pre>  $ free -m
                total        used        free      shared  buff/cache   available
  Mem:           1504        1491          13           0         855      <span><strong>792</strong></span>
  Swap:          2047           6        2041
</pre>
        <p><small>(On installations from before 2016, look at "free" column in the "-/+ buffers/cache" row instead.)</small></p>
        <p>This is your answer in MiB. If you just naively look at "used" and "free", you'll think your ram is 99% full when it's really just 47%!</p>
        <p>For a more detailed and technical description of what Linux counts as "available", see <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=34e431b0ae398fc54ea69ff85ec700722c9da773">the commit that added the field</a>.</p>

        <h2>When should I start to worry?</h2>
        <p>A <strong>healthy Linux system</strong> with more than enough memory will, after running for a while, show the following expected and harmless behavior:</p>
        <ul>
          <li><code>free</code> memory is close to <code>0</code> </li>
          <li><code>used</code> memory is close to <code>total</code> </li>
          <li><code>available</code> memory (or "free + buffers/cache") has enough room (let's say, 20%+ of total)</li>
          <li><code>swap used</code> does not change</li>
        </ul>
        <p><strong>Warning signs</strong> of a genuine low memory situation that you may want to look into:</p>
        <ul>
          <li><code>available</code> memory (or "free + buffers/cache") is close to zero</li>
          <li><code>swap used</code> increases or fluctuates</li>
          <li><code>dmesg | grep oom-killer</code> shows the OutOfMemory-killer at work</li>
        </ul>

        <h2>How can I verify these things?</h2>
        <p>See <a href="https://www.linuxatemyram.com/play.html">this page</a> for more details and how you can experiment with disk cache to show the effects described here. Few things make you appreciate disk caching more than measuring an order-of-magnitude speedup on your own hardware!</p>

        <small><strong>LinuxAteMyRam.com was presented by <a href="http://www.vidarholen.net/">VidarHolen.net</a>. This site is available <a href="https://github.com/koalaman/linuxatemyram.com">on GitHub</a> for comments and PRs.</strong></small>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Medieval staircases were not built going clockwise for the defender's advantage (287 pts)]]></title>
            <link>https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/</link>
            <guid>37822774</guid>
            <pubDate>Mon, 09 Oct 2023 17:20:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/">https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/</a>, See on <a href="https://news.ycombinator.com/item?id=37822774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">

	<main id="main" role="main">

		
			
<article id="post-3655">

	<!-- .entry-header -->

	<div>
		
<p>This story has been making the rounds on the internet with a claim that you’ve probably been told during visits to castles, but, it’s not true.</p>


<div>
<figure><img data-attachment-id="3661" data-permalink="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png" data-orig-size="601,1139" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2023-10-09-at-14-55-37-historic-vids-on-x" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=158" data-large-file="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=540" width="601" height="1139" src="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=540" alt="" srcset="https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png 601w, https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=79 79w, https://fakehistoryhunter.files.wordpress.com/2023/10/screenshot-2023-10-09-at-14-55-37-historic-vids-on-x.png?w=158 158w" sizes="(max-width: 601px) 100vw, 601px"></figure></div>


<p>In short the idea is that it’s easier for a soldier or right-handed knight to fight in a spiral staircase that is built clockwise when they were defending the castle as they had space to swing their weapon while the attacker would find this more difficult.</p>



<p>Like many myths that stick, the story at first makes sense.<br>So when we hear it from a guide during a castle tour, from our history teacher, or even on television documentaries, why would we doubt it?</p>



<p>But if you think about it a bit longer and start looking for evidence, you soon realise something is a bit iffy here.<br>For starters, there is no primary evidence, whatsoever, that the people who built, lived and fought in these castles built staircases in that way for that reason. During the Middle Ages, nobody wrote down that you should build staircases like this and why.<br>If it had been common knowledge among castle builders, then why are there still quite a lot (about 30%) of castles with counter-clockwise staircases?<br>And no, before you start, there’s no evidence of the Kerrs being left handed, that’s probably an 19th century (yes, them again) <a href="https://triskeleheritage.triskelepublishing.com/2023/08/15/mediaeval-mythbusting-blog-24-the-left-handed-kerrs/">myth</a>.<br>The Tower of London, one of the most important castles in England, where royalty live(d) has counter-clockwise stairs!<br>If medieval people thought this would give the defenders not an advantage, surely they would have fixed it, especially in this castle!</p>


<div>
<figure><img data-attachment-id="3666" data-permalink="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/both-stairs-at-cliffords-tower/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg" data-orig-size="921,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="both-stairs-at-cliffords-tower" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=300" data-large-file="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=748" width="921" height="640" src="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=921" alt="" srcset="https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg 921w, https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=150 150w, https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=300 300w, https://fakehistoryhunter.files.wordpress.com/2023/10/both-stairs-at-cliffords-tower.jpg?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption>Both these staircases are at Clifford’s Tower in York, two in the same building!<br>So the defenders didn’t mind if they weren’t at an advantage when the enemy took the right stairs?</figcaption></figure></div>


<p>Another reason why we know this story is a myth is that it also doesn’t make a lot of sense when you study medieval combat involving castles.<br>Castle builders knew that it didn’t really make a huge difference which way the stairs go, they’re not suitable for fighting at all, neither party has a lot of space to wield those long,<br>pointy, sharp weapons.<br>The person below you has the advantage of jabbing at your legs and feet while they can protect their head with their helmet and shield.<br>Of course the only way to win would be by pushing your enemy back down the stairs and then with whoever is left above you, retake the entire castle.<br>Yeah, that’s unlikely to work out.<br>Frankly, if you find yourself in this position the castle is probably already lost.<br>A better way to stop your enemy might be to block the stairs by throwing heavy furniture and everything else you can find down it while you then wait at the top of the stairs where you have more space to fight and where your enemy really is at a disadvantage as they’re still on the stairs below you.</p>



<p>For attackers it’s also not a very tempting scenario.<br>If you’ve already breached all the outer walls and defeated all the soldiers there, who would want to risk their life crawling up some stairs where the defenders are waiting for you?<br>Sieges often didn’t involve much fighting at all, as simply waiting outside the castle till the people inside ran out of water and food was a much easier and less bloody way to win.<br>In many cases simply realising the enemy was going to sit outside and wait was enough to surrender.</p>





<p>So in conclusion: there’s no evidence for this claim and it also doesn’t make a lot of sense.<br>This, like SO MANY myths about the middle ages can very likely be <a href="https://archive.org/details/spiralsinnaturea00cook/page/144/mode/2up">credited to the Victorians</a>.<br>For more research &amp; the opinions of historians, archaeologists &amp; other experts check the sources below.</p>



<p>Stairs were used to go up and down floors, they were not dimly lit or built to be uneven on purpose as you wouldn’t want servants, soldiers but also the lords and ladies themselves falling down them all the time.<br>“Oh no Lord Dave has fallen down the stairs and broken his neck because we have no lights and dodgy steps in the tower just in case there’s a siege even though we haven’t had one in generations….”</p>



<p>And if you’re trained in medieval combat and have access to some castle stairs, please do some experimenting, try if you can fight there and make a video of it, I’ll share it here!<br>Do be careful &amp; responsible though, I won’t take responsibility for you damaging yourself or worse, the castle 😉</p>



<p><strong>Sources:</strong></p>



<ul>
<li><a href="https://fakehistoryhunter.net/2023/09/08/ive-written-a-book/">Fake History, 101 things that never happened, by J.H.Teeuwisse</a></li>



<li><a href="http://www.castlestudiesgroup.org.uk/CSGJournal2011-12X5Stairs-low-res.pdf">‘The Rise of the Anti-clockwise Newel Stairs’, research by the Castle Studies Group (pdf link)</a></li>



<li><a href="https://www.medievalists.net/2012/08/the-rise-of-the-anti-clockwise-newel-stair/">Medievalists.net</a></li>



<li><a href="https://triskeleheritage.triskelepublishing.com/mediaeval-mythbusting-blog-2-the-man-who-invented-the-spiral-staircase-myth/">Triskele Heritage</a></li>



<li><a href="https://talesoftimesforgotten.com/2019/12/18/no-medieval-staircases-werent-designed-to-give-right-handed-defenders-an-advanta">Tales of times forgotten</a></li>



<li><a href="https://www.reddit.com/r/AskHistorians/comments/406sa5/were_castle_stairs_designed_to_impede_sword_use/">r/AskHistorians</a></li>
</ul>



<p>If you like my work, please consider supporting me on <a href="https://www.patreon.com/fakehistoryhunter">Patreon</a>;</p>


<div>
<figure><a href="https://www.patreon.com/fakehistoryhunter"><img data-attachment-id="1998" data-permalink="https://fakehistoryhunter.net/become_a_patron_button2x/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp" data-orig-size="434,102" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="patreon" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=300" data-large-file="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=434" loading="lazy" width="434" height="102" src="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=434" alt="Become a patron" srcset="https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp 434w, https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=150 150w, https://fakehistoryhunter.files.wordpress.com/2021/11/become_a_patron_button2x.webp?w=300 300w" sizes="(max-width: 434px) 100vw, 434px"></a></figure></div>


<p>Disclaimer;<br>Picture(s) found online, used for (re-)educational purposes only.<br>I do not own the copyrights to these images, I only share them here for educational purposes to try and make sure the real story behind it becomes known and people will stop spreading false information.<br>If the copyright owner objects to the sharing here, kindly contact me and I shall alter the article.<br>If you’re interested in using any of the images here get in touch with the copyright owners mentioned in the article.<br>Feel free to contact me with questions.</p>


<div>
<figure><img data-attachment-id="3673" data-permalink="https://fakehistoryhunter.net/2023/10/09/medieval-staircases-were-not-built-going-clockwise-for-the-defenders-advantage/clockwise-staircases/" data-orig-file="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg" data-orig-size="4203,2500" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="clockwise-staircases" data-image-description="" data-image-caption="" data-medium-file="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=300" data-large-file="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=748" loading="lazy" width="4203" height="2500" src="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=1024" alt="" srcset="https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=1024 1024w, https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=150 150w, https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=300 300w, https://fakehistoryhunter.files.wordpress.com/2023/10/clockwise-staircases.jpg?w=768 768w" sizes="(max-width: 4203px) 100vw, 4203px"></figure></div>



			</div><!-- .entry-content -->

	<!-- .entry-footer -->

</article><!-- #post-## -->
			
	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
			<hr>

			
<!-- #comments -->

		
	</main><!-- #main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lensm, a tool for viewing disassembly (140 pts)]]></title>
            <link>https://www.storj.io/blog/lensm</link>
            <guid>37822284</guid>
            <pubDate>Mon, 09 Oct 2023 16:45:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.storj.io/blog/lensm">https://www.storj.io/blog/lensm</a>, See on <a href="https://news.ycombinator.com/item?id=37822284">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I couldn’t find a great tool for viewing disassembly, so I <a href="https://github.com/loov/lensm">wrote it myself over the weekend</a>.</p><p>At Storj, we are constantly looking for ways to accelerate our team’s efficiency, and one of those is building the tools we need.</p><p>One of the major things you will rub against when you delve into performance optimization is viewing the assembly that the compiler generates. It's usually not efficient to write assembly yourself, and it's better to try to coerce the compiler to produce the assembly you want. Here's my story of writing a little tool for viewing disassembly.</p><h2>Getting Annoyed</h2><p>My story starts on a weekend when I was doing a bunch of tiny optimizations to the <a href="https://gioui.org/">Gio UI</a> project. There are ways to view the assembly; one is to use <strong>go tool objdump -s funcname</strong> from the command line. However, it's rather difficult to see how the source code and assembly are related.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cb12919477d388915cc_t8ODK_OCt9V0GN9lHO1jcjyu9RUAPpIP9cEvOgvmPiucYhk_aMd-UloDUGJJkcEA1oesZN22AuBJTFu__jToyjt6-GIE7cmVmh76yTpzEEBA2AP5-qIqdz_5B5D444i8BtXaRnM-rc_nGXo9NGE.png" alt=""></p></figure><p>There is an excellent online tool for writing code and seeing the output <a href="https://go.godbolt.org/">https://go.godbolt.org</a>. The visuals are much clearer.</p><p>The corresponding lines of code have the same color. When you hover over the specific lines of code, the corresponding assembly is also highlighted.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc602e1d3ed86d1b95e_DMf8jw43xXtFI9VfW3Hj17WssFpJzHrR5lDCejh-3X7phoUaeKtkl3lAHFPvBcgT-gPKgSSj6nCPFXPhi2purUPZsCrZ2SiTZursoz4K6kEUt6Zw1tUzFA3J-hjCQFtqtkrw7MkfPMXuW7X3RQM.png" alt=""></p></figure><p>Compiler Explorer has many other nice features as well: sharing the result, compiling with different versions, diffing output from different compilers, and description of assembly instructions. The amount of different languages and compilers is staggering.</p><p>Despite how nice Compiler Explorer is, it's still an online tool, and you need to copy-paste your relevant code to the explorer.</p><p>After trying many times, my annoyance finally kicked in:</p><p><em>"Someone should've written this tool already–it shouldn't be too difficult."</em></p><p>Over the years of developing, I've found that getting annoyed is a rather excellent way to start a new project.</p><p>The first step in the project was to have access to the disassembly. It would be wasteful to start a disassembler from scratch. I knew that <strong>go tool objdump</strong> could already do it, so maybe they have some library they are using.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc668b49010e1da87a0_9ZumolrPy31nqggaq6bmyW8SM52RXE8nu1UPccpx8b2swsXLZgCsZ2Zk9RPHOs_b1tfTRiyktO4-ICAZjlVFoujbwMHEvT1RBLPk7ozIchhTGEjpOrvJx8K5MUSLUkIKvku1kPOx89EZ6c0RI2Q.png" alt=""></p></figure><p>Indeed, they are using a library, but it's internal to the compiler. The internal library looks pretty nice to use as well. I guess I need to extract it for my own needs. Copying the relevant code and adjusting the import paths was grunt work, but I got it extracted. Luckily the license for the Go code is open-source.</p><p>I needed to expose a little bit more information from the API to access the <a href="https://github.com/loov/lensm/commit/5bb596225accd3d6c0b4dbc13c4e6189c558c879#diff-1596bd8ceb74246828aacab827b39a33075c86baa627fbbeb7491bd31eef1169">necessary details</a>, but I got it working. Here's the debug print from the initial output:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc6a3af67247e7df4fb_qb8O0Gzs-OGv1nnBklsfecHlKD6x7JpTrPfCW_N7KKQi9rcC95pGDTMootqeXThAIVxyViremLEKkBZljKxOEEqROCnD89s3VYdyU6rV9lJQyXQgLK2UtNrEjtmjuBBWJL8QFAcpdAACqhQZOkU.png" alt=""></p></figure><p>Of course, extracting the internals means needing to keep it manually updated. I'm sure there was a tool to rewrite the paths and keep them automatically updated. Alternatively, maybe the Go project would accept a patch that exposes the information in some JSON format so the visualizer can call the appropriate Go compiler. But all of that is a project for another day.</p><h2>Extracting Source Code</h2><p>The first important step was to figure out the relevant source code that needed to be loaded. This seems a relatively easy thing in concept. It's mainly "Collect the list of lines per source file". However, the gotcha is how to represent the data, and similarly, you probably don't want just the lines but also some of the surrounding code.</p><p>This is the basic structure for representing source:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55d48d4896058b5eb6965_BJUkF2Uiv10IYKczczPkzefpWBzNt4QzGDlC7cJU9OA670QO25JLlNpojNqynyJHwMk3aFuRN1fytiEEvlIeuRcw9qu88diNKMX8g4QtY08nAWBKf_JaELPFRpRNgh0REC_767Sbbp75D6cVPlQ.png" alt=""></p></figure><p>Every assembly function can have multiple associated <strong>Source</strong> files due to inlining. Similarly, the code needed from different files isn't contiguous, and you wouldn't want to show more than is required.</p><p>Most of the data munging is: collect all the source lines, convert them into ranges, expand the ranges (for the surrounding context). We also need to do it in reverse: figure out which lines in disassembly correspond to the source code. Note that each source line can correspond to multiple disassembly lines, and they might not be contiguous.</p><p>Once I got it working, I did a debug print of the relevant source lines:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc768b4902b80da87ec_EpbrIxhdW9F6YPsgVzttahc-6E1a9K4K3NuhkZoQbBRHcAf10iM2AHwdNnmF4aOyvtj0Atj7TuihVvPExnRym8JaB2o5G-AnfxKhg7OA8YBGNVQBSSWUncArrpf05OjKJt0dD4K0Iu804GtrXvo.png" alt=""></p></figure><h2>Drawing Code</h2><p>I was trying to optimize the code for <a href="https://gioui.org/">Gio UI</a>, so of course, it was a natural choice for building a tool such as this. It has pretty lovely drawing capabilities that I'll need.</p><p>The question was then, how should it be visualized. Compiler Explorer visualization is a great starting point. However, it's not as clear as I would like it to be. When starting the project, I already had a design in mind. There are many source diffing tools that offer visualizing related lines. For example, here is what Meld tool looks like:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc66767e74611aa360e_m0noVeRrYWM5IJkJhVOzigPqft8IKGueEubr3DLK4Ai0nzTPHXWvg70UdRclyZruohGiEnLkhU04GSTV1WOprOcoQzvROVf8qVqLKzKNhgny7_nKuK4nPERBTSUy_fE6cmaCb5lL18Sq6Z0qhDI.png" alt=""></p></figure><p>There are other tools such as Kompare, CodeCompare, Oxygen Compare that offer similar visualization. I really like how it shows how one side is related to the other. To draw the shape, we can use the following idea:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc7382d3335e050c095_usrJMIUtSESOyvB0GzlSs6yR1x0Uh6OUe9Sd_KaA12uAdnqSbL3ETP46qLbYAvNS1-OV2o9xAceE1QXyHa2hr911wUwVNm5FXYXhm9yr5WvmNWnCR0sPH77iB1t0IGr0Wjs2nl1Tk3xVd5nozLo.png" alt=""></p></figure><p><em>The purple lines show the final relation shape. The orange arrows show bezier curve handles.</em></p><p>Drawing the visuals seemed then straightforward:</p><ol role="list"><li>figure out the location of each line of the source and assembly;</li><li>draw the relation shape for each line of source and related assembly lines;</li><li>draw the text on top of the relation shapes.</li></ol><p>One difficult thing people encounter with such projects is: how to choose a random color such that they are distinct, visually pleasing, and code is easy to write. One nice trick I've picked up over time is this formula:</p><p><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;hue: index * phi * 2 * PI, saturation: 60%, lightness: 60%</em></p><p>You can adjust the saturation and lightness between 50% to 90% to get different lightness and saturation. If you want a more pastel color look, you would use a lower saturation and higher lightness. For dark mode, you would use lightness below 30%. (The color selection assumes that hue is defined with the range 0 .. 2*PI). There are a few variations of the hue selection:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc6291947aee6891f09_jDepN774WglSl6bMQnycbS9HX-BDsvx5RS_fY1vEsyZmiaviZOl2BUvMeBf2_tPJ2Obil58YigtEhxVa2nzz7m2zP6BAOo6YariH3C9_nwyw_bWW-vLphnx9vJFfTvpab7StlD0F1XdDVgIrKts.png" alt=""></p></figure><p>As you can see, the 𝜑 = 1.618033988749… constant allows selecting values on a hue circle such that sequential numbers are different and won't repeat. If you want a smoother transition, then using i × 1/𝜑 works a treat. If you want more contrast, then i × 𝜑 × 2𝜋 is nicer.</p><p>Once you put all these ideas together, you get the first output:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc792d7842017b7cca1_vj_GRqrXEcs_dWwyk7qZ-cbU6QwULj0sNybAArPdZn4QX0f5N8GoKcmkw0IxCgwc8NKetA5QXiC_qSa9BRWNqqZuaD5uuhpJpPBIPZu6BuN8h8I1w-WD8zKr8IltoyiPjfp28-ULlCUXv6wGOfM.png" alt=""></p></figure><p>I also added a small interaction – when you hover the mouse over a line of code, it highlights the relation shape.</p><h2>Drawing Jumps</h2><p>The next thing I wanted to visualize was drawing jumps in the code. They are important from a performance perspective. It's relatively common for disassemblers to draw an arrow from the jump location to the destination. This brings up two problems, detecting the jumps, and figuring out how to draw the lines.</p><p>Unfortunately, the objfile library disassembler doesn't expose the information whether the instruction is a jump and when it jumps, then where to. I didn't want to dig too deep into this, so I reached for the usual tool for this – regular expression matching. It seemed that all the jumps ended with a hex number, such as <strong>JMP 0x123</strong>... of course, that approach broke. On arm processors, they look like <strong>BLS 38(PC)</strong>. I added a special case for it for now, but it'll probably break again on some other platform.</p><p>To draw the jumps initially, I just drew them like a stack. In other words, push the jump line to the sidebar when you encounter one and then pop it when it ends. Of course, that didn't look great due to overlapping lines:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc7382d33da3a50c09c__vBqyuDL7Iwp3ZxyvZRiUyK-FoWL5JpH8PR7-UgVOr1Iw2vE6RFeM6syPPmhbeDfPLzoEWFEPzZYnA3k-X_6400rJYVj8BYQbIT66K-ITM3p9O61nnlzBK-LDwT-_z9Bs_HDhByCaFBuytRNe7s.png" alt=""></p></figure><p>In some cases it even caused the lines to be on top of each other. I searched for a nice algorithm for drawing them; however, I came up empty. Finally, I decided to go with the following approach, sort all the jump ranges based on their starting and ending point. If multiple ranges start from the same location, the larger range is sorted first. Then divide the sidebar into lanes; every new range picks the first lane that is free – starting from the left. This ends up minimizing crossings.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc733365697a909185c_PGA8v7YrP_F3LQKUIGUH9PZ8XpRfsEHP_Qyc6sKvZNavb-xgdPOWrquHLk1oaLEDEx00aBkwdrCLdm152__r96IX9HTiUqEfExezajtIZV_oVZNVu6fM89Xdu4JcG8w64ueUPFl30ILIdZQlQJ4.png" alt=""></p></figure><p>It's by no means ideal. It can still draw the jump line too far from the code.</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc7557a628d36655417_cOlVg7oIrOA5VJ-IPJujha90ug3CYdF9ENhcbtkQekQhn-RhI-3ry2gMUo9HZBMPfmOLTgZjcJK2zbCrucMUf1IYYU9cZDdQzQmRBHkSjkIJzxEWsuKNuC16mzuS_FGweaQK0Q7jAl_53bio3S4.png" alt=""></p></figure><p>Or do this thing here:</p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc74d138d629ee5bd63_oFJWLa1Kq1CQiIR9t4Uw0VRB4VJ5M1DAzUGp5fsxky3zNkmb0EM6LERZ_eZJSC01cV_ar1JVESdMP4PSZY2n6k946gE2jSVlWUU-JYSQqiLTFNVhlt2s0y3ujeqBhRhDPECjMJL6b2N5MS5yVl4.png" alt=""></p></figure><p>But, these are things someone will fix some other day.</p><h2>Summary</h2><p>After a few days of work, I have a nice tool for viewing disassembly. </p><figure><p><img src="https://assets-global.website-files.com/602eda09fc78af5a419706be/62d55cc724fc82ab5179a8e9_nn9EQG2KhJKrJqL0g9OwAKDzdb5-N9OcWcWKsKNbFs3GoOlsqPdbEEvGWPE5Ncnq0qd1og8yMFVgTvmx2QkKwo7suFvnHJCXVEx1iTAmGddNDUumhTB-ugVIZfbT9nuJWka92IvIp6MQFT3x5jU.png" alt=""></p></figure><p>Choosing a name was also a struggle. I wanted it to be easily recognizable and searchable. I asked in Gophers #performance channel and Jan Mercl suggested "lensm," which is "lens" and "asm" smushed together.</p><p>When you look at the code and think: "For a performance-conscious project, it doesn't look very efficient – allocations and suboptimal algorithms everywhere. Also, the code looks very messy."</p><p>That's all true, but the goal was to get it done quickly. And, if I do need to optimize, then I have an extra tool in my toolbelt to optimize it.</p><p>I'll still have a few things I want to add before I can call it sufficiently complete. Nevertheless, it's already functional, so give it a test run at <a href="https://github.com/loov/lensm">https://github.com/loov/lensm</a>. If you feel like something is missing, then come along for the ride and submit a patch; there have already been a few contributors.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[789 KB Linux Without MMU on RISC-V (152 pts)]]></title>
            <link>https://popovicu.com/posts/789-kb-linux-without-mmu-riscv/</link>
            <guid>37822082</guid>
            <pubDate>Mon, 09 Oct 2023 16:28:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://popovicu.com/posts/789-kb-linux-without-mmu-riscv/">https://popovicu.com/posts/789-kb-linux-without-mmu-riscv/</a>, See on <a href="https://news.ycombinator.com/item?id=37822082">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" role="article">
      <p><a href="https://twitter.com/popovicu94?ref_src=twsrc%5Etfw" data-show-count="false">Follow @popovicu94</a></p>
<p>In this guide, we’ll build a very tiny Linux kernel, weighing in at 789 K, and requiring <strong>no MMU support</strong>. We’ll write some userspace code and this will be deployed on a virtual RISC-V 64-bit machine, without MMU, and we’ll run some tiny programs of our own.</p>
<p>As a reminder, please go through <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">the guide for a micro Linux distro</a> to understand the concepts behind what we’re doing today: building the kernel, <code>initramfs</code>, etc. This guide is basically a continuation of that one and an exercise in making an absolutely minimal Linux deployment for (in theory) extremely cheap hardware.</p>
<p>Like before, there’s very little here that is specific to RISC-V, I just want to stay consistent with my previous guides. This exercise should be easily repeatable for other architectures too (though <code>x86</code> may be somewhat sticky).</p>
<h2 id="table-of-contents">Table of contents</h2>
<details><summary>Open Table of contents</summary>
<ul>
<li>
<p><a href="#mmu-and-linux">MMU and Linux</a></p>
<ul>
<li><a href="#brief-history-of-uclinux">Brief history of uClinux</a></li>
</ul>
</li>
<li>
<p><a href="#challenges-with-mmu-less-linux">Challenges with MMU-less Linux</a></p>
<ul>
<li><a href="#executable-file-format">Executable file format</a></li>
<li><a href="#pointers-are-dangerous-obviously">Pointers are dangerous (obviously!)</a></li>
<li><a href="#vfork-instead-of-fork"><code>vfork</code> instead of <code>fork</code></a></li>
</ul>
</li>
<li>
<p><a href="#building-binaries-for-an-mmu-less-kernel">Building binaries for an MMU-less kernel</a></p>
<ul>
<li><a href="#getting-the-toolchain">Getting the toolchain</a></li>
<li><a href="#building-the-toolchain">Building the toolchain</a></li>
<li><a href="#building-bflt-files">Building bFLT files</a></li>
</ul>
</li>
<li>
<p><a href="#building-an-extremely-tiny-linux-kernel">Building an extremely tiny Linux kernel</a></p>
</li>
<li>
<p><a href="#building-an-initramfs-image-for-the-tiny-mmu-less-kernel">Building an <code>initramfs</code> image for the tiny MMU-less kernel</a></p>
</li>
<li>
<p><a href="#slightly-more-complicated-build-verifying-system-calls-and-multiprocessing">Slightly more complicated build: verifying system calls and multiprocessing</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
<li>
<p><a href="#github-repo">GitHub repo</a></p>
</li>
</ul>
</details>
<h2 id="mmu-and-linux">MMU and Linux</h2>
<p>An important piece of hardware when running an operating system is an <strong>MMU: memory management unit</strong>. This unit oversees memory accesses from a running CPU and translates them to different physical addresses. The reason why this is hugely important is because that is how the memory is <strong>virtualized</strong>, and the MMU is heavily used by the operating systems to implement a <strong>virtual address space</strong>. What this means is that the kernel typically enables the applications to not worry about how other running applications occupy the memory on a machine. Each process has an illusion of complete ownership of the memory, and the kernel facilitates that by virtualizing the memory. In other words, 2 processes on the same machine may use a memory location <code>0x12345678</code> and what they’d really be hitting inside the physical memory could be locations <code>0xAABBCCDD</code> and <code>0xDDCCBBAA</code>, respectively. The MMU, once set up by the kernel, will route the <code>0x12345678</code> accesses from each one of these applications to the relevant end physical address.</p>
<p>Your typical Linux build virtualizes the address space and uses the MMU for this, and while we didn’t explicitly set it in <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">the previous guide</a>, MMU was used and the memory contents of one process were insulated from the other processes.</p>
<p>Now, as useful as MMU is, not all machines have it. The super simple budget-friendly microcontrollers typically do not have it, and the memory addresses coming out of the program running are actually what is used to access the memory. In this case, if a process accesses <code>0x12345678</code>, it will go to the address <code>0x12345678</code> indeed.</p>
<h3 id="brief-history-of-uclinux">Brief history of uClinux</h3>
<p>As Linux has been rising in popularity since its inception, there have been attempts to run it on pretty much any digital device. This includes popular <a href="https://en.wikipedia.org/wiki/Microcontroller">microcontrollers</a> that do not have an MMU attached. Enter <strong>uClinux</strong>.</p>
<p>The proper name for uClinux is actually μClinux, with a Greek ‘mu’, and so μC stands for ‘microcontroller’. We spell it as uClinux for ASCII-friendly simplicity.</p>
<p>The uClinux effort, per my understanding, was running independently for some time, before the decision has been made to <strong>mainline</strong> it, meaning it is now part of the Linux source code itself. Basically, what this means for us is that uClinux is now a set of configurations in the kernel build config, and we’ll get our MMU-less build easily.</p>
<h2 id="challenges-with-mmu-less-linux">Challenges with MMU-less Linux</h2>
<p>Before we get our hands dirty, I would like to highlight a few challenges with running Linux in this way. I will from this point refer to our Linux as MMU-less Linux, rather than uClinux to avoid confusion with the old project that has since been mainlined.</p>
<h3 id="executable-file-format">Executable file format</h3>
<p>First, ELF binaries will not work anymore. I have not been able to build a MMU-less flavor of Linux for ELF, and I strongly believe it is impossible. I’m not sure if something about the ELF format explicitly assumes a virtual address space necessarily, I don’t think it does, but it just seems impossible to load an ELF binary for running.</p>
<p>What MMU-less Linux likes are the <strong>bFLT</strong> binaries. FLT stands for <em>flat</em>, and this initially made me believe that there really is no file format here, that we’re supposed to just dump the machine instructions into a bare file, but this really isn’t the case. bFLT has some structure, which is far simpler than ELF, but it’s structured nonetheless. I personally found it very difficult to find any good documentation on what this file format really looks like, and really the only useful page I have found on the Internet around it is <a href="https://myembeddeddev.blogspot.com/2010/02/uclinux-flat-file-format.html">this page</a> from someone’s personal blog. It’s a bit interesting to think that if this blog goes offline, there really isn’t anything out there left except the actual source code in the Linux codebase, and I’m sure you agree that’s not the most elegant way to learn.</p>
<h3 id="pointers-are-dangerous-obviously">Pointers are dangerous (obviously!)</h3>
<p>It should be obvious, but I’ll still call it out — MMU is not routing our memory accesses now; whatever we access is really what we hit in the physical memory and this means that bad pointers are now very dangerous. You could easily corrupt the memory contents of another process or even the kernel itself.</p>
<p>This would be a great place to introduce something like Rust programming, but given that it was tricky to build bare C programs for this kind of a platform (more about it below), I would now just say it’s too early for that.</p>
<h3 id="vfork-instead-of-fork"><code>vfork</code> instead of <code>fork</code></h3>
<p>The <code>fork</code> system call does not work on an MMU-less Linux since that heavily depends on virtualizing the memory, and this may lead some people to believe that you can run only one process on a MMU-less Linux, but that is not correct, and we will show it later — multiprocessing is definitely possible.</p>
<p>The way you achieve multiprocessing is by simply using <code>vfork</code> instead of <code>fork</code>. I’ll keep things simple here and say that the difference between <code>vfork</code> and <code>fork</code> is that the parent process is sleeping until the child exits or calls <code>execve</code>. Please note that unless you <code>exec</code> into another binary from the child process, the child is running in <strong>the same memory space</strong>. Again, there is no MMU to help us out here.</p>
<h2 id="building-binaries-for-an-mmu-less-kernel">Building binaries for an MMU-less kernel</h2>
<p>As we mentioned before, we need to build bFLT binaries rather than ELFs. Figuring out how to exactly do this is what took most of my time in this exercise.</p>
<p>I’ll skip a lot of details and give you the end result, and I’m sure if you dig around why this is the end result, you’ll be able to quickly figure out what’s going on. Here it is: <strong>the simplest way to build bFLT binaries is with a uClibc toolchain</strong>.</p>
<p><code>uClibc</code> is basically a very slimmed down version of the C standard library, suitable for embedded systems. Of course, nothing is stopping you from using it outside of this context, for example, in a full blown desktop Linux distrbution.</p>
<p>Quick note: which flavor of the standard C library is the best is another frequent topic of debate.</p>
<h3 id="getting-the-toolchain">Getting the toolchain</h3>
<p>I strongly suggest building the <code>uClibc</code> toolchain from source. It’s very easy, since it is based on Buildroot.</p>
<p>Therefore, let’s head over to the <a href="https://buildroot.org/download.html">Buildroot download page</a>, fetch the latest release and unpack it. You can <code>cd</code> into the unpacked directory.</p>
<p>tl;dr on what Buildroot is: it is a massive collection of <code>Makefile</code>s that is typically used to build a Linux distribution for an embedded system. You can use it to drive the kernel download + build as well, though I personally prefer to do it separately. What I typically use Buildroot for is to fetch the sources of common tools and build the <code>initramfs</code> <code>cpio</code> archive containing them. If you don’t know what this means, please check the <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">previous guide on making a micro Linux distro</a>. You configure the Buildroot flow almost the same as you configure the Linux kernel build flow: you run <code>make menuconfig</code>, toggle a bunch of options and you’re good to go. Buildroot is great because it has the scripts to pull and build a super wide range of common Linux tools and applications: <code>busybox</code>, <code>ip</code>, <code>vi</code>, <code>python</code>, <code>Xorg server</code> you name it.</p>
<p>Sadly, this is as much as the <a href="https://www.uclibc.org/toolchains.html">uClibc toolchain page</a> says. Personally, I was a bit puzzled after reading it: how do I use the toolchain and how do I build the binaries for <code>uClinux</code>? I’ll cover that part right now.</p>
<h3 id="building-the-toolchain">Building the toolchain</h3>
<p>Now that you have Buildroot downloaded, you can build the <code>uClibc</code> toolchain, which basically means you’ll have a GCC set of tools to compile with against it. I was always under the impression that changing which standard library you want is a matter of just providing a different standard library to any GCC compiler, but after some digging online, my understanding now is that the GCC needs to be specifically compiled against it somehow. It’s a bit beyond my understanding at the moment, to be perfectly honest.</p>
<ol>
<li>As mentioned above, you can do <code>make menuconfig</code> from your unpacked Buildroot directory.</li>
<li>Go to <code>Target options</code>, and select <code>RISCV</code> as the architecture.</li>
<li><code>Target architecture size</code> should be 64-bit.</li>
<li><strong>Unselect the MMU support</strong> option.</li>
<li><code>Target Binary Format</code> should be <strong>FLAT</strong>.</li>
<li><code>Target ABI</code> is fine as <code>lp64d</code>.</li>
<li>Go back to the main menu and head over to the <code>Toolchain</code> section.</li>
<li>C library should be <code>uClibc-ng</code>.</li>
<li>Select <code>Compile and install uClibc utilities</code>.</li>
<li>Save and exit.</li>
</ol>
<p>You should be all set up to build the toolchain. From the Buildroot directory, run the following:</p>
<pre is:raw="" tabindex="0"><code><span><span>make sdk</span></span></code></pre>
<p>This could take a while. Once it’s done, you should have your new toolchain under <code>output/host/bin/</code> within the Buildroot directory. Go ahead and <code>ls</code> that directory and you’ll see a bunch of stuff built in there, including your well known GCC tools. All we’ll be using is <code>riscv64-buildroot-linux-uclibc-gcc</code>, so make sure you hold on to that one.</p>
<h3 id="building-bflt-files">Building bFLT files</h3>
<p>bFLT files are, per my understanding, derived from the ELF files, actually. You use your GCC to get an ELF file, and then you use a tool called <code>elf2flt</code> to construct the bFLT file.</p>
<p>I have tried building <code>elf2flt</code> from source and using it, but I had a hard time getting the build to work in the first place. After many attempts, I gave up, but I was happy to realize that Buildroot provides <code>elf2flt</code>. In fact, when you <code>ls</code>‘ed the directory for your toolchain just a minute ago, you could see something like <code>riscv64-buildroot-linux-uclibc-elf2flt</code> in that directory. Once I realized this, I thought it was easy and I could just build a regular RISC-V ELF and convert it to bFLT with this tool — turns out it’s not that straightforward.</p>
<p>I lost hope I’d ever get this done, and then I tried having Buildroot build the whole <code>initramfs</code> for me. I was skeptical it would run properly with the MMU-less Linux, but it did, so that means there really is a way to do this properly and quickly. My hack was to look at the Buildroot logs for how it built some of the packages an observe what are the GCC flags it uses.</p>
<p>It turns out that I was missing the linker flag <code>-Wl,-elf2flt=-r</code> to make things work. This makes sure that the <code>elf2flt</code> is involved during the linking process and in the end, I got my bFLT file. I never had to run <code>elf2flt</code> myself. We’ll see a concrete detailed example later as we build a sample application.</p>
<p>First, let’s build a MMU-less kernel that we have something to run against.</p>
<h2 id="building-an-extremely-tiny-linux-kernel">Building an extremely tiny Linux kernel</h2>
<p>As this is an exercise in minimalism, we’ll build an extremely minimal Linux kernel. It will offer little more than a basic filesystem and running binaries on top of the kernel.</p>
<p><em>At this point, I assume you know how to build a Linux kernel in general. If you don’t, please look at the <a href="https://popovicu.com/posts/making-a-micro-linux-distro/">micro Linux distro guide</a> and familiarize yourself with the basic concepts before proceeding.</em></p>
<p>For simplicity, I’ll simply get the <code>tar</code> file from <code>kernel.org</code> for stable version <code>6.5.5</code>, though I believe if you see something newer as the latest, you can just go for it and nothing should change. Let’s download and unpack that.</p>
<p><strong>Here and below: my <code>CROSS_COMPILE</code> prefix may be different from what you need on your machine to invoke the build tools.</strong></p>
<p>Let’s begin by setting up a super minimal Linux configuration:</p>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- tinyconfig</span></span></code></pre>
<p>This <code>tinyconfig</code> really strips down the build to the most basic things. It doesn’t even have <code>printk</code> support, so you won’t be getting a whole lot of output by booting this. More accurately, it doesn’t even have the TTY support, so you really can’t even output anything through the standard methods like <code>printk</code>, and you wouldn’t be able to display something through UART or otherwise via standard output in the user space.</p>
<p>Let’s, however, build this (I run <code>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- -j16</code>) and see what we get out of it. I’m getting the following:</p>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 943 K.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 559 K.</li>
</ul>
<p>This is good to know and we’ll use it as the baseline as we make the changes. Let’s do the following and make some changes to our build:</p>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- menuconfig</span></span></code></pre>
<p>The most important change we want to make is we want to disable the MMU facilities in the kernel. I’ve seen guides that say you can just drop a config line into the <code>.config</code> file because they don’t see the option to disable the MMU from <code>menuconfig</code>, but I would advise against it. I was able to get the option to appear, and I’m not sure if what they’re expericing is architecture specific, but for RISC-V, I was definitely able to get the option to disable the MMU stuff.</p>
<ol>
<li><code>CONFIG_NONPORTABLE</code> should be set to <code>y</code>. We are building for a specific machine and we want to enable non-portable builds as we know exactly what are the memory addresses we’d be deploying to.</li>
<li><code>CONFIG_MMU</code>: <code>n</code>. It should be obvious what this does. Note, we were unable to flip this to <code>n</code> before doing the step 1; we should be all good now.</li>
<li><code>PHYS_RAM_BASE_FIXED</code>: <code>y</code>. This means we’ll be deploying the kernel to a specific address in the memory.</li>
<li>Once you flip that, you can set <code>CONFIG_PHYS_RAM_BASE</code> to <code>0x80000000</code>. This makes perfect sense for us as this is where our execution will begin on the QEMU virtual machine. If you want to know more about it, please read the <a href="https://popovicu.com/posts/bare-metal-programming-risc-v/">bare metal guide</a> and the <a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process/">SBI and boot process guide</a>. Those guides are lengthy, but they will enable you to fully understand what’s going on. That said, for the latter guide, please note that <strong>we are not</strong> using OpenSBI to boot here. We’re running a very light Linux, and we are not relying on the SBI infrastructure. This is much closer to bare metal programming than running Linux as you’re used to it.</li>
</ol>
<p>Let’s build this really quick and see if there are any changes. Save and exit, and run:</p>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- -j16</span></span></code></pre>
<p>Let’s weigh our kernel again:</p>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 789 K.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 472 K.</li>
</ul>
<p>Wow, it’s significantly lighter! However, even though we disabled the MMU smartness from it, we still haven’t enabled any features and again, the <code>tinyconfig</code> is so tiny that it barely does anything. Let’s flip some more configurations:</p>
<ol>
<li><code>CONFIG_BLK_DEV_INITRD</code>: <code>y</code>. We need an <code>initramfs</code> image to be able to run our <code>init</code> process and start off some magic in the user space. Flip that to <code>y</code>.</li>
<li>The above will by default enable various compression support for the <code>initramfs</code>, but you can go ahead and disable them all. I will not list out all of them one by one (a single example is <code>CONFIG_RD_GZIP</code>), they should expand in <code>menuconfig</code> as <code>y</code> right under the option for enabling <code>initramfs</code>. You can flip them all to <code>n</code>, we don’t want to beef up our kernel image with compression algorithms now.</li>
<li><code>CONFIG_BINFMT_FLAT</code>: <code>y</code>. We need to add support for bFLT binaries. If you look at the same menu, there’s no mention of ELF: as soon as you disabled the MMU support, you lost the ELF binary support as well. We already knew this, so it’s not an issue, and as promised, we’ll talk about how to build bFLTs below on a concrete example. Let’s save and exit and build again:</li>
</ol>
<pre is:raw="" tabindex="0"><code><span><span>make ARCH=riscv CROSS_COMPILE=riscv64-linux-gnu- -j16</span></span></code></pre>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 789 K.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 476 K.</li>
</ul>
<p>The only difference from the previous step is that the compressed image is slightly thicker, but it’s still tiny!</p>
<p>At this point, we have what we need to run an <code>init</code> process in user space!</p>
<h2 id="building-an-initramfs-image-for-the-tiny-mmu-less-kernel">Building an <code>initramfs</code> image for the tiny MMU-less kernel</h2>
<p>We’ll have a useless <code>init</code> that prints a message to UART and just goes to sleep. Notice an inconsistency? I said we’ll print to UART, but our <code>tinyconfig</code> has no UART drivers, no TTY, nothing. So how could this possibly work? Well, since we’re without an MMU, we can really target any physical address on the system. If you go through the <a href="https://popovicu.com/posts/bare-metal-programming-risc-v/">bare metal guide</a>, you’ll learn that the QEMU system we’ll be using to run this image has an UART device mapped out at <code>0x10000000</code>. We’ll be printing to UART through this address for two reasons:</p>
<ol>
<li>Most importantly, to illustrate that on MMU-less kernel you can access any physical address. This can be both good and bad, probably more bad and not only in terms of stability and being resilient to bugs, but also in terms of security if your system accepts any sort of user input.</li>
<li>We want to achieve extreme minimalism here in terms of the size of the build and see how far we can push the boundaries on how much we can slim the kernel down. Right now, it’s under 800 K, which is pretty cool. Bringing in drivers for TTY, UART, etc. would certaily add some weight to the size of our image.</li>
</ol>
<p>That said, here’s our C program:</p>
<pre is:raw="" tabindex="0"><code><span><span>#include</span><span> </span><span>&lt;string.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;unistd.h&gt;</span></span>
<span></span>
<span><span>volatile</span><span> </span><span>char</span><span> </span><span>*</span><span>UART </span><span>=</span><span> (</span><span>char*</span><span>) </span><span>0x</span><span>10000000</span><span>;</span></span>
<span></span>
<span><span>void</span><span> </span><span>print_to_uart</span><span>(</span><span>char</span><span> </span><span>*</span><span>message</span><span>) {</span></span>
<span><span>  </span><span>for</span><span> (</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>; i </span><span>&lt;</span><span> </span><span>strlen</span><span>(message); i</span><span>++</span><span>) {</span></span>
<span><span>    </span><span>*</span><span>UART </span><span>=</span><span> </span><span>message</span><span>[i];</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>int</span><span> </span><span>main</span><span>() {</span></span>
<span><span>  </span><span>print_to_uart</span><span>(</span><span>"Hello world! Welcome to the Tiny Linux MMU-less kernel!</span><span>\n</span><span>"</span><span>);</span></span>
<span></span>
<span><span>  </span><span>while</span><span> (</span><span>1</span><span>) {</span></span>
<span><span>    </span><span>sleep</span><span>(</span><span>1000</span><span>);</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>return</span><span> </span><span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>Notice that we have an infinite loop: the <code>init</code> process is not supposed to ever really exit or the kernel falls into a panic (not that you would see it without <code>printk</code>, though).</p>
<p>Now is the time to compile this <code>init</code> to a bFLT file. This is where we’ll invoke the <code>uClibc</code> toolchain we had previously built. I run the following on my machine, and you only need to adjust the relevant paths to reproduce:</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/tiny/init$ /tmp/buildroot/buildroot-2023.02.5/output/host/bin/riscv64-buildroot-linux-uclibc-gcc -fPIC -Wl,-elf2flt=-r -Wall -static -o init init.c</span></span></code></pre>
<ul>
<li><code>-fPIC</code> is used to produce <strong>position independent code</strong>. This is crucial for understanding how bFLT binaries work on an MMU-less Linux. Since we’re directly going for the physical addresses, but we don’t know where exactly in memory our binary would be loaded, we can’t depend on any absolute address in our binary. If we did, we risk (and most likely will) hurting the memory of another process or the kernel itself. We simply can’t make any assumptions about the end memory addresses. Therefore, everything needs to be PC-relative in our code. If you don’t know what this means, please look this up online as it’s extremely important. tl;dr is that every memory access must be made with an offset relative to the CPU’s pointer to the current machine instruction, instead of accessing a hardcoded address. In other words, instead of accessing <code>0x1001</code> directly, we access with an offset of <code>1</code> if our program counter is at <code>0x1000</code>. This will still work if the binary loader places us at <code>0x2000</code> instead of <code>0x1000</code>; the former wouldn’t! Again, if you do not understand this concept, please review CPU addressing modes.</li>
<li><code>-Wl,-elf2flt=-r</code> is the magic flag we really needed from the toolchain. This ensures that <code>elf2flt</code> is invoked and that the end binary is able to relocate, meaning the loader can place it somewhere differently in memory and the binary should still work (owing to the <code>-fPIC</code> flag as well).</li>
<li>The rest of the flags should be familiar.</li>
</ul>
<p>This binary weighs in at onl 3.3 K, which is pretty light, especially for a statically linked binary. <code>uClibc</code> delivered on its promise of being light. Quick note here is that <code>elf2flt</code> also dropped a file called <code>init.gdb</code> which is an ELF file that you can use to do your <code>objdump</code> and whatnot with it to debug.</p>
<p>If you run <code>file init</code>, you should see something like this:</p>
<pre is:raw="" tabindex="0"><code><span><span>init: BFLT executable - version 4 ram gotpic</span></span></code></pre>
<p>This is what we needed. Let’s make a file called <code>file_list.txt</code> with a single line saying <code>init</code> and let’s make the <code>initramfs</code> image for this setup.</p>
<pre is:raw="" tabindex="0"><code><span><span>cpio -o -H newc &lt; file_list.txt &gt; initramfs.cpio</span></span></code></pre>
<p>Now that we have the kernel image and the <code>initramfs.cpio</code> file, we can fire this up in QEMU and see what we get.</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/linux/linux-6.5.5$ qemu-system-riscv64 -machine virt -cpu rv64,mmu=false -kernel /tmp/tiny/linux-6.5.5/arch/riscv/boot/Image -bios none -initrd /tmp/tiny/init/initramfs.cpio -nographic</span></span>
<span><span>Hello world! Welcome to the Tiny Linux MMU-less kernel!</span></span></code></pre>
<p>Awesome, we ran userspace code and even depended on a dangerous pointer to do something useful.</p>
<h2 id="slightly-more-complicated-build-verifying-system-calls-and-multiprocessing">Slightly more complicated build: verifying system calls and multiprocessing</h2>
<p>Instead of starting from a <code>tinyconfig</code> and working my way up, this time I start with the typical <code>defconfig</code>. From that point, I disabled a bunch of things like MMU (of course), networking, virtualization, etc. while retaining TTY, UART drivers and other useful goodies. Of course, nothing stops you from beginning with <code>tinyconfig</code> and adding incrementally, I just wanted to save myself some time. This time I ended up with images of these sizes:</p>
<ul>
<li><code>arch/riscv/boot/Image</code> weighs in at 4.1 M.</li>
<li><code>arch/riscv/boot/Image.gz</code> weighs in at 2.1 M.</li>
</ul>
<p>This is all much heavier than previously, but it comes with a bunch of cool features like ability to dump core, UART drivers, filesystem support, etc. The message I’m trying to send here is that kernel is full of amazing drivers and features that you can start taking advantage of by only adjusting your kernel build configuration. I ran the same <code>initramfs</code> image as above, and got much richer output with a lot of debug messages from the kernel:</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/linux/linux-6.5.5$ qemu-system-riscv64 -machine virt -cpu rv64,mmu=false -kernel /tmp/linux/linux-6.5.5/arch/riscv/boot/Image -bios none -initrd /tmp/tiny/init/initramfs.cpio -nographic</span></span></code></pre>
<pre is:raw="" tabindex="0"><code><span><span>[    0.000000] Linux version 6.5.5 (uros@uros-debian-desktop) (riscv64-linux-gnu-gcc (Debian 10.2.1-6) 10.2.1 20210110, GNU ld (GNU Binutils for Debian) 2.35.2) #9 Wed Oct  4 00:07:07 PDT 2023</span></span>
<span><span>[    0.000000] Machine model: riscv-virtio,qemu</span></span>
<span><span>[    0.000000] Zone ranges:</span></span>
<span><span>[    0.000000]   DMA32    [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000]   Normal   empty</span></span>
<span><span>[    0.000000] Movable zone start for each node</span></span>
<span><span>[    0.000000] Early memory node ranges</span></span>
<span><span>[    0.000000]   node   0: [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] Initmem setup node 0 [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] riscv: base ISA extensions acdfim</span></span>
<span><span>[    0.000000] riscv: ELF capabilities acdfim</span></span>
<span><span>[    0.000000] Kernel command line:</span></span>
<span><span>[    0.000000] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)</span></span>
<span><span>[    0.000000] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)</span></span>
<span><span>[    0.000000] Built 1 zonelists, mobility grouping on.  Total pages: 32320</span></span>
<span><span>[    0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off</span></span>
<span><span>[    0.000000] Memory: 124576K/131072K available (2526K kernel code, 684K rwdata, 809K rodata, 141K init, 276K bss, 6496K reserved, 0K cma-reserved)</span></span>
<span><span>[    0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1</span></span>
<span><span>[    0.000000] NR_IRQS: 64, nr_irqs: 64, preallocated irqs: 0</span></span>
<span><span>[    0.000000] riscv-intc: 64 local interrupts mapped</span></span>
<span><span>[    0.000000] plic: plic@c000000: mapped 53 interrupts with 1 handlers for 2 contexts.</span></span>
<span><span>[    0.000000] clint: clint@2000000: timer running at 10000000 Hz</span></span>
<span><span>[    0.000000] clocksource: clint_clocksource: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns</span></span>
<span><span>[    0.000062] sched_clock: 64 bits at 10MHz, resolution 100ns, wraps every 4398046511100ns</span></span>
<span><span>[    0.003318] Console: colour dummy device 80x25</span></span>
<span><span>[    0.003525] printk: console [tty0] enabled</span></span>
<span><span>[    0.006416] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)</span></span>
<span><span>[    0.006531] pid_max: default: 32768 minimum: 301</span></span>
<span><span>[    0.007085] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.007131] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.019370] RCU Tasks Trace: Setting shift to 0 and lim to 1 rcu_task_cb_adjust=1.</span></span>
<span><span>[    0.024447] devtmpfs: initialized</span></span>
<span><span>[    0.028181] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns</span></span>
<span><span>[    0.028380] futex hash table entries: 256 (order: 1, 12288 bytes, linear)</span></span>
<span><span>[    0.045655] clocksource: Switched to clocksource clint_clocksource</span></span>
<span><span>[    0.060880] Unpacking initramfs...</span></span>
<span><span>[    0.064002] workingset: timestamp_bits=62 max_order=15 bucket_order=0</span></span>
<span><span>[    0.066160] io scheduler mq-deadline registered</span></span>
<span><span>[    0.066228] io scheduler kyber registered</span></span>
<span><span>[    0.113049] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled</span></span>
<span><span>[    0.119589] 10000000.uart: ttyS0 at MMIO 0x10000000 (irq = 4, base_baud = 230400) is a 16550A</span></span>
<span><span>[    0.120520] printk: console [ttyS0] enabled</span></span>
<span><span>[    0.134884] goldfish_rtc 101000.rtc: registered as rtc0</span></span>
<span><span>[    0.135476] goldfish_rtc 101000.rtc: setting system clock to 2023-10-04T19:51:49 UTC (1696449109)</span></span>
<span><span>[    0.148278] sysfs: cannot create duplicate filename '/kernel/slab/:a-0000016'</span></span>
<span><span>[    0.148656] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.148979] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.149245] Call Trace:</span></span>
<span><span>[    0.149490] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.150053] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.150297] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.150546] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.150784] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.151040] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.151331] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.151638] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.151937] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.152216] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.152451] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.152736] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.153051] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.153319] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.153728] kobject: kobject_add_internal failed for :a-0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.154345] SLUB: Unable to add boot slab kmalloc-rcl-8 to sysfs</span></span>
<span><span>[    0.156569] sysfs: cannot create duplicate filename '/kernel/slab/:0000016'</span></span>
<span><span>[    0.156885] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.157159] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.157378] Call Trace:</span></span>
<span><span>[    0.157500] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.157809] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.158071] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.158354] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.158620] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.158899] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.159212] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.159518] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.159815] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.160101] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.160399] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.160693] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.161010] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.161278] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.161598] kobject: kobject_add_internal failed for :0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.162289] SLUB: Unable to add boot slab kmalloc-8 to sysfs</span></span>
<span><span>[    0.162761] SLUB: Unable to add boot slab alias ep_head to sysfs</span></span>
<span><span>[    0.163061] SLUB: Unable to add boot slab alias blkdev_ioc to sysfs</span></span>
<span><span>[    0.164939] Legacy PMU implementation is available</span></span>
<span><span>[    0.165494] clk: Disabling unused clocks</span></span>
<span><span>[    0.178717] Freeing unused kernel image (initmem) memory: 140K</span></span>
<span><span>[    0.178974] This architecture does not have kernel memory protection.</span></span>
<span><span>[    0.179296] Run /init as init process</span></span>
<span><span>Hello world! Welcome to the Tiny Linux MMU-less kernel!</span></span></code></pre>
<p>Let’s write an <code>init</code> that starts a bunch of other processes and verifies that multiprocessing keeps working after they’re spawned.</p>
<p><code>init.c</code> below:</p>
<pre is:raw="" tabindex="0"><code><span><span>#include</span><span> </span><span>&lt;stdio.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;stdlib.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;unistd.h&gt;</span></span>
<span></span>
<span><span>int</span><span> </span><span>main</span><span>(</span><span>int</span><span> </span><span>argc</span><span>,</span><span> </span><span>char</span><span> </span><span>*</span><span>argv</span><span>[]</span><span>) {</span></span>
<span><span>  </span><span>printf</span><span>(</span><span>"Hello world</span><span>\n</span><span>"</span><span>);</span></span>
<span></span>
<span><span>  </span><span>for</span><span> (</span><span>int</span><span> i </span><span>=</span><span> </span><span>0</span><span>; i </span><span>&lt;</span><span> </span><span>3</span><span>; i</span><span>++</span><span>) {</span></span>
<span><span>    </span><span>pid_t</span><span> pid;</span></span>
<span></span>
<span><span>    </span><span>if</span><span> ((pid </span><span>=</span><span> </span><span>vfork</span><span>()) </span><span>&lt;</span><span> </span><span>0</span><span>) {</span></span>
<span><span>      </span><span>fprintf</span><span>(stderr, </span><span>"Could not fork a worker at iteration </span><span>%d</span><span>\n</span><span>"</span><span>, i);</span></span>
<span><span>      </span><span>exit</span><span>(</span><span>1</span><span>);</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    </span><span>if</span><span> (pid </span><span>==</span><span> </span><span>0</span><span>) {</span></span>
<span><span>      </span><span>// Child process</span></span>
<span><span>      </span><span>char</span><span> </span><span>*</span><span>args</span><span>[</span><span>2</span><span>] </span><span>=</span><span> { </span><span>"worker"</span><span>, </span><span>NULL</span><span> };</span></span>
<span><span>      </span><span>execv</span><span>(</span><span>"/worker"</span><span>, args);</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>while</span><span> (</span><span>1</span><span>) {</span></span>
<span><span>    </span><span>sleep</span><span>(</span><span>5</span><span>);</span></span>
<span><span>    </span><span>printf</span><span>(</span><span>"Hello from init</span><span>\n</span><span>"</span><span>);</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>return</span><span> </span><span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p><code>worker.c</code> below:</p>
<pre is:raw="" tabindex="0"><code><span><span>#include</span><span> </span><span>&lt;stdio.h&gt;</span></span>
<span><span>#include</span><span> </span><span>&lt;unistd.h&gt;</span></span>
<span></span>
<span><span>int</span><span> </span><span>main</span><span>(</span><span>int</span><span> </span><span>argc</span><span>,</span><span> </span><span>char</span><span> </span><span>*</span><span>argv</span><span>[]</span><span>) {</span></span>
<span><span>  </span><span>while</span><span> (</span><span>1</span><span>) {</span></span>
<span><span>    </span><span>printf</span><span>(</span><span>"Hello from worker!</span><span>\n</span><span>"</span><span>);</span></span>
<span><span>    </span><span>sleep</span><span>(</span><span>3</span><span>);</span></span>
<span><span>  }</span></span>
<span></span>
<span><span>  </span><span>return</span><span> </span><span>0</span><span>;</span></span>
<span><span>}</span></span></code></pre>
<p>We build them the same way as the <code>init</code> we built before and package them into a <code>cpio</code> archive. Running this in QEMU for some time gives the following:</p>
<pre is:raw="" tabindex="0"><code><span><span>uros@uros-debian-desktop:/tmp/linux/linux-6.5.5$ qemu-system-riscv64 -machine virt -cpu rv64,mmu=false -kernel /tmp/linux/linux-6.5.5/arch/riscv/boot/Image -bios none -initrd /tmp/linux/init/initramfs.cpio -nographic</span></span></code></pre>
<pre is:raw="" tabindex="0"><code><span><span>[    0.000000] Linux version 6.5.5 (uros@uros-debian-desktop) (riscv64-linux-gnu-gcc (Debian 10.2.1-6) 10.2.1 20210110, GNU ld (GNU Binutils for Debian) 2.35.2) #9 Wed Oct  4 00:07:07 PDT 2023</span></span>
<span><span>[    0.000000] Machine model: riscv-virtio,qemu</span></span>
<span><span>[    0.000000] Zone ranges:</span></span>
<span><span>[    0.000000]   DMA32    [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000]   Normal   empty</span></span>
<span><span>[    0.000000] Movable zone start for each node</span></span>
<span><span>[    0.000000] Early memory node ranges</span></span>
<span><span>[    0.000000]   node   0: [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] Initmem setup node 0 [mem 0x0000000080000000-0x0000000087ffffff]</span></span>
<span><span>[    0.000000] riscv: base ISA extensions acdfim</span></span>
<span><span>[    0.000000] riscv: ELF capabilities acdfim</span></span>
<span><span>[    0.000000] Kernel command line:</span></span>
<span><span>[    0.000000] Dentry cache hash table entries: 16384 (order: 5, 131072 bytes, linear)</span></span>
<span><span>[    0.000000] Inode-cache hash table entries: 8192 (order: 4, 65536 bytes, linear)</span></span>
<span><span>[    0.000000] Built 1 zonelists, mobility grouping on.  Total pages: 32320</span></span>
<span><span>[    0.000000] mem auto-init: stack:off, heap alloc:off, heap free:off</span></span>
<span><span>[    0.000000] Memory: 124544K/131072K available (2526K kernel code, 684K rwdata, 809K rodata, 141K init, 276K bss, 6528K reserved, 0K cma-reserved)</span></span>
<span><span>[    0.000000] SLUB: HWalign=64, Order=0-3, MinObjects=0, CPUs=1, Nodes=1</span></span>
<span><span>[    0.000000] NR_IRQS: 64, nr_irqs: 64, preallocated irqs: 0</span></span>
<span><span>[    0.000000] riscv-intc: 64 local interrupts mapped</span></span>
<span><span>[    0.000000] plic: plic@c000000: mapped 53 interrupts with 1 handlers for 2 contexts.</span></span>
<span><span>[    0.000000] clint: clint@2000000: timer running at 10000000 Hz</span></span>
<span><span>[    0.000000] clocksource: clint_clocksource: mask: 0xffffffffffffffff max_cycles: 0x24e6a1710, max_idle_ns: 440795202120 ns</span></span>
<span><span>[    0.000059] sched_clock: 64 bits at 10MHz, resolution 100ns, wraps every 4398046511100ns</span></span>
<span><span>[    0.003249] Console: colour dummy device 80x25</span></span>
<span><span>[    0.003442] printk: console [tty0] enabled</span></span>
<span><span>[    0.006336] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)</span></span>
<span><span>[    0.006447] pid_max: default: 32768 minimum: 301</span></span>
<span><span>[    0.007026] Mount-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.007070] Mountpoint-cache hash table entries: 512 (order: 0, 4096 bytes, linear)</span></span>
<span><span>[    0.019398] RCU Tasks Trace: Setting shift to 0 and lim to 1 rcu_task_cb_adjust=1.</span></span>
<span><span>[    0.024599] devtmpfs: initialized</span></span>
<span><span>[    0.028455] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns</span></span>
<span><span>[    0.028661] futex hash table entries: 256 (order: 1, 12288 bytes, linear)</span></span>
<span><span>[    0.046105] clocksource: Switched to clocksource clint_clocksource</span></span>
<span><span>[    0.061575] Unpacking initramfs...</span></span>
<span><span>[    0.064941] workingset: timestamp_bits=62 max_order=15 bucket_order=0</span></span>
<span><span>[    0.066491] io scheduler mq-deadline registered</span></span>
<span><span>[    0.066556] io scheduler kyber registered</span></span>
<span><span>[    0.073683] Freeing initrd memory: 32K</span></span>
<span><span>[    0.114913] Serial: 8250/16550 driver, 4 ports, IRQ sharing disabled</span></span>
<span><span>[    0.121398] 10000000.uart: ttyS0 at MMIO 0x10000000 (irq = 4, base_baud = 230400) is a 16550A</span></span>
<span><span>[    0.122456] printk: console [ttyS0] enabled</span></span>
<span><span>[    0.134615] goldfish_rtc 101000.rtc: registered as rtc0</span></span>
<span><span>[    0.135109] goldfish_rtc 101000.rtc: setting system clock to 2023-10-04T21:01:14 UTC (1696453274)</span></span>
<span><span>[    0.147392] sysfs: cannot create duplicate filename '/kernel/slab/:a-0000016'</span></span>
<span><span>[    0.147670] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.147955] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.148164] Call Trace:</span></span>
<span><span>[    0.148375] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.148861] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.149056] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.149257] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.149435] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.149626] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.149837] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.150048] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.150284] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.150502] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.150695] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.150887] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.151102] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.151291] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.151561] kobject: kobject_add_internal failed for :a-0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.152043] SLUB: Unable to add boot slab kmalloc-rcl-8 to sysfs</span></span>
<span><span>[    0.153186] sysfs: cannot create duplicate filename '/kernel/slab/:0000016'</span></span>
<span><span>[    0.153443] CPU: 0 PID: 1 Comm: swapper Not tainted 6.5.5 #9</span></span>
<span><span>[    0.153632] Hardware name: riscv-virtio,qemu (DT)</span></span>
<span><span>[    0.153778] Call Trace:</span></span>
<span><span>[    0.153873] [&lt;0000000080003230&gt;] dump_backtrace+0x1c/0x24</span></span>
<span><span>[    0.154056] [&lt;000000008026c1ac&gt;] show_stack+0x2c/0x38</span></span>
<span><span>[    0.154247] [&lt;0000000080271822&gt;] dump_stack_lvl+0x20/0x32</span></span>
<span><span>[    0.154440] [&lt;0000000080271848&gt;] dump_stack+0x14/0x1c</span></span>
<span><span>[    0.154614] [&lt;000000008012b4d4&gt;] sysfs_warn_dup+0x52/0x66</span></span>
<span><span>[    0.154816] [&lt;000000008012b590&gt;] sysfs_create_dir_ns+0xa8/0xba</span></span>
<span><span>[    0.155035] [&lt;0000000080252640&gt;] kobject_add_internal+0x90/0x1ca</span></span>
<span><span>[    0.155256] [&lt;0000000080252878&gt;] kobject_init_and_add+0x50/0x84</span></span>
<span><span>[    0.155481] [&lt;00000000800cabe2&gt;] sysfs_slab_add+0x102/0x1d4</span></span>
<span><span>[    0.155691] [&lt;0000000080283388&gt;] slab_sysfs_init+0x8a/0xf6</span></span>
<span><span>[    0.155906] [&lt;000000008027959c&gt;] do_one_initcall+0x64/0x11e</span></span>
<span><span>[    0.156119] [&lt;0000000080279806&gt;] kernel_init_freeable+0x158/0x1b0</span></span>
<span><span>[    0.156342] [&lt;00000000802726a2&gt;] kernel_init+0x1c/0xea</span></span>
<span><span>[    0.156525] [&lt;0000000080001cde&gt;] ret_from_fork+0xa/0x1c</span></span>
<span><span>[    0.156744] kobject: kobject_add_internal failed for :0000016 with -EEXIST, don't try to register things with the same name in the same directory.</span></span>
<span><span>[    0.157236] SLUB: Unable to add boot slab kmalloc-8 to sysfs</span></span>
<span><span>[    0.157663] SLUB: Unable to add boot slab alias ep_head to sysfs</span></span>
<span><span>[    0.157902] SLUB: Unable to add boot slab alias blkdev_ioc to sysfs</span></span>
<span><span>[    0.159238] Legacy PMU implementation is available</span></span>
<span><span>[    0.159650] clk: Disabling unused clocks</span></span>
<span><span>[    0.172328] Freeing unused kernel image (initmem) memory: 140K</span></span>
<span><span>[    0.172645] This architecture does not have kernel memory protection.</span></span>
<span><span>[    0.172948] Run /init as init process</span></span>
<span><span>Hello world</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from init</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from worker!</span></span>
<span><span>Hello from init</span></span></code></pre>
<p>Hopefully this clears up the confusion about whether multiprocessing is possible on a no-MMU kernel build. Additionally, we verified that the system calls work properly.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We managed to build a very light Linux kernel for a system without an MMU. By building a custom <code>uClibc</code> toolchain we also managed to build bFLT binaries to run in the userspace. System calls and multiprocessing worked well and so we have a fully functional system.</p>
<p>We pushed the boundaries of a lightweight deployment through <code>tinyconfig</code>, and ended up running a userspace process that writes to UART by directly writing to the UART device, bypassing the kernel.</p>
<p>If all we want is to multi-task a bit on our device, Linux is likely an overkill, even in a tiny deployment like this. Additionally, if we’re not leveraging any drivers from the kernel code base, it’s probably another indicator we’re going too heavy. I leave it to you to decide if this lightweight Linux deployment makes sense for your usecase or not.</p>
<p>We could use Buildroot to add some of the well known tools to our system, potentially even make something interactive. I’ll stop here, however, as my goal was to bring up the absolutely minimal set up. Please connect with me and let me know if there is a way to make the set up I described above even lighter from the <code>tinyconfig</code>-based one.</p>
<p>I think this finally answers my question that I’ve had for a long time which is: what is the absolutely minimal Linux kernel? Something that runs on a single core, extremely simple, with as little cruft as possible, but that can still process some system calls and provide some sort of a filesystem. If anyone has been looking for this answer as well, I hope I am providing it correctly here.</p>
<p>The way I initially got to this question was I wanted to implement a minimal machine (in simulation or otherwise in FPGA) that can run something useful like some sort of a minimal Linux, and that I can program with at least some standard tooling like GCC. After studying my options, I think RISC-V and Linux are the answer, and the last few guides I have written are the summary of my studies.</p>
<h2 id="github-repo">GitHub repo</h2>
<p>As always, I’ll be posting the code from above to GitHub as well. There won’t be <code>Makefile</code>s due to the need for a custom toolchain, and I’d really like the readers to go through this writeup and understand what’s going on exactly in order to build bFLT libraries. It stumped me for a few days and I hope this helps anyone with the same questions. The repo can be found <a href="https://github.com/popovicu/linux-no-mmu-userspace-example">here</a>.</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make your own pyramid salt crystals (217 pts)]]></title>
            <link>https://crystalverse.com/pyramid-salt-crystals/</link>
            <guid>37821994</guid>
            <pubDate>Mon, 09 Oct 2023 16:21:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crystalverse.com/pyramid-salt-crystals/">https://crystalverse.com/pyramid-salt-crystals/</a>, See on <a href="https://news.ycombinator.com/item?id=37821994">Hacker News</a></p>
<div id="readability-page-1" class="page"><article aria-label="How to Easily Make Your Own Pyramid Salt Crystals" itemref="hero-page-title"><div><p><em>Here’s how you can transform regular table salt into gorgeous pyramid salt crystals at home.</em></p><!-- End Ezoic - gen_under_first_paragraph - under_first_paragraph --><!-- Ezoic - gen_under_first_paragraph - under_first_paragraph --><!-- Ezoic - wp_under_page_title - under_page_title --><!-- End Ezoic - wp_under_page_title - under_page_title -->
<p><img decoding="async" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2.jpg" alt="how to make pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-2-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Regular salt looks like a fine white powder. Sure, it tastes good, but it’s not very interesting to look at.</p>
<p>But what if I told you that you could transform the salt sitting in your kitchen into a work of art?</p><!-- End Ezoic - gen_under_second_paragraph - under_second_paragraph --><!-- Ezoic - gen_under_second_paragraph - under_second_paragraph --><!-- Ezoic - wp_under_first_paragraph - under_first_paragraph --><!-- End Ezoic - wp_under_first_paragraph - under_first_paragraph -->
<p>What if I told you that within a few hours, you could turn white, powdery salt into premium salt crystals shaped like pyramids, flowers and Eiffel towers?</p>
<p>Plus, you don’t need to be good at art. You don’t need to carve those pyramids yourself. Just sit beside the stove, and watch as pyramid salt crystals <em>grow</em> from a dish of salt water right before your eyes.</p>
<p>Let me show you how to do just that.</p><!-- Ezoic - wp_under_second_paragraph - under_second_paragraph --><p><span data-ez-name="crystalverse_com-medrectangle-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=111&amp;impression_group_id=crystalverse_com-medrectangle-4/2023-10-09/1344179903208687&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_under_second_paragraph - under_second_paragraph -->
<p>To my knowledge, it’s the only such guide on the Internet.</p><!-- End Ezoic - gen_mid_content - mid_content --><!-- Ezoic - gen_mid_content - mid_content -->
<p>First, let’s answer a question.</p>
<h3>What is pyramid salt?</h3>
<p>Pyramid salt crystals are made of the same stuff as regular salt. But these crystals look different because they formed in a different way.</p>
<p>In nature, these elusive crystals grow on the surface of quiet, undisturbed pools of salt water that evaporate under the hot sun.</p><!-- Ezoic - wp_mid_content - mid_content --><p><span data-ez-name="crystalverse_com-box-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=112&amp;impression_group_id=crystalverse_com-box-4/2023-10-09/1667659185236566&amp;ad_size=728x90&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_mid_content - mid_content -->
<p>Pyramid salt is more expensive than regular salt, because they taste saltier. Pyramid salt is hollow, and gram for gram, it dissolves in your mouth faster than regular salt. So the saltiness comes at your taste buds all at once.</p>
<p>Plus, they also look awesome.</p>
<p><img decoding="async" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro.jpg" alt="what are pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-intro-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Now, it’s easy to make regular salt crystals at home. Just leave a dish of salt water to evaporate, and you’ll get white powdery salt inside after a few hours.</p><!-- End Ezoic - gen_long_content - long_content --><p><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=912&amp;impression_group_id=crystalverse_com-banner-1/2023-10-09/8617102485236414&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_long_content - long_content -->
<p>However, it’s much harder to make pyramid salt.</p><!-- Ezoic - wp_long_content - long_content --><!-- End Ezoic - wp_long_content - long_content -->
<p>True, you can buy them online. Maldon Sea Salt, for instance, contains crunchy pyramidal salt crystals. They are made by evaporating sea water in large heated pans, mimicking nature.</p>
<p>But that kind of salt is produced industrially, with special equipment and mineral rich seawater.</p>
<p>I’ve always wondered whether you could grow pyramids at home using a hot plate, a glass dish and some regular table salt.</p>
<p>It took over 100 experiments and some sleepless nights, but here are the results.</p><!-- End Ezoic - gen_longer_content - longer_content --><!-- Ezoic - gen_longer_content - longer_content --><!-- Ezoic - wp_longer_content - longer_content --><!-- End Ezoic - wp_longer_content - longer_content -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt.jpg" alt="homemade pyramid salt recipe" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<h3>How to make pyramid salt crystals</h3>
<p>This guide will consist of the following parts:</p><p><span></span><span id="ez-clearholder-medrectangle-3"></span><span data-ez-name="crystalverse_com-medrectangle-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=21&amp;impression_group_id=crystalverse_com-medrectangle-3/2023-10-09/1751908139167726&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><ol>
<li><a href="#materials">Materials</a></li>
<li><a href="#preparing-the-salt-solution">Preparing the salt solution</a></li>
<li><a href="#growing-the-pyramid-salt-crystals">Growing the pyramid salt crystals</a></li>
<li><a href="#harvesting-the-pyramid-salt-crystals">Harvesting the pyramid salt crystals</a></li>
<li><a href="#storing-the-pyramid-salt-crystals">Storing the pyramid salt crystals</a></li>
<li><a href="#tasting-the-pyramid-salt-crystals">Tasting the pyramid salt crystals</a></li>
<li><a href="#types-of-pyramid-salt-crystals">8 types of pyramid salt crystals</a></li>
<li><a href="#some-more-information">Some more information</a></li>
<li><a href="#summary">Summary</a></li>
</ol>
<h3 id="materials">Materials</h3>
<p>To make pyramid salt crystals, you’ll need:</p>
<ul>
<li>A bag of salt</li>
<li>Alum powder</li>
<li>A stove/hot plate</li>
<li>A heat resistant glass dish</li>
<li>A pair of tweezers</li>
<li>A thermometer (optional)</li>
</ul>
<p>I have tried table salt, sea salt, and Himalayan rock salt, and they all work. Sea salt seems to give better results.</p><!-- Ezoic - wp_longest_content - longest_content --><!-- End Ezoic - wp_longest_content - longest_content -->
<p>I’ve used both tap and deionized water. Both are fine.</p>
<p>Also, in this experiment, we’ll be heating some very concentrated salt water. This solution will damage metallic objects, so you can’t use a stainless steel pot.</p>
<p>Instead, I suggest using a heat resistant glass dish. The exact type doesn’t matter. You can use a Pyrex dish or an enameled cast iron pot, which won’t get corroded.</p>
<p>I used a glass casserole.</p><!-- Ezoic - wp_incontent_5 - incontent_5 --><!-- End Ezoic - wp_incontent_5 - incontent_5 -->
<p><a href="https://amzn.to/3RARFBA" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/product-glass-casserole.jpg" alt="" width="400" height="364" srcset="https://crystalverse.com/wp-content/uploads/2022/09/product-glass-casserole.jpg 400w, https://crystalverse.com/wp-content/uploads/2022/09/product-glass-casserole-300x273.jpg 300w" sizes="(max-width: 400px) 100vw, 400px"></a></p>
<h3 id="preparing-the-salt-solution">Preparing the salt solution</h3>
<p>Dissolve 165 g of salt in 500 mL of hot water. If you want to make a bigger batch, just use the same ratio (e.g. 330 g of salt per 1 L of water).</p><!-- End Ezoic - gen_longest_content - longest_content --><!-- Ezoic - gen_longest_content - longest_content -->
<p>Stir the solution gently until all of it dissolves.</p>
<p>Depending on whether the salt is dirty, you can choose to filter it. I filtered mine.</p><!-- Ezoic - wp_incontent_6 - incontent_6 --><p><span data-ez-name="crystalverse_com-square-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=117&amp;impression_group_id=crystalverse_com-square-2/2023-10-09/795413405248367&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_6 - incontent_6 -->
<p>In my setup, I poured my filtered salt solution into a glass casserole sitting on top of a hot plate.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/growing-setup.jpg" alt="growing setup" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/growing-setup.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/growing-setup-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/growing-setup-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p>A hot plate is fine. But don’t put the glass dish directly on the gas stove – the glass might break due to strong, uneven heating, even though it is <em>technically</em>&nbsp;heat resistant. Use a water bath instead.</p>
<h3 id="growing-the-pyramid-salt-crystals">Growing the pyramid salt crystals</h3>
<p>Now, heat the solution to 60-70°C and keep it there throughout the growing process.</p><!-- End Ezoic - gen_incontent_5 - incontent_5 --><!-- Ezoic - gen_incontent_5 - incontent_5 -->
<p>When the solution warms up, convection currents start forming, causing the surface of the solution to swirl around.</p><!-- Ezoic - wp_incontent_7 - incontent_7 --><!-- End Ezoic - wp_incontent_7 - incontent_7 -->
<p>This is bad news, because when our pyramids form, they will also move around the surface of the solution. And they will bump into each other, stick together and fall to the bottom of the dish.</p>
<p>The key is to add an ingredient called potassium alum. Alum calms the surface and helps the pyramids form. It is normally used in baking and pickling. You can find it at the grocery store, or buy it online.</p>
<p><a href="https://amzn.to/3U3mHUq" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/02/product2.jpg" alt="" width="400" height="364" srcset="https://crystalverse.com/wp-content/uploads/2022/02/product2.jpg 400w, https://crystalverse.com/wp-content/uploads/2022/02/product2-300x273.jpg 300w" sizes="(max-width: 400px) 100vw, 400px"></a><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/adding-alum.jpg" alt="adding potassium alum to the solution" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/adding-alum.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/adding-alum-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/adding-alum-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"><em>Add 0.5 g of alum per 500 mL of salt solution. No need to measure – just drop a few pea-sized pieces of alum/two pinches of alum powder into the solution and let it dissolve.</em></p><!-- End Ezoic - gen_incontent_6 - incontent_6 --><!-- Ezoic - gen_incontent_6 - incontent_6 --><p>Several minutes after the alum has dissolved, the surface of the solution should start to settle down. Check out this GIF:</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/drifting.gif" alt="the effect of adding alum to the salt solution" width="600" height="360">I placed a cork on the surface of the solution to visualize the movement on the surface. Before adding alum, the cork swirled around. After adding alum, the cork was completely motionless.</em></p><!-- Ezoic - wp_incontent_8 - incontent_8 --><!-- End Ezoic - wp_incontent_8 - incontent_8 -->
<p>Good. Now you just need to wait.</p>
<p>It takes about 30 minutes for the salt solution to reach saturation, which is the point where salt crystals start to form.</p>
<p>Eventually, small white squares will appear on the surface of the solution.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-forming-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Those are baby pyramid salt crystals.</p>
<p>They’ll keep growing, and within 15 minutes they’ll look like this:</p><!-- End Ezoic - gen_incontent_7 - incontent_7 --><!-- Ezoic - gen_incontent_7 - incontent_7 --><!-- Ezoic - wp_incontent_9 - incontent_9 --><!-- End Ezoic - wp_incontent_9 - incontent_9 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals.jpg" alt="growing pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">The crystals are actually upside down pyramids, suspended on the surface of the solution due to surface tension. It’s the same principle that lets some insects walk on water.</p><p><span></span><span id="ez-clearholder-large-leaderboard-2"></span><span data-ez-name="crystalverse_com-large-leaderboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=36&amp;impression_group_id=crystalverse_com-large-leaderboard-2/2023-10-09/5772296549169062&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>Here’s what they look like from the side:</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2.jpg" alt="growing pyramid salt crystals side view" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/growing-pyramid-salt-crystals-2-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">As the pyramid salt crystals get heavier, they sink lower into the solution. But evaporation on the surface causes the base of the pyramids to grow outwards, widening it and forming a staircase pattern in the process.</p>
<p>Super cool.</p>
<p>Here’s a time lapse of the growing process over 1 hour:</p><!-- Ezoic - wp_incontent_10 - incontent_10 --><p><span data-ez-name="crystalverse_com-portrait-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=121&amp;impression_group_id=crystalverse_com-portrait-1/2023-10-09/3006809575214744&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_10 - incontent_10 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-growth-timelapse.gif" alt="growing pyramid salt crystals timelapse" width="1000" height="563">As the pyramids get larger, they risk bumping into their neighbors.</p><p><span></span><span id="ez-clearholder-leader-1"></span><span data-ez-name="crystalverse_com-leader-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=37&amp;impression_group_id=crystalverse_com-leader-1/2023-10-09/1041402029238281&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>Usually, it isn’t a big problem – unless your solution is too hot. If you heat it beyond 80°C, the pyramids quickly join together to form a layer of crust.</p><!-- End Ezoic - gen_incontent_8 - incontent_8 --><p><span data-ez-name="crystalverse_com-leader-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=918&amp;impression_group_id=crystalverse_com-leader-4/2023-10-09/2721672241229637&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_8 - incontent_8 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/salt-crust.jpg" alt="salt crust" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/salt-crust.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/salt-crust-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/salt-crust-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">But even at 60°C, you shouldn’t leave them there, because they might get too heavy and fall to the bottom to the dish.</p>
<p>So it’s time to harvest the pyramids.</p>
<h3 id="harvesting-the-pyramid-salt-crystals">Harvesting the pyramid salt crystals</h3>
<p>Using a pair of tweezers, carefully remove the pyramid that you want, and place it on a piece of tissue paper. The paper will soak up excess salt solution.</p><!-- Ezoic - wp_incontent_11 - incontent_11 --><p><span data-ez-name="crystalverse_com-netboard-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=122&amp;impression_group_id=crystalverse_com-netboard-1/2023-10-09/7495419673188588&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_11 - incontent_11 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals.jpg" alt="harvesting salt pyramids" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/harvesting-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Before you remove the second pyramid, dip the tweezers in a cup of water. This step ensures that there are no powdery salt grains sticking to your tweezers – which will cause thousands of tiny crystals to form in the dish.</p><p><span></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=700&amp;impression_group_id=crystalverse_com-large-mobile-banner-2/2023-10-09/6206741729208347&amp;ad_size=580x400&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>Then, dry the tweezers with a tissue, and remove your second pyramid. Rinse and repeat.</p>
<p>Instead of using tweezers, you can also use a sieve to scoop up those pyramids. Remember to dip the sieve in water after every run.</p><!-- End Ezoic - gen_incontent_9 - incontent_9 --><!-- Ezoic - gen_incontent_9 - incontent_9 -->
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/nucleation.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/nucleation.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/nucleation-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/nucleation-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Wash your tweezers after every run to prevent powdery salt grains from forming.</em></p>
<p>You can keep doing this until the salt water starts to dry out. By this time, you should have quite a few pyramids.</p><!-- Ezoic - wp_incontent_12 - incontent_12 --><p><span data-ez-name="crystalverse_com-small-square-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=123&amp;impression_group_id=crystalverse_com-small-square-2/2023-10-09/3989411035204644&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_12 - incontent_12 -->
<p>And that’s it!</p>
<p>You’ve just made the fabled pyramid salt, also known as <em>fleur de sel</em>, flower of salt, at home.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid.jpg" alt="a large salt pyramid i grew" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/salt-pyramid-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">If you want to make more pyramids, just add some water to the dish and wait for all the salt to re-dissolve. Then repeat the process. This time, you don’t need to add alum.</p><p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/redissolving.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/redissolving.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/redissolving-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/redissolving-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Re-dissolving the salt to make more pyramids.</em></p>
<h3 id="storing-the-pyramid-salt-crystals">Storing the pyramid salt crystals</h3>
<p>Just store them like regular salt.</p><!-- Ezoic - wp_incontent_13 - incontent_13 --><!-- End Ezoic - wp_incontent_13 - incontent_13 -->
<p>If you live somewhere humid, the crystals will absorb moisture from the air and get slightly wet. This will cause part of the pyramid’s base to dissolve.</p><!-- End Ezoic - gen_incontent_10 - incontent_10 --><!-- Ezoic - gen_incontent_10 - incontent_10 -->
<p>It’s no big deal, but if you want to prevent this, store the pyramid salt crystals with a desiccant.</p>
<h3 id="tasting-the-pyramid-salt-crystals">Tasting the pyramid salt crystals</h3>
<p>What do you mean?</p>
<p>Of course I’ve licked the pyramids.</p>
<p>They taste a bit saltier than regular salt. And crunchier.</p><!-- Ezoic - wp_incontent_14 - incontent_14 --><p><span data-ez-name="crystalverse_com-portrait-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=125&amp;impression_group_id=crystalverse_com-portrait-2/2023-10-09/1700991509187471&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_14 - incontent_14 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/flaky-pyramid-salt-1-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">You might also wonder if the alum added to the solution changes the taste of the salt, or if it’s unhealthy.</p>
<p>First, we added an extremely small amount of alum to the salt solution. So the pyramids taste like pure salt.</p>
<p>And since potassium alum is used in baking powder and considered safe by the FDA, it’s alright to bite a pyramid or two.</p>
<p>However, I would discourage you from eating pyramid salt grown with this method regularly. I’m no dietician, and it’s best to look for an expert before adding something new to your diet.</p><!-- End Ezoic - gen_incontent_11 - incontent_11 --><!-- Ezoic - gen_incontent_11 - incontent_11 -->
<h3 id="types-of-pyramid-salt-crystals">8 types of pyramid salt crystals</h3>
<p>At the start, I promised you’d see all sorts of pyramid salt crystals, some narrow, others wide. I told tales of Mayan pyramids, flowers and Eiffel Towers.</p><!-- Ezoic - wp_incontent_15 - incontent_15 --><!-- End Ezoic - wp_incontent_15 - incontent_15 -->
<p>Below you will find pictures of 8 different types of pyramid salt crystals and how I grew them.</p>
<h4>1. Regular pyramids</h4>
<p>Regular pyramids are the most common type of salt crystal. They form from a solution heated to 60-70°C at low to medium humidity.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals.jpg" alt="regular pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/regular-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">They look like the typical right pyramid, with a square base, and straight edges that meet at the top. The edges have small crystals on them.</p>
<p>Remember, pyramids form upside down – hence, they grow from the top to the bottom. Since salt crystals get larger the longer they stay in the solution, the crystals near the top are bigger than the ones at the bottom.</p><!-- End Ezoic - gen_incontent_12 - incontent_12 --><!-- Ezoic - gen_incontent_12 - incontent_12 -->
<h4>2. Thick pyramids</h4>
<p>Now, regular pyramids are thin and fragile. But if they drop into the solution and are left there, more crystals will deposit on their surface, thickening the faces of the pyramid.</p><!-- Ezoic - wp_incontent_16 - incontent_16 --><!-- End Ezoic - wp_incontent_16 - incontent_16 -->
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals.jpg" alt="thick pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/thick-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Compare the regular pyramid, grown on the surface of the solution, vs the pyramid that fell to the bottom of the dish and left to thicken as more crystals formed on its surface.</em></p><p><span></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=702&amp;impression_group_id=crystalverse_com-large-mobile-banner-1/2023-10-09/8227365365215580&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>These “thick” pyramids might look less elegant, but they are also less fragile.</p>
<h4>3. Two sided pyramids</h4>
<p>Once, I tried to pick up a pyramid with my tweezers, but by accident, it fell back into the solution. Instead of sinking, it continued to float – but with the tip of the pyramid facing up, and the base facing down.</p>
<p>I let it grow for another 15 minutes, and the pyramid turned into this magnificent hourglass shaped crystal:</p><!-- End Ezoic - gen_incontent_13 - incontent_13 --><p><span data-ez-name="crystalverse_com-square-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=923&amp;impression_group_id=crystalverse_com-square-1/2023-10-09/6230693317183869&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_13 - incontent_13 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal.jpg" alt="a pyramid salt crystal shaped like an hourglass" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/two-sided-pyramid-salt-crystal-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<h4>4. Narrow pyramids</h4>
<p>Pyramid growth is a balancing act between gravity and how fast the base of the pyramid can widen. Sometimes, the base of the pyramid grows very slowly, while gravity keeps pulling it downwards.</p><!-- Ezoic - wp_incontent_17 - incontent_17 --><!-- End Ezoic - wp_incontent_17 - incontent_17 -->
<p>As a result, we get narrow salt crystals that look less like pyramids and more like Eiffel towers, or chess pieces, if you will.</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals.jpg" alt="narrow pyramid salt crystals shaped like chess pieces" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/narrow-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Salty chess. When you capture a piece, you eat it.</em></p>
<p>These narrow pyramids like to form when the temperature of the solution is below 60°C.</p>
<p>My theory is that when the temperature is low, less evaporation occurs, and so less crystal growth occurs at the surface. Thus, the pyramids sink faster than they widen – hence the narrower shape.</p><!-- Ezoic - wp_incontent_18 - incontent_18 --><p><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=129&amp;impression_group_id=crystalverse_com-vertical-banner-1/2023-10-09/2871160131219933&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_18 - incontent_18 -->
<p>If you increase the temperature while these salt crystals are forming, the base will get wider, curving outwards. The resulting pyramids look like trumpets.</p><!-- End Ezoic - gen_incontent_14 - incontent_14 --><!-- Ezoic - gen_incontent_14 - incontent_14 -->
<h4>5. Big headed pyramids</h4>
<p>If you look closely at the pyramids, you’ll find that each pyramid has a “head” at its tip. Sometimes the head is small, sometimes it is big.</p>
<p>Below are some big headed pyramids.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals.jpg" alt="big headed pyramid salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">The so-called “head” is actually a large salt cube. When it starts forming, it looks like a tiny square on the surface of the solution.</p>
<p>Then, as the crystal gets heavier, it sinks a little into the solution. As it sinks, layers of salt crystals grow on the face of the cube facing the sky, forming a pyramid. But the other sides of the crystal cube (that are underwater) also keep growing. Eventually, they form the “head” of the pyramid.</p><!-- Ezoic - wp_incontent_19 - incontent_19 --><!-- End Ezoic - wp_incontent_19 - incontent_19 -->
<p>Sometimes, the head is tiny. Sometimes the head is much larger, and you can see interesting patterns on the hopper crystal.</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers.jpg" alt="flowers made of salt" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-flowers-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">If you place the pyramids upside down, they look remarkably like flowers. You might be able to serve some ketchup in them.</em></p><!-- End Ezoic - gen_incontent_15 - incontent_15 --><p><span data-ez-name="crystalverse_com-sky-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=925&amp;impression_group_id=crystalverse_com-sky-3/2023-10-09/2581966311209185&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_15 - incontent_15 -->
<p>Despite having spent an unhealthy amount of time on this project at home, I confess that there was one secret that escaped me: how to control the size of the heads.</p>
<p>At first, I thought it was due to different types of salt. So I tried comparing two types of salt – sea salt and rock salt. I found that the batch with sea salt gave big heads and rock salt gave small heads.</p>
<p>I thought I had my answer.</p><!-- Ezoic - wp_incontent_20 - incontent_20 --><p><span data-ez-name="crystalverse_com-narrow-sky-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=131&amp;impression_group_id=crystalverse_com-narrow-sky-2/2023-10-09/7652709461229354&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_20 - incontent_20 -->
<p>After a few days, out of curiosity, I ran the two experiments again, side by side. This time, it was the opposite – sea salt gave small heads and rock salt gave big heads.</p>
<p>I was equal parts surprised and confused.</p>
<p>And we haven’t even gotten to the scary part yet.</p>
<p>After 15 minutes, the heads on the sea salt pyramids started growing bigger, until they were just as big as the heads of the rock salt pyramids!</p>
<p>Such was my hunt for the reason behind different head sizes. I tried changing the temperature and the type of container. I tried using deionized water. I even tried adding impurities such as vinegar and baking soda to the solution.</p><!-- End Ezoic - gen_incontent_16 - incontent_16 --><p><span data-ez-name="crystalverse_com-square-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=926&amp;impression_group_id=crystalverse_com-square-3/2023-10-09/5737811381184322&amp;ad_size=728x90&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_16 - incontent_16 --><!-- Ezoic - wp_incontent_21 - incontent_21 --><!-- End Ezoic - wp_incontent_21 - incontent_21 -->
<p>But my efforts were mostly frustrating and fruitless. It was full of contradictions. I was as salty as the saturated salt solution and my mood as sour as the vinegar I added to it.</p>
<p><em><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-1-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2.jpg" alt="" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/big-headed-pyramid-formation-2-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Top and side view of big headed pyramid salt crystals.</em></p>
<p>My last hope was the effect of humidity. But I didn’t have a device to measure humidity. So I had to rely on a crude technique – obsessively checking the weather station reports. Based on the several experiments I did, there seemed to be some relationship:</p>
<p><strong>The lower the humidity, the smaller the pyramid head.</strong></p>
<p>My tests were not conclusive, as occasionally large heads still formed on hot sunny days. But generally, drier days yielded smaller heads.</p><!-- Ezoic - wp_incontent_22 - incontent_22 --><p><span data-ez-name="crystalverse_com-small-rectangle-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=133&amp;impression_group_id=crystalverse_com-small-rectangle-2/2023-10-09/3304111503200098&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_22 - incontent_22 -->
<p>I’ll discuss this later. For now, let’s look at 3 other types of pyramids.</p>
<p>They were grown from the exact same salt solution – in which I had added a teaspoon of Epsom salt.</p><!-- End Ezoic - gen_incontent_17 - incontent_17 --><p><span data-ez-name="crystalverse_com-leader-3"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=927&amp;impression_group_id=crystalverse_com-leader-3/2023-10-09/5545226655187678&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_17 - incontent_17 -->
<h4>6. Monster pyramids</h4>
<p>The first pyramid salt crystal that grew from this solution was an absolute beast. The humongous head was covered with all sorts of intricate formations that reminded me of bismuth crystals.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal.jpg" alt="a massive salt hopper crystal" width="1000" height="1333" srcset="https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal-225x300.jpg 225w, https://crystalverse.com/wp-content/uploads/2022/09/salt-hopper-crystal-768x1024.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">After half an hour, I extracted this crystal with tweezers and dried it. Then, from the same solution, a different type of pyramid started forming:</p>
<h4>7. Slanted pyramids</h4>
<p>At first, it looked like a regular, small-headed pyramid. Then, it tilted over to one side and continued growing, until it looked like this:</p><!-- Ezoic - wp_incontent_23 - incontent_23 --><p><span data-ez-name="crystalverse_com-netboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=134&amp;impression_group_id=crystalverse_com-netboard-2/2023-10-09/4274464571177895&amp;ad_size=580x400&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_23 - incontent_23 -->
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal.jpg" alt="a large slanted pyramid salt crystal" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/slanted-pyramid-salt-crystal-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<h4>8. Ultra wide pyramids</h4>
<p>After removing the slanted crystal, more pyramids continued to form. These were regular symmetrical pyramids with small heads. But they were also very flat – the flattest I have ever seen:</p><p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals.jpg" alt="ultra wide pyramidal salt crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/ultra-wide-pyramid-salt-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">3 different types of salt crystals forming from the same solution, barely an hour apart.</p><!-- End Ezoic - gen_incontent_18 - incontent_18 --><!-- Ezoic - gen_incontent_18 - incontent_18 --><p><span></span><span id="ez-clearholder-mobile-leaderboard-2"></span><span data-ez-name="crystalverse_com-mobile-leaderboard-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=704&amp;impression_group_id=crystalverse_com-mobile-leaderboard-2/2023-10-09/5619997869225204&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><p>I was reminded once again that the art of crystal growing is both mysterious and wonderful.</p>
<h3><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals.jpg" alt="pyramid salt hopper crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-hopper-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></h3>
<h3 id="some-more-information">Some more information</h3>
<p>Before writing this article, I have looked online for guides on how to grow pyramidal salt at home, and found nothing.</p><!-- Ezoic - wp_incontent_24 - incontent_24 --><p><span data-ez-name="crystalverse_com-leader-2"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=135&amp;impression_group_id=crystalverse_com-leader-2/2023-10-09/5777086383174099&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_24 - incontent_24 -->
<p>But I did find <a href="https://www.jstage.jst.go.jp/article/swsj/73/2/73_81/_pdf" target="_blank" rel="noopener">a study</a> published in the World Salt Symposium where researchers successfully grew pyramid salt from waste salt water in large, steel crystallizers.</p>
<p>They claim that calcium ions in seawater help pyramids form by allowing more salt to dissolve in water. I tried adding various amounts of calcium chloride to my solutions, and it had no noticeable effect.</p>
<p>They also claim that a pH of 4, and a temperature of 55-65°C was good for pyramid growth. My experiments agree.</p><!-- End Ezoic - gen_incontent_19 - incontent_19 --><p><span data-ez-name="crystalverse_com-sky-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=929&amp;impression_group_id=crystalverse_com-sky-4/2023-10-09/5371588283228848&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_19 - incontent_19 -->
<p>Since alum is mildly acidic, dissolving some alum in water would indeed yield a pH of around 4. But I have tried using other acids like vinegar and cream of tartar. Neither yielded pyramids. I suspect it has something to do with aluminum ions, because replacing potassium alum with aluminum sulfate worked.</p>
<p>Finally, according to the authors, sulfate ions were bad for pyramid growth because they encouraged hopper cubes (we know them as “heads”) to form. After removing the sulfates, the researchers managed to grow nice regular pyramids.</p><!-- Ezoic - wp_incontent_25 - incontent_25 --><!-- End Ezoic - wp_incontent_25 - incontent_25 -->
<p>I knew that sulfates were not the only factor that affects head size, because in my experiments, the same solution could form both big and small heads.</p>
<p>Nevertheless, I decided to try this hypothesis. I had no easy way to <em>remove</em> the sulfates, but I could <em>add</em> Epsom salt (magnesium sulfate) to my solutions.</p>
<p>You have seen the results in the previous section. The same solution formed monster pyramids, slanted pyramids and ultra wide pyramids, 1 hour apart. Maybe magnesium sulfate indeed makes the heads bigger, but then, it must be quickly used up, causing subsequent pyramids to have very small heads. But it’s hardly conclusive.</p><!-- End Ezoic - gen_incontent_20 - incontent_20 --><!-- Ezoic - gen_incontent_20 - incontent_20 -->
<p>What do you think?</p>
<p>How do you control head size? Whether you’re a science loving kid or a research chemist, I leave it to you.</p><!-- Ezoic - wp_incontent_26 - incontent_26 --><p><span data-ez-name="crystalverse_com-small-rectangle-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=137&amp;impression_group_id=crystalverse_com-small-rectangle-1/2023-10-09/218855441170946&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_26 - incontent_26 -->
<h3 id="summary">Summary</h3>
<p>That’s all for now. I have been trying to grow pyramid salt crystals for a very long time, and I’m glad to share what I’ve learnt with you. Hopefully you found the guide useful.</p>
<p><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4.jpg" alt="growing salt pyramids at home" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/pyramid-salt-crystals-4-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px">Here’s a super short summary of what we’ve covered.</p><p>To grow pyramid salt crystals, you’ll need:</p>
<ul>
<li>A bag of salt</li>
<li><a href="https://amzn.to/3U3mHUq" target="_blank" rel="noopener">Alum powder</a></li>
<li><a href="https://amzn.to/3QNa90B" target="_blank" rel="noopener">A stove/hot plate</a></li>
<li><a href="https://amzn.to/3RARFBA" target="_blank" rel="noopener">A heat resistant glass dish</a></li>
<li>A pair of tweezers</li>
<li>A thermometer (optional)</li>
</ul>
<ol>
<li>Dissolve 165 g salt per 500 mL of water.</li>
<li>Heat the solution to 60°C.</li>
<li>Add 0.5 g alum per 500 mL of solution.</li>
<li>Wait for pyramids to form.</li>
<li>Remove the pyramids with tweezers.</li>
<li>Dry and store them with a desiccant.</li>
<li>Enjoy your pyramid salt.</li>
</ol>
<p>***</p>
<p>Thank you for reading.</p><!-- Ezoic - wp_incontent_27 - incontent_27 --><p><span data-ez-name="crystalverse_com-square-4"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=138&amp;impression_group_id=crystalverse_com-square-4/2023-10-09/8658461997180016&amp;ad_size=250x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_27 - incontent_27 -->
<p>Maybe you found a new hobby today. Maybe you’ll find a few hours of joy with your kids. Or maybe it simply put a small smile on your face.</p>
<p>I grow crystals because it makes me happy, and I hope it made you happy too.</p>
<p>If you want to start crystal growing, I also recommend <a href="https://crystalverse.com/grow-alum-crystals-at-home/">making alum crystals</a>. They are large, transparent and easy to grow.</p><!-- End Ezoic - gen_incontent_21 - incontent_21 --><p><span data-ez-name="crystalverse_com-narrow-sky-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=931&amp;impression_group_id=crystalverse_com-narrow-sky-1/2023-10-09/5562498227237401&amp;ad_size=300x250&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- Ezoic - gen_incontent_21 - incontent_21 -->
<p><a href="https://crystalverse.com/grow-alum-crystals-at-home/"><img decoding="async" loading="lazy" src="https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals.jpg" alt="alum crystals" width="1000" height="750" srcset="https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals.jpg 1000w, https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals-300x225.jpg 300w, https://crystalverse.com/wp-content/uploads/2022/09/alum-crystals-768x576.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></a>And if you enjoyed this guide, consider subscribing to <a href="https://crystalverse.com/#newsletter">my newsletter</a>. Let’s keep in touch. I’ll share more crystal growing guides with you when they come out.</p>
<p>As always, happy growing.</p><!-- Ezoic - wp_incontent_28 - incontent_28 --><p><span data-ez-name="crystalverse_com-mobile-leaderboard-1"></span><span><span><img src="https://go.ezodn.com/utilcave_com/ezoicbwa.png" alt="Ezoic" loading="lazy" title="ezoic" name="?pageview_id=6e9708ee-5e09-4301-568d-fa2359664f3f&amp;ad_position_id=139&amp;impression_group_id=crystalverse_com-mobile-leaderboard-1/2023-10-09/5327963983219860&amp;ad_size=468x60&amp;domain_id=327783&amp;url=https://crystalverse.com/pyramid-salt-crystals/"></span></span></p><!-- End Ezoic - wp_incontent_28 - incontent_28 -->
<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://crystalverse.com/pyramid-salt-crystals/"
    dc:identifier="https://crystalverse.com/pyramid-salt-crystals/"
    dc:title="How to Easily Make Your Own Pyramid Salt Crystals"
    trackback:ping="https://crystalverse.com/pyramid-salt-crystals/trackback/" />
</rdf:RDF>-->
</div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DNS record "hn.algolia.com" is gone (254 pts)]]></title>
            <link>https://www.nslookup.io/domains/hn.algolia.com/dns-records/</link>
            <guid>37821821</guid>
            <pubDate>Mon, 09 Oct 2023 16:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nslookup.io/domains/hn.algolia.com/dns-records/">https://www.nslookup.io/domains/hn.algolia.com/dns-records/</a>, See on <a href="https://news.ycombinator.com/item?id=37821821">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>