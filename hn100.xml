<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 30 Dec 2023 05:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Koka: Strongly typed functional-style language with effect types and handlers (111 pts)]]></title>
            <link>https://koka-lang.github.io/koka/doc/index.html</link>
            <guid>38810073</guid>
            <pubDate>Fri, 29 Dec 2023 20:53:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://koka-lang.github.io/koka/doc/index.html">https://koka-lang.github.io/koka/doc/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38810073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>Welcome to Koka – a strongly typed functional-style language with effect types and handlers.
</p>
<p><a href="#install" title="Install">Install <span></span></a>
<a href="https://koka-lang.github.io/koka/doc/book.html" data-linkid="kokabook" target="_top">Get Started</a>
<a href="https://koka-lang.github.io/koka/doc/book.html" data-linkid="kokabook" target="_top">Documentation</a>
<a href="https://github.com/koka-lang/koka" data-linkid="kokarepo" target="_top">Github</a></p>
<div>
<p>Note: Koka v2 is a research language that is currently under development
and not ready for production use. 
Nevertheless, the language is stable and the compiler
implements the full specification. The main things lacking at the moment are 
libraries, package management, and deep IDE integration. 
</p>
<div>
<p>News:
</p>
<ul>
<li>
<p>2023-07-03: Koka v2.4.2 released: add support for <code>fip</code> and <code>fbip</code> keywords described
in “FP<sup>2</sup>: Fully in-Place Functional Programming” 
(ICFP'23) [<a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/05/fbip.pdf">pdf</a>].
Various fixes and performance improvements.
</p></li>
<li>
<p>2021-02-04 (pinned) The&nbsp;<a href="https://www.youtube.com/channel/UCS4FAVeYW_IaZqAbqhlvxlA">Context Free</a> 
youtube channel posted a short and fun&nbsp;<a href="https://www.youtube.com/watch?v=olISecOUX1g&amp;t=959s">video</a>
about effects in Koka (and 12 (!) other languages).
</p></li>
<li>
<p>2021-09-01 (pinned) The ICFP'21 tutorial
“<em>Programming with Effect Handlers and FBIP in Koka</em>” is now available on 
<a href="https://www.youtube.com/watch?v=6OFhD_mHtKA">youtube</a>.
</p></li>
<li>
<p>2022-02-07: Koka v2.4.0 released: improved specialization and <code>int</code> operations, add <code>rbtree-fbip</code> sample,
improve grammar (<code>pub</code> (instead of <code>public</code>, remove private (as everything is private by default now)), 
<code>final ctl</code> (instead of <code>brk</code>), underscores in number literals, etc), rename <code>double</code> to <code>float64</code>, various bug fixes.
</p></li>
<li>
<p>2021-12-27: Koka v2.3.8 released: improved <code>int</code> performance, various bug fixes, update wasm backend, 
initial conan support, fix js backend.
</p></li>
<li>
<p>2021-11-26: Koka v2.3.6 released: 
<code>maybe</code>-like types are already value types, but now also no longer need heap allocation 
if not nested (and <code>[<span>Just</span>(<span>1</span>)]</code> uses the same heap space as <code>[<span>1</span>]</code>),
improved atomic refcounting (by Anton Lorenzen), improved specialization (by Steven Fontanella),
various small fixes, add <code><span>std/os/</span>readline</code>, fix build on freeBSD  
</p></li>
<li>
<p>2021-10-15: Koka v2.3.2 released, with initial wasm support 
(use <code>--target<span>=</span>wasm</code>, and install&nbsp;<a href="https://emscripten.org/docs/getting_started/downloads.html" data-linkid="emscripten">emscripten</a> and&nbsp;<a href="https://wasmtime.dev/" data-linkid="wasmtime">wasmtime</a>), 
improved reuse specialization (by Anton Lorenzen), and various bug fixes.
</p></li>
<li>
<p>2021-09-29: Koka v2.3.1 released, with improved TRMC optimizations, and improved reuse 
(the rbtree benchmark is as fast as C++ now), and 
faster effect operations. Experimental: allow elision of <code><span>-&gt;</span></code> in anonymous
function expressions (e.g. <code>xs<span>.</span>map( fn(x) x + <span>1</span> )</code>) and operation clauses.
Command line options changed a bit with <code>.koka</code> as the standard output directory.  
</p></li>
<li>
<p>2021-09-20: Koka v2.3.0 released, with new 
<a href="https://koka-lang.github.io/koka/doc/book.html#sec-layout">brace elision</a> and if/match
conditions without parenthesis. Updated the javascript backend
using ES6 modules and BigInt. new <code><span>module</span> <span>std/num/int64</span></code>, improved effect operation performance.
</p></li>
<li>
<p>2021-09-05: Koka v2.2.1 released, with initial parallel tasks, the binary-trees benchmark, and
<a href="https://koka-lang.github.io/koka/doc/book.html#sec-layout">brace elision</a>.
</p></li>
<li>
<p>2021-08-26: Koka v2.2.0 released, improved simplification (by Rashika B), cross-module specialization (Steven Fontanella),
and borrowing annotations with improved reuse analysis (Anton Lorenzen).
</p></li>
<li>
<p>2021-08-26: At 12:30 EST was the live Koka tutorial at
<a href="https://icfp21.sigplan.org/details/icfp-2021-tutorials/5/Programming-with-Effect-Handlers-and-FBIP-in-Koka">ICFP'21</a>,
see it on&nbsp;<a href="https://www.youtube.com/watch?v=6OFhD_mHtKA">youtube</a>.
</p></li>
<li>
<p>2021-08-23: “<em>Generalized Evidence Passing for Effect Handlers</em>”, by Ningning Xie and Daan Leijen presented at ICFP'21.
See it on&nbsp;<a href="https://www.youtube.com/watch?v=yAT0qYlD0UM&amp;list=PLyrlk8Xaylp5ed_Yhg2oTdVhrtVohVaoa&amp;index=40">youtube</a>
or read the&nbsp;<a href="https://www.microsoft.com/en-us/research/publication/generalized-evidence-passing-for-effect-handlers/">paper</a>.
</p></li>
<li>
<p>2021-08-22: “<em>First-class Named Effect Handlers</em>”, by Youyou Cong, Ningning Xie, and Daan Leijen presented at HOPE'21.
See it on&nbsp;<a href="https://www.youtube.com/watch?v=3HsI4__8RQM&amp;list=PLyrlk8Xaylp6Q52MwsRZBUSIRL3wOk_k1&amp;index=4">youtube</a>
or read the&nbsp;<a href="https://www.microsoft.com/en-us/research/publication/first-class-named-effect-handlers/">paper</a>.
</p></li>
<li>
<p>2021-06-23: Koka v2.1.9 released, initial cross-module specialization (by Steven Fontanella).
</p></li>
<li>
<p>2021-06-17: Koka v2.1.8 released, initial Apple M1 support.
</p></li>
<li>
<p>The&nbsp;<a href="https://www.microsoft.com/en-us/research/uploads/prod/2020/11/perceus-tr-v1.pdf" data-linkid="perceus">Perceus</a> paper won a distinguished paper award at PLDI'21!
</p></li>
<li>
<p>2021-06-10: Koka v2.1.6 released.
</p></li>
<li>
<p>2021-05-31: Koka v2.1.4 released.
</p></li>
<li>
<p>2021-05-01: Koka v2.1.2 released.
</p></li>
<li>
<p>2021-03-08: Koka v2.1.1 released.
</p></li>
<li>
<p>2021-02-14: Koka v2.0.16 released.
</p></li>
<li>
<p>2020-12-12: Koka v2.0.14 released.
</p></li>
<li>
<p>2020-12-02: Koka v2.0.12 released.
</p></li>
<li>
<p>2020-11-29: Perceus technical report publised (<a href="https://www.microsoft.com/en-us/research/uploads/prod/2020/11/perceus-tr-v1.pdf" data-linkid="perceus">pdf</a>).
</p></li></ul></div></div></div><div>
<!--
On macOS (x64, M1), you can install and upgrade &koka; using Homebrew:

&acopy;
{.copy; data-value:"brew install koka"}

    \(**brew install koka**\)
-->



<p>On Windows (x64), open a <code>cmd</code> prompt and use:
</p>

<pre><code><span><strong>curl -sSL -o %tmp%\install-koka.bat https://github.com/koka-lang/koka/releases/latest/download/install.bat &amp;&amp; %tmp%\install-koka.bat</strong></span></code></pre>
<p>On Linux (x64) and macOS (x64, arm64 (M1/M2)), you can install Koka using:
</p>

<pre><code><span><strong>curl -sSL https://github.com/koka-lang/koka/releases/latest/download/install.sh | sh</strong></span></code></pre>
<p>(If you previously installed Koka on macOS using <code>brew</code>, do an <code>brew uninstall koka</code> first).
On other platforms it is usually easy to build Koka from&nbsp;<a href="https://github.com/koka-lang/koka#build-from-source">source</a> instead.
</p><!--
On macOS (x64, M1), you can install and upgrade &koka; using Homebrew:

&acopy;
{.copy; data-value:"brew install koka"}

    \(**brew install koka**\)

There are also installation packages for various Linux distributions:
Ubuntu/Debian ([x64][ubuntu-x64], [arm64][ubuntu-arm64]),
Alpine ([x64][alpine-x64], [arm64][alpine-arm64]),
Arch ([x64][arch-x64], [arm64][arch-arm64]),
Red Hat ([x64][rhel-x64]), and
openSUSE ([x64][opensuse-x64]).
{text-align:left}
-->



<p>After installation, verify if Koka installed correctly:
</p>
<pre><code><span><strong><code>$ koka</code></strong></span>
 _         _
| |       | |
| | _ ___ | | _ __ _
| |/ / _ \| |/ / _' |  welcome to the koka interactive compiler
|   ( (_) |   ( (_| |  version 2.4.0, Feb  7 2022, libc x64 (gcc)
|_|\_\___/|_|\_\__,_|  type :? for help, and :q to quit

loading: std/core
loading: std/core/types
loading: std/core/hnd
<span><strong><code>&gt;</code></strong></span></code></pre>
<p>Type <code>:q</code> to exit the interactive environment.
</p>
<p>For detailed installation instructions and other platforms see the&nbsp;<a href="https://github.com/koka-lang/koka/releases" data-linkid="releases">releases</a> page.
It is also straightforward to build the compiler&nbsp;<a href="https://github.com/koka-lang/koka/#build-from-source" data-linkid="build">from source</a>.
</p>
<p><a href="https://koka-lang.github.io/koka/doc/book.html#sec-running-the-compiler">Get started with the compiler</a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toyota-owned automaker tampered with safety tests for 30 years (110 pts)]]></title>
            <link>https://www.cnn.com/2023/12/27/business/daihatsu-japan-production-halt-safety-tests-intl-hnk/index.html</link>
            <guid>38809154</guid>
            <pubDate>Fri, 29 Dec 2023 19:27:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2023/12/27/business/daihatsu-japan-production-halt-safety-tests-intl-hnk/index.html">https://www.cnn.com/2023/12/27/business/daihatsu-japan-production-halt-safety-tests-intl-hnk/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=38809154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-image-variation="image" data-breakpoints="{&quot;image--eq-extra-small&quot;: 115, &quot;image--eq-small&quot;: 300}" data-uri="cms.cnn.com/_components/image/instances/clqn97fda000b3b6h5edcjmu0@published" data-name="Daihatsu factory 122623" data-component-name="image" data-observe-resizes="" data-original-ratio="0.602" data-original-height="1806" data-original-width="3000" data-url="https://media.cnn.com/api/v1/images/stellar/prod/231226223730-daihatsu-factory-122623.jpg?c=original" data-editable="lede" data-freewheel-lede="true">
       <picture><source height="383" width="680" media="(max-width: 479px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231226223730-daihatsu-factory-122623.jpg?c=16x9&amp;q=h_383,w_680,c_fill/f_webp" type="image/webp"><source height="653" width="1160" media="(min-width: 480px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231226223730-daihatsu-factory-122623.jpg?c=16x9&amp;q=h_653,w_1160,c_fill/f_webp" type="image/webp"><source height="605" width="1075" media="(min-width: 960px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231226223730-daihatsu-factory-122623.jpg?c=16x9&amp;q=h_605,w_1075,c_fill/f_webp" type="image/webp"><source height="833" width="1480" media="(min-width: 1280px)" srcset="https://media.cnn.com/api/v1/images/stellar/prod/231226223730-daihatsu-factory-122623.jpg?c=16x9&amp;q=h_833,w_1480,c_fill/f_webp" type="image/webp"><img src="https://media.cnn.com/api/v1/images/stellar/prod/231226223730-daihatsu-factory-122623.jpg?c=16x9&amp;q=h_833,w_1480,c_fill" alt="Photo taken from a Kyodo News helicopter on Dec. 25, 2023, shows a Daihatsu Motor Co. factory in Oyamazaki in Kyoto Prefecture, western Japan. The small-car unit of Toyota Motor Corp. said the same day it will suspend production at all domestic factories until at least the end of January due to a safety testing scandal. (Photo by Kyodo News via Getty Images)" onload="this.classList.remove('image__dam-img--loading')" onerror="imageLoadError(this)" height="1806" width="3000"></picture>
    </div><div data-editable="content" itemprop="articleBody" data-reorderable="content">
                    <p><cite>
      <span data-editable="location">Hong Kong/Tokyo</span>
      <span data-editable="source">CNN</span>
        &nbsp;—&nbsp;
    </cite>
</p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn7c3nx006364qfdb6i8r7k@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Daihatsu, the Japanese automaker owned by Toyota, has halted domestic production after admitting it forged the results of safety tests for its vehicles for more than 30 years.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn7e79b00083b6homjw22qi@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The brand, best known for manufacturing small passenger cars, has stopped output at all four of its Japanese factories as of Tuesday, including one at its headquarters in Osaka, a spokesperson told CNN.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqne8xal00083b6hl20vd44t@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The shutdown will last through at least the end of January, affecting roughly 9,000 employees who work in domestic production, according to the representative.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqngg48e000z3b6hq57gpon5@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The move comes as Daihatsu grapples with a deepening safety scandal that Toyota <a href="https://global.toyota/en/newsroom/corporate/40238738.html" target="_blank">says</a> “has shaken the very foundations of the company.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn99fvo000d3b6hdqqk9h21@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Last week, Daihatsu <a href="https://www.daihatsu.com/news/2023/20231220-4.html" target="_blank">announced</a> an independent third-party committee had found evidence of tampering with safety tests on as many as 64 vehicle models, including those sold under the Toyota brand.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqnevsee000g3b6hl6pd7pcl@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      As a result, Daihatsu said it would temporarily suspend all domestic and international vehicle shipments and consult with authorities on how to move forward.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqnezotj000i3b6h2e6qhxzm@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The scandal is another blow to the automaker, which had admitted <a href="https://www.daihatsu.com/news/2023/20230428-4.html" target="_blank">in April</a> to violating standards on crash tests on more than 88,000 cars, mostly sold under the Toyota brand in countries such as Malaysia and Thailand.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqnf8oqk000m3b6h7m3t1mlo@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In that case, “the inside lining of the front seat door was improperly modified” for some checks, while Daihatsu did not comply with regulatory requirements for certain side collision tests, it said in a statement at the time.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqnfgufn000o3b6h608w3itz@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In May, the automaker <a href="https://www.daihatsu.com/news/2023/20230519-6.html" target="_blank">said</a> it had discovered more wrongdoing, revealing that it had submitted incorrect data for collision tests on two hybrid electric vehicles. The company said at the time it had stopped shipping and selling those models.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqnevmy7000e3b6hi0b8nkwx@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The latest probe further threatens the company’s reputation. According to a <a href="https://www.daihatsu.com/news/2023/report_1_E.pdf" target="_blank">report</a> released last Wednesday by the investigative committee, 174 more cases were found of Daihatsu manipulating data, making false statements or improperly tinkering with vehicles to pass safety certification tests.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqnfpms0000q3b6hv5whw7hv@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      The oldest case was traced back to 1989, with a noted increase in the number of cases since 2014, the report said.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn99gwp000f3b6hu4jj46iu@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      Toyota shares dropped 4% in Tokyo last Thursday following the news. The stock has since pared some losses.
  </p>

  


  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn99gwp000g3b6hhh4f2a53@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      In response, the Japanese behemoth has promised to shake up its subsidiary, saying in a&nbsp;<a href="https://global.toyota/en/newsroom/corporate/40238738.html" target="_blank">statement</a> last week that “fundamental reform is needed to revitalize Daihatsu.”
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn99gwp000h3b6haglzd9fd@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “This will be an extremely significant task that cannot be accomplished overnight,” Toyota said, adding that it would require a sweeping review of management, operations, and how the unit was structured.
  </p>

  <p data-uri="cms.cnn.com/_components/paragraph/instances/clqn9e7ol000l3b6hqwgd04s2@published" data-editable="text" data-component-name="paragraph" data-article-gutter="true">
      “We recognize the extreme gravity of the fact that Daihatsu’s neglect of the certification process has shaken the very foundations of the company as an automobile manufacturer,” Toyota added.
  </p>

  <p data-uri="cms.cnn.com/_components/footnote/instances/clqn99pec000j3b6hyb8jt2fk@published" data-editable="text" data-article-gutter="true">
  — CNN’s Emiko Jozuka contributed to this report.
</p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Blot turns a folder into a website (294 pts)]]></title>
            <link>https://blot.im/how</link>
            <guid>38809145</guid>
            <pubDate>Fri, 29 Dec 2023 19:26:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blot.im/how">https://blot.im/how</a>, See on <a href="https://news.ycombinator.com/item?id=38809145">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>

          <h2>Getting started</h2>

<p>Blot turns a folder into a website. Files in the folder be­come posts on your website. </p>

<h2 id="files-and-posts"><a href="https://blot.im/how/posts">Files and posts</a></h2>
 <ul>
     <li><a href="https://blot.im/how/posts/text-and-markdown"><span>Text and Markdown</span>.txt&nbsp;&nbsp;.md&nbsp;&nbsp;.rtf</a></li>
     
     <li><a href="https://blot.im/how/posts/images"><span>Images</span>.png&nbsp;&nbsp;.jpeg&nbsp;&nbsp;.gif</a></li>

     <li><a href="https://blot.im/how/posts/word-documents"><span>Word Documents</span>.docx &nbsp;.odt</a></li>
     
     <li><a href="https://blot.im/how/posts/google-docs"><span>Google Docs</span>.gdoc</a></li>
     
     <li><a href="https://blot.im/how/posts/bookmarks"><span>Bookmarks</span>.webloc&nbsp;&nbsp;.url</a></li>

     <li><a href="https://blot.im/how/posts/html"><span>HTML</span>.html <!-- &nbsp; .htm --></a></li>

     
      <li><a href="https://blot.im/how/posts/org"><span>Org Mode</span>.org</a></li>
     
   </ul>
<h2 id="sync-your-folder"><a href="#sync-your-folder">Sync your folder</a></h2>

<h2 id="prevent-a-file-becoming-a-post"><a href="#prevent-a-file-becoming-a-post">Prevent a file becoming a post</a></h2>
<p> Files and folders whose name starts with an underscore do not become posts or pages. You can link to or <a href="#files-in-your-folder-are-public">embed them in posts</a>.</p>
<table>
  <tbody>
    <tr>
       <td>
        <nobr><span></span> _Banana.jpg</nobr>
      </td>
    </tr>
  <tr>
      <td>
        <nobr><span></span> _Fruits</nobr><span>›</span><nobr><span></span> Banana.jpg</nobr>
      </td>      
    </tr>
  </tbody>
</table>

<h2 id="files-in-your-folder-are-public"><a href="#files-in-your-folder-are-public">Files in your folder are public</a></h2>

<p>The files in your site’s folder are public. This is useful if you want to embed an image, a video or an audio file in a post. You can also use this to share files with your readers. For example, given the folder below, your readers can download <em>Archive.zip</em> if they visit <em>/Files/Archive.zip</em> on your site.</p>

<div>

  

  <p>Name <span></span></p>

  <div>
    <p><span></span> Files</p>
    <p><span></span> Archive.zip</p>
    <p><span></span> index.html</p>
    <p><span></span> Posts</p>
    
    
    
    
    
  </div>
  
  
  
  
  

  
  
  
  
</div>


        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source liability is coming (101 pts)]]></title>
            <link>https://developersalliance.org/open-source-liability-is-coming/</link>
            <guid>38808163</guid>
            <pubDate>Fri, 29 Dec 2023 18:09:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developersalliance.org/open-source-liability-is-coming/">https://developersalliance.org/open-source-liability-is-coming/</a>, See on <a href="https://news.ycombinator.com/item?id=38808163">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p><strong>No good deed goes unpunished (at least in Europe)</strong></p>



<p>Those who know me know I wrote my first code in the early 80s, and though I never made a career of it, I dabbled early-on like all the other geeks. In those days, we all wrote and swapped simple games and trivial tools. At that time, it was one of the main functions of the bulletin boards that would one day spawn the internet. The idea we’d pay for software one day was lurking, but free was more the norm. Bandwidth and storage were what was monetized back then. The idea someone might sue us for a program bug or unexpected crash was not even remotely on our minds.</p>



<p>Ah, to be so innocent and naive again.</p>



<figure><img fetchpriority="high" decoding="async" width="1250" height="718" src="https://developersalliance.org/wp-content/uploads/2023/12/Coding-old.jpg" alt="" srcset="https://developersalliance.org/wp-content/uploads/2023/12/Coding-old.jpg 1250w, https://developersalliance.org/wp-content/uploads/2023/12/Coding-old-300x172.jpg 300w, https://developersalliance.org/wp-content/uploads/2023/12/Coding-old-1024x588.jpg 1024w, https://developersalliance.org/wp-content/uploads/2023/12/Coding-old-768x441.jpg 768w" sizes="(max-width: 1250px) 100vw, 1250px"></figure>







<p>You might be surprised to learn that, as I write, the EU is finalizing rules that will make open-source creators and licensees liable for any user harm their software might cause. The focus for lawmakers is that, like cars and chainsaws, software is complex and can be inherently dangerous. Policymakers believe that consumers are at a disadvantage when things go horribly wrong: how can they prove someone sold them faulty software when they can’t hope to understand how apps work or how they’re created? The solution they’re adopting is to shift the onus to the software and app creators to prove their code didn’t do anything wrong. This will be burdensome but is at least possible if you write and market your own code. But what if you’re just part of a collaborative open source project, give away your app, or if there’s open source code in the product you put on the market? Who gets blamed when open source might be the heart of the problem?</p>



<p><strong>EU policymakers are clear; going forward, someone must be liable for software harm.</strong> Data was lost, customers couldn’t transact, files got garbled, hackers made entries – someone in the software chain must make the user whole. Today you can license-away that liability by putting the onus on the user to accept the risk, since bugs happen and hackers hack. Not your fault, you did your best, and you told the user that upfront. My read of the emerging regime changes that. It forces you to prove your code wasn’t the cause of the harm – “strict liability” in legal circles. Products like cars often get regulated this way. Essentially, the carmaker is at fault when something goes wrong unless they can prove they’re not. It’s a way of shifting societal costs back to the party that profits from the product in question. It allows consumers to be confident that cars are safe, without having an expert reverse engineer them before use or agreeing to accept that the brakes may fail – too bad for you. The carmaker designed and built a complex thing so they should be in the best position to prove they implemented appropriate safeguards.</p>



<p>So, how is open-source software implicated? If a commercial software product causes harm, whoever put the software on the market will soon be strictly liable. You will need to prove that your code wasn’t to blame to escape the costs. But what if you’ve embedded open-source code, used open-source tools, or called open-source APIs? Under the pending rules, you’d be liable for any errors in those sources as well, regardless of whether you directly contributed or not. A license like the one Apache provides won’t help, since state-imposed strict liability isn’t a harm that can be licensed away by private actors. The user must be made whole, and that’s on you. Worse still, how will you in turn identify or sue the collaborator or collaboration that actually wrote the faulty open-source code to recoup your costs? In that case, the license you signed likely insulates your open-source partners from your claims.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/u1UbotkGPqkBI1vLYXUk-N-VVxO8G5bxZ7LxHO-fo8_ddSHqPucKT6pD-qigwr9Gity11btgUM3nPOufuKSpsjo56zvHTS7GO2tOd-bd-5cZJUjkqC_3x89n05KzUOiSVPvfyXTnJ17-TN3iRPe7D2g" alt=""></figure>







<p>Let’s unpack that and put it simply. If a user is harmed by software, the person they paid (targeted ads would count) must compensate them for the harm – unless the software provider can prove their software played no role in the breach/loss/failure/psychological/physical/financial or other harm.<strong> If open source resources are in/called/touched your code, you’re responsible for their performance too.</strong> The open source resource licensed away their liability to you. Oops.</p>



<p>So what will the world look like when this change takes place? First off, despite the fact that many open source tools and resources are more robust and better reviewed than anything you could produce in-house, you’ll need to decide whether you accept the cost if they harm your users. That includes the burden of proving they didn’t, if you think that’s the case. Put another way, it may be hard to prove your code isn’t at fault without reviewing and defending every open source element involved. The open source community will have two choices: leave the licensing regime in place and leave those who use the code to hold the bag, or collaboratively assess and defend projects as claims emerge – even though that kind-of-means you need to assess your licensee’s code to ensure they didn’t just dump their own problem on you. More likely than not the open source community will choose the simpler path, stay the course,&nbsp; and leave others to deal with the new complexities.</p>



<p>The economic impact of this change reduces the value of open source software by placing the burden of bugs and breaches on developers who use and incorporate this code – even if they can prove the open source was at fault. Users must be made whole, open source add-ons have licensed away liability, and so the middle man is on the hook unless they can prove both the open source and closed source code they use is blame free. But that’s not a huge change – just the strict liability burden with open source collaborations getting a free pass. So why am I preaching doom?</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/W20MaDgP8fZ7DcxjlXdZxA_u-5spvKAlCIzNJ3EqZ5HRMhY2ngJlglW0BoQxYhj6ADoey5eKVdF_M3KRPBUZQxzGjGGZ88h7lXI-DaXPtK61BPI4_wRuC3EL2E_eV8cRXRpWcJX8SZat5GSV4RXxyys" alt=""></figure>







<p><strong>What if an open source project is used directly by consumers, and causes them harm?</strong> The public policy is clear: they must be compensated. Does it matter if they signed a license or didn’t pay someone? Their business is bankrupt, their files are in a hacker’s hands, or their own customers are suing them. Someone should be strictly liable. But who?</p>



<p>The EU is grappling with that very question, and it culminates in whether “open source” is exempt from liability in a law designed to protect consumers. So far the answer is “probably not?” Exemption means consumers bear the cost – exactly what the law is trying to change. Perhaps if the open source in question remains an academic or research tool, versus reaching consumers, we’re okay? The proof may come when the first consumer demands compensation, and the courts step in. But lawmakers know enough to realize that much of the open source out there – by definition – belongs to no one, or many someones, or really nobody that can be named and made liable. So waiting on a court case might provide clarity but no compensation and no one to even argue the case. Not the clarity a law is designed to provide.</p>



<p>My prediction, for what it’s worth, is that open source’s days outside academia and hobbyists are numbered. At some point, some government authority will require a single throat-to-choke when open source causes consumer harm. <strong>Someone, or some entity, will need to accept financial and legal responsibility for what the project does in consumer hands. No license can insulate them from that.</strong> Given that existing open source licenses don’t contemplate a private purchase, they’ll need to either wind down, release licensees from taking them commercial, or find a means to restrict consumer use (which may be hard with no one in control). Policy makers simply won’t allow a dangerous animal to wander around unchained, and a lack of owner won’t make the situation better.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["No inventions; no innovations" A History of US Steel (213 pts)]]></title>
            <link>https://www.construction-physics.com/p/no-inventions-no-innovations-a-history</link>
            <guid>38807720</guid>
            <pubDate>Fri, 29 Dec 2023 17:35:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.construction-physics.com/p/no-inventions-no-innovations-a-history">https://www.construction-physics.com/p/no-inventions-no-innovations-a-history</a>, See on <a href="https://news.ycombinator.com/item?id=38807720">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Last week US Steel announced it was </span><a href="https://www.reuters.com/markets/deals/japans-nippon-steel-plans-acquire-us-steel-7-bln-nikkei-2023-12-18/" rel="">being acquired</a><span> by Japanese steel company Nippon Steel. The milestone gives an opportunity to look back at what once was the largest and most important company in the US (and arguably the world), and how it slowly declined. Prior to the acquisition announcement, US Steel had a market cap of around $8 billion, not even enough to put it in the Fortune 500 (it would come in at around #690, slightly below the </span><a href="https://en.wikipedia.org/wiki/Texas_Roadhouse" rel="">Texas Roadhouse</a><span> restaurant chain).</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-140174766" href="https://www.construction-physics.com/p/no-inventions-no-innovations-a-history#footnote-1-140174766" target="_self" rel="">1</a></span><span> Over its lifespan, the company slowly but steadily lost market share and importance. When it was formed in 1901, it was by far the largest company in the world, and produced nearly 2/3rds of American steel. Today, it makes just 12% of American steel, around a third of the steel that it made in 1955, and employs around the same number of people as online pet retailer </span><a href="https://en.wikipedia.org/wiki/Chewy_(company)" rel="">Chewy</a><span>.</span></p><p>How did a once mighty industrial titan fall so far? Let’s take a look.</p><p>By the turn of the 20th century, the American steel industry had eclipsed Britain to be the largest and most efficient in the world. In 1896, an engineer for the Pennsylvania Steel Company wrote that “within the last decade America has made marvelous developments in her iron industry, until she now leads the world in the quantity of her products and bows to none in their quality”. Relentless competitors like Andrew Carnegie of Carnegie Steel had, in the course of expanding their steelmaking capacity and acquiring market share, steadily driven down the price of steel, which fell by more than 80% between 1870 and 1896.</p><p>But these successes had come at a cost. Steel production was subject to very large economies of scale - the larger your blast furnaces, and the more Bessemer converters and open hearth furnaces you operated, the cheaper making steel became. And because of the high fixed costs of these facilities, producers were incentivized to keep them full, cutting prices to just above the marginal cost of production in times of low demand. The result was chronic overcapacity and as steelmakers built ever-larger facilities and tried to underprice each other - at the end of the 19th century, nearly half of steelmaking capacity in the US went unused each year.</p><p><span>There was thus a growing desire for consolidation of the industry. If many competing firms were combined, production volumes of the new firm would rise and duplicate plant could be eliminated, enabling even greater economies of scale and lowered costs. The instigating event for such a merger was a&nbsp;banquet of bankers and industrialists in 1900, where Carnegie Steel president Charles Schwab spoke of the potential benefits of industry rationalization via merger. Less than 4 months later, it was done. Organized by JP Morgan, a new company was created by combining Carnegie Steel and Federal Steel, along with a hodgepodge of smaller companies including National Steel, American Sheet Steel, and American Hoop.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-140174766" href="https://www.construction-physics.com/p/no-inventions-no-innovations-a-history#footnote-2-140174766" target="_self" rel="">2</a></span><span>&nbsp;</span></p><p><span>The new company, US Steel, was a monster. The first company to be worth more than $1 billion, the company had 168,000 employees and produced just under 9 million tons of steel annually, over 60% of all the steel in the US. And it quickly grew even larger. By 1917 US Steel (now up to 268,000 employees) was more than </span><a href="https://www.forbes.com/sites/jeffkauflin/2017/09/19/americas-top-50-companies-1917-2017/?sh=378273e16295" rel="">3 times as large</a><span> as the next largest company, AT&amp;T, and had more than 7 times as many employees as Standard Oil when </span><a href="https://content.time.com/time/subscriber/article/0,33009,871865,00.html" rel="">it was broken up</a><span>.</span></p><p><span>The decades prior to the formation of US Steel were characterized by cutthroat competition, but that ended with the formation of US Steel. The head of the new company, Judge Elbert Gary, was a fundamentally conservative businessman, and his desire was to bring stability to what was a cyclical and chaotic industry. Whereas previously companies like Carnegie Steel would constantly cut prices to achieve greater market share and drive their competitors out of business, Gary set (generally) higher prices, and kept them high even as demand for steel fluctuated. Though its size did give it production cost advantages, these savings were retained as higher profits rather than passed on to the consumer. Gary was, according to former managing director of Carnegie Steel James Gayley, “opposed to the old method of going out into the market and slashing prices in order to get business”. To maintain prices in the face of fluctuating demand, Gary would gather the industry’s leadership together in regular “</span><a href="https://content.time.com/time/subscriber/article/0,33009,728689,00.html" rel="">Gary Dinners</a><span>”, where price levels would be agreed upon and Gary would “exhort the chairmen, presidents, or other major owners of steel companies to maintain rank”. Those who refused to cooperate would be “disciplined” by the others. Many former Carnegie Steel executives, schooled in the intense competition of the Carnegie years, were allergic to this strategy, and departed for other steel companies.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png" width="606" height="451" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:451,&quot;width&quot;:606,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F007ea525-dd47-4ec3-afea-f04bcfa28ccc_606x451.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Via Temin 1964 and USGS</figcaption></figure></div><p>Gary proved adept at navigating the company through a cultural climate that was increasingly hostile towards potential monopolies. Under his leadership, the company successfully fought off a Justice Department lawsuit to break up the company as an illegal monopoly. (Perversely, the court ruled that the Gary Dinners proved that US Steel did not have the power to set prices, and thus couldn’t be a monopoly). But other threats proved harder to cope with. US Steel was consistently behind on adopting the latest steelmaking technology, and was often forced to license technologies from more forward-looking companies (some of which were run by former Carnegie men). A 1936 magazine article described early US Steel company policy as “No inventions; no innovations”.</p><p>In 1902, for instance, a man named Henry Grey invented what was known as a “Universal Beam Mill”. At the time, beams were made in the shape of an uppercase I, with a tall vertical web capped with narrow flanges at the top and the bottom. If you wanted wider flanges capable of carrying heavier loads, you would need to weld or rivet steel plates to the beam, an expensive and time-consuming process. The Universal Mill made it possible to roll wide-flange beams in a single operation, eliminating the process of attaching extra steel plates. Grey first brought his mill design to US Steel, but it was rejected by the finance committee. Instead, the first Universal Mill in the US was built by Bethlehem Steel, run by former Carnegie president Charles Schwab. Faced with declining market share in the growing construction steel market (which made heavy use of wide-flange steel beams), US Steel was ultimately forced to license the Universal Mill from Bethlehem in 1926.</p><p>The same pattern repeated for other new technologies. In the 1920s, technology for making large-diameter pipe by electrical resistance welding was invented. Though it was (supposedly) first offered to US Steel, the company again passed, only to adopt it several years later to keep up with its competitors. Around the same time, technology for continuous rolling of wide sheets of steel was invented, which greatly reduced production costs. US Steel had investigated continuous sheet rolling as early as 1902, but had abandoned its efforts. Instead, it was once again forced to license the technology from others to remain competitive (though in fairness, it was one of the first manufacturers to license it).</p><p>More generally, US Steel’s enormous size made it unwieldy and difficult to manage. It took time for information to filter up through the many layers of management between the factory floor and company leadership, and to get all of the disparate operations of the company moving in the same direction. This, on top of the fundamental conservative culture created by Gary, and the lack of top management talent as former Carnegie executives abandoned the company, caused US Steel to steadily lose market share to its more agile rivals. The company continued to grow, but other companies grew faster. By 1941 US Steel’s output had risen to nearly 30 million tons of steel annually, triple what it made when it was founded, but its market share had fallen from over 60% to around 35%.</p><p><span>At the end of WWII, the American steel industry was an unchallenged juggernaut. During the war, American steel production had risen by more than a third, while the steel industries of most other countries had been nearly wiped out. By 1945, America was producing over 60% of the world’s steel. American steelmakers had the latest technology, unparalleled expertise, the largest economies of scale, and easy access to resources such as iron ore and coal. In 1945, the president of the US Steel Export Company George Wolf testified before congress that “the European steel industry is still far behind that of the United States, product, quality, and cost wise”, and that the gap was “an ever-widening one”. Japan, which would later emerge as a steel juggernaut, wasn’t even on the radar, producing just </span><a href="https://academic.oup.com/book/27157/chapter-abstract/196566880?redirectedFrom=fulltext" rel="">0.56 million tons</a><span> in 1946 against America’s 66 million tons. US Steel continued to dominate the industry, producing more than twice as much steel as the next largest company (Bethlehem Steel), and averaging around 30% of American steel output in the mid-1950s.</span></p><p>With seemingly no rivals on the horizon, American steel companies, including US Steel, became complacent. The post-war years are sometimes described as the “dodo period” of the American steel industry, as it steadily raised prices (steel prices rose at 7% annually between 1947 and 1957) and enjoyed large profits while ignoring the progress that was taking place in other parts of the world.</p><p><span>As American steelmakers built new capacity to meet post-war demand (by 1962 American steel capacity reached 154 million tons annually, nearly twice the production at the end of WWII), they did so using existing steelmaking technology, primarily the open hearth furnace. In an open hearth furnace, a combination of liquid pig iron from a blast furnace and steel scrap is placed in a large crucible, which is then heated using burning gas blown through a </span><a href="https://en.wikipedia.org/wiki/Regenerative_heat_exchanger" rel="">regenerative heat exchanger</a><span>. In 1954, over 90% of steelmaking capacity in the US was open hearth furnaces, with the balance a mix of electric arc furnaces and Bessemer converters.</span></p><p>But in 1952, a new steelmaking technology appeared, the Basic Oxygen Furnace (BOF). The BOF was in a sense a refinement of the earlier Bessemer converter, the first technology for mass-producing steel. Whereas the Bessemer converter worked by blowing air through liquid pig iron from below, the BOF worked by blowing pure oxygen into pig iron from above. Oxygen furnaces had been conceived as early as the mid-19th century, but weren’t feasible to build until pure oxygen began to be made on an industrial scale in the 20th century.</p><p>The open hearth furnace replaced Bessemer converters because the latter was difficult to control, tended to result in nitrogen-embrittled steel, and was limited in the types of ore it could use. But open hearths came with drawbacks. They were more expensive to build, ran slower, and required much more fuel than Bessemer converters. Only cheap scrap metal, which could be remelted in an open hearth furnace along with liquid pig iron, made them economical to operate.</p><p>The BOF, by contrast, had many of the benefits of the Bessemer converter (rapid conversion of iron to steel, low fuel and labor costs, comparatively cheaper to build) while eliminating many of its drawbacks (nitrogen embrittlement, limitations on types of ore it could use).</p><p>The first commercial BOF was built in Austria in 1952, and diffused through the industry as other companies experimented with it. By the end of the 1950s, it was clear that the BOF could produce steel more cheaply than the open hearth furnace (and in fact, no new open hearth integrated steelworks were built in the US after 1958).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png" width="540" height="345" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:345,&quot;width&quot;:540,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa32d9817-2b08-471b-8016-6a13cd9b2c40_540x345.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>But US Steel was once again slow to adopt the technology. Reluctant to abandon expensive open hearths that had years of useful life left, as late as 1962 US Steel executives were arguing that open hearth steel would remain competitive. US Steel didn’t build its first BOF until 1964, well behind other American companies like Kaiser Steel, which by 1964 was making 43% of its steel in BOFs.</p><p>Though US Steel was once again a laggard, it was emblematic of the entire US Steel industry, which was comparatively slow to adopt the BOF. By the time US Steel built its first BOF, the BOF was producing around 17% of steel in the US, compared to around 55% of steel in Japan.</p><p>And the BOF wasn’t the only steel technology where Japan was pushing ahead of America. In pursuit of ever-larger economies of scale, Japan went far beyond the US in the size of its blast furnaces. By the mid-1970s, average blast furnace size at Nippon Steel was 4 times the average at US Steel, and by 1977 more than half the blast furnaces in Japan had a volume of more than 2000 cubic meters, compared to just 2.6% of furnaces in the US. When US Steel had trouble with its own large blast furnace at its Gary Works, it was eventually forced to turn to the Japanese for help, who by then had much more experience than Americans operating very large furnaces.</p><p>A similar trajectory occurred with continuous casting technology, which produced continuous slabs of steel instead of individual ingots, and thus eliminated much of the rolling required for steel production. Though US firms pioneered much of this research, other countries adopted it more quickly. By 1975, only 9% of steel was continuously cast in the US, compared to 31% in Japan and 24% in West Germany. Here again, US Steel lagged, and didn’t widely adopt continuous casting until the early 1990s.</p><p>Thus, by the early 1960s cracks in America’s seemingly unassailable steel industry were beginning to show. Foreign producers like Japan had expanded their industries and adopted the newest steelmaking technology like the BOF and continuous casting. American steelmakers like US Steel, saddled with outdated technology and high labor costs, found themselves under threat from foreign producers for the first time. By 1958 some steelmakers in Germany and Japan were able to compete on price with US producers, and by the mid-1970s input costs for Japanese steel (ore, labor, coking coal, etc.) were nearly half those of US costs. Between 1955 and 1970 steel imports to the US increased by more than factor of 10, going from less than 2% of US production to more than 15%, and continued to rise.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png" width="733" height="463" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/785d8481-3ce4-4033-a877-cdca332604e9_733x463.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:463,&quot;width&quot;:733,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F785d8481-3ce4-4033-a877-cdca332604e9_733x463.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>In the face of foreign pressure, US Steel could no longer maintain the “price leadership” it had in the past, setting whatever price it wanted and encouraging the rest of the industry to follow suit. The company continued to lose ground to its more nimble rivals, who now included overseas competitors. By 1971, it was still the largest steel company in the US, but had been eclipsed in size by Japanese steelmaker </span><a href="https://books.google.com/books?id=goF9w0jocLgC&amp;pg=PA30603&amp;dq=history+of+nippon+steel&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwjwlp2D35uDAxUgsoQIHXdoAyU4MhDoAXoECAYQAg#v=onepage&amp;q=history%20of%20nippon%20steel&amp;f=false" rel="">Nippon Steel</a><span>. Its annual output of steel was just over 27 million tons, less than it had produced in 1941, and its share of the US market had fallen to around 24%.</span></p><p>The American steel industry responded to the rise of foreign producers not by trying to improve their operations, but by demanding government protection from “unfair” foreign trade practices. In 1968, steel producers in Japan and Europe, at the behest of President Lyndon Johnson, agreed to artificially restrict their steel exports to the US. This was intended to give US producers “breathing room” to modernize their facilities and improve operations, though this didn’t occur (in fact, capital investment by American steelmakers declined after the agreements). And though pressure had been temporarily removed, things were about to get much worse for US Steel and the American steel industry.</p><p><span>Having temporarily fended off foreign threats, American steel production continued to climb. In 1973, right around when Hyman Roth was boasting that their mafia operations were “</span><a href="https://www.youtube.com/watch?v=Rmxluz27Q-4" rel="">bigger than US Steel</a><span>”, America produced 137 million tons of steel, more than any other country in the world. While not the unrivaled behemoth it once was, US Steel was still the </span><a href="https://money.cnn.com/magazines/fortune/fortune500_archive/full/1973/" rel="">13th largest company in the US</a><span> by revenue, and the largest steelmaker in the US.</span></p><p>It was widely predicted that demand for steel would continue to rise, as it had for most of the 20th century. In 1972, chairman of US Steel Edwin Gott predicted that worldwide demand for steel would rise 25% by 1980. Countries around the world expanded their steelmaking capacity in anticipation.</p><p>Instead, demand for steel stagnated. Between 1973 and 1984 worldwide demand for steel was essentially flat, and in industrialized countries it declined by around 25%. Steelmakers around the world, faced with large amounts of excess capacity, were incentivized to sell steel for just above the variable costs of production, “dumping” it on foreign markets. It’s somewhat unclear if such dumping actually occurred, but steel imports to the US continued to rise through the 1970s even as overall demand dropped. And US Steel was hurt most of all - nearly all of the loss in market share to foreign steelmakers came at the expense of US Steel.</p><p><span>American producers once again demanded government protection from foreign competition. They filed dozens of “antidumping” cases under the Trade Act of 1974, and secured other protectionist measures such as a “</span><a href="https://www.clevelandfed.org/publications/economic-commentary/1982/ec-19820517-the-steel-trigger-price-mechanism" rel="">trigger price mechanism</a><span>” in 1978 (which prevented foreign steelmakers from selling below their total costs of production) and a new round of voluntary export restrictions in 1984.</span></p><p>These measures helped stave off foreign competition - steel imports declined from 26 million tons in 1984 to 17 million tons in 1989. But they couldn’t stop a threat that was emerging from within the US: the minimill.</p><p>Historically, steel had been produced in large, integrated steelworks. Iron ore would be turned into pig iron in a blast furnace, which would then be turned into steel in an open hearth or basic oxygen furnace. From there, the steel would be cast into ingots or slabs and then rolled into various shapes - wire, rods, plate, beams, sheets, and so on.</p><p>But in the late 1960s, a new type of steelmaking facility began to appear, the minimill. The minimill made steel not by processing iron ore, but by remelting scrap steel in an electric arc furnace. By eliminating the blast furnaces which turned iron ore into pig iron, minimills were not only much cheaper to build than integrated steelworks (as little as 1/10th the cost per ton of steel they produced), but they could profitably be built much smaller. And the scrap steel they required was widely available thanks to the previous transition to the BOF, which used much less scrap than the open hearth it replaced.</p><p>Because scrap steel was often contaminated with other metals such as copper that couldn’t be easily separated, minimill steel was initially lower quality than BOF steel, and minimills were only competitive in products where such quality didn’t matter, like concrete reinforcing steel. But as minimill technology improved, they began to take more and more share from large, integrated steelmakers like US Steel. Between 1974 and 1994 steelmaking capacity of integrated producers fell by more than 50%, while the capacity of minimills increased by 360%, reaching 30% of American steelmaking capacity.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png" width="622" height="374.19343389529723" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:678,&quot;width&quot;:1127,&quot;resizeWidth&quot;:622,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52e1f9bb-ec6d-476e-bee8-af6b2de0fed6_1127x678.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png" width="628" height="364.1298245614035" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:661,&quot;width&quot;:1140,&quot;resizeWidth&quot;:628,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6971254a-7a6c-4fb8-8a56-0af90b108329_1140x661.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Rise of minimills between 1974 and 1994</figcaption></figure></div><p>Thus, by the early 1980s, US Steel was in trouble. Its market share had fallen to around 20% of the US market, and it was massively less efficient than both low-cost steelmakers abroad and increasingly capable minimills at home. Whereas for much of its history it had been one of the most profitable American steelmakers thanks to its scale, it was now one of the least profitable.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png" width="594" height="389" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/143ad033-14c8-4409-8abe-120886cf54a9_594x389.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:389,&quot;width&quot;:594,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F143ad033-14c8-4409-8abe-120886cf54a9_594x389.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>US Steel responded to these threats with bitter medicine. It cut tens of thousands of jobs and closed dozens of plants, reducing employment from 171,000 in 1979 to less than 21,000 in 1995. It divested many of its auxiliary operations like mines, warehouses, and bridge construction. It abandoned market segments like rebar and heavy structural steel where it couldn’t compete with the minimills, and instead focused on things like sheet steel products (which minimills still had trouble with), concentrating operations in a small number of large plants. By 1985, US Steel had closed more than 150 facilities, and by 1998 its steelmaking capacity was down 71% from its peak in 1973.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png" width="780" height="298" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:298,&quot;width&quot;:780,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F13528ee3-31f2-4990-896b-8b5e2712bb3b_780x298.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>(US Steel was far from the only integrated producer that needed to take such drastic steps. The entire American steel industry (and indeed, the worldwide steel industry) shed hundreds of thousands of workers as it dealt with its overcapacity.)</p><p>This tough medicine worked. Productivity increased enormously, and US Steel became one of the most efficient integrated steelmakers in the world (though it still had trouble matching the productivity of the most efficient minimills).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png" width="630" height="814.9115044247787" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:877,&quot;width&quot;:678,&quot;resizeWidth&quot;:630,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0ab399c3-f72c-4e6d-a997-4df448dc61cc_678x877.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The new, lean US Steel proved to be a scrappy competitor. As imports continued to rise (reaching 37% of US production in 1998), and minimills continued to take market share (electric arc furnaces reached 47% of US production by 2000), US Steel survived where many of its competitors didn’t. Kaiser Steel, the company that had beaten US Steel to the punch in installing BOFs, closed shop in 1983 after 18 quarters of losses. Between 1997 and 2001, </span><a href="https://ideas.repec.org/p/iie/pbrief/pb03-01.html" rel="">30 steel companies declared bankruptcy</a><span>, including longtime rival Bethlehem Steel.</span></p><p><span>But the new, lean US Steel still continued to be a step behind on technological innovation. US Steel didn’t adopt the minimill until 2020, when it acquired a minimill company and built its own minimill in Alabama. (Minimills now produce around 25% of US Steel’s domestic output.) Companies like Nucor beat it to the punch with things like </span><a href="https://www.nytimes.com/1991/02/27/business/business-technology-making-steel-faster-and-cheaper.html" rel="">thin slab casting technology</a><span>.</span></p><p><span>Today, the momentum in the American steel industry is clearly with the minimills. An ever-larger fraction of American steel is </span><a href="https://www.spglobal.com/commodityinsights/en/market-insights/blogs/metals/050919-us-steel-sector-thrives-as-mills-move-up-quality-ladder" rel="">made in electric arc furnaces</a><span>. Minimill company Nucor passed US Steel in production in 2015, and today is the largest steel producer in the US.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png" width="594" height="362" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:362,&quot;width&quot;:594,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F359c8bbb-ee17-4b2d-a74e-6ce58ef91577_594x362.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Arguably, US Steel has been a disappointment since the day it was formed. It was created as a fundamentally conservative reaction to the vicissitudes of the steel industry, and this guided its early years and shaped its culture. The economies of scale it achieved were never passed on to the consumer, and instead it used its size to bully other steelmakers and extract money from consumers. When this stopped working, it used its political influence to prevent consumers from buying low-cost foreign steel. Improving the efficiency of its operations was something it did as a last resort when left with no other options.</p><p>The company’s large size made it unwieldy to manage, and it was late to every major advance in steelmaking technology of the last 100 years, from continuous rolling to the basic oxygen furnace to the minimill. When the company did try its hand at technology innovation, it reliably made missteps. In some cases, like with continuous rolling, it gave up too early, while in other cases it spent many years unsuccessfully developing a technology. In the 1950s, for instance, it spent many years trying to develop an alternative to the BOF that blew oxygen in from the side, long after other producers had given up on the technology. And in the 1970s it tried to develop another alternative to the BOF called Q-BOP that likewise didn’t seem to pan out. As far as I can tell, no major steelmaking technology over the last century came out of US Steel.&nbsp;</p><p>The US Steel of today is a far cry from the industrial giant of the 20th century. But being transformed into a lean, competitive company doesn’t seem to have changed its fundamental culture, a company that's content to be a follower, rather than a leader in technological development and pushing the industry forward.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[UK announces commercial operations of longest land/subsea interconnector (145 pts)]]></title>
            <link>https://www.nationalgrid.com/national-grid-announces-commercial-operations-viking-link-worlds-longest-land-and-subsea</link>
            <guid>38807001</guid>
            <pubDate>Fri, 29 Dec 2023 16:45:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nationalgrid.com/national-grid-announces-commercial-operations-viking-link-worlds-longest-land-and-subsea">https://www.nationalgrid.com/national-grid-announces-commercial-operations-viking-link-worlds-longest-land-and-subsea</a>, See on <a href="https://news.ycombinator.com/item?id=38807001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><span>The world’s longest land and subsea interconnector started commercial operations today (29<sup>th</sup> December 2023).&nbsp;</span></p><p><span>National Grid’s new Viking Link electricity interconnector became operational this afternoon&nbsp;transporting power between the UK and Denmark. The link has a capacity of 1.4 GW and stretches for 475 miles under land and sea to join Bicker Fen substation in Lincolnshire with Revsing substation in southern Jutland, Denmark.&nbsp;</span></p><p><span>The £1.7 billion&nbsp;project is a joint venture between National Grid and Danish System Operator, Energinet, and has the capacity to transport enough electricity for up to 2.5 million* UK homes, bringing over £500 million of cumulative savings for UK consumers over the next decade* due to cheaper imported power from Denmark.</span></p><p><span>Construction on Viking Link, National Grid’s sixth interconnector,&nbsp;started in 2019, with more than four<strong>&nbsp;</strong>million working hours spent to get to this point.&nbsp;</span></p><p><span>National Grid’s interconnector business is run by National Grid Ventures (NGV),&nbsp;which operates outside of National Grid’s core regulated businesses in the UK and US. NGV develops, operates and invests in energy projects, technologies and partnerships to accelerate the development of our clean energy future.</span></p><p><span>Viking Link will bring huge benefits for UK consumers including cheaper, lower carbon power and increased energy security as the UK can call on additional power from Denmark when needed.&nbsp;</span></p><div><p><span>Initially,</span><span> Viking Link will be operating at a capacity of 800MW before increasing up over time to 1.4GW.&nbsp;</span><span>National Grid and Energinet will be working together to bring the asset up to full capacity over the coming year.&nbsp;</span></p><p><span>In its first year of operation Viking Link is expected to save approximately 600,000 tonnes of carbon emissions – this is equivalent to taking roughly 280,000 cars off the road.*</span></p></div><p><span>President of National Grid Ventures Katie Jackson said: “This record-breaking new link is a fantastic example of engineering and collaboration with our partner, Energinet. As we deploy more wind power to meet our climate and energy security targets, connections to our neighbouring countries will play a vital role increasing security of supply and reducing prices for consumers. Stretching further across land and sea than any of our existing links, it connects the UK to clean, green Danish energy, improving security of supply and bringing huge carbon and cost savings for UK consumers.”</span></p><p><span>Viking Link has a converter station on each end of the cable where the power is transformed into the correct frequency before being transported onto each country’s transmission systems. &nbsp;&nbsp;Principal Contractor Siemens Energy built the converter<u>&nbsp;</u>station in the UK while Energinet built the Danish converter station. &nbsp;Siemens Energy have designed, installed and commissioned the electrical assets on both sides.</span></p><p><span>The HVDC offshore cable was manufactured and laid by Prysmian Group</span><s><span>&nbsp;</span></s><span>. The cable was laid on the seabed using a custom-made vessel The Leonardo Da Vinci which was then buried using Asso trenchers. &nbsp;&nbsp;</span></p><p><span>&nbsp;Prysmian Group manufactured the HVDC land cable which was installed by Balfour Beatty, the offshore section was manufactured and installed by Prysmian Group<u> i</u>n the UK and the Danish land section was manufactured by NKT and installed by Monck.&nbsp;</span></p><p><span>The UK land cable was made up of 118 sections stretching for 67km between Bicker Fen and Sutton-on-Sea where the subsea cable begins. It was connected to the UK’s National Transmission Network by National Grid Electricity Transmission at the existing Bicker Fen substation.&nbsp;</span></p><p><span>Interconnectors enable the fast, flexible sharing of energy between countries, making them the perfect tool for managing the intermittent nature of renewable energy sources.&nbsp;</span></p><p><span>The switch on was a proud moment for Managing Director of National Grid Interconnectors Rebecca Sedler.</span></p><div><p><span>She said:&nbsp;"Viking Link is an achievement for both Denmark and the UK, and consumers in both countries will benefit from this infrastructure for many years to come. The hard work and collaboration of our teams, accounting for more than four million labour hours, highlights National Grid’s dedication to the UK’s clean energy transition.”</span></p><p><span>&nbsp;National Grid launched the UK’s first interconnector (IFA) to France in 1986. Since then, it has built five more including a second link with France (IFA2) and further connections with The Netherlands (BritNed), Belgium (Nemo Link) and Norway (North Sea Link).</span></p></div><p><span>Between 2020 and 2030, National Grid expects its interconnectors will have helped the UK to avoid around 100 million tonnes of carbon emissions and by 2030, 90% of the energy imported through the company’s interconnectors will be from zero carbon energy sources.</span></p><p><span><strong>Energy Security Secretary Claire Coutinho said:</strong></span></p><blockquote><p><em><span>Great news today as the new Viking Link interconnector starts to transport energy between Denmark and the UK, under the North Sea.</span></em></p><p><em><span>&nbsp;The 475-mile cable is the longest land and subsea electricity cable in the world and will provide cleaner, cheaper more secure energy to power up to 2.5 million homes in the UK.</span></em></p><p><em><span>&nbsp;It will help British families save £500 million on their bills over the next decade, while cutting emissions.</span></em></p></blockquote><p><span>Earlier this year (2023) National Grid announced joint plans with TenneT for a new 1.8GW interconnector between the UK and The Netherlands, called LionLink. The link would not only join the two countries but also connect to offshore wind generation.&nbsp;LionLink would be the second link between the two countries and is expected to be operational in the early 2030s. A second new link called Nautilus, is also in the planning phase with the potential to connect with Belgium.&nbsp;</span></p><p><span>To find out more about National Grid Interconnectors, how they work and their role in decarbonising the energy system click&nbsp;</span><a href="https://www.nationalgrid.com/national-grid-ventures/interconnectors-connecting-cleaner-future"><span><strong>here</strong></span></a><span>.</span></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everyone's getting ghosted, the new normal in tech recruiting (139 pts)]]></title>
            <link>https://medium.com/@k0ryk/everyones-getting-ghosted-dbf0fbaf161</link>
            <guid>38806473</guid>
            <pubDate>Fri, 29 Dec 2023 16:11:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@k0ryk/everyones-getting-ghosted-dbf0fbaf161">https://medium.com/@k0ryk/everyones-getting-ghosted-dbf0fbaf161</a>, See on <a href="https://news.ycombinator.com/item?id=38806473">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="366d">The new normal in tech recruiting</h2><div><a rel="noopener follow" href="https://medium.com/@k0ryk?source=post_page-----dbf0fbaf161--------------------------------"><div aria-hidden="false"><p><img alt="Kory Kirk" src="https://miro.medium.com/v2/resize:fill:88:88/1*Bw3CANMDRroIS4BGKIYQ3A.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><p id="ad44">The company I interviewed for was up and coming, YC funded, now profitable, a well-known player in the generative AI space. I was excited for the opportunity. They have many in-house recruiting resources and a policy to <strong>not</strong> ghost candidates. Yet, I got ghosted. I’m not alone in this, and we’re going to investigate why this happens.</p><p id="1a8f"><strong>Ghosting</strong> is a term that refers to asynchronous communication that is abruptly cut off by one party. The term is typically used in dating, but works well for tech recruiting too. In order for it to be ghosting, the ghosted party has to expect the conversation will continue. This means that if you apply and never hear back from a job, that’s not ghosting, a conversation never started. It only becomes ghosting when there is an expected next step that never happens.</p><figure><figcaption>Once ghosted, do we become ghosts? Source: Dall-E</figcaption></figure><p id="956d">The effect of getting ghosted for me, and likely others, is impactful. The narrative in my head played out like this: “was I really so bad that they wouldn’t even tell me no?” It was also a chilling effect for my projects that involved generative AI. I didn’t want to work on them. Every time I logged into my Github, I was reminded of the company because I still had a fork of the take home assignment. It took about a month for my project work to feel normal again, but I shelved some of my LLM projects and moved on. The fire of disappointment had smoldered into an ember of resentment.</p><p id="2323">The resentment that, months later, inspired me to write a message to the team’s Product Manager (PM). I didn’t reach out on Linkedin. It was much more intimate, using my gamer tag. Discord is a social media platform where you can join communities that have chat rooms, forums, video and voice chat. I am a member of 50+ Discord communities, and many of them are dedicated to open source projects or technologies. The PM was in a Discord I was active in for an open source LLM toolset. Seeing that they were still in the server, and not wanting them to entice others to get ghosted. I private messaged them with the story of my experience. Thankfully, he was receptive.</p></div><div><p id="556c">I had finished a 3-hour take home test and went through hours of Zoom interviews. My loop was done. I didn’t feel great about my performance, but didn’t feel bad. I had done well, but not perfect. My experience was not well aligned with the role. They were looking for a senior level engineer they deemed an “AI hacker.” I had spent the previous decade in technical lead roles, spending as much time on technical direction as I have with coding. I was expecting a message in the next two weeks saying “no,” but would be pleasantly surprised if they said “yes.”</p><p id="88bd">Two weeks after my final interview, I hear nothing. I am tired of waiting for the no, so I send an email to the recruiter asking for more details. I thought that something probably happened in the process and I slipped through the cracks, and I want to give them the opportunity to do the right thing. The right thing being not ghosting me. The recruiter never responded.</p><blockquote><p id="35e4">Ugh. That’s tough to hear.</p></blockquote><p id="1b09">The PM says after I tell them about this part in the story.</p><blockquote><p id="7fd0">Let me go talk to our talent team and see what went on here. Really appreciate you sharing this with me.</p></blockquote><figure><figcaption>Ghost in an email shell. Source: Dall-E</figcaption></figure><p id="78fb">There is this sort of liminal space between interpreting behavior as a mistake or malicious, at least for the story I tell in my head. I remind myself of <a href="https://simple.wikipedia.org/wiki/Hanlon%27s_razor" rel="noopener ugc nofollow" target="_blank">Hanlon’s razor</a>, “never attribute to malice that which is adequately explained by [misunderstanding].” When the weeks passed by with no response from the recruiter, the story in my head solidified — it’s malice. However, after the PM’s attempted reconciliation and more context, it seems like it was probably misunderstanding, or in the actual quote from Wikipedia: “stupidity.” A week after the PM got back to me, I get this email:</p><figure><figcaption>Mixed feelings of 🙏and🖕. Source: Me</figcaption></figure><p id="019a">I didn’t bomb the interview and feedback was generally positive, though vague. Their policy is to not ghost candidates, and it seems I slipped through the cracks. This works for me as closure. I will not be responding to the recruiting manager. I thanked the PM for helping me out, solid person, really appreciate them.</p><h2 id="8aec">Ghost World</h2><p id="b392">I had not been ghosted by an interviewer before. I typically apply to positions where I know people, so that may be why. I reached out to some coding communities I am in to ask for their experiences. Here are the parts of the discussion that stuck out:</p><blockquote><p id="0e93">Almost all of the people i know have been ghosted multiple times by potential employers</p><p id="ebb6">I had an HR lady tell me ‘we’ll definitely reach out one way or another we’re not one of those places that will leave you hanging’ and then proceed to leave me hanging</p><p id="f303">recruiters have really been shit the past couple years with actually responding<br>in the tech world…. Literally every single company i interviewed at (including some really big well known ones) recently have ghosted me</p></blockquote><p id="7def">This is a small sample, and does not include all the people who weren’t ghosted. These people are smart and talented with varying levels of experience.</p><p id="d9bf">Knowing the skillsets of others who got ghosted and my personal experience, here are some of my assumptions about the recruitment ghosting trend:</p><ul><li id="2df6">It has nothing to do with how well you interviewed (you could be 2nd pick and still get ghosted).</li><li id="133b">The majority of people who participated in the interview are not aware of the ghosting. The people who performed the interview probably assume they have humane recruiting practices.</li><li id="85e3">There is no perceived incentive from recruiters to not ghost</li><li id="42d4">Verifying or measuring contact with rejected candidates is not a priority and not done. Even if there is a policy, there is nobody checking to see if it is followed.</li></ul><h2 id="7f40">Nonperformative policy</h2><blockquote><p id="819b">the message that they intended to send to you never made it to your inbox. You were meant to receive our decision with a link to book time for feedback.</p></blockquote><p id="78e2">In Sarah Ahmed’s <em>Complaint! </em>she talks about institutions and their policies, describing many as “nonperformative,” a term which “seemed to capture how saying something was not doing something.” Some policies exist simply to bolster the institutions image, like an anti-bullying policy or inclusion policy.</p><p id="75f5">Nonperformative policies are not necessarily malicious, they come about when there is no investment or measurement into the success of the policy. In my case, the policy to follow up with every candidate was not appropriately measured, therefore allowing me to “slip through the cracks.”</p><p id="4cce">I wonder how many other candidates have slipped through the cracks as well. From the recruiter’s perspective, there is very little incentive to do a final follow up with a rejected candidate. That person is no longer part of the pool of potential candidates, which is the group of people who will make them money. They will definitely prioritize profitable communications over closing the loop with a rejected candidate.</p><h2 id="e7ed"><strong>Final Thoughts</strong></h2><p id="1410">From a game theory perspective if “winning” is having a job that fits all your wants and needs. Then the best way to win is to look and apply for jobs constantly, not just when you are discontent with your current job. That means a lot of opportunities for learning and improving interviewing skills. When recruiters ghost us, it becomes incredibly difficult to gauge our performance in those interviews and continue to improve.</p><p id="0a9b">The truth is that getting ghosted by recruiters (or anyone) feels bad. Spending 10 hours on an interview process to not even get the time of day for a “no” is an inhumane practice and should be stopped. It cannot just be stopped with a policy, there needs to be measurement of compliance to the policy. The whole thing could be automated rather simply.</p><p id="73d2">We all know that working with recruiters can be frustrating from both a candidate and interviewer perspective. Those of us who perform interviews regularly in our professional lives should be more aware and verify that loops are closed for candidates. I have so many great conversations with potential coworkers, but a lot of times it doesn’t work out. I want those people to be treated with dignity and respect, and the easiest way I can do that is to ping the recruiter I work with on Slack and verify. So, that’s what I’ll do. Thanks for reading.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In 2024, please switch to Firefox (1518 pts)]]></title>
            <link>https://roytanck.com/2023/12/23/in-2024-please-switch-to-firefox/</link>
            <guid>38806270</guid>
            <pubDate>Fri, 29 Dec 2023 15:57:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://roytanck.com/2023/12/23/in-2024-please-switch-to-firefox/">https://roytanck.com/2023/12/23/in-2024-please-switch-to-firefox/</a>, See on <a href="https://news.ycombinator.com/item?id=38806270">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
		
			
			<div>
				
<p>This December, if there’s one tech New Year’s resolution I’d encourage you to have, it’s switching to the only remaining ethical web browser, <a href="https://firefox.com/">Firefox</a>. According to recent posts on social media, Firefox’s market share is slipping. We should not let that happen. There are two main reasons why switching is important.</p>



<figure><img decoding="async" width="2047" height="1356" src="https://roytanck.com/wp-content/uploads/2023/12/16071828377_9bdfbd9789_k.jpg" alt="A red panda (firefox) resting on a tree branch." srcset="https://roytanck.com/wp-content/uploads/2023/12/16071828377_9bdfbd9789_k.jpg 2047w, https://roytanck.com/wp-content/uploads/2023/12/16071828377_9bdfbd9789_k-1440x954.jpg 1440w, https://roytanck.com/wp-content/uploads/2023/12/16071828377_9bdfbd9789_k-768x509.jpg 768w, https://roytanck.com/wp-content/uploads/2023/12/16071828377_9bdfbd9789_k-1536x1017.jpg 1536w, https://roytanck.com/wp-content/uploads/2023/12/16071828377_9bdfbd9789_k-1070x709.jpg 1070w" sizes="(max-width: 2047px) 100vw, 2047px"><figcaption>“<a href="https://www.flickr.com/photos/91501748@N07/16071828377" target="_blank" rel="noreferrer noopener">Red Panda</a>” by <a href="https://www.flickr.com/photos/91501748@N07" target="_blank" rel="noreferrer noopener">Mathias Appel</a> is marked with <a href="https://creativecommons.org/publicdomain/zero/1.0/?ref=openverse" target="_blank" rel="noreferrer noopener">CC0 1.0</a>.</figcaption></figure>



<h2>1. Privacy</h2>



<p>Firefox is the only major browser not built by a company that makes money from advertising and/or selling your personal data. There’s been a lot of talk about websites tracking users using cookies, fingerprinting and other nefarious technologies that hurt your privacy. But owning the browser puts Google, Apple and Microsoft in a position where they don’t even need those tricks. We need to use browsers that are independent, and right now that means Firefox.</p>



<h2>2. Browser engine monopoly</h2>



<p>Wikipedia <a href="https://en.wikipedia.org/wiki/Comparison_of_browser_engines">lists four browser engines as being “active”</a>. Browser engines are the bits that take a web page’s code and display it on your screen. Ideally, they conform to the official <a href="https://www.w3.org/">W3C</a> standards, and display all elements as it describes. If that’s the case, web developers can easily write sites that work on all browsers. No proprietary vendor lock-in nonsense, just glorious open standards at work.</p>



<h3>It’s happened before</h3>



<p>In the early 2000’s, Internet Explorer had a massive 95% market share. This meant that many sites were only developed for use with IE. They’d use experimental features that IE supported, in favor of things from the official HTML standard. This was a very bad situation, which hindered the development of the World Wide Web.</p>



<p>Currenty, Chrome, Safari and Edge all use variations of the closely related Webkit and Blink engines. If we want to avoid another browser engine monopoly, we need to support Firefox, and its “Gecko” engine.</p>



<h2>Firefox is actually really good</h2>



<p>If Firefox would be a bad browser, I would not recommend you to switch. It’s fast, has a nice user interface, and feels every bit as modern and elegant as its competition. I’ve been using it as my main browser for a couple of years now, on Linux, Windows, MacOS and Android. As a web developer, I usually have at least three browsers open, but when I go look something up on the web, I pick Firefox.</p>



<p>So please, help save the web by <a href="https://www.mozilla.org/en-US/firefox/new/">using the best browser out there</a>. It’s an easy thing to do, and it makes a big difference.</p>
			</div><!-- .entry-content -->
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Every Major Pharmacy Chain Giving Government Warrantless Medical Record Access (299 pts)]]></title>
            <link>https://www.techdirt.com/2023/12/28/every-major-pharmacy-chain-is-giving-the-government-warrantless-access-to-medical-records/</link>
            <guid>38805779</guid>
            <pubDate>Fri, 29 Dec 2023 15:13:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/12/28/every-major-pharmacy-chain-is-giving-the-government-warrantless-access-to-medical-records/">https://www.techdirt.com/2023/12/28/every-major-pharmacy-chain-is-giving-the-government-warrantless-access-to-medical-records/</a>, See on <a href="https://news.ycombinator.com/item?id=38805779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-429217">


<h3>from the <i>third-party-doctrine-beats-HIPAA</i> dept</h3>

<p>The Fourth Amendment is rarely a match for the <a href="https://www.techdirt.com/blog/?tag=third+party+doctrine" data-type="link" data-id="https://www.techdirt.com/blog/?tag=third+party+doctrine">Third Party Doctrine</a>. In recent years, things have gotten a wee bit better thanks <a href="https://www.techdirt.com/2018/06/22/supreme-court-says-warrants-are-needed-cell-site-location-info/" data-type="link" data-id="https://www.techdirt.com/2018/06/22/supreme-court-says-warrants-are-needed-cell-site-location-info/">to a couple</a> of Supreme Court rulings. But the operative principle still overrides: whatever we share (voluntarily or not) with private companies can often be obtained without a warrant.</p>
<p>That’s why bills <a href="https://www.techdirt.com/2014/08/18/ron-wyden-its-time-to-kill-third-party-doctrine-go-back-to-respecting-privacy/" data-type="link" data-id="https://www.techdirt.com/2014/08/18/ron-wyden-its-time-to-kill-third-party-doctrine-go-back-to-respecting-privacy/">have been introduced</a> to add Fourth Amendment protections to cell location data gathered by phone apps. That’s why there’s been a constant struggle in courts <a href="https://www.techdirt.com/2023/07/21/wyden-bill-targeting-data-broker-sales-to-law-enforcement-passes-in-the-house/" data-type="link" data-id="https://www.techdirt.com/2023/07/21/wyden-bill-targeting-data-broker-sales-to-law-enforcement-passes-in-the-house/">and in Congress</a> to reconcile the Third Party Doctrine with the Fourth Amendment, <a href="https://www.techdirt.com/2021/03/25/data-broker-looking-to-sell-real-time-vehicle-location-data-to-government-agencies-including-military/" data-type="link" data-id="https://www.techdirt.com/2021/03/25/data-broker-looking-to-sell-real-time-vehicle-location-data-to-government-agencies-including-military/">given the vast amount</a> of information and data Americans now share with thousands of third parties.</p>
<p>Then there’s the players in the <a href="https://www.techdirt.com/2022/09/09/yet-another-data-broker-found-to-give-massive-amounts-of-location-info-to-law-enforcement/" data-type="link" data-id="https://www.techdirt.com/2022/09/09/yet-another-data-broker-found-to-give-massive-amounts-of-location-info-to-law-enforcement/">Third Party Doctrine market</a>. There’s the government, which wants as much information as it can obtain without having to subject its actions and motives to judicial scrutiny. And there are the private companies, who figure it’s far more cost effective to just give the government what it wants, rather than challenge government requests for data in court. </p>
<p>The private entities involved here probably have more reason than most to not try to piss the government off. Not only are they <a href="https://www.reuters.com/markets/deals/us-pharmacy-chain-rite-aid-agrees-bankruptcy-mediation-gets-loan-approval-2023-12-19/#:~:text=Rite%20Aid%2C%20which%20operates%20about,filling%20illegal%20or%20suspicious%20prescriptions." data-type="link" data-id="https://www.reuters.com/markets/deals/us-pharmacy-chain-rite-aid-agrees-bankruptcy-mediation-gets-loan-approval-2023-12-19/#:~:text=Rite%20Aid%2C%20which%20operates%20about,filling%20illegal%20or%20suspicious%20prescriptions.">still struggling to recover from a widespread retail downturn</a> ignited by a worldwide pandemic, but they’re also <a href="https://www.npr.org/2022/12/13/1142416718/cvs-walgreens-opioid-crisis-settlement" data-type="link" data-id="https://www.npr.org/2022/12/13/1142416718/cvs-walgreens-opioid-crisis-settlement">paying off large settlements to the government</a> for playing things a bit too fast and loose when it came to handing out opioids to Americans.</p>
<p>As Beth Mole reports for Ars Technica (and following on the heels of the news pharmacy chain Rite Aid is facing a five-year facial recognition tech ban), <a href="https://arstechnica.com/science/2023/12/cvs-rite-aid-walgreens-hand-out-medical-records-to-cops-without-warrants/" data-type="link" data-id="https://arstechnica.com/science/2023/12/cvs-rite-aid-walgreens-hand-out-medical-records-to-cops-without-warrants/">every major player in the retail pharmacy business has been handing over sensitive medical data to the government</a> without ever demanding to see an actual warrant. </p>
<blockquote>
<p><em>All of the big pharmacy chains in the US hand over sensitive medical records to law enforcement without a warrant—and some will do so without even running the requests by a legal professional, according to a congressional investigation.</em></p>
<p><em>[…]</em></p>
<p><em>They include the seven largest pharmacy chains in the country: CVS Health, Walgreens Boots Alliance, Cigna, Optum Rx, Walmart Stores, Inc., The Kroger Company, and Rite Aid Corporation. The lawmakers also spoke with Amazon Pharmacy.</em></p>
<p><em>All eight of the pharmacies said they do not require law enforcement to have a warrant prior to sharing private and sensitive medical records, which can include the prescription drugs a person used or uses and their medical conditions. Instead, all the pharmacies hand over such information with nothing more than a subpoena, which can be issued by government agencies and does not require review or approval by a judge.</em></p>
</blockquote>
<p>Three chains (CVS, Kroger, and Rite Aid) all told Congress they don’t even do a legal review of the subpoenas handed to them by government agencies. Instead, they apparently assume that if the government’s name is on it, it must be a valid request. The good news, I suppose, is that the other chains are at least involving their lawyers when it comes to data requests. </p>
<p>HIPAA (Health Insurance Portability and Accountability Act) — the medical record privacy law frequently misunderstood (and <a href="https://www.google.com/search?sca_esv=594127581&amp;rlz=1CALAYK_enUS1026&amp;sxsrf=AM9HkKm9ONokuP9V-HtSsqmBSeM4VENMRA:1703730315377&amp;q=%22hippa%22+site:facebook.com&amp;nfpr=1&amp;sa=X&amp;ved=2ahUKEwjgx_aBirGDAxVDEDQIHQzfDwgQvgUoAXoECAgQAw&amp;biw=1920&amp;bih=911&amp;dpr=1#ip=1" data-type="link" data-id="https://www.google.com/search?sca_esv=594127581&amp;rlz=1CALAYK_enUS1026&amp;sxsrf=AM9HkKm9ONokuP9V-HtSsqmBSeM4VENMRA:1703730315377&amp;q=%22hippa%22+site:facebook.com&amp;nfpr=1&amp;sa=X&amp;ved=2ahUKEwjgx_aBirGDAxVDEDQIHQzfDwgQvgUoAXoECAgQAw&amp;biw=1920&amp;bih=911&amp;dpr=1#ip=1">mis-acronymed</a>) by laymen, lawyers, and legislators alike — is of no use here. HIPAA only prevents medical information from being released without permission to private parties not specifically authorized to obtain it. Pretty much any request originating from law enforcement agencies is considered to fall under the “if required by law” exception, even if the requests haven’t actually been vetted by pharmacy company lawyers and/or may not be legitimate demands for sensitive medical info.</p>
<p>The “required by law” phrase is important here. Law enforcement agencies have their own legal interpretations of the Third Party Doctrine, but none of that matters much in the case of HIPAA. All it would take to prevent pharmacy chains from handing out this data without a warrant would be the federal Department of Health and Human Services (HHS) taking this out of the Third Party Doctrine’s hands and placing a presumption of privacy on it. </p>
<p>That’s the gist of the <a href="https://s3.documentcloud.org/documents/24243486/pharmacy-letter.pdf" data-type="link" data-id="https://s3.documentcloud.org/documents/24243486/pharmacy-letter.pdf">letter</a> [PDF] recently sent to HHS Secretary Xavier Becerra by Senator Ron Wyden, Rep. Pramila Jaypal, and Rep. Sara Jacobs. It cites a bit of courtroom and private company precedent to urge this situation along. </p>
<blockquote>
<p><em>We urge HHS to consider further strengthening its HIPAA regulations to more closely align them with Americans’ reasonable expectations of privacy and Constitutional principles. Pharmacies can and should insist on a warrant, and invite law enforcement agencies that insist on demanding patient medical records with solely a subpoena to go to court to enforce that demand. The requirement for a warrant is exactly the approach taken by tech companies to protect customer privacy. In 2010, after just one Federal Court of Appeals held that Americans have a reasonable expectation of privacy in their emails and that the 1986 Congressionally enacted law permitting disclosures of email pursuant to a subpoena was unconstitutional, all of the major free email providers — Google, Yahoo, and Microsoft — started insisting on a warrant before disclosing such data</em>.</p>
</blockquote>
<p>Looks pretty simple. All that’s needed is a change of policy, even if there’s no change in law. The problem with this, though, is that the head of the HHS has had plenty of time to change this policy to erect a higher standard for demands for customers’ information. The letter notes the legislators first informed Becerra of this potential issue in July, following <a href="https://www.techdirt.com/2022/07/05/how-the-dobbs-decision-will-lead-to-attacks-on-free-speech-or-why-democrats-need-to-stop-undermining-free-speech/" data-type="link" data-id="https://www.techdirt.com/2022/07/05/how-the-dobbs-decision-will-lead-to-attacks-on-free-speech-or-why-democrats-need-to-stop-undermining-free-speech/">the <em>Dobbs</em> decision</a> in June, hoping the HHS would erect more protections to prevent people from being prosecuted for obtaining birth control products. </p>
<p>The following months delivered confirmation of the legislators’ concerns. Now, it’s up to the HHS to move forward. While we wait to see whether <a href="https://en.wikipedia.org/wiki/Xavier_Becerra#California_Attorney_General_(2017%E2%80%932021)" data-type="link" data-id="https://en.wikipedia.org/wiki/Xavier_Becerra#California_Attorney_General_(2017%E2%80%932021)">a former </a><a href="https://www.techdirt.com/2019/03/08/california-attorney-general-doubles-down-threatening-journalists-possessing-convicted-cops-list/" data-type="link" data-id="https://en.wikipedia.org/wiki/Xavier_Becerra#California_Attorney_General_(2017%E2%80%932021)">prosecutor</a> is willing to elevate the privacy of Americans above the warrantless desires of law enforcement, we can at least be somewhat comforted by the fact that some of these companies are going to be a bit more transparent about their cooperation with the government. CVS, Walgreens, and Kroger have all promised to publish periodic reports about government requests for data. Amazon has gone one step further by notifying customers about government demands for their data.</p>
<p>There’s no reason the government shouldn’t need to secure a warrant to obtain this data. It’s protected by federal law against everyone else patients haven’t specifically granted permission to obtain. The government shouldn’t presume the existence of the Third Party Doctrine means customers’ prescription records are an open book. But it does and that needs to change, either through voluntary action or legislative mandate if the government can’t be talked into respecting the privacy of records most Americans likely assume are already covered by federal privacy protections.</p>

<p>
Filed Under: <a href="https://www.techdirt.com/tag/4th-amendment/" rel="tag">4th amendment</a>, <a href="https://www.techdirt.com/tag/drug-records/" rel="tag">drug records</a>, <a href="https://www.techdirt.com/tag/hipaa/" rel="tag">hipaa</a>, <a href="https://www.techdirt.com/tag/pharmacies/" rel="tag">pharmacies</a>, <a href="https://www.techdirt.com/tag/surveillance/" rel="tag">surveillance</a>, <a href="https://www.techdirt.com/tag/third-party-doctrine/" rel="tag">third party doctrine</a>
<br>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Linux Backdoor Attempt of 2003 (2013) (187 pts)]]></title>
            <link>https://freedom-to-tinker.com/2013/10/09/the-linux-backdoor-attempt-of-2003/</link>
            <guid>38805439</guid>
            <pubDate>Fri, 29 Dec 2023 14:42:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://freedom-to-tinker.com/2013/10/09/the-linux-backdoor-attempt-of-2003/">https://freedom-to-tinker.com/2013/10/09/the-linux-backdoor-attempt-of-2003/</a>, See on <a href="https://news.ycombinator.com/item?id=38805439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Josh <a href="https://freedom-to-tinker.com/blog/kroll/software-transparency-debian-openssl-bug/">wrote</a> recently about a serious security bug that appeared in Debian Linux back in 2006, and whether it was really a backdoor inserted by the NSA.   (He concluded that it probably was not.)</p>
<p>Today I want to write about another <a href="https://lwn.net/Articles/57135/">incident</a>, in 2003, in which someone tried to backdoor the Linux kernel.   This one was definitely an attempt to insert a backdoor.  But we don’t know who it was that made the attempt—and we probably never will.<br>
<span id="more-8995"></span><br>
Back in 2003 Linux used a system called BitKeeper to store the master copy of the Linux source code.  If a developer wanted to propose a modification to the Linux code, they would submit their proposed change, and it would go through an organized approval process to decide whether the change would be accepted into the master code.   Every change to the master code would come with a short explanation, which always included a pointer to the record of its approval.</p>
<p>But some people didn’t like BitKeeper, so a second copy of the source code was kept so that developers could get the code via another code system called CVS.  The CVS copy of the code was a direct clone of the primary BitKeeper copy.</p>
<p>But on Nov. 5, 2003, Larry McVoy <a href="https://lwn.net/Articles/57137/">noticed</a> that there was a code change in the CVS copy that did not have a pointer to a record of approval.  Investigation showed that the change had never been approved and, stranger yet, that this change did not appear in the primary BitKeeper repository at all.  Further investigation determined that someone had apparently broken in (electronically) to the CVS server and inserted this change.</p>
<p>What did the change do?   This is where it gets really interesting.  The change modified the code of a Linux function called wait4, which a program could use to wait for something to happen.  Specifically, it added these two lines of code:</p>
<pre>if ((options == (__WCLONE|__WALL)) &amp;&amp; (current-&gt;uid = 0))
        retval = -EINVAL;
</pre>
<p>[Exercise for readers who know the C programming language: What is unusual about this code?   Answer appears below.]</p>
<p>A casual reading by an expert would interpret this as innocuous error-checking code to make wait4 return an error code when wait4 was called in a certain way that was forbidden by the documentation.   But a really careful expert reader would notice that, near the end of the first line, it said “= 0” rather than “== 0”.   The normal thing to write in code like this is “== 0”, which tests whether the user ID of the currently running code (current-&gt;uid) is equal to zero, without modifying the user ID.  But what actually appears is “= 0”, which has the effect of setting the user ID to zero.</p>
<p>Setting the user ID to zero is a problem because user ID number zero is the “root” user, which is allowed to do absolutely anything it wants—to access all data, change the behavior of all code, and to compromise entirely the security of all parts of the system. So the effect of this code is to give root privileges to any piece of software that called wait4 in a particular way that is supposed to be invalid.  In other words … it’s a classic backdoor.</p>
<p>This is a very clever piece of work.  It looks like innocuous error checking, but it’s really a back door.  And it was slipped into the code outside the normal approval process, to avoid any possibility that the approval process would notice what was up.</p>
<p>But the attempt didn’t work, because the Linux team was careful enough to notice that that this code was in the CVS repository without having gone through the normal approval process.  Score one for Linux.</p>
<p>Could this have been an NSA attack? Maybe. But there were many others who had the skill and motivation to carry out this attack. Unless somebody confesses, or a smoking-gun document turns up, we’ll never know.</p>
<p>[Post edited (2013-10-09) to correct the spelling of Larry McVoy’s name.]</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the append-only btree works (182 pts)]]></title>
            <link>https://www.bzero.se/ldapd/btree.html</link>
            <guid>38805383</guid>
            <pubDate>Fri, 29 Dec 2023 14:38:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bzero.se/ldapd/btree.html">https://www.bzero.se/ldapd/btree.html</a>, See on <a href="https://news.ycombinator.com/item?id=38805383">Hacker News</a></p>
<div id="readability-page-1" class="page">


<p>
  Consider this 3-level b+tree. There are two levels of branch pages
  (the root is a branch page), and 5 leaf pages.  Data and keys are
  stored in the leaf pages.
</p>
<p>
  Leaf chaining, ie links between leaf pages for easy sequential
  access, is not supported as it would require the whole tree to
  be rewritten on each update.
</p>
<p>
  <a href="https://www.bzero.se/ldapd/how-the-btree-works.pdf" title="click for PDF version">
    <img src="https://www.bzero.se/ldapd/how-the-btree-works.png">
  </a>
</p>

<p>
  The pages are stored sequentially in the database file. Increasing
  page numbers means increasing file offsets. The meta page includes
  a pointer to the root page, a SHA1 hash, and statistics counters.
</p>
<p>
  When the file is opened it is scanned backwards page by page to
  find a valid meta page, and thus the root of the tree.
</p>
<p>
  <a href="https://www.bzero.se/ldapd/sequential-page-view.pdf" title="click for PDF version">
    <img src="https://www.bzero.se/ldapd/sequential-page-view.png">
  </a>
</p>

<p>
  When updating a value in leaf page 8, instead of changing the
  page in-place, a whole new page is appended to the file (here as
  page 12). Because the location of the page is changed, each parent
  page needs to be updated to point to the new locations.
</p>
<p>
  Leaf page 7 is not affected. A new root page is created
  as a copy of the previous root page, only the pointer to branch
  page 6 is updated to point to branch page 11.
</p>
<p>
  Any cursor still having a pointer to root page 9 can traverse the
  tree unaffected by the change. It will see a consistent snapshot
  of the database.  Dashed pages and pointers in the diagram are
  still there in the file, they are just not the last version.
</p>
<p>
  <a href="https://www.bzero.se/ldapd/updated-btree.pdf" title="click for PDF version">
    <img src="https://www.bzero.se/ldapd/updated-btree.png">
  </a>
</p>

<p>
  In the file, pages are written sequentially by appending new pages
  to the file. Already written pages are never modified.
</p>
<p>
  After each new generation of the tree is written, there is a meta
  page pointing to the new root.
</p>
<p>
  <a href="https://www.bzero.se/ldapd/flattened-btree-page-structure.pdf" title="click for PDF version">
    <img src="https://www.bzero.se/ldapd/flattened-btree-page-structure.png">
  </a>
</p>
<p>
  Changing one page (leaf page 8) resulted in 4 new pages being
  appended to the file. This wastes disk space, but writing consecutive
  pages to disk is more efficient than writing random locations.
  And there is no need for a transaction log, because <em>the
  database file <strong>is</strong> the transaction log</em>.
</p>


<!--p style="color: gray">
  Diagrams created in <a href="http://figr.bzero.se/">figr</a>.
</p-->




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Programming Courses for Experienced Coders? (298 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38804603</link>
            <guid>38804603</guid>
            <pubDate>Fri, 29 Dec 2023 13:23:59 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38804603">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38805841"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805841" href="https://news.ycombinator.com/vote?id=38805841&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>There is a general lack of advanced materials in software engineering. This is one area where market economy works against common good, unfortunately. People who have the knowledge and want to capitalise on it are highly incentivised to preparing beginner level materials and maybe a tiny bit to prepare the something for people who already have a bit of knowledge. After that, the number of people who are your potential target drops off sharply and you would have to increase the price dramatically. And it happens that people will not buy a $200 book even if it had $100k worth knowledge in it.<p>There are some positions available though. For example, I recently found Let over Lambda by Doug Hoyte. Excellent book if you are <i>that</i> kind of programmer.</p><p>Another problem with advanced materials is that frequently people are even unable to recognise them as advanced or valuable. It is easy to look at and evaluate things you have experience with, it is much more difficult to impossible to do the same with stuff that is beyond your experience (also called The Blub Paradox: <a href="https://www.paulgraham.com/avg.html" rel="nofollow">https://www.paulgraham.com/avg.html</a>).</p><p>Personally, I just read a lot. I try to keep an open mind and even if I don't agree fully with the contents of the book, I try to use the ideas as inspirations for my own thinking. You can read codebases written by other people and learn new ideas. Over time, you gather a library of solutions to problems and knowledge of when to and when not to apply them.</p><p>If you do enough of it, you will find useful knowledge in unusual places.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805885"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805885" href="https://news.ycombinator.com/vote?id=38805885&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>I've taken 2 of David Beazley's courses.[1] And, I highly recommend them. If you haven't seen some of his talks, he's very good at explaining things by building them from nothing.<p>I took 2 courses: "Rafting Trip" and "Write a Compiler". Both were awesome. The Rafting Trip took us through implementing the Raft consensus algorithm from scratch. And the "Write a Compiler" course had us build a small language using LLVM.</p><p>Both courses (but especially the Rafting trip one) were definitely for experienced programmers. In the courses I took, people generally had at least 5 years of professional work. And even still, there were a few people that really struggled to stay on pace in the course.</p><p>But at the end, most people had a (kinda) working Raft library or compiler!</p><p>[1] <a href="https://dabeaz.com/" rel="nofollow">https://dabeaz.com/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38807129"><td></td></tr>
            <tr id="38807056"><td></td></tr>
            <tr id="38807041"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38807041" href="https://news.ycombinator.com/vote?id=38807041&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>The ideas shared in the post replies are great. My approach has been more hands-on and puzzled together recently. I've been digging into harder problems on sites like leetcode to learn more math, and solidify some algorithm and data structure concepts. It has really helped me feel more confident and erase some of the lingering imposter syndrome around the algorithm-side of programming. A great guide that got me started on this was the tech interview handbook[1], which helped me dig into specific concepts instead of just randomly targeting. I've found my ability to review code has also improved through this, as I am picking up different libraries and concepts that I wouldn't have otherwise.<p>1. <a href="https://www.techinterviewhandbook.org/algorithms/study-cheatsheet/" rel="nofollow">https://www.techinterviewhandbook.org/algorithms/study-cheat...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805188"><td></td></tr>
                <tr id="38805356"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805356" href="https://news.ycombinator.com/vote?id=38805356&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>It is also very interesting to watch an accomplished computer scientist write code and solve problems.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38806923"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806923" href="https://news.ycombinator.com/vote?id=38806923&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>As others have said, expert-level material tend to not lend itself well to a book format.<p>Instead I find a lot of advance level knowledge is usually shared in tech blog posts and tech talks. The quality of these tends to vary a lot, so you need a bit of curation and due diligence. I myself found the videos from InfoQ very useful with 15 yoe (particularly in the software architecture track).</p><p>And if you want the really advanced stuff, you can also read papers. The barrier to entry is higher and sometimes is difficult to connect them to your everyday problems, but it doesn't get more cutting edge that than.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38807109"><td></td></tr>
            <tr id="38807062"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38807062" href="https://news.ycombinator.com/vote?id=38807062&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>CodeCrafters (YC S22) has an Elixir track comprising 2 challenges today<p>* Build your own BitTorrent</p><p>* Build your own Redis</p><p><a href="https://app.codecrafters.io/tracks/elixir">https://app.codecrafters.io/tracks/elixir</a></p><p>You get to recreate a simple version of these software from scratch, as a way to learn Elixir (or any of our other languages e.g Rust, Go, Haskell, etc)</p><p>(Disclaimer: I’m a co-founder)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805815"><td></td></tr>
                <tr id="38806036"><td></td></tr>
                <tr id="38806810"><td></td></tr>
                <tr id="38806836"><td></td></tr>
                              <tr id="38805336"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805336" href="https://news.ycombinator.com/vote?id=38805336&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>When writing a small application in Go I had great success asking Chat GPT specific questions. It helped me figure out which packages I needed to use and how to interact with them.<p>I understand that this might not fit your use-case, but it's worth a try. Just be aware that it tends to hallucinate APIs.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38805429"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805429" href="https://news.ycombinator.com/vote?id=38805429&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>If it does hallucinate, you can just paste it the latest documentation and the hallucination rate goes to nearly zero.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805524"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805524" href="https://news.ycombinator.com/vote?id=38805524&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Or it apologizes profusely, tells you you’re correct, and fails to fix its reasoning or the examples it gives you.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805697"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38805697" href="https://news.ycombinator.com/vote?id=38805697&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>I was trying to get it to write some Elixir code to handle Erlang B calculations and it just couldn't figure it out, but it was pretty confident with the wrong things it was printing out.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38806260"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38806260" href="https://news.ycombinator.com/vote?id=38806260&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>The rust borrow checker often requires too much critical thinking for ChatGPT, as well.<p>LLMs confer a tremendous productivity boost. You just have to understand their limits and know when it's faster to think through and write the solution yourself.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38805637"><td></td></tr>
                <tr id="38805994"><td></td></tr>
                <tr id="38807079"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_38807079" href="https://news.ycombinator.com/vote?id=38807079&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>No, because there is nothing I wanted it to do instead. Perhaps what I should have done was to change the system prompt to something like "You are a helpful assistant that will admit its mistakes but never apologise for them."</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38805755"><td></td></tr>
                  <tr id="38805586"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805586" href="https://news.ycombinator.com/vote?id=38805586&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>Does it actually consume the documentation? You could (haven’t tried in a while) also have ChatGPT tell you anything you wanted aslong as you stated “It’s been posted on Wikipedia after your last consumed date”.<p>I feel like telling it that it’s wrong and linking documentation is the same as referring to Wikipedia?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38805465"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805465" href="https://news.ycombinator.com/vote?id=38805465&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>&gt;Just be aware that it tends to hallucinate APIs.<p>It gives you nice little hints and a different perspective on your api design itself. I'd have a chat with chatgpt and sometimes I'd miss to share specific code and it just assumes or hallucinate on that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805624"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805624" href="https://news.ycombinator.com/vote?id=38805624&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>The person asking the question seems to be looking for a course or textbook with which to challenge themselves.<p>What you've described is the opposite of that.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38805945"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805945" href="https://news.ycombinator.com/vote?id=38805945&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>I understand. But as a long-time programmer I like to explore new programming languages or APIs by working on a small project. I start with a first prototype to get the feel of the language, before I look into extended documentation. 
Chat GPT helps with this use-case.<p>It's also more fun to have something which can be easily extended than to start from scratch.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38806201"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806201" href="https://news.ycombinator.com/vote?id=38806201&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>I don’t have any general course recommendations but the strange loop conference videos have been the most inspiring for me. I hope to attend soon, and a life goal of mine is to have something interesting enough to present there.<p>For Elixir, Dave Thomas’ coding gnome “elixir for programmers” course skips all the menial BS about “what is a string” etc and goes right into the meat and potatoes of leveraging the language correctly. I loved it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38806525"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38806525" href="https://news.ycombinator.com/vote?id=38806525&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Possibly mistaken but from what I understand 2023 was the last year of Strange Loop - I was hoping to attend 2024’s</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38806673"><td></td></tr>
            <tr id="38806549"><td></td></tr>
                  <tr id="38806741"><td></td></tr>
                  <tr id="38805096"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805096" href="https://news.ycombinator.com/vote?id=38805096&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>When I want to take the next step with a new language, I usually find a popular or interesting framework/library for that language, and I do a deep dive into the codebase.<p>Set it up for local development, then step through calls with a debugger, look at the whole call/request lifecycle, start to tinker with the subsystems..</p><p>It's a great way to see the real-world usage of all the core concepts you've been introduced to in the intro/learning courses or tutorials, and be exposed to more advanced patterns.</p><p>For Elixir, the obvious choice would be Phoenix if you're on the web app side of things..
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38806053"><td></td></tr>
                <tr id="38806992"><td></td></tr>
            <tr id="38806296"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38806296" href="https://news.ycombinator.com/vote?id=38806296&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>I took his course as well. It is indeed advanced. I certainly learned a fair amount from it. (coding for 15 years)</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38806064"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806064" href="https://news.ycombinator.com/vote?id=38806064&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>Besides most courses being beginner-focussed, there are at least two other related problems:<p>- Most advanced courses sell themselves dishonestly as beginner-friendly even if they aren't after the first couple of lessons. On the free market everyone is after every single potential customer, no matter what.</p><p>- Everything is stretched out so much that information density is annoyingly low. Again free market pays per page and minute and not value.</p><p>You might have more luck looking at resources produced free from these constraints and the best place I know is university courses. Still, good ones are hard to come by, but I learned a ton at uni I'd never had learned outside.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805705"><td></td></tr>
            <tr id="38805060"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805060" href="https://news.ycombinator.com/vote?id=38805060&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>The obvious “next step” is experiential, i.e., write complicated programs. Books about writing compilers, databases, operating systems, emulators, file systems, etc. are all useful.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805324"><td></td></tr>
                <tr id="38805851"><td></td></tr>
                <tr id="38806957"><td></td></tr>
            <tr id="38805923"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38805923" href="https://news.ycombinator.com/vote?id=38805923&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>It uses Java and C. Strictly speaking there's no reason you have to use either language, you can also use the design in the language of your choice (assuming sufficiently matching semantics, like C# or Kotlin instead of Java for Part 1, or a willingness to put in more legwork if you go further afield).</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38806057"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38806057" href="https://news.ycombinator.com/vote?id=38806057&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>"Computer Systems: A Programmer's Perspective" is a great introductory systems textbook on everything going on in a computer.<p>For more advanced C/C++ developers I can recommend "The Linux Programming Interface" - (<a href="https://man7.org/tlpi/" rel="nofollow">https://man7.org/tlpi/</a>). It is a GREAT compendium for writing code against the POSIX API. I have a (legal) copy of this book on all the computers I have access to.</p><p>"The Database Redbook" - (<a href="http://www.redbook.io/" rel="nofollow">http://www.redbook.io</a>) is a valuable source on database implementations.</p><p>"Compilers: Principles, Techniques, and Tools" (Dragon Book) is a great starting point. The book is out of print and but I think it should still hold up for most basic use-cases.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38806529"><td></td></tr>
            <tr id="38805371"><td></td></tr>
            <tr id="38806479"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806479" href="https://news.ycombinator.com/vote?id=38806479&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>Advent of Code (<a href="https://adventofcode.com/" rel="nofollow">https://adventofcode.com/</a>)<p>It's not a programming course per-se, but it's a great resource to master the skill of coding and problem solving.</p><p>It's just one part though, it won't teach you anything about architecturing a bigger system.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805552"><td></td></tr>
                <tr id="38805887"><td></td></tr>
                <tr id="38807083"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38807083" href="https://news.ycombinator.com/vote?id=38807083&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Any chance of a revised version one of these days? I, too, loved this book, but the ecosystem has moved far in the meantime &amp; many of the examples no longer compile.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38806470"><td></td></tr>
            <tr id="38806907"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806907" href="https://news.ycombinator.com/vote?id=38806907&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>computerenhance.com is a course focused on understanding how to measure and write high performance software. It's a great course targeting experienced programmers.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38805442"><td></td></tr>
            <tr id="38806334"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806334" href="https://news.ycombinator.com/vote?id=38806334&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>There are so many great books on specific domains but it depends on what you want to learn and you can then search for that. "Programming" is obviously too broad a category for experienced people.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38805093"><td></td></tr>
                <tr id="38805141"><td></td></tr>
                  <tr id="38805807"><td></td></tr>
            <tr id="38805740"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805740" href="https://news.ycombinator.com/vote?id=38805740&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Aside from raw theory, the best thing you can do is try to translate a project you have, maybe a toy project of reasonable complexity, and rewrite it idiomatically in the new language. Use all the preferred methods, semantics, and modeling tools of the target language. Use the language's docs and X in Y Minutes page.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805784"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805784" href="https://news.ycombinator.com/vote?id=38805784&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>But "which methods, semantics, and modeling tools are preferred" is probably what you're trying to learn.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805984"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805984" href="https://news.ycombinator.com/vote?id=38805984&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Unfortunately, that's what language docs are for. Like I said, you can get some theory. If you're learning functional programming, you can find books on lambda calculus and category theory and more. But ultimately you have to learn how to build good software, and there are scant few books about that out there. In the functional world, I know of two and they're both in Scheme. So the best approach tends to be feet-first into the fire using the language's docs, and hopefully the creator(s) has documents explaining theory and practice.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38805778"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805778" href="https://news.ycombinator.com/vote?id=38805778&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>I would not call myself experienced, but I often find myself glancing over documentation first (building a mental model and a map of what features are offered by this thing), then trying to build something, rather than sit through a slow paced course. This may or may not work for you.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38806720"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806720" href="https://news.ycombinator.com/vote?id=38806720&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Well, I don't know how advanced I am (except in age).  But I have found the best advanced training is the same as it was in college.  No book makes up for the late night hours.  I find other projects and offer to help -- there's always a shortage of coding labor (especially if it's free).  You learn what the book or course never discusses -- things like "What the heck was the person trying to do here?" and "Even God doesn't know how this code works!"  You know you're in trouble when you see "Oh God!  What an evil hack!  But it works... don't touch anything!" or "Good luck future Matt!  You KNEW this was a horrible job, but did you come back in time and stop me?"</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38805360"><td></td></tr>
            <tr id="38805242"><td></td></tr>
                <tr id="38805480"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805480" href="https://news.ycombinator.com/vote?id=38805480&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>I've been using it and it's been fun for learning rust. I've only done DNS and web server modules so far, but it has helped a lot in giving me goals that are achievable</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38805025"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805025" href="https://news.ycombinator.com/vote?id=38805025&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>My take is that there’s such variance in people’s skill levels and so it’s really hard to cater educational programming content. Personally, I’ve found getting introductory books/courses and skimming through it until you hit something that you don’t understand and then diving deeper into that bit.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805241"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805241" href="https://news.ycombinator.com/vote?id=38805241&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>It is interesting, though, that you can easily get intermediate training and coaching in basically any sport. But the thing you do for money? Take this very ad-hoc approach.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38805397"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805397" href="https://news.ycombinator.com/vote?id=38805397&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>People age out of being competitive athletes themselves and coaching is a natural way to stay involved with the sport.<p>Old coders who love coding don't have to do so indirectly.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805650"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805650" href="https://news.ycombinator.com/vote?id=38805650&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Concepts and excercises in sport don't change that frequently comparing to programming. Programming is very ad-hoc indeed, it has way more variables for the intermediate level so that the coach won't have enough time to digest the details.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38805346"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38805346" href="https://news.ycombinator.com/vote?id=38805346&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>I’m sure you can find individual coaches but the cost will exceed what most people are willing to spend or invest. Take executive coaches for example, they exist but from what I understand they’re largely private coaching and cost $$$.</span></p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="38806763"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38806763" href="https://news.ycombinator.com/vote?id=38806763&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>No, there's no such thing as "advanced". It's just that people "forgot" fundamentals of things, then they see those "fundamentals" as advanced.<p>I do think, teaching is hard. It basically turned "advanced" into "fundamentals" with correct teaching/learning approach.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805799"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805799" href="https://news.ycombinator.com/vote?id=38805799&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Yeah, I see this problem. And I found some solution for this issue. We need to promote coaching relationships between starters and experienced engineers.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38805847"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805847" href="https://news.ycombinator.com/vote?id=38805847&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>I don't know anything about learning Elixir, so, cannot help on that specific topic.<p>But, here's how I conceptually think about advancing one's understanding in programming.</p><p>First, you can aim for breadth or for depth of knowledge.  So, learning another language is, in itself a kind of "advance".  However, for depth, you'd usually want to pick a specific sub-discipline in programming and concentrate on that.  You will have better luck with choosing theoretical disciplines, because those usually are rooted in math, and so have longer history and more systematic approach.  The more "practical" aspects usually follow the arc of having an introductory course (at best) with the next learning stage being an "area of active research" (also, the intro course would typically be bad).</p><p>To give you an example: in college I became interested in regular languages.  So, I was looking to expand my knowledge on the subject.  Out of all things that I could dig up on regular languages two seemed most appealing: approximation of context-free grammars with regular languages and equivalence between generating functions and regular languages.  In a short while I realized that I don't have enough of mathematical background to go after the generative functions part, but the approximation part turn out to be fun and interesting.  I was able to dig up some papers and even try my hand in doing something with the concept.</p><p>You'd have similar success if you went after types in programming languages.  There are plenty of publications, and you will have multiple steps ahead of you before you run up the wall of "area of active research".  My journey down that path started with Benjamin C. Pierce's Types in Programming Languages.</p><p>Another direction you may consider is to try to generalize your knowledge.  For example, of programming languages.  In this regard, I find the book by Shriram Krishamurthy, Programming Languages: Application and Interpretation to be a good introduction to the theoretical side of crafting and evaluation of programming languages.</p><p>There are, also, unfortunately, some areas where a lot of programming work has been done, but very little learning material is available, and, especially nothing deep has been produced.  For example, if you want to go down the system programming route... there are books, that's true, but the level of generalization leaves a lot to be desired.  It's often boggled in all kinds of "practical advise" and very concrete examples based on Linux Kernel code long ago replaced by something else (or worse yet, but original Unix code etc.)</p><p>Or, even worse, if you consider fields like testing.  Or even GUI.  It's surprisingly common and yet surprisingly without much analysis or structure.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805683"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805683" href="https://news.ycombinator.com/vote?id=38805683&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>Well it's not popular (even though it ought to be), but Edsger Dijkstra's <i>A Discipline of Programming</i> is an approachable and informal (by the author's standards) look at solving non-trivial problems in a provably correct way. In fact the entire EWD archive[1] can be arranged into a course pretty readily, although you'll definitely want to skim or skip large chunks of it. Also some of the papers are just acerbic observations on life, which some people like and some don't.<p>And there's it's big brother <i>Predicate Calculus and Program Semantics</i> by Dijkstra and Scholten that more rigorously formalizes the same approach.</p><p>Dafny[2] is one approach out of Microsoft Research that attempts to provide automated tooling around some of those concepts.</p><p>All of the above are excellent places to start if you're interested in learning how to write better code with the imperative languages that you're actually going to use professionally.</p><p>[1] <a href="https://www.cs.utexas.edu/users/EWD/" rel="nofollow">https://www.cs.utexas.edu/users/EWD/</a></p><p>[2] <a href="https://dafny.org/" rel="nofollow">https://dafny.org/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38805017"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38805017" href="https://news.ycombinator.com/vote?id=38805017&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><p><span>I'm guessing that anything functional-language-focused aimed at a higher level would work. But I would also like to know the answer to this (and also am focused on Elixir).<p>Informally I just tend to write tight modules that loosely adhere to hexagonal architecture and are easy to unit-test.</p><p>I'm at a startup that is hiring, btw (I would be the one to reach out to). Seeking someone that is... probably like you, actually. Interested in Elixir but trying to aim higher as a self-motivated learner.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38805125"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38805125" href="https://news.ycombinator.com/vote?id=38805125&amp;how=up&amp;goto=item%3Fid%3D38804603"></a></center>    </td><td><br><div>
                  <p><span>Hi, nice to meet you. I'm an early adopter of Elixir (coming from Haskell/OCaml) and I will second another comment here, I've found the best way for me to learn Elixir is to be frequently building tooling that I either need or want, one habit I started was to migrate small projects I had previously over to Elixir, the community is a pretty good place to go for questions/inspiration. <a href="https://elixirforum.com/" rel="nofollow">https://elixirforum.com/</a></span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38805094"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2023 was the year that GPUs stood still (119 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/</link>
            <guid>38804502</guid>
            <pubDate>Fri, 29 Dec 2023 13:13:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/">https://arstechnica.com/gadgets/2023/12/2023-was-the-year-that-gpus-stood-still/</a>, See on <a href="https://news.ycombinator.com/item?id=38804502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/IMG_1072-800x533.jpeg" alt="2023 was the year that GPUs stood still">
      <figcaption><p>Andrew Cunningham</p></figcaption>  </figure>

  




<!-- cache hit 362:single/related:8e3b3346f5d3d88cd2ba442c8d5fbfe4 --><!-- empty -->
<p>In many ways, 2023 was a long-awaited return to normalcy for people who build their own gaming and/or workstation PCs. For the entire year, most mainstream components have been available at or a little under their official retail prices, making it possible to build all kinds of PCs at relatively reasonable prices without worrying about restocks or waiting for discounts. It was a welcome continuation of <a href="https://arstechnica.com/gaming/2022/12/2022-in-gpus-the-shortage-ends-but-higher-prices-seem-here-to-stay/">some GPU trends</a> that started in 2022. Nvidia, AMD, and Intel could release a new GPU, and you could consistently buy that GPU for roughly what it was supposed to cost.</p>
<p>That's where we get into how frustrating 2023 was for GPU buyers, though. Cards like the GeForce RTX 4090 and Radeon RX 7900 series launched in late 2022 and boosted performance beyond what any last-generation cards could achieve. But 2023's midrange GPU launches were less ambitious. Not only did they offer the performance of a last-generation GPU, but most of them did it for around the same price as the last-gen GPUs whose performance they matched.</p>
<h2>The midrange runs in place</h2>
<p>Not every midrange GPU launch will get us a <a href="https://arstechnica.com/gadgets/2016/07/nvidia-gtx-1060-review/">GTX 1060</a>—a card roughly 50 percent faster than its immediate predecessor and beat the previous-generation GTX 980 despite costing just a bit over half as much money. But even if your expectations were low, this year's midrange GPU launches have been underwhelming.</p>
<p>The worst was probably the GeForce RTX 4060 Ti, which sometimes struggled to beat the card it replaced at around the same price. The 16GB version of the card was particularly maligned since it was $100 more expensive but was only faster than the 8GB version in a handful of games.</p>
<p>The regular RTX 4060 was slightly better news, thanks partly to a $30 price drop from where the RTX 3060 started. The performance gains were small, and a drop from 12GB to 8GB of RAM isn't the direction we prefer to see things move, but it was still a slightly faster and more efficient card at around the same price. AMD's <a href="https://arstechnica.com/gadgets/2023/05/review-amds-269-rx-7600-is-a-good-1080p-card-but-the-rtx-4060-looms/">Radeon RX 7600</a>, <a href="https://arstechnica.com/gadgets/2023/09/amd-rx-7700-xt-and-7800-xt-review-closing-out-the-fine-i-guess-gpu-generation/">RX 7700 XT, and RX 7800 XT</a> all belong in this same broad category—some improvements, but generally similar performance to previous-generation parts at similar or slightly lower prices. Not an exciting leap for people with aging GPUs who waited out the GPU shortage to get an upgrade.</p>                                            
                                                        
<p>The best midrange card of the generation—and at $600, we're definitely stretching the definition of "midrange"—might be the GeForce RTX 4070, which can generally match or slightly beat the RTX 3080 while using much less power and costing $100 less than the RTX 3080's suggested retail price. That seems like a solid deal once you consider that the RTX 3080 was essentially unavailable at its suggested retail price for most of its life span. But $600 is still a $100 increase from the 2070 and a $220 increase from the 1070, making it tougher to swallow.</p>
<p>In all, 2023 wasn't the worst time to buy a $300 GPU; that dubious honor belongs to the depths of 2021, when you'd be lucky to snag a GTX 1650 for that price. But "consistently available, basically competent GPUs" are harder to be thankful for the further we get from the GPU shortage.</p>
<h2>Marketing gets more misleading</h2>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/GeForce-RTX-4060-Series-Press-Deck-12-2.jpeg" data-height="1080" data-width="1920" alt="1.7 times faster than the last-gen GPU? Sure, under exactly the right conditions in specific games."><img alt="1.7 times faster than the last-gen GPU? Sure, under exactly the right conditions in specific games." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/GeForce-RTX-4060-Series-Press-Deck-12-2-980x551.jpeg" width="980" height="551"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/GeForce-RTX-4060-Series-Press-Deck-12-2.jpeg" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> 1.7 times faster than the last-gen GPU? Sure, under exactly the right conditions in specific games.</p><p>Nvidia</p></figcaption></figure>
<p>If you just looked at <a href="https://arstechnica.com/gadgets/2023/05/nvidias-399-4060-ti-comes-with-no-price-hike-but-mild-performance-improvements/">Nvidia's early performance claims</a> for each of these GPUs, you might think that the RTX 40-series was an exciting jump forward.</p>
<p>But these numbers were only possible in games that supported these GPUs' newest software gimmick, DLSS Frame Generation (FG). The original DLSS and DLSS 2 improve performance by upsampling the images generated by your GPU, generating interpolated pixels that make lower-res image into higher-res ones without the blurriness and loss of image quality you'd get from simple upscaling. DLSS FG generates entire frames in between the ones being rendered by your GPU, theoretically providing big frame rate boosts without requiring a powerful GPU.</p>

<p>The technology is impressive when it works, and it's been successful enough to spawn hardware-agnostic imitators like <a href="https://arstechnica.com/gaming/2023/08/amds-fps-doubling-fsr-3-is-coming-soon-and-not-just-to-radeon-graphics-cards/">the AMD-backed FSR 3</a> and <a href="https://www.tomshardware.com/pc-components/gpus/intel-details-game-boosting-frame-generation-tech-that-applies-a-different-technique-extrass-uses-extrapolation-instead-of-amd-and-nvidias-approach-that-uses-interpolation">an alternate implementation from Intel</a> that's still in early stages. But it has notable limitations—mainly, it needs a reasonably high base frame rate to have enough data to generate convincing extra frames, something that these midrange cards may struggle to do. Even when performance is good, it can introduce weird visual artifacts or lose fine detail. The technology isn't available in all games. And DLSS FG also adds a bit of latency, though this can be offset with latency-reducing technologies like <a href="https://www.nvidia.com/en-us/geforce/technologies/reflex/">Nvidia Reflex</a>.</p>
<p>As another tool in the performance-enhancing toolbox, DLSS FG is nice to have. But to put it front-and-center in comparisons with previous-generation graphics cards is, at best, painting an overly rosy picture of what upgraders can actually expect.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Korea to welcome 'digital nomads' with new visa starting Jan. 1 (205 pts)]]></title>
            <link>https://koreajoongangdaily.joins.com/news/2023-12-29/national/kcampus/Korea-to-welcome-digital-nomads-with-new-visa-starting-Jan-1/1947155</link>
            <guid>38804452</guid>
            <pubDate>Fri, 29 Dec 2023 13:08:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://koreajoongangdaily.joins.com/news/2023-12-29/national/kcampus/Korea-to-welcome-digital-nomads-with-new-visa-starting-Jan-1/1947155">https://koreajoongangdaily.joins.com/news/2023-12-29/national/kcampus/Korea-to-welcome-digital-nomads-with-new-visa-starting-Jan-1/1947155</a>, See on <a href="https://news.ycombinator.com/item?id=38804452">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="doc">
                    
                    
                                            <div>              <p><img alt="A shared office space for digital nomads in Busan [SONG BONG-GEUN]" src="https://koreajoongangdaily.joins.com/data/photo/2023/12/29/89ecb553-cc16-43b4-903c-13a9f3f9e4e4.jpg">          <span></span>                  </p>                  <p>A shared office space for digital nomads in Busan [SONG BONG-GEUN]</p>              </div><p>        Foreigners will be able to work remotely in Korea for up to two years with the new workcation visa that will be created next year, also being able to bring their families along.  </p><p>   &nbsp;     The Ministry of Justice announced Friday that the government will start issuing the workcation visa starting Jan. 1.  </p><p>   &nbsp;     The workcation visa, also known as the digital nomad visa, will allow foreigners to work remotely in Korea for a company abroad for one year. Visa holders can extend their stay for another year, staying in Korea for up to two years.   </p><p>   &nbsp;     Applicants must be 18 or older and have worked in their current field for at least a year.   </p><p>   &nbsp;     The visa requires applicants to have an annual income double the amount of Korea's gross national income (GNI) per capita for the previous year.   </p><p>   &nbsp;     Korea's GNI per capita was 42.48 million won ($33,000) as of 2022, requiring those applying for the visa to have an annual income of 84.96 million won.   </p><p>   &nbsp;     Foreigners currently in Korea with a short-term tourist visa such as the B-1, B-2 and C-3 can transition into the workcation visa if they meet all the requirements.   </p><p>   &nbsp;     Visa holders will also be able to bring their spouse or children with the visa.  </p><p>   &nbsp;     Those who wish to obtain the visa can apply via Korean embassies in their respective country.   </p><p>   &nbsp;     The workcation visa doesn't allow holders to apply for a job within Korea. Foreigners will need other working visas to do so.  </p><p>   &nbsp;     "We hope the workcation visa will allow high-earning foreigners to stay in Korea's various regions and vitalize the local economy," the Justice Ministry said in a statement. "We hope the visa will be an opportunity for us to showcase our country and our culture."  </p><p> BY LEE TAE-HEE [lee.taehee2@joongang.co.kr]</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gentoo Linux Goes Binary (309 pts)]]></title>
            <link>https://www.gentoo.org/news/2023/12/29/Gentoo-binary.html</link>
            <guid>38804135</guid>
            <pubDate>Fri, 29 Dec 2023 12:12:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gentoo.org/news/2023/12/29/Gentoo-binary.html">https://www.gentoo.org/news/2023/12/29/Gentoo-binary.html</a>, See on <a href="https://news.ycombinator.com/item?id=38804135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
          

<p><a href="https://www.gentoo.org/news/2023/12/29/Gentoo-binary.html">
  <img src="https://www.gentoo.org/assets/img/news/2023/larry-packages.png" alt="Larry the cow with packages">
</a></p>

<p>You probably all know Gentoo Linux as your favourite source-based distribution.
Did you know that our package manager, Portage, already for years also has support for binary
packages, and that source- and binary-based package installations can be freely mixed?</p>

<p>To speed up working with slow hardware and for overall convenience, we’re now also offering
<strong>binary packages for download and direct installation</strong>! For most architectures, this is
limited to the core system and weekly updates - not so for <strong>amd64 and arm64</strong> however. There we’ve got a 
stunning <strong>&gt;20 GByte of packages</strong> on our mirrors, from LibreOffice to KDE Plasma and from Gnome to Docker.
Gentoo stable, updated daily. Enjoy! And <a href="https://www.gentoo.org/news/2023/12/29/Gentoo-binary.html">read 
on for more details!</a></p>

<!--more-->

<h2 id="questions--answers">Questions &amp; Answers</h2>

<h3 id="how-can-i-set-up-my-existing-gentoo-installation-to-use-these-packages">How can I set up my existing Gentoo installation to use these packages?</h3>

<p><a href="https://wiki.gentoo.org/wiki/Binary_package_quickstart">Quick setup instructions</a> for
the most common cases can be found in our wiki. In short, you need to create a configuration 
file in <code>/etc/portage/binrepos.conf/</code>.</p>

<p>In addition, we have a rather neat <a href="https://wiki.gentoo.org/wiki/Binary_package_guide">binary package guide</a> on
our Wiki that goes into much more detail.</p>

<h3 id="what-do-i-have-to-do-with-a-new-stage--new-installation">What do I have to do with a new stage / new installation?</h3>

<p>New stages already contain the suitable <code>/etc/portage/binrepos.conf/gentoobinhost.conf</code>. You are
good to go from the start, although you may want to replace the <code>src-uri</code> 
setting in there with an URI pointing to the corresponding directory on a 
<a href="https://www.gentoo.org/downloads/mirrors/">local mirror</a>.</p>

<blockquote>
  <p><code>$ emerge -uDNavg @world</code></p>
</blockquote>

<h3 id="what-compile-settings-use-flags--do-the-normal-amd64-packages-use">What compile settings, use flags, … do the ‘‘normal’’ amd64 packages use?</h3>

<p>The binary packages under <code>amd64/binpackages/17.1/x86-64</code> are compiled using
<code>CFLAGS="-march=x86-64 -mtune=generic -O2 -pipe"</code> and will work with any amd64 / x86-64 machine.</p>

<p>The available useflag settings and versions correspond to the stable packages
of the <code>amd64/17.1/nomultilib</code> (i.e., openrc), <code>amd64/17.1/desktop/plasma/systemd</code>,
and <code>amd64/17.1/desktop/gnome/systemd</code> profiles. This should provide fairly large
coverage.</p>

<h3 id="what-compile-settings-use-flags--do-the-normal-arm64-packages-use">What compile settings, use flags, … do the ‘‘normal’’ arm64 packages use?</h3>

<p>The binary packages under <code>arm64/binpackages/17.0/arm64</code> are compiled using
<code>CFLAGS="-O2 -pipe"</code> and will work with any arm64 / AArch64 machine.</p>

<p>The available useflag settings and versions correspond to the stable packages
of the <code>arm64/17.0</code> (i.e., openrc), <code>arm64/17.0/desktop/plasma/systemd</code>,
and <code>arm64/17.0/desktop/gnome/systemd</code> profiles.</p>

<h3 id="but-hey-thats-not-optimized-for-my-cpu">But hey, that’s not optimized for my CPU!</h3>

<p>Tough luck. You can still compile packages yourself just as before!</p>

<h3 id="what-settings-do-the-packages-for-other-architectures-and-abis-use">What settings do the packages for other architectures and ABIs use?</h3>

<p>The binary package hosting is wired up with the stage builds. Which
means, for about every stage there is a binary package hosting which 
covers (only) the stage contents and settings. There are no further plans 
to expand coverage for now. But hey, this includes the compiler (gcc or
clang) and the whole build toolchain!</p>

<h3 id="are-the-packages-cryptographically-signed">Are the packages cryptographically signed?</h3>

<p>Yes, with the <a href="https://www.gentoo.org/downloads/signatures/">same key as the stages</a>.</p>

<h3 id="are-the-cryptographic-signatures-verified-before-installation">Are the cryptographic signatures verified before installation?</h3>

<p>Yes, with one limitation (in the default setting).</p>

<p>Portage knows two binary package formats, XPAK (old) and GPKG (new). Only GPKG supports
cryptographic signing. Until recently, XPAK was the default setting (and it may still
be the default on your installation since this is not changed during upgrade, but only
at new installation).</p>

<p>The new, official Gentoo binary packages are all in GPKG format.
GPKG packages have their signature verified, and if this fails, installation is refused.
To avoid breaking compatibility with old binary packages, by default XPAK
packages (which do not have signatures) can still be installed however.</p>

<p>If you want to require verified signatures (which is something we strongly recommend), 
set <code>FEATURES="binpkg-request-signature"</code> in <code>make.conf</code>. Then, obviously, you can also
only use GPKG packages.</p>

<h3 id="i-get-an-error-that-signatures-cannot-be-verified">I get an error that signatures cannot be verified.</h3>

<p>Try running the Gentoo Trust Tool <code>getuto</code> as root.</p>

<blockquote>
  <p><code>$ getuto</code></p>
</blockquote>

<p>This should set up the required key ring with the Gentoo Release Engineering keys for
Portage.</p>

<p>If you have <code>FEATURES="binpkg-request-signature"</code> enabled in <code>make.conf</code>, then <code>getuto</code>
is called automatically before every binary package download operation, to make sure
that key updates and revocations are imported.</p>

<h3 id="ive-made-binary-packages-myself-and-portage-refuses-to-use-them-now">I’ve made binary packages myself and portage refuses to use them now!</h3>

<p>Well, you found the side effect of <code>FEATURES="binpkg-request-signature"</code>.
For your self-made packages you will need to set up a signing key and have that key
trusted by the anchor in <code>/etc/portage/gnupg</code>.</p>

<p>The <a href="https://wiki.gentoo.org/wiki/Binary_package_guide">binary package guide</a> on
our Wiki will be helpful here.</p>

<h3 id="my-download-is-slow">My download is slow.</h3>

<p>Then pretty please use a <a href="https://www.gentoo.org/downloads/mirrors/">local mirror</a>
instead of downloading from University of Oregon. You can just edit the URI 
in your <code>/etc/portage/binrepos.conf</code>. And yes, that’s safe, because of the 
cryptographic signature.</p>

<h3 id="my-portage-still-wants-to-compile-from-source">My Portage still wants to compile from source.</h3>

<p>If you use useflag combinations deviating from the profile default, then
you can’t and won’t use the packages. Portage will happily mix and match though
and combine binary packages with locally compiled ones. Gentoo still remains
a source-based distribution, and we are not aiming for a full binary-only 
installation without any compilation at all.</p>

<h3 id="can-i-use-the-packages-on-a-merged-usr-system">Can I use the packages on a merged-usr system?</h3>

<p>Yes. (If anything breaks, then this is a bug and <a href="https://bugs.gentoo.org/">should be reported</a>.)</p>

<h3 id="can-i-use-the-packages-with-other-older-or-newer-profile-versions">Can I use the packages with other (older or newer) profile versions?</h3>

<p><strong>No.</strong> That’s why the <code>src-uri</code> path contains, e.g.,  “17.1”.
<strong>When there’s a new profile version, we’ll also provide new, separate package directories.</strong></p>

<h3 id="any-plans-to-offer-binary-packages-of-amd64-">Any plans to offer binary packages of ~amd64 ?</h3>

<p>Not yet. This would mean a ton of rebuilds… If we offer it one day, it’ll 
be at a separate URI for technical reasons.</p>

<p>The advice for now is to stick to stable as much as possible, and locally
add in <code>package.accept_keywords</code> whatever packages from testing you want to use.
This means you can still use a large amount of binary packages, and just
compile the rest yourself.</p>

<h3 id="i-have-found-a-problem-with-portage-or-a-specific-package">I have found a problem, with portage or a specific package!</h3>

<p>Then please <strong>ask for advice</strong> (on IRC, the forums, or a mailing list) and/or 
<a href="https://bugs.gentoo.org/"><strong>file a bug!</strong></a></p>

<p>Binary package support has been tested for some time, but with many more people using
it edge cases will certainly occur, and quality bug reports are always appreciated!</p>

<h3 id="any-pretty-pictures">Any pretty pictures?</h3>

<p>Of course! Here’s the amount of binary package data in GByte for each architecture…</p>

<p><img src="https://www.akhuettel.de/~huettel/plots/mirrors/binpackages-month.png" alt="package data over time"></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disney, Warner, Comcast, and Paramount are contemplating cuts, possible mergers (118 pts)]]></title>
            <link>https://arstechnica.com/culture/2023/12/its-shakeout-time-as-losses-of-netflix-rivals-top-5-billion/</link>
            <guid>38804133</guid>
            <pubDate>Fri, 29 Dec 2023 12:12:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/culture/2023/12/its-shakeout-time-as-losses-of-netflix-rivals-top-5-billion/">https://arstechnica.com/culture/2023/12/its-shakeout-time-as-losses-of-netflix-rivals-top-5-billion/</a>, See on <a href="https://news.ycombinator.com/item?id=38804133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Not so great for consumers    —
</h4>
            
            <h2 itemprop="description">Disney, Warner, Comcast, and Paramount are contemplating cuts, possible mergers.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/comcast-peacock-hiding-800x450.jpg" alt="An NBC peacock logo is on the loose and hiding behind the corner of a brick building.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 359:single/related:e82a7f6d04a89e1d73d13a5a52a6186a --><!-- empty -->
<p>The world’s largest traditional entertainment companies face a reckoning in 2024 after losing more than $5 billion in the past year from the streaming services they built to compete with Netflix.</p>
<p>Disney, Warner Bros Discovery, Comcast and Paramount—US entertainment conglomerates that have been growing ever larger for decades—are facing pressure to shrink or sell legacy businesses, scale back production and slash costs following billions in losses from their digital platforms.</p>
<p>Shari Redstone, Paramount’s billionaire controlling shareholder, has effectively put the company on the block in recent weeks. She has held talks about selling the Hollywood studio to Skydance, the production company behind <i>Top Gun: Maverick</i>, people familiar with the matter say.</p>
<p>Paramount chief executive Bob Bakish also discussed a possible combination over lunch with Warner CEO David Zaslav in mid-December. In both cases the discussions were said to be at an early stage and people familiar with the talks cautioned that a deal might not materialize.</p>
<p>Beyond their streaming losses, the traditional media groups are facing a weak advertising market, declining television revenues and higher production costs following the Hollywood strikes.</p>
<p>Rich Greenfield, an analyst at LightShed Partners, said Paramount’s deal discussions were a reflection of the “complete and utter panic” in the industry.</p>
<p>“TV advertising is falling far short, cord-cutting is continuing to accelerate, sports costs are going up and the movie business is not performing,” he said. “Everything is going wrong that can go wrong. The only thing [the companies] know how to do to survive is try to merge and cut costs.”</p>                                            
                                                        
<p>But as the traditional media owners struggle, Netflix, the tech group that pioneered the streaming model over a decade ago, has emerged as the winner of the battle to reshape video distribution.</p>
<p>“For much of the past four years, the entertainment industry spent money like drunken sailors to fight the first salvos of the streaming wars,” analyst Michael Nathanson wrote in November. “Now, we are finally starting to feel the hangover and the weight of the unpaid bar bill.”</p>
<p>For companies that have been trying to compete with Netflix, Nathanson added, “the shakeout has begun.”</p>
<p>After a bumpy 2022, Netflix has set itself apart from rivals—most notably by being profitable. Earnings for its most recent quarter soared past Wall Street’s expectations as it added 9 million new subscribers—the strongest rise since early 2020, when Covid-19 lockdowns led to a jump.</p>
<p>“Netflix has pulled away,” says John Martin, co-founder of Pugilist Capital and former chief executive of Turner Broadcasting. For its rivals, he said, the question is “how do you create a viable streaming service with a viable business model? Because they’re not working.”</p>
<p>The leading streaming services aggressively raised prices in 2023. Now, analysts, investors and executives predict that consolidation could be ahead next year as some of the smaller services combine or bow out of the streaming wars.</p>
<p>Warner, home to HBO and the Warner Bros movie studio, has made a small profit at its US streaming services this year, in part by raising prices, aggressively culling some series and licensing others to Netflix. However, this has come at a price: Warner lost more than 2 million streaming subscribers in its two most recent quarters.</p>
<p>The company, which merged with rival Discovery last year, has long been rumored as a potential takeover candidate, with Comcast seen as the most likely buyer. But Zaslav in November hinted that his group wanted to be an acquirer instead of a target.</p>                                            
                                                        
<p>“There are a lot of . . . excess players in the market. So, this will give us a chance not only to fight to grow in the next year, but to have the kind of balance sheet and the kind of stability . . . that we could be really opportunistic over the next 12 to 24 months,” he said on an earnings call.</p>
<p>The terms of the Warner-Discovery merger barred the group from dealmaking for two years. That period expires on April 8.</p>
<p>Disney, the largest traditional media company, is in the midst of a gutting restructuring that has featured 7,000 job cuts and attacks from activist investors. It lost more than $1.6 billion from its streaming businesses in the first nine months of 2023, during which its Disney+ service gained 8 million subscribers. The company says it will turn a profit in streaming in late 2024.</p>
<p>Bob Iger, Disney chief executive, this year openly pondered whether some of its assets still fit within the company, prompting speculation that he was considering disposals. But no deals emerged, leading some investors to conclude there is little appetite among private equity or tech companies for acquiring legacy businesses.</p>
<p>Paramount’s shares have risen almost 40 percent since early November as sale speculation mounted. The stock rose sharply after the Skydance talks were reported, but both Paramount and Warner shares fell after news of their discussions came to light.</p>
<p>Analysts said the two companies’ high debt levels were an immediate concern for investors. “We suspect investors will focus on pro forma leverage above all else,” Citi analysts wrote in a note last week. They estimated that an all-stock combination of Warner and Paramount could yield at least $1 billion of synergies.</p>
<p>But Greenfield said merging two companies with lossmaking streaming services and large portfolios of declining television assets was not the answer to their problems.</p>
<p>“The right answer should be, let’s stop trying to be in the streaming business,” he said. “The answer is, let’s get smaller and focused and stop trying to be a huge company. Let’s dramatically shrink.”</p>
<p><em><a href="https://www.ft.com/">© 2023 The Financial Times Ltd</a>. <a href="https://www.ft.com/">All rights reserved</a>. Not to be redistributed, copied, or modified in any way.</em></p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Copyright is not a moral right, it's a monetization strategy (203 pts)]]></title>
            <link>https://twitter.com/Plinz/status/1740597001652461895</link>
            <guid>38803614</guid>
            <pubDate>Fri, 29 Dec 2023 10:37:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/Plinz/status/1740597001652461895">https://twitter.com/Plinz/status/1740597001652461895</a>, See on <a href="https://news.ycombinator.com/item?id=38803614">Hacker News</a></p>
Couldn't get https://twitter.com/Plinz/status/1740597001652461895: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Salt and salary: Were Roman soldiers paid in salt? (2017) (130 pts)]]></title>
            <link>http://kiwihellenist.blogspot.com/2017/01/salt-and-salary.html</link>
            <guid>38803589</guid>
            <pubDate>Fri, 29 Dec 2023 10:34:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://kiwihellenist.blogspot.com/2017/01/salt-and-salary.html">http://kiwihellenist.blogspot.com/2017/01/salt-and-salary.html</a>, See on <a href="https://news.ycombinator.com/item?id=38803589">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
A few weeks ago, <a href="http://kiwihellenist.blogspot.co.nz/2016/12/salting-earth.html">we looked at</a> myths to do with ploughing over cities and salting the earth. Today we’re looking at a kind of companion myth. The basic idea is that Roman soldiers were paid in salt, or received an allowance of ‘salt money’.</p><p>
A few other ancillary myths tend to come along with it too. Take a look at these gloriously mangled pieces of misinformation:</p><p>
(The blog post, in particular, has been uncritically copied, paraphrased, and plagiarised on many other parts of the web -- like <a href="https://termcoord.wordpress.com/2012/06/29/salt-salary/">this page</a><span> offered up by the European Parliament’s Terminology Coordination Unit.)</span><br>
<span><br></span>
First, the accurate bits. (1) The English word ‘salary’ does indeed come from Latin <i>salarium</i> ‘stipend, money allowance’. (2) <i>Salarium</i> does indeed appear to be linked to <i>sal</i> ‘salt’, via the adjective <i>salarius</i> ‘pertaining to salt’. And there the accuracy ends.</p><p>
Here’s the simplest form of the myth.</p><p>
Pure fantasy. There isn’t the tiniest scrap of evidence to suggest this. At all, to any extent, ever.</p><p>

The allure of this myth comes simply from the link between <i>salarius</i> and <i>salarium</i>. Naturally everyone wants to have the true explanation of what exactly the link is. Unfortunately no ancient source tells us one. And so we end up in the situation where people invent explanations for themselves.</p><p>

Folks who propagate this myth don’t usually try to cite sources, but when people do go looking for sources, they end up drawn to two pieces of ancient testimony. First is the 1st century CE writer Pliny the Elder:</p><div><p>
And second, testimony about state taxes on salt. For example, the historian Livy reports how the Roman censors imposed a new tax in 204 BCE:</p><blockquote>
<i>vectigal etiam novum ex salaria annona statuerunt. sextante sal et Romae et per totam Italiam erat; Romae pretio eodem, pluris in foris et
conciliabulis et alio alibi pretio praebendum locaverunt. id vectigal commentum alterum ex censoribus satis credebant ... inde Salinatori Livio inditum cognomen.</i></blockquote>
<blockquote>
(The censors) also imposed a new tax on the annual salt production. Salt cost a sixth of an <i>as</i> in Rome and throughout Italy; they set it to be offered at the same price in Rome, but more in town squares and marketplaces, and at other rates in other places. It was widely believed that just one of the two censors devised this tax ... As a result (the censor) Marcus Livius was given the nickname ‘salt-dealer’.<br>

</blockquote><p>
Elsewhere Cato the Elder is quoted as talking about <i>salinatores aerarii</i>, treasurers of the salt taxes, as a specialised post in the 190s BCE (<span>reported in Servius auctus, commentary on </span><i>Aeneid</i><span> 4.244). </span>These passages, along with Pliny, are close as we get to a link between salt and money in any extant Roman sources.</p><p>

The trouble with citing Pliny as a source for the myth is of course that Pliny doesn’t say anything of the kind. The problem is exacerbated by Wikipedia, which bald-facedly re-writes Pliny, and has been quoted very widely:</p><blockquote>
the Roman historian Pliny the Elder, who stated as an aside in his Natural History’s discussion of sea water, that ‘[I]n Rome...the soldier’s pay was originally salt and the word salary derives from it...’.<br>

</blockquote><p>
This is a mistranslation, just to be clear. And this wording doesn’t even appear in the linked source. And Pliny isn’t writing about sea water, but about salt itself. None of that has stopped this fake quotation being repeated in countless books and websites.</p><p><i>Note, 18 Jan.:</i> this error, and the other Wikipedia excerpt quoted above, have since been corrected. However, some other parts of the articles are still inaccurate: see below.</p>
<table><tbody>
<tr><td><a href="http://3.bp.blogspot.com/-z0KgpZsmySA/WG2x0C8T4JI/AAAAAAAAFi4/UMVdPAYMxG83Ifv_9qmorh3ujPTa2yyCACK4B/s1600/Salt_refinery_CanaryIslands.jpg" imageanchor="1"><img height="300" src="https://3.bp.blogspot.com/-z0KgpZsmySA/WG2x0C8T4JI/AAAAAAAAFi4/UMVdPAYMxG83Ifv_9qmorh3ujPTa2yyCACK4B/s400/Salt_refinery_CanaryIslands.jpg" width="400"></a></td></tr>
<tr><td>Brine refinery at Fuerteventura, Canary Islands (source: <a href="http://fuerteventurapics.blogspot.com/">tourist blog</a>). Ancient Roman <i>salinae</i> worked in more or less the same way: see Pliny <i>Nat. hist.</i> <a href="https://archive.org/stream/naturalhistory08plinuoft#page/426/mode/2up">31.81-83</a>.</td></tr>
</tbody></table><p>
If you take a global view, of course you’re bound to find <i>some</i> times and places where salt could act as a means of storing value and facilitating exchange. The most famous example is Ethiopia in the modern era. Here’s how it’s reported by Ray’s <i>Travels</i>, a classic 17th century piece of travel writing:</p><blockquote>
In trading, they make no use of coined money, as the <i>Europeans</i> do, but their money are pieces of fifteen or twenty <i>Pics</i> of cloth, gold, which they give by weight, and a kind of salt, which they reduce into little square pieces like pieces of soap, and these pass for money. They cut out that salt upon the side of the Red Sea, five or six days journeys from <i>Dangala</i>, as you go from <i>Cairo</i>, and the places where they make it are called <i>Arbo</i>.
<p>
-- John Ray, <i>A collection of curious travels and voyages</i>, vol. 2 (1st ed. 1693, 2nd ed. 1705), <a href="https://archive.org/stream/travelsthroughlo02rayj#page/486/mode/2up">1738 printing, p. 486</a></p>
</blockquote>
<p><a href="https://books.google.co.nz/books?id=RhejBQAAQBAJ&amp;pg=PA113#v=onepage&amp;q&amp;f=false">This 1949 book</a>, <a href="https://books.google.co.nz/books?id=6u8rBgAAQBAJ&amp;pg=PA299#v=onepage&amp;q&amp;f=false">this 1977 essay</a>, and <a href="https://books.google.co.nz/books?id=jX7-0ROBfyIC&amp;pg=PA54#v=onepage&amp;q&amp;f=false">this 1994 book</a> report that salt bars called <i>amoléh</i> continued to serve as an important medium for exchange -- one among many; others included Maria Theresa thalers, clothing, iron, gold, and cattle -- all the way up until the beginning of the 20th century. Reportedly the chief source of Ethiopian salt bars was the <a href="https://en.wikipedia.org/wiki/Afar_Triangle" rel="nofollow">Afar depression</a>, next to the Red Sea, a region that includes present-day Djibouti as well as slivers of Ethiopia, Eritrea, and Somalia.</p><p>

Just bear in mind that this has <i>nothing at all</i> to do with Roman soldiers. The fact that salt could mediate exchange in 17th-19th century Ethiopia has no bearing on ancient Rome. Salt money might be a plausible thing in and of itself, but we have absolutely no reason to imagine salt currency in Rome. It’s just that when you go hunting for something specific across the whole of human history, you’re likely to find it.</p><p>

A few more examples. <a href="https://books.google.co.nz/books?id=Ydo_9TEmuVQC&amp;pg=PA285#v=onepage&amp;q&amp;f=false">This 2013 book</a> claims that salt has also been used as ‘money’ (the word is tendentious: ‘a medium for trade’ and ‘money’ are not the same thing) in China, pre-Columbian Mexico, Borneo, and elsewhere. A person who uploaded <a href="https://commons.wikimedia.org/wiki/File:Currency_of_salt_and_fiber,_Angola,_collected_before_1901_-_Royal_Ontario_Museum_-_DSC09598.JPG" rel="nofollow">this photo</a> to Wikimedia.org claims it is a sample of salt currency from early 20th century Angola, held at the Royal Ontario Museum. And <a href="https://en.wikipedia.org/w/index.php?title=History_of_salt&amp;oldid=752687729#Cities_and_wars" rel="nofollow">Wikipedia alleges</a> that American soldiers were paid in brine during the War of 1812. This last one appears to be completely fictional, like the Roman case: apparently it’s some kind of distant distortion of the British salt embargo during the war, and the development of several important brine refineries in the USA throughout the 1800s-1810s.</p><hr>
<p>
‘Roman soldiers were paid in salt’ may be the simplest form of the myth, but it’s also a secondary form. I’ve done some searching around in Google Books with date constraints, and that seems to indicate that people first started writing about the idea around the 1860s (<a href="https://books.google.co.nz/books?id=omMWAQAAIAAJ&amp;dq=%22roman%20soldiers%20received%20part%20of%20their%20pay%20in%20salt%22&amp;pg=PA95#v=onepage&amp;q=%22roman%20soldiers%20received%20part%20of%20their%20pay%20in%20salt%22&amp;f=false">here</a>, for example).</p><p>

The older, primary form of the myth is that soldiers were given ‘salt money’, that is, a monetary allowance for buying salt. This, too, is a modern invention. It isn’t nearly as daft as ‘soldiers were paid in salt’, but it’s still only a conjecture, unsupported by any ancient testimony.</p><p>

The phrase ‘salt money’, or in Latin <i>salarium argentum</i>, is an invention of 18th and 19th century Latin dictionaries. The phrase was coined by dictionary-writers as their <i>best guess</i> for how <i>salarium</i> ‘salary’ came from <i>salarius</i> ‘pertaining to salt’. Here’s one of the two standard Latin-English dictionaries, Lewis &amp; Short, on the subject:</p><blockquote>
<b>B. sălārĭum,</b> ii, <i>n.</i> (sc. argentum; cf.: calcearium, congiarium, vestiarium, etc.); orig., <i>the money given to the soldiers for salt, salt-money;</i> hence, post-Aug. (v. Dio Cass. 52, 23, and 78, 22), in gen., <i>a pension, stipend, allowance, salary</i> (cf.: honorarium, annuum, merces, stipendium)
<p>
-- Lewis &amp; Short, <i>A Latin dictionary</i> (1879), p. 1618, <a href="https://archive.org/stream/LewisShortLatnDiccionary#page/n1631/mode/1up">‘Salarius’<span id="goog_1023461061"></span></a></p>
</blockquote><p>
The key bit is in the first line. The supposed meaning ‘salt money’ (‘sc[ilicet] argentum’, i.e. ‘with <i>argentum</i> implied’) is not actually attested anywhere. It’s inferred by analogy with some other, real, expressions: <i>calcearium</i> (‘shoe money’, from <i>calceus</i> ‘shoe’); <i>congiarium</i> (‘distribution of largesse’, from <i>congius</i> ‘half an amphora’s worth’); and <i>vestiarium</i> (‘clothing money’, from <i>vestis</i> ‘clothing’). Unlike <i>salarium argentum</i>, these terms actually do appear in various ancient sources, with the correct meanings.</p><p>

Lewis &amp; Short didn’t invent the conjecture: it also appears in the older Latin-German dictionaries of <a href="https://archive.org/stream/bub_gb_nQEtAAAAYAAJ_2/bub_gb_nQEtAAAAYAAJ#page/n231/mode/2up">Freund (1834)</a> and <a href="https://archive.org/stream/ausfhrlichesun05sche#page/4828/mode/2up">Scheller (1804)</a>. It seems to have its origin in the 1st edition of Facciolati and Forcellini’s <i>Totius Latinitatis lexicon</i> (‘dictionary of the entire Latin language’):</p><blockquote>
<i>Salarium, ii</i> ...: proprie est annona salis, quae olim dabatur militibus.</blockquote>
<blockquote>
‘salary’ ...: strictly, the annual salt revenue, which was once given to soldiers.
<p>
-- <i>Totius Latinitatis lexicon</i> (1st edition, 1771), vol. 4 p. 15, <a href="https://archive.org/stream/bub_gb_d-wTPUxIaC8C#page/n18/mode/1up">‘Salarius’</a></p>
</blockquote><p>
This was already a very muddled rendering of the evidence. Facciolati-Forcellini go on to cite Pliny, though as we have seen Pliny doesn’t actually say this. It looks like what’s happened is that they've conflated the Pliny passage with the Livy passage. Livy referred to a tax on the <i>salaria annona</i> ‘annual salt production’. <i>Annona</i> can mean either ‘annual production’ or ‘annual revenue’, and Facciolati-Forcellini have taken Livy’s phrase and used it with the other meaning: <i>annona salis</i> ‘annual salt revenue’. Later on, Scheller and Freund realised that Pliny didn’t say what Facciolati-Forcellini claimed he did, but they liked the idea so they instead supported it with the analogies of ‘shoe money’, ‘clothing money’, and so on. And the idea stuck.</p><p>

All these dictionaries are engaging in conjecture. No ancient source ever actually uses <i>salarium</i> to mean ‘salt allowance’. It’s a guess. It isn’t a terrible guess, but it’s still a guess. One thing that weighs heavily against it is that even Pliny, who’s trying to link <i>salarium</i> to ‘salt’ as closely as he can, doesn’t try to get away with inventing ‘salt money’.</p><p>

The current standard, the <i>Oxford Latin dictionary</i> (1968), very properly avoids taking any view on the question. It just states that <i>salarium</i> comes from <i>sal</i>. Unlike the older dictionaries, it doesn’t make any inferences about how or why the two words are related.</p><p>

‘Salt money’ certainly isn’t as ridiculous as the idea of paying soldiers in salt -- it does have parallels that make it at least a <i>reasonable</i> conjecture -- but there’s still no evidence for it.</p><table><tbody>
<tr><td><a href="http://2.bp.blogspot.com/-8FpTc5rKA44/WHQ1faDOEvI/AAAAAAAAFjo/Wwh79M_zeAYvvV70Nam8CwKj1yjuSJAUQCK4B/s1600/Salt_refinery_France.jpg" imageanchor="1"><img height="300" src="https://2.bp.blogspot.com/-8FpTc5rKA44/WHQ1faDOEvI/AAAAAAAAFjo/Wwh79M_zeAYvvV70Nam8CwKj1yjuSJAUQCK4B/s400/Salt_refinery_France.jpg" width="400"></a></td></tr>
<tr><td>Sea water refinery in western France (source: <a href="http://isslr.org/salt-of-the-earth/" rel="nofollow">ISSLR.org</a>)</td></tr>
</tbody></table><p>
I don’t have a perfect explanation for how the Latin word for ‘salty’ gave rise to the word for ‘salary’. Of course I don’t: that’s why we have this myth floating around. We <i>don’t have the evidence</i> to settle on a single explanation.</p><p>

As I said above, ‘salt allowance’ isn’t a terrible guess. But I strongly suspect it’s much more metaphorical than that. Compare how the Greek word for a salary was <i>opsōnion</i>, literally ‘(money) for buying <i>opson</i>’, where <i>opson</i> means ‘fish, relish, sauce’. That doesn’t mean Greek workers were given a ‘fish allowance’: it means that there was a generalised idea that wages went on traded goods <i>like</i> fish, and not on things like barley which land-owners would grow for themselves. Similarly, in Rome, grain allowances were a common thing; it could easily make sense to interpret <i>salarium</i> as ‘everything-else-money’.</p><p>

This interpretation is less specific, slightly metaphorical, and it’s still just a conjecture. But I’d say it’s more plausible, and certainly a more economical explanation, than inventing a specialised category of wages out of thin air.</p><hr>
<p>
We still haven’t dealt with this:</p><blockquote>
A soldier’s salary was cut if he ‘was not worth his salt,’ a phrase that came into being because the Greeks and Romans often bought slaves with salt.<br>

</blockquote><p>
Oh dear oh dear. This one has made it <a href="https://en.wikipedia.org/w/index.php?title=History_of_salt&amp;oldid=752687729#Ancient_world" rel="nofollow">into Wikipedia too</a> (‘soldiers who did their job well were “worth their salt”’). Unfortunately for <i>Time</i> and for the thousands of people who have repeated this idea, the phrase ‘worth one’s salt’ is definitely not Roman. It is first attested in the 1830s (<a href="http://www.etymonline.com/index.php?term=SALT">Etymonline.com</a>; for sources, see OED under ‘salt’). The thing about buying slaves with salt is fictional too.</p><p>

And then there’s ‘salt of the earth’, which comes up in the 2009 blog post I quoted at the start. I mentioned this in <a href="http://kiwihellenist.blogspot.co.nz/2016/12/salting-earth.html">my previous post</a> on ‘salting the earth’. It’s nothing to do with Roman soldiers: it’s biblical, from <a href="https://www.biblegateway.com/passage/?search=Matthew+5%3A13&amp;version=NRSVA">Matthew 5:13</a> in the New Testament. This means that (1) it isn’t a Roman phrase, but at closest, Helleno-Christian; (2) it’s later than Pliny’s mention of <i>salarium</i>; (3) it’s about using salt as a fertiliser as much as anything else, as I argued in my earlier post.</p><p>
Salt was certainly a significant strategic resource in antiquity. But calling it ‘prized and valuable’ is silly. Yes, it’s the single most common preservative agent ever used, and it is by far the most common seasoning. The Roman salt trade was under state control from the earliest times (see e.g. Livy <a href="https://archive.org/stream/L114LivyHistoryOfRomeI12/L114-Livy%20History%20of%20Rome%20I%3A1-2#page/n161/mode/2up">1.33.9</a>, <a href="https://archive.org/stream/L114LivyHistoryOfRomeI12/L114-Livy%20History%20of%20Rome%20I%3A1-2#page/n285/mode/2up">2.9.6</a>); the Via Salaria or ‘Salt Road’ owed its name to its role in salt transportation; the Etruscan city of Veii owed much of its wealth to salt production; and access to salt even provoked <a href="https://archive.org/stream/L322TacitusVAnnals1316/L322-Tacitus%20V%20Annals%2013-16#page/n107/mode/2up">a war between two German tribes</a> at Bad Salzungen in the 1st century CE.</p><p>

But ‘prized and valuable’ -- no. That suggests a special cultural status which isn’t supported by any evidence. No one thought of salt as an heirloom, or used it for jewellery. No one talks about awarding salt as a prize for contests. There’s no evidence anyone used salt bars as money -- not even as one among many forms of exchange, as in 19th century Ethiopia. Salt was not a prestige object.</p><p>

Modern people who repeat these myths sometimes emphasise the high value of salt in the Roman world. Well, sure, the salt <i>trade</i> was valuable ... that’s because it was traded in such high volume. But in 204 BCE, when Marcus Livius ‘the salt-dealer’ imposed his tax on salt, Livy quotes the price of salt at a <i>sextans</i>: that is, one sixth of a copper <i>as</i>, or one 60th of a silver <i>denarius</i> (or in a civilian context, a <i>sextans</i> was one 96th of a <i>denarius</i>). Polybius, writing in the mid-100s BCE, quotes a foot-soldier’s pay as ‘two obols’ per day, that is to say, one third of a <i>denarius</i> (Polybius <a href="http://penelope.uchicago.edu/Thayer/E/Roman/Texts/Polybius/6*.html#39.12">6.39.12</a>).</p><p>

In other words, a Roman pound of salt (ca. 330 grams) cost one twentieth of a foot-soldier’s daily wages.</p><p>

Important? Of course. Expensive by modern standards? Maybe, depending on the price of salt where you live. ‘Prized and valuable’? No.</p><p>

Actually that deserves more than a ‘no’. It deserves a hearty laugh followed by a ‘no’. Thus: ‘Ha ha ha ha! No.’ There, got it right now.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why are Apple Silicon VMs so different? (276 pts)]]></title>
            <link>https://eclecticlight.co/2023/12/29/why-are-apple-silicon-vms-so-different/</link>
            <guid>38803556</guid>
            <pubDate>Fri, 29 Dec 2023 10:29:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eclecticlight.co/2023/12/29/why-are-apple-silicon-vms-so-different/">https://eclecticlight.co/2023/12/29/why-are-apple-silicon-vms-so-different/</a>, See on <a href="https://news.ycombinator.com/item?id=38803556">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-77454">
	
	<!-- .entry-header -->

	
		<div data-first_letter="R">
		<p>Running macOS virtual machines (VMs) on Apple silicon Macs may not seem popular, but it has long been one of Apple’s important goals. Yet, if you do use a virtualiser on an M-series Mac, you’ll know how different it is from those that virtualise macOS and other operating systems on Intel Macs. This article explains why virtualisation is so important, and how it has become so different.</p>
<p>Wind the clock back to WWDC in June 2020, when Craig Federighi announced details of what was coming in Apple silicon, and he identified three pillars to support a rich diversity of software on these new Macs: Universal apps that run on both architectures, Rosetta 2 to translate Intel code to Arm instructions, and virtualisation. At the time, before Apple had even released its Developer Transition Kit, Andreas Wendker went on to demonstrate a pre-release version of Parallels Desktop running Linux as a guest, but there was no mention at all of Windows.</p>
<p>Although the first version of macOS to run on Apple silicon, Big Sur, didn’t support the lightweight virtualisation that was to follow in Monterey, it brought what Apple termed its Virtualization Extensions, an implementation of Arm’s <a href="https://developer.arm.com/documentation/100942/0100/AArch64-virtualization?lang=en" target="_blank">AArch64 virtualization</a>.</p>
<p>In the early days of virtualisation, two distinct types were distinguished. Type 1 runs a hypervisor (the core of the virtualiser) direct on the computer’s hardware. Type 2, also known as <em>hosted,</em> runs a primary host operating system on the hardware, and hypervisors then run on top of, or in close conjunction with, that to deliver the same range of services to guest operating systems. A host operating system can run more than one hypervisor at a time, and each hypervisor in turn can run more than one guest, but ultimately all converge on the host operating system and its kernel. These are now much more common on desktop computers, and include popular products such as VMware Fusion, Parallels Desktop and Oracle VirtualBox.</p>
<p>Running unmodified guest operating systems is made simpler when there’s hardware support for a hypervisor. Those adopting that approach can use Intel’s VT-x feature set, typically with Extended Page Tables (EPT) and Unrestricted Mode, or, in the case of Arm CPUs, AArch64 virtualization. This still leaves the problem of device support, which can either be left to the virtualiser to address, or can be provided for in a higher-level virtualisation framework. Over the years, and thanks to the effort of many engineers, virtualisers running on Intel hardware including Macs have grown extensive device support, and that’s what we rely on when virtualising macOS on Intel Macs.</p>
<p>Every single hardware device in an Apple silicon chip is different from its equivalent (if there is one) in Intel Macs. Even if Apple had wanted to document them fully for external use, the engineering effort to match device support in Intel Macs would have been too costly for any third party. Thus starting with a hypervisor and expecting others to build a complete virtualiser wasn’t feasible, nor was it likely to result in the high performance that Apple and users expected. What Apple did instead was to build device support into macOS, in the form of Virtio drivers.</p>
<p>Virtio is a standard originally developed by Rusty Russell that provides an abstraction layer over I/O devices. When the guest operating system calls to open a file, for example, that’s passed to a front-end Virtio storage device para-driver, and from there into a Virtio back-end driver that interacts with the storage device. Although this might seem less efficient than traditional virtualisation, in practice it can prove far more efficient. Its most obvious advantage is that creating a virtualiser app becomes a matter of configuring and opening the required Virtio devices, and letting the guest, Virtio and the host get on with it. And that’s essentially what an app using Apple’s Virtualisation framework does.</p>
<p><span><img data-attachment-id="66331" data-permalink="https://eclecticlight.co/virtualisation1/" data-orig-file="https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg" data-orig-size="2148,1386" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="virtualisation1" data-image-description="" data-image-caption="" data-medium-file="https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=300" data-large-file="https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=940" src="https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=940" alt="virtualisation1" srcset="https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg 2148w, https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=150&amp;h=97 150w, https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=300&amp;h=194 300w, https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=768&amp;h=496 768w, https://eclecticlightdotcom.files.wordpress.com/2022/07/virtualisation1.jpg?w=1024&amp;h=661 1024w" sizes="(max-width: 2148px) 100vw, 2148px"></span></p>
<p>Apple’s choice of Virtio was undoubtedly swayed by the fact that Linux already has good Virtio support, but at the time macOS had none. In the couple of years preceding the release of Monterey, Apple’s engineers thus set about building Virtio support into macOS, which explains why macOS lightweight virtualisation is only available on Monterey and later hosts, and when running Monterey and later guests. As implemented in macOS (both as guest and host), there are also extensions to support keyboard and pointing devices, a shared clipboard (‘Spice’), and high-performance graphics with Metal and GPU support.</p>
<p>In the Virtio model, providing such support is the task of the operating system, not the virtualiser. For vendors like VMware and Parallels this reduces not only the cost of development, but also the commercial value of their products; there’s no scope for either of them to engineer better or faster graphics support, as that’s determined by features provided in both guest and host operating systems, via Virtio or an equivalent. That puts Apple in charge of what hardware and features are supported by virtualisation on Apple silicon, and the difficulties that have arisen over Apple ID access for VMs.</p>
<p>On the other hand, it guarantees optimum performance in VMs. Not only is their CPU and GPU code run direct on the hardware, just as in the host, but Virtio devices deliver almost as good performance as on the host.</p>
<p>The reward for Apple is flexibility in the future of macOS. Running older versions of macOS in a VM enables users to run Intel-only apps long after Rosetta 2 support is dropped from the current macOS, and for newer Apple silicon Macs to run software that’s incompatible with their minimum version of macOS. Using either Linux or macOS, developers can distribute Docker-like lightweight VM packages, something already done by Cirrus Labs’ <a href="https://tart.run/" target="_blank">Tart</a>.</p>
<p>Virtualisation may seem to be a minority pursuit just now. That’s likely to change over the coming few years, thanks to lightweight virtualisation and Virtio.</p>
<p><strong>Further reading</strong></p>
<p>Edouard Bugnion, Jason Nieh, Dan Tsafrir (2017) <em>Hardware and Software Support for Virtualization,</em> Morgan &amp; Claypool. ISBN 978 1 62705 693 9. Bugnion was a co-founder of VMware.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are good books/blogs to read for a first time CTO (449 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38803092</link>
            <guid>38803092</guid>
            <pubDate>Fri, 29 Dec 2023 09:18:48 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38803092">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38803405"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803405" href="https://news.ycombinator.com/vote?id=38803405&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>Depends a lot on your situation:<p>Does "CTO" mean you are the tech lead of a small (single team) engineering organization? Then everything written for staff engineers applies. E.g I've heard good things about "Staff engineer's path" by Tanya Reilly.</p><p>Does "CTO" mean you are leading an org that is too large to be hands-on with tech, and need to build an effective structure and culture? Then I second the recommendation for "an elegant puzzle" by Will Larson.</p><p>Or does "CTO" mean that you switched from being an engineer to managing a team of engineers? Then everything for new managers applies, for starters I'd recommend "Becoming an effective software engineering manager" by James Stanier, or "Engineering management for the rest of us" by Sarah Drasner.</p><p>For some good general material, I'd also recommend the resources that Gergely Orosz makes available for subscribers to his "pragmatic engineer" newsletter. Those are templates for the kind of documents and processes you will most likely need - if you're new to the role, you will not go too wrong by using them, and if you want to create your own they are excellent starting points.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38803697"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38803697" href="https://news.ycombinator.com/vote?id=38803697&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>And maybe CTO means “the founding programmer of a new startup” in which case my advice would be to stop reading and start coding :-)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38804026"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38804026" href="https://news.ycombinator.com/vote?id=38804026&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>And honestly, pre product-market fit my advice would be not even coding, but iterating in an extremely scrappy way (read: Google Sheets, Jupyter Notebooks, no-/low code, handwritten invoices) until you have people paying for your product and not churning after the first month. Everything else comes secondary. For every company that didn‘t manage to scale their tech and teams fast enough, there‘s 100 that die by „building and they will come“ a polished app with great UX through 4 ecosystems that get launched to deafening silence.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38803966"><td></td></tr>
                        <tr id="38803972"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803972" href="https://news.ycombinator.com/vote?id=38803972&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>I was CTO of a startup from pre-seed stage ($0 raised, bootstrapping) thru Series A + B stages ($millions raised, scaling). I then promoted a senior engineer to the CTO role, around the time that we had ~20-30 engineers organized into sub-teams with engineering leads. As part of that, I ran an engineering management book club internally for the new CTO and engineering leads (which was also open to any engineers to join). I then published that reading list as a neatly organized blog post.<p>The team wrote web / SaaS / analytics software in Python and JavaScript, deployed on Linux + AWS, using lightweight planning tools like GitHub and Notion. It was also a fully distributed team long before the pandemic. Over time, the company (Parse.ly) gained hundreds of enterprise customers and established itself via profitable growth in a straightforward SaaS business model. In 2021, less than a year after this blog post was published, the company was acquired by one of the largest open web internet companies (Automattic, creators of WordPress.com).</p><p>"Managing software teams: the definitive reading list"</p><p><a href="https://amontalenti.com/2020/11/28/definitive-reading-list" rel="nofollow">https://amontalenti.com/2020/11/28/definitive-reading-list</a></p><p>The blog post is organized into a few sections, each featuring a few relevant books:</p><p>- Management as a high-leverage activity</p><p>- Product marketing and product management</p><p>- Debugging dysfunctional product cultures</p><p>- The psychology of deep work</p><p>- Fully distributed teams</p><p>- Programmer mindset and philosophy</p><p>It's easy to skip around to find a good starting point or make your own (smaller) reading list. Hope that helps. Good luck!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803901"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803901" href="https://news.ycombinator.com/vote?id=38803901&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>I've been a CTO a couple of times (VMware, startup), I don't think I'm a good one (I am better as an individual contributor, rather than as a manager), but I have one piece of advice for you: ignore books, or use them as secondary source of truth.<p>You should instead TALK to long-time or former CTOs and ask them for advice. You won't find that advice in any book. It's invaluable.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803795"><td></td></tr>
            <tr id="38803616"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803616" href="https://news.ycombinator.com/vote?id=38803616&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>Whichever books you read - some great suggestions in the comments so far - please treat them as advice, and not religious texts.<p>So many managers and higher fail terribly at being effective because they believe all they need to do is encourage/enforce the practices in the books on the engineering teams, and that is the path to failure and the death of morale.</p><p>Take the books as guidance, but listen and engage with your reports (and their reports) to find the problems that need to be solved. Don't dictate or drive people, let them use their expertise in the direction you lead.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38803663"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38803663" href="https://news.ycombinator.com/vote?id=38803663&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>People are notoriously bad at identifying what actually led to their success. Career advice authors even more so.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38803987"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803987" href="https://news.ycombinator.com/vote?id=38803987&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>For a startup, focus on shipping faster. The only thing that matters in a startup is finding the product market fit.<p>If you don’t get to this point, the startup will die. So spending time optimizing the performance or arguing which code formatting standards to follow is just a waste of time and resources.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803277"><td></td></tr>
            <tr id="38803771"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803771" href="https://news.ycombinator.com/vote?id=38803771&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>At a startup phase, I'm not sure there is anything that is strictly speaking a "CTO" task, except the paperwork. And once you get big enough for it to matter, the same rule applies as for a CEO: the CxO you need for your first million is a different one you need for your 100 million and different yet again for your first billion.<p>There is of course a GitHub list for this: <a href="https://github.com/kuchin/awesome-cto">https://github.com/kuchin/awesome-cto</a> and perhaps the best way to find out what you need is to check things off of that list that don't actually have anything to do with what you're actually working on. Role names generally have very little meaning on their own, it's all about context.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803938"><td></td></tr>
            <tr id="38803530"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803530" href="https://news.ycombinator.com/vote?id=38803530&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>If this is the first time you'd to be responsible for budgets, working with the board, finance teams, HR, etc, then I'd recommend a general business management book like "The Personal MBA" to give you an introduction to the concepts and language that those teams will use.<p>The Personal MBA: A World-Class Business Education in a Single Volume <a href="https://amzn.eu/d/dTAp1GF" rel="nofollow">https://amzn.eu/d/dTAp1GF</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803334"><td></td></tr>
            <tr id="38803288"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803288" href="https://news.ycombinator.com/vote?id=38803288&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>If it's just a "planning my first startup" stage and not an existing enterprise of some non-zero size, I'd suggest starting from the book "The Lean Startup" by Eric Ries and other general "startup mentality" information sources. For a tech-minded CTO, it's especially important to have that correct "startup mentality" to avoid big mistakes from the start.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38803778"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803778" href="https://news.ycombinator.com/vote?id=38803778&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>You need to book communication and/or good sales course. As CTO you’re into politics, not into tech. Ability to communicate clearly and steer the conversation is your skill number one. Tech background is nice to have, but not really useful. You will hire people for that.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38803858"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803858" href="https://news.ycombinator.com/vote?id=38803858&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>The effective manager - how to manage people<p>The mom test - how to discover product</p><p>The EOS (Traction and Co) - how to manage the company and give direction to the vision of the company
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803723"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803723" href="https://news.ycombinator.com/vote?id=38803723&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>Technical founders are not CTOs. At least, not for a long time. A CTO role defines the strategic vision for the org. You'll have a vague idea of that as a founder but until you nail the product and where it fits in a market it won't really matter too much. Focus on executing and getting traction instead.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38803560"><td></td></tr>
            <tr id="38803328"><td></td></tr>
            <tr id="38803797"><td></td></tr>
            <tr id="38803416"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803416" href="https://news.ycombinator.com/vote?id=38803416&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>As a CTO you'll work a lot with people, the best resource you can get is related to people.<p>Get a mentor, read books about dealing with people in the most optimal way for you and the business (closing deals, negotiation, psychology etc).</p><p>Also learn how to develop people. There are a few books on this, but nothing beats experience and being reflective about it. Every situation is specific and it's up to you to strategize how to develop people in your team, finding out what are the right buttons to push.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803719"><td></td></tr>
            <tr id="38803280"><td></td></tr>
            <tr id="38803574"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803574" href="https://news.ycombinator.com/vote?id=38803574&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>I would suggest reading 2-3 books from your tech domain, I mean the tech stack your startup will be using, and maybe 2-3 more about your niche (for example if you are in online advertising, read books about advertising in general and online in particular)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38803667"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803667" href="https://news.ycombinator.com/vote?id=38803667&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><br><div>
                  <p><span>On a side note, when I had my startup and was the CTO, a lot of advice I got and also what I ended up realising was that my priority and goal was to build an amazing `Tech Team`.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38803622"><td></td></tr>
            <tr id="38803355"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803355" href="https://news.ycombinator.com/vote?id=38803355&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>Assumming you have worked as software engineer I recommend to talk with other CTOs, product people, and/or senior engineers (peer groups) and have concrete problems you would like to solve in mind.<p>What kind of startup you want to build and in what field? Knowing more details about the challenges you will face help to narrow the focus to specific knowledge and skills.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803850"><td></td></tr>
            <tr id="38803738"><td></td></tr>
            <tr id="38803566"><td></td></tr>
                <tr id="38803884"><td></td></tr>
                  <tr id="38803314"><td></td></tr>
            <tr id="38803489"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38803489" href="https://news.ycombinator.com/vote?id=38803489&amp;how=up&amp;goto=item%3Fid%3D38803092"></a></center>    </td><td><p><span>Given that you have provided no information about your industry, the size of your company or team, your background, or any relevant information that could be used to help, literally any book could be a good fit for you.<p>Your best bet is to see if your company is willing to pay for you to take some Dale Carnegie classes (Specifically the ones on Effective Communication). It will help you more than anything technical.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38803573"><td></td></tr>
            <tr id="38803305"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[40% of US electricity is now emissions-free (123 pts)]]></title>
            <link>https://arstechnica.com/science/2023/12/40-of-us-electricity-is-now-emissions-free/</link>
            <guid>38802152</guid>
            <pubDate>Fri, 29 Dec 2023 05:57:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/science/2023/12/40-of-us-electricity-is-now-emissions-free/">https://arstechnica.com/science/2023/12/40-of-us-electricity-is-now-emissions-free/</a>, See on <a href="https://news.ycombinator.com/item?id=38802152">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Decarbonizing, but slowly    —
</h4>
            
            <h2 itemprop="description">Good news as natural gas, coal, and solar see the biggest changes.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/GettyImages-1414366794-800x533.jpg" alt="Image of electric power lines with a power plant cooling tower in the background.">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 353:single/related:5b9a036a34fed5756a2f33fdf9114d1c --><!-- empty -->
<p>Just before the holiday break, the US Energy Information Agency released data on the country's electrical generation. Because of delays in reporting, the monthly data runs through October, so it doesn't provide a complete picture of the changes we've seen in 2023. But some of the trends now seem locked in for the year: wind and solar are likely to be in a dead heat with coal, and all carbon-emissions-free sources combined will account for roughly 40 percent of US electricity production.</p>
<h2>Tracking trends</h2>
<p>Having data through October necessarily provides an incomplete picture of 2023. There are several factors that can cause the later months of the year to differ from the earlier ones. Some forms of generation are seasonal—notably solar, which has its highest production over the summer months. Weather can also play a role, as unusually high demand for heating in the winter months could potentially require that older fossil fuel plants be brought online. It also influences production from hydroelectric plants, creating lots of year-to-year variation.</p>
<p>Finally, everything's taking place against a backdrop of booming construction of solar and natural gas. So, it's entirely possible that we will have built enough new solar over the course of the year to offset the seasonal decline at the end of the year.</p>
<p>Let's look at the year-to-date data to get a sense of the trends and where things stand. We'll then check the monthly data for October to see if any of those trends show indications of reversing.</p>                                            
                                                        
<p>The most important takeaway is that energy use is largely flat. Overall electricity production year-to-date is down by just over one percent from 2022, though demand was higher this October compared to last year. This is in keeping with a general trend of flat-to-declining electricity use as greater efficiency is offsetting factors like population growth and expanding electrification.</p>
<p>That's important because it means that any newly added capacity will displace the use of existing facilities. And, at the moment, that displacement is happening to coal.</p>
<h2>Can’t hide the decline</h2>
<p>At this point last year, coal had produced nearly 20 percent of the electricity in the US. This year, it's down to 16.2 percent, and only accounts for 15.5 percent of October's production. Wind and solar combined are presently at 16 percent of year-to-date production, meaning they're likely to be in a dead heat with coal this year and easily surpass it next year.</p>
<p>Year-to-date, wind is largely unchanged since 2022, accounting for about 10 percent of total generation, and it's up to over 11 percent in the October data, so that's unlikely to change much by the end of the year. Solar has seen a significant change, going from five to six percent of the total electricity production (this figure includes both utility-scale generation and the EIA's estimate of residential production). And it's largely unchanged in October alone, suggesting that new construction is offsetting some of the seasonal decline.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/2023-emissions.png" data-height="1536" data-width="2048" alt="Coal is being squeezed out by natural gas, with an assist from renewables."><img alt="Coal is being squeezed out by natural gas, with an assist from renewables." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/2023-emissions-640x480.png" width="640" height="480" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/12/2023-emissions-1280x960.png 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/2023-emissions.png" data-height="1536" data-width="2048">Enlarge</a> <span>/</span> Coal is being squeezed out by natural gas, with an assist from renewables.</p><p>Eric Bangeman/Ars Technica</p></figcaption></figure>
<p>Hydroelectric production has dropped by about six percent since last year, causing it to slip from 6.1 percent to 5.8 percent of the total production. Depending on the next couple of months, that may allow solar to pass hydro on the list of renewables.</p>                                            
                                                        
<p>Combined, the three major renewables account for about 22 percent of year-to-date electricity generation, up about 0.5 percent since last year. They're up by even more in the October data, placing them well ahead of both nuclear and coal.</p>
<p>Nuclear itself is largely unchanged, allowing it to pass coal thanks to the latter's decline. Its output has been boosted by a new, 1.1 Gigawatt reactor that come online this year (a second at the same site, Vogtle in Georgia, is set to start commercial production at any moment). But that's likely to be the end of new nuclear capacity for this decade; the challenge will be keeping existing plants open despite their age and high costs.</p>
<p>If we combine nuclear and renewables under the umbrella of carbon-free generation, then that's up by nearly 1 percent since 2022 and is likely to surpass 40 percent for the first time.</p>
<p>The only thing that's keeping carbon-free power from growing faster is natural gas, which is the fastest-growing source of generation at the moment, going from 40 percent of the year-to-date total in 2022 to 43.3 percent this year. (It's actually slightly below that level in the October data.) The explosive growth of natural gas in the US has been a big environmental win, since it creates the least particulate pollution of all the fossil fuels, as well as the lowest carbon emissions per unit of electricity. But its use is going to need to start dropping soon if the US is to meet its climate goals, so it will be critical to see whether its growth flat lines over the next few years.</p>
<p>Outside of natural gas, however, all the trends in US generation are good, especially considering that the rise of renewable production would have seemed like an impossibility a decade ago. Unfortunately, the pace is currently too slow for the US to have a net-zero electric grid by the end of the decade.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ideal Monitor Rotation for Programmers (2021) (447 pts)]]></title>
            <link>https://sprocketfox.io/xssfox/2021/12/02/xrandr/</link>
            <guid>38802086</guid>
            <pubDate>Fri, 29 Dec 2023 05:39:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sprocketfox.io/xssfox/2021/12/02/xrandr/">https://sprocketfox.io/xssfox/2021/12/02/xrandr/</a>, See on <a href="https://news.ycombinator.com/item?id=38802086">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      
  <figure>
    <img src="https://sprocketfox.io/xssfox/images/PXL_20211202_033906006.jpg" alt="Monitor in landscape mode">
    <figcaption></figcaption>
</figure>
<p>It all started with this toot from <a href="https://cloudisland.nz/web/accounts/1">Aurynn</a>.</p>

<blockquote>
<p>do I just need to put one screen in portrait mode?</p>
</blockquote>
<p>In the past I had experimented with using portrait displays for reading and programming. The ability to display large amount of text is certainly appealing.</p>
<h3 id="boring">Boring</h3>
<figure>
    <img src="https://sprocketfox.io/xssfox/images/PXL_20211202_034116753.jpg" alt="Monitor in portrait mode">
    <figcaption></figcaption>
</figure>
<p>But is this the most optimal display for software development? Lets evaluate</p>
<table>
<thead>
<tr>
<th>Rotation</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td>0°</td>
<td>Works with most applications. Video content is usually in wide format</td>
<td>Websites and documents usually end up with a lot of whitespace and padding around them</td>
</tr>
<tr>
<td>90°</td>
<td>Great for text documents - can read down like a book page</td>
<td>Movies don’t display well. Viewing angle problems</td>
</tr>
</tbody>
</table>
<p>Here you might think we might done. But there are soooooo many more angles we can try. This is a little tricky on macOS and Windows but on Linux we have all the freedom we need.</p>
<h3 id="odd-but-ok">Odd but ok.</h3>
<p>We have a little tool called <code>xrandr</code> (x resize and rotate). We can use it to rotate the screen around to any angle we want. In practice I couldn’t get this to work on my MacBook. My desktop on the otherhand it had no problems. So lets try a few out.</p>
<figure>
    <img src="https://sprocketfox.io/xssfox/images/PXL_20211202_034333303.jpg" alt="Monitor with a 1 degree rotation">
    <figcaption></figcaption>
</figure>
<blockquote>
<p>1° - notice the menu bar disappearing to the right</p>
</blockquote>
<figure>
    <img src="https://sprocketfox.io/xssfox/images/PXL_20211202_034744788.jpg" alt="Monitor with a 45 degree rotation">
    <figcaption></figcaption>
</figure>
<blockquote>
<p>45° - I run out of space</p>
</blockquote>
<table>
<thead>
<tr>
<th>Rotation</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td>1°</td>
<td>Handy if your desk is on a slight slope</td>
<td>fonts render a little weird</td>
</tr>
<tr>
<td>45°</td>
<td>Middle ground between vertical and horizontal</td>
<td>doesn’t fit well with non square aspect ratios</td>
</tr>
</tbody>
</table>
<p>One neat thing about 45° is that it gives us pretty close to the diagonal. But not on my ultra wide. Due to maths, the amount we’d need to rotate is based on the angle of a triangle which match the aspect ration of the screen we are using. This ends up being about 22° for a 21:9 ratio.</p>
<h3 id="the-perfect-rotation">The perfect rotation</h3>
<figure>
    <img src="https://sprocketfox.io/xssfox/images/PXL_20211202_035205492.jpg" alt="Monitor with a 22 degree rotation">
    <figcaption></figcaption>
</figure>
<blockquote>
<p>22° - Perfect</p>
</blockquote>
<table>
<thead>
<tr>
<th>Rotation</th>
<th>Advantages</th>
<th>Disadvantages</th>
</tr>
</thead>
<tbody>
<tr>
<td>22°</td>
<td>Longest line length!</td>
<td>Webcam starts sliding away</td>
</tr>
</tbody>
</table>
<p>So this here I think is the best monitor orientation for software development. It provides the longest line lengths and no longer need to worry about that pesky 80 column limit.</p>
<h3 id="how-do-i-do-this">How do I do this?</h3>
<p>First off, I could only get this to work in xorg - no wayland support yet. <code>xrandr --output HDMI-3 --transform lots of numbers here</code> takes a transformation matrix thats used to position the screen. We can use that to rotate the display.</p>
<p>The basic syntax that we need for rotating and shifting is this</p>
<pre tabindex="0"><code>cos(x),-sin(x),shift_left,sin(x),cos(x),shift_up,0,0,1
</code></pre><p>Some examples</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span><span># these won't shift / center the display as I don't know the resolution</span>
</span></span><span><span>
</span></span><span><span><span>#-0.1</span>
</span></span><span><span>xrandr --output HDMI-3 --transform 0.999998476913288,0.00174532836589831,0,-0.00174532836589831,0.999998476913288,0,0,0,1
</span></span><span><span><span>#1</span>
</span></span><span><span>xrandr --output HDMI-3 --transform 0.999847695156391,-0.0174524064372835,0,0.0174524064372835,0.999847695156391,0,0,0,1
</span></span><span><span><span>#45</span>
</span></span><span><span>xrandr --output HDMI-3 --transform 0.707106781186548,-0.707106781186548,0,0.707106781186548,0.707106781186548,0,0,0,1
</span></span><span><span><span>#22</span>
</span></span><span><span>xrandr --output HDMI-3 --transform 0.927183854566787,-0.374606593415912,0,0.374606593415912,0.927183854566787,0,0,0,1
</span></span></code></pre></div><h4 id="calculator">Calculator</h4>
<p>This little javascript calculator should generate the xrandr command for given inputs</p>


<p>Enjoy.</p>




      
        
      
    </article></div>]]></description>
        </item>
    </channel>
</rss>