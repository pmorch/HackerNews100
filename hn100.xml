<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 13 Oct 2024 14:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Starship Flight 5 Stream (287 pts)]]></title>
            <link>https://twitter.com/SpaceX/status/1845152255944819015</link>
            <guid>41827362</guid>
            <pubDate>Sun, 13 Oct 2024 12:23:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/SpaceX/status/1845152255944819015">https://twitter.com/SpaceX/status/1845152255944819015</a>, See on <a href="https://news.ycombinator.com/item?id=41827362">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Large language models reduce public knowledge sharing on online Q&A platforms (117 pts)]]></title>
            <link>https://academic.oup.com/pnasnexus/article/3/9/pgae400/7754871</link>
            <guid>41827043</guid>
            <pubDate>Sun, 13 Oct 2024 11:26:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/pnasnexus/article/3/9/pgae400/7754871">https://academic.oup.com/pnasnexus/article/3/9/pgae400/7754871</a>, See on <a href="https://news.ycombinator.com/item?id=41827043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widgetname="ArticleFulltext">





                    <h2 scrollto-destination="483096323" id="483096323">Abstract</h2>
<section><p>Large language models (LLMs) are a potential substitute for human-generated data and knowledge resources. This substitution, however, can present a significant problem for the training data needed to develop future models if it leads to a reduction of human-generated content. In this work, we document a reduction in activity on Stack Overflow coinciding with the release of ChatGPT, a popular LLM. To test whether this reduction in activity is specific to the introduction of this LLM, we use counterfactuals involving similar human-generated knowledge resources that should not be affected by the introduction of ChatGPT to such extent. Within 6 months of ChatGPT’s release, activity on Stack Overflow decreased by 25% relative to its Russian and Chinese counterparts, where access to ChatGPT is limited, and to similar forums for mathematics, where ChatGPT is less capable. We interpret this estimate as a lower bound of the true impact of ChatGPT on Stack Overflow. The decline is larger for posts related to the most widely used programming languages. We find no significant change in post quality, measured by peer feedback, and observe similar decreases in content creation by more and less experienced users alike. Thus, LLMs are not only displacing duplicate, low-quality, or beginner-level content. Our findings suggest that the rapid adoption of LLMs reduces the production of public data needed to train them, with significant consequences.</p></section>                    
<div id="pgae400-box1"><p>This study examines the impact of ChatGPT, a large language model, on online communities that contribute to public knowledge shared on the Internet. We found that ChatGPT has led to a 25% drop in activity on Stack Overflow, a key reference website where programmers share knowledge and solve problems. This substitution threatens the future of the open web, as interactions with AI models are not added to the shared pool of online knowledge. Moreover, this phenomenon could weaken the quality of training data for future models, as machine-generated content likely cannot fully replace human creativity and insight. This shift could have significant consequences for both the public Internet and the future of AI.</p></div>                    <h2 scrollto-destination="483096327" id="483096327" data-legacy-id="pgae400-s1">Introduction</h2>
<p>Over the last 30 years, humans have constructed a vast and open library of information on the web. Using powerful search engines, anyone with an internet connection can access valuable information from online knowledge repositories like Wikipedia, Stack Overflow, and Reddit. New content and discussions posted online are quickly integrated into this ever-growing ecosystem, becoming digital public goods used by people all around the world to learn new technologies and solve their problems (<span id="jumplink-pgae400-B1 pgae400-B2 pgae400-B3 pgae400-B4"></span>1–4).</p><p>These public goods are essential for training AI systems, in particular, large language models (LLMs) (<span id="jumplink-pgae400-B5"></span>5). For example, the LLM in ChatGPT (<span id="jumplink-pgae400-B6"></span>6) is trained to recognize patterns, facts, and information from vast repositories of online public text by predicting the next words in sequences. It answers users’ questions by generating responses that not only integrate and contextualize this information but also infer underlying meanings and connections. The remarkable effectiveness of ChatGPT is reflected in its quick adoption (<span id="jumplink-pgae400-B7"></span>7) and application across diverse fields, including auditing (<span id="jumplink-pgae400-B8"></span>8), astronomy (<span id="jumplink-pgae400-B9"></span>9), medicine (<span id="jumplink-pgae400-B10"></span>10), and chemistry (<span id="jumplink-pgae400-B11"></span>11). Randomized control trials show that using LLMs significantly boosts productivity and quality in computer programming, professional writing, customer support tasks, consulting, and writing job applications (<span id="jumplink-pgae400-B12 pgae400-B13 pgae400-B14 pgae400-B15 pgae400-B16"></span>12–16). Indeed, the widely reported successes of LLMs, like ChatGPT, suggest that we will observe a significant change in how people search for, create and share information online.</p><p>Ironically, if LLMs like ChatGPT, substitute for traditional methods of searching and interrogating the web, they could displace the very human behavior that generated their original training data. As people begin to use ChatGPT or similar LLMs instead of online knowledge repositories to find information, traffic and contributions to these repositories will likely decrease, diminishing the quantity and quality of these digital public goods. Previous work refers to this sort of displacement as the “paradox of re-use”: for example, the information on platforms like Wikipedia powers Google search (via information boxes and summaries) while reducing the need to visit Wikipedia (<span id="jumplink-pgae400-B17"></span>17, <span id="jumplink-pgae400-B18"></span>18). While such a shift could have significant social and economic implications, we have little evidence on whether people are indeed reducing their consumption and creation of valuable digital public goods as LLMs’ popularity grows.</p><p>The aim of this article is to evaluate the impact of LLMs on the generation of open data on popular question-and-answer (Q&amp;A) platforms. We focus on the effects of the most widely adopted LLM as of now—ChatGPT. Because ChatGPT performs relatively well on software programming tasks (<span id="jumplink-pgae400-B15"></span>15), we study Stack Overflow, the largest online Q&amp;A platform for software development and programming. Preliminary studies have shown that ChatGPT’s quality is competitive with answers from Stack Overflow in specific fields (<span id="jumplink-pgae400-B19"></span>19, <span id="jumplink-pgae400-B20"></span>20).</p><p>We present three results. First, we examine whether the release of ChatGPT has decreased the volume of posts, i.e. questions and answers, published on the platform. We estimate the causal effect of ChatGPT’s release on Stack Overflow activity using a difference-in-differences model. We compare the weekly posting activity on Stack Overflow against that of four comparable Q&amp;A platforms. These counterfactual platforms are less likely to be affected by ChatGPT either because their users experience difficulties with accessing ChatGPT or because ChatGPT performs poorly in questions discussed on those platforms.</p><p>We find that posting activity on Stack Overflow decreased by about <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">25</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> relative to the counterfactual platforms 6 months after the release of ChatGPT. We estimate the average effect across the 6 months to be <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">15</mn><mi mathvariant="normal" xmlns="">%</mi></math>⁠</span>, reflecting a lagged kick-in and gradual adoption of ChatGPT. We interpret the <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">25</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> figure as a lower bound of the total impact of ChatGPT on Stack Overflow, as LLMs likely had some impact on even the counterfactual platforms. Additional evidence from the 2023 Stack Overflow Developer Survey supports the hypothesis that ChatGPT users are less likely to post on Stack Overflow and to visit the platform regularly.</p><p>Second, we investigate whether ChatGPT is simply displacing lower-quality posts on Stack Overflow. To do so, we use data on up- and downvotes, simple forms of social feedback provided by other users to rate posts. We observe little change in the votes posts received on Stack Overflow since the release of ChatGPT. In addition, we find significant declines in posting by users of all experience levels, from novice to expert. These results suggest that ChatGPT is displacing various Stack Overflow posts, including high-quality content.</p><p>Third, we study the heterogeneity of ChatGPT’s impact across different programming languages discussed on Stack Overflow. We test for these heterogeneities using an event study design. We observe that posting activity in some languages, like Python and Javascript, has decreased significantly more than the platform’s average. Using data on programming language popularity on GitHub, we find that the most widely used languages (and, hence, languages with richer data for training ChatGPT) tend to have larger relative declines in posting activity.</p><p>Our analysis points to several significant implications for the sustainability of the current AI ecosystem. The first is that the decreased production of open data will limit the training of future models (<span id="jumplink-pgae400-B21"></span>21). LLM-generated content itself is likely an ineffective substitute for training data generated by humans for the purpose of training new models (<span id="jumplink-pgae400-B22 pgae400-B23 pgae400-B24"></span>22–24). One analogy is that training an LLM on LLM-generated content is like making a photocopy of a photocopy, providing successively less satisfying results (<span id="jumplink-pgae400-B25"></span>25). While human feedback to LLMs may facilitate continued learning, data generated by interactions with privately owned LLMs belong to the owners of these LLMs.</p><p>This leads to the second issue: the initial advantage of the first mover, in this case OpenAI with its ChatGPT, compounds if the LLM effectively learns from interactions with users while crowding out the generation of new open data that competitors could use to improve their models. While it is well-known that increasing returns to users and data in the digital sector can lead to winner-take-all dynamics and technological lock-in (<span id="jumplink-pgae400-B26"></span>26, <span id="jumplink-pgae400-B27"></span>27), the transformation of the online commons into a private database presents a novel risk to consumer welfare. More broadly, a shift from open data to a more closed web will likely have significant second-order impacts on the ever-growing digital economy (<span id="jumplink-pgae400-B28"></span>28) and how we access, share, and evaluate information. These potential consequences have been overlooked in previous risk taxonomies of LLMs (<span id="jumplink-pgae400-B29"></span>29).</p><p>The rest of the article is organized as follows. We introduce our empirical set-up, including the data and models used in our analysis, in Data and methods section. Results section presents our results. In Discussion section, we discuss their implications. We argue that our findings of a significant decline in activity on Stack Overflow following the release of ChatGPT have important implications for the training of future models, competition in the AI sector, the provision of digital public goods, and how humans seek and share information.</p>                    <h2 scrollto-destination="483096339" id="483096339" data-legacy-id="pgae400-s2">Data and methods</h2>
                    <h3 scrollto-destination="483096340" id="483096340" data-legacy-id="pgae400-s2.1">Stack exchange and Segmentfault data</h3>
<p>To measure the effect ChatGPT can have on digital public goods, we compare the change in Stack Overflow’s activity with the activity on a set of similar platforms. These platforms are similar to Stack Overflow in that they are technical Q&amp;A platforms but are less prone to substitution by ChatGPT given their focus or target group. Specifically, we study the Stack Exchange platforms: Mathematics and Math Overflow and the Russian-language version of Stack Overflow. We also examine a Chinese-language Q&amp;A platform on computer programming called Segmentfault.</p><p>Mathematics and Math Overflow focus on university- and research-level mathematics questions, respectively. We consider these sites to be less susceptible to replacement by ChatGPT given that, during our study’s period of observation, the free-tier version of ChatGPT performed poorly (0–20th percentile) on advanced high-school mathematics exams (<span id="jumplink-pgae400-B6"></span>6) and was therefore unlikely to serve as a suitable alternative to these platforms.</p><p>The Russian Stack Overflow and the Chinese Segmentfault have similar scope as Stack Overflow, but target users located in Russia and China, respectively. We consider these platforms to be less affected by ChatGPT given that ChatGPT is officially unavailable in the Russian Federation, Belarus, Russian-occupied Ukrainian territory, and the People’s Republic of China. Although people in these places can and do access ChatGPT via VPNs, such barriers still represent a hurdle to widespread fast adoption (<span id="jumplink-pgae400-B30"></span>30).</p><p>We extract all posts (questions and answers) on Stack Overflow, Mathematics, Math Overflow, and Russian Stack Overflow from their launch to early June 2023 using <a href="https://archive.org/details/stackexchange" target="_blank">https://archive.org/details/stackexchange</a>. We scraped the data from Segmentfault directly. Our initial dataset comprises 58 million posts on Stack Overflow, over 900 thousand posts for the Russian-language version of Stack Overflow, 3.5 million posts on Mathematics Stack Exchange, 300 thousand posts for Math Overflow, and about 300 thousand for Segmentfault. We focus our analysis on data from January 2022 to the end of May 2023, noting that our findings are robust to alternative time windows.</p><p>For each post in the Stack Exchange sites, we additionally extract the post’s type (question or answer), the number of votes (up—positive feedback, or down—negative feedback) the post received, and the tags assigned to the post, where tags are predefined labels that summarize the content of the post, for instance, an associated programming language. In addition, we also extract the experience of the post’s author (i.e. number of previous posts). Using this information, we classify posts into those from “New”, “Inexperienced”, “Experienced”, and “Expert” users depending on whether the author had 0, 1–10, 11–100, or more than 100 posts, respectively at the time the post was published.<sup><span id="jumplink-FN1"></span>a</sup> For more details on the data from Q&amp;A platforms we used, we refer the reader to section.</p><p>Finally, we also investigated data from the 2023 Stack Overflow Developer Survey, conducted in mid-May 2023. It includes 89,184 responses from software developers living in 185 countries. We focus on user responses to the prompt “Which AI-powered tools did you use regularly over the past year?”, for which ChatGPT was an option to tick. We use this information to provide further suggestive evidence for the relationship between the adoption of ChatGPT and Stack Overflow activity at the individual programmer’s level while controlling for a rich set of characteristics, such as professional status, education, experience, and preferred programming language.</p>                    <h3 scrollto-destination="483096347" id="483096347" data-legacy-id="pgae400-s2.2">Models</h3>
                    <h4 scrollto-destination="483096348" id="483096348" data-legacy-id="pgae400-s2.2.1">Difference-in-differences</h4>
<p>We estimate the effect of ChatGPT for posting activity on Stack Overflow using a difference-in-differences method with four counterfactual platforms. We aggregate posting data at platform- and week-level and fit a regression model using ordinary least squares (OLS):<sup><span id="jumplink-FN2"></span>b</sup></p><div><div id="jumplink-M0001" content-id="M0001"><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mrow xmlns=""><mi mathvariant="normal">Log</mi></mrow><mo stretchy="false" xmlns="">(</mo><msub xmlns=""><mrow><mi mathvariant="normal">Posts</mi></mrow><mrow><mspace width=".1em"></mspace><mi>p</mi><mo>,</mo><mi>t</mi></mrow></msub><mo stretchy="false" xmlns="">)</mo><mo xmlns="">=</mo><msub xmlns=""><mi>α</mi><mrow><mspace width=".1em"></mspace><mi>p</mi></mrow></msub><mo xmlns="">+</mo><msub xmlns=""><mi>λ</mi><mi>t</mi></msub><mo xmlns="">+</mo><mi xmlns="">β</mi><mo xmlns="">×</mo><msub xmlns=""><mrow><mi mathvariant="normal">Treated</mi></mrow><mrow><mspace width=".1em"></mspace><mi>p</mi><mo>,</mo><mi>t</mi></mrow></msub><mo xmlns="">+</mo><msub xmlns=""><mi>ϵ</mi><mrow><mspace width=".1em"></mspace><mi>p</mi><mo>,</mo><mi>t</mi></mrow></msub><mo xmlns="">,</mo></math></p></div><p><span>(1)</span></p></div><p>where <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mrow><mi mathvariant="normal">Posts</mi></mrow><mrow><mspace width=".1em"></mspace><mi>p</mi><mo>,</mo><mi>t</mi></mrow></msub></math></span> is the number of posts on platform <em>p</em> in a week <em>t</em>, which we log-transform. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>α</mi><mrow><mspace width=".1em"></mspace><mi>p</mi></mrow></msub></math></span> are platform fixed effects, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>λ</mi><mi>t</mi></msub></math></span> are time (week) fixed effects, and <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>ϵ</mi><mrow><mspace width=".1em"></mspace><mi>p</mi><mo>,</mo><mi>t</mi></mrow></msub></math></span> is the error term.</p><p>The coefficient of interest is <em>β</em>, which captures the estimated effect of ChatGPT on posting activity on Stack Overflow relative to the less affected platforms: Treated equals one for weeks after the release of ChatGPT (starting with the week of 2022 November 27) when the platform <em>p</em> is Stack Overflow and zero otherwise. We report standard errors clustered at the monthly level to account for month-specific shocks common to all platforms. We note that <em>β</em> defines an estimate of the effect of ChatGPT on Stack Overflow relative to the counterfactuals averaged across the entire 6-month post-treatment period of our data. We focus our difference-in-differences estimations on the period between January 2022 and May 2023, covering 48 weeks before the release of ChatGPT and 25 weeks after it.<sup><span id="jumplink-FN3"></span>c</sup> However, to show that our results are not specific to the selected time window, we also repeat the estimations using a wider time period starting from January 2019.</p><p>The validity of the difference-in-differences approach relies on the assumption of parallel trends. While Fig. <span id="jumplink-pgae400-F1"></span>1b, illustrates that posting activity on Stack Overflow and the counterfactual platforms had developed in a similar way prior to the ChatGPT shock, we conduct several formal checks. First, we add platform-specific time trends that represent an interaction between a linear time trend and the average change in the number of posts on a platform between 2018 and pre-GPT. This allows us to check if the results are robust to the inclusion of differential time trends (<span id="jumplink-pgae400-B32"></span>32). Second, we estimate a generalized difference-in-differences model. Specifically, we employ a similar specification, but instead of <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">β</mi><mo xmlns="">×</mo><msub xmlns=""><mrow><mi mathvariant="normal">Treated</mi></mrow><mrow><mspace width=".1em"></mspace><mi>p</mi><mo>,</mo><mi>t</mi></mrow></msub></math>⁠</span>, we use <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><munder xmlns=""><mo>∑</mo><mi>t</mi></munder><msub xmlns=""><mi>β</mi><mi>t</mi></msub><mo xmlns="">×</mo><mi xmlns="">I</mi><mo stretchy="false" xmlns="">(</mo><mrow xmlns=""><mi mathvariant="normal">week</mi></mrow><mo xmlns="">=</mo><mi xmlns="">t</mi><mo stretchy="false" xmlns="">)</mo><mo xmlns="">×</mo><mi xmlns="">I</mi><mo stretchy="false" xmlns="">(</mo><mrow xmlns=""><mi mathvariant="normal">platform</mi><mspace width=".1em"></mspace></mrow><mo xmlns="">=</mo><mrow xmlns=""><mi mathvariant="normal">StackOverflow</mi></mrow><mo stretchy="false" xmlns="">)</mo></math>⁠</span>. We standardize the effects to 0 in the week before the public release of ChatGPT by dropping the indicator for that week from the regression. This model allows us to examine possible pretrends in our data. By estimating separate coefficients for the weeks <em>before</em> the release, we can check if posts on Stack Overflow had evolved similarly to the activity on counterfactual platforms prior to the release of ChatGPT. This specification also allows us to investigate the dynamics of the ChatGPT effect over time. Separate coefficients for 25 weeks <em>following</em> the release of ChatGPT show how the effects of ChatGPT realized over time as more users adopted the technology.</p>                    <div data-id="pgae400-f1" data-content-id="pgae400-f1" swap-content-for-modal="true"><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/m_pgae400f1.jpeg?Expires=1731613731&amp;Signature=YFepQXrCPIxzAqXuYmMWOEBmLrKFL40uYS5Q--hUOQIkVcRDnZ7rd85dyg6PXbt7s7s0ep~2fKwV2NguWJyv5sx6zFx4ilIkwMbqbwlfot9l4FEBhkt8jPuv-L15I~t2tRfAGx~Dh4PbVSUp9psIByP~k25PuHW5k8xA8HSCRYmdXoUDsP5qwQ8PHGArHIf6nJG-ZWSuEAdP3T21YsfmyC1XswjYBuw1T1bOgYZiLw5Tyd4O0NTIIAUf8gU5R1X2Ak8lPFIGzhDqo5J5DwpX3JLx3eCaLG5bxOCQBVV~WtsLdhnFHx2H4bJ0GmXOlCYmcSG9igu22dBvXXOcxxqaSA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="a) Time series of weekly posts to Stack Overflow since early 2016. The number of weekly posts decreases at a rate of about 7,000 posts each year from 2016 to 2022. In the 6 months after the release of ChatGPT, the weekly posting rate decreases by around 20,000 posts. b) Comparing posts to Stack Overflow, its Russian- and Chinese-language counterparts, and mathematics Q&amp;A platforms since early 2022. Post counts are standardized by the average and standard deviation of post counts within each platform prior to the release of ChatGPT. Posting activity on Stack Overflow falls significantly more relative to activity on other platforms." data-path-from-xml="pgae400f1.jpg"></p><div><p>Fig. 1.</p><p>a) Time series of weekly posts to Stack Overflow since early 2016. The number of weekly posts decreases at a rate of about 7,000 posts each year from 2016 to 2022. In the 6 months after the release of ChatGPT, the weekly posting rate decreases by around 20,000 posts. b) Comparing posts to Stack Overflow, its Russian- and Chinese-language counterparts, and mathematics Q&amp;A platforms since early 2022. Post counts are standardized by the average and standard deviation of post counts within each platform prior to the release of ChatGPT. Posting activity on Stack Overflow falls significantly more relative to activity on other platforms.</p></div></div><p>The advantage of the difference-in-differences method compared to a simple event study with Stack Overflow data only is that we estimate ChatGPT effects net of possible weekly shocks that are common across the technical Q&amp;A platforms. For the interpretation of the coefficient, we note that we estimate <em>relative</em> change in posting activity on Stack Overflow compared to activity on other platforms before vs. after the release of ChatGPT. To the extent that ChatGPT also affected activity on the counterfactual platforms, our estimates will be downward biased in the magnitude of the effect.</p><p>To investigate whether the decrease in posting was driven mainly by a decrease in the number of posts authored by new or inexperienced users, we run the same regression as in <span id="jumplink-M0001"></span><a href="#M0001">Eq. 1</a> separately for weekly posts made by users with different levels of prior experience. We assign each post the number of previous posts the user had made and differentiate between four groups of posts: posts by “new” users who have not posted before, posts by “inexperienced” users who posted between 1 and 10 times, posts by “experienced” users with between 11 and 100 prior posts, and posts by “expert” users who posted more than 100 times previously.</p>                    <h4 scrollto-destination="483096357" id="483096357" data-legacy-id="pgae400-s2.2.2">Event study</h4>
<p>When analyzing the effect of ChatGPT on activity across programming languages, we can no longer compare data from Stack Overflow with the counterfactual platforms. This is because the tags annotating posts are different between Stack Exchange platforms. Therefore, we study ChatGPT’s heterogeneous effects using an event-study specification. For each programming language <em>i</em> (identified by a tag), we model the standardized number of posts in a week <em>t</em> on Stack Overflow by fitting a simple linear time trend with seasonal effects:</p><div><div id="jumplink-M0002" content-id="M0002"><p><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mover><mrow><mi mathvariant="normal">Posts</mi></mrow><mo accent="false">¯</mo></mover><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo xmlns="">=</mo><msub xmlns=""><mi>β</mi><mn>0</mn></msub><mo xmlns="">+</mo><msub xmlns=""><mi>β</mi><mn>1</mn></msub><mi xmlns="">t</mi><mo xmlns="">+</mo><msub xmlns=""><mi>β</mi><mn>2</mn></msub><mrow xmlns=""><mi mathvariant="normal">ChatGPT</mi></mrow><mo xmlns="">+</mo><msub xmlns=""><mi>β</mi><mn>3</mn></msub><mo stretchy="false" xmlns="">(</mo><mi xmlns="">t</mi><mo xmlns="">×</mo><mrow xmlns=""><mi mathvariant="normal">ChatGPT</mi></mrow><mo stretchy="false" xmlns="">)</mo><mo xmlns="">+</mo><mi xmlns="">η</mi><mo xmlns="">+</mo><msub xmlns=""><mi>ϵ</mi><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo xmlns="">,</mo></math></p></div><p><span>(2)</span></p></div><p>where <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mover xmlns=""><msub><mrow><mi mathvariant="normal">Posts</mi></mrow><mrow><mi>i</mi><mo>,</mo><mi>t</mi></mrow></msub><mo accent="false">¯</mo></mover></math></span> stands for the standardized number of posts associated with a programming language <em>i</em> in a week <em>t</em>. We standardize the dependent variable in order to be better able to compare effects across programming languages with different numbers of posts.<sup><span id="jumplink-FN4"></span>d</sup><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>β</mi><mn>1</mn></msub><mo stretchy="false" xmlns="">(</mo><mi xmlns="">t</mi><mo stretchy="false" xmlns="">)</mo></math></span> captures the linear time trend and <em>η</em> are seasonal (month of year) fixed effects. ChatGPT equals one if the week <em>t</em> is after the release of ChatGPT and zero otherwise. Coefficient <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>β</mi><mn>2</mn></msub></math></span> captures the change in the intercept, while coefficient <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>β</mi><mn>3</mn></msub></math></span> reflects the change in the slope of the time trend following the release of ChatGPT. We report HAC standard errors.</p>                    <h4 scrollto-destination="483096361" id="483096361" data-legacy-id="pgae400-s2.2.3">Additional regression analysis with the Stack Overflow 2023 survey</h4>
<p>We run an additional model using Stack Overflow survey data to corroborate our findings. We compute the association between self-reported individual activity on Stack Overflow and the adoption of ChatGPT by estimating the following logistic regression:</p><div><div id="jumplink-M0003" content-id="M0003"><p><math xmlns="http://www.w3.org/1998/Math/MathML"><mtable columnalign="right left" rowspacing=".5em" columnspacing="thickmathspace" displaystyle="true" xmlns=""><mtr><mtd><mrow><mi mathvariant="normal">log</mi></mrow><mstyle scriptlevel="0"><mrow><mo maxsize="2.470em" minsize="2.470em">(</mo></mrow></mstyle><mrow><mfrac><msub><mrow><mi mathvariant="normal">Activity</mi></mrow><mrow><mi>d</mi><mo>,</mo><mi>i</mi></mrow></msub><mrow><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mrow><mi mathvariant="normal">Activity</mi></mrow><mrow><mi>d</mi><mo>,</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><mstyle scriptlevel="0"><mrow><mo maxsize="2.470em" minsize="2.470em">)</mo></mrow></mstyle></mtd><mtd><mo>=</mo><msub><mi>β</mi><mn>0</mn></msub><mo>+</mo><msub><mi>β</mi><mn>1</mn></msub><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">Use</mi><mspace width=".1em"></mspace><mi mathvariant="normal">ChatGPT</mi></mrow><mi>d</mi></msub><mo stretchy="false">)</mo></mtd></mtr><mtr><mtd></mtd><mtd><mspace width="1em"></mspace><mo>+</mo><msub><mi>β</mi><mn>2</mn></msub><mo stretchy="false">(</mo><msub><mi>X</mi><mi>d</mi></msub><mo stretchy="false">)</mo><mo>+</mo><msub><mrow><mi mathvariant="normal">Age</mi></mrow><mi>d</mi></msub><mo>+</mo><msub><mi>C</mi><mi>d</mi></msub><mo>+</mo><msub><mi>I</mi><mi>d</mi></msub><mo>+</mo><msub><mrow><mi mathvariant="normal">Lang</mi></mrow><mi>i</mi></msub><mo>+</mo><msub><mrow><mi mathvariant="normal">Type</mi></mrow><mi>d</mi></msub><mo>+</mo><msub><mi>ϵ</mi><mrow><mi>d</mi><mo>,</mo><mi>i</mi></mrow></msub><mo>,</mo></mtd></mtr></mtable></math></p></div><p><span>(3)</span></p></div><p>where <em>d</em> stands for the developer and <em>i</em> denotes a programming language used by the developer. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mrow><mi mathvariant="normal">Activity</mi></mrow><mrow><mi>d</mi><mo>,</mo><mi>i</mi></mrow></msub></math></span> corresponds to the probability of being a frequent Stack Overflow visitor/contributor. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msub xmlns=""><mi>X</mi><mi>d</mi></msub></math></span> comprises a set of controls at the developer’s level: a dummy of whether the developer is a professional software engineer, education level, employment status, working mode (remote, hybrid, or in-person), and years of coding. We also add age (Age), country (<em>C</em>), industry (<em>I</em>), programming language (Lang), and developer type (Type) (e.g. researcher, front-end, back-end, full-stack, QA, etc.) fixed effects. Because most developers report using more than one programming language, we expand the dataset to the developer × language level. We apply weights (1/number of languages) to avoid double counts.<sup><span id="jumplink-FN5"></span>e</sup> We cluster standard errors at the programming language level to allow for common shocks. While the cross-sectional nature of the survey data does not allow us to interpret the results as causal, we try to reduce the endogeneity by controlling for a rich set of the above individual characteristics that are likely to influence both the adoption of ChatGPT and Stack Overflow contributions. In this way, we are comparing how the contributions to Stack Overflow vary between ChatGPT adopters and nonadopters, who are otherwise very similar to each other.</p>                    <h2 scrollto-destination="483096365" id="483096365" data-legacy-id="pgae400-s3">Results</h2>
                    <h3 scrollto-destination="483096366" id="483096366" data-legacy-id="pgae400-s3.1">Decrease in posting activity</h3>
<p>Figure <span id="jumplink-pgae400-F1"></span>1a shows the evolution of activity on Stack Overflow from January 2016 to June 2023. Up to 2022 there was a gradual decrease in activity from roughly 110,000 to 60,000 posts per week, that is roughly 7,000k posts less per week each year. However, after the release of ChatGPT (2022 November 30) posting activity decreased sharply, with the weekly average falling from around 60,000 posts to 40,000 within 6 months. Compared to the pre-ChatGPT trend, this decrease represents more than 5 years worth of deceleration in just half a year.</p><p>The decrease in activity on Stack Overflow is larger than for similar platforms for which we expect ChatGPT to be a less viable substitute. Figure <span id="jumplink-pgae400-F1"></span>1b shows the standardized posting activity on Stack Overflow, the Russian- and Chinese-language counterparts of Stack Overflow, and two mathematics Q&amp;A platforms. We standardize posting activity by the average and standard deviation of post counts within each platform prior to the release of ChatGPT.</p><p>Figure <span id="jumplink-pgae400-F1"></span>1b highlights that Stack Overflow activity deviates markedly from activity on the other platforms after the release of ChatGPT. The plot visualizes the standardized posting activity within each platform since early 2022. Smoothed weekly activity varies between plus and minus two standard deviations for all platforms for most of 2022. Events, such as the Chinese New Year and other holidays and the start of the Russian invasion of Ukraine, are visible. Following the release of ChatGPT, we observe a significant and persistent decline in activity on Stack Overflow.</p><p>Our difference-in-differences model reveals that Stack Overflow activity significantly declined after the release of ChatGPT, and that this effect became more pronounced over time. Table <span id="jumplink-pgae400-T1"></span>1 reports our estimates, the first column indicates that ChatGPT decreased posting activity on Stack Overflow by 15% (<span>⁠<span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">1</mn><mo xmlns="">−</mo><msup xmlns=""><mi>e</mi><mrow><mo>−</mo><mn>0.163</mn></mrow></msup></math>⁠</span>). Note that this is a measure of the average effect across the 6 months of post-ChatGPT data we consider. If ChatGPT adoption is gradual, we expect that the effect observed at the end of the data will be larger than at the beginning.</p>                    <div content-id="pgae400-T1"><div id="pgae400-T1" data-id="pgae400-T1"><p><span id="label-16735">Table 1.</span></p><p>Results of a difference-in-differences model, estimating the change in activity observed weekly on stack overflow following the release of ChatGPT, relative to activity on four other platforms less likely to have been impacted.</p> </div><div><table role="table" aria-labelledby="
                        label-16735" aria-describedby="
                        caption-16735"><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of questions</td><td>Weekday posts</td></tr><tr><td>Variables</td><td></td><td></td><td></td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.163</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.105</mn><mo xmlns="">+</mo></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.151</mn><mo>*</mo></msup></math></span></td></tr><tr><td></td><td>(0.0584)</td><td>(0.0597)</td><td>(0.0613)</td></tr><tr><td>Observations</td><td>370</td><td>370</td><td>370</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0458</td><td>0.0189</td><td>0.0294</td></tr></tbody></table></div><div><table><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of questions</td><td>Weekday posts</td></tr><tr><td>Variables</td><td></td><td></td><td></td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.163</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.105</mn><mo xmlns="">+</mo></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.151</mn><mo>*</mo></msup></math></span></td></tr><tr><td></td><td>(0.0584)</td><td>(0.0597)</td><td>(0.0613)</td></tr><tr><td>Observations</td><td>370</td><td>370</td><td>370</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0458</td><td>0.0189</td><td>0.0294</td></tr></tbody></table></div><div><p><span><p>All regressions comprise platform fixed effects and week fixed effects. The standard error of the estimate clustered on month is reported in parentheses. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span> (within) is derived after differencing out week and platform fixed effects. Significance codes: ***: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.001</mn></math>⁠</span>, <sup>**</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.01</mn></math>⁠</span>, <sup>*</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.05</mn></math>⁠</span>, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">+</mo></math>⁠</span>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.1</mn></math>⁠</span>.</p></span></p></div></div><div><div id="pgae400-T1" data-id="pgae400-T1"><p><span id="label-16735">Table 1.</span></p><p>Results of a difference-in-differences model, estimating the change in activity observed weekly on stack overflow following the release of ChatGPT, relative to activity on four other platforms less likely to have been impacted.</p> </div><div><table role="table" aria-labelledby="
                        label-16735" aria-describedby="
                        caption-16735"><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of questions</td><td>Weekday posts</td></tr><tr><td>Variables</td><td></td><td></td><td></td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.163</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.105</mn><mo xmlns="">+</mo></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.151</mn><mo>*</mo></msup></math></span></td></tr><tr><td></td><td>(0.0584)</td><td>(0.0597)</td><td>(0.0613)</td></tr><tr><td>Observations</td><td>370</td><td>370</td><td>370</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0458</td><td>0.0189</td><td>0.0294</td></tr></tbody></table></div><div><table><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of questions</td><td>Weekday posts</td></tr><tr><td>Variables</td><td></td><td></td><td></td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.163</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><mn xmlns="">0.105</mn><mo xmlns="">+</mo></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.151</mn><mo>*</mo></msup></math></span></td></tr><tr><td></td><td>(0.0584)</td><td>(0.0597)</td><td>(0.0613)</td></tr><tr><td>Observations</td><td>370</td><td>370</td><td>370</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0458</td><td>0.0189</td><td>0.0294</td></tr></tbody></table></div><div><p><span><p>All regressions comprise platform fixed effects and week fixed effects. The standard error of the estimate clustered on month is reported in parentheses. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span> (within) is derived after differencing out week and platform fixed effects. Significance codes: ***: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.001</mn></math>⁠</span>, <sup>**</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.01</mn></math>⁠</span>, <sup>*</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.05</mn></math>⁠</span>, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">+</mo></math>⁠</span>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.1</mn></math>⁠</span>.</p></span></p></div></div><p>Indeed, our second specification observes exactly this trend. We visualize the weekly estimates of the relative change in the Stack Overflow activity in Fig. <span id="jumplink-pgae400-F2"></span>2. This figure shows the impact of ChatGPT is increasing over time and is greater in magnitude than the average post-ChatGPT effect estimated in Table <span id="jumplink-pgae400-T1"></span>1 by the end of our study period. By the end of April 2023, coinciding with a peak in traffic to ChatGPT, <sup><span id="jumplink-FN6"></span>f</sup> the estimated decrease in activity stabilizes at around 25%.</p>                    <div data-id="pgae400-f2" data-content-id="pgae400-f2" swap-content-for-modal="true"><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/m_pgae400f2.jpeg?Expires=1731613731&amp;Signature=WXvvneTac~xvlDnzRAJ15zn9dlANlB7kPvy4bvTaS0HzOMfo94DYC3Mdk30ToYQJSr~MqFOO7qgOXxhENPecNKXFLUasXo3ZGOJxw02xXlClEPVm7pst-0FEXR8c9HYr~3p1CmvHSicYqHGdAjUlqlXMF2H7vafyxlF~DnVDWBirizRQrhSD7Iw4DqslNoEc5iDKJJoSubgf6EqJFhQ1mA01nMtODZkIRoE6D0m1ukGR-JTSxAfvT1sJyV3mSTpqQIVvF5DTM4S6EL22rFqd0HcL6RxYnvF3W5bJFzKcUp8E1ZUbLkOLEZBfeFEcbBxZAK7r6-5a6Z2kYmXEo-FyVg__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Difference-in-differences analysis for posting activities. The dashed line marks the week of 2022 November 27—the release week of ChatGPT. Eight weeks after its introduction, we observe a steady decline in the activity of Stack Overflow. The plotted coefficients correspond to the interaction between a weekly dummy and posting on Stack Overflow. We normalize the effects to 0 in the week before the public release of ChatGPT by dropping the indicator for that week from the regression. The reported CIs are at 95%. The regression comprises platform fixed effects and week fixed effects." data-path-from-xml="pgae400f2.jpg"></p><div><p>Fig. 2.</p><p>Difference-in-differences analysis for posting activities. The dashed line marks the week of 2022 November 27—the release week of ChatGPT. Eight weeks after its introduction, we observe a steady decline in the activity of Stack Overflow. The plotted coefficients correspond to the interaction between a weekly dummy and posting on Stack Overflow. We normalize the effects to 0 in the week before the public release of ChatGPT by dropping the indicator for that week from the regression. The reported CIs are at 95%. The regression comprises platform fixed effects and week fixed effects.</p></div></div><p>We also tested for heterogeneity in subsets of the data, considering only questions (rather than counting both questions and answers) and posts on weekdays. In both subsets, our estimates did not deviate significantly from the main result: we estimate a 10% relative decrease in questions and 14% relative decrease in posts on weekdays (see the second and third column of Table <span id="jumplink-pgae400-T1"></span>1). Our results are robust to using alternative transformations of the outcome (Tables <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S1 and S2</a></span>), adding platform-specific trends (Table <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S3</a></span>), and extending the time window of the analysis (Table <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S4</a></span>).</p><p>The decrease in Stack Overflow activity is consistent with the individual-level evidence from the 2023 Stack Overflow Developer Survey. In particular, we estimate the relationship between self-reported ChatGPT usage and Stack Overflow visit and contribution frequency using specification <span id="jumplink-M0003"></span><a href="#M0003">Eq. 3</a>. We consider several binary variables as the outcomes: <em>Contribute to Stack Overflow ever (weekly or more)</em> is equal to one if a developer has contributed to Stack Overflow at least once (weekly or more often) and zero otherwise, <em>Visit Stack Overflow daily</em> is equal to one if a developer reports visiting the platform once or more times per day. As participants were recruited through Stack Overflow and related platforms, they represent a selected group of engaged Stack Overflow users, and, therefore, their levels of activity are high: about 75% of all respondents have contributed to the platform at least once, and 42% visit it daily. We report the results in Table <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S7</a></span>. The coefficients represent changes in log odds of the outcomes, and we also compute the average marginal effects of ChatGPT adoption on the likelihood of frequent contributions/visits.</p><p>We find that ChatGPT adopters are less likely to contribute to Stack Overflow and to visit the platform frequently compared to nonadopters of the same age, experience, education, employment status, working mode, industry, and programming language used. Moreover, even when we limit the sample to the most active respondents (i.e. those who have contributed at least once to Stack Overflow), we can still detect statistically significant differences in the probability of both contributing weekly and visiting daily between otherwise similar ChatGPT adopters and nonadopters. The magnitude of the effect is not very high. For instance, the average marginal effect of ChatGPT on the likelihood of contributing to Stack Overflow weekly or more is about 0.8 percentage points (or 2.7% lower probability). However, these results are likely to be downward biased because of the selection into survey participation: those who use Stack Overflow less frequently (including those who have reduced their activity because of ChatGPT) were less likely to respond.</p>                    <h4 scrollto-destination="483096377" id="483096377" data-legacy-id="pgae400-s3.1.1">Post and user heterogeneities</h4>
<p>A decrease in overall activity on Stack Overflow is not an issue if it is rather the less interesting questions that are outsourced to ChatGPT. We use a post’s score (i.e. difference between upvotes and downvotes) observed 5 weeks after its creation as a proxy of its value—good (bad) posts have a positive (negative) score, while neutral questions have a score of zero.</p><p>If ChatGPT is displacing bad questions, we would expect that after its release there would be a downward trend in the share of bad questions. However, as Fig. <span id="jumplink-pgae400-F3"></span>3a shows, while there was a slight uptick in the fraction of good questions, these were mostly replacing neutral questions and the trend of bad questions was flat. The short-lived increase in the fraction of good questions may be a result of ChatGPT inducing interest in novel topics, such as large language models, which usually results in good questions (see our Discussion section below on the increase in interest in CUDA). With respect to answers, there was no change in the trends of good, bad, and neutral answers. In general, there is a remarkable stability in the proportions post-ChatGPT. We confirm these results by estimating a difference-in-differences specification where the outcome is the number of up(down) votes that posts published in a given week receive over the first 5 weeks, normalized to the total number of posts from this week (Table <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S5 and Fig. S1</a></span>). Unlike our previous results on posts, we do not detect any effect of ChatGPT.</p>                    <div data-id="pgae400-f3" data-content-id="pgae400-f3" swap-content-for-modal="true"><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/m_pgae400f3.jpeg?Expires=1731613731&amp;Signature=Mad4b29cp5iv46g3rARmcVvhYjKqjNU4s4lEEhCn0l1nuykhHBkhVaricVh8UnErSYHkT4Efx9TuJiJkvtNeaJbpPBWqx8camMB~RQr-MUSzrOeXKZW8CQUXboBU8P7y~U-IQxac2XB60ft4tC27JYs8VWr7Wo2BpQ1nAQ5UQCaxDd9mlCpKOETV3xUkzCn5hyroDGJq-KJK3Xj4o5tTKy6GUdaJGqTdaktzTLssbmVZ7h18ctK4ht8zD0JflNIHpVSZOF1zsAaLAvnpUwBvJmhvamlPmXqUuEPCeQnVBZEpg1ovSwWLfxjpPjryH7MLcWVYCjE1WjKhr2XMu7VzKA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="a) The weekly time series of the fraction of neutral, good, and bad questions and answers. Good (bad) post are those with a positive (negative) score after 5 weeks of its creation, while neutral questions have a zero score. The horizontal axis indicates the week of the post and the dashed line the week of the release of ChatGPT. We observe no major change in trends in bad posts since the release of ChatGPT. b) Weekly counts of questions and answers, respectively, by users, binned by experience level at the time of posting. We observe larger decreases in posting by users with previous experience post-ChatGPT." data-path-from-xml="pgae400f3.jpg"></p><div><p>Fig. 3.</p><p>a) The weekly time series of the fraction of neutral, good, and bad questions and answers. Good (bad) post are those with a positive (negative) score after 5 weeks of its creation, while neutral questions have a zero score. The horizontal axis indicates the week of the post and the dashed line the week of the release of ChatGPT. We observe no major change in trends in bad posts since the release of ChatGPT. b) Weekly counts of questions and answers, respectively, by users, binned by experience level at the time of posting. We observe larger decreases in posting by users with previous experience post-ChatGPT.</p></div></div><p>Votes do not capture all aspects of quality or more generally the ways in which ChatGPT may have influenced content on Stack Overflow. For example, users with different levels of experience contribute different kinds of content to the platform. New users tend to ask more basic questions, which ChatGPT may answer better. In contrast, experienced users may ask more sophisticated questions beyond the abilities of ChatGPT. A heterogeneous effect of ChatGPT on participation on Stack Overflow by users stratified by experience would have significant implications for content.</p><p>Table <span id="jumplink-pgae400-T2"></span>2 reports changes in activity estimated in a difference-in-differences specification, decomposed by prior user experience at the time of posting. Our estimates show that, while posts made by first-time users on Stack Overflow decreased only slightly relative to the control platforms, inexperienced, experienced, and expert users made significantly fewer posts on average after the release of ChatGPT.<sup><span id="jumplink-FN7"></span>g</sup> The point estimates (a reduction of about 21% relative to the counterfactual platforms) for both inexperienced and experienced users are almost identical, suggesting no significant difference in the decrease in activity. Table <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S8</a></span> estimates separate effects of ChatGPT on questions and answers. Interestingly, while inexperienced users reduce the number of their questions and answers to a similar extent, the effects for experienced and expert users are more pronounced for posting answers. We could link the latter result to lower incentives to contribute to Stack Overflow: as fewer developers are using the platform, the visibility “premium” that could be earned by answering questions becomes lower.</p>                    <div content-id="pgae400-T2"><div id="pgae400-T2" data-id="pgae400-T2"><p><span id="label-19892">Table 2.</span></p><p>Results of a difference-in-differences model, estimating the change in activity observed weekly on stack overflow following the release of ChatGPT by user group, relative to activity on three other platforms (we exclude segment fault as we do not have access to user experience data) less likely to have been impacted.</p> </div><div><table role="table" aria-labelledby="
                        label-19892" aria-describedby="
                        caption-19892"><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th><th>(4)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td></tr><tr><td>VARIABLES</td><td>NewUser</td><td>InexperiencedUser</td><td>ExperiencedUser</td><td>ExpertUser</td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.0833</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.245</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.254</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.168</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td></tr><tr><td></td><td>(0.0376)</td><td>(0.0529)</td><td>(0.0424)</td><td>(0.0292)</td></tr><tr><td>Observations</td><td>296</td><td>296</td><td>296</td><td>296</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0259</td><td>0.198</td><td>0.235</td><td>0.104</td></tr></tbody></table></div><div><table><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th><th>(4)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td></tr><tr><td>VARIABLES</td><td>NewUser</td><td>InexperiencedUser</td><td>ExperiencedUser</td><td>ExpertUser</td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.0833</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.245</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.254</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.168</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td></tr><tr><td></td><td>(0.0376)</td><td>(0.0529)</td><td>(0.0424)</td><td>(0.0292)</td></tr><tr><td>Observations</td><td>296</td><td>296</td><td>296</td><td>296</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0259</td><td>0.198</td><td>0.235</td><td>0.104</td></tr></tbody></table></div><div><p><span><p>Posts by new users are posts by users with no previous posts at the time of posting. Inexperienced users have posted 1–10 times before, experienced users 11–100, and experts more than 100 times. All regressions comprise platform fixed effects and week fixed effects. The standard error of the estimate clustered on month is reported in parentheses. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span> (within) is derived after differencing out week and platform fixed effects. Significance codes: ***: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.001</mn></math>⁠</span>, <sup>**</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.01</mn></math>⁠</span>, <sup>*</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.05</mn></math>⁠</span>, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">+</mo></math>⁠</span>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.1</mn></math>⁠</span>.</p></span></p></div></div><div><div id="pgae400-T2" data-id="pgae400-T2"><p><span id="label-19892">Table 2.</span></p><p>Results of a difference-in-differences model, estimating the change in activity observed weekly on stack overflow following the release of ChatGPT by user group, relative to activity on three other platforms (we exclude segment fault as we do not have access to user experience data) less likely to have been impacted.</p> </div><div><table role="table" aria-labelledby="
                        label-19892" aria-describedby="
                        caption-19892"><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th><th>(4)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td></tr><tr><td>VARIABLES</td><td>NewUser</td><td>InexperiencedUser</td><td>ExperiencedUser</td><td>ExpertUser</td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.0833</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.245</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.254</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.168</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td></tr><tr><td></td><td>(0.0376)</td><td>(0.0529)</td><td>(0.0424)</td><td>(0.0292)</td></tr><tr><td>Observations</td><td>296</td><td>296</td><td>296</td><td>296</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0259</td><td>0.198</td><td>0.235</td><td>0.104</td></tr></tbody></table></div><div><table><thead><tr><th></th><th>(1)</th><th>(2)</th><th>(3)</th><th>(4)</th></tr></thead><tbody><tr><td></td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td><td>Number of posts</td></tr><tr><td>VARIABLES</td><td>NewUser</td><td>InexperiencedUser</td><td>ExperiencedUser</td><td>ExpertUser</td></tr><tr><td>Stack Overflow × Post-GPT</td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.0833</mn><mo>*</mo></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.245</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.254</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">−</mo><msup xmlns=""><mn>0.168</mn><mrow><mo>*</mo><mo>*</mo><mo>*</mo></mrow></msup></math></span></td></tr><tr><td></td><td>(0.0376)</td><td>(0.0529)</td><td>(0.0424)</td><td>(0.0292)</td></tr><tr><td>Observations</td><td>296</td><td>296</td><td>296</td><td>296</td></tr><tr><td><span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span>-within</td><td>0.0259</td><td>0.198</td><td>0.235</td><td>0.104</td></tr></tbody></table></div><div><p><span><p>Posts by new users are posts by users with no previous posts at the time of posting. Inexperienced users have posted 1–10 times before, experienced users 11–100, and experts more than 100 times. All regressions comprise platform fixed effects and week fixed effects. The standard error of the estimate clustered on month is reported in parentheses. <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><msup xmlns=""><mi>R</mi><mn>2</mn></msup></math></span> (within) is derived after differencing out week and platform fixed effects. Significance codes: ***: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.001</mn></math>⁠</span>, <sup>**</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.01</mn></math>⁠</span>, <sup>*</sup>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.05</mn></math>⁠</span>, <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mo xmlns="">+</mo></math>⁠</span>: <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.1</mn></math>⁠</span>.</p></span></p></div></div><p>Overall, our analysis shows little evidence that ChatGPT tends to replace low-quality posts and no evidence that it replaced posts by inexperienced users relative to experts and experienced users.</p>                    <h3 scrollto-destination="483096385" id="483096385" data-legacy-id="pgae400-s3.2">Heterogeneities across programming languages</h3>
<p>Next, we investigated differences in the impact of ChatGPT on posts about different programming languages, finding significant heterogeneities. In Facet A of Fig. <span id="jumplink-pgae400-F4"></span>4, we plot the estimated effects (slope changes in the linear time trend after the introduction of ChatGPT) for those 69 tags that we connected to a programming language on GitHub. We estimate a negative effect of ChatGPT for most tags, but the estimates range between a 0.25 standard deviation decrease in slope (i.e. change per week following the ChatGPT release) to a 0.03 standard deviation <em>increase</em>. We observe that some of the widely used languages like Python and Javascript are the most impacted by ChatGPT. Interestingly, the model estimates that posts about CUDA have increased (though not significantly) after ChatGPT was released. CUDA is an application programming interface created by Nvidia, a graphics card manufacturer, that facilitates the use of graphics cards for computational tasks, in particular for machine learning and AI. This exception again demonstrates the impact of ChatGPT on the world of computer programming: people are increasingly interested in software relating to AI.</p>                    <div data-id="pgae400-f4" data-content-id="pgae400-f4" swap-content-for-modal="true"><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/m_pgae400f4.jpeg?Expires=1731613731&amp;Signature=1oZ7w0HBe0ElTKKgDektcwu2~M6scG70I0u3y5lGHZNEgTyPgguOADMKoj~oi5sSSzRF80~xZ8WSrxilZoiTo2XETnWq62GkAkzFY~QObzO3KGA7ETgpBIUeI3YpsPgacQFwWROPtPF92zDtQeAcGdiMz1OBVVvtlpL0qhL90eg49PHwhT6-f9ITgEnX0bZoNWOPznZ5VQHoqxbV~F1TP~pSQbD1GTZ-3LtUGX~ynAkqQHuqWKSTuJD7~u8mJ-4HUw6o-Jpkicmx1NVfPZ0~hj8R6DJiL2zIgXdMoR4A4W43VJl83BTbe8bmY8rQSWwxPCYiXPEpGJG55tiTHbd8qw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="a) The event study estimates of the effect of ChatGPT’s release on activity on a selection of tags on Stack Overflow. We report HAC-corrected 95% CIs. b) The relationship between estimated effects and salary data from the Stack Overflow Developer Survey. We find no significant relationship. c) The relationship between the number of GitHub repositories using a tag and the estimated effect of ChatGPT on that tag. In both b) and c), we plot a linear fit with bootstrapped 95% CIs. The dashed line in b) indicates that the correlation is not significant." data-path-from-xml="pgae400f4.jpg"></p><div><p>Fig. 4.</p><p>a) The event study estimates of the effect of ChatGPT’s release on activity on a selection of tags on Stack Overflow. We report HAC-corrected 95% CIs. b) The relationship between estimated effects and salary data from the Stack Overflow Developer Survey. We find no significant relationship. c) The relationship between the number of GitHub repositories using a tag and the estimated effect of ChatGPT on that tag. In both b) and c), we plot a linear fit with bootstrapped 95% CIs. The dashed line in b) indicates that the correlation is not significant.</p></div></div><p>Given that previous research suggests that high-wage jobs are more exposed to ChatGPT (<span id="jumplink-pgae400-B33"></span>33), we test whether the impact of ChatGPT is more predominant among better-paid languages. We source salary data from the 2022 Stack Overflow Developer Survey, focusing on US-based developers and calculating medians of reported salaries. In Fig. <span id="jumplink-pgae400-F4"></span>4b, we compare the estimated impact of ChatGPT on different languages against the salary data of developers using those languages. We observe no clear relationship between the estimated labor market value of a specific language and changes in posting behavior in that language post-ChatGPT.</p><p>To better understand the relationship between the size of the user base of a programming language and how it is impacted by ChatGPT, we compare our estimates with data from GitHub, the largest online platform for collaborative software development. Among other sources, ChatGPT was trained on data from GitHub. Because training data were collected up to September 2021, we use data on language use on GitHub up to June 2021. In Facet C of Fig. <span id="jumplink-pgae400-F4"></span>4, we visualize the relationship between the number of GitHub repositories (coding projects) in a specific language and the estimated impact of ChatGPT on that language. We observe that languages with more GitHub repositories tend to be more significantly impacted by the release of ChatGPT in terms of associated activity on Stack Overflow (Pearson’s <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mi xmlns="">ρ</mi><mo xmlns="">=</mo><mo xmlns="">−</mo><mn xmlns="">0.45</mn><mo xmlns="">,</mo><mi xmlns="">P</mi><mo xmlns="">&lt;</mo><mn xmlns="">0.001</mn></math>⁠</span>). This result is confirmed by estimating a difference-in-differences specification that compares the change in posting following the release of ChatGPT between more and less popular programming languages as measured by the number of GitHub commits attributed to a given language as of 2021 (Table <span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">S6</a></span>).</p>                    <h3 scrollto-destination="483096390" id="483096390" data-legacy-id="pgae400-s3.3">Subsequent dynamics</h3>
<p>Using the Stack Exchange Data Explorer, we extended the timeseries of weekly posts to Stack Overflow to Spring 2024. We visualize this data in Fig. <span id="jumplink-pgae400-F5"></span>5. We observe a continued, if slower, decrease in weekly posting activity after the end of our statistical analyses. In raw terms, the number of weekly posts to Stack Overflow has fallen from 60,000 to 30,000 from May 2022 to May 2024, with much of that change happening in the 6 months following the release of ChatGPT. Again, this suggests that the 25% estimate of the effect of ChatGPT on Stack Overflow should be interpreted as a lower bound effect, which is likely still growing.</p>                    <div data-id="pgae400-f5" data-content-id="pgae400-f5" swap-content-for-modal="true"><p><img src="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/m_pgae400f5.jpeg?Expires=1731613731&amp;Signature=Gopr5dzWjofg9tEiwPD07o5ZfI29VIxgX1q-94F3bTpTluFRJUaoZKZwhW2vXSyx3o8ozAsf7PHzv9dQV1g9yRfY8uJPhJDjH-6~7pjaLD5JCmo60eoq8UckQo052jPDEmiZLNX0d7hpaRTe1YKj4KsFR-LWvkuTFcSYGYaUvTLJi2HcuGJ0JwR7T46OUjTDm4R2AXD0vy3hG~JhQopeaVuf6pIEfZNz2thCDEoAxntOKnJF4BsgL~PcSgYXqxJ3OXgud3zm0X3lIXm4PqXk2-Zr-RiVP9NBjyHQ1Xei2oqJmw4~aLDGIdrOOMnXwv-i29wh3zg4Harr~2WBPqLdRQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="An extended timeseries of the weekly posts to Stack Overflow. We highlight the release of ChatGPT and the conclusion of the data we use in the statistical analyses, respectively. After May 2023, the decline in posting activity continues, albeit at a slower rate." data-path-from-xml="pgae400f5.jpg"></p><div><p>Fig. 5.</p><p>An extended timeseries of the weekly posts to Stack Overflow. We highlight the release of ChatGPT and the conclusion of the data we use in the statistical analyses, respectively. After May 2023, the decline in posting activity continues, albeit at a slower rate.</p></div></div><p>An extension of the difference-in-differences analysis would not yield reliable estimates of the relative impact of LLMs of Stack Overflow for several reasons. First, the subsequent proliferation of ChatGPT or-better quality LLMs, including open source models and models available in Russia and China mean that the reference timeseries are no longer valid counterfactuals. Moreover, advances in LLM capabilities have significantly improved their performance in mathematical tasks. Thus, we do not extend our difference-in-differences analyses.</p>                    <h2 scrollto-destination="483096394" id="483096394" data-legacy-id="pgae400-s4">Discussion</h2>
<p>The rate at which people have adopted ChatGPT is one of the fastest in the history of technology (<span id="jumplink-pgae400-B7"></span>7). It is essential that we better understand what activities this new technology displaces and what second-order effects this substitution may have (<span id="jumplink-pgae400-B34"></span>34, <span id="jumplink-pgae400-B35"></span>35). This article shows that after the introduction of ChatGPT there was a sharp decrease in human content creation on Stack Overflow. We compare the decrease in activity on Stack Overflow with other Stack Exchange platforms where current LLMs are less likely to be used. Using a difference-in-differences model, we estimates a <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">25</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> decline to posts on Stack Overflow relative to the counterfactual platforms within 6 months of ChatGPT’s release. We interpret this as a lower bound as ChatGPT is likely to have had small but growing impact on the counterfactual platforms as well. The Stack Overflow Developer Survey confirms that people using ChatGPT were less likely to post questions or answers on Stack Overflow.</p><p>We observe no large change in social feedback on posts, measured using votes, nor in the experience composition of posting users following ChatGPT’s release. These results suggest that average post quality has not changed, nor has ChatGPT replaced only the new and inexperienced users. Posting activity related to more popular programming languages decreased more on average than that for more niche languages. Given that LLMs performance depends on the quantity of training data, this finding suggests that users are more likely to substitute Stack Overflow with ChatGPT with respect to languages LLMs are more knowledgeable about. Consequently, the widespread adoption of LLMs will likely decrease the provision of digital public goods including open data previously generated by interactions on the web.</p><p>Two of our results offer some limited reasons for optimism. While posting activity on Stack Overflow decreased among inexperienced, experienced, and expert users relative to the control platforms, content created by new users remained relatively stable. New users are known to be essential to the long-run health of online communities (<span id="jumplink-pgae400-B36"></span>36). However, this optimism should be nuanced given that, if new users start behaving as inexperienced users did, then new users will also be more to likely reduce their activity in Stack Overflow. The second is that the impact of ChatGPT was less on more niche languages used by fewer people, suggesting that online conversations around such languages and the valuable information they generate will continue.</p><p>Recent work by Burtch et al. (<span id="jumplink-pgae400-B37"></span>37) studying the evolution of activity on Stack Overflow and Reddit found similar results to ours. Using a synthetic control method to adjust for seasonality, the authors report a roughly 20% decrease in posting activity on Stack Overflow within 15 weeks of the release of ChatGPT, and find similar heterogeneities among programming languages. These findings complement ours, which are derived from a more conservative analysis using counterfactual platforms. One difference in our findings is that their method finds a sharp decrease in posts by new users, while we observe fewer posts by more experienced users on Stack Overflow compared to the counterfactual platforms. It would be valuable for future work to resolve this ambiguity given the importance of new users to platform health discussed above.</p><p>Our results and data have some shortcomings that point to other open questions about the use and impact of LLMs. First, while we can present strong evidence that ChatGPT decreased the posting activity in Stack Overflow, we can only partially assess quality of posting activity using data on upvotes and downvotes. Users may be posting more challenging questions, ones that LLMs cannot (yet) address, to Stack Overflow. Future work should examine whether continued activity on Stack Overflow is more complex or sophisticated on average than posts from prior to ChatGPT release. Similarly, ChatGPT may have reduced the volume of duplicate questions about simple topics, though this is unlikely to impact our main results as duplicates are estimated to account for only <span><span></span><math xmlns="http://www.w3.org/1998/Math/MathML"><mn xmlns="">3</mn><mi mathvariant="normal" xmlns="">%</mi></math></span> of posts (<span id="jumplink-pgae400-B38"></span>38), and we do not observe significant changes in voting outcomes.</p><p>A second limitation of our work is that we cannot observe the extent to which Russian- and Chinese-language users of the corresponding Q&amp;A platforms are actually hindered from accessing ChatGPT; indeed recent work has shown a spike in VPN and Tor activity following the blocking of ChatGPT in Italy (<span id="jumplink-pgae400-B30"></span>30). While our results are robust to excluding the Chinese and the Russian counterfactuals, given the potential economic importance of ChatGPT and similar LLMs, it is essential that we better understand how such bans and blocks impact the accessibility of these tools (<span id="jumplink-pgae400-B39"></span>39, <span id="jumplink-pgae400-B40"></span>40). Finally, we do not address the issue that ChatGPT may be used to generate Stack Overflow content. Stack Overflow policy effectively banned posts authored by ChatGPT within a week of its release. In any case, a significant amount of ChatGPT generated content on Stack Overflow would mean that our measures underestimate the magnitude of the ChatGPT effect.</p><p>Despite these shortcomings, our results have important implications for the future of digital public goods. Before the introduction of ChatGPT, more human-generated content was posted to Stack Overflow, forming a collective digital public good due to their nonrivalrous and nonexclusionary nature—anyone with internet access can view, absorb, and extend this information, without diminishing the value of the knowledge. Now, part of this information is rather fed into privately owned LLMs like ChatGPT. This represents a significant shift of knowledge from public to private domains.</p><p>This observed substitution effect also poses several issues for the future of AI. The first is that if language models crowd out open data creation, they will be limiting their own future training data and effectiveness. The second is that owners of the current leading models have exclusive access to user inputs and feedback, which, with a relatively smaller pool of open data, gives them a significant advantage against new competitors in training future models. Third, the decline of public resources on the web would reverse progress made by the web toward democratizing access to knowledge and information. Finally, the consolidation of humans searching for information around one or a few language models could narrow our explorations and focus our attention on mainstream topics. We briefly elaborate on these points, then conclude with a wider appeal for more research on the political economy of open data and AI, and how we can incentivize continued contributions to digital public goods.</p>                    <h4 scrollto-destination="483096404" id="483096404" data-legacy-id="pgae400-s4.1.1">Training future models</h4>
<p>Our findings suggest that the widespread adoption of ChatGPT may ironically make it difficult to train future models (<span id="jumplink-pgae400-B41"></span>41). Though researchers have already expressed concerns about running out of data for training AI models (<span id="jumplink-pgae400-B21"></span>21), our results show that the use of LLMs can slow down the creation of new (open) data. Given the growing evidence that data generated by LLMs are unlikely to effectively train new LLMs (<span id="jumplink-pgae400-B22"></span>22, <span id="jumplink-pgae400-B23"></span>23), modelers face the real problem of running out of useful data. While research on using synthetic data and mixed data to train LLMs is still ongoing, current results show that use of synthetic training data can degrade performance (<span id="jumplink-pgae400-B24"></span>24) and may even amplify biases in models (<span id="jumplink-pgae400-B42"></span>42). Human input and guidance can mitigate these issues to some extent, but in general it is still unclear if synthetic data can power continued advances in LLM capabilities.</p><p>If ChatGPT truly is a “blurry JPEG” of the web (<span id="jumplink-pgae400-B25"></span>25), then in the long run, it cannot effectively replace its most important input: data derived from human activity. Indeed, OpenAI’s recent strategic partnerships with Stack Overflow and Reddit demonstrate the value of this kind of data for the continued training of LLMs.<sup><span id="jumplink-FN8"></span>h</sup> The proliferation of LLMs has already impacted other forms of data creation: many Amazon Mechanical Turk workers now generate content (i.e. respond to surveys, evaluate texts) using ChatGPT (<span id="jumplink-pgae400-B43"></span>43). And though watermarks may help humans and models identify data creators (<span id="jumplink-pgae400-B44"></span>44), the general problem of determining whether, for example, a text is written by a human or LLM is difficult at scale (<span id="jumplink-pgae400-B45"></span>45).</p>                    <h3 scrollto-destination="483096407" id="483096407" data-legacy-id="pgae400-s4.2">Competition in the AI sector</h3>
<p>A firm’s early advantage in technological innovation often leads to significant market share via various mechanisms of path dependence (<span id="jumplink-pgae400-B46"></span>46). There are increasing returns to using ChatGPT as more people use it, as it can learn from user feedback (<span id="jumplink-pgae400-B26"></span>26). Our results indicate that ChatGPT is simultaneously decreasing the amount of open training data that competitors could use to build competing models while it captures user data for itself, which may lead to technological lock-in (<span id="jumplink-pgae400-B27"></span>27). Unlike synthetic data, data on user interactions with LLMs can be used to significantly improve and tune their performance (<span id="jumplink-pgae400-B47"></span>47). We suggest that besides increasing returns to scale from network effects, the transformation of public data commons into private databases presents another mechanism by which the tech sector can become even more concentrated.</p>                    <h3 scrollto-destination="483096409" id="483096409" data-legacy-id="pgae400-s4.3">Lost economic value</h3>
<p>Digital public goods generate value in many ways besides feeding LLMs and other algorithms. For instance, Wikipedia is an important source of information worldwide, but in developing countries, readers are more often motivated by intrinsic learning goals and tend to read articles in greater detail (<span id="jumplink-pgae400-B3"></span>3). Unequal access to AI may also compound inequalities in growth and innovation between countries (<span id="jumplink-pgae400-B40"></span>40).</p><p>Digital public goods also provide direct value to the many websites that extract data from open data to complement their core services with extra information (<span id="jumplink-pgae400-B4"></span>4). For instance, there is substantial interdependence between sites like Wikipedia, Reddit, and Stack Overflow and the search engines that use them to enrich responses to user queries via infoboxes (<span id="jumplink-pgae400-B17"></span>17, <span id="jumplink-pgae400-B48"></span>48), sometimes referred to as the “paradox of re-use” (<span id="jumplink-pgae400-B18"></span>18). In the case of search engines, putting links to knowledge sources within infoboxes has mitigated the issue to some degree (<span id="jumplink-pgae400-B49"></span>49), but LLMs like ChatGPT are substituting for search engines and are much less likely to link to sources. Their widespread adoption presents a significant threat to the overall sustainability of the web (<span id="jumplink-pgae400-B50"></span>50).</p><p>Creators of digital public goods may also lose out. Contributors to Stack Overflow or Open Source Software (OSS) often enjoy indirect benefits (<span id="jumplink-pgae400-B51"></span>51). For instance, while OSS itself provides significant value in the global economy (<span id="jumplink-pgae400-B52"></span>52), OSS contributions are valuable signals of a firm’s capabilities to investors (<span id="jumplink-pgae400-B53"></span>53). Individual contributions to Stack Overflow are used to signal ability on the labor market (<span id="jumplink-pgae400-B54"></span>54). Any general tendency of ChatGPT to crowd out contributions to digital public goods, may limit these valuable signals that reduce economic frictions. On the other hand, such signaling activity may serve as a powerful incentive to keep people contributing.</p>                    <h4 scrollto-destination="483096413" id="483096413" data-legacy-id="pgae400-s4.3.1">Narrowing of information seeking</h4>
<p>The substitution effect we report likely has important second-order effects on how people search for information and their exposure to new ideas. LLMs likely favor well-established perspectives and due to their efficiency decrease the need for users to forage for information. These features of LLMs may reinforce a trend observed earlier in the context of the web. Specifically, internet search engines are thought to have pushed science toward consensus and narrower topics by improving efficiency of information search and improving the visibility of mainstream information (<span id="jumplink-pgae400-B55"></span>55). LLMs may also disincentivize the use of new or niche tools because they most amplify our productivity with those tools for which it has much training data. For instance, ChatGPT may not be able to help users of a new programming language that is has not seen many examples of. Given that LLMs are poised to change how we do research (<span id="jumplink-pgae400-B56"></span>56), present a strong competitor to search engines (<span id="jumplink-pgae400-B57"></span>57), and will likely influence our news consumption (<span id="jumplink-pgae400-B58"></span>58), we need to understand what LLM efficiency implies for our contact with diverse sources of information and incentives to try new things.</p><p>More generally, models like ChatGPT are going to generate political and economic winners and losers like many previous breakthrough technologies. While early evidence shows that these models enhance productivity especially among new and inexperienced workers (<span id="jumplink-pgae400-B12"></span>12, <span id="jumplink-pgae400-B14"></span>14), there are other ways in which they may contribute to inequality between people and firms (<span id="jumplink-pgae400-B59"></span>59), for instance via potential negative side effects of automation (<span id="jumplink-pgae400-B33"></span>33, <span id="jumplink-pgae400-B60"></span>60). Our results suggest that the economics of data creation and ownership will become more salient: as data become more valuable, there will be growing interest in how creators of data can capture some of that value (<span id="jumplink-pgae400-B61"></span>61). These multifaceted aspects of the impact of LLMs suggest that the political economy of data and AI will be especially important in the next years (<span id="jumplink-pgae400-B58"></span>58, <span id="jumplink-pgae400-B62"></span>62, <span id="jumplink-pgae400-B63"></span>63).</p><p>In this context, our work highlights the specific issue that valuable digital public goods may be under-produced as a result of the proliferation of AI. A natural follow-up question is how we can incentivize the creation of such goods. While unemployment shocks are known to increase the provision of digital public goods (<span id="jumplink-pgae400-B64"></span>64), it would be an unsatisfying solution to suggest that people put out of work by automation will fill this gap. In the case of platforms like Stack Overflow, active users are often motivated by social feedback and gamification (<span id="jumplink-pgae400-B65"></span>65), but the continual onboarding of new users is what keeps these platforms relevant in the long run (<span id="jumplink-pgae400-B36"></span>36). For the sake of a sustainable open web and an AI ecosystem that draws on its data, we should think about how to keep people exchanging information and knowledge online.</p>                    <h2 scrollto-destination="483096417" id="483096417" data-legacy-id="pgae400-s5">Materials</h2>
                    <h4 scrollto-destination="483096419" id="483096419" data-legacy-id="pgae400-s5.1.1">Stack Exchange platform sites</h4>
<p>The raw dataset obtained from <a href="https://archive.org/details/stackexchange" target="_blank">https://archive.org/details/stackexchange</a> contains nearly all posting activity on the question and answer platforms hosted on the Stack Exchange network from its launch in 2008 to early June 2023. These include Stack Overflow, its Russian language version, and Math Overflow and Math Stack Exchange. Stack Overflow is the largest online Q&amp;A platform for topics relating to computer programming and software development. It provides a community-curated discussion of issues programmers face (<span id="jumplink-pgae400-B65"></span>65). Questions have multiple answers, and users debate the relative merits of solutions and alternatives in comments. A track record on Stack Overflow has value on the labor market as a signal of an individual’s skills (<span id="jumplink-pgae400-B54"></span>54).</p><p>The data contain over 58 million posts, including both questions and answers. Posts are linked to their posting users, from which we infer poster previous activity and can identify posts made by new users. Questions are annotated with tags indicating the topic of the post including programming languages used. Users can give posts upvotes or downvotes, providing posting users with social feedback and reputation points. The Russian language version of Stack Overflow (over 900 thousand posts) and the mathematics-oriented platforms Math Stack Exchange (over 3.5 million posts) and Math Overflow (over 300 thousand posts) have identically structured data dumps hosted in the same location.</p><p>Registered users can upvotes and downvote posts made on Stack Exchange platforms. These votes provide a valuable signal of the value of posts (<span id="jumplink-pgae400-B65"></span>65, <span id="jumplink-pgae400-B66"></span>66). They are the primary way users earn reputation points and status on Stack Exchange platforms. Votes also influence the ranking of posts in user feeds and search engine results, facilitating information filtering. Downvotes are used to moderate. The Stack Exchange data dump contains data on every vote cast, including the corresponding post, the date the vote was made, and whether it was an upvote or downvote.</p>                    <h4 scrollto-destination="483096423" id="483096423" data-legacy-id="pgae400-s5.1.2">Segmentfault</h4>
<p>Segmentfault is a Chinese language platform with a Q&amp;A platform for developers that has many similarities with the Stack Exchange sites. Users post questions on programming language topics and other users post answers. Questions are tagged by relevant languages and technologies, and there are similar gamification elements on the platform. We scraped data on all posts as of early June 2023, gathering over 300 thousand in total. We were careful to follow best practices when collecting this data, limiting strain on the host platform’s servers and retaining only anonymized data and metadata rather than content of posts (<span id="jumplink-pgae400-B67"></span>67).</p>                    <h4 scrollto-destination="483096425" id="483096425" data-legacy-id="pgae400-s5.1.3">Selection of tags</h4>
<p>Stack Overflow posts are annotated by tags which describe the concepts and technologies used in the post. For example, many tags indicate programming languages, web frameworks, database technologies, or programming concepts like functions or algorithms. Stack Overflow reconciles tags referring to the same things via a centralized synonym dictionary. We selected the 1,000 most used tags up to early June 2023 and focused on those 69 which could be directly linked to language statistics reported by GitHub, described next.</p>                    <h4 scrollto-destination="483096427" id="483096427" data-legacy-id="pgae400-s5.1.4">GitHub data on programming language use</h4>
<p>We use data from the June 2021 GHTorrent data dump (<span id="jumplink-pgae400-B68"></span>68) as a proxy measure for the amount of open data available for each programming language. The dataset reports which languages are used in each project or repository on GitHub. We simply count the number of repositories mentioning each language. We then link the languages with tags on Stack Overflow. As an alternative, we count the number of commits, elemental code contributions to repositories, to each repository, hence language. In the main article, we visualize the estimated effects of ChatGPT on specific tags that we can link to GitHub languages. We exclude some tags which refer to file formats or plain text, specifically: yaml, json, text, svg, markdown, and xml.</p>                    <h4 scrollto-destination="483096429" id="483096429" data-legacy-id="pgae400-s5.1.5">Stack Overflow Developer Survey</h4>
<p>The 2023 Stack Overflow Developer Survey was conducted from 2023 May 8 to May 19 and captured responses from 89,184 software developers across 185 countries. Respondents were recruited primarily through channels owned by Stack Overflow, therefore users that are highly engaged on Stack Overflow were more likely to notice the prompts to take the survey over the duration of the collection promotion.<sup><span id="jumplink-FN9"></span>i</sup> This survey includes self-disclosed information about respondents professional status, academic qualifications, employment type, remote work status, and years of coding experience. Moreover the survey asked participants ’Which AI powered tools did you use regularly over the past year’ and included ChatGPT as an option to tick.</p>                    <h2 scrollto-destination="483096431" id="483096431">Notes</h2>
<p><span><span><span rel="nofollow" data-fn-id="FN1">a</span></span><p>There is no standard classification of user experience based on the number of posts. We chose a log-binned classification since activity on Stack Overflow is heavy-tailed (<span id="jumplink-pgae400-B31"></span>31), and log base 10 is a commonly used base.</p></span></p><p><span><span><span rel="nofollow" data-fn-id="FN2">b</span></span><p>For robustness, we test an OLS specification with standardized outcomes and a specification with the raw count of posts that we fit using the Poisson pseudo-maximum likelihood method.</p></span></p><p><span><span><span rel="nofollow" data-fn-id="FN3">c</span></span><p>In this way, we do not include Covid-induced positive shock in 2020 and then the reversion to the trend in 2021.</p></span></p><p><span><span><span rel="nofollow" data-fn-id="FN4">d</span></span><p>We standardize the number of posts within each tag by subtracting the mean and dividing by the standard deviation. Both statistics are calculated using data up to the release of ChatGPT.</p></span></p><p><span><span><span rel="nofollow" data-fn-id="FN5">e</span></span><p>For example, if a developer reports using three languages, there will be three entries (one for each language) in our dataset for this developer, each with a weight of 1/3.</p></span></p><p><span><span><span rel="nofollow" data-fn-id="FN7">g</span></span><p>Prior to the release of ChatGPT, new users contributed 9.5 thousand posts per week; inexperienced users—almost 20 thousand; experienced users—about 17.5 thousand, and expert users—16 thousand.</p></span></p>                    <h2 scrollto-destination="483096441" id="483096441" data-legacy-id="ack1">Acknowledgments</h2>
<p>We thank Frank Neffke, Gergő Tóth, Christoffer Koch, Sándor Juhász, Martin Allen, Manran Zhu, Karl Wachs, László Czaller, Todd Davies, Thomas Fackler, César Hidalgo, Florian Englmaier, Helene Strandt, and James Evans for helpful comments and discussions.</p>                    <h2 scrollto-destination="483096443" id="483096443" data-legacy-id="pgae400-s6">Supplementary Material</h2>
<p><span data-supplement-target="sup1"></span><span><a path-from-xml="sup1" href="https://oup.silverchair-cdn.com/oup/backfile/Content_public/Journal/pnasnexus/3/9/10.1093_pnasnexus_pgae400/1/pgae400_supplementary_data.pdf?Expires=1731613731&amp;Signature=yOqPdmGqAJzaymtZijxgcLBjJYhTgpFyyhshkYMXxLbEeXbNxnac4EOiGoHrB6fauLrC9wXzg67yvxqnLp-6qXrkZ6wInSXkDW-F1fbkbUCwySoIgqd4UBWW~CEsHAVnqxAYHDKaVbD0njho7DZ1C20k3OZsXsNjCDm3g8d0NeNJIK46-1fjAUsKYewq6IsuYLe2HSNu13qEzu~pRRVIMQ7jMK25x4paT57rGZMgkJLwF19qfFAVKsnfhsERlcmMxPQsANv09KeJpumtZS3BCwNzR1IVlzyVLvGnsZtO7rhy40ZGQKbxssxMuYj8b~mx5Pmm50pKjsjUZw18ZmlFSw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA">Supplementary material</a></span> is available at <em>PNAS Nexus</em> online.</p>                    <h2 scrollto-destination="483096445" id="483096445" data-legacy-id="pgae400-s7">Funding</h2>
<p>R.M.D.R.C. acknowledges funding from James S. McDonnell Foundation. J.W. acknowledges support from the Hungarian National Scientific Fund (OTKA FK 145960) and use of the HUN-REN Cloud (<span id="jumplink-pgae400-B69"></span>69) in the “Geographies of Creation, Learning and Use in Software” project. N.L. acknowledges support from CRC TRR 190 Rationality &amp; Competition.</p>                    <h2 scrollto-destination="483096447" id="483096447" data-legacy-id="pgae400-s8">Author Contributions</h2>
<p>R.M.D.R.C., N.L., and J.W. together conceived the idea, collected the data, created the models, analyzed the results, and wrote the manuscript.</p>                    <h2 scrollto-destination="483096449" id="483096449" data-legacy-id="pgae400-s9">Preprints</h2>
<p>A preprint of this article is published at <a href="https://arxiv.org/abs/2307.07367" target="_blank">https://arxiv.org/abs/2307.07367</a>.</p>                    <h2 scrollto-destination="483096451" id="483096451" data-legacy-id="pgae400-s10">Data Availability</h2>
<p>Data and code to reproduce our analyses are available on Zenodo: <a href="https://zenodo.org/records/12670482" target="_blank">https://zenodo.org/records/12670482</a>. The Stack Overflow data dump is available here: <a href="https://archive.org/details/stackexchange" target="_blank">https://archive.org/details/stackexchange</a>.</p>                    <h2 scrollto-destination="483096453" id="483096453" data-legacy-id="ref1">References</h2>
<div><div id="ref-auto-pgae400-B1" data-id="pgae400-B1" content-id="pgae400-B1" data-legacy-id="pgae400-B1"><p><span>1</span></p><div><p>Henzinger</p>  <p>M</p><p>, <span><p>Lawrence</p>  <p>S</p></span>. </p><p>2004</p><p>. </p><p>Extracting knowledge from the world wide web</p><p>. </p><p>Proc Natl Acad Sci U S A</p><p>. </p><p>101</p><p>:</p><p>5186</p><p>–</p><p>5191</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B2" data-id="pgae400-B2" content-id="pgae400-B2" data-legacy-id="pgae400-B2"><p><span>2</span></p><div><p>Hess</p>  <p>C</p><p>, <span><p>Ostrom</p>  <p>E</p></span>. </p><p>2003</p><p>. </p><p>Ideas, artifacts, and facilities: information as a common-pool resource</p><p>. </p><p>Law Contemp Probl</p><p>. </p><p>66</p><p>(</p><p>1/2</p><p>):</p><p>111</p><p>–</p><p>145</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B3" data-id="pgae400-B3" content-id="pgae400-B3" data-legacy-id="pgae400-B3"><p><span>3</span></p><div><p>Lemmerich</p>  <p>F</p><p>, <span><p>Sáez-Trumper</p>  <p>D</p></span>, <span><p>West</p>  <p>R</p></span>, <span><p>Zia</p>  <p>L</p></span>. </p><p>2019</p><p>. </p><p>Why the world reads Wikipedia: beyond English speakers. In: Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining; Melbourne. ACM. p. 618–626</p><p>.</p></div></div><div id="ref-auto-pgae400-B4" data-id="pgae400-B4" content-id="pgae400-B4" data-legacy-id="pgae400-B4"><p><span>4</span></p><div><p>Piccardi</p>  <p>T</p><p>, <span><p>Redi</p>  <p>M</p></span>, <span><p>Colavizza</p>  <p>G</p></span>, <span><p>West</p>  <p>R</p></span>. </p><p>2021</p><p>. </p><p>On the value of Wikipedia as a gateway to the web. In: Proceedings of the Web Conference 2021; IW3C2, Ljubljana. p. 249–260</p><p>.</p></div></div><div id="ref-auto-pgae400-B5" data-id="pgae400-B5" content-id="pgae400-B5" data-legacy-id="pgae400-B5"><p><span>5</span></p><div><p>Naveed</p>  <p>H</p><p>, <em>et al</em>. </p><p>2023</p><p>. A comprehensive overview of large language models, arXiv, arXiv:2307.06435, preprint: not peer reviewed. </p></div></div><div id="ref-auto-pgae400-B6" data-id="pgae400-B6" content-id="pgae400-B6" data-legacy-id="pgae400-B6"><p><span>6</span></p><div><p>OpenAI</p><p>. </p><p>2023</p><p>. </p><p>GPT-4 Technical Report</p><p>.</p></div></div><div id="ref-auto-pgae400-B7" data-id="pgae400-B7" content-id="pgae400-B7" data-legacy-id="pgae400-B7"><p><span>7</span></p><div><p>Teubner</p>  <p>T</p><p>, <span><p>Flath</p>  <p>CM</p></span>, <span><p>Weinhardt</p>  <p>C</p></span>, <span><p>van der Aalst</p>  <p>W</p></span>, <span><p>Hinz</p>  <p>O</p></span>. </p><p>2023</p><p>. </p><p>Welcome to the era of ChatGPT et al. the prospects of large language models</p><p>. </p><p>Bus Inf Syst Eng</p><p>. </p><p>65</p><p>(</p><p>2</p><p>):</p><p>95</p><p>–</p><p>101</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B8" data-id="pgae400-B8" content-id="pgae400-B8" data-legacy-id="pgae400-B8"><p><span>8</span></p><div><p>Gu</p>  <p>H</p><p>, <span><p>Schreyer</p>  <p>M</p></span>, <span><p>Moffitt</p>  <p>K</p></span>, <span><p>Vasarhelyi</p>  <p>MA</p></span>. </p><p>2023</p><p>. </p><p>Artificial intelligence co-piloted auditing. Available at SSRN 4444763</p><p>.</p></div></div><div id="ref-auto-pgae400-B9" data-id="pgae400-B9" content-id="pgae400-B9" data-legacy-id="pgae400-B9"><p><span>9</span></p><div><p>Smith</p>  <p>MJ</p><p>, <span><p>Geach</p>  <p>JE</p></span>. </p><p>2023</p><p>. </p><p>Astronomia ex machina: a history, primer and outlook on neural networks in astronomy</p><p>. </p><p>R Soc Open Sci</p><p>. </p><p>10</p><p>(</p><p>5</p><p>):</p><p>221454</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B10" data-id="pgae400-B10" content-id="pgae400-B10" data-legacy-id="pgae400-B10"><p><span>10</span></p><div><p>Kanjee</p>  <p>Z</p><p>, <span><p>Crowe</p>  <p>B</p></span>, <span><p>Rodman</p>  <p>A</p></span>. </p><p>2023</p><p>. </p><p>Accuracy of a generative artificial intelligence model in a complex diagnostic challenge</p><p>. </p><p>JAMA</p><p>. </p><p>330</p><p>(</p><p>1</p><p>):</p><p>78</p><p>–</p><p>80</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B11" data-id="pgae400-B11" content-id="pgae400-B11" data-legacy-id="pgae400-B11"><p><span>11</span></p><div><p>Guo</p>  <p>T</p><p>, <em>et al</em>. </p><p>2023</p><p>. What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks, arXiv, arXiv:2305.18365, preprint: not peer reviewed. </p></div></div><div id="ref-auto-pgae400-B12" data-id="pgae400-B12" content-id="pgae400-B12" data-legacy-id="pgae400-B12"><p><span>12</span></p><div><p>Brynjolfsson</p>  <p>E</p><p>, <span><p>Li</p>  <p>D</p></span>, <span><p>Raymond</p>  <p>LR</p></span>. </p><p>2023</p><p>. </p><p>Generative AI at work. Technical Report, National Bureau of Economic Research</p><p>.</p></div></div><div id="ref-auto-pgae400-B13" data-id="pgae400-B13" content-id="pgae400-B13" data-legacy-id="pgae400-B13"><p><span>13</span></p><div><p>Dell’Acqua</p>  <p>F</p><p>, <em>et al</em>. </p><p>2023</p><p>. </p><p>Navigating the jagged technological frontier: field experimental evidence of the effects of ai on knowledge worker productivity and quality. Harvard Business School Technology &amp; Operations Mgt. Unit Working Paper (24-013)</p><p>.</p></div></div><div id="ref-auto-pgae400-B14" data-id="pgae400-B14" content-id="pgae400-B14" data-legacy-id="pgae400-B14"><p><span>14</span></p><div><p>Noy</p>  <p>S</p><p>, <span><p>Zhang</p>  <p>W</p></span>. </p><p>2023</p><p>. </p><p>Experimental evidence on the productivity effects of generative artificial intelligence</p><p>. </p><p>Science</p><p>. </p><p>381</p><p>(</p><p>6654</p><p>):</p><p>187</p><p>–</p><p>192</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B15" data-id="pgae400-B15" content-id="pgae400-B15" data-legacy-id="pgae400-B15"><p><span>15</span></p><div><p>Peng</p>  <p>S</p><p>, <span><p>Kalliamvakou</p>  <p>E</p></span>, <span><p>Cihon</p>  <p>P</p></span>, <span><p>Demirer</p>  <p>M</p></span>. </p><p>2023</p><p>. The impact of AI on developer productivity: evidence from GitHub Copilot, arXiv, arXiv:2302.06590, preprint: not peer reviewed. </p></div></div><div id="ref-auto-pgae400-B16" data-id="pgae400-B16" content-id="pgae400-B16" data-legacy-id="pgae400-B16"><p><span>16</span></p><div><p>Wiles</p>  <p>E</p><p>, <span><p>Munyikwa</p>  <p>ZT</p></span>, <span><p>Horton</p>  <p>JJ</p></span>. </p><p>2023</p><p>. </p><p>Algorithmic writing assistance on Jobseekers’ resumes increases hires. Technical Report. National Bureau of Economic Research</p><p>.</p></div></div><div id="ref-auto-pgae400-B17" data-id="pgae400-B17" content-id="pgae400-B17" data-legacy-id="pgae400-B17"><p><span>17</span></p><div><p>McMahon</p>  <p>C</p><p>, <span><p>Johnson</p>  <p>I</p></span>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2017</p><p>. </p><p>The substantial interdependence of Wikipedia and Google: a case study on the relationship between peer production communities and information technologies. In: Proceedings of the International AAAI Conference on Web and Social Media; Montreal. AAAI. vol. 11, p. 142–151</p><p>.</p></div></div><div id="ref-auto-pgae400-B18" data-id="pgae400-B18" content-id="pgae400-B18" data-legacy-id="pgae400-B18"><p><span>18</span></p><div><p>Taraborelli</p>  <p>D</p><p>. </p><p>2015</p><p>. The sum of all human knowledge in the age of machines: a new research agenda for Wikimedia. In: ICWSM-15 Workshop on Wikipedia; Oxford. AAAI.</p></div></div><div id="ref-auto-pgae400-B19" data-id="pgae400-B19" content-id="pgae400-B19" data-legacy-id="pgae400-B19"><p><span>19</span></p><div><p>Delile</p>  <p>Z</p><p>, <em>et al</em>. </p><p>2023</p><p>. Evaluating privacy questions from stack overflow: can ChatGPT compete?, arXiv, arXiv:2306.11174, preprint: not peer reviewed. </p></div></div><div id="ref-auto-pgae400-B20" data-id="pgae400-B20" content-id="pgae400-B20" data-legacy-id="pgae400-B20"><p><span>20</span></p><div><p>Widjojo</p>  <p>P</p><p>, <span><p>Treude</p>  <p>C</p></span>. </p><p>2023</p><p>. Addressing compiler errors: stack overflow or large language models?, arXiv, arXiv:2307.10793, preprint: not peer reviewed. </p></div></div><div id="ref-auto-pgae400-B21" data-id="pgae400-B21" content-id="pgae400-B21" data-legacy-id="pgae400-B21"><p><span>21</span></p><div><p>Villalobos</p>  <p>P</p><p>, <em>et al</em>. </p><p>2022</p><p>. Will we run out of data? An analysis of the limits of scaling datasets in Machine Learning, arXiv, arXiv:2211.04325, preprint: not peer reviewed. </p></div></div><div id="ref-auto-pgae400-B22" data-id="pgae400-B22" content-id="pgae400-B22" data-legacy-id="pgae400-B22"><p><span>22</span></p><div><p>Alemohammad</p>  <p>S</p><p>, <em>et al</em>. </p><p>2023</p><p>. </p><p>Self-consuming generative models go mad</p><p>, </p><p>arXiv, arXiv:2307.01850</p><p>, preprint.</p></div></div><div id="ref-auto-pgae400-B23" data-id="pgae400-B23" content-id="pgae400-B23" data-legacy-id="pgae400-B23"><p><span>23</span></p><div><p>Gudibande</p>  <p>A</p><p>, <em>et al</em>. </p><p>2023</p><p>. </p><p>The false promise of imitating proprietary LLMs, arXiv, arXiv:2305.15717, preprint: not peer reviewed</p><p>. </p></div></div><div id="ref-auto-pgae400-B24" data-id="pgae400-B24" content-id="pgae400-B24" data-legacy-id="pgae400-B24"><p><span>24</span></p><div><p>Shumailov</p>  <p>I</p><p>, <em>et al</em>. </p><p>2024</p><p>. </p><p>Ai models collapse when trained on recursively generated data</p><p>. </p><p>Nature</p><p>. </p><p>631</p><p>(</p><p>8022</p><p>):</p><p>755</p><p>–</p><p>759</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B25" data-id="pgae400-B25" content-id="pgae400-B25" data-legacy-id="pgae400-B25"><p><span>25</span></p><div><p>Chiang</p>  <p>T</p><p>. </p><p>2023</p><p>. </p><p>ChatGPT is a blurry JPEG of the web</p><p>. </p><p>The New Yorker</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B26" data-id="pgae400-B26" content-id="pgae400-B26" data-legacy-id="pgae400-B26"><p><span>26</span></p><div><p>Arthur</p>  <p>WB</p><p>. </p><p>1989</p><p>. </p><p>Competing technologies, increasing returns, and lock-in by historical events</p><p>. </p><p>Econ J</p><p>. </p><p>99</p><p>(</p><p>394</p><p>):</p><p>116</p><p>–</p><p>131</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B27" data-id="pgae400-B27" content-id="pgae400-B27" data-legacy-id="pgae400-B27"><p><span>27</span></p><div><p>David</p>  <p>PA</p><p>. </p><p>1985</p><p>. </p><p>Clio and the economics of QWERTY</p><p>. </p><p>Am Econ Rev</p><p>. </p><p>75</p><p>(</p><p>2</p><p>):</p><p>332</p><p>–</p><p>337</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B28" data-id="pgae400-B28" content-id="pgae400-B28" data-legacy-id="pgae400-B28"><p><span>28</span></p><div><p>Stojkoski</p>  <p>V</p><p>, <span><p>Koch</p>  <p>P</p></span>, <span><p>Coll</p>  <p>E</p></span>, <span><p>Hidalgo</p>  <p>CA</p></span>. </p><p>2024</p><p>. </p><p>Estimating digital product trade through corporate revenue data</p><p>. </p><p>Nat Commun</p><p>. </p><p>15</p><p>(</p><p>1</p><p>):</p><p>5262</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B29" data-id="pgae400-B29" content-id="pgae400-B29" data-legacy-id="pgae400-B29"><p><span>29</span></p><div><p>Weidinger</p>  <p>L</p><p>. </p><p>2022</p><p>. </p><p>Taxonomy of risks posed by language models. In: Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency; Seoul. ACM. p. 214–229</p><p>.</p></div></div><div id="ref-auto-pgae400-B30" data-id="pgae400-B30" content-id="pgae400-B30" data-legacy-id="pgae400-B30"><p><span>30</span></p><div><p>Kreitmeir</p>  <p>DH</p><p>, <span><p>Raschky</p>  <p>PA</p></span>. </p><p>2023</p><p>. </p><p>The Unintended Consequences of Censoring Digital Technology–Evidence from Italy’s ChatGPT Ban, arXiv, arXiv:2304.09339, preprint: not peer reviewed</p><p>. </p></div></div><div id="ref-auto-pgae400-B31" data-id="pgae400-B31" content-id="pgae400-B31" data-legacy-id="pgae400-B31"><p><span>31</span></p><div><p>Upadhyay</p>  <p>U</p><p>, <span><p>Valera</p>  <p>I</p></span>, <span><p>Gomez-Rodriguez</p>  <p>M</p></span>. </p><p>2017</p><p>. </p><p>Uncovering the dynamics of crowdlearning and the value of knowledge. In: Proceedings of the Tenth ACM International Conference on Web Search and Data Mining. p. 61–70; Cambridge (UK). ACM.</p></div></div><div id="ref-auto-pgae400-B32" data-id="pgae400-B32" content-id="pgae400-B32" data-legacy-id="pgae400-B32"><p><span>32</span></p><div><p>Bilinski</p>  <p>A</p><p>, <span><p>Hatfield</p>  <p>LA</p></span>. </p><p>2018</p><p>. </p><p>Nothing to see here? Non-inferiority approaches to parallel trends and other model assumptions, arXiv, arXiv:1805.03273, preprint: not peer reviewed</p><p>. </p></div></div><div id="ref-auto-pgae400-B33" data-id="pgae400-B33" content-id="pgae400-B33" data-legacy-id="pgae400-B33"><p><span>33</span></p><div><p>Eloundou</p>  <p>T</p><p>, <span><p>Manning</p>  <p>S</p></span>, <span><p>Mishkin</p>  <p>P</p></span>, <span><p>Rock</p>  <p>D</p></span>. </p><p>2024</p><p>. </p><p>GPTs are GPTs: labor market impact potential of LLMs</p><p>. </p><p>Science</p><p>. </p><p>384</p><p>(</p><p>6702</p><p>):</p><p>1306</p><p>–</p><p>1308</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B34" data-id="pgae400-B34" content-id="pgae400-B34" data-legacy-id="pgae400-B34"><p><span>34</span></p><div><p>Aghion</p>  <p>P</p><p>, <span><p>Howitt</p>  <p>P</p></span>. </p><p>1992</p><p>. </p><p>A model of growth through creative destruction</p><p>. </p><p>Econometrica</p><p>. </p><p>60</p><p>(</p><p>2</p><p>):</p><p>323</p><p>–</p><p>351</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B35" data-id="pgae400-B35" content-id="pgae400-B35" data-legacy-id="pgae400-B35"><p><span>35</span></p><div><p>Schumpeter</p>  <p>JA</p><p>. </p><p>1942</p><p>. </p><p>Capitalism, socialism, and democracy</p><p>. </p><p>New York</p><p>: </p><p>Routledge</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B36" data-id="pgae400-B36" content-id="pgae400-B36" data-legacy-id="pgae400-B36"><p><span>36</span></p><div><p>Danescu-Niculescu-Mizil</p>  <p>C</p><p>, <span><p>West</p>  <p>R</p></span>, <span><p>Jurafsky</p>  <p>D</p></span>, <span><p>Leskovec</p>  <p>J</p></span>, <span><p>Potts</p>  <p>C</p></span>. </p><p>2013</p><p>. </p><p>No country for old members: user lifecycle and linguistic change in online communities. In: Proceedings of the 22nd international conference on World Wide Web; Rio, ACM. p. 307–318</p><p>.</p></div></div><div id="ref-auto-pgae400-B37" data-id="pgae400-B37" content-id="pgae400-B37" data-legacy-id="pgae400-B37"><p><span>37</span></p><div><p>Burtch</p>  <p>G</p><p>, <span><p>Lee</p>  <p>D</p></span>, <span><p>Chen</p>  <p>Z</p></span>. </p><p>2024</p><p>. </p><p>The consequences of generative AI for online knowledge communities</p><p>. </p><p>Sci Rep</p><p>. </p><p>14</p><p>(</p><p>1</p><p>):</p><p>10413</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B38" data-id="pgae400-B38" content-id="pgae400-B38" data-legacy-id="pgae400-B38"><p><span>38</span></p><div><p>Correa</p>  <p>D</p><p>, <span><p>Sureka</p>  <p>A</p></span>. </p><p>2013</p><p>. </p><p>Fit or unfit: analysis and prediction of ’closed questions’ on Stack Overflow. In: Proceedings of the First ACM conference on Online Social Networks; Boston. ACM. p. 201–212</p><p>.</p></div></div><div id="ref-auto-pgae400-B39" data-id="pgae400-B39" content-id="pgae400-B39" data-legacy-id="pgae400-B39"><p><span>39</span></p><div><p>Bao</p>  <p>H</p><p>, <span><p>Sun</p>  <p>M</p></span>, <span><p>Teplitskiy</p>  <p>M</p></span>. </p><p>2024</p><p>. </p><p>Where there’s a will there’s a way: ChatGPT is used more for science in countries where it is prohibited</p><p>.</p></div></div><div id="ref-auto-pgae400-B40" data-id="pgae400-B40" content-id="pgae400-B40" data-legacy-id="pgae400-B40"><p><span>40</span></p><div><p>Gaessler</p>  <p>F</p><p>, <span><p>Piezunka</p>  <p>H</p></span>. </p><p>2023</p><p>. </p><p>Training with AI: evidence from chess computers</p><p>. </p><p>Strat Manag J</p><p>.</p><p>44</p><p>(</p><p>11</p><p>):</p><p>2724</p><p>–</p><p>2750</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B41" data-id="pgae400-B41" content-id="pgae400-B41" data-legacy-id="pgae400-B41"><p><span>41</span></p><div><p>Taleb</p>  <p>NN</p><p>. </p><p>2012</p><p>. </p><p>Antifragile: how to live in a world we don’t understand</p><p>. </p><p>vol. 3</p><p>. </p><p>London</p><p>: </p><p>Allen Lane</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B42" data-id="pgae400-B42" content-id="pgae400-B42" data-legacy-id="pgae400-B42"><p><span>42</span></p><div><p>Wyllie</p>  <p>S</p><p>, <span><p>Shumailov</p>  <p>I</p></span>, <span><p>Papernot</p>  <p>N</p></span>. </p><p>2024</p><p>. </p><p>Fairness feedback loops: training on synthetic data amplifies bias, arXiv, arXiv:2403.07857, preprint: not peer reviewed</p><p>. </p></div></div><div id="ref-auto-pgae400-B43" data-id="pgae400-B43" content-id="pgae400-B43" data-legacy-id="pgae400-B43"><p><span>43</span></p><div><p>Veselovsky</p>  <p>V</p><p>, <span><p>Ribeiro</p>  <p>MH</p></span>, <span><p>West</p>  <p>R</p></span>. </p><p>2023</p><p>. </p><p>Artificial artificial artificial intelligence: crowd workers widely use large language models for text production tasks, arXiv, arXiv:2306.07899, preprint: not peer reviewed</p><p>. </p></div></div><div id="ref-auto-pgae400-B44" data-id="pgae400-B44" content-id="pgae400-B44" data-legacy-id="pgae400-B44"><p><span>44</span></p><div><p>Tian-Zheng Wei</p>  <p>J</p><p>, <span><p>Wang</p>  <p>RY</p></span>, <span><p>Jia</p>  <p>R</p></span>. </p><p>2024</p><p>. </p><p>Proving membership in LLM pretraining data via data watermarks, arXiv, arXiv:2402.10892, preprint: not peer reviewed.</p> </div></div><div id="ref-auto-pgae400-B45" data-id="pgae400-B45" content-id="pgae400-B45" data-legacy-id="pgae400-B45"><p><span>45</span></p><div><p>Tang</p>  <p>R</p><p>, <span><p>Chuang</p>  <p>Y-N</p></span>, <span><p>Hu</p>  <p>X</p></span>. </p><p>2024</p><p>. </p><p>The science of detecting LLM-generated text</p><p>. </p><p>Commun ACM</p><p>. </p><p>67</p><p>(</p><p>4</p><p>):</p><p>50</p><p>–</p><p>59</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B46" data-id="pgae400-B46" content-id="pgae400-B46" data-legacy-id="pgae400-B46"><p><span>46</span></p><div><p>Page</p>  <p>SE</p><p>. </p><p>2006</p><p>. </p><p>Path dependence</p><p>. </p><p>Quart J Polit Sci</p><p>. </p><p>1</p><p>(</p><p>1</p><p>):</p><p>87</p><p>–</p><p>115</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B47" data-id="pgae400-B47" content-id="pgae400-B47" data-legacy-id="pgae400-B47"><p><span>47</span></p><div><p>Köpf</p>  <p>A</p><p>. </p><p>2024</p><p>. </p><p>Openassistant conversations-democratizing large language model alignment</p><p>. </p><p>Adv Neural Inf Process Syst</p><p>. </p><p>36</p><p>:</p><p>47669</p><p>–</p><p>47681</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B48" data-id="pgae400-B48" content-id="pgae400-B48" data-legacy-id="pgae400-B48"><p><span>48</span></p><div><p>Vincent</p>  <p>N</p><p>, <span><p>Johnson</p>  <p>I</p></span>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2018</p><p>. </p><p>Examining Wikipedia with a broader lens: quantifying the value of Wikipedia’s relationships with other large-scale online communities. In: Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems; Quebec. ACM. p. 1–13</p><p>.</p></div></div><div id="ref-auto-pgae400-B49" data-id="pgae400-B49" content-id="pgae400-B49" data-legacy-id="pgae400-B49"><p><span>49</span></p><div><p>Vincent</p>  <p>N</p><p>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2021</p><p>. </p><p>A deeper investigation of the importance of Wikipedia links to search engine results</p><p>. </p><p>Proc ACM Hum-Comput Inter</p><p>. </p><p>5</p><p>(</p><p>CSCW1</p><p>):</p><p>1</p><p>–</p><p>15</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B50" data-id="pgae400-B50" content-id="pgae400-B50" data-legacy-id="pgae400-B50"><p><span>50</span></p><div><p>Vincent</p>  <p>N</p><p>. </p><p>2022</p><p>. </p><p>The paradox of reuse, language models edition. Data leverage</p><p>.</p></div></div><div id="ref-auto-pgae400-B51" data-id="pgae400-B51" content-id="pgae400-B51" data-legacy-id="pgae400-B51"><p><span>51</span></p><div><p>Lerner</p>  <p>J</p><p>, <span><p>Tirole</p>  <p>J</p></span>. </p><p>2002</p><p>. </p><p>Some simple economics of open source</p><p>. </p><p>J Ind Econ</p><p>. </p><p>50</p><p>(</p><p>2</p><p>):</p><p>197</p><p>–</p><p>234</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B52" data-id="pgae400-B52" content-id="pgae400-B52" data-legacy-id="pgae400-B52"><p><span>52</span></p><div><p>Greenstein</p>  <p>S</p><p>, <span><p>Nagle</p>  <p>F</p></span>. </p><p>2014</p><p>. </p><p>Digital dark matter and the economic contribution of Apache</p><p>. </p><p>Res Policy</p><p>. </p><p>43</p><p>(</p><p>4</p><p>):</p><p>623</p><p>–</p><p>631</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B53" data-id="pgae400-B53" content-id="pgae400-B53" data-legacy-id="pgae400-B53"><p><span>53</span></p><div><p>Conti</p>  <p>A</p><p>, <span><p>Peukert</p>  <p>C</p></span>, <span><p>Roche</p>  <p>MP</p></span>. </p><p>2021</p><p>. </p><p>Beefing IT up for your investor? Open sourcing and startup funding: evidence from GitHub. HBS Working Paper 22-001</p><p>.</p></div></div><div id="ref-auto-pgae400-B54" data-id="pgae400-B54" content-id="pgae400-B54" data-legacy-id="pgae400-B54"><p><span>54</span></p><div><p>Xu</p>  <p>L</p><p>, <span><p>Nian</p>  <p>T</p></span>, <span><p>Cabral</p>  <p>L</p></span>. </p><p>2020</p><p>. </p><p>What makes geeks tick? A study of stack overflow careers</p><p>. </p><p>Manage Sci</p><p>. </p><p>66</p><p>(</p><p>2</p><p>):</p><p>587</p><p>–</p><p>604</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B55" data-id="pgae400-B55" content-id="pgae400-B55" data-legacy-id="pgae400-B55"><p><span>55</span></p><div><p>Evans</p>  <p>JA</p><p>. </p><p>2008</p><p>. </p><p>Electronic publication and the narrowing of science and scholarship</p><p>. </p><p>Science</p><p>. </p><p>321</p><p>(</p><p>5887</p><p>):</p><p>395</p><p>–</p><p>399</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B56" data-id="pgae400-B56" content-id="pgae400-B56" data-legacy-id="pgae400-B56"><p><span>56</span></p><div><p>Grossmann</p>  <p>I</p><p>, <em>et al</em>. </p><p>2023</p><p>. </p><p>AI and the transformation of social science research</p><p>. </p><p>Science</p><p>. </p><p>380</p><p>(</p><p>6650</p><p>):</p><p>1108</p><p>–</p><p>1109</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B57" data-id="pgae400-B57" content-id="pgae400-B57" data-legacy-id="pgae400-B57"><p><span>57</span></p><div><p>Xu</p>  <p>R</p><p>, <span><p>Feng</p>  <p>Y</p></span>, <span><p>Chen</p>  <p>H</p></span>. </p><p>2023</p><p>. </p><p>ChatGPT vs. Google: a comparative study of search performance and user experience, arXiv, arXiv:2307.01135, preprint: not peer reviewed</p><p>. </p></div></div><div id="ref-auto-pgae400-B58" data-id="pgae400-B58" content-id="pgae400-B58" data-legacy-id="pgae400-B58"><p><span>58</span></p><div><p>Sandrini</p>  <p>L</p><p>, <span><p>Somogyi</p>  <p>R</p></span>. </p><p>2023</p><p>. </p><p>Generative ai and deceptive news consumption</p><p>. </p><p>Econ Lett</p><p>. </p><p>232</p><p>:</p><p>111317</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B59" data-id="pgae400-B59" content-id="pgae400-B59" data-legacy-id="pgae400-B59"><p><span>59</span></p><div><p>Rock</p>  <p>D</p><p>. </p><p>2019</p><p>. </p><p>Engineering value: the returns to technological talent and investments in artificial intelligence. Available at SSRN 3427412</p><p>.</p></div></div><div id="ref-auto-pgae400-B60" data-id="pgae400-B60" content-id="pgae400-B60" data-legacy-id="pgae400-B60"><p><span>60</span></p><div><p>Acemoglu</p>  <p>D</p><p>, <span><p>Restrepo</p>  <p>P</p></span>. </p><p>2019</p><p>. </p><p>Automation and new tasks: how technology displaces and reinstates labor</p><p>. </p><p>J Econ Perspect</p><p>. </p><p>33</p><p>(</p><p>2</p><p>):</p><p>3</p><p>–</p><p>30</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B61" data-id="pgae400-B61" content-id="pgae400-B61" data-legacy-id="pgae400-B61"><p><span>61</span></p><div><p>Li</p>  <p>H</p><p>, <span><p>Vincent</p>  <p>N</p></span>, <span><p>Chancellor</p>  <p>S</p></span>, <span><p>Hecht</p>  <p>B</p></span>. </p><p>2023</p><p>. </p><p>The dimensions of data labor: a road map for researchers, activists, and policymakers to empower data producers. In: Proceedings of the 2023 ACM Conference on Fairness, Accountability, and Transparency; Chicago. ACM. p. 1151–1161</p><p>.</p></div></div><div id="ref-auto-pgae400-B62" data-id="pgae400-B62" content-id="pgae400-B62" data-legacy-id="pgae400-B62"><p><span>62</span></p><div><p>Johnson</p>  <p>S</p><p>, <span><p>Acemoglu</p>  <p>D</p></span>. </p><p>2023</p><p>. </p><p>Power and progress: our thousand-year struggle over technology and prosperity</p><p>. </p><p>UK</p><p>: </p><p>Hachette</p><p>.</p><!--citationLinks: case 2--></div></div><div id="ref-auto-pgae400-B63" data-id="pgae400-B63" content-id="pgae400-B63" data-legacy-id="pgae400-B63"><p><span>63</span></p><div><p>Lehdonvirta</p>  <p>V</p><p>. </p><p>2022</p><p>. </p><p>Cloud empires: how digital platforms are overtaking the state and how we can regain control</p><p>. </p><p>Cambridge</p><p>: </p><p>MIT Press</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B64" data-id="pgae400-B64" content-id="pgae400-B64" data-legacy-id="pgae400-B64"><p><span>64</span></p><div><p>Kummer</p>  <p>M</p><p>, <span><p>Slivko</p>  <p>O</p></span>, <span><p>Zhang</p>  <p>X</p></span>. </p><p>2020</p><p>. </p><p>Unemployment and digital public goods contribution</p><p>. </p><p>Inform Syst Res</p><p>. </p><p>31</p><p>(</p><p>3</p><p>):</p><p>801</p><p>–</p><p>819</p><p>.</p><!--citationLinks: case 1--></div></div><div id="ref-auto-pgae400-B65" data-id="pgae400-B65" content-id="pgae400-B65" data-legacy-id="pgae400-B65"><p><span>65</span></p><div><p>Anderson</p>  <p>A</p><p>, <span><p>Huttenlocher</p>  <p>D</p></span>, <span><p>Kleinberg</p>  <p>J</p></span>, <span><p>Leskovec</p>  <p>J</p></span>. </p><p>2012</p><p>. </p><p>Discovering value from community activity on focused question answering sites: a case study of Stack Overflow. In: Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; Beijing. ACM. p. 850–858</p><p>.</p></div></div><div id="ref-auto-pgae400-B66" data-id="pgae400-B66" content-id="pgae400-B66" data-legacy-id="pgae400-B66"><p><span>66</span></p><div><p>Mamykina</p>  <p>L</p><p>, <span><p>Manoim</p>  <p>B</p></span>, <span><p>Mittal</p>  <p>M</p></span>, <span><p>Hripcsak</p>  <p>G</p></span>, <span><p>Hartmann</p>  <p>B</p></span>. </p><p>2011</p><p>. </p><p>Design lessons from the fastest Q&amp;A site in the west. In: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems; Vancouver. ACM. p. 2857–2866</p><p>.</p></div></div><div id="ref-auto-pgae400-B67" data-id="pgae400-B67" content-id="pgae400-B67" data-legacy-id="pgae400-B67"><p><span>67</span></p><div><p>Franzke</p>  <p>AS</p><p>, <span><p>Bechmann</p>  <p>A</p></span>, <span><p>Zimmer</p>  <p>M</p></span>, <span><p>Ess</p>  <p>C</p></span>, </p><p>The Association of Internet Researchers</p><p>. </p><p>2020</p><p>. </p><p>Internet research: ethical guidelines 3.0. Technical Report, Association of Internet Researchers</p><p>.</p></div></div><div id="ref-auto-pgae400-B68" data-id="pgae400-B68" content-id="pgae400-B68" data-legacy-id="pgae400-B68"><p><span>68</span></p><div><p>Gousios</p>  <p>G</p><p>, <span><p>Spinellis</p>  <p>D</p></span>. </p><p>2012</p><p>. </p><p>GHTorrent: GitHub’s data from a firehose. In: 2012 9th IEEE Working Conference on Mining Software Repositories (MSR); Zurich. IEEE. p. 12–21</p><p>.</p></div></div><div id="ref-auto-pgae400-B69" data-id="pgae400-B69" content-id="pgae400-B69" data-legacy-id="pgae400-B69"><p><span>69</span></p><div><p>Héder</p>  <p>M</p><p>, <em>et al</em>. </p><p>2022</p><p>. </p><p>The past, present and future of the ELKH cloud</p><p>. </p><p>Inform Társadalom</p><p>. </p><p>22</p><p>(</p><p>2</p><p>):</p><p>128</p><p>.</p><!--citationLinks: case 1--></div></div></div>    <!-- /foreach in Model.Sections -->
    



        

        
                    <h2 id="authorNotesSectionTitle" scrollto-destination="authorNotesSectionTitle">Author notes</h2>
<p><span><p><strong>Competing Interest:</strong> The authors declare no competing interests.</p></span></p><p>© The Author(s) 2024. Published by Oxford University Press on behalf of National Academy of Sciences.</p><div><p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">https://creativecommons.org/licenses/by/4.0/</a>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</p></div><!-- /foreach -->

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eating less can lead to a longer life: study in mice shows why (103 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-03277-6</link>
            <guid>41826449</guid>
            <pubDate>Sun, 13 Oct 2024 09:25:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-03277-6">https://www.nature.com/articles/d41586-024-03277-6</a>, See on <a href="https://news.ycombinator.com/item?id=41826449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
        <div>
            <ul data-test="article-identifier">
                <li data-test="article-category"><span>NEWS</span></li>
                <li><time datetime="2024-10-09">09 October 2024</time></li>
                
            </ul>

            

            <div>
                
                <p>
                    Weight loss and metabolic improvements do not explain the longevity benefits of severe dietary restrictions.
                </p>
            </div>
        </div>
        
            <div data-test="author-info">
    <ol>
        
            <li>
                
                    <span>Elie Dolgin</span>
                
                
                    <ol>
                        <li id="Aff0">
                            <p>Elie Dolgin is a science journalist in Somerville, Massachusetts.</p>
                        </li>
                    </ol>
                
                
                    
                
            </li>
        
    </ol>
</div>
        
    </header>
    
</div><div>
                    
                        <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03277-6/d41586-024-03277-6_27701126.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03277-6/d41586-024-03277-6_27701126.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Coloured scanning electron micrograph of fat cells shown in various shades of pink" loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03277-6/d41586-024-03277-6_27701126.jpg">
  <figcaption>
   <p><span>Fat cells (artificially coloured). Restrictive diets cause fat loss and lengthen life, but the two effects are not necessarily linked.</span><span>Credit: Steve Gschmeissner/SPL</span></p>
  </figcaption>
 </picture>
</figure><p>Cutting calorie intake can lead to a leaner body — <a href="https://www.nature.com/articles/nature.2014.14963" data-track="click" data-label="https://www.nature.com/articles/nature.2014.14963" data-track-category="body text link">and a longer life</a>, an effect often chalked up to the weight loss and <a href="https://www.nature.com/articles/d41586-018-03431-x" data-track="click" data-label="https://www.nature.com/articles/d41586-018-03431-x" data-track-category="body text link">metabolic changes caused by consuming less food</a>. Now, one of the biggest studies<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> of dietary restrictions ever conducted in laboratory animals challenges the conventional wisdom about how dietary restriction boosts longevity.</p><p>The study, involving nearly 1,000 mice fed low-calorie diets or subjected to regular bouts of <a href="https://www.nature.com/articles/d41586-024-02700-2" data-track="click" data-label="https://www.nature.com/articles/d41586-024-02700-2" data-track-category="body text link">fasting</a>, found that such regimens do indeed cause weight loss and related metabolic changes. But other factors — including <a href="https://www.nature.com/articles/d41586-024-00871-6" data-track="click" data-label="https://www.nature.com/articles/d41586-024-00871-6" data-track-category="body text link">immune health</a>, genetics and physiological indicators of resiliency — seem to better explain the link between cutting calories and increased lifespan.</p><p>“The metabolic changes are important,” says Gary Churchill, a mouse geneticist at the Jackson Laboratory in Bar Harbor, Maine, who co-led the study. “But they don’t lead to lifespan extension.”</p><p>To outside investigators, the results drive home the intricate and individualized nature of the body’s reaction to caloric restriction. “It’s revelatory about the complexity of this intervention,” says James Nelson, a biogerontologist at the University of Texas Health Science Center in San Antonio.</p><p>The study was published today in <i>Nature</i> by Churchill and his co-authors, including scientists at Calico Life Sciences in South San Francisco, California, the anti-ageing focused biotech company that funded the study.</p><h2>Counting calories</h2><p>Scientists have long known that caloric restriction, a regimen of long-term limits on food intake, lengthens lifespan in laboratory animals<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. Some studies<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup><sup>,</sup><sup><a href="#ref-CR4" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">4</a></sup> have shown that intermittent fasting, which involves <a href="https://www.nature.com/articles/d41586-021-01578-8" data-track="click" data-label="https://www.nature.com/articles/d41586-021-01578-8" data-track-category="body text link">short bouts of food deprivation</a>, can also increase longevity.</p><p>To learn more about how such diets work, the researchers monitored the health and longevity of 960 mice, each a genetically distinct individual drawn from a diverse population that mirrors the genetic variability found in humans. Some mice were placed on calorie-limited diets, another group followed intermittent fasting regimens, and others were allowed to eat freely.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-03244-1" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03277-6/d41586-024-03277-6_27700972.jpg"><p>Life expectancy rise in rich countries slows down: why discovery took 30 years to prove</p></a>
 </article><p>Cutting calories by 40% yielded the longest longevity bump, but intermittent fasting and less severe calorie restriction also increased average lifespan. The dieting mice also displayed favourable metabolic changes, such as reductions in body fat and blood sugar levels.</p><p>However, the effects of dietary restriction on metabolism and lifespan didn’t always change in lockstep. To the authors’ surprise, the mice that lost the most weight on a calorie-limited diet tended to die younger than did animals that lost relatively modest amounts.</p><p>This suggests that processes beyond simple metabolic regulation drive how the body responds to limited-calorie regimes. What mattered most for lengthening lifespan were traits related to immune health and red-blood-cell function. Also key was overall resilience, presumably encoded in the animals’ genes, to the stress of reduced food intake.</p><p>“The intervention is a stressor,” Churchill explains. The most-resilient animals lost the least weight, maintained immune function and lived longer.</p><h2>Leanness for longevity</h2><p>The findings could reshape how scientists think about studies of dietary restriction in humans. In one of the most comprehensive clinical trials of a low-calorie diet in healthy, non-obese individuals, researchers found<sup><a href="#ref-CR5" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">5</a></sup> that <a href="https://www.nature.com/articles/d41586-018-03431-x" data-track="click" data-label="https://www.nature.com/articles/d41586-018-03431-x" data-track-category="body text link">the intervention helped to dial down metabolic rates</a> — a short-term effect thought to signal longer-term benefits for lifespan.</p><p>But the mouse data from Churchill’s team suggest that metabolic measurements might reflect <a href="https://www.nature.com/articles/529154a" data-track="click" data-label="https://www.nature.com/articles/529154a" data-track-category="body text link">‘healthspan’ — the period of life spent free from chronic disease and disability</a> — but that other metrics are needed to say whether such ‘anti-ageing’ strategies can truly extend life.</p><p>Daniel Belsky, an epidemiologist who studies ageing at the Columbia University Mailman School of Public Health in New York City, cautions against over-extrapolating from mice to humans. But he also acknowledges that the study “adds to the growing understanding we have that healthspan and lifespan are not the same thing”.</p>
                    
                </div><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference" data-track-context="references section"><li data-counter="1."><p id="ref-CR1">Di Francesco, A. <i>et al.</i> <i>Nature</i> https://doi.org/10.1038/s41586-024-08026-3 (2024).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41586-024-08026-3" data-track-item_id="10.1038/s41586-024-08026-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-024-08026-3" aria-label="Article reference 1" data-doi="10.1038/s41586-024-08026-3">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Nature&amp;doi=10.1038%2Fs41586-024-08026-3&amp;publication_year=2024&amp;author=Di%20Francesco%2CA.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Fontana, L., Partridge, L. &amp; Longo, V. D. <i>Science</i> <b>328</b>, 321–326 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1126/science.1172539" data-track-item_id="10.1126/science.1172539" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1172539" aria-label="Article reference 2" data-doi="10.1126/science.1172539">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20395504" aria-label="PubMed reference 2">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Science&amp;doi=10.1126%2Fscience.1172539&amp;volume=328&amp;pages=321-326&amp;publication_year=2010&amp;author=Fontana%2CL.&amp;author=Partridge%2CL.&amp;author=Longo%2CV.%20D.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Mitchell, S. <i>et al.</i> <i>Cell Metab.</i> <b>29</b>, 221–228.e3 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cmet.2018.08.011" data-track-item_id="10.1016/j.cmet.2018.08.011" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cmet.2018.08.011" aria-label="Article reference 3" data-doi="10.1016/j.cmet.2018.08.011">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30197301" aria-label="PubMed reference 3">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Cell%20Metab.&amp;doi=10.1016%2Fj.cmet.2018.08.011&amp;volume=29&amp;pages=221-228.e3&amp;publication_year=2019&amp;author=Mitchell%2CS.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="4."><p id="ref-CR4">Duregon, E. <i>et al.</i> <i>Cell Metab.</i> <b>35</b>, 1179–1194.e5 (2023).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.cmet.2023.05.003" data-track-item_id="10.1016/j.cmet.2023.05.003" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cmet.2023.05.003" aria-label="Article reference 4" data-doi="10.1016/j.cmet.2023.05.003">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=37437544" aria-label="PubMed reference 4">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=Cell%20Metab.&amp;doi=10.1016%2Fj.cmet.2023.05.003&amp;volume=35&amp;pages=1179-1194.e5&amp;publication_year=2023&amp;author=Duregon%2CE.">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="5."><p id="ref-CR5">Ravussin, E. <i>et al.</i> <i>J. Gerentol. Ser. A</i> <b>70</b>, 1097–1104 (2015).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/gerona/glv057" data-track-item_id="10.1093/gerona/glv057" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fgerona%2Fglv057" aria-label="Article reference 5" data-doi="10.1093/gerona/glv057">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=&amp;journal=J.%20Gerentol.%20Ser.%20A&amp;doi=10.1093%2Fgerona%2Fglv057&amp;volume=70&amp;pages=1097-1104&amp;publication_year=2015&amp;author=Ravussin%2CE.">
                    Google Scholar</a>&nbsp;
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/d41586-024-03277-6?format=refman&amp;flavour=references">Download references</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playable Counter-Strike Diffusion World Model (trained on 2x4090, 5M frames) (268 pts)]]></title>
            <link>https://diamond-wm.github.io/</link>
            <guid>41826402</guid>
            <pubDate>Sun, 13 Oct 2024 09:18:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diamond-wm.github.io/">https://diamond-wm.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=41826402">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <h2>How does it work?</h2>
            <p>
              We train a diffusion model to predict the next frame of the game.
              The diffusion model takes into account the agent’s action and the previous frames
              to simulate the environment response.
            </p>
            <figure>
              <img src="https://diamond-wm.github.io/static/gifs/kungfu.gif" alt="The diffusion world model takes into account the agent's action and previous frames to generate the next frame.">
              <center><blockquote>The diffusion world model takes into account the agent's action and previous frames to generate the next frame.</blockquote></center>
            </figure>
          <p><br>
            The agent repeatedly provides new actions, and the diffusion model updates the game.
          </p>
          <p>
            The diffusion model acts as a world model in which the agent can learn to play.
          </p>
          <center>
            <img src="https://diamond-wm.github.io/static/gifs/imagination.gif" alt="Autoregressive generation with diffusion world model.">
            <figcaption><blockquote>Autoregressive generation enables the diffusion model to act as a world model in which the agent can learn to play.</blockquote></figcaption>
          </center>
          
            <p>
            To make the world model fast, we need to reduce the number of denoising steps.
            We found <a href="https://arxiv.org/abs/2006.11239">DDPM</a> (Ho et al. 2020) to become unstable with low numbers of denoising steps.
            In contrast, we found <a href="https://arxiv.org/abs/2206.00364">EDM</a> (Karras et al., 2022) to produce stable trajectories even for 1 denoising step.
          </p>
          <center>
            <img src="https://diamond-wm.github.io/static/gifs/ddpm.gif" alt="DDPM vs EDM based diffusion world models. The DDPM-based model becomes unstable for low numbers of denoising steps, while the EDM-based model remains stable.">
            <figcaption><blockquote>The DDPM-based model is unstable for low numbers of denoising steps due to accumulating autoregressive error, while the EDM-based model remains stable. Lower denoising steps enables a faster world model.</blockquote></figcaption>
          </center>
          
          <p>
            But in Boxing, 1-step denoising interpolates between possible outcomes and results in blurry predictions for the unpredictable black player.
          </p>
          <p>
            In contrast, using more denoising steps enables better selection of a particular mode, improving consistency over time.
          </p>
          <center>
            <img src="https://diamond-wm.github.io/static/gifs/boxing.gif" alt="Diffusion world model trajectories for the Atari game Boxing for varying numbers of denoising steps.">
            <figcaption><blockquote>Larger numbers of denoising steps n enable better mode selection for transitions with multiple modes. We therefore use n=3 for Diamond's diffusion world model.</blockquote></figcaption>
          </center>
          
          <p>
            Interestingly, the white player's movements are predicted correctly regardless of the number of denoising steps.
            This is because it is controlled by the policy, so its actions are given to the world model. This removes any ambiguity that can cause blurry predictions.
          </p>
          <p>
            We find that diffusion-based DIAMOND provides better modeling of important visual details than the discrete token-based <a href="https://arxiv.org/abs/2209.00588">IRIS</a>.
          </p>
          <center>
            <img src="https://diamond-wm.github.io/static/gifs/iris.gif" alt="Visualisation of IRIS and DIAMOND world's models on Asterix, Breakout and RoadRunner.">
            <figcaption><blockquote>DIAMOND's world model is able to better capture important visual details than the discrete token-based IRIS.</blockquote></figcaption>
          </center>
          <br>
          <div><p>
            Training an agent with reinforcement learning on this diffusion world model, DIAMOND achieves a mean human-normalized score of 1.46 on Atari 100k (46% better than human); a new best for agents trained in a world model on 100k frames.
            </p><p>
            
            Check out our <a href="https://arxiv.org/pdf/2405.12399">paper</a> for more details!
          </p></div>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WordPress.org's latest move involves taking control of a WP Engine plugin (234 pts)]]></title>
            <link>https://www.theverge.com/2024/10/12/24268637/wordpress-org-matt-mullenweg-acf-fork-secure-custom-fields-wp-engine</link>
            <guid>41826082</guid>
            <pubDate>Sun, 13 Oct 2024 08:05:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/10/12/24268637/wordpress-org-matt-mullenweg-acf-fork-secure-custom-fields-wp-engine">https://www.theverge.com/2024/10/12/24268637/wordpress-org-matt-mullenweg-acf-fork-secure-custom-fields-wp-engine</a>, See on <a href="https://news.ycombinator.com/item?id=41826082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>WordPress.org has taken over a popular WP Engine plugin in order “to remove commercial upsells and fix a security problem,” WordPress cofounder and Automattic CEO Matt Mullenweg <a href="https://wordpress.org/news/2024/10/secure-custom-fields/">announced today</a>. This “minimal” update, which he labels a fork of the Advanced Custom Fields (ACF) plugin, is <a href="https://wordpress.org/plugins/advanced-custom-fields/">now called</a> “Secure Custom Fields.”</p><p>It’s not clear what security problem Mullenweg is referring to in the post. He writes that he’s “invoking point 18 of the plugin directory guidelines,” <a href="https://github.com/wordpress/wporg-plugin-guidelines/blob/trunk/guideline-18.md">in which</a> the WordPress team reserves several rights, including removing a plugin, or changing it “without developer consent.” Mullenweg explains that the move has to do with WP Engine’s <a href="https://www.theverge.com/2024/10/3/24261016/wordpress-wp-engine-lawsuit-automattic-matt-mullenweg">recently-filed lawsuit</a> against him and Automattic.</p><div><blockquote><p>Similar situations have happened before, but not at this scale. This is a rare and unusual situation brought on by WP Engine’s legal attacks, we do not anticipate this happening for other plugins.</p></blockquote></div><p>WP Engine’s ACF team <a href="https://x.com/wp_acf/status/1845169499064107049">claimed on X</a> that WordPress has never “unilaterally and forcibly” taken a plugin “from its creator without consent.” It later <a href="https://x.com/wp_acf/status/1845190372764401908?s=46&amp;t=s7yjJ2YTk92nj3NQJLk0ww">wrote</a> that those who aren’t WP Engine, Flywheel, or ACF Pro customers will need to go to the ACF site and follow steps it <a href="https://www.advancedcustomfields.com/blog/installing-and-upgrading-to-the-latest-version-of-acf/#update-acf">published earlier</a> to “perform a 1-time download of the genuine 6.3.8 version” to keep getting updates.</p><p>As its name implies, the ACF plugin allows website creators to use custom fields when existing generic ones won’t do — something ACF’s <a href="https://www.advancedcustomfields.com/resources/getting-started-with-acf/">overview</a> of the plugin says is already a native, but “not very user friendly,” feature of WordPress. </p><p><em>The Verge</em> has reached out to Automattic, <a href="http://wordpress.org/">WordPress.org</a>, and WP Engine for comment.</p><p><em><strong>Update October 12th: </strong>Adjusted to add clarity about Mullenweg’s use of the “fork” label.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ACF Has Been Hijacked (221 pts)]]></title>
            <link>https://anderegg.ca/2024/10/13/acf-has-been-hijacked</link>
            <guid>41824852</guid>
            <pubDate>Sun, 13 Oct 2024 03:05:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://anderegg.ca/2024/10/13/acf-has-been-hijacked">https://anderegg.ca/2024/10/13/acf-has-been-hijacked</a>, See on <a href="https://news.ycombinator.com/item?id=41824852">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
				<article>
					
					<h3>October 13, 2024</h3>
					<p>It’s super late at night on Thanksgiving weekend in Canada. I shouldn’t be thinking about weird internet drama, but here we are.</p>

<p><a href="https://anderegg.ca/2024/10/10/loyalty-test-checkbox">Since I last wrote</a> about the ongoing WordPress drama:</p>

<ul>
  <li>Matt Mullenweg promoted a “fork” of WordPress that wasn’t actually a fork.</li>
  <li>He then hijacked one of the most prominent plugins in the WordPress development world.</li>
</ul>

<p>The first point is pretty minor, but highlights the depths of strangeness at play. <a href="https://x.com/vinnysgreen">Vinny Green</a> created <a href="https://freewp.com/">a project called FreeWP</a> that… actually, I don’t actually know what it’s about. You need to read the site for yourself. It seems to be an announcement of an organization that includes a news site, a class action lawsuit, and <a href="https://freewp.com/faq/">some other things</a>. It’s not really clear to me, and it seems like it might be an elaborate troll.</p>

<p>This normally wouldn’t be news, <a href="https://wordpress.org/news/2024/10/spoon/">except Matt Mullenweg made it so</a>. It’s uncertain if Mullenweg even understood what Green was building, but Green was quick to point out that <a href="https://x.com/vinnysgreen/status/1844488053060141233">it wasn’t a fork of WordPress</a>. Mullenweg then amended his post to include <a href="https://aspirepress.org/about-us/">AspirePress</a>, and noted a spelling error. The whole thing seems strange, but I’m assuming that Mullenweg wrote the blog post to make fun of potential WordPress forks.</p>

<p>The bigger issue happened on Saturday when <a href="https://wordpress.org/news/2024/10/secure-custom-fields/">Automattic hijacked the Advanced Custom Fields (ACF) plugin</a>. As I’ve written in the past, <a href="https://anderegg.ca/2024/10/06/wordpress-vs-acf#:~:text=ACF%20is%20a%20WordPress%20plugin%20that%20is%20a%20requirement%20for%20many%20WordPress%20builds">ACF is a major plugin in the WordPress development world</a>, and a requirement for many custom websites. It’s also owned by WP Engine, the company Mullenweg is beefing with. In the previous link, I had guessed that Mullenweg intended to kick them out of the WordPress plugin directory. Turns out, they went one further.</p>

<p>In a post titled “<a href="https://wordpress.org/news/2024/10/secure-custom-fields/">Secure Custom Fields</a>”, and in the category “Security”, Mullenweg posted that he was invoking “<a href="https://github.com/wordpress/wporg-plugin-guidelines/blob/trunk/guideline-18.md">point 18</a>” of the plugin directory guidelines to hijack the ACF plugin. ACF is ostensibly offered under the GPL because it interfaces with WordPress. That said, it doesn’t have an explicit license listed on <a href="https://github.com/AdvancedCustomFields/acf">its GitHub page</a>. Still, it’s almost certainly legal and reasonable for Automattic to fork it and do whatever it wants with the source code.</p>

<p>But that’s not the point. ACF is something that WordPress users trust and expect to come from a specific source. That Automattic would unilaterally decide to hijack such a popular plugin is completely insane. I’m not sure how this differs from a supply-chain attack. As I’ve written, the reason for this is invented and <a href="https://anderegg.ca/2024/10/06/wordpress-vs-acf#:~:text=The%20issue%20here%20is%20that%20the%20ACF%20team%20has%20been%20blocked%20by%20Mullenweg%20from%20accessing%20WordPress.org%20and%20the%20infrastructure%20it%20provides.">brought on by Automattic’s blocking of WP Engine employees from WordPress.org</a>. Automattic just happened to find a mild vulnerability in ACF, and is now using <strong>the block Automattic imposed</strong> as a reason to take control of the plugin because the ACF team can’t update the plugin while the block is in place.</p>

<p>This is some Grade-A 100% bullshit.</p>

<p>The ACF site has been <a href="https://www.advancedcustomfields.com/">updated with a notice about the takeover</a>, but most users likely won’t see this. The team behind the WordPress plugin directory could now update ACF to make any changes they’d like. If they’re willing to do this, I wouldn’t trust any plugins hosted on WordPress.org.</p>

<p>I really don’t know what to say at this point. I assumed that ACF would be removed from the WordPress plugin directory, but I never would have guessed it would be hijacked. It seems like Mullenweg has lost the plot completely.</p>

<p>If you use WordPress for a living, I recommend strongly that you consider changing platforms.</p>

				</article>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FLUX is fast and it's open source (199 pts)]]></title>
            <link>https://replicate.com/blog/flux-is-fast-and-open-source</link>
            <guid>41824390</guid>
            <pubDate>Sun, 13 Oct 2024 01:28:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://replicate.com/blog/flux-is-fast-and-open-source">https://replicate.com/blog/flux-is-fast-and-open-source</a>, See on <a href="https://news.ycombinator.com/item?id=41824390">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
    

<article>
  <hgroup>
    

    <p>
      Posted
      <time datetime="2024-10-10">
        October 10, 2024
      </time>
      by
      

      
      <a href="https://replicate.com/bfirsh">@bfirsh</a>

      
    </p>
  </hgroup>

  
<div>
  <p>FLUX is now much faster on Replicate, and we’ve made our optimizations open-source so you can see exactly how they work and build upon them.</p>
<p>Here are the end-to-end speeds:</p>
<ul>
<li><a href="https://replicate.com/black-forest-labs/flux-schnell">FLUX.1 [schnell]</a> at 512x512 and 4 steps: 0.29 seconds (P90: 0.49 seconds)</li>
<li><a href="https://replicate.com/black-forest-labs/flux-schnell">FLUX.1 [schnell]</a> at 1024x1024 and 4 steps: 0.72 seconds (P90: 0.95 seconds)</li>
<li><a href="https://replicate.com/black-forest-labs/flux-dev">FLUX.1 [dev]</a> at 1024x1024 and 28 steps: 3.03 seconds (P90: 3.90 seconds)</li>
</ul>
<p>This is from the west coast of the US using the Python client.</p>
<p>Here’s a demo of FLUX.1 [schnell]. (It’s live, just start typing!)</p>


<p>Here’s <a href="https://fast-flux-demo.replicate.workers.dev/">the full app, and source code</a>, if you’d like to check it out.</p>
<h2 id="how-did-we-do-it">How did we do it?</h2>
<p>Most of the models on Replicate are contributed by our community, but we maintain the FLUX models in collaboration with <a href="https://blackforestlabs.ai/">Black Forest Labs</a>.</p>
<p>We’ve done two main things to make FLUX faster:</p>
<ul>
<li>We optimized the model. We used Alex Redden’s <a href="https://github.com/aredden/flux-fp8-api">flux-fp8-api</a> as a starting point, then optimized it with <code>torch.compile</code> and used fast CuDNN attention kernels in the nightly Torch builds.</li>
<li>We added a new <a href="https://replicate.com/changelog/2024-10-09-synchronous-api">synchronous HTTP API</a> that makes all image models much faster on Replicate.</li>
</ul>
<p>The quantization in flux-fp8-api slightly changes the output of the model, but we have found it has little impact on the quality.</p>
<p><a href="https://flux-quality-comparison.vercel.app/">
<img src="https://d31rfu1d3w8e4q.cloudfront.net/static/blog/flux-is-fast/slow.webp" title="Guess which is which!">
</a>
<a href="https://flux-quality-comparison.vercel.app/">
<img src="https://d31rfu1d3w8e4q.cloudfront.net/static/blog/flux-is-fast/fast.webp" title="Guess which is which!">
</a>
</p>

<p>We’ve created a tool that compares the output of thousands of prompts on FLUX.1 [schnell] and FLUX.1 [dev]. We’re not cherry picking. <a href="https://flux-quality-comparison.vercel.app/">Take a look for yourself.</a></p>
<p>You can disable this by setting the <code>go_fast</code> input on the model to <code>false</code>.</p>
<p>We want to be open with you about how we’re optimizing the models. It’s notoriously hard to compare output between models and providers, and it’s often unclear whether providers are doing things that impact the quality of the model.</p>
<p>We’re just going to tell you how we did it and let you disable any optimizations. That means you’re not wondering whether the output you’re getting is the best quality it can be.</p>
<p>Most importantly, the code is open-source, so you can see exactly how it works: <a href="https://github.com/replicate/cog-flux">github.com/replicate/cog-flux</a></p>
<h2 id="open-source-should-be-fast-too">Open-source should be fast too</h2>
<p>Open-source models are often slow out of the box. Model providers then optimize these models to make them fast and release them behind proprietary APIs, without contributing the improvements back to the community.</p>
<p>We want to change that. We think open-source should be fast too.</p>
<p><a href="https://github.com/replicate/cog-flux">We’re open-sourcing all the improvements we make to FLUX.</a> We’re also collaborating with the <a href="https://github.com/ai-compiler-study">AI Compiler Study Group</a> and other AI researchers to make an open-source fast version of FLUX. </p>
<p>Making the FLUX optimizations open-source is not just the right thing to do, it also means all the experts in the world can collaborate together to make it the fastest. Pull requests welcome.</p>
<h2 id="its-going-to-get-faster">It’s going to get faster</h2>
<p>New techniques are coming out all the time to make models faster, and by collaborating with the community, you can be sure that they’re going to be on Replicate as fast as possible. Stay tuned.</p>
<h2 id="do-more-with-flux">Do more with FLUX</h2>
<p>You can do more than just run FLUX on Replicate. You can:</p>
<ul>
<li><a href="https://replicate.com/blog/fine-tune-flux">Fine-tune FLUX on your own data</a> (training and running trained models is going to much faster soon too!)</li>
<li><a href="https://github.com/replicate/cog-flux">Edit the code and deploy a custom version</a>, if you’re doing something advanced</li>
<li><a href="https://replicate.com/playground/">Try out the models and compare outputs on our new playground</a></li>
</ul>
<p><a href="https://x.com/replicate">Follow us on X</a> to keep up to speed.</p>
</div>


  
</article>



    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omni SenseVoice: High-Speed Speech Recognition with Words Timestamps (103 pts)]]></title>
            <link>https://github.com/lifeiteng/OmniSenseVoice</link>
            <guid>41824171</guid>
            <pubDate>Sun, 13 Oct 2024 00:48:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lifeiteng/OmniSenseVoice">https://github.com/lifeiteng/OmniSenseVoice</a>, See on <a href="https://news.ycombinator.com/item?id=41824171">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Omni SenseVoice 🚀</h2><a id="user-content-omni-sensevoice-" aria-label="Permalink: Omni SenseVoice 🚀" href="#omni-sensevoice-"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The Ultimate Speech Recognition Solution</h2><a id="user-content-the-ultimate-speech-recognition-solution" aria-label="Permalink: The Ultimate Speech Recognition Solution" href="#the-ultimate-speech-recognition-solution"></a></p>
<p dir="auto">Built on <a href="https://github.com/FunAudioLLM/SenseVoice">SenseVoice</a>, Omni SenseVoice is optimized for lightning-fast inference and precise timestamps—giving you a smarter, faster way to handle audio transcription!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<div data-snippet-clipboard-copy-content="omnisense transcribe [OPTIONS] AUDIO_PATH"><pre><code>omnisense transcribe [OPTIONS] AUDIO_PATH
</code></pre></div>
<p dir="auto">Key Options:</p>
<ul dir="auto">
<li><code>--language</code>: Automatically detect the language or specify (<code>auto, zh, en, yue, ja, ko</code>).</li>
<li><code>--textnorm</code>: Choose whether to apply inverse text normalization (<code>withitn for inverse normalized</code> or <code>woitn for raw</code>).</li>
<li><code>--device-id</code>: Run on a specific GPU (default: -1 for CPU).</li>
<li><code>--quantize</code>: Use a quantized model for faster processing.</li>
<li><code>--help</code>: Display detailed help information.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark</h2><a id="user-content-benchmark" aria-label="Permalink: Benchmark" href="#benchmark"></a></p>
<p dir="auto"><code>omnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl</code></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Optimize</th>
<th>GPU</th>
<th>WER ⬇️</th>
<th>RTF ⬇️</th>
<th>Speed Up 🔥</th>
</tr>
</thead>
<tbody>
<tr>
<td>baseline(onnx)</td>
<td>NVIDIA L4 GPU</td>
<td>4.47%</td>
<td>0.1200</td>
<td>1x</td>
</tr>
<tr>
<td>torch</td>
<td>NVIDIA L4 GPU</td>
<td>5.02%</td>
<td>0.0022</td>
<td>50x</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li>With Omni SenseVoice, experience up to 50x faster processing without sacrificing accuracy.</li>
</ul>
<div data-snippet-clipboard-copy-content="# LibriTTS
DIR=benchmark/data
lhotse download libritts -p dev-clean benchmark/dataLibriTTS
lhotse prepare libritts -p dev-clean benchmark/data/LibriTTS/LibriTTS benchmark/data/manifests/libritts

lhotse cut simple --force-eager -r benchmark/data/manifests/libritts/libritts_recordings_dev-clean.jsonl.gz \
    -s benchmark/data/manifests/libritts/libritts_supervisions_dev-clean.jsonl.gz \
    benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl

omnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 -
-textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl

omnisense benchmark -s --num-workers 4 --device-id 0 --batch-size 16 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl"><pre><code># LibriTTS
DIR=benchmark/data
lhotse download libritts -p dev-clean benchmark/dataLibriTTS
lhotse prepare libritts -p dev-clean benchmark/data/LibriTTS/LibriTTS benchmark/data/manifests/libritts

lhotse cut simple --force-eager -r benchmark/data/manifests/libritts/libritts_recordings_dev-clean.jsonl.gz \
    -s benchmark/data/manifests/libritts/libritts_supervisions_dev-clean.jsonl.gz \
    benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl

omnisense benchmark -s -d --num-workers 2 --device-id 0 --batch-size 10 -
-textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl

omnisense benchmark -s --num-workers 4 --device-id 0 --batch-size 16 --textnorm woitn --language en benchmark/data/manifests/libritts/libritts_cuts_dev-clean.jsonl
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing 🙌</h2><a id="user-content-contributing-" aria-label="Permalink: Contributing 🙌" href="#contributing-"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 1: Code Formatting</h4><a id="user-content-step-1-code-formatting" aria-label="Permalink: Step 1: Code Formatting" href="#step-1-code-formatting"></a></p>
<p dir="auto">Set up pre-commit hooks:</p>
<div data-snippet-clipboard-copy-content="pip install pre-commit==3.6.0
pre-commit install"><pre><code>pip install pre-commit==3.6.0
pre-commit install
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step 2: Pull Request</h4><a id="user-content-step-2-pull-request" aria-label="Permalink: Step 2: Pull Request" href="#step-2-pull-request"></a></p>
<p dir="auto">Submit your awesome improvements through a PR. 😊</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The 1/8th Sleep (155 pts)]]></title>
            <link>https://near.blog/the-1-8th-sleep/</link>
            <guid>41824138</guid>
            <pubDate>Sun, 13 Oct 2024 00:43:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://near.blog/the-1-8th-sleep/">https://near.blog/the-1-8th-sleep/</a>, See on <a href="https://news.ycombinator.com/item?id=41824138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>The eight sleep bed is a popular self-cooling bed. Sleeping on a colder surface not only feels great but often improves sleep as well. This post discusses a cheaper homemade option that I use instead.</p>


<div>
<figure><img decoding="async" src="https://near.blog/wp-content/uploads/2024/10/sleepy.png" alt="" width="394" height="457"><figcaption>A 12℉ difference between the bed surface and the surrounding air. Some ice was used in the cooler prior to the image as measuring surface temperature is challenging with the pictured thermometer.</figcaption></figure></div>


<h3>Why I didn’t Buy an Eight Sleep</h3>



<p>Although many of my friends are happy eight sleep customers, I was put off by the product due to the now-mandatory paired subscription ($200/yr with purchase, annually paired only, can cancel after), the excessive marketing featuring futuristic animations with terms like ‘intelligence’ and ‘autopilot’, constant paid referral links and name dropping of Huberman et al, and the high price points of $3,000 total and $366 for the addition of two pillows and a bed sheet.</p>



<p>I already have a mattress that I like, so I don’t feel the need to replace it. I also inherently dislike the thought of paying a subscription to sleep, and the proprietary nature of the data and cloud app certainly don’t help the case (although I found <a rel="noreferrer noopener" href="https://github.com/bobobo1618/ninesleep" target="_blank">one user who reversed it</a>).</p>







<h3>Popular Alternatives</h3>



<p>Here are a few categories of products in the space:</p>



<ul>
<li>Eight Sleep: $2400 to $7600 depending on options (full mattress)</li>
</ul>



<ul>
<li>Chilipad: $574 to $1300 depending on options (mattress topper only)</li>
</ul>



<ul>
<li>BedJet 3: $429 to $949 (mattress topper only, pretty loud)</li>
</ul>



<ul>
<li>Random Chinese Amazon items: $140-$300 (topper + evaporative cooler, generally not good products)</li>
</ul>



<ul>
<li>Cooling gel mattress pads: $90 (does not actually cool – just a high-ventilation material)</li>
</ul>







<h3>Current Solution</h3>



<p>Here is my current setup, <a rel="noreferrer noopener" href="https://x.com/xannysndtrannys/status/1830167334742606231" target="_blank">inspired fully by this tweet</a>:</p>



<ol>
<li>Low-quality cooling system with a topper: <a rel="noreferrer noopener" href="https://www.amazon.com/dp/B0BZZSQ7GR" target="_blank">Adamson B10 Gray Bed Cooling System</a> ($140)</li>



<li>Replace the above low-quality evaporative cooler with a <a rel="noreferrer noopener" href="https://www.amazon.com/dp/B08C2W5TYW" target="_blank">Poafamx Fish Tank Cooler</a> ($180)</li>



<li>A <a rel="noreferrer noopener" href="https://www.amazon.com/dp/B07RZKRM13" target="_blank">stronger pump</a> ($15) and <a rel="noreferrer noopener" href="https://www.amazon.com/dp/B0CLJNF8LV" target="_blank">small extension tubes</a> ($9)</li>



<li>A <a rel="noreferrer noopener" href="https://www.amazon.com/dp/B09HMZT1C5" target="_blank">small cooler</a> which allows me to get the temperature extra low before bed ($18) </li>



<li>A <a rel="noreferrer noopener" href="https://www.amazon.com/gp/product/B084JML1WN" target="_blank">Smart plug</a> in order to turn the system on and off from my phone ($20)</li>
</ol>



<p>The total came out to $382 (without counting <a rel="noreferrer noopener" href="https://near.blog/personal-finance-tips/" target="_blank">5% off via Amazon</a>) although you could reduce this by at least 15% by <a rel="noreferrer noopener" href="https://www.aliexpress.us/item/3256807457188700.html" target="_blank">purchasing</a> from <a rel="noreferrer noopener" href="https://www.aliexpress.us/item/3256802936516625.html" target="_blank">AliExpress</a> (or much more if you properly source from Alibaba). It’s also possible to save on step one by finding only the mattress topper, but I didn’t want to look through Alibaba for this. </p>



<p>This setup is 1/8th the cost of an eight sleep so I named it <strong>the 1/8th sleep</strong>.</p>







<h3>How It Works</h3>



<p>At first glance it may seem complicated to buy six items, but it’s actually a simple setup. The first item comes with a mattress topper which you can run water through (the low-quality cooling unit it came with was not used). It was placed under the first layer of sheets, making it difficult to notice and aesthetically nonmodifying.</p>



<p>Next you need a way to continuously pump water through the mattress topper, which the pump and cooler are used for (you could just have a pump but the cooler gives you a water reservoir which simplifies the process and allows for more control).</p>



<p>Lastly you need to cool the water, which the fish tank cooler is for (water flows into it and comes out cooler).</p>


<div>
<figure><img decoding="async" loading="lazy" src="https://near.blog/wp-content/uploads/2024/10/cooler.png" alt="" width="362" height="430"><figcaption>An image of the cooler used – I keep it set to as low as it will go which will usually be around 12℉ lower than the air temperature.</figcaption></figure></div>


<p>The extension tubes were purchased so that I could move the setup out of my bedroom entirely both to reduce noise (which was already low – the equivalent of a desktop PC fan) and to ensure any heat output went elsewhere. I placed the tubes near a baseboard and put them under the corner of a door, making it hard to notice I’ve modified my bed at all.</p>



<p>The smart plug allows me to perform a single tap on my phone to turn the system on or off.</p>



<p>As an added bonus you can put ice (or something even colder like dry ice) in the cooler if you’d like to sleep on an extra-cold surface.</p>



<p>The eight sleep bed comes with a sleep tracking app, although I have no reason to believe it is better than a whoop, oura, or apple watch. I use an apple watch to track my sleep which has the benefits of requiring no subscription and of allowing me to export and control my  data (<a rel="noreferrer noopener" href="https://claude.ai/" target="_blank">Claude</a> wrote me a full script to parse my apple health data with just minutes of work</p>







<h3>Tradeoffs Made</h3>



<p>All systems come with trade-offs. Here are some for the 1/8th sleep:</p>



<p>Pros:</p>



<ul>
<li>Significantly cheaper</li>



<li>Ability to excessively lower temperature via ice/dry ice</li>



<li>Ability to further modify the system, e.g. move the cooler out of the room, upgrade only the cooler, cover an arbitrary part of the bed</li>



<li>Can be paired with any mattress – users may keep their existing beds</li>



<li>You don’t have to pay a subscription to sleep</li>
</ul>



<p>Cons:</p>



<ul>
<li>Less aesthetic (This can be improved with a bit of effort – I may 3d-print an optimally-sized encasement)</li>



<li>No ability to heat the mattress</li>



<li>No fine-grained temperature controls via a phone app (I always set it as low as it will cool regardless)</li>



<li>No built-in sleep tracking (I use an Apple watch)</li>



<li>Easier to incorrectly set up: if you don’t tighten tube connectors you could cause a water leak. If you attempt a setup like this it must be thoroughly tested before applying it to your bed!</li>



<li>The mattress topper linked for this setup is for a twin bed, although you could purchase two or find a larger one</li>



<li>Eight sleep loses thousands of dollars in potential revenue (<em>contested</em> – many argue this is a pro)</li>
</ul>







<h3>Conclusion</h3>



<p>This setup is experimental and has only been used for one week. While I’m happy with the results thus far, I wouldn’t suggest it to anyone without an experimental/DIY mindset. This post was made not because the setup is optimal but simply because it seems better to post this than to post nothing at all. This post contains zero referral links.</p>



<p>Special thanks to everyone who responded to <a rel="noreferrer noopener" href="https://x.com/nearcyan/status/1830015788973215834" target="_blank">the initial tweet on the topic</a>, especially <a rel="noreferrer noopener" href="https://x.com/xannysndtrannys/status/1830167334742606231" target="_blank">this response</a> which inspired this setup.</p>



<p><a href="https://near.blog/" target="_blank" rel="noreferrer noopener">Back to my homepage</a></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First Greenhouse Gas Plumes Detected with NASA-Designed Instrument (116 pts)]]></title>
            <link>https://www.jpl.nasa.gov/news/first-greenhouse-gas-plumes-detected-with-nasa-designed-instrument/</link>
            <guid>41822321</guid>
            <pubDate>Sat, 12 Oct 2024 20:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jpl.nasa.gov/news/first-greenhouse-gas-plumes-detected-with-nasa-designed-instrument/">https://www.jpl.nasa.gov/news/first-greenhouse-gas-plumes-detected-with-nasa-designed-instrument/</a>, See on <a href="https://news.ycombinator.com/item?id=41822321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p data-block-key="nq5ze">Using data from an instrument designed by NASA’s Jet Propulsion Laboratory in Southern California, the nonprofit Carbon Mapper has released the first methane and carbon dioxide detections from the Tanager-1 satellite. The detections highlight methane plumes in Pakistan and Texas, as well as a carbon dioxide plume in South Africa.</p><p data-block-key="6g0g9">The data contributes to Carbon Mapper’s goal to identify and measure greenhouse gas point-source emissions on a global scale and make that information accessible and actionable.</p></div><div><p data-block-key="apopd">Enabled by Carbon Mapper and built by Planet Labs PBC, Tanager-1 launched from Vandenberg Space Force Base in California on Aug. 16 and has been collecting data to verify that its imaging spectrometer, which is based on technology developed at NASA JPL, is functioning properly. Both Planet Labs PBC and JPL are members of the philanthropically funded Carbon Mapper Coalition.</p><p data-block-key="9n6n">“The first greenhouse gas images from Tanager-1 are exciting and are a compelling sign of things to come,” said James Graf, director for Earth Science and Technology at JPL. “The satellite plays a crucial role in detecting and measuring methane and carbon dioxide emissions. The mission is a giant step forward in addressing greenhouse gas emissions.”</p><p data-block-key="8p6n5">The data used to produce the Pakistan image was collected over the city of Karachi on Sept. 19 and shows a roughly 2.5-mile-long (4-kilometer-long) methane plume emanating from a landfill. Carbon Mapper’s preliminary estimate of the source emissions rate is more than 2,600 pounds (1,200 kilograms) of methane released per hour.</p><p data-block-key="euvb9">The image collected that same day over Kendal, South Africa, displays a nearly 2-mile-long (3-kilometer-long) carbon dioxide plume coming from a coal-fired power plant. Carbon Mapper’s preliminary estimate of the source emissions rate is roughly 1.3 million pounds (600,000 kilograms) of carbon dioxide per hour.</p><p data-block-key="e6qpj">The Texas image, collected on Sept. 24, reveals a methane plume to the south of the city of Midland, in the Permian Basin, one of the largest oilfields in the world. Carbon Mapper’s preliminary estimate of the source emissions rate is nearly 900 pounds (400 kilograms) of methane per hour.</p><p data-block-key="dma4i">In the 1980s, JPL helped pioneer the development of imaging spectrometers with <a href="https://aviris.jpl.nasa.gov/">AVIRIS</a> (Airborne Visible/Infrared Imaging Spectrometer), and in 2022, NASA installed the imaging spectrometer <a href="https://earth.jpl.nasa.gov/emit/">EMIT</a> (Earth Surface Mineral Dust Source Investigation), developed at JPL, aboard the International Space Station.</p><p data-block-key="89mt6">A descendant of those instruments, the imaging spectrometer aboard Tanager-1 can measure hundreds of wavelengths of light reflected from Earth’s surface. Each chemical compound on the ground and in the atmosphere reflects and absorbs different combinations of wavelengths, which give it a “spectral fingerprint” that researchers can identify. Using this approach, Tanager-1 will help researchers detect and measure emissions down to the facility level.</p><p data-block-key="69ibt">Once in full operation, the spacecraft will scan about 116,000 square miles (300,000 square kilometers) of Earth’s surface per day. Methane and carbon dioxide measurements collected by Tanager-1 will be publicly available on the <a href="https://data.carbonmapper.org/">Carbon Mapper data portal</a>.</p><h3 data-block-key="2im27"><b>More About Carbon Mapper</b></h3><p data-block-key="1a4fp">Carbon Mapper is a nonprofit organization focused on facilitating timely action to mitigate greenhouse gas emissions. Its mission is to fill gaps in the emerging global ecosystem of methane and carbon dioxide monitoring systems by delivering data at facility scale that is precise, timely, and accessible to empower science-based decision making and action. The organization is leading the development of the Carbon Mapper constellation of satellites supported by a public-private partnership composed of Planet Labs PBC, JPL, the California Air Resources Board, Arizona State University, and RMI, with funding from High Tide Foundation, Bloomberg Philanthropies, Grantham Foundation for the Protection of the Environment, and other philanthropic donors.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PayPal (USA) will automatically share data about you to participating stores (267 pts)]]></title>
            <link>https://www.paypal.com/us/legalhub/upcoming-policies-full</link>
            <guid>41822178</guid>
            <pubDate>Sat, 12 Oct 2024 20:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.paypal.com/us/legalhub/upcoming-policies-full">https://www.paypal.com/us/legalhub/upcoming-policies-full</a>, See on <a href="https://news.ycombinator.com/item?id=41822178">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="upcoming-policies-full-introduction"><p data-ppui-id="ppui-suggestion-544"><strong data-ppui-id="ppui-suggestion-545">Notice of Amendment(s) to the United States PayPal Agreement(s)</strong></p>

<p data-ppui-id="ppui-suggestion-547"><strong data-ppui-id="ppui-suggestion-548">This Page</strong></p>
<p data-ppui-id="ppui-suggestion-549">This page details and/or previews updates to PayPal users of changes to the United States PayPal User Agreement or other online agreements, policies, or statements that require notice.<span data-ppui-id="ppui-suggestion-550">&nbsp;</span><a href="https://www.paypal.com/legalhub/archive-policies-full" title="Past Policy Updates" pa-marked="1" data-ppui-id="ppui-suggestion-551"><strong data-ppui-id="ppui-suggestion-552">You can also review Past Policy Updates notices</strong></a>. Note that additional changes could be made to previewed agreements on or before the effective dates listed, provided the applicable notice requirements are met.</p>
<p data-ppui-id="ppui-suggestion-553"><strong data-ppui-id="ppui-suggestion-554">Upcoming Changes</strong></p>
<p data-ppui-id="ppui-suggestion-555">We’re making changes to certain agreements (listed below) that govern your relationship with PayPal. These changes will take place automatically on the corresponding effective date(s) shown below.</p>
<p data-ppui-id="ppui-suggestion-556"><strong data-ppui-id="ppui-suggestion-557">Actions Needed</strong></p>
<p data-ppui-id="ppui-suggestion-558">Please carefully review the notices below and familiarize yourself with the upcoming changes. By continuing to use our services after the changes take effect, you agree to be bound by those changes. Otherwise, no further action is needed from you to accept such changes. However, if you would prefer to decline them, then you will need to close your PayPal account prior to the applicable effective date, as described in the user agreement.</p>

<p data-ppui-id="ppui-suggestion-560"><strong data-ppui-id="ppui-suggestion-561">Notices</strong></p>
<p data-ppui-id="ppui-suggestion-562">Issued: September 23, 2024</p>
<p data-ppui-id="ppui-suggestion-563"><strong data-ppui-id="ppui-suggestion-564">Amendments to the PayPal Privacy Statement</strong><br data-ppui-id="ppui-suggestion-565"><strong data-ppui-id="ppui-suggestion-566">Effective November 27, 2024:</strong></p>
<ul data-ppui-id="ppui-suggestion-567">
    <li data-ppui-id="ppui-suggestion-568">We are updating our Privacy Statement to explain how, starting early Summer 2025, we will share information to help improve your shopping experience and make it more personalized for you. The key update to the Privacy Statement explains how we will share information with merchants to personalize your shopping experience and recommend our services to you. Personal information we disclose includes, for example, products, preferences, sizes, and styles we think you’ll like. Information gathered about you after the effective date of our updated Privacy Statement, November 27, 2024, will be shared with participating stores where you shop, unless you live in California, North Dakota, or Vermont. For PayPal customers in California, North Dakota, or Vermont, we’ll only share your information with those merchants if you tell us to do so. No matter where you live, you’ll always be able to exercise your right to opt out of this data sharing by updating your preference settings in your account under “Data and Privacy.”</li>
    <li data-ppui-id="ppui-suggestion-569">We are also making other updates to our Privacy Statement including some additional disclosures related to your right, depending on the jurisdiction in which you reside, to ask us for a list of the third parties to which we have disclosed personal information, and to provide other clarifying information. </li>

</ul>
<p data-ppui-id="ppui-suggestion-570">
    <a href="https://www.paypal.com/us/legalhub/preview-privacy-full-effective-november272024" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-571">Review the updated PayPal Privacy Statement </a>
</p>


<p data-ppui-id="ppui-suggestion-572">
    <a href="https://www.paypal.com/us/legalhub/preview-privacy-states-effective-november272024" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-573">Review the new California, North Dakota, and Vermont Supplemental Financial Privacy Notice </a>
</p>

<p data-ppui-id="ppui-suggestion-576"><strong data-ppui-id="ppui-suggestion-577">Amendments to PayPal's Seller Protection Program<br data-ppui-id="ppui-suggestion-578">Effective November 18, 2024:</strong></p>
<ul data-ppui-id="ppui-suggestion-579">
    <li data-ppui-id="ppui-suggestion-580">We are revising the ‘Basic Requirements’ for PayPal’s Seller Protection program to include integration requirements for sellers who have integrated a PayPal Checkout product with their website.</li>
    <li data-ppui-id="ppui-suggestion-581">We are revising PayPal’s Seller Protection Program to extend eligibility to Guest Checkout transactions received by accounts registered in certain countries.</li>
</ul>
<p data-ppui-id="ppui-suggestion-582"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/spp-111824.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-583">Review the updated Seller Protection Program</a></p>


<p data-ppui-id="ppui-suggestion-585"><strong data-ppui-id="ppui-suggestion-586">Amendments to the PayPal Online Payment Services Agreement <br data-ppui-id="ppui-suggestion-587">Effective November 18, 2024:</strong></p>
<ul data-ppui-id="ppui-suggestion-588">
    <li data-ppui-id="ppui-suggestion-589">We are changing this agreement to introduce a new service which will enable merchants to accept Automated Clearing House (“ACH”) payments, allowing their customers to use their bank accounts as a payment method.</li>
    <li data-ppui-id="ppui-suggestion-590">Consequently, we are also renaming the PayPal Online Card Payment Services Agreement, and all references thereto, to the PayPal Online Payment Services Agreement.</li>
    <li data-ppui-id="ppui-suggestion-591">We are also changing our Merchant fee page to introduce new fees relating to this service.</li>
</ul>
<p data-ppui-id="ppui-suggestion-592"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/popsa-full-111824.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-593">Review the updated PayPal Online Payment Services Agreement</a></p>

<p data-ppui-id="ppui-suggestion-594"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/merchant-fee-111824.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-595">Review the updated Merchant Fees page</a></p>

<p data-ppui-id="ppui-suggestion-596"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/ach-services-addendum-111824.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-597">Review the new ACH Services Addendum</a></p>

<p data-ppui-id="ppui-suggestion-599"><strong data-ppui-id="ppui-suggestion-600">Discontinuation of the PayPal Fundraisers Program<br data-ppui-id="ppui-suggestion-601">Effective: October 7, 2024:</strong></p>
<p data-ppui-id="ppui-suggestion-602">On October 7, 2024, PayPal will disable the ability to create Fundraisers.</p>
<ul data-ppui-id="ppui-suggestion-603">
    <li data-ppui-id="ppui-suggestion-604">All current Fundraisers will remain open until they expire.</li>
    <li data-ppui-id="ppui-suggestion-605">You will need to move any funds from your existing Fundraisers into your PayPal balance no later than January 12, 2025. If you do not do so, we will move any remaining funds into your PayPal balance on January 13, 2025.</li>
    <li data-ppui-id="ppui-suggestion-606">If you have created a Fundraiser for Charity, please keep a copy of the list of contributors to your Fundraiser for Charity for your records, as this information will no longer be available after January 12, 2025. You will be able to continue to track contributor information for other Fundraisers in your account activity.</li>
</ul>
<p data-ppui-id="ppui-suggestion-607"><span data-ppui-id="ppui-suggestion-608">The PayPal Fundraisers Terms and Conditions will be removed from our Legal Agreements for PayPal Services page on January 13, 2025. If you wish to retain a copy of the relevant terms, please visit our website and download a copy prior to that date. A pdf copy of the PayPal Fundraisers Terms and Conditions and corresponding fees are also available using the links below.</span></p>
<p data-ppui-id="ppui-suggestion-609"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/pp-fundraisers-tnc-092324.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-610">PayPal Fundraisers Terms and Conditions </a></p>

<p data-ppui-id="ppui-suggestion-611"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/Merchant%20-%20fee-%20081424.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-612">Merchant Fees page </a></p>

<p data-ppui-id="ppui-suggestion-613"><a href="https://www.paypalobjects.com/marketing/ua/pdf/US/en/Consumer-fee-011624.pdf" target="_blank" pa-marked="1" data-ppui-id="ppui-suggestion-614">Consumer Fees page</a></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The ACF plugin on the WordPress directory has been taken over by WordPress.org (376 pts)]]></title>
            <link>https://twitter.com/wp_acf/status/1845169499064107049</link>
            <guid>41821400</guid>
            <pubDate>Sat, 12 Oct 2024 18:46:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/wp_acf/status/1845169499064107049">https://twitter.com/wp_acf/status/1845169499064107049</a>, See on <a href="https://news.ycombinator.com/item?id=41821400">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Exploring Typst, a new typesetting system similar to LaTeX (425 pts)]]></title>
            <link>https://blog.jreyesr.com/posts/typst/</link>
            <guid>41821361</guid>
            <pubDate>Sat, 12 Oct 2024 18:41:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jreyesr.com/posts/typst/">https://blog.jreyesr.com/posts/typst/</a>, See on <a href="https://news.ycombinator.com/item?id=41821361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Hello again! Today we’ll review Typst ("<a href="https://github.com/typst/typst?tab=readme-ov-file#pronunciation-and-spelling">Ty like in Typesetting and pst like in hipster</a>"), a language and tool to write text documents, usually PDF documents. This will be a very long article; it started small but then kept growing and growing.</p><p>Typst is similar in spirit and aims to LaTeX: it’s a typesetting tool that can be used to write and generate documents, usually PDF files. It intends to be used in academic/scientific environments, much like LaTeX is nowadays.</p><blockquote><p>Typst is a good choice for writing any long form text such as essays, articles, scientific papers, books, reports, and homework assignments. Moreover, Typst is a great fit for any documents containing mathematical notation, such as papers in the math, physics, and engineering fields. Finally, due to its strong styling and automation features, it is an excellent choice for any set of documents that share a common style, such as a book series.</p><p><a href="https://typst.app/docs/tutorial/">https://typst.app/docs/tutorial/</a></p></blockquote><p>Since this is the internet, we’ll first start with The People’s Source of Truth, Reddit™. <a href="https://www.reddit.com/r/LaTeX/comments/zyuyfc/has_anyone_tried_typst/">Here’s a thread on <code>/r/LaTeX</code></a>, which you’d expect to be biased, if anything, towards LaTeX. And <em>holy cow isn’t that the nicest, most civil Reddit thread in all of the universe</em>. Seriously. In the LaTeX community, talking about a LaTeX alternative. There’s just one (1) rude comment. That’s two years old, so some shortcomings mentioned there (e.g. introspection for counters, and the compiler not being open source) have already been solved.</p><p>In this article, we’ll review Typst’s syntax and compare it to LaTeX and Markdown. We’ll see the manner in which Typst is normally used, and then we’ll explore its applicability to a scenario that isn’t mentioned in their docs: using Typst as a way to generate PDF reports, invoices and other similar documents that follow a template that must be filled with variable data.</p><p>A word: throughout this article I’ll mention LaTeX as the comparison for Typst, even though LaTeX <a href="https://tex.stackexchange.com/questions/49/what-is-the-difference-between-tex-and-latex">is a collection of macros that uses TeX</a> under the hood, and some properties (e.g. the layout algorithms used) are more properly predicated of TeX than of LaTeX. Yet other properties (e.g. the UI pattern of having the raw LaTeX file at the left of the screen and the rendered PDF at the right) are actually properties of the editing programs that handle LaTeX documents, not of LaTeX. In short, whenever you see LaTeX in this document, it may actually mean “something on the constellation of tools and programs in the vicinity of LaTeX”, not necessarily LaTeX itself, because making all those distinctions may become confusing and provides no additional clarity for the purposes of this post.</p><h2 id="showcase">Showcase
<span><a href="#showcase"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>Before starting, let’s showcase some documents made in Typst. They may look similar to those that could be made in LaTeX, but that’s the point: if it can come close to The Great LaTeX, that’s a win! LaTeX has had several decades and tons of very smart people pouring tons of very smart work into it.</p><figure><img src="https://typst.app/assets/docs/3-advanced-paper.png" alt="the first page of a PDF paper, filled with placeholder text, showing a title, authors, an abstract, and two-column text with sections"><figcaption>A normal paper, styled with Typst</figcaption></figure><figure><img src="https://typst.app/assets/docs/2yP_ovYByyA1-Wxn__oJDQAAAAAAAAAA.png" alt="a set of equations"><figcaption>Equations</figcaption></figure><figure><img src="https://blog.jreyesr.com/posts/typst/_resources/3bbacdff0ace9f15bb8e929c81beea01.png" alt="a Python code block where some lines have been highlighted in different colors"><figcaption>Code blocks with syntax highlighting and annotations: https://typst.app/universe/package/codly</figcaption></figure><figure><img src="https://raw.githubusercontent.com/typst/packages/main/packages/preview/conchord/0.2.0/examples/zombie.png" alt="a song with lyrics and chords above the lyrics, plus the digitations for the corresponding guitar chords"><figcaption>Songs with lyrics and chords: https://typst.app/universe/package/conchord</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/fletcher/0.5.1/docs/gallery/io-flowchart.svg" alt="a dataflow diagram with an input, three processing steps and an output, joined with arrows of various styles"><figcaption>Flowchart-style diagrams of boxes and arrows: https://typst.app/universe/package/fletcher</figcaption></figure><figure><img src="https://andreaskroepelin.github.io/polylux/book/themes/gallery/simple.png" alt="a set of slides in a PDF document, one slide per page"><figcaption>Slides for presentations: https://typst.app/universe/package/polylux</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/timeliney/0.0.1/sample.png" alt="a Gantt chart with three sections and activities in each section"><figcaption>Gantt charts: https://typst.app/universe/package/timeliney</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/board-n-pieces/0.5.0/examples/example-2.svg" alt="a chess board"><figcaption>Chess boards in FEN: https://typst.app/universe/package/board-n-pieces</figcaption></figure><figure><img src="https://github.com/jomaway/typst-bytefield/blob/main/docs/bytefield_example.png?raw=true" alt="a diagram of a network packet or similar, showing the use of each bit in the packet"><figcaption>Bit-level packet diagrams: https://typst.app/universe/package/bytefield</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/circuiteria/0.1.0/gallery/test.png" alt="a circuit diagram of a basic processor, showing the data path"><figcaption>Block circuit diagrams: https://typst.app/universe/package/circuiteria</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/keyle/0.2.0/test/test-3.png" alt="several keyboard shortcuts, displayed as rectangles that represent the key combinations"><figcaption>Keyboard shortcuts: https://typst.app/universe/package/keyle</figcaption></figure><figure><img src="https://github.com/ThatOneCalculator/riesketcher/assets/44733677/4f87b750-e4be-4698-b650-74f4fe56789d" alt="some integral approximations (Riemann sums) where the area under a curve is approximated by rectangles that go up to the curve"><figcaption>Displaying Riemann sums: https://typst.app/universe/package/riesketcher</figcaption></figure><figure><img src="https://raw.githubusercontent.com/rangerjo/tutor/main/imgs/example_mod.png" alt="two side-by-side versions of an exam, where one is unfilled and the other has the solutions"><figcaption>Exams with and without solutions from the same source: https://typst.app/universe/package/tutor</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/wavy/0.1.1/wavy.svg" alt="a digital timing/waveform diagram, with a clock signal that toggles periodically, a bus that changes values, and a &amp;ldquo;wire&amp;rdquo; signal"><figcaption>Waveform diagrams: https://typst.app/universe/package/wavy</figcaption></figure><figure><img src="https://github.com/TomVer99/Typst-checklist-template/blob/main/img/BN%20Islander-0.png?raw=true" alt="a checklist with multiple checks to be performed for a plane"><figcaption>Aviation-style checklists: https://typst.app/universe/package/aero-check</figcaption></figure><figure><img src="https://github.com/typst/packages/raw/main/packages/preview/grotesk-cv/0.1.2/thumbnail.png" alt="a CV with personal data, previous experience, education, skills, languages and other information"><figcaption>One of many CV templates: https://typst.app/universe/package/grotesk-cv</figcaption></figure><figure><img src="https://github.com/ad-si/invoice-maker/blob/master/images/example-invoice-hq.png?raw=true" alt="an invoice with recipient information, a table of bought items, pricing and payment information"><figcaption>Invoices: https://typst.app/universe/package/invoice-maker</figcaption></figure><figure><img src="https://github.com/cetz-package/cetz/raw/master/gallery/tree.png" alt="a directed graph/tree layout"><figcaption>A directed tree, made with CetZ: https://github.com/cetz-package/cetz/blob/master/gallery/tree.typ</figcaption></figure><figure><img src="https://forum.typst.app/uploads/default/original/1X/0fb27441c50538a2308003df4701a22f1e47b199.png" alt="a badge/diploma for a participant in a congress, containing the person&amp;rsquo;s name, some logos, and a QR code"><figcaption>Badges/diplomas for participants in a university event: https://forum.typst.app/t/using-typst-for-event-badges/128</figcaption></figure><h2 id="introduction-to-typst">Introduction to Typst
<span><a href="#introduction-to-typst"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>Typst intends to be similar to LaTeX: it “<a href="https://github.com/typst/typst?tab=readme-ov-file">is designed to be as powerful as LaTeX while being much easier to learn and use</a>”. The constructs that it supports are the traditional ones in markup/typesetting systems, which are also similar to those of HTML and languages that compile to HTML, like Markdown: paragraphs of text, <a href="https://typst.app/docs/reference/model/heading/">headings in several levels</a>, <a href="https://typst.app/docs/reference/model/enum/">ordered</a> and <a href="https://typst.app/docs/reference/model/list/">unordered</a> lists, <a href="https://typst.app/docs/reference/model/strong/">bold</a> and <a href="https://typst.app/docs/reference/model/emph/">italics</a>, <a href="https://typst.app/docs/reference/visualize/image/">images</a>, <a href="https://typst.app/docs/reference/model/table/">tables</a>, <a href="https://typst.app/docs/reference/model/footnote/">footnotes</a>, <a href="https://typst.app/docs/reference/model/link/">hyperlinks</a>, and such.</p><p>It also has other elements that aren’t too common in Web content (e.g. HTML and Markdown), yet very common in academic documents (i.e. LaTeX, and to a degree MS Word): <a href="https://typst.app/docs/reference/model/figure/">numbered images and tables</a>, <a href="https://typst.app/docs/reference/model/ref/">automatic cross-references</a> to said numbered images, tables and headings; <a href="https://typst.app/docs/reference/model/bibliography/">bibliography</a> and <a href="https://typst.app/docs/reference/model/cite/">citations</a>, a <a href="https://typst.app/docs/reference/model/outline/">table of contents</a> that is automatically kept up-to-date, <a href="https://typst.app/docs/reference/model/outline/#parameters-target">tables of tables, images, equations or code blocks</a>, <a href="https://typst.app/docs/reference/layout/page/#parameters-paper">different page sizes</a>, <a href="https://typst.app/docs/reference/math/">large amounts of math/equations symbols</a>, the concept of a document’s <a href="https://typst.app/docs/reference/model/document/#parameters-author">author</a> and <a href="https://typst.app/docs/reference/model/document/#parameters-date">creation date</a>, and <a href="https://typst.app/universe/">a package ecosystem</a> for things like <a href="https://typst.app/universe/package/cetz/">drawing stuff</a> (the equivalent of <a href="https://www.overleaf.com/learn/latex/TikZ_package">TikZ</a>) or <a href="https://typst.app/universe/package/polylux/">building presentation slides</a> (the equivalent of <a href="https://www.overleaf.com/learn/latex/Beamer">Beamer</a>).</p><p>In short, Typst intends to provide more or less the same elements as those provided by LaTeX. Many already exist, those that don’t may be added later, since Typst is still a very young project.</p><h2 id="typst-latex-and-markdown">Typst, LaTeX and Markdown
<span><a href="#typst-latex-and-markdown"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>The syntax of the Typst language is way closer to Markdown than it is to LaTeX. Compare Markdown:</p><div><pre tabindex="0"><code data-lang="markdown"><span><span># A Sample Document
</span></span><span><span>
</span></span><span><span><span>## Introduction
</span></span></span><span><span><span></span>
</span></span><span><span>This is an introduction.
</span></span><span><span>
</span></span><span><span><span>## Section One
</span></span></span><span><span><span></span>
</span></span><span><span><span>*</span> A
</span></span><span><span><span>*</span> B
</span></span><span><span><span>*</span> C
</span></span><span><span>
</span></span><span><span>Figure 1 shows a figure. As can be seen, 
</span></span><span><span>the figure depicts an image of a picture.
</span></span><span><span>
</span></span><span><span>![<span>Figure 1: Observe the image in the picture</span>](<span>image.jpg</span>)
</span></span><span><span>
</span></span><span><span>[<span>This is a link</span>](<span>https://example.com</span>)
</span></span></code></pre></div><p>Here’s LaTeX:</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\documentclass</span><span>[12pt, a4paper]</span>{article}
</span></span><span><span>
</span></span><span><span><span>\usepackage</span>{graphicx}
</span></span><span><span><span>\usepackage</span>{hyperref}
</span></span><span><span>
</span></span><span><span><span>\title</span>{A Sample Document}
</span></span><span><span><span>\author</span>{My Name}
</span></span><span><span><span>\date</span>{<span>\today</span>}
</span></span><span><span>
</span></span><span><span><span>\begin</span>{document}
</span></span><span><span><span>\maketitle</span>
</span></span><span><span>
</span></span><span><span><span>\section</span>{Introduction}
</span></span><span><span>This is an introduction.
</span></span><span><span>
</span></span><span><span><span>\section</span>{Section One}
</span></span><span><span><span>\begin</span>{itemize}
</span></span><span><span>	<span>\item</span>{A}
</span></span><span><span>	<span>\item</span>{B}
</span></span><span><span>	<span>\item</span>{C}
</span></span><span><span><span>\end</span>{itemize}
</span></span><span><span>
</span></span><span><span>Figure <span>\ref</span>{fig:figure} shows a figure. As can be seen, 
</span></span><span><span>the figure depicts an image of a picture.
</span></span><span><span>
</span></span><span><span><span>\begin</span>{figure}[h]
</span></span><span><span>    <span>\centering</span>
</span></span><span><span>    <span>\includegraphics</span><span>[width=0.7\textwidth]</span>{image}
</span></span><span><span>    <span>\caption</span>{Observe the image in the picture}
</span></span><span><span>    <span>\label</span>{fig:figure}
</span></span><span><span><span>\end</span>{figure}
</span></span><span><span>
</span></span><span><span><span>\href</span>{https://example.com}{This is a link}
</span></span><span><span><span>\end</span>{document}
</span></span></code></pre></div><p>And Typst:</p><pre tabindex="0"><code data-lang="typst">= Introduction

This is an introduction.

= Section One

- A
- B
- C

@figure shows a figure. As can be seen, the figure depicts
an image of a picture.

#figure(
  image("image.jpg", width: 70%),
  caption: [
    Observe the image in the picture
  ],
) &lt;figure&gt;

#link("https://example.com")[This is a link]
</code></pre><p>Let’s now compare Typst individually with LaTeX, Markdown and Word and similar editors.</p><h3 id="vs-latex">vs. LaTeX
<span><a href="#vs-latex"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>As can be seen, Typst is much less verbose than LaTeX. For example, a heading isn’t <code>\section{Title}</code>, but rather <code>= Title</code>, in the spirit of Markdown’s <code># Title</code>. Links aren’t <code>\usepackage{hyperref}</code> and then <code>\href{https://example.com}{This is a link}</code>, but just <code>#link("https://example.com")[This is a link]</code>, again quite similar to Markdown. And so on. Typst relies much less on backslash-prefixed macros to write special elements, instead using dedicated syntax for the most common operations (for example, unordered lists, AKA bullet lists, use <code>-</code> for every entry. Numbered lists, on the other hand, use <code>+</code>. Headings use <code>=</code>s, one per level of the heading. Citations use <code>&lt;tag&gt;</code> to create the reference and <code>@tag</code> to refer to it. Bold and italics use <code>*content*</code> and <code>_content_</code>. Code uses <code>`backticks`</code>).</p><p>Anything that doesn’t have dedicated syntax uses “function calls”, which are quite similar to a programming language’s function calls. For example, to add a strikethrough:</p><div><pre tabindex="0"><code data-lang="text"><span><span>This is #strike[not] relevant.
</span></span></code></pre></div><p>whereas for LaTeX:</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\usepackage</span>{soul}
</span></span><span><span>
</span></span><span><span>This is <span>\st</span>{relevant}
</span></span></code></pre></div><p>The function call syntax is much closer to LaTeX’s macros, except that LaTeX backslashes are replaced by number/pound signs <code>#</code>, and arguments aren’t provided inside curly braces, but inside regular parentheses and square brackets.</p><p>More complicated syntax, such as tables, also looks similar:</p><div><pre tabindex="0"><code data-lang="text"><span><span>#table(
</span></span><span><span>  columns: 4,
</span></span><span><span>  [], [Exam 1], [Exam 2], [Exam 3],
</span></span><span><span>
</span></span><span><span>  [John],   N/A, A, N/A,
</span></span><span><span>  [Mary],   N/A, A, A,
</span></span><span><span>  [Robert], B,   A, B,
</span></span><span><span>)
</span></span></code></pre></div><p>which generates something like this (after applying some styling that I don’t show here for clarity):</p><p><img src="https://typst.app/assets/docs/tvXJoKB8oJjSM7xb5x80tQAAAAAAAAAA.png" alt="a picture of a table containing the data above"></p><p>In LaTeX, said table may look like this:</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\begin</span>{tabular}{|l|l|l|l|}
</span></span><span><span>	<span>\hline</span>
</span></span><span><span>	&amp; Exam 1 &amp; Exam 2 &amp; Exam 3 <span>\\</span>
</span></span><span><span>	<span>\hline</span>
</span></span><span><span>	John &amp; N/A &amp; A &amp; N/A <span>\\</span>
</span></span><span><span>	<span>\hline</span>
</span></span><span><span>	Mary &amp; N/A &amp; A &amp; A <span>\\</span>
</span></span><span><span>	<span>\hline</span>
</span></span><span><span>	Robert &amp; B &amp; A &amp; B <span>\\</span>
</span></span><span><span>	<span>\hline</span>
</span></span><span><span><span>\end</span>{tabular}
</span></span></code></pre></div><p>Again, slightly similar. LaTeX’s table may be slightly less clean, such as in the explicit newlines and column separators, and in the way in which presentation (namely, the <code>\hline</code>s) is mixed with the data (the actual content of the cells).</p><p>Typst can also read bibliographies <a href="https://typst.app/docs/reference/model/bibliography/">in BibLaTeX format</a>, which is nice because many tools (e.g. Google Scholar or Mendeley) can export references in that format. It can also use <a href="https://github.com/typst/hayagriva/blob/main/docs/file-format.md">Hayagriva</a>, another format (also developed by Typst themselves) based on YAML:</p><div><pre tabindex="0"><code data-lang="yaml"><span><span><span>harry</span>:
</span></span><span><span>    <span>type</span>: <span>Book</span>
</span></span><span><span>    <span>title</span>: <span>Harry Potter and the Order of the Phoenix</span>
</span></span><span><span>    <span>author</span>: <span>Rowling, J. K.</span>
</span></span><span><span>    <span>volume</span>: <span>5</span>
</span></span><span><span>    <span>page-total</span>: <span>768</span>
</span></span><span><span>    <span>date</span>: <span>2003-06-21</span>
</span></span><span><span>
</span></span><span><span><span>electronic</span>:
</span></span><span><span>    <span>type</span>: <span>Web</span>
</span></span><span><span>    <span>title</span>: <span>Ishkur's Guide to Electronic Music</span>
</span></span><span><span>    <span>serial-number</span>: <span>v2.5</span>
</span></span><span><span>    <span>author</span>: <span>Ishkur</span>
</span></span><span><span>    <span>url</span>: <span>http://www.techno.org/electronic-music-guide/</span>
</span></span></code></pre></div><p>Citing references is done like this:</p><div><pre tabindex="0"><code data-lang="text"><span><span>@electronic states that electronic music is made by electrons.
</span></span></code></pre></div><p>Again, quite similar to LaTeX’s <code>\cite{electronic}</code>. Unlike LaTeX, the exact same syntax is also used to insert cross-references: if you have, say, a table with a label <code>&lt;table_label&gt;</code>, you can also insert a reference to the table with <code>@table_label</code>. LaTeX uses distinct commands, <code>\cite{}</code> for citations and <code>\ref{}</code> for cross-references. Another difference is that LaTeX’s references only insert the number (e.g. you’d write <code>Figure~\ref{fig:something} shows that ...</code>, and LaTeX would only substitute the number), while Typst references insert the entire name+number (i.e. you’d write <code>@fig_something shows that ...</code>, and the <code>@fig_something</code> reference would be replaced by <code>Figure 1</code> or something similar)</p><p>Equations are also supported (as you would expect of anything that even tries to play in the same league as LaTeX). Both inline equations (i.e. those that are typeset inside a paragraph, inside the normal flow of text) and block-mode (equations that are set in their own paragraph) are available:</p><div><pre tabindex="0"><code data-lang="text"><span><span>#set math.equation(numbering: "(1)")
</span></span><span><span>
</span></span><span><span>It has always been known that, for physicists, $pi = 3$.
</span></span><span><span>
</span></span><span><span>Proof:
</span></span><span><span>
</span></span><span><span>$ 
</span></span><span><span>  &amp; pi = 3.14 \
</span></span><span><span>  &amp; 3.14 = 3 \
</span></span><span><span>  therefore &amp; pi = 3
</span></span><span><span>$
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/f6b8eb53d4507d8e6e24f5398d7645b0.png" alt="a screenshot of rendered text with the same content as the code block above"></p><p>For LaTeX:</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\usepackage</span>{amssymb}
</span></span><span><span><span>\usepackage</span>{amsmath}
</span></span><span><span>
</span></span><span><span>It has always been known that, for physicists, <span>$</span>\pi <span>=</span> <span>3</span><span>$</span>.
</span></span><span><span>
</span></span><span><span>Proof:
</span></span><span><span>
</span></span><span><span><span>\begin</span>{equation}
</span></span><span><span><span>\begin</span>{split}
</span></span><span><span>	&amp; <span>\pi</span> = 3.14 <span>\\</span>
</span></span><span><span>	&amp; 3.14 = 3 <span>\\</span>
</span></span><span><span>	<span>\therefore</span> &amp; <span>\pi</span> = 3
</span></span><span><span><span>\end</span>{split}
</span></span><span><span><span>\end</span>{equation}
</span></span></code></pre></div><p>generates this:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/177ac92384e160dd70459d7728ebabd0.png" alt="a screenshot of rendered text with the same content as the code block above"></p><p>Probably the biggest difference with equations is that, in Typst, symbols are inserted via normal words. Observe, for example, the <code>$pi = 3$</code> inline equation: <code>pi</code> is converted to the actual π symbol. (The dollar sign at the start isn’t part of the <code>pi</code> symbol, it’s the delimiter of the entire inline equation, much like in LaTeX). In LaTeX, symbols always require the backslash. The same thing happens with the three dots in a triangle that make up ∴ the <em>therefore</em> symbol: LaTeX requires a backslash, while Typst doesn’t. Just writing <code>pi</code> with no backslash in LaTeX would interpret it as the two variables <code>p</code> and <code>i</code>, which are typeset in italics. Typst only does that for single-letter words. Anything longer than that is interpreted <a href="https://typst.app/docs/reference/symbols/sym/">as a symbol</a>. To write actual sequences of variables (such as <code>ab &gt; 0</code>, where <code>a</code> and <code>b</code> are multiplied), you leave a space between them: <code>a b &gt; 0</code>. To write actual text, which shouldn’t be composed of sequences of italicized letters, you wrap it in double quotes: <code>{ x | x "is positive" }</code></p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/4e6aa4c80e9c6ff7482505aeb75ae242.png" alt="a screenshot of an equation with some words in normal (upright) font, generated in Typst"></p><p>LaTeX would do it like this:</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\{</span> x <span>\mid</span> x <span>\textrm</span>{ is positive} <span>\}</span>
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/baea2122974af41901b3c3bd35d3ec2b.png" alt="a screenshot of an equation with some words in normal (upright) font, generated in LaTeX"></p><h3 id="vs-markdown">vs. Markdown
<span><a href="#vs-markdown"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>As we’ve seen, the most common syntax constructs in Typst look fairly close to Markdown. In particular, headings, bold&amp;italics, links and lists (both ordered and unordered) use very minimal special characters, which aren’t those of Markdown but fulfill the same purpose.</p><p>Nonetheless, Markdown and Typst are quite different in their aims. Markdown’s intended destination is typically either Markdown itself (e.g. when you use Markdown to take notes, as is done in the <a href="https://help.obsidian.md/Editing+and+formatting/Basic+formatting+syntax">Obsidian</a> and <a href="https://joplinapp.org/">Joplin</a> note-taking applications, which store notes in Markdown) or HTML (as is done, for example, on <a href="https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes">the READMEs that are included on Github repositories</a>, or on some website generators <a href="https://gohugo.io/">such as Hugo</a>, in which this very blog is written, at least currently). Markdown’s data model is therefore a restricted subset of HTML’s available elements, with far less syntax (for example, a level 1 heading, <code># Title</code>, is translated into <code>&lt;h1&gt;Title&lt;/h1&gt;</code>. Images <code>![alt](link)</code> are translated into <code>&lt;img src="link" alt="alt"&gt;</code>, <a href="https://www.markdownguide.org/hacks/#image-size">with no native control over sizes</a>).</p><p>In other words, Markdown is a product of the age of the Web and works with and for the Web. Things that don’t appear normally on web pages won’t appear on Markdown either. This means things like <a href="https://www.markdownguide.org/hacks/#table-of-contents">a table of contents</a>, <a href="https://www.markdownguide.org/hacks/#underline">underlined text</a> (which in the Web means almost exclusively a hyperlink, and so shouldn’t be exposed for people to use on things that aren’t hyperlinks), equations, citations, the concept of a “document author”, or cross-references to other parts of the document (though most Markdown processors do support <a href="https://www.markdownguide.org/extended-syntax/#heading-ids">cross-linking</a>, just not automatically inserting text like “Section 2.1” where the number is the correct one for the link’s destination).</p><p>Being Web-focused, Markdown’s documents also like to live on a single vertically-infinite page (web pages don’t usually have page breaks).</p><p>Typst and LaTeX, by contrast, operate on the world of PDF documents composed of a certain number of rectangular pages, perhaps numbered. In Markdown you’ll never find a setting to set the page size to A4… because on the Web that makes no sense! Same goes for margins, page numbers, adding the current section at “the top of each page”, per-page headers and footers, anything to do with odd vs. even pages (e.g. aligning the page number to the right or to the left, or having asymmetric margins for bookbinding at the left edge), leaving blank pages as necessary so chapters always start on the right side when a book is printed, or prevention of <a href="https://en.wikipedia.org/wiki/Widows_and_orphans">widows and orphans</a> (i.e. very short one-or-two-lines paragraphs that are left at the top and bottom of a page, respectively).</p><p>All of those, however, are provided by LaTeX and Typst. In short: if your document will become a PDF with separate pages, and it isn’t just a cascade of text and images (which could just be dumped to pages as they come, breaking when the page runs out of space), Markdown isn’t as useful, since it doesn’t provide page-aware features.</p><p>Furthermore, Markdown doesn’t have built-in support for some features that are used (and arguably vital) in academic/scientific documents:</p><ul><li>Citations and bibliography</li><li>Cross-references (e.g. referring to Table 1, Figure 2, or Section 3.4 in other parts of the text)</li><li>Equations (some tools, such as Hugo, do <a href="https://gohugo.io/content-management/mathematics/">support equations</a>, but that is not Markdown’s concern: it’s handled <a href="https://www.mathjax.org/">elsewhere</a>, with Markdown just ignoring all that content)</li><li>Captioned images. Markdown’s images, <code>![alt text](link)</code>, are just rendered as <code>&lt;img&gt;</code> elements. That can again <a href="https://adityanaik.dev/blog/2022/04/23/links-images-captions-quotes-and-iframes-in-a-hugo-blog/#image-handling-and-adding-a-caption">be added</a>, but it’s beyond Markdown itself</li><li>Captioned tables, necessary for cross-referencing said tables</li><li><a href="https://www.markdownguide.org/hacks/#color">Any way of styling content</a>, at least directly on Markdown. For instance, it isn’t possible to have a certain word colored red. If converting the Markdown document to HTML, it is sometimes possible to use the Markdown rendering tool to <a href="https://pandoc.org/MANUAL.html#option--css">provide a CSS file</a> that will style the resulting output. In particular, Markdown provides no facilities to have all section titles be in Arial 12 point bold <em>al dente</em> typeface, which may be required by the journal to which you want to submit your awesome paper</li></ul><p>Note that all of these could be manually added. For example, a citation can be typed out literally, such as <code>See [2] for a review of available methods...</code> (like, the <em>literal</em> 2 surrounded in literal brackets), and then at the end a <code># Bibliography</code> section could be added, where each reference is manually written, including the number that it was assigned, the authors, the title, the journal, and whatever else. Of course, the minute another reference is added it may be necessary to reshuffle all existing references (since some reference styles mandate that references be sorted on the first author’s last name or something), and all citations to reshuffled references need to be updated too. Image captions can be added, for example, by wrapping the image in a two-row table, where the top row contains the image and the bottom row says literally <code>Figure 1: A Title For The Image</code>. That can’t be done for tables, but it would be possible to just insert the table caption as a lone paragraph just above or below the table. And then “cross-references” can be the literal words <code>Figure 1 shows that ...</code>. Of course, once again, if another figure or table needs to be inserted between two others, it’d cause the numbering of all later entries to change, thereby requiring that all references to those elements be changed too.</p><p>Equations and content styling are simply outside of Markdown’s purview. They can be handled elsewhere, in the surrouding application that parses the Markdown document and renders something else, typically HTML, or PDF with HTML as an intermediate step (converting an HTML document to PDF is fairly mechanical, by using an HTML rendering engine such <a href="https://help.syncfusion.com/document-processing/pdf/conversions/html-to-pdf/net/blink">as those found in browsers</a> or <a href="https://wkhtmltopdf.org/">Qt’s WebKit engine</a>)</p><p>In general, the issue (which is only an issue when trying to use it as a LaTeX replacement. Markdown is plenty good for what it does) with Markdown is that it doesn’t operate at the abstraction level (and, therefore, with the concepts) of “research paper”. It operates at the level of “text document”. In the land of text documents, the important entities are paragraphs, sentences, headings, images, lists, tables, hyperlinks and such. The land of research papers is also concerned with references, figures, tables of contents, and more. Note that the higher-level concepts that are found in scientific papers are actually composed of lower-level concepts: a citation is actually just a hyperlink, that displays a bit of text, but it embodies some additional ideas, such a specific format (e.g. <code>[1]</code> for IEEE-style citations), the fact that its hyperlink goes to another location in the document (namely, the corresponding entry in the references list), and the ability to change automatically when its corresponding reference is reordered.</p><p>In a similar way, a paper’s figures are a raw image (a rectangle filled with colored pixels) + some text (the caption), but there are additional constraints placed upon it: the image and the text are part of the same entity, such that they move as a unit (i.e. no decent typesetting system will place the image at the end of a page and its caption at the start of the next one, but instead place both elements together on one page or the other), the fact that the provided caption will be automatically prefixed with something like <code>Figure 1: </code>, the automatically-increasing counter for images (which, by the way, is separate from similar counters that may be used for section names, tables, code blocks and other enumerated elements), and the ability to create references to that element that automatically get replaced with the figure’s current number.</p><p>A table of contents is similarly composed of lines of text, but they aren’t any random lines of text: a table of contents gets its data from the headings/section names that are defined elsewhere in a document, and presents them in order, maybe preserving their hierarchy (e.g. subsections are presented indented relative to their parent section), where each entry may have its page number (which, again, is a PDF-specific concept that makes no sense in the Web, where each page is on an infinitely tall container) displayed at the right side, with a character (e.g. dots <code>.</code>) filling the space between the end of the title and the page number. All of these features could be manually typed from text lines, but the higher-level concept of a table of contents implies all those constraints already, freeing the author from the work of keeping the table well-formed. This is arguably one of the biggest reasons for the existence of tools that focus on papers and similar documents: they provide higher-level concepts directly in the language.</p><h3 id="vs-word-google-docs-and-text-processors">vs. Word, Google Docs and text processors
<span><a href="#vs-word-google-docs-and-text-processors"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>Of course, whoever doesn’t write papers in LaTeX most likely writes them in Word or other equivalent text processor<a href="https://xkcd.com/285/">[citation needed]</a>. Word has the advantage that it’s probably one of the most well-known pieces of (desktop) software in the world (surprisingly, there appears to be no easily-found chart of the most common applications in a desktop environment!). It now has multi-user simultaneous editing too, via Office’s cloud subscription plans (which is called Office 365, I think?), which is useful for collaborative editing.</p><p>There’s also <a href="https://docs.google.com/">Google Docs</a>, part of Google’s suite of “office tools”. It links everything to your Google account, whereas Word does so to your Microsoft account (if you want to. Word also works with no connection to the mothership… <em>for now</em>. Looking at you, <a href="https://www.tomshardware.com/how-to/install-windows-11-without-microsoft-account">Windows 11</a>!). As a web-first application (as opposed to Word, which was born when the Web wasn’t a thing, and is therefore a child of the desktop age), Google Docs is exclusively accessed through a browser (ignoring browsers-in-disguise such as PWAs, which I couldn’t verify are used by Google Docs). Features such as cloud saving and collaboration come built-in with Google Docs. The interface is also different to that of Word: Word uses <a href="https://support.microsoft.com/en-us/office/customize-the-ribbon-in-word-c4b6051a-7a70-43c8-a527-932917dec682">the ribbon</a>, whereas Google Docs uses the more traditional <a href="https://edu.gcfglobal.org/en/googledocuments/getting-started-with-your-document/1/">menu bar</a> with dropdown menus, plus right-click contextual menus. Google Docs therefore allocates more screen space to the document itself.</p><p>And then there’s everyone else: <a href="https://www.libreoffice.org/">LibreOffice</a> (bundled with Ubuntu), <a href="https://www.openoffice.org/">OpenOffice</a> (<a href="https://en.wikipedia.org/wiki/LibreOffice#History">from which LibreOffice was forked</a>, way back in 2010), <a href="https://www.onlyoffice.com/">OnlyOffice</a>, <a href="https://www.wps.com/">WPS Office</a>, <a href="https://support.apple.com/pages">Apple Pages</a>, and probably a bazillion more.</p><p>All of these apps have something in common: they’re <a href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> text/word processors, AKA “awhat you see is what you get”, AKA you edit a document that has the same appearance as the final document:</p><blockquote><p>WYSIWYG was a great advance over earlier interactions, in which users specified their goals more abstractly and didn’t see the results until far later. To make text bold in a WYSIWYG interface, for example, you highlight the text with the mouse and choose the “Bold” command from a formatting menu. Easy. And, even more important, as soon as you choose the formatting command, the document’s screen appearance changes to reflect the new formatting. At any given time, what you see on the screen is what you’ve built and what you’ll get if you print it.</p><p>Jakob Nielsen, <a href="https://www.nngroup.com/articles/rip-wysiwyg/">https://www.nngroup.com/articles/rip-wysiwyg/</a></p></blockquote><p>This is as opposed to LaTeX, where, say, bolding text is done by surrounding it with <code>\textbf{...}</code> in the source (plaintext) document, and then observing the change in the rendered PDF; Typst and Markdown, where it is done by surrounding it with <code>*...*</code>; or HTML, where it’s done by surrounding it with <code>&lt;b&gt;...&lt;/b&gt;</code>. In all of those cases, formatting of the text is performed by adding more text around it: formatting isn’t a magical property, but more text near (usually around) the “target” text. On the other hand, on Word, Google Docs and such, formatting lives on a different realm, “superimposed over” the content as it were, rather than alongside it.</p><p>This means that WYSIWYG editors are easier for people to grasp, since the performed operations are immediately reflected in-place, rather than being instructions to a build process that generates another document.</p><p>On the other hand, since styling is applied on top of the content, it’s usually more difficult to globally apply styles, absent a way to declare “styles” that are later applied to the “content”. To be fair, <a href="https://support.microsoft.com/en-us/office/customize-or-create-new-styles-d38d6e47-f6fc-48eb-a607-1eb120dec563">Word</a>, <a href="https://support.google.com/docs/thread/29527841/creating-a-new-style?hl=en">Google Docs</a>, <a href="https://books.libreoffice.org/en/GS73/GS7303-StylesAndTemplates.html#toc6">LibreOffice</a> and everyone else do support styles, i.e. a set of properties (such as font size, color, line spacing, whether or not the content is numbered, indentation, alignment, and more) that can then be applied to multiple parts of the content at once. For example, in a Word document, most content would probably be in the Normal style, which is the standard boring text. Section titles may be in Heading 1, subsections in Heading 2, the title of the whole document in Title, and so on. In fact, you can usually spot a Word document because section titles are in the traditional light blue of Heading 1 (or 2, or 3):</p><p><img src="https://support.content.office.net/en-us/media/aba917d3-4fab-4697-829d-a3e5065162be.png" alt="a screenshot of Word&amp;rsquo;s ribbon showing the style list"></p><p>However, the fact that those styles are optional means that you are free to ignore them and apply changes to pieces of the document itself. Need some more spacing between lines? Rather than editing the Normal style, most people will likely Ctrl+A to select the entire document (or, more likely, go to the start of the document, click there, and then drag to the bottom), then change the spacing. This will apply the new setting to everything that exists already, and then Word will keep applying the same style to any new paragraphs that are inserted by pressing Enter…</p><p>Until it doesn’t, that is, and for some reason one paragraph picks up the original line spacing again. Or you paste some content from a web page and it carries over its own formatting, and you click the Clear Formatting button to delete it, and your custom spacing gets lost too.</p><p>And there’s also the issue that a style applied via… well, a Style, is indistinguishable from one applied manually, by virtue of these applications being WYSIWYG. That’s the whole point! In other words, these two lines look the same:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/e39715cd7a207fe2e8244d9a666107a5.png" alt="a screenshot of a text document with two lines that look the same, but the second one doesn&amp;rsquo;t have the same style applied as the first one"></p><p>The second line was manually styled to match the Title style. But it doesn’t <em>have</em> the Title style, it’s just a Body Text. And if we changed the Title style, that second line wouldn’t have the changes applied: as far as the editor is concerned, it’s a piece of normal text. And there’s no way to detect that except for clicking on each piece of text that looks like it has the style applied, and checking if it actually does.</p><p>Also, there are the minor annoyances with graphical tools: ever tried to enter thirty references in Word? At least back when I used to write papers, it was a very boring task: open the References dialog, click New, choose a type of reference, then manually click and fill several text fields, then click Save, then repeat it all over for the other twenty-nine references. The root cause of that is that point-and-clicking is slower than copy-pasting text, and Word doesn’t have something like a textual representation of a template. By contrast, Google Scholar (and probably other sites that produce bibliography) can very easily provide a way to import a reference into LaTeX:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/cf006702ba6e3489297a1371b5d10011.png" alt="a screenshot of Google Scholar showing the Cite menu of a reference, which has an option to copy the BibTeX-formatted reference"></p><p>The actual reference is a piece of plain text that can be copied into a clipboard, passed around through an email or text message, and pasted into a file. Try doing that with a Word reference:</p><pre tabindex="0"><code>@book{vulis1992modern,
  title={Modern TEX and its Applications},
  author={Vulis, Michael},
  year={1992},
  publisher={CRC Press}
}
</code></pre><p>Or have you ever found a numbered list that is composed of literal numbers at the start? Word tries very hard to identify things that look like the start of a numbered list and turns them into actual numbered lists, but it may fail if someone uses a non-recognized format. Such lists would look mostly like real numbered lists, except that they have none of the list-specific features: no auto-incrementing number, no automatic indentation, no adding child lists that use a different numbering style (e.g. the main list using 1., 2., 3. and the sublist using a., b., c.). Have you found a section heading that was manually styled? Or an image that was manually captioned? Or (<em>shudder</em>) a manually written reference list? Or a manually written and painstakingly maintained table of contents? Or one that, while automatically created, is out of sync with the actual document? All of these are things that can happen with a general-purpose text processor that isn’t operating at the abstraction level of “this is the heading of a section”, but just at “this is a line of text”.</p><p>And let’s not forget that, not being typesetting systems, Word and company don’t usually have the fancier typesetting features. Have you ever had to go to the start of a paragraph and manually press Enter a couple of times, just to make that paragraph start at the start of the next page (or, if you were really fancy, Ctrl+Enter to insert a page break)? That’s Word not trying to prevent widows and orphans. Ever had one of those justified paragraphs <a href="https://www.datanumen.com/blogs/5-ways-not-stretch-last-line-justified-paragraph/">where a line has huge spaces between words</a>, for some reason? That’s a less-than-ideal justification algorithm being used. <a href="https://en.wikipedia.org/wiki/Ligature_(writing)#Computer_typesetting">Ligatures (e.g. between the <em>f</em> and the <em>i</em> in the word “official”)</a> aren’t used in Word by default, as far as I’m aware. <a href="https://nitens.org/w/latex/">A large list of differences, written from the perspective of a LaTeX enjoyer, is here</a> (though keep in mind that it’s fairly old, circa 2008, and Word especially is liable to have changed a lot in the meantime. LaTeX is more stable and should have changed less). To be sure, most of those are very small changes, probably only perceivable if you <em>really</em> like fonts or when seeing them side-by-side, but still.</p><p>Text processors typically use an opaque-ish data format as the backing store for the document (for example, Word’s DOCX documents <a href="https://docs.fileformat.com/word-processing/docx/#docx-file-format-specifications---more-information">are actually ZIP files in disguise</a>, filled with XML documents). This means that they aren’t really amenable to automation, or in other words, automatically generating documents with variable information, in the style of a template (for example, an automatic letter that always starts with “Dear &lt;name&gt;”). There are tools to do so, to be sure, <a href="https://carbone.io/">many</a> <a href="https://docxtemplater.com/">of</a> <a href="https://jsreport.net/learn/docx">them</a> <a href="https://www.docmosis.com/how-it-works/">in</a> <a href="https://templater.info/">fact</a>, but they all have to fight <em>against</em> the DOCX data model. For example, consider <a href="https://templater.info/">this tool</a>, which lets you insert variable data in a document by surrounding it with double square brackets, <code>[[variable]]</code>:</p><p><img src="https://templater.info/images/my-document-example/a+bath-300.png" alt="a screenshot of Word showing the replacement of a tag"></p><p>In <a href="https://templater.info/user-manual">their documentation</a> they have the following paragraphs:</p><blockquote><p>On surface Templater looks just like a mail merge solution. You can put tags on specific places in the document and replace them later with actual values. One could wonder why a library would even be required for that, as OOXML is just a ZIP file with an XML files which can be easily edited/manipulated.</p><p>But even in such a simple use case there are obstacles, as Word tends to split text into paragraphs so even a simple text such as [[TAG]] often looks like</p><div><pre tabindex="0"><code data-lang="xml"><span><span><span>&lt;w:r</span> <span>w:rsidRPr=</span><span>"00A42204"</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;w:rPr&gt;</span>
</span></span><span><span>    <span>&lt;w:lang</span> <span>w:val=</span><span>"en-US"</span><span>/&gt;</span>
</span></span><span><span>  <span>&lt;/w:rPr&gt;</span>
</span></span><span><span>  <span>&lt;w:t&gt;</span>[[<span>&lt;/w:t&gt;</span>
</span></span><span><span><span>&lt;/w:r&gt;</span>
</span></span><span><span><span>&lt;w:proofErr</span> <span>w:type=</span><span>"spellStart"</span><span>/&gt;</span>
</span></span><span><span><span>&lt;w:r</span> <span>w:rsidRPr=</span><span>"00A42204"</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;w:rPr&gt;</span>
</span></span><span><span>    <span>&lt;w:lang</span> <span>w:val=</span><span>"en-US"</span><span>/&gt;</span>
</span></span><span><span>  <span>&lt;/w:rPr&gt;</span>
</span></span><span><span>  <span>&lt;w:t&gt;</span>TAG<span>&lt;/w:t&gt;</span>
</span></span><span><span><span>&lt;/w:r&gt;</span>
</span></span><span><span><span>&lt;w:proofErr</span> <span>w:type=</span><span>"spellEnd"</span><span>/&gt;</span>
</span></span><span><span><span>&lt;w:r</span> <span>w:rsidRPr=</span><span>"00A42204"</span><span>&gt;</span>
</span></span><span><span>  <span>&lt;w:rPr&gt;</span>
</span></span><span><span>    <span>&lt;w:lang</span> <span>w:val=</span><span>"en-US"</span><span>/&gt;</span>
</span></span><span><span>  <span>&lt;/w:rPr&gt;</span>
</span></span><span><span>  <span>&lt;w:t</span> <span>xml:space=</span><span>"preserve"</span><span>&gt;</span>]] <span>&lt;/w:t&gt;</span>
</span></span><span><span><span>&lt;/w:r&gt;</span>
</span></span></code></pre></div><p>which contains various “useless” Word specific information not really relevant for the original [[TAG]] text. There are also various Word specific rules such as <strong>xml:space=“preserve”</strong> which must be respected during processing.</p><p>Once tables and lists start to get used, replacing a tag is no longer: <em>“just locate and replace tag value in XML”</em>. With the addition of images, special Word objects, such as charts which are implemented as an embedded Excel file within the Word zip changing tags requires extensive knowledge of the Word behavior, format and rules. Therefore, a library which copes with those adjustments can be of quite a big help to the developer, even if his is quite familiar with the OOXML format.</p></blockquote><p>Oof. When even simple words aren’t preserved in the source XML document, things get really nasty. Naïve text replacement or the traditional text templating engines that are used, for example, on server-side HTML frameworks (e.g. <a href="https://jinja.palletsprojects.com/en/3.1.x/templates/#synopsis">Jinja</a> or <a href="https://pkg.go.dev/text/template">Go’s <code>text/template</code></a>) don’t work on those XML documents, because they rely on special markers (typically <code>{{ some_var }}</code> or something to that effect), which, as we’ve seen above, Word breaks into different XML elements so the literal content <code>{{ ... }}</code> doesn’t appear anywhere in the XML. And that’s before we start with repetitions (say you want to render a list of items into a bullet list), conditional formatting (e.g. coloring some items in the list red or conditionally bold them), tables (where you may want to <a href="https://carbone.io/documentation.html#repetitions">repeat a row</a> several times), inserting images or charts (which involve an entire embedded Excel document which contains the data that feeds the table), trying to add data (e.g. today’s date) in a header, adding variable data as a watermark, or other more advanced replacements, then things get ugly fast.</p><p>By contrast, tools like LaTeX or Typst, where the source data is a plain text file, play very nicely with templating tools. There’s no mysterious syntax that is added behind the scenes. Therefore, including automatic data in a document is fairly easy to do: we could just use any text templating engine to insert the requisite tags and/or directives in the LaTeX/Typst document, then render with the engine to generate a LaTeX/Typst document, then render <em>that</em> document with TeX or Typst respectively to generate a PDF document. The key here is that since the source documents are plain text, there are many tools that can process them, unlike the weird XML documents of Word.</p><p>We’ll see more examples of templating documents with Typst in a later section.</p><p>Generating reports or other automatic documents starting from a Typst or LaTeX template has the issue that they render into PDF. This means that the output is already set in stone, more or less. There are ways of editing PDF documents (<a href="https://edu.gcfglobal.org/en/word2013/editing-pdf-files/1/">Word can</a>, at the possible cost of some formatting; and there’s also <a href="https://www.adobe.com/acrobat.html">Adobe Acrobat</a>, not the Reader version, which can do so starting at the low cost of $12.99 per month, about $150 per year), but they’re unwieldy and/or paid. Thus, there’s no easy way to pre-render most of the document, perhaps the boring parts that are always the same or can be filled directly from some data source, and then present the half-filled document to a person for the final touches to be added or corrections to be made. Tools that template Word documents <a href="https://carbone.io/documentation.html#quickstart-carbone-js">can usually take a Word document and output another Word document</a>, which is much easier for people to edit afterwards; they don’t freeze their output in a difficult-to-edit PDF.</p><p>To recap: text/word processors like Word or Google Docs are a different kind of beast to typesetting systems like LaTeX or Typst. They’re much more general, yet operate at a lower level of abstraction (by need of being more general). The mixing of styling and content, which is natural to WYSIWYG editors, means that there are more opportunities for styles or content patterns to drift out of sync across a document or across several documents. LaTeX and Typst (and HTML, for that matter) have a level of “semantic” annotation, meaning that it’s not “this line is Arial 14, bolded, left-justified, with two levels of numbering”; but instead “this line has whatever styling is applied to subsection headings”, which is a higher-level concept. Furthermore, since DOCX documents carry the document’s raw information in XML files, it’s fairly difficult to use them as templates from which documents are rendered with variable information, unlike plain-text-based formats such as Markdown, HTML, LaTeX and Typst where such templating is fairly easy to perform.</p><p>Finally, can Word <a href="https://github.com/liantze/AltaCV">do this</a> (showing little circles for the competency level of several languages in a CV)?</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\cvsection</span>{Languages}
</span></span><span><span><span>\cvskill</span>{English}{5}
</span></span><span><span><span>\divider</span>
</span></span><span><span><span>\cvskill</span>{Spanish}{4}
</span></span><span><span><span>\divider</span>
</span></span><span><span><span>\cvskill</span>{German}{3.5}
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/f672d6c165c6014411bb84f8ed5a8fa2.png" alt="a screenshot of part of a CV showing several languages and a &amp;ldquo;skill level&amp;rdquo; from 1 to 5, displayed as filled or empty circles"></p><p>Or <a href="https://www.ctan.org/pkg/menukeys">this</a> (displaying key presses, such as in a software manual, in little boxes)?</p><div><pre tabindex="0"><code data-lang="latex"><span><span>This is some more or less blind text, 
</span></span><span><span>to demonstrate how the sequence looks 
</span></span><span><span>in text. This <span>\keys</span>{<span>\ctrl</span>+<span>\alt</span>+Q} is 
</span></span><span><span>the result of a style which name...
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/8366882151d8a87fb58f3306f2c12b23.png" alt="a screenshot of a PDF document where a sequence of keys is displayed with the keys surrounded in little boxes that simulate keycaps"></p><p>Or <a href="https://www.baeldung.com/cs/latex-drawing-graphs">this</a> (drawing graphs directly in the document)?</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\begin</span>{tikzpicture}[node distance={15mm}, thick, main/.style = {draw, circle}] 
</span></span><span><span><span>\node</span><span>[main]</span> (1) {<span>$</span>x_<span>1</span><span>$</span>}; 
</span></span><span><span><span>\node</span><span>[main]</span> (2) [above right of=1] {<span>$</span>x_<span>2</span><span>$</span>}; 
</span></span><span><span><span>\node</span><span>[main]</span> (3) [below right of=1] {<span>$</span>x_<span>3</span><span>$</span>}; 
</span></span><span><span><span>\node</span><span>[main]</span> (4) [above right of=3] {<span>$</span>x_<span>4</span><span>$</span>}; 
</span></span><span><span><span>\node</span><span>[main]</span> (5) [above right of=4] {<span>$</span>x_<span>5</span><span>$</span>}; 
</span></span><span><span><span>\node</span><span>[main]</span> (6) [below right of=4] {<span>$</span>x_<span>6</span><span>$</span>}; 
</span></span><span><span><span>\draw</span><span>[-&gt;]</span> (1) -- (2); 
</span></span><span><span><span>\draw</span><span>[-&gt;]</span> (1) -- (3); 
</span></span><span><span><span>\draw</span> (1) to [out=135,in=90,looseness=1.5] (5); 
</span></span><span><span><span>\draw</span> (1) to [out=180,in=270,looseness=5] (1); 
</span></span><span><span><span>\draw</span> (2) -- (4); 
</span></span><span><span><span>\draw</span> (3) -- (4); 
</span></span><span><span><span>\draw</span> (5) -- (4); 
</span></span><span><span><span>\draw</span><span>[-&gt;]</span> (5) to [out=315, in=315, looseness=2.5] (3); 
</span></span><span><span><span>\draw</span><span>[-&gt;]</span> (6) -- node[midway, above right, sloped, pos=1] {+1} (4); 
</span></span><span><span><span>\end</span>{tikzpicture} 
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/36edc3c6700ed83e8bca543461db89c9.png" alt="a picture of a graph with several circular nodes joined with arrows and lines. Each node has a name from x1 to x6"></p><p>Or, my personal favorite, <a href="https://www.ctan.org/pkg/songbook">this</a>? It’s a package to write songbooks, with lyrics and chords, complete with such fancy tools as <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec5.4">replaying a verse’s sequence of chords on the next verses</a>, showing <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec5.6">parts that should be echoed</a>, <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec5.8">notes to the musicians</a> that don’t appear on the singer’s books, <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec6">guitar tablatures</a>, <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec7">automatic transposition</a>, <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec7.0.0.1">smart enharmonics</a> (i.e. whether a certain chord should be displayed as B♭ or A♯, which are technically the same sound. Which one to choose depends on the song’s key, usually dictated by the song’s first chord), <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec8.2">quotations from the Bible</a>, <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec10">automatic indices</a> (by title, by author, by Bible reference, by notable lyrics such as the first line), and <a href="https://songs.sourceforge.net/songsdoc/songs.html#sec4.0.0.1">the ability to create books with and without chords</a> (for the musicians and for the singers respectively) from the same source document.</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\songsection</span>{Worship Songs}
</span></span><span><span>
</span></span><span><span><span>\begin</span>{songs}{}
</span></span><span><span><span>\beginsong</span>{Doxology}[by={Louis Bourgeois and Thomas Ken},
</span></span><span><span>                     sr={Revelation 5:13},
</span></span><span><span>                     cr={Public domain.},
</span></span><span><span>                     index={Praise God, from Whom all blessings flow}]
</span></span><span><span><span>\transpose</span>{2}
</span></span><span><span><span>\beginverse</span>
</span></span><span><span><span>\[</span>G<span>]</span>Praise God, \[D<span>]</span>from \[Em<span>]</span>Whom \[Bm<span>]</span>all \[Em<span>]</span>bless\[D<span>]</span>ings \[G<span>]</span>flow;
</span></span><span><span>\[G<span>]</span>Praise Him, all \[D<span>]</span>crea\[Em<span>]</span>tures \[C<span>]</span>here \[G<span>]</span>be\[D<span>]</span>low;
</span></span><span><span>\[Em<span>]</span>Praise \[D<span>]</span>Him \[G<span>]</span>a\[D<span>]</span>bove, \[G<span>]</span>ye \[C<span>]</span>heav'n\[D<span>]</span>ly \[Em<span>]</span>host;
</span></span><span><span>\[G<span>]</span>Praise Fa\[Em<span>]</span>ther, \[D<span>]</span>Son, \[Am<span>]</span>and \[G<span>/</span>B G<span>/</span>C<span>]</span>Ho\[D<span>]</span>ly \[G<span>]</span>Ghost.
</span></span><span><span>\[C<span>]</span>A\[G<span>]</span>men.
</span></span><span><span>\endverse
</span></span><span><span>\endsong
</span></span><span><span>\end{songs}
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/7cf654add475e8a8ea281a0631f644f4.png" alt="a screenshot of a PDF document containing a song with chords placed in the correct places in the song&amp;rsquo;s lyrics"></p><p>Or, finally, can Word do <a href="https://ctan.org/pkg/tikzducks">ducks</a>? <a href="https://github.com/samcarter/tikzducks?tab=readme-ov-file#examples">Many ducks</a>? Tons of ducks?</p><div><pre tabindex="0"><code data-lang="latex"><span><span><span>\begin</span>{tikzpicture}[scale=0.6]
</span></span><span><span><span>\duck</span>
</span></span><span><span><span>\duck</span><span>[xshift=90pt, scale=.3, yshift=150pt]</span>
</span></span><span><span><span>\duck</span><span>[xshift=60pt, scale=.3, yshift=100pt]</span>
</span></span><span><span><span>\duck</span>[body=gray!50!white, head=gray!50!white,
</span></span><span><span>xshift=80pt, scale=.3, yshift=50pt]
</span></span><span><span><span>\end</span>{tikzpicture}
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/e4680717b1e1fe86c7e2df70461a5e61.png" alt="a picture of four ducks, a large yellow one, two small yellow ones following the large duck, and a small gray duck also following the large one"></p><p>To be fair, all of these were done in LaTeX, not in Typst, but the point was to compare to Word. Word doesn’t do any of those (maybe with macros, but hopefully we’ve agreed, as a species, on the fact that <a href="https://en.wikipedia.org/wiki/Macro_virus">macros are evil</a>). Typst, being similar to LaTeX in capabilities, should at least in theory be able to do all of that. For example, all the graphical examples (namely, the circles for the language competency, the fancy keystrokes, the graph with arrows, and the ducks) use <a href="https://en.wikipedia.org/wiki/PGF/TikZ">TikZ</a> in LaTeX. Typst already has <a href="https://typst.app/universe/package/cetz"><code>cetz</code></a>, “a library for drawing with Typst with an API inspired by TikZ”. It should allow users to do similar things (otherwise, contributions are probably welcome). For the songbook, <a href="https://typst.app/universe/package/conchord">there’s already <code>conchord</code></a> <a href="https://github.com/ljgago/typst-chords?tab=readme-ov-file#single-chords">and <code>chordx</code></a>, both of which already typeset chords over lyrics. There’s also Typst packages <a href="https://typst.app/universe/package/fletcher">for drawing diagrams made of nodes and arrows</a> à la <a href="https://graphviz.org/">Graphviz</a>/<a href="https://graphviz.org/doc/info/lang.html">DOT</a>, <a href="https://typst.app/universe/package/physica">timing/signal diagrams</a>, <a href="https://typst.app/universe/package/quill">quantum circuits</a>, <a href="https://typst.app/universe/package/polylux">slides</a> à la <a href="https://www.overleaf.com/learn/latex/Beamer">Beamer</a>, <a href="https://typst.app/universe/package/timeliney">Gantt charts</a>, <a href="https://typst.app/universe/package/unify">units for physical quantities</a>, <a href="https://typst.app/universe/package/board-n-pieces">chess boards</a> (including Forsyth–Edwards Notation), <a href="https://github.com/jamesrswift/typst-chem-par">chemical formulae</a>, <a href="https://typst.app/universe/package/cineca">calendars with events</a>, <a href="https://typst.app/universe/package/dashy-todo">TODOs or editor’s notes or comments at the sides of the content</a>, <a href="https://typst.app/universe/package/fractusist">fractals</a>, <a href="https://typst.app/universe/package/genealotree">genealogical trees</a>, <a href="https://typst.app/universe/package/iridis">color-matched parentheses</a>, <a href="https://typst.app/universe/package/k-mapper">Karnaugh maps</a>, <a href="https://typst.app/universe/package/mino">Tetris screens</a>, <a href="https://typst.app/universe/package/pintorita">multiple types of diagrams</a>, <a href="https://typst.app/universe/package/riesketcher">Riemann sums</a>, <a href="https://typst.app/universe/package/salsa-dip">chip pinout diagrams</a>, <a href="https://typst.app/universe/package/tutor">exams</a>, <a href="https://typst.app/universe/package/truthfy">truth tables</a> (automatically filled!), <a href="https://typst.app/universe/package/wavy">more timing diagrams</a>, and more.</p><h2 id="styling-documents">Styling documents
<span><a href="#styling-documents"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>Styling in Typst uses an approach that I hadn’t seen before, which they call <a href="https://typst.app/docs/reference/styling/">set rules and show rules</a>. Set rules behave somewhat like CSS, in that a set rule specifies a certain type of element that will be affected by it, and some parameters (e.g. that element’s color, size, position or alignment) can be controlled. However, unlike CSS, set rules can be applied in the middle of a document (they only take effect from the point that they’re encountered). Their “selector” capability is also much less powerful than that of CSS, as a set rule only targets one type of element (then again, different elements have entirely different settings, so being able to target multiple elements at once isn’t that useful).</p><p>Set and show rules are what Typst packages use to control the appearance of documents. They’re what differentiates an IEEE-style paper from a book from a leaflet from a 16th-century-style book. They control the appearance of headings (font family and size, indentation, numbering style), paragraphs (font family and size, spacing), tables (the style of headings, cells, borders and more), pages (size, margins, columns, binding style, numbering, header, footer), figures (the numbering style and naming convention), and more. All those very detailed conventions that a certain conference, journal or book may want your document to follow are converted to set rules.</p><p>A simple set rule looks like this:</p><pre tabindex="0"><code data-lang="typst">= Unstyled introduction
This title hasn't had the new style applied yet

#set heading(numbering: "1.")

= Introduction
The set rule above was applied to the title
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/58c602ad2f69d7c158647486490e64ab.png" alt="a screenshot of a PDF document showing two titles, one with no number and one with a number. A set rule between the two titles causes the second one to have a number"></p><p>As discussed above, set rules take effect from the moment they’re declared until the end of the document (or containing block, if they’re declared inside some sort of block). Here we <a href="https://typst.app/docs/reference/model/heading/#parameters-numbering">configured the <code>numbering</code> parameter of the <code>heading(...)</code> function</a>, which is what <code>= Title</code> headings end up as. We specified that headings should be numbered with arabic numberals, and the second heading had that new style applied.</p><p>In general, set rules can modify anything that the element in question exposes as a parameter. Recall that, in Typst, every element (yes, including plain text) is actually a function call. For example, <code>= Title</code> is secretly a <code>heading(level: 1, "Title")</code>. <code>- Element</code> (in the context of an unordered list) is <a href="https://typst.app/docs/reference/model/enum/">an element inside an <code>enum</code>’s last variadic argument</a>. A citation, inserted with <code>@citation_key</code>, is actually <a href="https://typst.app/docs/reference/model/cite/">a call to <code>cite(label("citation_key"))</code></a>.</p><p>Therefore, since every part of the text is a function, and every function has some configurable parameters, set rules can control aspects of each element. For example, <a href="https://typst.app/docs/reference/model/heading/#parameters">headings can have their numbering style controlled, as well as whether or not they appear in the table of contents</a>. Other functions have other parameters, such as <a href="https://typst.app/docs/reference/text/text/">the <code>text(...)</code> function</a>, which has <a href="https://typst.app/docs/reference/text/text/#parameters">a ton of parameters</a> that control the appearance of that bit of text: the font, weight, size, fill color, stroke color, spacing (between characters, words and lines), language, direction (left-to-right or right-to-left), whether to request the character that adds a slash across the zero, and more.</p><p>For an example, observe <a href="https://typst.app/universe/package/charged-ieee">the <code>charged-ieee</code> template</a>, which implements styling to conform to the IEEE conferences and journals guidelines. The template <a href="https://github.com/typst/templates/tree/main/charged-ieee">is open source</a>, under a variant of the MIT license that requires no attribution. As can be seen in the template’s source code, <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L31-L183">the largest amount of the template’s code</a> is devoted to set rules that configure various aspects of the document: there’s <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L34">font family and size</a>, the <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L37">styles for numbered lists</a> (first level is “1)”, second level is “a)” and third level is “i)”), <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L41-L44">styling for table’s captions</a>, <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L469">styling for images</a>, <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L53-L65">margins and page size</a>, <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L68-L69">equation numbering</a>, <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L90">heading numbering</a> (sections are “I.”, subsections are “A.”, and sub-sub-sections are “a.”), <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L137">font size for the bibliography</a>, <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L181">two-column mode</a>, and finally <a href="https://github.com/typst/templates/blob/fd8fd73a825bef6e7fbc85f0dc9eac43b67c5715/charged-ieee/lib.typ#L197">the content</a>. While it’s been a while since I’ve had to write a paper in IEEE format, I’m fairly sure that all those set rules have a more-or-less direct correspondence with the IEEE guidelines.</p><p>Typst’s set rules can also target with more granularity than entire functions, by <a href="https://typst.app/docs/reference/foundations/selector/">using <code>where(...)</code> to compose more precise selectors</a>. For example, let’s say that we wanted to target only second-level headings (i.e. <code>== Title</code> but not <code>= Title</code> or <code>=== Title</code>). This would be expressed in a show-set rule as:</p><pre tabindex="0"><code data-lang="typst">#show heading.where(level: 2): set heading(numbering: "1.")
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/aec592ea10b72ca295fb690f80ed0b8a.png" alt="a screenshot of a PDF with three titles, one of level 1, one of level 2, and one of level 3. Only the level 2 title has a number"></p><p>Only the second-level heading gets the numbering applied.</p><p>The last rule was an example of a show-set rule: rather than being applied to each instance of the <code>heading(...)</code> function, i.e. all headings, this one applies only to level 2 headings, via the <code>.where(level: 2)</code> part. This capability is not available to set rules, only to show rules. These are much closer to CSS selectors: where a set rule can do something like <code>a {...}</code> (i.e. matching all <code>&lt;a&gt;</code> elements), a show rule can be much closer to <code>button[type='submit'] {...}</code> (i.e. match only <code>&lt;button type="submit" ...&gt;</code>). Show rules can match only function calls that have a certain parameter, or a certain element, as long as it has a label.</p><p>Show rules aren’t limited either to only presetting the arguments that the specific function has available. Instead, a show rule can declare a function that receives the raw element that is being formatted. The function should return some content, but it is not limited to modifying the element that it received; it can build one from scratch instead. For example, we could write a Typst document where it isn’t possible to bold content:</p><pre tabindex="0"><code data-lang="typst">*Normal Bold*

#show strong: it =&gt; emph(it.body.text)

*Still Bold?*
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/7cbada243d1e877b3b76b1c69dd1b49b.png" alt="a screenshot of a PDF document where bolded text actually appears in italics"></p><p>As can be seen above, once the show rule has been declared, any further attempts to print bolded text actually print italicized text. This is because, whenever <a href="https://typst.app/docs/reference/model/strong/">a call to <code>strong(...)</code></a> is encountered, Typst instead invokes the function that was passed to the show rule. <code>it</code> contains the entire bold element, which happens to contain its raw text in <code>it.body.text</code>. Thus, we wrap it <a href="https://typst.app/docs/reference/model/emph/">with a call to <code>emph(...)</code></a>, which italicizes its argument, and return it. No more bold text.</p><p>In effect, when used in this way, show rules are capable of completely intercepting calls to a certain content function, and the actual return value of that function is completely under the control of the show rule, which can decide to return an entirely different element.</p><p>To recap: Styling in Typst is achieved via <em>set rules</em>, which target a class of elements (e.g. headings, or text blocks, or code blocks, or unordered lists) and can preset configuration values for that class of elements. There are also <em>show rules</em>, which can target elements with more precision, and can also completely override the presentation of an element by providing a custom function that will be called whenever a certain class of element is encountered. Said custom functions can completely drop the element, change some arguments, or replace it entirely.</p><h2 id="scripting-in-typst">Scripting in Typst
<span><a href="#scripting-in-typst"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>Typst, much like LaTeX, embeds <a href="https://typst.app/docs/reference/scripting/">something that acts like a programming language</a>, though I’m unsure if it’s Turing complete. Typst’s scripting language is a bit like <a href="https://react.dev/learn/writing-markup-with-jsx">JSX</a> (React’s language, that allows Javascript to manipulate HTML elements) in that functions written in the scripting language can directly return Typst elements (e.g. headings, tables, or images), in the same way that in JSX it’s valid to write <code>return &lt;h1&gt;Hello!&lt;/h1&gt;</code>, i.e. returning (from Javascript) an HTML element. Similarly, in Typst:</p><pre tabindex="0"><code data-lang="typst">#let name = "jreyesr"
#let titlify(text) = heading(level: 1, text)

#titlify("Written by " + name)
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/599f2b0e78d82ce31079019c0e9737c6.png" alt="a screenshot of a PDF document with a single level 1 heading that says &amp;ldquo;Written by jreyesr&amp;rdquo;"></p><p>The first line declares a variable, <code>name</code>, with a value, in the same way as any mainstream programming language would (though, in the spirit of JS and Python, types are inferred rather than stated). This variable will be available to the rest of the document. By the way, a line that starts with <code>#</code> belongs to the scripting realm, rather than the standard Typst “content” realm. In the scripting realm, scripting lines are executed, and what appears back in the content realm is the <em>return value</em> of each line. A <code>let</code> binding, which assigns a name to something, returns nothing. Not even a blank line. Therefore, the first line causes nothing to appear on the output document.</p><p>The second line is more of the same: it binds the name <code>titlify</code>, but this time <em>to a function</em> rather than to a static value. This function, when called, will return (Typst functions have an implicit return of their last statement, like Rust’s <a href="https://users.rust-lang.org/t/explicit-and-implicit-return-in-functions/17089">implicit returns</a>) <a href="https://typst.app/docs/reference/model/heading/">a heading element</a>, which is itself composed by calling the <code>heading(level: N, content)</code> function that is built-in to the language. In fact, this function is called internally when you write a heading in normal Typst content, e.g. <code>== Something</code> would call <code>heading(level: 2, "Something")</code>. After the second line, we have a function available that takes some text (as a normal string) and returns a content block that is a heading of level 1 whose text content is the provided text.</p><p>Again, since the entire line is actually a <code>let</code> binding, and <code>let</code> bindings return nothing, this line doesn’t output anything to the document either.</p><p>And then, on the third line (actually fourth), we call/invoke that <code>titlify</code> function. We pass it an expression (joining two strings, a fixed one and the variable <code>name</code> that was declared before). This concatenates the strings first, then passes them to <code>titlify</code>, which in turn calls <code>heading(level: 1, ...)</code> with that value. <code>heading(...)</code> returns a piece of content, which is in turn returned by <code>titlify(...)</code> because its last line was the call to <code>heading(...)</code>. Therefore, the fourth line is replaced by a piece of content that contains a heading. This <em>is</em> printed to the output document, and causes the heading to appear in the PDF.</p><p>Script snippets can be interspersed with text content:</p><pre tabindex="0"><code data-lang="typst">#let name = "jreyesr"

This was *written by #name!*
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/dca2e02c0682a1415100e9a3b60829a2.png" alt="a screenshot of a PDF document with a single line, that says &amp;ldquo;This was written by jreyesr!&amp;rdquo;. Part of the line is bolded"></p><p>This is similar to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals">template literals</a> in Javascript, where it’s possible to embed variables in a string. The working principle in this example is the same as above: the first line, which declares the <code>name</code> variable via <code>let</code>, returns nothing and therefore prints nothing on the document. The second (actually third) line enters the scripting realm when <code>#name</code> is encountered, which when evaluated actually returns a string, which is therefore printed on the content realm.</p><p>Expressions can be more complex than just a variable name, i.e. <code>We've found #(items.len()) results</code>, which uses <code>#()</code> to delimit the expression <code>items.len()</code>raw, and also <a href="https://typst.app/docs/reference/foundations/array/#definitions-len">calls a method on the <code>items</code> array</a>. Again, this is similar to the capabilities of <a href="https://www.hackingwithswift.com/articles/178/super-powered-string-interpolation-in-swift-5-0">Swift</a>, <a href="https://www.hackingwithswift.com/articles/178/super-powered-string-interpolation-in-swift-5-0">Dart</a> or JS, where full expressions (not just variable names) are allowed inside strings.</p><p>We’ve seen that Typst documents alternate between two modes: normal “content” mode, in which text is output to the PDF document; and code/scripting mode, in which a different syntax is used. There’s also math mode, in which equations are typeset, but that’s not used here. You enter code mode by typing <code>#</code>. In code mode, Typst behaves more like a traditional programming language in which variables can be defined and <a href="https://typst.app/docs/reference/scripting/#conditionals">logic (e.g. if-else expressions)</a> can be expressed. There are values (e.g. strings, numbers, arrays/lists, and dictionaries/hashmaps), which can be passed to functions, have methods called on them, and otherwise manipulated. Each expression (roughly a line) in code mode has a “return value”. For example, <code>let x = "abc"</code> returns nothing (it’s a variable assignment, and the interesting part of variable assignments is the fact that they assign a variable, not their return value as if they were a mathematical operation), whereas <code>"abc".len()</code> would return 3 (the length of the string <code>"abc"</code>). Whenever a line in code mode returns something, that return value is transported back into the content mode and placed there. This is the way in which code mode can have an effect on the output: if it couldn’t communicate back to content mode, nothing that happened in code mode would change the PDF output, and at that point, why have it at all?</p><p>Of course, once code mode can produce content that is output to the document, it’s possible to build a document, at least in part, from code. For example, <a href="https://typst.app/docs/reference/scripting/#loops">code mode supports for-each and do-while loops</a>. Each iteration of the loop can output some content, which is useful, for example, to write variable-length bullet lists:</p><pre tabindex="0"><code data-lang="typst">#let vowels = "aeiou".clusters()
#let consonants = "bcdfghjklmnpqrstvwxyz".clusters()

#let word = "Hello!"

= Word of the day: "#word" (#word.len() characters)

#for c in word [
    - #c #sym.triangle.filled.small.r #if vowels.contains(lower(c)) [Vowel] else if consonants.contains(lower(c)) [Consonant] else [Symbol]
]
</code></pre><p>This would evaluate to something like this (still in Typst format, but now with all scripting content already evaluated and therefore removed):</p><pre tabindex="0"><code data-lang="typst">= Word of the day: "Hello!" (6 characters)

- H #sym.triangle.filled.small.r Consonant
- e #sym.triangle.filled.small.r Vowel
- l #sym.triangle.filled.small.r Consonant
- l #sym.triangle.filled.small.r Consonant
- o #sym.triangle.filled.small.r Vowel
- ! #sym.triangle.filled.small.r Symbol
</code></pre><p>which in turn renders into this PDF:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/3ecce6af6341001b5fe2943c5a9c4a19.png" alt="a screenshot of a PDF document with a bullet list containing each letter of the word &amp;ldquo;Hello&amp;rdquo;. Each letter also has an indication on whether it&amp;rsquo;s a vowel, a consonant or a symbol"></p><p>Notice how the entire content of the document (the title, the character count in the title, how many bullet points there are, and the content of each one) is controlled by a single variable, <code>word</code>. If we just change the word, the entire document changes to match:</p><pre tabindex="0"><code data-lang="typst">#let vowels = "aeiou".clusters()
#let consonants = "bcdfghjklmnpqrstvwxyz".clusters()

#let word = "test"

= Word of the day: "#word" (#word.len() characters)

#for c in word [
    - #c #sym.triangle.filled.small.r #if vowels.contains(lower(c)) [Vowel] else if consonants.contains(lower(c)) [Consonant] else [Symbol]
]
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/c522ce25e33d0da929878df72f8127c5.png" alt="a screenshot of a PDF document with the same structure as the screenshot above, except that now it talks about the word &amp;ldquo;test&amp;rdquo; instead of &amp;ldquo;Hello&amp;rdquo;"></p><p>Tables can also be filled with this approach, albeit with a bit more syntax:</p><pre tabindex="0"><code data-lang="typst">#let vowels = "aeiou".clusters()
#let consonants = "bcdfghjklmnpqrstvwxyz".clusters()
#let descr(c) = if vowels.contains(lower(c)) {"Vowel"} else if consonants.contains(lower(c)) {"Consonant"} else {"Symbol"}

#let word = "Hello!"

= Advanced analysis of the word "#word"

#table(
  columns: (auto, auto),
  inset: 10pt,
  align: horizon,
  table.header(
    [*Letter*], [*Type*],
  ),
  ..for c in word {
    (c, descr(c))
  }
)
</code></pre><p>The first part is the same as above. The <code>table()</code> call, <a href="https://typst.app/docs/reference/model/table/">which is always used to create tables</a>, happens to <a href="https://typst.app/docs/reference/model/table/#parameters-children">take the cells as its last arguments</a>. In other words, it’s always called like this: <code>#table(arg1: val1, arg2: val2, cell1, cell2, cell3, cell4, ...)</code>. The first arguments, which have a name and a value, are configuration/formatting arguments for the table, such as the number and width of the columns, alignment, padding, row heights, colors for the lines and cell backgrounds, and similar. Then, anything else is collected and treated as cells: the final argument argument is variadic, meaning that it can take an unspecified number of arguments, acting as a catch-all that eats everything that isn’t a formatting parameter for the table. In our case, we use a for-each loop to run over each character and, for each one, create <a href="https://typst.app/docs/reference/foundations/array/">an array</a> with two values: the character itself and a description of the character, e.g. “Vowel” or “Consonant”. Therefore, the for-each loop itself can be thought of as being replaced by an array of arrays: for each character in the word, there’s an array with two values.</p><p>Then, <a href="https://typst.app/docs/reference/foundations/arguments/#spreading">the <code>..</code> operator</a> is used to “spread” that array of arrays into the variadic argument of the <code>table(...)</code> function. <a href="https://github.com/typst/typst/discussions/3365">That pattern is discussed here</a>, and is explicitly endorsed by Typst’s authors. The table rendering code then takes over, having received a bunch of cells, and renders this:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/15cef0151d4795a7231a0c8a1d38e714.png" alt="a screenshot of a PDF document which contains a table with two columns. In the left column are the letters of the word &amp;ldquo;Hello&amp;rdquo;, and on the right column there is whether that letter is a vowel, a consonant or a symbol"></p><p>This demonstrates that tables can be created programmatically, by generating their cells in code and then passing them to the <code>#table(...)</code> function. Of course, we can then apply traditional programming techniques, such as extracting the code which generates a single row to another function:</p><pre tabindex="0"><code data-lang="typst">#let vowels = "aeiou".clusters()
#let consonants = "bcdfghjklmnpqrstvwxyz".clusters()
#let descr(c) = if vowels.contains(lower(c)) {"Vowel"} else if consonants.contains(lower(c)) {"Consonant"} else {"Symbol"}

#let word = "Hello!"

= Advanced analysis of the word "#word"

#let row(letter) = (strong(letter), descr(letter))

#table(
  columns: (auto, auto),
  inset: 10pt,
  align: horizon,
  table.header(
    [*Letter*], [*Type*],
  ),
  ..for c in word {
    row(c)
  }
)
</code></pre><p>This is nearly the same as the previous example, except that now we have a new function, <code>row(letter)</code>. It receives a single character and returns the row that corresponds to that character. Here it’s just two cells: the first (leftmost) cell displays the character itself, bolded; and the second (rightmost) cell contains its description, either “Vowel”, “Consonant” or “Symbol”. Then, the table merely calls <code>row(letter)</code> inside the for-each loop. Of course, since this is a trivial table, doing this is unnecessary, but for more complex tables it may be useful since now the <code>row(letter)</code> function is just concerned with <em>a single row</em> of the table.</p><p>People familiar with React may recognize this as similar to <a href="https://react.dev/learn/your-first-component#components-ui-building-blocks">React’s components</a>, AKA new-style or function components (not <a href="https://www.twilio.com/en-us/blog/react-choose-functional-components">class components</a>, which are older). Of course, all concepts related to interactivity (event handlers, hooks, lifecycle functions) don’t apply to Typst. But the idea of <a href="https://react.dev/learn/your-first-component#defining-a-component">“a JavaScript function that you can sprinkle with markup”</a> can be carried over to Typst. For example, our <code>row(c)</code> function in the example above would be similar to a <code>function Row({character})</code> component in React, called like this: <code>&lt;Row character={c}&gt;</code>:</p><div><pre tabindex="0"><code data-lang="jsx"><span><span><span>function</span> <span>descr</span>(<span>c</span>) {
</span></span><span><span>  <span>if</span>(<span>"aeiou"</span>.<span>includes</span>(<span>c</span>.<span>toLowerCase</span>())) {
</span></span><span><span>    <span>return</span> <span>"Vowel"</span>
</span></span><span><span>  } <span>else</span> <span>if</span>(<span>"bcdfghjklmnpqrstvwxyz"</span>.<span>includes</span>(<span>c</span>.<span>toLowerCase</span>())) {
</span></span><span><span>    <span>return</span> <span>"Consonant"</span>
</span></span><span><span>  }
</span></span><span><span>  <span>return</span> <span>"Symbol"</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>function</span> <span>Row</span>({<span>character</span>}) {
</span></span><span><span>  <span>return</span> (
</span></span><span><span>    &lt;<span>tr</span>&gt;
</span></span><span><span>      &lt;<span>td</span>&gt;{<span>character</span>}&lt;/<span>td</span>&gt;
</span></span><span><span>      &lt;<span>td</span>&gt;{<span>descr</span>(<span>character</span>)}&lt;/<span>td</span>&gt;
</span></span><span><span>    &lt;/<span>tr</span>&gt;
</span></span><span><span>  )
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>function</span> <span>Table</span>({<span>word</span>}) {
</span></span><span><span>  <span>return</span> (
</span></span><span><span>    &lt;<span>table</span>&gt;
</span></span><span><span>      &lt;<span>thead</span>&gt;
</span></span><span><span>        &lt;<span>tr</span>&gt;
</span></span><span><span>          &lt;<span>th</span>&gt;<span>Letter</span>&lt;/<span>th</span>&gt;
</span></span><span><span>          &lt;<span>th</span>&gt;<span>Type</span>&lt;/<span>th</span>&gt;
</span></span><span><span>        &lt;/<span>tr</span>&gt;
</span></span><span><span>      &lt;/<span>thead</span>&gt;
</span></span><span><span>      &lt;<span>tbody</span>&gt;
</span></span><span><span>        {[...<span>word</span>].<span>map</span>((<span>c</span>, <span>i</span>) =&gt; (&lt;<span>Row</span> <span>character</span><span>=</span>{<span>c</span>} <span>key</span><span>=</span>{<span>i</span>}/&gt;))}
</span></span><span><span>      &lt;/<span>tbody</span>&gt;
</span></span><span><span>    &lt;/<span>table</span>&gt;
</span></span><span><span>  )
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>export</span> <span>function</span> <span>App</span>(<span>props</span>) {
</span></span><span><span>  <span>return</span> (
</span></span><span><span>    &lt;<span>Table</span> <span>word</span><span>=</span><span>"Hello!"</span>/&gt;
</span></span><span><span>  );
</span></span><span><span>}
</span></span></code></pre></div><p>In both cases (React and Typst), it’s possible (and, in the case of React, it’s the official way too) to write functions that receive some parameters and return a piece of visual content (a bit of HTML code in React, and something that gets printed to the PDF in Typst). Those functions can compose neatly, since they can be called by other functions, even repeatedly, which is actually React’s core idea of <a href="https://react.dev/learn/understanding-your-ui-as-a-tree">the UI being a tree</a> where components are nested inside other components. In the case of Typst, that model (that of nested elements) may not be as useful since the final destination of the content is a PDF, where things are a lot more “linear” in nature, but it may still be of use.</p><p>Images can also be inserted automatically, even from a string. Let’s say that you have a Base64-encoded string that contains an image. <a href="https://typst.app/universe/package/based/">The <code>based</code> package</a> (third party, open source, available <a href="https://github.com/EpicEricEE/typst-based">on Github</a>) can decode that Base64 string to a raw byte array (Typst <a href="https://typst.app/docs/reference/foundations/bytes/">does have a native Bytes type</a> which can represent arbitrary sequences of bytes, so there’s no need to transport them as strings, where special characters may cause issues). At this point, we have a byte array with the raw image data. Then, there’s <a href="https://typst.app/docs/reference/visualize/image/#definitions-decode">the <code>image.decode(...)</code> function</a>, which can read said byte array and generate an image. Normally, images are loaded by providing a file path, e.g. <code>image("path.png")</code>, but it’s also possible to load them from a bytes object, which doesn’t require that any files on disk are read.</p><pre tabindex="0"><code data-lang="typst">#import "@preview/based:0.1.0": base64

#let data = base64.decode("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")

#figure(
    image.decode(data),
    caption: "Very important image"
)
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/37f556a06e486e1175390fadb6b07298.png" alt="a screenshot of a PDF showing an image that was decoded from a Base64 string"></p><p>You’re welcome.</p><p>And, finally, Typst scripts are capable of intepreting and running <em>other</em> Typst scripts that come in as a string, which therefore grants Typst scripts the same power as Typst itself. This is done <a href="https://typst.app/docs/reference/foundations/eval/">by using the <code>eval(...)</code> function</a>, which takes a string (i.e. a sequence of characters) and interprets it as Typst code, in one of three contexts: markup/content mode, scripting mode, or math mode:</p><pre tabindex="0"><code data-lang="typst">Code: #eval("1 + 1") // outputs 2, code mode is the default

Markup: #eval("= Title", mode: "markup") // Outputs a level-1 heading

Math: #eval("1 + 1", mode: "math") // Outputs 1+1, typeset as an equation

#table(
    columns: (auto, auto, auto),
    table.header([*Mode*], [*Result*], [*Type*]),
    [Code (default)], repr(eval("1+1")), repr(type(eval("1+1"))),
    [Markup], eval("1+1", mode: "markup"), repr(type(eval("1+1", mode: "markup"))),
    [Math], eval("1+1", mode: "math"), repr(type(eval("1+1", mode: "math")))
)
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/8bc82d59522730c15299bf1ddcf34dd3.png" alt="a screenshot of a PDF document which displays the different interpretation modes for 1+1, as described in the text above"></p><p>In theory, <code>eval(...)</code> would allow Typst code to dynamically generate <em>more</em> Typst code. It could also be used to, say, <a href="https://typst.app/docs/reference/data-loading/read/">read other Typst files from disk</a>, and then pass them to Typst’s engine for evaluation, with their results (be them the result of code being run, or markdown) being included in the main document that called <code>eval</code>. This isn’t quite LISP levels of code inception, but it’s fairly close without the code-is-data philosophy of LISPs.</p><p>Use of <code>eval</code> isn’t recommended, as is the case with similar functions in other programming languages that offer similar functionality. For references, see <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/eval#never_use_direct_eval!">Javascript’s dire warnings</a> and <a href="https://www.udacity.com/blog/2023/03/pythons-eval-the-most-powerful-function-you-should-never-use.html">an article on Python’s <code>eval</code></a>.</p><blockquote><p>This function should only be used as a last resort.</p></blockquote><p>However, it’s still there, in case you need it.</p><p>To conclude this part: Typst’s documents have <a href="https://typst.app/docs/reference/scripting/">a fairly powerful scripting language</a> that can perform various operations, such as logical and arithmetical operations, string manipulations, reading data from disk, and more. Furthermore, the scripts that exist inside a Typst document can build and output content to the PDF that is being generated. This means that Typst documents can have parts that are generated dynamically, such as a bullet list whose elements are read from a file, images that vary, or tables with a variable number of rows. This means that Typst can be used as a tool to build dynamic “reports” or other similar documents, that have a fixed structure and some parts but where other parts vary per document.</p><h3 id="bonus-plugins">Bonus: plugins!
<span><a href="#bonus-plugins"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>While we’re on the topic of Typst’s scripting language, let’s briefly mention Typst’s plugins, since they’re very useful in extending Typst’s capabilities.</p><p>Typst natively supports plugins, pieces of third-party code that extend the functionality of Typst’s scripting language. Plugins are used to implement templates (e.g. a certain journal’s style guidelines), visualizations, pure logic (such as the base-64 package that we’ve just used) and other features that aren’t feasible to include with the Typst core.</p><p>As we’ve discussed before, there’s a repository where plugins can be published, called <a href="https://typst.app/universe/">Universe</a>. It’s where most plugins live (though note that it’s not required, as you could publish a package just on Github or elsewhere and direct people to <a href="https://github.com/typst/packages#local-packages">download the code and place it in the appropriate directory</a>). The Universe provides discoverability (it has a really nice web UI with a search bar and a preview of each package’s README, much like NPM, Pip, Cargo or other package managers), and it also eases installation (if a package is published in the Universe, users can just import it in their Typst files. There’s no need to run any commands or install things). Some LaTeX distributions, such as MiKTeX, also <a href="https://docs.miktex.org/manual/autoinstall.html">have the ability to autoinstall packages</a> when they’re imported and aren’t installed in the computer.</p><p>To use a package in a document, you use <a href="https://typst.app/docs/reference/scripting/#modules">the <code>import</code> function</a>:</p><pre tabindex="0"><code data-lang="typst">#import "@preview/based:0.1.0"

#str(based.base64.decode("SGVsbG8h"))

OR

#import "@preview/based:0.1.0": base64

#str(base64.decode("SGVsbG8h"))
</code></pre><p>The first form imports the entire package, here <code>based</code>, <a href="https://typst.app/universe/package/based">a package that implements conversions to and from base-16, base-32 and base-64</a>. That package has a <code>base64</code> variable that contains a <code>decode(...)</code> function.</p><p>In the second form, we specify which elements from the package should be imported, here only <code>base64</code>. The rest of the code is the same.</p><p>Some packages are pure Typst code, such <a href="https://github.com/EpicEricEE/typst-based/tree/master/src">as the <code>based</code> package above</a>. They may just contain logic that can be expressed in Typst code. Or they may not need anything else: consider templates for a certain journal, where everything can in principle be written in Typst itself (it’s just a lot of settings for a lot of elements, and set rules, and show rules, and other Typst constructs). Or they may be providing a higher-level API over lower-level functions that already exist on Typst, such as <a href="https://github.com/cetz-package/cetz">the <code>cetz</code> package</a>, which eventually resolves its shapes to <a href="https://typst.app/docs/reference/visualize/">raw visualization calls</a>, in terms of lines, ellipses and polygons.</p><p>However, Typst also supports plugins written in other programming languages. This is done <a href="https://typst.app/docs/reference/foundations/plugin/">via WebAssembly plugins</a>. WebAssembly is a fairly modern technology, <a href="https://developer.mozilla.org/en-US/docs/WebAssembly">originally designed, as its name implies, for web browsers</a>. It’s fairly low level code (similar to assembly in that it operates on primitive instructions such as addition or loading to a register, along with a very simple linear memory model), which can be executed in a browser in a very performant manner, close to that of native (compiled) code. Of course, much like with traditional assembly language, you most likely won’t write programs directly in it. Instead, other higher-level programming languages (e.g. Rust, C# or Python) can be compiled into WebAssembly and used in browsers, as long as they obey the calling conventions, which are standardized.</p><p>WebAssembly, being a web technology that would be used on browsers, is <em>very</em> concerned with safety. Safety <a href="https://www.embedded.com/memory-safety-in-rust/">as in memory-safe</a>, AKA preventing null-pointers from doing null-pointery things; and also safety as in sandboxing, AKA very strong guarantees (that can be enforced by the host application, typically the browser) on what can be done by the WebAssembly programs that run inside of it. This is, of course, because browsers need to treat all their inputs (usually Javascript code, and now WASM too) as potentially untrusted, since the user may have visited a malicious page. In practice, this means that a lot of care has been taken to prevent WASM programs from being able to compromise their host application/interpreter/VM. In a browser, such compromises (such as being able to read arbitrary process memory) would allow a malicious page to extract user data, such as what other tabs are open and what is displayed on them, or the user’s credentials that are saved in the browser password manager, or cookies, or (if writes are possible) to modify said data. Hence the memory safety.</p><p>That being said, WASM has also found some popularity in other, <a href="https://webassembly.org/docs/non-web/">non-Web environments</a>. Its emphasis in memory safety means that it’s much more difficult for a plugin written in WASM to crash its entire host entire application, because traditional bad reads and writes that are possible in, say, C are a lot more difficult (ideally impossible). The sandboxing capabilities mean that the host application can provide good guarantees on what the plugin is and isn’t allowed to do, which is nice when you may be running not-necessarily-trusted code. Since WASM was defined for browsers, which are by necessity cross-OS, WASM’s semantics are the same across OSs and processor architectures, which means that (as long as there’s a compliant interpreter for your processor+OS+whatever else combo) WASM programs should run in the same way for everyone. WASM programs aren’t tied to, say, the Windows API, or the Linux API, or the Mac OS API.</p><p>For example, WebAssembly programs <a href="https://docs.deno.com/runtime/reference/wasm/">can run in Deno</a>, a Javascript runtime (think “replacement for Node.JS”) with <a href="https://docs.deno.com/runtime/fundamentals/security/">very nice security guarantees</a> (e.g. “no programs can read the file system or make network calls unless explicitly allowed”). WASM is used <a href="https://developer.fermyon.com/spin/v2/">by Spin</a>, a serverless platform (similar to AWS Lambda or Cloudflare Workers) where event handlers can be written in one of many programming languages (they’re then all compiled to WASM before they’re loaded on Spin). Istio (a service mesh that is fairly common in Kubernetes ecosytems) <a href="https://istio.io/latest/docs/reference/config/proxy_extensions/wasm-plugin/">can load and use WASM plugins</a> at various points when a request is being processed. Fluent Bit, which is a program that collects, processes and forwards observability data (i.e. logs, metrics and traces) from applications to monitoring applications, <a href="https://docs.fluentbit.io/manual/development/wasm-filter-plugins">supports WASM plugins</a> for inputs (i.e. sources of data) and filters (i.e. stages that receive some data, transform it in some way and then output the new data). The Open Policy Agent, OPA, which is a tool where authorization policies can be expressed (e.g. “users who are in the Customer Service group can see the accounts of other users who are in their same region, for troubleshooting purposes”) and evaluated (e.g. given a certain user X who wants to see the account of another user Y, should that be allowed?) can <a href="https://www.openpolicyagent.org/docs/latest/wasm/">dynamically generate and return small WASM programs</a> that implement the authorization policy. For example, OPA would be able to generate a WASM program that, when called with the data of two users, returns either <code>true</code> or <code>false</code>, depending on whether the first input user is allowed to access the account of the second input user. In effect, that’s the authorization policy, embodied in an executable form. In this way, the application that needs to enforce that policy can do so itself (it asks OPA for the decision program, then loads it locally using a WASM runtime in the app’s language, and then calls it repeatedly whenever it needs to authorize an operation). Otherwise, the application would have to call OPA, which is a separate component, whenever an authorization decision needs to be made, which adds latency (because of the network hop) into <em>every</em> request, because most requests probably need authorization.</p><p>There are probably many more examples. WASM provides a nice way for programs to load and run small pieces of code that need to run fast and should be isolated, perhaps because they may not be trusted. It’s also useful to provide cross-language compatibility (by using yet another language, WASM). And it’s supposed to be fast.</p><p>Typst can also load and invoke WASM plugins. They’re completely isolated:</p><blockquote><p>Plugins run in isolation from your system, which means that printing, reading files, or anything like that will not be supported for security reasons.</p></blockquote><p>This means that WASM plugins in Typst are limited to “pure” computations, i.e. take an input, crunch the data, spit out an output. No reading files, calling servers, or other environmental interactions.</p><p>While it’s not explicitly stated in the docs, one of the points of providing WASM plugins is to allow people to write plugins in other programming languages, not necessarily on Typst’s scripting language. As long as it can compile into WASM (and most mainstream programming languages can), it should be possible to use many languages to express the logic of the plugin, and then have the WASM compiler translate it into something that Typst can load and use.</p><p>Since WASM is a very low-level language, there’s <a href="https://typst.app/docs/reference/foundations/plugin/#protocol">a protocol that all plugins must adhere to</a>. It involves a bunch of byte arrays (the equivalent of <code>char*</code> in C), into which the input arguments are read. Once it has its arguments, the WASM function can do whatever it wants with them (subject to the constraints of the sandbox), and it’ll then place its output in another byte array, from which Typst code will read it. Typst provides <a href="https://github.com/astrale-sharp/wasm-minimal-protocol">an example repo</a> with Rust, Zig and C examples, all of which can compile into WASM.</p><h2 id="typst-as-a-dynamic-document-generator">Typst as a dynamic document generator
<span><a href="#typst-as-a-dynamic-document-generator"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>Now that we’ve seen that Typst embeds a scripting engine that has many of the capabilities of a programming language, we will see how Typst could be used as a report generator or templating engine.</p><h3 id="alternatives">Alternatives
<span><a href="#alternatives"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>There are many tools that can take a Word document with some special markup (a “template”), plus some variable “data” (typically a JSON document) and generate either Word or PDF documents where the variable data has been merged into the template document. A non-exhaustive list, in alphabetical order, is as follows (each one links to a page with demos):</p><ul><li><a href="https://carbone.io/templates-examples.html">Carbone</a></li><li><a href="https://www.docmosis.com/how-it-works/document-gallery/">Docmosis</a></li><li><a href="https://docxtemplater.com/demo/#/view/energy-performance-certificate">Docxtemplater</a></li><li><a href="https://playground.jsreport.net/w/admin/d7o0nIWc">JSReport</a> (note: click the Run button at the top left to generate the output report)</li><li><a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/demos.html">Plumsail</a></li><li><a href="https://templater.info/demo">Templater</a></li></ul><p>They all use the same ideas: you design (typically in Word, which is what people are familiar with) something that looks like this:</p><figure><img src="https://blog.jreyesr.com/posts/typst/_resources/e7074bdf99a30309581b6d96a1d381b7.png" alt="a screenshot of a Word document with variables included"><figcaption>Docmosis syntax, wrap variables with &lt;&lt;angle brackets&gt;&gt;</figcaption></figure><p>This is the template, from which many documents will be rendered. To render a document, the templating engine is called with that template and a set of data to replace into the template, typically a JSON document, which may look like this:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>	<span>"title"</span>: <span>"Miss"</span>,
</span></span><span><span>	<span>"firstName"</span>: <span>"Victoria"</span>,
</span></span><span><span>	<span>"lastName"</span>: <span>"Barton"</span>,
</span></span><span><span>	<span>...</span>
</span></span><span><span>}
</span></span></code></pre></div><p>The result is either a Word or PDF document that may look like this:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/ec54bc168a015236b3d7f8d9e2a443db.png" alt="a screenshot of a Word document with the placeholders replaced by real values"></p><p>Another example, this time of an invoice:</p><figure><img src="https://blog.jreyesr.com/posts/typst/_resources/a53c6880bbaaa53456499ada778ef91e.png" alt="a screenshot of a Word invoice with variables included"><figcaption>Plumsail syntax, variables are wrapped in {{curly braces}}</figcaption></figure><p><img src="https://blog.jreyesr.com/posts/typst/_resources/92fa50cfddc4b9d3d23fe126765da56d.png" alt="a screenshot of a Word invoice with the placeholders replaced by real values"></p><p>Of course, all these templating engines aren’t just capable of replacing <code>&lt;&lt;var&gt;&gt;</code>, <code>[[var]]</code> or <code>{{var}}</code> placeholders (the exact syntax depends on the engine). They can also run loops to repeat elements. Some of them do it automatically, such as in the Plumsail invoice just above. Observe how the table has a single row in the template, which represents a single line item in the invoice. However, once rendered the row has four items, one for each of the elements in the <code>items</code> array. Other engines, such as Carbone, have explicit markers for the start and end of the loop.</p><p>They can also conditionally show or hide parts of the document, depending on conditions that are checked against the input data. Most of them can include images in the document, though for most of the listed projects the ability to do so is paid (and, in some, the entire engine is paid). Some even allow for conditional formatting (say, only bold some text if a certain condition is fulfilled).</p><h3 id="uses">Uses
<span><a href="#uses"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>Engines such as these are useful whenever you have an application that needs to generate PDF documents, e.g. invoices, certificates, or other documents that have a fixed skeleton but variable contents. For example, my bank can generate account statements that certify that person X with national ID document N has account M in the bank with a balance of between A and B. Somewhere in the bank’s applications is a templating engine. Our tax authority also generates PDF certificates whenever you submit a tax declaration, displaying the amount that you declared, any paid money, and the date. If you have an online course service (à la Coursera/edX/whatever), the PDF certificates of completion/passing are generated from a template. Most if not all e-commerce sites can generate PDF invoices. Our traffic department (called <a href="https://en.wikipedia.org/wiki/Department_of_motor_vehicles">DMV</a> in the US) generates PDFs that contain the date, time and license plate of your car for your annual car revision appointments, which you must present when taking the car there. SaaS applications may be interested in generating, say, a report of user accounts, each with its active/inactive status, time of last activity and granted privileges. My university, if I ask nicely and pay a certain amount of dobloons, will probably generate a transcript with the courses that I took and the grades that I got on each. There’s <a href="https://www.senescyt.gob.ec/">a government dependency</a> which validates all university-and-higher degrees, without which your title isn’t valid in Ecuador, and you can also check the degrees that a certain person has. They can generate, on demand, a PDF with a list of all said degrees. And so on.</p><p>Some of those applications (e.g. a bank that emits the account certificates, the DMV generating appointment PDFs, or a university that can generate course grade transcripts) have fixed templates, that just need to be filled with variable data. They can be thought of as having empty “slots” that should be filled by data to generate a complete document. For example, a bank account certificate may contain:</p><ul><li>The date the certificate was generated</li><li>A “certificate number”</li><li>A validity date, which when I generated one was 15 days after generation</li><li>A name to which the entire certificate, which is in the form of a letter, is addressed to</li><li>The name of the account holder who requested the certificate</li><li>The identity number of the account holder</li><li>A table with all the “financial products” that the account holder has on the bank (e.g. accounts), each with the product name (e.g. checking or savings account), the account number, opening date, and status (active/inactive)</li></ul><p>Of that data, some comes from the bank’s app database (e.g. the user’s name and ID number, which were collected when opening the online banking account, and the contents of the table with the user’s accounts), some comes from the web application and is collected when the report generation is commanded (namely, the name of whoever the certificate is addressed to), some comes from internal logic (the certificate number), some is a property of the universe at that time (the date of generation), and some could be computed just-in-time from other properties (the validity date, which is the generation date, plus 15 days).</p><p>For other use cases (e.g. an e-learning platform where people or organizations can submit courses, and other users can take them), the templates <em>themselves</em> aren’t part of the platform itself, but are instead part of the user-submitted data that the application manages. Much like course creators provide a course name, description and image when submitting a new course (along, of course, with the course’s actual content), they may also have the ability to control the appearance of the certificates that they emit. Not all e-learning platforms have this, presumably due to the difficulty of implementing it: Udemy <a href="https://business-support.udemy.com/hc/en-us/articles/4421577903383-How-to-Add-Your-Company-s-Logo-to-Certificates-of-Completion-for-Custom-Courses">only allows coursemakers to request that their organization’s logo be added to certificates</a>, while edX <a href="https://edx.readthedocs.io/projects/edx-installing-configuring-and-running/en/latest/configuration/enable_certificates.html#customize-certificate-templates-for-your-organization">only seems to support customization of the HTML templates that generate certificates</a> in the self-hosted Open edX platform (I couldn’t find any such information for course makers in the official edX site).</p><p>Same goes for e-commerce sites: the platform that implements the e-commerce stuff is usually separate from the products themselves that are sold there. The application is just “an e-commerce platform” that then a company deploys and fills with the things that they actually sell. If the “e-commerce platform” wants to provide the people that deploy it with a way to send customized PDF invoices on every order, then they need a way to render arbitrary user-submitted templates. Or consider Amazon, which (ignoring Amazon-sold products) is supposed to be just a channel between sellers and buyers. If Amazon allowed sellers to generate custom invoices (I couldn’t find any evidence that they do), they’d need a way for sellers to upload a template that would then be filled, by Amazon, with each purchase’s information; and mailed, by Amazon, to the purchaser. Same goes for PayPal, where payments can be made and invoices sent: they’ll always, as far as I could see, use <a href="https://www.paypal.com/us/invoice/invoice-template-generator">this same payment template</a>. In fact, that’s a really good example because it neatly highlights the variable fields (pointed to below by red arrows) and the fields that, while not static, can be computed from others (pointed to by green arrows):</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/ebf696a9e05b43b355405ee039996a2c.png" alt="a screenshot of PayPal&amp;rsquo;s invoice generator, showing many empty fields that must be filled to create an invoice"></p><h3 id="typsts-applicability">Typst’s applicability
<span><a href="#typsts-applicability"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>As we’ve seen, Typst is mainly intended to be used to generate static documents (i.e. ones where the source <code>.typ</code> file, plus any resources such as images that need to be displayed, will generate the same PDF every time). This is much in the spirit of LaTeX, where the source <code>.tex</code> file is the source of truth for the output PDF, another representation of the same content. The source files (<code>.typ</code> or <code>.tex</code>, respectively) would have been lovingly typed, character by character, by whoever is authoring the document.</p><p>However, Typst (and LaTeX too, for that matter, since it also embeds a programming language) can also be used to dynamically replace content into the document, thereby allowing them to be used to implement templates. These documents would be generated automatically, outside of anyone’s direct supervision, and embedded in automatic processes such as invoicing or reporting, where the first time that someone would see the document is when it’s already generated and sent to someone, such as via a monthly email or on every purchase.</p><h3 id="feeding-variable-data">Feeding variable data
<span><a href="#feeding-variable-data"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>The first need of templating engines is to have a way to pass variable data into the template, so it can be referred to. The way of doing so varies per engine, but it typically involves providing a JSON document that will then be accessible in the template, either directly or under a magic name. For example, <a href="https://carbone.io/documentation.html#substitutions">Carbone</a> exposes all the input data under the <code>d</code> variable:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/be3a43d4e5e8d266558e8027a67b868c.png" alt="Carbone&amp;rsquo;s way of referring to input data as d.X"></p><p>whereas <a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/how-it-works.html">Plumsail</a> puts each key of the input JSON document into the topmost context, much as if they were global variables:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/779326853cfd379f2317e93d5870aab4.png" alt="Plumsail&amp;rsquo;s way of referring to input data as plain variables"></p><p>In Typst, there are two (that I could see) main ways of passing data <em>into</em> the template. The first one would be to <a href="https://typst.app/docs/reference/data-loading/json/">read a file and parse it as JSON</a>, after which point the data will be available as a native Typst value, probably a <a href="https://typst.app/docs/reference/foundations/dictionary/">dictionary</a> or an <a href="https://typst.app/docs/reference/foundations/array/">array</a>:</p><pre tabindex="0"><code data-lang="typst">#let d = json("invoice_data.json")

= Invoice #sym.hash #d.number

/ Due date: #d.due_date
/ Bill to: #d.buyer_name (#link("mailto:" + d.buyer_email)[d.buyer_email])

TODO table here!
</code></pre><p>If we place a file named <code>invoice_data.json</code> right besides the <code>.typ</code> file and then run the Typst compiler, we get a PDF like this:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/b156b921fe5d556bc8bbbe18595e0149.png" alt="a screenshot of a PDF containing the header for an invoice"></p><p>In practice, a web application that wanted to use this approach would do something like this:</p><ol><li>The Typst template should already exist, either hardcoded as part of the application (if it’s controlled by the application’s developers and changes aren’t frequent, as happens for example with password reset emails, whose templates are typically included in the app’s code), provided by the application’s users (as in the case of e-learning with custom certificates) or read from some sort of object storage (which would allow changes to the template without the need to deploy a new version of the application)</li><li>When a PDF needs to be generated (say, a sale is made and an invoice should be sent, or the user of the banking application clicks the button to download his account certificate), the application copies the master template into a new, empty directory (probably on the system’s temp directory, e.g. <code>/tmp</code> on Linux)</li><li>The application prepares the data that should be rendered into the template, as a JSON-equivalent document, and saves it as a JSON-encoded file in the same directory</li><li>The application invokes the Typst compiler on that directory<ul><li>The easiest way is to shell out and call the <code>typst</code> command. This approach <a href="https://github.com/typst-community/typst.js/tree/main">is taken by the <code>typst.js</code> Javascript package</a> (<a href="https://github.com/typst-community/typst.js/blob/cebc5e31651d1f0c5180bf7320136d10de836bff/src/compile.ts#L44-L46">here</a> you can see how it dynamically builds the CLI arguments for Typst and then calls something equivalent to <code>typst compile --flag1 val1 --flag2 val2 input_file.typ</code>)</li><li>It’s also possible to call Typst directly from the programming language used, for some programming languages: Typst is <a href="https://crates.io/crates/typst">a Rust library</a>, and by depending on that crate it’s possible (from a Rust program) to call <a href="https://docs.rs/typst/0.11.1/typst/fn.compile.html">the top-level <code>compile</code> function</a>, which wraps the entire compilation process. There is also <a href="https://github.com/messense/typst-py">a Python package, <code>typst-py</code></a>, which embeds Rust code and thus includes Typst’s crate directly: <a href="https://github.com/messense/typst-py/blob/4492759b5a06f820a0c026852022275f25bc69c4/src/lib.rs#L193">here’s</a> the calls to Rust code, which is then wrapped and presented as a Pythonic library</li></ul></li><li>Whatever the approach, the result is either a new document written to the same directory (such as when using the Typst CLI) or a binary string that contains the PDF’s bytes (the Typst crate and Python library, for example, support that)</li><li>The new document can be served to the user, e.g. by returning it as a HTTP response <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Disposition">with the <code>Content-Disposition</code> header set to <code>inline</code></a>, which triggers the browser to display the image in the built-in PDF viewer, or to <code>attachment</code> to trigger the browser to download the PDF directly</li><li>Alternatively, the PDF can be sent via email, stored in object storage to be presented to the user later, or whatever else needs to be done</li></ol><p>The main idea is therefore to write templates assuming that there’s a magical JSON file that will always exist and have data <em>for the current rendering of the template</em>. It’s then the application’s responsibility to ensure that the template is always rendered with the proper data, hence the whole process of copying the template to a temp directory for each render. Otherwise, it wouldn’t be possible to render the same template multiple times simultaneously, since they all would try to point to the same JSON file</p><p>There’s an alternative, provided by Typst’s <a href="https://typst.app/docs/reference/foundations/sys/"><code>sys.inputs</code> dictionary</a>. This “makes external inputs available to the project”, and they’re provided on the CLI by using <code>--input key=value</code>, which will then be available on the template as <code>#sys.inputs.key</code>, of value <code>"value"</code> (always a string). For the use case of rendering templates, where it’s very likely that things more complex than a single string are required, <a href="https://typst.app/docs/reference/data-loading/json/#definitions-decode">the <code>json.decode</code> function</a> can be used to convert that string into a Typst dictionary, which can then be used just like the result of <code>json("path.json")</code>.</p><p>The advantage of this method is that it keeps data flow explicit and it’s purer (in <a href="https://wiki.haskell.org/Pure">the functional programming sense of the word</a>), whereas dropping the JSON data into a file and then having the Typst compiler read it relies on side-effects: one part of the program writes a file, later another part reads that same path, and they expect the same contents to be read from that path as were written there. This is why we had to have the temp directory and copy the template there. By contrast, using <code>sys.inputs</code> passes the data straight from the compiler to the Typst template. It also incurs in no I/O, which may be nice in certain situations and plays well with the stateless nature of containers (which, to be fair, could also use <code>/tmp</code>), since all the data is passed around in memory only.</p><pre tabindex="0"><code data-lang="typst">#let d = json.decode(sys.inputs.data)

// NOTE: Below is the same, d contains the same data as in the example above

= Invoice #sym.hash #d.number

/ Due date: #d.due_date
/ Bill to: #d.buyer_name (#link("mailto:" + d.buyer_email, d.buyer_email))

TODO table here!
</code></pre><p>This needs to be compiled like this (in Bash. Other shells may need a different syntax for quote escapement, since it’s necessary that the inner quotes, which are provided to Typst, are double quotes. JSON needs those):</p><div><pre tabindex="0"><code data-lang="bash"><span><span>typst compile --input data<span>=</span><span>'{"number": "INV01-2024-012345","due_date": "2024-09-30","buyer_name": "John Doe","buyer_email": "<a href="https://blog.jreyesr.com/cdn-cgi/l/email-protection" data-cfemail="056f616a60456268646c692b666a68">[email&nbsp;protected]</a>"}'</span>
</span></span></code></pre></div><p>Or, if using the Python library, where <code>sys.inputs</code> can be provided:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>import</span> json
</span></span><span><span><span>import</span> typst
</span></span><span><span>
</span></span><span><span><span># Read from DB, compose dynamically, or whatever</span>
</span></span><span><span>context <span>=</span> {
</span></span><span><span>  <span>"number"</span>: <span>"INV01-2024-012345"</span>,
</span></span><span><span>  <span>"due_date"</span>: <span>"2024-09-30"</span>,
</span></span><span><span>  <span>"buyer_name"</span>: <span>"John Doe"</span>,
</span></span><span><span>  <span>"buyer_email"</span>: <span>"<a href="https://blog.jreyesr.com/cdn-cgi/l/email-protection" data-cfemail="fc96989399bc9b919d9590d29f9391">[email&nbsp;protected]</a>"</span>,
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span># Rendr template into PDF</span>
</span></span><span><span>pdf_bytes <span>=</span> typst<span>.</span>compile(
</span></span><span><span>              <span>"template.typ"</span>, <span># Should refer to sys.inputs.data</span>
</span></span><span><span>              sys_inputs<span>=</span>{<span>"data"</span>: json<span>.</span>dumps(context)})
</span></span><span><span>
</span></span><span><span><span># Now pdf_bytes can be written to a file, sent via email, stored on object storage, or whatever</span>
</span></span></code></pre></div><p>This compiles into exactly the same PDF as in the example above, where we read the JSON document from a file in the filesystem.</p><p>Of course, since <code>sys.inputs</code> is a built-in feature of Typst, it can be used on <a href="https://docs.rs/typst/0.11.1/typst/foundations/sys/fn.module.html">the Rust crate</a> or any other bindings that use it (e.g. <a href="https://github.com/messense/typst-py/blob/4492759b5a06f820a0c026852022275f25bc69c4/python/typst/__init__.pyi#L108">Python’s binding</a>). In this way, applications can compile Typst documents without ever shelling out (to call the Typst CLI) or performing disk operations (to read the template and/or data files, nor to write out the PDF), purely in memory and as close as it’s possible to get to pure computation.</p><p>It’s unclear how much of Typst’s incremental compilation (yes, <a href="https://github.com/typst/comemo/">they do have incremental compilation</a>, which is useful to speed up PDF generation) would be used in such cases. Then again, how much is shared in the case of templates with variable data? When writing a paper, most of the time you’ll be recompiling documents that have almost the same content as the last time, usually with some more added. Therefore, a large portion of work (say, each paragraph that wasn’t touched. I’m uncertain on how Typst handles it) could be reused. Not so in document generation, where the changes happen all at once and across the entire document.</p><p>A possible middle point (between reading actual files from disk using <code>json("filename.json")</code> and using <code>sys.inputs</code> for direct-to-engine injection of values) would be, if using a library that supports it, to intercept file reads and, if they refer to files that end in <code>.json</code>, not to read them from disk but to return the template data. In such cases, it would be possible to provide “virtual files”, i.e. files that don’t actually exist, but to the template they do exist, and contain data (which is transparently switched on each invocation, but the template doesn’t need to know that).</p><p>For example, the Python library <a href="https://github.com/messense/typst-py/blob/4492759b5a06f820a0c026852022275f25bc69c4/src/world.rs#L317-L324">reads all files from disk</a> directly, whenever a file read is requested. However, it could, in theory, provide a hook for Python code to intercept the read request and decide how it wants to proceed. The code could decide to read an actual file from disk, or maybe just return some data directly, in the case of the template’s context. Such read-file hooks may also be useful to implement a level of sandboxing, since all reads requested by the template would go through developer-controlled code that could, for example, return a “file not found” error if a file that isn’t in a whitelist of approved files is read by the template. Typst itself isn’t that concerned with that<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, since it’s assumed that you’ll write and compile your own templates, and therefore no shenaniganry should be afoot. But in the context of a multi-user web application where people may upload templates, some more care may be necessary.</p><h3 id="variable-interpolation">Variable interpolation
<span><a href="#variable-interpolation"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>We’ve already seen the simple case of variable interpolation, i.e. taking something from the input data and “filling in” the template. This is normally done by <code>{{field}}</code> or <code>[[field]]</code> or something to the effect, a marker sequence that wraps the name of the field that should be read and replaced.</p><p>In Typst, since we have a variable (declared in scripting context) that holds the template’s data, we can just switch to scripting mode and print out the value, like this:</p><pre tabindex="0"><code data-lang="typst">// Assume that "data" contains the input data

Greetings, #data.first_name #data.last_name!

...
</code></pre><p>While on scripting mode, some more complex expressions that are based on the input data can be inserted in exactly the same way:</p><pre tabindex="0"><code data-lang="typst">To be paid to: #upper(data.name)

Details (#data.items.len() items)
</code></pre><p>We can call functions (e.g. <code>upper(somestring)</code>) or methods (e.g. <code>somearray.len()</code>), and those values can be inserted too. This may be useful to perform some lightweight calculations on the input data.</p><h3 id="conditionals-and-loops">Conditionals and loops
<span><a href="#conditionals-and-loops"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>Templates may need to conditionally show and/or hide content. An easy example would be to display “You’ve bought the following product” vs. “You’ve bought the following 4 products”, depending on whether a single product or several were bought.</p><p>Some of the projects that we’ve been comparing to Typst work by wrapping the content that should either appear or not in a special block, where the condition is specified. For example, <a href="https://docxtemplater.com/docs/tag-types/#conditions">DOCXTemplater does that</a>:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/327441f2e1dba5ee680caa688fd586c1.png" alt="a screenshot from DOCXTemplater docs showing that a section can be wrapped in a condition to either hide or show it"></p><p>whereas <a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/conditionally-hide-blocks.html#hide-arbitrary-block">Plumsail</a> uses a magical <code>hide-block-if</code> tag that, when found and true, causes its containing block (e.g. a table cell, which can have invisible borders) to disappear:</p><p><img src="https://plumsail.com/docs/documents/v1.x/_images/hide-arbitrary-block-template.webp" alt="an image from a Word document where a hidden table contains content that will disappear"></p><p>Typst <a href="https://typst.app/docs/reference/scripting/#conditionals">supports <code>if-else</code> blocks</a> natively, so it can already show or hide content:</p><pre tabindex="0"><code data-lang="typst">#let d = json("invoice_data.json")
#repr(d)

= Invoice #d.number

/ Bill to: #d.buyer_name #if(d.at("buyer_email", default: none) != none)[(#d.buyer_email)]
</code></pre><p>When we try to render a document with a <code>buyer_email</code>, the if block renders, as expected:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/60bd288819c6af7a2bbe0bd66b58d9ac.png" alt="a PDF document where a user&amp;rsquo;s email is displayed"></p><p>However, if we don’t have a <code>buyer_email</code> in <code>d</code>, then the key lookup <a href="https://typst.app/docs/reference/foundations/none/">returns the <code>none</code> value</a>, and the block isn’t displayed, and neither are its parentheses:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/cc2ea840f8bbb12b66f1d433d00c3071.png" alt="a PDF document where a user&amp;rsquo;s email is not displayed"></p><p>In general, it should always be possible to make Typst completely hide content, because <a href="https://typst.app/docs/reference/foundations/none/">of the existence of <code>none</code></a>. This is the equivalent of <code>null</code>/<code>nil</code>/<code>None</code> in other programming languages, and it represents, as usual, the absence of a value. However, in Typst this value has another use: if it is inserted into the document, it generates nothing, not even an empty space. As we’ve seen, scripting lines that shouldn’t generate output (e.g <code>let var = val</code>) <em>actually</em> output a <code>none</code>. Therefore, if at any point it is necessary to not output something, it’s always possible to emit a <code>none</code>. It’ll be safely non-printed on the document.</p><p>As for loops, some tools (e.g. <a href="https://carbone.io/documentation.html#repetitions">Carbone</a>) employ some sort of marker for the start and end of the loop. Carbone, as an example, uses the reserved variables <code>i</code> and <code>i+1</code>, much as you’d use if you were writing a classical <code>for</code> loop in C. Whenever a “repeatable section” (e.g. a bullet point, or a table’s row, or a paragraph) is found that mentions the <code>i</code> variable, it will be repeated until <code>i+1</code> is found:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/93c04537e12483073944d7aa96d471f2.png" alt="a screenshot of Carbone&amp;rsquo;s docs showing that a section (a title and a table) can be repeated"></p><p>As can be seen in the example above, it’s typically possible to perform nested repeats. Above we want to repeat sections of the document, one for each brand of car, where each brand has <em>itself</em> a table that is composed of repeated car models. For the top level, Carbone repeats everything between the <code>{d[i].brand}</code> and <code>{d[i+1].brand}</code> markers, and for the inner repeat, it uses <code>{d[i].models[i].size}</code> and <code>{d[i].models[i+1].size}</code> as endpoints.</p><p>There are other engines, e.g. <a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/loops-and-nesting.html">Plumsail</a>, where repetition is implicit (i.e. it has no start and end markers. Instead, it’s inferred when the template contains a reference to a key that is <em>inside</em> an array). For example, if you had the following data:</p><div><pre tabindex="0"><code data-lang="json"><span><span>[
</span></span><span><span>    {
</span></span><span><span>        <span>"firstName"</span>: <span>"Efren"</span>,
</span></span><span><span>        <span>"lastName"</span>: <span>"Gaskill"</span>
</span></span><span><span>    }, {
</span></span><span><span>        <span>"firstName"</span>: <span>"Sanly"</span>,
</span></span><span><span>        <span>"lastName"</span>: <span>"Keyme"</span>
</span></span><span><span>    }, {
</span></span><span><span>        <span>"firstName"</span>: <span>"Mark"</span>,
</span></span><span><span>        <span>"lastName"</span>: <span>"Nigma"</span>
</span></span><span><span>    }
</span></span><span><span>]
</span></span></code></pre></div><p>the following template, by referring to the properties <code>firstName</code> and <code>lastName</code>, which are properties of objects that are inside an array, trigger a repetition (in this case, of bullet points):</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/83832b13f91438bff63992d9bc73d018.png" alt="a Word template that expands into a series of bullet points, one per person"></p><p>The issue with this approach is that, since there is no end marker, there must be some rules as to what elements are “repeatable”. For example, in Plumsail only table rows, bullet lists (and numbered list) and chapters (sections, as defined by using one of the Heading styles) can be repeated.</p><blockquote><p>If you need to repeat some content that is not a table, bullet list or chapter, just create a single table cell with transparent borders and put content that you want to repeat inside.</p><p><a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/loops-and-nesting.html">https://plumsail.com/docs/documents/v1.x/document-generation/docx/loops-and-nesting.html</a></p></blockquote><p>In Typst, looping is achieved by generating an array of <code>content</code> elements (which can be anything, such as paragraphs, tables, table cells, images, or whatever. Everything that is output to the PDF is a <code>content</code> in Typst.) Arrays of <code>content</code> elements are displayed one after the other.</p><p>For example, if you wanted to write a set of bullet points, you’d write <a href="https://typst.app/docs/reference/scripting/#loops">a <code>for</code> loop</a> that generated one bullet point (which is internally represented by <a href="https://typst.app/docs/reference/model/list/#definitions-item">a call to <code>list.item(...)</code></a>) per item in the array:</p><div><pre tabindex="0"><code data-lang="json"><span><span>[
</span></span><span><span>    {
</span></span><span><span>        <span>"firstName"</span>: <span>"Efren"</span>,
</span></span><span><span>        <span>"lastName"</span>: <span>"Gaskill"</span>
</span></span><span><span>    }, {
</span></span><span><span>        <span>"firstName"</span>: <span>"Sanly"</span>,
</span></span><span><span>        <span>"lastName"</span>: <span>"Keyme"</span>
</span></span><span><span>    }, {
</span></span><span><span>        <span>"firstName"</span>: <span>"Mark"</span>,
</span></span><span><span>        <span>"lastName"</span>: <span>"Nigma"</span>
</span></span><span><span>    }
</span></span><span><span>]
</span></span></code></pre></div><pre tabindex="0"><code data-lang="typst">#let d = json("invoice_data.json")

#repr(d)

= List of customers (#d.len() total)

#for person in d [- #person.firstName #person.lastName]
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/7cfee14533216956f36528fadfd35e17.png" alt="a PDF document that shows a bullet list with three items, corresponding to the three elements of the input array"></p><p>A similar construct, albeit with more nested loops, can be used to repeat things that themselves have repetitions, such as sections where each section has a table where rows repeat:</p><div><pre tabindex="0"><code data-lang="json"><span><span>[
</span></span><span><span>  {
</span></span><span><span>    <span>"brand"</span>: <span>"Toyota"</span>,
</span></span><span><span>    <span>"models"</span>: [{ <span>"size"</span>: <span>"Prius 2"</span> }, { <span>"size"</span>: <span>"Prius 3"</span> }]
</span></span><span><span>  },
</span></span><span><span>  {
</span></span><span><span>    <span>"brand"</span>: <span>"Tesla"</span>,
</span></span><span><span>    <span>"models"</span>: [{ <span>"size"</span>: <span>"S"</span> }, { <span>"size"</span>: <span>"X"</span> }]
</span></span><span><span>  }
</span></span><span><span>]
</span></span></code></pre></div><pre tabindex="0"><code data-lang="typst">#let brands = json("invoice_data.json")

#repr(brands)

#for brand in brands {
  heading(level: 1, brand.brand)
  table(
    columns: (auto),
    table.header([*Models*]),
    ..brand.models.map(model =&gt; model.size)
  )
}
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/6361edf59fb5a0bec50df8261dc79ec5.png" alt="a PDF document with two sections, one for each car manufacturer, where each section contains a table with car models made by that manufacturer"></p><p>Here we use <a href="https://typst.app/docs/reference/foundations/array/#definitions-map">the <code>array.map()</code> function</a>. This function is “the map function”, one of the three of the holy triad <a href="https://dev.to/mlevkov/the-holy-trinity-map-filter-and-reduce-381e">in functional programming</a>: it’s invoked on an array (here, <code>brand.models</code>), it takes a function that describes how each element of the array should be transformed (here, we receive the entire model and pick out the <code>size</code> property, which happens to be the only one), and it returns another array, of the same size as the original one, where each element has been transformed as indicated by the provided function. We then <a href="https://typst.app/docs/reference/foundations/arguments/#spreading">spread</a> that array into the call to <code>table(...)</code>, so each model becomes a cell (and, since the table has only one column, each cell in turn becomes a separate row).</p><p>Of course, nothing prevents us from nesting <em>even more</em> loops inside them. Perhaps having bullet lists inside the cells that are inside the table that is inside the repeated sections. At that point, it probably makes sense to separate parts of the code (for example, the table) to a separate “component function”, which receives a single brand/manufacturer and renders that manufacturer’s table.</p><h3 id="formatting">Formatting
<span><a href="#formatting"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>All of the tools that we’ve been reviewing respect the formatting of the source document. In other words, if a certain template tag (e.g. <code>{{some_var}}</code>) is in a certain font, size or color, then when that tag gets replaced with its actual value, the value will also have that font, size or color. For example, observe the following Word template:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/8e7c9a19e8cb7e69ae29f5695b2a0a71.png" alt="a screenshot of a template for a list of beer ratings, where some placeholders are in large font and in other colors"></p><p>Once compiled, the user’s name and age are in large orange font, as expected, since they’re part of the title. Similarly, each beer’s name is bolded, and the brewery is italicized:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/b68f0c69810c5214ff6f5149f8c6af47.png" alt="a PDF document containing a user&amp;rsquo;s beer ratings, where the placeholders have been replaced by actual values, but the formatting of the placeholders has been preserved"></p><p>This is nice because formatting can be performed in the usual Word/WYSIWYG way, while editing the template, by selecting a bit of content and applying a format to it. Technically, what was styled isn’t actually <em>the content</em>, but rather <em>the placeholder for the content</em>, but all engines handle that properly.</p><p>Typst also works well with that, because interpolating content is a first-class citizen of the language (i.e. switching between markup mode and scripting mode is a normal thing to do in the middle of, for example, a heading or a bolded block). Formatting is therefore preserved:</p><pre tabindex="0"><code data-lang="typst">#let d = json("invoice_data.json")

#show emph: it =&gt; {
  text(red, it.body)
}

= Invoice #d.number

_ Hello, #d.buyer_name _
</code></pre><p>Here we place the invoice number within a level 1 heading, and the buyer’s name inside an italics block:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/4e103adbb101c71f55ddf92e34f33a9c.png" alt="a PDF document where a variable appears as part of a title and another variable appears inside an italicized red block"></p><p>We’ve switched italics so they render in red, so you can see that the <code>d.buyer_name</code> variable is also colored (as it should be, since it’s <em>inside</em> the underscores that mark the borders of the <code>emph</code> block).</p><p>Then there’s the issue of <em>conditional formatting</em>, such as coloring some table cells (those that indicate errors) in red, or perhaps specifying a color as a variable that comes in as template data (consider, for example, rendering reports in the user’s preferred color, perhaps as part of a B2B application where companies can provide their logo and company color).</p><p><a href="https://jsreport.net/learn/docx#docxstyle">In JSReport</a> that can be done by <a href="https://playground.jsreport.net/w/admin/Mc2Pdcyo">using the <code>docxStyle</code> tag</a>:</p><div><pre tabindex="0"><code data-lang="handlebars"><span><span><span>{{</span><span>#docxStyle</span> <span>textColor</span><span>=</span>user.theme.mainColor<span>}}{{</span>companyName<span>}}</span>'s Report<span>{{</span><span>/docxStyle</span><span>}}</span>
</span></span></code></pre></div><p>This can be rendered with the following JSON data:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>    <span>"user"</span>: {
</span></span><span><span>        <span>"theme"</span>: {
</span></span><span><span>            <span>"mainColor"</span>: <span>"green"</span>
</span></span><span><span>        }
</span></span><span><span>    },
</span></span><span><span>    <span>"companyName"</span>: <span>"ACME Co."</span>
</span></span><span><span>}
</span></span></code></pre></div><p><img src="https://blog.jreyesr.com/posts/typst/_resources/0cefe88ab964cb653fcf6b2ed113ee7e.png" alt="a screenshot of a Word template where the color of a heading has been changed based on context data"></p><p><a href="https://carbone.io/documentation.html#-color">Carbone</a> also has a <code>:color</code> formatter that, when applied to a paragraph, table cell or table row, can change either the element’s text or background color. For example, assume that the input JSON data has a key <code>error</code> with value <code>#FF0000</code>, the hexadecimal color for pure red. The following text will take that color and apply it to the entire paragraph where the tag appears:</p><pre tabindex="0"><code>The assessment did not passed {d.error:color(p)}
</code></pre><p><img src="https://blog.jreyesr.com/posts/typst/_resources/ecfa98d1dfbf0e2661dee226f7e367c3.png" alt="a screenshot from Carbone&amp;rsquo;s docs showing a paragraph whose text color has been changed to red, as indicated in the input JSON data"></p><p>This also works neatly to conditionally color table rows, since the <code>:color</code> formatter can alter the colors of the table row in which it appears. For example, below we have some sort of cybersecurity assessment report, where each failed test should be highlighted in red:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/e060c91f004e5586da05e123ecfd97a3.png" alt="a screenshot from Carbone&amp;rsquo;s docs showing how to render a table where some rows are colored in red"></p><p>Typst can also do that by directly using <a href="https://typst.app/docs/reference/text/text/">the <code>text(...)</code> function</a>, which “Customizes the look and layout of text in a variety of ways”. This function can receive <a href="https://typst.app/docs/reference/text/text/#parameters">many parameters</a>, and (at the end, or optionally after the call, in square brackets) a content element. This element will be displayed just as it would normally be, except that whatever parameters were provided to <code>text(...)</code> will be overridden. For example, consider the Typst document below:</p><pre tabindex="0"><code data-lang="typst">#let d = json("invoice_data.json")

#text(fill: rgb(d.user.theme.mainColor))[= #d.companyName's Invoice]
</code></pre><p>After the line that reads the data from a JSON file, we have a call of the form <code>text(fill: &lt;color&gt;)[= A heading]</code>. This is syntactic sugar for a call of the form <code>text(fill: &lt;color&gt;, &lt;content&gt;)</code>, where <code>&lt;color&gt;</code> is in turn a call to <code>rgb(d.user.theme.mainColor)</code> (which is itself a constructor of <a href="https://typst.app/docs/reference/visualize/color/">the <code>color</code> type</a>, a way of initializing a <code>color</code> value from a hexadecimal string), and <code>&lt;content&gt;</code> contains a level 1 heading, <code>= #d.companyName's Invoice</code>, which <em>in turn</em> interpolates a variable, <code>#d.companyName</code>. In this way, the entire document jumps three or four times between markup mode and scripting mode:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/f8969024f95008fd69c9144d66cf5e40.png" alt="a diagram showing how the Typst template above switches between markup and scripting mode as the template is parsed"></p><p>The example that controls the background of a table’s color is also possible, because <a href="https://typst.app/docs/reference/model/table/#definitions-cell">Typst allows for a cell’s properties, such as the background color, to be manually specified</a>:</p><pre tabindex="0"><code data-lang="typst">#let d = json("invoice_data.json")

#repr(d)

#let row(test) = {
  let fillColor = if test.result == "ok" {white} else {red}
  let textColor = if test.result == "ok" {black} else {white}
  let textWeight = if test.result == "ok" {"regular"} else {"semibold"}
  let cell(content) = table.cell(fill: fillColor, text(fill: textColor, weight: textWeight, content))
  
  (cell(test.name), cell(test.result))
}

#table(
  columns: (auto, 1fr),
  align: horizon,
  table.header(
    [*Test name*], [*Success*]
  ),
  ..for t in d.tests {
    row(t)
  }
)
</code></pre><p>In the document above, we create a <code>row(test)</code> function, which receives a dictionary with the keys <code>name</code> and <code>result</code>, and returns all the cells (two in this case) that would make up the row in the table that corresponds to that test. It uses the test’s <code>result</code> to decide whether that row should have black test on white background (in the case of passed tests, where <code>result = "ok"</code>), or white text on red background (otherwise, which are failed tests). The background color is applied to the <code>table.cell(...)</code> call, while the text color is applied to the <code>text(...)</code> call, not to <code>table.cell(...)</code>. As far as this last function is concerned, it just receives <em>some content</em>. The fact that this content happens to be colored text isn’t its business. This is useful because text color is controlled in just one place, in <code>text(...)</code> calls; there’s no separate “table cell text color” setting.</p><p><code>row(test)</code> returns an array of two cells. Since it’s called in a <code>for...in</code> loop, which is then <a href="https://typst.app/docs/reference/foundations/arguments/#spreading">spread</a> into the table call, it generates two cells per test (there are three tests in the sample JSON, so six cells in total, not counting the two heading cells).</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/19e54ad910ec6a9377145d646a2c864e.png" alt="a PDF document with a table that has three &amp;ldquo;tests&amp;rdquo;, one failed and two passed. The failed test&amp;rsquo;s row is colored red and the text is bolded"></p><p>This example also highlights a point where Typst seems more powerful than the other templating engines that we’ve been comparing it to: conditional formatting can be applied to any property, not just color. Notice how the text in the failed test in the table above is bolded, it hasn’t just had its text color changed to white. And the same thing could be done for the text’s font family, size or alignment. By contrast, in <a href="https://carbone.io/documentation.html#-color">Carbone</a> and <a href="https://jsreport.net/learn/docx#docxstyle">JSReport</a> (to take two examples), setting the color is a dedicated operation, with no equivalent operation for bolding, switching the font size, or other similar operations. In Typst, however, they’re all handled in exactly the same way: as arguments to the <code>text(...)</code> call.</p><h3 id="images">Images
<span><a href="#images"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>Inserting static images in a templated document (say, your company’s logo, if you’re generating invoices) is trivial: they can just be inserted in the template and they’ll appear on each output document.</p><p>Inserting <em>dynamic</em> images, on the other hand, is much more difficult. Say that you’re a university and want to generate student transcripts, and you want the student’s picture to appear in a corner of the document. Somewhere in a web application there’s a file for each student, which let’s imagine they had to submit when they enrolled, or that picture was taken when they were issued their university ID card. The issue is: how can that (variable per-user) picture be inserted in the template?</p><p>This is typically done (see <a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/pictures.html">Plumsail</a>, <a href="https://carbone.io/documentation.html#pictures">Carbone</a>, <a href="https://jsreport.net/learn/docx#docximage">JSReport</a>) by inserting a “placeholder image” in the template document, perhaps a blank image. Then, that <a href="https://support.microsoft.com/en-us/office/add-alternative-text-to-a-shape-picture-chart-smartart-graphic-or-other-object-44989b2a-903c-4d9a-b742-6a75b451c669">picture’s Alt Text</a> is used to provide the tag that indicates from where in the context the image data will be read:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/0e57ce9828061b7f8cebdb20713a4dad.png" alt="a diagram showing how an image with alt text is replaced by the image that lives at the URL indicated by that alt text"></p><p>Other tools (namely <a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/pictures.html#insert-picture-using-text-token">Plumsail</a>) can use pure text tags, without requiring the template to have a placeholder image:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/dac8bb0bc8c8e33537d3edfc375d1d7a.png" alt="a Word template containing a tag that will be replaced by a picture"></p><p>As for the actual <em>data</em> of the image, two options are commonly offered: either the variable that is mentioned in the alt text contains a URL:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>    <span>"publicUrl"</span>: <span>"https://plumsail.com/docs/documents/v1.x/_images/plumsail-logo.png"</span>
</span></span><span><span>}
</span></span></code></pre></div><p>or it contains the raw image data, encoded in Base64 so it can be transported on a JSON string:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>"imageData"</span>: <span>"data:image/jpeg;base64,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"</span>
</span></span><span><span>}
</span></span></code></pre></div><p>If a URL is provided, the templating engine fetches the image that lives at that URL internally while rendering the document. If a Base64 string is provided instead, it can be processed directly, since it contains the image’s pixels already.</p><p>In Typst, images (just like everything else) are content that is generated via function calls. Images are typically specified by a file path on disk, from where the Typst engine reads them, but it’s also possible to pass the raw image data, <a href="https://typst.app/docs/reference/visualize/image/#definitions-decode">by using the built-in <code>image.decode(...)</code> function</a>:</p><pre tabindex="0"><code data-lang="typst">#import "@preview/based:0.1.0": base64
#let d = json("invoice_data.json")
#let imgBytes = base64.decode(d.imageData.split(",").at(1))

#image.decode(imgBytes)
</code></pre><p>The input JSON, truncated, looks like this:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>"imageData"</span>: <span>"data:image/jpeg;base64,/9j/4AAQSkZJRgABAQABLAEsAAD/4QGERXhpZgAATU0AKgAAAAgACQEPAAIAAAAGAAAAegEQAAIAAAANAAAAgAESAAMAAAABAAEAAAEaAAUAAAABAAAAjgEbAAUAAAABAAAAlgEo..."</span>
</span></span><span><span>}
</span></span></code></pre></div><p>We need to first clean up the image data, because it starts with the <code>data:image/jpeg;base64,</code> preamble, which isn’t actually part of the data. This is only there because I copied this example directly from Carbone’s docs. If we were in control of the application that is generating the data, it would be possible to avoid generating that preamble.</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/901b49cd9242821525ddc90e6ef7fe5c.png" alt="a PDF document where a small France flag has been inserted into the document"></p><p>The issue with Typst is that <a href="https://github.com/typst/typst/discussions/1219">it isn’t possible, by design, to use web URLs for dynamic images</a>. This is because compilation of Typst documents is sandboxed <em>very tightly</em> to prevent anything from accessing “the outside world”. The Typst compiler itself can pierce the sandbox (as it does, for example, when loading images by path, when it reaches out to the local disk), but there’s no functionality to read files from URLs. And, based on <a href="https://github.com/typst/typst/issues/1056">this very long and detailed discussion</a>, there’s not much interest in adding so: adding that would, for example, expose anyone who receives Typst documents from other sources (e.g. editors in journals, reviewers) to very nasty attacks or data exfiltration. The recommended way is to have an external application (which, in the case of automatic document generation, would be whatever application wants to have the documents generated) predownload any files that are needed and place them next to the Typst source file. Or, as we discussed above in the case of reading JSON data from disk, it may be possible, if using the Rust crate or any other libraries that embed it, to intercept file reads so it’s not necessary to actually write the files to disk.</p><p>In fact, there’s <a href="https://typst.app/universe/package/prequery/">a package that helps with that, <code>prequery</code></a>:</p><blockquote><p>Typst compilations are sandboxed: it is not possible for Typst packages, or even just a Typst document itself, to access the “ouside world”. The only inputs that a Typst document can read are files within the compilation root, and strings given on the command line via <code>--input</code>. For example, if you want to embed an image from the internet in your document, you need to download the image using its URL, save the image in your Typst project, and then show that file using the <code>image()</code> function. Within your document, the image is not linked to its URL; that step was something <em>you</em> had to do, and have to do for every image you want to use from the internet.</p><p>This sandboxing of Typst has good reasons. Yet, it is often convenient to trade a bit of security for convenience by weakening it. Prequery helps with that by providing some simple scaffolding for supporting preprocessing of documents. The process is roughly like that:</p><ol><li>You start authoring a document without all the external data ready, but specify in the document which data you will need. (With an image for example, you’d use Prequery’s <code>image()</code> instead of the built-in one to specify not only the file path but also the URL.)</li><li>Using <code>typst query</code>, you extract a list of everything that’s necessary from the document. (For images, the command is given in <code>image()</code>’s documentation.)
. You run an external tool (a preprocessor) that is not subject to Typst’s sandboxing to gather all the data into the expected places. (There is a <em>not very well implemented</em> Python script for image download in the gallery. For now, treat it as an example and not part of this package’s feature set!)</li><li>Now that the external data is available, you compile the document.</li></ol></blockquote><p>It works like this:</p><pre tabindex="0"><code data-lang="typst">#import "@preview/prequery:0.1.0"

#prequery.image(
  "https://en.wikipedia.org/static/images/icons/wikipedia.png",
  "assets/wikipedia.png")
</code></pre><p>When the following command is run:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>typst query --input prequery-fallback<span>=</span>true --field value <span>\
</span></span></span><span><span><span></span>    main.typ <span>'&lt;web-resource&gt;'</span>
</span></span></code></pre></div><p>it outputs a JSON document like this:</p><div><pre tabindex="0"><code data-lang="json"><span><span>[{<span>"url"</span>: <span>"https://en.wikipedia.org/static/images/icons/wikipedia.png"</span>, <span>"path"</span>: <span>"assets/wikipedia.png"</span>}]
</span></span></code></pre></div><p>This JSON document is an array that contains one item per <code>prequery.image(...)</code> call that appears in the Typst document, and holds the <code>url</code> and <code>path</code> for each one. With this, an external tool can fetch the file that lives in <code>url</code>, then write it to the local path indicated in <code>path</code>. It can then run the render command for the Typst document (either <code>typst compile</code> directly by shelling out or, if using a library, whatever function call is used on that library to render a document).</p><p>By the way, the magical <code>typst query</code> command that generated the JSON file is <a href="https://typst.app/docs/reference/introspection/query/#command-line-queries">a built-in Typst utility</a>. The main idea is that, at any point in a Typst document, <a href="https://typst.app/docs/reference/introspection/metadata/">the <code>metadata(...)</code> function</a> can be called. This function generates no visible output in the document, but it registers a bit of data. What that data means is left to the user, Typst just records it as it appears. Then, the <code>typst query</code> CLI command (or, from within a Typst document itself, <a href="https://typst.app/docs/reference/introspection/query">the <code>query(...)</code> function</a>) can be used to ask for, for example, “all the <code>figure</code>s in the document”, or “the element with tag <code>ref1</code>” (as indicated by writing <code>&lt;fig1&gt;</code> somewhere in the Typst document). In this case, each image that is inserted with a URL, via <code>prequery.image(...)</code>, is tagged with <code>&lt;web-resource&gt;</code> (multiple elements can have the same tag, or in other words, tags aren’t necessarily unique identifiers of an element in the document). Therefore, when <code>typst query</code> is invoked with that tag as the selector, it fetches each instance of those images. Each image carries two pieces of metadata: a URL and a path, both of which were provided by the user. Those are output as a JSON document, which can be read by other systems.</p><p>In this way, Typst is kept pure and calm in its nice isolated side-effect-free world. Typst can assume that it’ll have whatever resources it needs whenever it needs them. The wrapper application handles that.</p><p>Furthermore, if using a library that bundles the Cargo library, it’s not necessary to run the <code>typst query</code> step in a shell either. For example, <a href="https://github.com/messense/typst-py">the Python library</a> (which, as we’ve seen, actually wraps the Rust library via inter-language calls) can <a href="https://github.com/messense/typst-py/blob/4492759b5a06f820a0c026852022275f25bc69c4/python/typst/__init__.pyi#L100-L122">run something equivalent to the <code>typst query</code> command directly</a>:</p><div><pre tabindex="0"><code data-lang="py"><span><span><span>import</span> json
</span></span><span><span>
</span></span><span><span><span>import</span> typst
</span></span><span><span>
</span></span><span><span>imgs <span>=</span> json<span>.</span>loads(
</span></span><span><span>  typst<span>.</span>query(
</span></span><span><span>    <span>"main.typ"</span>, 
</span></span><span><span>    selector<span>=</span><span>"&lt;web-resource&gt;"</span>, 
</span></span><span><span>    field<span>=</span><span>"value"</span>, 
</span></span><span><span>    sys_inputs<span>=</span>{<span>"prequery-fallback"</span>: <span>"true"</span>}))
</span></span><span><span>
</span></span><span><span><span># imgs will be something like: </span>
</span></span><span><span><span># [</span>
</span></span><span><span><span>#   {"url": "https://en.wikipedia.org/static/images/icons/wikipedia.png", "path": "assets/wikipedia.png"}</span>
</span></span><span><span><span># ]</span>
</span></span></code></pre></div><p>From there on, the application would be able to fetch the URLs in that list, save them to the requested directory, and then run the <code>typst.compile</code> function in the same package to generate the actual PDF.</p><p>Otherwise, if the language in which the application is written doesn’t embed the Cargo library directly, there’s always the option of shelling out and running the <code>typst</code> CLI manually.</p><p>To recap: when generating documents from templates, it may be necessary to insert images that vary per document, such as photos, profile pictures, charts, logos, or even QR codes that are tied to the document. In Typst, this can be done by passing the image data as Base64 strings in the input JSON document. These strings can be read directly by a sibling of the <code>image</code> function that is used normally to insert static images that are read from disk, except that now, since the actual image data is passed to the template, it can vary per render.</p><p>If the images are instead provided as (public, non-authenticated) URLs, then Typst doesn’t support downloading them as part of the render process, by design, since rendering is supposed to be a sandboxed, self-contained process that involves as little from the external world as possible. However, there’s <a href="https://typst.app/universe/package/prequery">the <code>prequery</code> package</a>, whose main example usecase is precisely to download images from URLs. It works by adding a pre-processing step in which <code>typst query</code> is run, which collects all the appearances of Web-hosted images and outputs a JSON document which contains the URL from which each image should be downloaded, and the path in which the downloaded file should be placed. An external system (here, whichever application needs a PDF rendered) should parse that JSON document, download the URLs, place them in the appropriate locations, and then re-render the Typst document, at which point it’ll pick up the (now local) images and render them as normal.</p><h3 id="charts">Charts
<span><a href="#charts"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h3><p>To round up the feature recap, let’s look at charts. Statistical charts, to be precise, such as bar plots or pie charts.</p><p>Word <a href="https://support.microsoft.com/en-us/office/add-a-chart-to-your-document-in-word-ff48e3eb-5e04-4368-a39e-20df7c798932">supports charts</a>, which are internally implemented as embedded Excel documents <em>inside</em> the Word document. Therefore, the raw data that feeds a chart is an Excel sheet. The rendering engine is also shared, or at least looks the same.</p><p>Templating engines support charts via several methods. <a href="https://docxtemplater.com/modules/chart/">DOCXTemplater</a>, for example, detects a chart if the title of the chart or a paragraph just before it mentions the chart’s data, starting with a dollar sign:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/1d437aa744d96c6956b6fd8b8cda476c.png" alt="a Word template chart which is preceded by a paragraph with a special tag"></p><p>Since that is a bar chart, it has “categories” (each clump of bars) and “series” (each color of bar), each combination of which has a “value” (which determines the width of that clump+color combination). This is passed as part of the JSON context:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>	  <span>"chart2"</span>: {
</span></span><span><span>        <span>"categories"</span>: [<span>"5th Qtr"</span>, <span>"6th Qtr"</span>, <span>"7th Qtr"</span>, <span>"8th Qtr"</span>],
</span></span><span><span>        <span>"series"</span>: [{ <span>"data"</span>: [<span>130</span>, <span>20</span>, <span>40</span>, <span>10</span>] }],
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>This renders into a four-category, single-series (hence single-color) plot:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/5ba4f05b49a9071e4e210a16243fb6f7.png" alt="a Word chart with four bars"></p><p>Therefore, the only connection between the input data (in JSON form) and the chart is the <code>{$chart}</code> tag that should appear near the chart.</p><p>Other tools, such as <a href="https://plumsail.com/docs/documents/v1.x/document-generation/docx/charts.html">Plumsail</a> or <a href="https://carbone.io/documentation.html#native-charts">Carbone</a>, prefer to make the relationship between input (JSON) data and chart (Excel) data explicit. They allow you to edit the internal XLSX file, in the same way as if you were manually inserting data for the chart. Inside that Excel file, it’s possible to use the same template tags, loops and whatever else the templater can use, so the Excel file will also be filled dynamically. Observe the image below, and notice how the Excel file that feeds the chart has been filled with a loop (this is Carbone, hence the two rows with <code>{d.temps[i]}</code> and <code>d.temps[i+1]</code>, which acts as the end marker):</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/83e8dbd30eef2375a9073c01c9f3f0aa.png" alt="a Word document with an embedded chart being edited, showing the Excel editor that appears when doing so"></p><p>This is rendered as normal with a JSON context that looks like this:</p><div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>"temps"</span>: [
</span></span><span><span>    {
</span></span><span><span>      <span>"date"</span>: <span>"01/07/2022"</span>,
</span></span><span><span>      <span>"min"</span>: <span>13</span>,
</span></span><span><span>      <span>"max"</span>: <span>28</span>,
</span></span><span><span>      <span>"avg"</span>: <span>20.5</span>
</span></span><span><span>    },
</span></span><span><span>    <span>...</span>
</span></span><span><span>  ]
</span></span><span><span>}
</span></span></code></pre></div><p>This generates the following PDF, as expected:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/9e263c7345742dd503e06982984f4c28.png" alt="a PDF document with a line chart of minimum, maximum and average temperatures"></p><p>In effect, these tools extend the templating abilities of the tool into embedded Excel documents too. When a chart is encountered, its backing Excel sheet is also templated, just as if it were part of the main document. This generates a filled sheet. This newly-generated data is then used to render the chart.</p><p>In Typst, charts could be generated <a href="https://github.com/cetz-package/cetz-plot">with <code>cetz-plot</code></a>, a library that adds statistical plots to <code>cetz</code>, Typst’s equivalent to TikZ in LaTeX. This library, which is still very new, supports bar, column and pie charts (no scatter plots or line charts yet)</p><p><img src="https://github.com/cetz-package/cetz-plot/raw/master/gallery/line.png" alt="a XY plot of three functions, with colored regions"></p><p><img src="https://github.com/cetz-package/cetz-plot/raw/master/gallery/piechart.png" alt="a pie chart"></p><p>There’s also <a href="https://github.com/Pegacraft/typst-plotting"><code>typst-plotting</code></a>, which <a href="https://github.com/Pegacraft/typst-plotting/blob/master/example/Plotting.pdf">can draw</a> scatter, line, histogram, pie and bar charts, plus some more exotic chart types such as radar charts and box-and-whiskers:</p><p><img src="https://github.com/Pegacraft/typst-plotting/raw/master/images/graph.png" alt="two line plots, one where points are joined with straight lines, and another where they&amp;rsquo;re joined with curves"></p><p><img src="https://github.com/Pegacraft/typst-plotting/raw/master/images/bar.png" alt="a bar chart with five colored horizontal bars, one for each working day of the week"></p><p>And <a href="https://typst.app/universe/package/neoplot"><code>neoplot</code></a>, which provides a way to embed <a href="http://www.gnuplot.info/">Gnuplot</a> (which, despite its name, is <em>not</em> related to the GNU project), a very robust plotting framework used, among others, by <a href="https://octave.org/">GNU Octave</a>, the open-source alternative (not necessarily replacement, though) to Matlab. Gnuplot is more aimed at function plotting (i.e. 2D <code>y=f(x)</code> and 3D <code>z=f(x, y)</code> functions), so it can be used in that case. It can, however, also be used for stats charts (which I know because Octave can render them, so Gnuplot must be able to).</p><p>There’s also <a href="https://typst.app/universe/package/nulite/"><code>nulite</code></a>, which embeds <a href="https://vega.github.io/vega-lite/">Vega-Lite</a>. Vega-Lite is a language, based on JSON, that can specify the data and the visualization, in a similar manner to <a href="https://plotly.com/javascript/reference/index/">Plotly’s JSON syntax</a>. Since <code>nulite</code> is mostly a pass-through to Vega-Lite, it follows that it can render whatever Vega-Lite supports, <a href="https://vega.github.io/vega-lite/examples/#single-view-plots">which is a lot</a>.</p><p><code>nulite</code> uses <a href="https://typst.app/universe/package/ctxjs/">the <code>ctxjs</code> package</a> under the hood. This is “A Typst plugin to evaluate javascript code”. It can load JS modules directly on Typst and run them. <code>nulite</code> uses it because Vega-Lite is developed and distributed as a JS library, which is then brought into Typst’s plugin environment. In particular, <code>ctxjs</code> is a Rust plugin that uses <a href="https://github.com/DelSkayn/rquickjs">the <code>rquickjs</code> Rust bindings</a> to <a href="https://bellard.org/quickjs/">the QuickJS Javascript engine</a>, which is what actually interprets and runs the JS code. This is an alternative implementation of a Javascript interpreter, different to that used by browsers (for example, Chromium uses <a href="https://v8.dev/">V8</a>, Firefox uses <a href="https://spidermonkey.dev/">SpiderMonkey</a>, Safari uses… something?) and server/other environments (for example, Node.js, Electron and Deno all use V8). They’re all supposed to perform the same tasks (take in Javascript files, text files, and run them performing whatever steps the files contain) in the same way (which is defined in the <a href="https://tc39.github.io/ecma262/">ECMAScript specification</a> and its <a href="https://github.com/tc39/test262">accompanying Conformance Test Suite</a>, which “covers every observable behavior specified in the ECMA-414 Standards Suite”)</p><p>Thus, <code>nulite</code>, via <code>ctxjs</code>, via <code>rquickjs</code>, via QuickJS, embeds an actual Javascript interpreter. This interpreter is then used to load and run the (unmodified, as far as I can see) Vega-Lite visualization library. All of this is done out of view of the user of <code>nulite</code>. The user just feeds JSON documents (AKA Vega-Lite specs) that are used by Vega-Lite to lay out and render a chart, such as a bar chart or scatter plot. The result of this call to Vega-Lite is <a href="https://vega.github.io/vega/">a Vega spec</a>, another JSON document that is fed to Vega, a related project that actually generates the visualizations (in this sense, Vega-Lite is just a higher-level library that abstracts away the chore of specifying each aspect of the charts, using sensible defaults, and <a href="https://vega.github.io/vega-lite/usage/compile.html">hides the lower-level Vega (sans -Lite) syntax</a>). Vega (which is also included and run in the QuickJS Javascript interpreter that is bundled with <code>nulite</code>) <a href="https://vega.github.io/vega/docs/api/view/#view_toSVG">renders the chart to SVG</a>, which Typst <a href="https://typst.app/docs/reference/visualize/image/#parameters-format">natively supports</a>, and is included into the document just as if it were imported from disk.</p><p>As you can see, even in Typst’s fairly early stage of life, there’s already several packages for rendering charts, including at least two (<code>neoplot</code>, which calls Gnuplot; and <code>nulite</code>, which embeds Vega) that make use of very robust, external plotting libraries, thus giving Typst very mature plotting capabilities. In other words, Typst already has, through those libraries, charts comparable to those of Matplotlib or Octave, in terms of capabilities and aesthetics. In fact, it could be argued that, just by having Gnuplot or Vega available, Typst is <em>already</em> better than Word, which is not a dedicated statistical plotting program. Word charts are nice and useful and all, but still… Compare this:</p><figure><img src="https://blog.jreyesr.com/posts/typst/_resources/1ec71f45aa3f279386244b9e228a8403.png" alt="a stacked 3D bar chart generated in Excel"><figcaption>An Excel chart</figcaption></figure><p>with this:</p><figure><img src="https://blog.jreyesr.com/posts/typst/_resources/visualization.png" alt="a horizontal stacked bar chart generated in Vega"><figcaption>A Vega chart</figcaption></figure><p>(Okay, I’m intentionally using one of the worst Excel visualization types, a 3D bar chart. You get the point, though)</p><p>Let’s replicate <a href="https://docxtemplater.com/modules/chart/#viewport">an example from DOCXTemplater</a> in Typst, using <code>nulite</code>, which uses Vega. As a reminder, the original chart (made in Word) looks like this:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/6ddf35089e54e2b0571479b0932da760.png" alt="a bar chart in a Word document with four horizontal bars"></p><p>The Typst document is as follows:</p><pre tabindex="0"><code data-lang="typst">#import "@preview/nulite:0.1.0" as nulite
#let d = json("invoice_data.json")

#repr(d)

#nulite.render(
  width: 50%,
  height: 20%,
  zoom: 1,
  (
    data: (values: d),
    mark: "bar",
    encoding: (
      x: (field: "val", type: "quantitative"),
      y: (field: "qtr", type: "nominal"),
    )
  )
)
</code></pre><p>This is rendered with the following JSON data:</p><div><pre tabindex="0"><code data-lang="json"><span><span>[
</span></span><span><span>  {<span>"qtr"</span>: <span>"5th Qtr"</span>, <span>"val"</span>: <span>130</span>},
</span></span><span><span>  {<span>"qtr"</span>: <span>"6th Qtr"</span>, <span>"val"</span>: <span>20</span>},
</span></span><span><span>  {<span>"qtr"</span>: <span>"7th Qtr"</span>, <span>"val"</span>: <span>40</span>},
</span></span><span><span>  {<span>"qtr"</span>: <span>"8th Qtr"</span>, <span>"val"</span>: <span>10</span>}
</span></span><span><span>]
</span></span></code></pre></div><p>and generates the following PDF:</p><p><img src="https://blog.jreyesr.com/posts/typst/_resources/5f3ea6e42ba5bfd86e66e60c85cd84b4.png" alt="a PDF document with a bar chart generated with Vega"></p><p>Of course, anything that is possible with Vega should also possible here, absent any weird bugs in the QuickJS interpreter or the magical bundling into a Typst plugin.</p><p>To recap: Word templating engines (e.g. Carbone, Plumsail, DOCXTemplater, and so) typically offer a way to render those statistical charts that can be inserted natively in Word (that is, not image, but actual charts that are backed by an actual Excel spreadsheet that is embedded in the Word document). This is sometimes done by extending the templating logic of the engine (e.g. the fact that writing <code>{{some_var}}</code> or something to that effect looks up <code>some_var</code> in the JSON context and inserts its value at that point, or a way to perform loops) into Excel too, such that it’s possible to use data that is passed via the JSON context (say, an array of records, each with a label and a number) to “fill up” the Excel sheet that will then render, say, a pie chart. In this way, rendered documents can include charts whose values change with each render, according to the JSON context passed to each render.</p><p>Typst doesn’t support that natively (it’s a typesetting system, after all, not a plotting library), but there are plenty of packages already that do so. For example, <code>cetz-plot</code> is a part of CetZ, Typst’s <em>de facto</em> standard graphing library, which supports several types of charts. There are some more independent graphing libraries. There’s also <code>neoplot</code>, which leverages Gnuplot, a third-party, very mature graphing library (also used, among other things, in GNU Octave). And finally (and my personal favorite), there’s <code>nulite</code>, which allows the use of Vega and Vega-Lite specs to render very configurable and fairly modern-looking charts, of <a href="https://vega.github.io/vega-lite/examples/">all sorts of different types</a>. Charts are typically inserted as SVG documents, vector images, not PNG or JPEG raster images, which is nice when zooming in.</p><h2 id="conclusions">Conclusions
<span><a href="#conclusions"><svg viewBox="0 0 28 23" height="100%" width="19" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71" fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2"></path></svg></a></span></h2><p>In this (very long) article, we’ve reviewed Typst, a very young (at least when compared to LaTeX and Word) typesetting system that is similar in spirit and intended usage to LaTeX. It was conceived by two German academics, and its main audience is academia, where papers are written, containing Sections, an Abstract, several authors, each with his own affiliation, Figure 1s, Equation 2s, and IEEE citations.</p><p>The name Typst is applied to both the <em>compiler</em> (i.e. an application that takes in a Typst file and generates a PDF document) and to the <em>language</em> itself (i.e. the syntax that should be obeyed in those files that will be passed to the compiler). Typst is also a web application, similar to Overleaf and other online collaborative LaTeX editors, which has paid plans. The compiler and the language, however, <a href="https://github.com/typst/typst?tab=Apache-2.0-1-ov-file#readme">are all properly open sourced</a> (<a href="https://www.latex-project.org/publications/2011-FMi-TUB-tb100mittbach-lppl-history.pdf">like LaTeX</a>), so hopefully there’s no drama lurking there.</p><p>Like LaTeX and Markdown, and unlike Word, Typst’s source documents are plain text that can be read and edited in any ultra-basic text editor. Also unlike Word, to see the modifications you need to recompile the source document and generate the output PDF, i.e. you don’t edit the preview of the document, as is done in Word, where selecting a word and bolding it instantly changes <em>the same word</em> that was selected. Typst’s compilation times are supposed to be faster than LaTeX’s (I’ve seen on the order of tens of <em>milli</em>seconds when rerendering a document where not much has changed), and it has incremental compilation (i.e. it can reuse parts of the previous compilation, maybe things like entirely skipping a paragraph if it hasn’t changed since the previous time). Typst can therefore provide a live preview of changes (i.e. you type and the PDF at the side changes in near-real-time), which LaTeX tools like Overleaf don<a href="https://www.reddit.com/r/LaTeX/comments/17dw2r4/is_there_latex_editor_that_compilesrenders_as_you/">’t typically support</a>, because it may be slightly not-fast-enough.</p><p>Typst’s syntax is, at least in the common cases, fairly more lightweight than that of LaTeX. The syntax overhead for common cases (i.e. the amount of characters that must be used to mark common formatting constructs such as headings or bold letters) is on par with Markdown (e.g. <code>= Title</code> for titles, <code>*bold*</code> for bolding, as opposed to <code>\section{Title}</code> and <code>\textbf{bold}</code> respectively).</p><p>Typst, like LaTeX, embeds a “scripting engine” (equivalent to LaTeX’s macros), which can be interleaved with the actual content (called <em>markup</em>) and is able to generate content itself. For example, a script can insert the content of a variable (which has been declared beforehand in script-land) into the document. Or it can use a loop to generate a set of bullet points or table rows, such that it’s not necessary to type them all out by hand, or several representations of the same data can always be kept up-to-date.</p><p>Then, we explored the applicability of Typst to the job of generating, not hand-written papers, but instead machine-generated documents (e.g. invoices, reports, certificates, and such) where <em>a template</em> is hand-designed and provided with placeholders, and then that template is repeatedly <em>rendered</em> with different data in each invocation. These are normally driven from a larger application: e.g. an e-learning site may wish to issue certificates of course completion to students, normally subject to the payment of a modically exorbitant sum of galactic credits. Or a bank that offers a button where account holders can generate and download a letter that certifies, To Whom It May Concern, that person Such-And-Such has account #Something open in this bank.</p><p>An alternative for generating such automated documents can be found in Word-based templating engines, such as Carbone, Plumsail, DOCXTemplater, JSReport, Docmosis and Templater. These use a normal Word document, filled with magical syntax, as the template. The advantage of such systems is that everyone (who uses Windows, that is) will most likely already have the template editor installed (it’s Word, after all), and that, at least for simple cases such as replacing a variable (e.g. “Dear X Y”), the template looks very similar to the documents that it will generate. For more complex constructs, such as paragraphs that should only be shown when a certain condition is true, things may get weirder (some engines, for example, require that you wrap the paragraph in question in a single-row, single-column table with invisible borders, so it can be hidden or shown as a block).</p><p>Typst, since it has a scripting engine, is also capable of expressing the conditions that typical templating engines use. Inserting a variable value into the document is done by just switching to scripting mode and inserting that variable. Loops (such as repeating bullet points, table rows, figures or entire sections) are also possible. Conditional display of content (i.e. content that appears and disappears depending on some condition) is possible since Typst has the concept of a “null” value, actually the absence of a value, that can be used at any point and generates no output. Therefore, it’s possible to make content appear or disappear by switching in either the actual content or the null value. Finally, since content can also be styled (e.g. the text color can be set) and all Typst syntax ultimately resolves to function calls (e.g. the title <code>== Heading</code> is internally interpreted as a function call similar to <code>heading(level: 2, "Heading")</code>), it’s possible to dynamically style content by using the raw function calls instead of the syntactic sugar and using the appropriate styling parameters, which can now be controlled by the input values for <em>this particular</em> rendering of the template.</p><p>Dynamic images can also be inserted by passing them as Base-64 encoded strings, which can then be interpreted by Typst just as if they had just been read from disk, which is “the normal” way of using images when writing papers. Word templating engines also tend to support this. In Typst, however, it’s not possible, by design, to use a URL as the source for an image, since Typst wants to treat compilation as an isolated, sandboxed process. There are some workarounds for it that involve a pre-processing step where an external system (which, in the case of automated document generation, could very well be the external application that is driving the process) retrieves information about which URLs are mentioned in the document, then downloads them and places them on local files, and then the Typst document can be rendered as normal, reading the images from disk as necessary.</p><p>Finally, Word templating engines also tend to support Word’s native charts, which are backed by an internal Excel sheet. This is usually done by allowing said Excel sheet to be templated like the Word document, thereby allowing variable data to be inserted into the sheet, which then causes the chart to change (e.g. bar lengths change, pie sections are added and their angles change, scatter points are added, and so on). In Typst, charts can be added via several packages. Some internally use CetZ, which is used to render arbitrary graphics, in terms of basic graphical elements such as lines, arrows, points, rectangles, circles and polygons. At least one package delegates the chart generation to Gnuplot, which receives commands in <a href="https://lwn.net/Articles/628537/">its own special language</a>. And another embeds and delegates to Vega, a Javascript library that is used to generate plots, one of Javascript’s equivalents to Python’s Matplotlib or Seaborn (another fairly common one is Plotly). By using Vega, Typst inherits all kinds of charts, which can be rendered from a JSON document, which Typst handles just fine.</p><p>In conclusion, we’ve seen how Typst can be used as a general-purpose document typesetting system, in the same areas as LaTeX (i.e. academic papers and such), and also in other areas. In particular, we reviewed the case of automatically generating documents from templates, in which the structure is fixed (more or less, since pieces may be repeated, or appear and disappear) but the content changes per document (such as reports or certificates that must be emitted with different content each time, but keeping the same style and general structure). We saw how, combining Typst’s basic markup constructs (e.g. titles, lists, images, tables) with Typst’s scripting engine (which adds the ability to read data as part of the document render, insert that data into the document as-is, or use the data to control the rendering of the document, such as repeating a table row for each item in an array), it’s possible to write Typst documents that change themselves based on input data. This is all done without any reliance on text templating systems such as those typically used to generate HTML in server-side frameworks (e.g. Handlebars or Mustache, or Jinja or Django’s templates, or Go’s templating language, or Twig). Instead of such text-replacement systems, which don’t take into account the specific syntax of the file that is being templated (i.e. if we used one of those systems here, it wouldn’t be aware of Typst’s syntax and could therefore introduce nonsensical syntax), we use Typst’s native facilities to keep all processing Typst-aware. Things that aren’t available in Typst proper, such as charting, can be handled (and, indeed, have been handled already!) by plugins that, thanks to WebAssembly, can have some very powerful abilities, up to and including embedding an entire Javascript interpreter in which third-party Javascript libraries, that know nothing about the Typst project, can be loaded and used.</p><p>Overall, Typst seems like a very nice project. It’s a joy to work with, and very powerful if you want it to. The scripting system can be made to work in fairly advanced ways, it’s not just a gimmick. Since it’s very new, it can get inspiration from all sorts of modern ideas (observe: functions as first-class values, lambda expressions, a modern syntax for the language, Markdown’s lightweight markup syntax, JSON as an interchange format, WebAssembly for plugins, a first-class web application, which also causes an insistence on live reloading). If you’re in academia or in any other environment (if there are any) where LaTeX is popular, consider giving Typst a whirl.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Secure Custom Fields by WordPress.org (157 pts)]]></title>
            <link>https://wordpress.org/plugins/advanced-custom-fields/</link>
            <guid>41821336</guid>
            <pubDate>Sat, 12 Oct 2024 18:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.org/plugins/advanced-custom-fields/">https://wordpress.org/plugins/advanced-custom-fields/</a>, See on <a href="https://news.ycombinator.com/item?id=41821336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<div id="tab-description">
	
	<p>Secure Custom Fields (SCF) turns WordPress sites into a fully-fledged content management system by giving you all the tools to do more with your data.</p>
<p>Use the SCF plugin to take full control of your WordPress edit screens, custom field data, and more.</p>
<p><strong>Add fields on demand.</strong><br>
The SCF field builder allows you to quickly and easily add fields to WP edit screens with only the click of a few buttons! Whether it’s something simple like adding an “author” field to a book review post, or something more complex like the structured data needs of an ecommerce site or marketplace, SCF makes adding fields to your content model easy.</p>
<p><strong>Add them anywhere.</strong><br>
Fields can be added all over WordPress including posts, pages, users, taxonomy terms, media, comments and even custom options pages! It couldn’t be simpler to bring structure to the WordPress content creation experience.</p>
<p><strong>Show them everywhere.</strong><br>
Load and display your custom field values in any theme template file with our hassle-free, developer friendly functions! Whether you need to display a single value or generate content based on a more complex query, the out-of-the-box functions of SCF make templating a dream for developers of all levels of experience.</p>
<p><strong>Any Content, Fast.</strong><br>
Turning WordPress into a true content management system is not just about custom fields. Creating new custom post types and taxonomies is an essential part of building custom WordPress sites. Registering post types and taxonomies is now possible right in the SCF UI, speeding up the content modeling workflow without the need to touch code or use another plugin.</p>
<p><strong>Simply beautiful and intentionally accessible.</strong><br>
For content creators and those tasked with data entry, the field user experience is as intuitive as they could desire while fitting neatly into the native WordPress experience. Accessibility standards are regularly reviewed and applied, ensuring SCF is able to empower as close to anyone as possible.</p>
<p><strong>Documentation and developer guides.</strong><br>
Over 10 plus years of vibrant community contribution alongside an ongoing commitment to clear documentation means that you’ll be able to find the guidance you need to build what you want.</p>
<h4>Features</h4>
<ul>
<li>Simple &amp; Intuitive</li>
<li>Powerful Functions</li>
<li>Over 30 Field Types</li>
<li>Extensive Documentation</li>
<li>Millions of Users</li>
</ul></div>

<div id="screenshots">
	
	<ul><li><figure><a href="https://ps.w.org/advanced-custom-fields/assets/screenshot-1.jpg?rev=3167679" rel="nofollow"><img decoding="async" src="https://ps.w.org/advanced-custom-fields/assets/screenshot-1.jpg?rev=3167679" alt=""></a><figcaption><p>Simple &amp; Intuitive</p></figcaption></figure></li><li><figure><a href="https://ps.w.org/advanced-custom-fields/assets/screenshot-2.jpg?rev=3167679" rel="nofollow"><img decoding="async" src="https://ps.w.org/advanced-custom-fields/assets/screenshot-2.jpg?rev=3167679" alt=""></a><figcaption><p>Made for Developers</p></figcaption></figure></li><li><figure><a href="https://ps.w.org/advanced-custom-fields/assets/screenshot-3.jpg?rev=3167679" rel="nofollow"><img decoding="async" src="https://ps.w.org/advanced-custom-fields/assets/screenshot-3.jpg?rev=3167679" alt=""></a><figcaption><p>All About Fields</p></figcaption></figure></li><li><figure><a href="https://ps.w.org/advanced-custom-fields/assets/screenshot-4.jpg?rev=3167679" rel="nofollow"><img decoding="async" src="https://ps.w.org/advanced-custom-fields/assets/screenshot-4.jpg?rev=3167679" alt=""></a><figcaption><p>Registering Custom Post Types</p></figcaption></figure></li><li><figure><a href="https://ps.w.org/advanced-custom-fields/assets/screenshot-5.jpg?rev=3167679" rel="nofollow"><img decoding="async" src="https://ps.w.org/advanced-custom-fields/assets/screenshot-5.jpg?rev=3167679" alt=""></a><figcaption><p>Registering Taxonomies</p></figcaption></figure></li></ul></div>

<div id="tab-reviews">
	
	<div>
							<article>
					<p><img alt="" src="https://secure.gravatar.com/avatar/bf074d0d7a71c0804bf72d675dcc9bee?s=60&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/bf074d0d7a71c0804bf72d675dcc9bee?s=120&amp;d=retro&amp;r=g 2x" height="60" width="60">					</p><div>
						<header>
							
							
						</header>
						<p>So many powerful things possible because of ACF.</p>
					</div>
				</article>
							<article>
					<p><img alt="" src="https://secure.gravatar.com/avatar/c680a8dc5e64c81ef2cc0834ba949f9d?s=60&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/c680a8dc5e64c81ef2cc0834ba949f9d?s=120&amp;d=retro&amp;r=g 2x" height="60" width="60">					</p><div>
						<header>
							
							
						</header>
						<p>I probably would use a different framework if it wasn’t for ACF.  Also make sure you download ACF from the creator’s site because they can’t update here at the moment.</p>
					</div>
				</article>
							<article>
					<p><img alt="" src="https://secure.gravatar.com/avatar/9edd84d4340307ac77da98e902a9f4c2?s=60&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/9edd84d4340307ac77da98e902a9f4c2?s=120&amp;d=retro&amp;r=g 2x" height="60" width="60">					</p><div>
						<header>
							
							
						</header>
						<p>ACF has always been the best choice (IMHO) for custom fields in WordPress. After WP Engine acquired ACF, it’s gotten even better! Thanks to their developers, the GUI has been vastly improved and you can now create custom post types in ACF. I look forward to a future with the WP Engine team in it!</p>
					</div>
				</article>
							<article>
					<p><img alt="" src="https://secure.gravatar.com/avatar/87c9bb3486d7280acfda3815409a474a?s=60&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/87c9bb3486d7280acfda3815409a474a?s=120&amp;d=retro&amp;r=g 2x" height="60" width="60">					</p><div>
						<header>
							
							
						</header>
						<p>Great plugin for demanding custom fields. Everything that good developer needs!</p>
					</div>
				</article>
							<article>
					<p><img alt="" src="https://secure.gravatar.com/avatar/337d759f095e1f31f874b553bffe3942?s=60&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/337d759f095e1f31f874b553bffe3942?s=120&amp;d=retro&amp;r=g 2x" height="60" width="60">					</p><div>
						<header>
							
							
						</header>
						<p>I used to write little custom plugins to create custom post types, custom taxonomies, and custom meta data for them. This simplifies the process with a rock solid easy to use interface that drastically reduces the time need to build anything out.



It does everything, is easily transportable between projects, &amp; repeatable. Like butter!</p>
					</div>
				</article>
							<article>
					<p><img alt="" src="https://secure.gravatar.com/avatar/8e826a449b099c9960502c9c1bde7fee?s=60&amp;d=retro&amp;r=g" srcset="https://secure.gravatar.com/avatar/8e826a449b099c9960502c9c1bde7fee?s=120&amp;d=retro&amp;r=g 2x" height="60" width="60">					</p><div>
						<header>
							
							
						</header>
						<p>Advanced Custom Fields speeds up the development time of complex projects. Rather than spending countless hours coding custom functionality, we leverage ACF to get the job done in half the time. As long as it can be imagined, it can be accomplished using ACF.</p>
					</div>
				</article>
					</div>

		<p><a href="https://wordpress.org/support/plugin/advanced-custom-fields/reviews/">
			Read all 1,224 reviews		</a></p></div>

<div id="tab-developers"><p>“Secure Custom Fields” is open source software. The following people have contributed to this plugin.</p><p><span>Contributors</span></p>

		</div>

<div id="tab-changelog">
	
	<h4>6.3.6.2</h4>
<p><em>Release Date 12th October 2024</em></p>
<ul>
<li>Security – Harden fix in 6.3.6.1 to cover $_REQUEST as well.</li>
<li>Fork – Change name of plugin to Secure Custom Fields.</li>
</ul>
<h4>6.3.6.1</h4>
<p><em>Release Date 7th October 2024</em></p>
<ul>
<li>Security – ACF defined Post Type and Taxonomy metabox callbacks no longer have access to $_POST data. (Thanks to the Automattic Security Team for the disclosure)</li>
</ul></div>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Machine learning and information theory concepts towards an AI Mathematician (103 pts)]]></title>
            <link>https://arxiv.org/abs/2403.04571</link>
            <guid>41821179</guid>
            <pubDate>Sat, 12 Oct 2024 18:18:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2403.04571">https://arxiv.org/abs/2403.04571</a>, See on <a href="https://news.ycombinator.com/item?id=41821179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2403.04571">View PDF</a>
    <a href="https://arxiv.org/html/2403.04571v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The current state-of-the-art in artificial intelligence is impressive, especially in terms of mastery of language, but not so much in terms of mathematical reasoning. What could be missing? Can we learn something useful about that gap from how the brains of mathematicians go about their craft? This essay builds on the idea that current deep learning mostly succeeds at system 1 abilities -- which correspond to our intuition and habitual behaviors -- but still lacks something important regarding system 2 abilities -- which include reasoning and robust uncertainty estimation. It takes an information-theoretical posture to ask questions about what constitutes an interesting mathematical statement, which could guide future work in crafting an AI mathematician. The focus is not on proving a given theorem but on discovering new and interesting conjectures. The central hypothesis is that a desirable body of theorems better summarizes the set of all provable statements, for example by having a small description length while at the same time being close (in terms of number of derivation steps) to many provable statements.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Nikolay Malkin [<a href="https://arxiv.org/show-email/d15ad36d/2403.04571">view email</a>]      <br>    <strong>[v1]</strong>
        Thu, 7 Mar 2024 15:12:06 UTC (33 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starship Flight 5 license issued by FAA (248 pts)]]></title>
            <link>https://drs.faa.gov/browse/excelExternalWindow/DRSDOCID173891218620231102140506.0001?modalOpened=true</link>
            <guid>41820785</guid>
            <pubDate>Sat, 12 Oct 2024 17:23:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drs.faa.gov/browse/excelExternalWindow/DRSDOCID173891218620231102140506.0001?modalOpened=true">https://drs.faa.gov/browse/excelExternalWindow/DRSDOCID173891218620231102140506.0001?modalOpened=true</a>, See on <a href="https://news.ycombinator.com/item?id=41820785">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Germany's 49-euro ticket resulted in significant modal shift from road to rail (657 pts)]]></title>
            <link>https://www.mcc-berlin.net/en/news/information/information-detail/article/49-euro-ticket-resulted-in-significant-modal-shift-from-road-to-rail.html</link>
            <guid>41819481</guid>
            <pubDate>Sat, 12 Oct 2024 14:47:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mcc-berlin.net/en/news/information/information-detail/article/49-euro-ticket-resulted-in-significant-modal-shift-from-road-to-rail.html">https://www.mcc-berlin.net/en/news/information/information-detail/article/49-euro-ticket-resulted-in-significant-modal-shift-from-road-to-rail.html</a>, See on <a href="https://news.ycombinator.com/item?id=41819481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>
                            MCC analysis for the Ariadne energy transition project shows 30 percent more rail journeys. The announced increase in price to 58 euros per month undoes half of this.
                        </p><div><p><a href="https://www.mcc-berlin.net/fileadmin/_processed_/0/8/csm_241008_Hauptbahnhof_K%C3%B6ln_2474346251_Shutterstock-Dimitrios_1000_36b46f6c07.jpg" data-fancybox="" data-caption="Cologne Central Station"><img title="Cologne Central Station" src="https://www.mcc-berlin.net/fileadmin/_processed_/0/8/csm_241008_Hauptbahnhof_K%C3%B6ln_2474346251_Shutterstock-Dimitrios_1000_4b66de10e5.jpg" width="880" height="600" alt=""></a></p><p>Cologne Central Station: tThanks to the 49-euro ticket, there are significantly more train journeys and much lower CO<sub>2</sub> emissions.
                                                    
                                                        | Photo: Shutterstock/Dimitrios
                                                    
                                                    </p></div><p>
                            08.10.2024
                        </p><div><p>The state-subsidised 49-euro ”Deutschland-Ticket”, which allows you to travel by local and regional bus and rail throughout Germany for a month, has led to a significant shift in traffic from road to rail. This has now been determined by a research team from the Berlin-based climate research institute MCC (Mercator Research Institute on Global Commons and Climate Change) for the <a href="https://www.mcc-berlin.net/en/news/information/information-detail/article/shaping-the-energy-transition-together-kopernikus-project-ariadne-launched.html" target="_blank">Ariadne</a> energy transition project funded by the Federal Ministry of Education and Research. With regard to the future modal split, the announced price increase to 58 euros per month is highly counterproductive. Detailed results can be viewed interactively on a web-based German-language ”Ariadne D-Ticket Impact Tracker”.</p><p>The research team looked at the first 12 months since the introduction of the Deutschland-Ticket on 1 May 2023. It statistically evaluated mobile phone and car movement data for Germany, as well as data from a control group of eight other European countries. This allowed the team to determine the causal effect of the Deutschland-Ticket on peoples’s mobility behaviour for the first time.</p><p>According to the study, the Deutschland-Ticket increased the number of train journeys of more than 30 kilometres by 30.4 percent compared to what would have been the case without the measure. By contrast, personal transport was noticeably more moderate across all distances, with 7.6 percent fewer kilometres travelled by car. Because the Deutschland-Ticket did not change the total number of trips across all transport modes – including bike, plane, car and train – this means that the share of train journeys (“modal split”) rose from around 10 percent to 12 percent. This saved around 6.7 million tonnes of CO<sub>2</sub> emissions, corresponding to 4.7 percent of total transport emissions in Germany.</p><p>Based on their empirical analyses, the researchers also predict how the announced price increase will change people’s mobility behaviour, and thus emissions. At a special meeting on 23 September 2024, the transport ministers of the German federal states decided to increase the price of the Deutschland-Ticket from 49 to 58 euros per month. The research team concludes that train journeys may decrease by 14 percent as a result of the price increase, and that kilometres travelled by car may increase by 3.5 percent. This means that the price hike could almost halve the reduction in emissions achieved with the 49-euro ticket in its first year.</p><p>The statistical impact analysis, including changes in mobility patterns, differences between districts, and the extent of emission reductions, can be viewed in the interactive German-language Ariadne D-Ticket Impact Tracker.</p><p><strong>Go to the D-Ticket Impact Tracker:</strong><br><a href="https://mcc-berlin-ariadne.shinyapps.io/dticket-tracker/" target="_blank" rel="noreferrer">https://mcc-berlin-ariadne.shinyapps.io/dticket-tracker/</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The phone ban has had a big impact on school work (182 pts)]]></title>
            <link>https://icelandmonitor.mbl.is/news/news/2024/10/09/the_phone_ban_has_had_a_big_impact_on_school_work/</link>
            <guid>41819442</guid>
            <pubDate>Sat, 12 Oct 2024 14:43:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://icelandmonitor.mbl.is/news/news/2024/10/09/the_phone_ban_has_had_a_big_impact_on_school_work/">https://icelandmonitor.mbl.is/news/news/2024/10/09/the_phone_ban_has_had_a_big_impact_on_school_work/</a>, See on <a href="https://news.ycombinator.com/item?id=41819442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><a href="https://c.arvakur.is/frimg/1/52/4/1520426.jpg" id="a1520426" target="_blank" title="Valdimar Víðisson, the headmaster of Öldutúnsskóli says that the phoneban has been well received, both by students and their parents." rel="newsimgs"><img src="https://c.arvakur.is/frimg/1/52/4/1520426.jpg" alt="Valdimar Víðisson, the headmaster of Öldutúnsskóli says that the phoneban …" width="730" height="486"></a>
    </p>
      <p>
        Valdimar Víðisson, the headmaster of Öldutúnsskóli says that the phoneban has been well received, both by students and their parents.
          <span>Composite image</span>
      </p>
  </div><div>
        
  
    

        
          <p>
 A phone ban has been in place at Öldutún School since the beginning of 2019, and according to the principal, it has worked well. The school's atmosphere and culture have changed for the better, and there is more peace in the classroom.
</p>

        
          <p>
 However, the headmaster Valdimar Víðisson says that it has not been separately studied whether the phone ban has had a positive effect on literacy and interest in reading. Still, Öldutúnsskóli has scored considerably above average regarding interest in reading.
</p>

        
          

        
          <p>
 "We haven't connected it to the phones directly, but it would be interesting to look at it separately." However, we see this in an improved school culture, and cyberbullying has decreased significantly during school hours with this measure and is now hardly existent."
</p>

        
          <h3>
 More screen time reduces interest
</h3>

        
          <p>
 It has been reported in Morgunblaðið that students who spend more time on smartphones are less interested in reading than those who use their phones little or not at all.
</p>

        
          <p>
 The interest in reading is waning faster and faster as students spend more time on their smart devices.
</p>

        
          <p>
 These are the results of research by Kristján Ketill Stefánsson, assistant professor of pedagogy at the University of Iceland's Faculty of Education. The research is based on data from more than fifteen thousand students in grades 6 to 10 in 120 elementary schools across the country.
</p>

        
          <p>
 Everything seems to indicate that more screen time reduces children's interest in reading.
</p>

        
          <h3>
 The ban was prepared for a whole year
</h3>

        
          <p>
 Stefánsson does not necessarily think it is wise to encourage a general ban on mobile phones in schools, but rather implement some kind of phone “holiday”.
</p>

        
          <p>
 Öldutúnsskóli has, however, taken the route of completely banning the use of phones during school hours. The phone ban is in place in all year groups of the school, from 1st to 10th grade, and the headmaster says he is not about to drop it.
</p>

        
          <p>
 Víðisson says he realizes that phones can be a safety device and that children use them, for example, after the school day ends to reach their parents. "The phone is therefore not prohibited in the building, but its use is not allowed during school hours," he explains.
</p>

        
          <p>
 Both students and parents have welcomed the phone ban, as it was prepared for a whole year in collaboration with the board of the student association, school council and parents, according to Víðisson.
</p>

        
          
  
  

  



        
          <p>
 "We did a lot of things in return, for example, we opened a new space for the teenagers that they designed, so there was no dissatisfaction with this at the time and it has not arisen. People just know that using phones is not allowed, and if the kids are sneaking to use the phone and an employee is nearby, they are very quick to react and know that this is not allowed."
</p>

        
          <h3>
 Phones may not be taken from students
</h3>

        
          <p>
 When asked if phones are taken from students if they don't follow the rules, he says they haven't done so as the school doesn't have the authority to do so.
</p>

        
          <p>
 "However, we have the authority to request that the phone be left at home and that the parents make sure that it does not come to school. But in general, the same applies to violations of telephone rules and violations of other rules. It depends on a certain process, after a certain time there is a meeting with the parents and so on," he says.
</p>

        
          <p>
 "If this is a problem for a child, it has been worked with parents, and in some cases phones have had to be left at home for a while and something like that."
</p>

        
          <h3>
 Spend much less time on the phone
</h3>

        
          <p>
 Stefánsson’s study results also revealed that the majority of children in the top three grades of primary school spend an hour a day or more on smartphones during school hours. There are even examples of children spending up to three hours a day on the phone during school hours.
</p>

        
          <p>
 The headmaster says that in Skólapúlsinn (research portal for schools) it is clearly stated that the children in Öldutúnsskóli, and other schools where the phone ban is in place, spend much less time on the phone than their peers, or less than 30 minutes a day. In Skólapúlsinn, the children themselves answer questions about school work, well-being, activity in studies, and more, and the information is collected without revealing personal information.
</p>

        
          <p>
 "This has fixed and improved the atmosphere at our school and there is much better work peace during lessons. The kids know what the rules are, if they are using the phone, there are certain penalties for that, so it has become part of their culture that the phone is not a teaching tool."
</p>

        
          <p>
 The kids talk more and the teenagers use the new space to play table tennis, pool, and more, listen to music, and play chess.
</p>

    

  

  

      </div></div>]]></description>
        </item>
    </channel>
</rss>