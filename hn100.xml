<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 25 May 2024 02:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Spot – Simple, cross-platform, reactive desktop GUI toolkit for Go (129 pts)]]></title>
            <link>https://github.com/roblillack/spot</link>
            <guid>40469592</guid>
            <pubDate>Fri, 24 May 2024 19:19:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/roblillack/spot">https://github.com/roblillack/spot</a>, See on <a href="https://news.ycombinator.com/item?id=40469592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/roblillack/spot/blob/main/resources/2024-05-13-demo-video.gif"><img src="https://github.com/roblillack/spot/raw/main/resources/2024-05-13-demo-video.gif" width="50%" height="50%" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Spot</h2><a id="user-content-spot" aria-label="Permalink: Spot" href="#spot"></a></p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/roblillack/spot" rel="nofollow"><img src="https://camo.githubusercontent.com/70e8dd7078dc2d09f7058a74f24a866773920c82925f6cb45402920c4e770829/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f726f626c696c6c61636b2f73706f742e737667" alt="Go Reference" data-canonical-src="https://pkg.go.dev/badge/github.com/roblillack/spot.svg"></a>
<a href="https://goreportcard.com/report/github.com/roblillack/spot" rel="nofollow"><img src="https://camo.githubusercontent.com/45ab88ab7352fae584dc4ff3808407d5b9333a11c524d602d13879175e82b3dd/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f726f626c696c6c61636b2f73706f74" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/roblillack/spot"></a></p>
<p dir="auto">Spot is a simple, cross-platform, reactive GUI toolkit for Go using native
widgets where available. It is designed to be easy to use and to provide a
consistent API across different platforms.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example</h2><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;

	&quot;github.com/roblillack/spot&quot;
	&quot;github.com/roblillack/spot/ui&quot;
)

func main() {
	ui.Init()

	spot.MountFn(func(ctx *spot.RenderContext) spot.Component {
		counter, setCounter := spot.UseState[int](ctx, 0)

		buttonTitle := &quot;Click me!&quot;
		if counter > 0 {
			buttonTitle = fmt.Sprintf(&quot;Clicked %d times!&quot;, counter)
		}

		return &amp;ui.Window{
			Title:  &quot;Hello World!&quot;,
			Width:  200,
			Height: 125,
			Children: []spot.Component{
				&amp;ui.Button{
					X: 25, Y: 50, Width: 150, Height: 25,
					Title: buttonTitle,
					OnClick: func() {
						setCounter(counter + 1)
					},
				},
			},
		}
	})

	ui.Run()
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>

	<span>"github.com/roblillack/spot"</span>
	<span>"github.com/roblillack/spot/ui"</span>
)

<span>func</span> <span>main</span>() {
	<span>ui</span>.<span>Init</span>()

	<span>spot</span>.<span>MountFn</span>(<span>func</span>(<span>ctx</span> <span>*</span>spot.<span>RenderContext</span>) spot.<span>Component</span> {
		<span>counter</span>, <span>setCounter</span> <span>:=</span> <span>spot</span>.<span>UseState</span>[<span>int</span>](<span>ctx</span>, <span>0</span>)

		<span>buttonTitle</span> <span>:=</span> <span>"Click me!"</span>
		<span>if</span> <span>counter</span> <span>&gt;</span> <span>0</span> {
			<span>buttonTitle</span> <span>=</span> <span>fmt</span>.<span>Sprintf</span>(<span>"Clicked %d times!"</span>, <span>counter</span>)
		}

		<span>return</span> <span>&amp;</span>ui.<span>Window</span>{
			<span>Title</span>:  <span>"Hello World!"</span>,
			<span>Width</span>:  <span>200</span>,
			<span>Height</span>: <span>125</span>,
			<span>Children</span>: []spot.<span>Component</span>{
				<span>&amp;</span>ui.<span>Button</span>{
					<span>X</span>: <span>25</span>, <span>Y</span>: <span>50</span>, <span>Width</span>: <span>150</span>, <span>Height</span>: <span>25</span>,
					<span>Title</span>: <span>buttonTitle</span>,
					<span>OnClick</span>: <span>func</span>() {
						<span>setCounter</span>(<span>counter</span> <span>+</span> <span>1</span>)
					},
				},
			},
		}
	})

	<span>ui</span>.<span>Run</span>()
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Simple</strong>: You can add Spot as a simple dependency to your project and start
building your UI right away. No need to use additional tools or code
generation steps. Just write Go code and get a native GUI application as a
self-contained binary.</li>
<li><strong>Cross-platform</strong>: Spot uses native widgets where available and
automatically selects the best backend for the platform you are running on
at compile time. Currently, two backend implementations are provided: one
based on <a href="https://fltk.org/" rel="nofollow">FLTK</a> using
<a href="https://github.com/pwiecz/go-fltk">go-fltk</a> and one based on Cocoa using
(<a href="https://github.com/roblillack/gocoa">a modified version of</a>)
<a href="https://github.com/mojbro/gocoa">gocoa</a>.</li>
<li><strong>Reactive</strong>: Spot automatically updates the UI when the state of the
application changes. You just provide side-effect free rendering functions
and manage the state of your application using the <a href="https://pkg.go.dev/github.com/roblillack/spot#UseState" rel="nofollow"><code>UseState</code></a> hook.</li>
<li><strong>Broad widget support</strong>: Spot provides a wide range of UI controls out of
the box, including buttons, labels, text inputs, sliders, dropdowns, and
more. See the full list:
<a href="#list-of-supported-ui-controls">List of supported UI controls</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQs</h2><a id="user-content-faqs" aria-label="Permalink: FAQs" href="#faqs"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">What does "reactive" mean?</h4><a id="user-content-what-does-reactive-mean" aria-label="Permalink: What does &quot;reactive&quot; mean?" href="#what-does-reactive-mean"></a></p>
<p dir="auto">In the context of Spot, <em>reactive</em> means that the UI is automatically updated
when the state of the application changes. This is achieved by re-building an
immutable component tree upon state changes which can quickly be compared to
the previous state in order to determine what UI controls need to be updated.
In the web world, this idea is often called a "virtual DOM" and Spot actually
started as an experiment to bring this concept to Go by implementing a
React-like GUI library for the desktop.</p>
<p dir="auto">By using a reactive model, the developer does not need to worry about updating
the UI manually. Instead, the developer can focus on the application logic and
let Spot take care of updating the UI.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">What are the "native widgets" that Spot uses?</h4><a id="user-content-what-are-the-native-widgets-that-spot-uses" aria-label="Permalink: What are the &quot;native widgets&quot; that Spot uses?" href="#what-are-the-native-widgets-that-spot-uses"></a></p>
<p dir="auto">Currently, Spot uses a Cocoa backend on macOS and a FLTK-based one on all other
platforms. Optionally, FLTK can be used on the Mac, too. Better support for
Windows is planned for the future.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I implement my own hooks?</h4><a id="user-content-can-i-implement-my-own-hooks" aria-label="Permalink: Can I implement my own hooks?" href="#can-i-implement-my-own-hooks"></a></p>
<p dir="auto">Yes, just like in React, you can implement your own hooks. Just create a
function which takes a <code>*spot.RenderContext</code> as first argument and use this to
"hook" into the Spot lifecycle by calling <code>spot.UseState</code>, <code>spot.UseEffect</code>,
etc. Convention here is to prefix the function with <code>Use…</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How do I write custom components?</h4><a id="user-content-how-do-i-write-custom-components" aria-label="Permalink: How do I write custom components?" href="#how-do-i-write-custom-components"></a></p>
<p dir="auto">There are a few different ways to separate your UI into components in Spot;
for some ideas, check out the <code>custom-components</code> example. The main way to
write custom components is to create a struct that implements the
<code>spot.Component</code> interface. This interface has a single method,
<code>Render(ctx *spot.RenderContext) spot.Component</code>, which is called to render
the component. Components created like this can be used in the same way as
the built-in ones.</p>
<p dir="auto">Look at the <code>BlinkingButton</code> component in the example to see how this is done.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I use Spot with a completely different widget library than the provided one?</h4><a id="user-content-can-i-use-spot-with-a-completely-different-widget-library-than-the-provided-one" aria-label="Permalink: Can I use Spot with a completely different widget library than the provided one?" href="#can-i-use-spot-with-a-completely-different-widget-library-than-the-provided-one"></a></p>
<p dir="auto">Yes, you can. You just need to create some structs that implement the
<code>spot.Component</code> interface and which take care of managing the native widgets.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Can I use <code>spot/ui</code>, but with a different backend than Cocoa or FLTK?</h4><a id="user-content-can-i-use-spotui-but-with-a-different-backend-than-cocoa-or-fltk" aria-label="Permalink: Can I use spot/ui, but with a different backend than Cocoa or FLTK?" href="#can-i-use-spotui-but-with-a-different-backend-than-cocoa-or-fltk"></a></p>
<p dir="auto">Currently, these are the only backends that are supported. But feel free to
create a PR if you want to add support for another backend. <em>*hint hint*</em></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">What's the difference between <code>spot/ui</code> and <code>spot</code>?</h4><a id="user-content-whats-the-difference-between-spotui-and-spot" aria-label="Permalink: What's the difference between spot/ui and spot?" href="#whats-the-difference-between-spotui-and-spot"></a></p>
<p dir="auto"><code>spot</code> is the core package that provides the reactive model and the rendering
functionality. It is backend-agnostic and can be used with any set of controls
which implement the <code>spot.Control</code> interface.</p>
<p dir="auto"><code>spot/ui</code> is a package that provides a set of pre-built cross-platform GUI
controls that which can be used with <code>spot</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">What's the difference between a “component” and a “control”?</h4><a id="user-content-whats-the-difference-between-a-component-and-a-control" aria-label="Permalink: What's the difference between a “component” and a “control”?" href="#whats-the-difference-between-a-component-and-a-control"></a></p>
<p dir="auto">In Spot, a <em>component</em> is a logical unit of the application that contains
business logic and state. Any component is made out of other componens and
can ultimately be rendered down to a single or multiple "controls".</p>
<p dir="auto">A <em>control</em> is special kind component is mounted to the UI tree and represents
a visual element on the screen. Usually a control is backed by a native
implementation of the GUI backend, like a button, a label, or a text input.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">What do the terms ”make”, “render”, “build”, “mount”, and “update” mean in the context of Spot?</h4><a id="user-content-what-do-the-terms-make-render-build-mount-and-update-mean-in-the-context-of-spot" aria-label="Permalink: What do the terms ”make”, “render”, “build”, “mount”, and “update” mean in the context of Spot?" href="#what-do-the-terms-make-render-build-mount-and-update-mean-in-the-context-of-spot"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><em>Make</em>: The process of creating a new component instance. This is done by
creating a reference to an instance of a struct that implements the
<code>spot.Component</code> interface or by calling <code>spot.Make</code> with a render function.</p>
</li>
<li>
<p dir="auto"><em>Render</em>: The process of applying a component's state to its building blocks
and hereby returning another component instance. This is done by calling the
<code>Render</code> method on a component instance.</p>
</li>
<li>
<p dir="auto"><em>Build</em>: The process of creating a new UI tree from a component instance.
This is done by <em>recursively</em> rendering a component to create a tree of
controls. This can be done by calling <code>spot.Build</code> with a component instance
or <code>spot.BuildFn</code> with a render function.</p>
</li>
<li>
<p dir="auto"><em>Mount</em>: The process of creating real UI controls from a (virtual) tree of
controls. This is done by calling <code>Mount</code> on a tree node or <code>spot.Mount</code> with
a component instance or <code>spot.MountFn</code> with a render function.</p>
</li>
<li>
<p dir="auto"><em>Update</em>: The process of updating a tree of (mounted) controls. This is done
by calling <code>Update</code> on a tree node.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features, Spot does not have right now</h2><a id="user-content-features-spot-does-not-have-right-now" aria-label="Permalink: Features, Spot does not have right now" href="#features-spot-does-not-have-right-now"></a></p>
<ul dir="auto">
<li>Automatic layouting</li>
<li>Multiple windows</li>
<li>Modal dialogs</li>
<li>Resizable windows</li>
<li>Menu bars</li>
<li>Custom widgets</li>
<li>Access to native widgets</li>
<li>Drag and drop</li>
<li>Internationalization</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">List of supported UI controls</h2><a id="user-content-list-of-supported-ui-controls" aria-label="Permalink: List of supported UI controls" href="#list-of-supported-ui-controls"></a></p>
<p dir="auto">Explanation of the status column: <br>
❓ Not implemented /
🚧 Work in progress /
<g-emoji alias="warning">⚠️</g-emoji> Partially implemented /
✅ Done</p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th>Native controls used</th>
<th>Status</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Button" rel="nofollow">Button</a></td>
<td>Simple button to initiate an action</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Button.html" rel="nofollow">Fl_Button</a> <br> <a href="https://developer.apple.com/documentation/appkit/nsbutton" rel="nofollow">NSButton</a></td>
<td>✅</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Checkbox" rel="nofollow">Checkbox</a></td>
<td>Control offering the user a choice between two mutually exclusive options</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Check__Button.html" rel="nofollow">Fl_Check_Button</a> <br> <a href="https://developer.apple.com/documentation/appkit/nsbutton" rel="nofollow">NSButton</a> (<a href="https://developer.apple.com/documentation/appkit/nsbuttontype/nsbuttontypeswitch" rel="nofollow">NSButtonTypeSwitch</a>)</td>
<td>✅</td>
</tr>
<tr>
<td>ComboBox</td>
<td>A combined dropdown menu with text input</td>
<td>ComboBox <br> NSComboBox</td>
<td>Not started</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Dial" rel="nofollow">Dial</a></td>
<td>Circular status control</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Dial.html" rel="nofollow">Fl_Dial</a> <br> <a href="https://developer.apple.com/documentation/appkit/nsprogressindicator" rel="nofollow">NSProgressIndicator</a> (with <code>NSCircular</code> style)</td>
<td><g-emoji alias="warning">⚠️</g-emoji></td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Dropdown" rel="nofollow">Dropdown</a></td>
<td>Drop-down menu to select a single item out of multiple options</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Choice.html" rel="nofollow">Fl_Choice</a> <br> <a href="https://developer.apple.com/documentation/appkit/nscombobox" rel="nofollow">NSComboBox</a></td>
<td>✅</td>
</tr>
<tr>
<td>Image</td>
<td>An image control</td>
<td>Image <br> NSImageView</td>
<td>Not started</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Label" rel="nofollow">Label</a></td>
<td>Simple, non-editable text label</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Box.html" rel="nofollow">Fl_Box</a> <br> <a href="https://developer.apple.com/documentation/appkit/nstextfield" rel="nofollow">NSTextField</a></td>
<td>✅</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#ListBox" rel="nofollow">ListBox</a></td>
<td>Scrollable control which allows the user to select a single or multible items from a given list</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Select__Browser.html" rel="nofollow">Fl_Select_Browser</a>/<a href="https://www.fltk.org/doc-1.4/classFl__Multi__Browser.html" rel="nofollow">Fl_Multi_Browser</a><br> <a href="https://developer.apple.com/documentation/appkit/nstableview" rel="nofollow">NSTableView</a></td>
<td>✅</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#ProgressBar" rel="nofollow">ProgressBar</a></td>
<td>Progress bar control to visualize the progression of a long-running operation</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Progress.html" rel="nofollow">Fl_Progress</a> <br> <a href="https://developer.apple.com/documentation/appkit/nsprogressindicator" rel="nofollow">NSProgressIndicator</a></td>
<td>✅</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Slider" rel="nofollow">Slider</a></td>
<td>Horizontal slider input control</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Slider.html" rel="nofollow">Fl_Slider</a> <br> <a href="https://developer.apple.com/documentation/appkit/nsslider" rel="nofollow">NSSlider</a></td>
<td>✅</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Spinner" rel="nofollow">Spinner</a></td>
<td>Number input control with up/down buttons</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Spinner.html" rel="nofollow">Fl_Spinner</a> <br> <a href="https://developer.apple.com/documentation/appkit/nstextfield" rel="nofollow">NSTextField</a>+<a href="https://developer.apple.com/documentation/appkit/nsstepper" rel="nofollow">NSStepper</a></td>
<td>✅</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#TextField" rel="nofollow">TextField</a></td>
<td>Control for single-line text input</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Input.html" rel="nofollow">Fl_Input</a> <br> <a href="https://developer.apple.com/documentation/appkit/nstextfield" rel="nofollow">NSTextField</a></td>
<td>✅</td>
</tr>
<tr>
<td>TextView/TextEditor</td>
<td>General-purpose text box to view/edit multi-line text content</td>
<td>Text <br> NSTextView</td>
<td>🚧</td>
</tr>
<tr>
<td><a href="https://pkg.go.dev/github.com/roblillack/spot/ui#Window" rel="nofollow">Window</a></td>
<td>Control representing a (top-level) window on the screen</td>
<td><a href="https://www.fltk.org/doc-1.4/classFl__Window.html" rel="nofollow">Fl_Window</a> <br> <a href="https://developer.apple.com/documentation/appkit/nswindow" rel="nofollow">NSWindow</a></td>
<td>✅</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Potential future backends to look at</h2><a id="user-content-potential-future-backends-to-look-at" aria-label="Permalink: Potential future backends to look at" href="#potential-future-backends-to-look-at"></a></p>
<ul dir="auto">
<li>Native Windows controls: <a href="https://github.com/rodrigocfd/windigo">https://github.com/rodrigocfd/windigo</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mp3tag – The Universal Tag Editor (219 pts)]]></title>
            <link>https://www.mp3tag.de/en/</link>
            <guid>40468933</guid>
            <pubDate>Fri, 24 May 2024 18:15:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mp3tag.de/en/">https://www.mp3tag.de/en/</a>, See on <a href="https://news.ycombinator.com/item?id=40468933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<section>
	
	<p>
		Mp3tag is a powerful and easy-to-use tool to edit metadata of audio files.
	</p>

	<p>
	  It supports batch tag-editing of ID3v1, ID3v2.3, ID3v2.4, iTunes MP4, WMA, Vorbis Comments and APE Tags for multiple files at once covering a variety of <a href="#formats">audio formats</a>.
	</p>

	<p>
	  Furthermore, it supports online database lookups from, e.g., Discogs, MusicBrainz or freedb, allowing you to automatically gather proper tags and download cover art for your music library.
	</p>

	<p>
	  You can rename files based on the tag information, replace characters or words in tags and filenames, import/export tag information, create playlists and <a href="#features">more</a>.
	</p>

	<p>
		<a href="https://www.mp3tag.de/en/screenshots.html" title="Screenshots"><img src="https://www.mp3tag.de/images/mp3tag-en.png" alt="Screenshots"></a>
	</p>
</section>

<section>
	<h2><a id="features"></a>Main features:</h2>

	<p><strong>Batch Tag Editing</strong> 
	Write ID3v1.1, ID3v2.3, ID3v2.4, MP4, WMA, APEv2 Tags and Vorbis Comments to multiple files at once.</p>
	
	<p><strong>Support for Cover Art</strong>
	Download and add album covers to your files and make your library even more shiny.</p>
	
	<p><strong>Import from Discogs, freedb, MusicBrainz</strong>
	Save typing and import tags from online databases like Discogs, freedb, MusicBrainz, and more.</p>
	
	<p><strong>Replace characters or words</strong>
	Replace strings in tags and filenames (with support for Regular Expressions).</p>
	
	<p><strong>Create Playlists automatically</strong>
	Create and manage playlists automatically while editing.</p>

	<p><strong>Rename files from tags</strong>
	Rename files based on the tag information and import tags from filenames.</p>
		
	<p><strong>Export to HTML, RTF, CSV</strong>
	Generate nice reports and lists of your collection based on user-defined templates.</p>
	
	<p><strong>Full Unicode Support</strong>
	User-interface and tagging are fully Unicode compliant.</p>
	
	<p>
		Besides these main features Mp3tag offers a variety of other functions and features ranging
		from batch export of embedded album covers, over support for iTunes-specific tags like
		media type or TV Show settings, to combining multiple actions into groups that can be applied
		with a single mouse click.
	</p>
</section>

<section>	
<h2><a id="formats"></a>Supported Audio Formats</h2>

<ul>
	<li>Advanced Audio Coding (<a href="https://wiki.hydrogenaud.io/index.php?title=Advanced_Audio_Coding">aac</a>)</li>
	<li>Apple Lossless Audio Codec (<a href="https://en.wikipedia.org/wiki/Apple_Lossless">alac</a>)</li>
	<li>Audio Interchange File Format (<a href="https://en.wikipedia.org/wiki/Audio_Interchange_File_Format">aif / aifc / aiff</a>)</li>
	<li>Direct Stream Digital Audio (<a href="https://en.wikipedia.org/wiki/Direct_Stream_Digital">dsf</a>)</li><!--  -->
	<li>Free Lossless Audio Codec (<a href="https://xiph.org/flac/">flac</a>)</li>
	<li>Matroska (<a href="https://www.matroska.org/">mka / mkv</a>)</li>
	<li>Monkey's Audio (<a href="https://monkeysaudio.com/">ape</a>)</li>
	<li>Mpeg Layer 3 (<a href="https://en.wikipedia.org/wiki/MP3">mp3</a>)</li>
	<li>MPEG-4 (<a href="https://en.wikipedia.org/wiki/MPEG-4">mp4 / m4a / m4b / m4v / iTunes</a>)</li>
	<li>Musepack (<a href="https://www.musepack.net/">mpc</a>)</li>
	<li>Ogg Vorbis (<a href="https://xiph.org/vorbis/">ogg</a>)</li>
	<li>IETF Opus (<a href="https://opus-codec.org/">opus</a>)</li>
	<li>OptimFROG (<a href="http://losslessaudio.org/">ofr / ofs</a>)</li>
	<li>Speex (<a href="https://www.speex.org/">spx</a>)</li>
	<li>Tom's Audio Kompressor (<a href="http://www.thbeck.de/Tak/Tak.html">tak</a>)</li>
	<li>True Audio (<a href="http://tausoft.org/wiki/True_Audio_Codec_Overview">tta</a>)</li>
	<li>Windows Media Audio (<a href="https://en.wikipedia.org/wiki/Windows_Media_Audio">wma</a>)</li>
	<li>WavPack (<a href="https://www.wavpack.com/">wv</a>)</li>
	<li>WAV (<a href="https://en.wikipedia.org/wiki/WAV">wav</a>)</li>
	<li>WebM (<a href="https://www.webmproject.org/">webm</a>)</li>
</ul>
</section>
</div><div>
	<h2><a href="https://community.mp3tag.de/c/announcements.rss" title="Subscribe to the Mp3tag News RSS-Feed"><img src="https://www.mp3tag.de/images/icons/feed-icon-14x14.png" title="Subscribe to the Mp3tag News RSS-Feed" alt="RSS"></a> Latest News</h2>

	

	<p>2024-05-24</p>
	<div>
		<p><strong>Mp3tag v3.26</strong> — This version introduces
		Cover Thumbnails for Query Results from Tag Sources,
		Copy as Text to copy a textual representation of the selected files to the clipboard,
		and other improvements and fixes, including performance improvements when writing tags via the Tag Panel, Extended Tags, or the converters.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-26-released/64768" title="Mp3tag v3.26 Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p>2024-03-28</p>
	<div>
		<p><strong>Mp3tag v3.25</strong> — This version is a spring-cleaning release and fixes a few issues that were reported over the past weeks.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-25-released/64218" title="Mp3tag v3.25 Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p>2024-01-26</p>
	<div>
		<p><strong>Mp3tag v3.24</strong> — This version introduces the Playlist Generator to batch-generate multiple playlists at once,
		the option to choose a dedicated field at actions of type Remove Duplicate Fields,
		a utility function to optimize padding for FLAC files,
		and other improvements and fixes.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-24-released/63562" title="Mp3tag v3.24 Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p>2023-11-03</p>
	<div>
		<p><strong>Mp3tag v3.23</strong> — This version comes with modernized dialogs, a larger
		default font for dialogs and windows, new features for the Web Sources Framework,
		and other improvements and fixes.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-23-released/62640" title="Mp3tag v3.23 Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p>2023-09-20</p>
	<div>
		<p><strong>Mp3tag v3.22b</strong> — This version fixes a security issue in one of the external libraries used by Mp3tag.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-22-released/61895/4" title="Mp3tag v3.22b Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p>2023-08-24</p>
	<div>
		<p><strong>Mp3tag v3.22</strong> — This version comes with checkbox fields on the Tag Panel,
		configuration settings for Tag Sources, more JSON-related functions for the Web Sources Framework,
		and many other improvements and fixes.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-22-released/61895" title="Mp3tag v3.22 Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p>2023-05-26</p>
	<div>
		<p><strong>Mp3tag v3.21</strong> — This version comes with support for redoing the last undone operation, repeating the last performed action
		or action groups, and many other improvements and fixes.
		</p><p>See the <a href="https://community.mp3tag.de/t/mp3tag-v3-21-released/61070" title="Mp3tag v3.21 Release Notes">Release Notes</a> for more details.</p>
		
	</div>

	<p><a href="https://www.mp3tag.de/en/news.html" title="old news">More ...</a>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Financial Statement Analysis with Large Language Models (310 pts)]]></title>
            <link>https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311</link>
            <guid>40468518</guid>
            <pubDate>Fri, 24 May 2024 17:39:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311</a>, See on <a href="https://news.ycombinator.com/item?id=40468518">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

	
	
		
	

	
	
		
		
	

	
	

	
	
	
	
	
    
        
    
	

	
	<p>
		
		
			<span>54 Pages</span>
		
		

		<span>Posted: 21 May 2024</span>
		
		
		
	</p>
	
		
	
	
	
	
	



	
	
	
	
		
		
	
	
		
			<p>Date Written: May 20, 2024</p>
		
	

	
	
		
		
	

	
	
		
	
	<div>
		<h3>Abstract</h3>
		<p>We investigate whether an LLM can successfully perform financial statement analysis in a way similar to a professional human analyst. We provide standardized and anonymous financial statements to GPT4 and instruct the model to analyze them to determine the direction of future earnings. Even without any narrative or industry-specific information, the LLM outperforms financial analysts in its ability to predict earnings changes. The LLM exhibits a relative advantage over human analysts in situations when the analysts tend to struggle. Furthermore, we find that the prediction accuracy of the LLM is on par with the performance of a narrowly trained state-of-the-art ML model. LLM prediction does not stem from its training memory. Instead, we find that the LLM generates useful narrative insights about a company's future performance. Lastly, our trading strategies based on GPT's predictions yield a higher Sharpe ratio and alphas than strategies based on other models. Taken together, our results suggest that LLMs may take a central role in decision-making. </p>
	</div>
	

	<center>
		
		


	

	
	

		
		

	
	


	</center>

	
	
	
		
	
	
	

	
	
		
		
			
				
			
		
		<p><strong>Keywords:</strong> GPT4, neural network, asset pricing, earnings, direction of earnings changes, analysts, chain-of-thought, financial statement analysis, large language models</p>
	
	

	
    
    
	

	
	
		<p><strong>JEL Classification:</strong> G12, G14, G41, M41</p>
	
	

	
	

























    	
	
	
	
   	
	
	
	
	
	            
	















	











    
    










    
    
    
    
















	



    




	<p>
		<strong>Suggested Citation:</strong>
		<a href="#">Suggested Citation<i></i></a>
	</p>
	<p>
		
			Kim,  Alex G. and Muhn,  Maximilian and Nikolaev,  Valeri V., Financial Statement Analysis with Large Language Models (May 20, 2024). Chicago Booth Research Paper Forthcoming, Fama-Miller Working Paper,  Available at SSRN: <a href="https://ssrn.com/abstract=4835311" target="_blank">https://ssrn.com/abstract=4835311</a> or <a href="https://dx.doi.org/10.2139/ssrn.4835311" target="_blank">http://dx.doi.org/10.2139/ssrn.4835311 </a>
		
	</p>
	

	
	
	

	
	

	
	
		
	

	
	
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Search Is Now a Giant Hallucination (160 pts)]]></title>
            <link>https://gizmodo.com/google-search-ai-overview-giant-hallucination-1851499031</link>
            <guid>40468230</guid>
            <pubDate>Fri, 24 May 2024 17:10:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/google-search-ai-overview-giant-hallucination-1851499031">https://gizmodo.com/google-search-ai-overview-giant-hallucination-1851499031</a>, See on <a href="https://news.ycombinator.com/item?id=40468230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><figure id="" data-id="22a4db1dbab790a8ed087ea2a106062c" data-recommend-id="image://22a4db1dbab790a8ed087ea2a106062c" data-format="jpg" data-width="4072" data-height="2290" data-lightbox="false" data-recommended="true" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="getty" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/22a4db1dbab790a8ed087ea2a106062c.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/22a4db1dbab790a8ed087ea2a106062c.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/22a4db1dbab790a8ed087ea2a106062c.jpg"><img alt="The stage during Google’s I/O conference." data-chomp-id="22a4db1dbab790a8ed087ea2a106062c" data-format="jpg" data-height="2290" data-alt="The stage during Google’s I/O conference." data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/22a4db1dbab790a8ed087ea2a106062c.jpg"></picture></div><p><figcaption>The stage during Google’s I/O conference.</figcaption><figcaption>Photo<!-- -->: <!-- -->Andrej Sokolow/picture alliance<!-- --> (<!-- -->Getty Images<!-- -->)</figcaption></p></div><span data-id="22a4db1dbab790a8ed087ea2a106062c" data-recommend-id="image://22a4db1dbab790a8ed087ea2a106062c" data-format="jpg" data-width="4072" data-height="2290" data-lightbox="false" data-recommended="true" data-hide="false"></span></figure><div><p>Google tested out AI overviews for months before releasing them nationwide last week, but clearly, that wasn’t enough time. The <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/google-shopping-ai-search-generative-experience-1851028975&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/google-shopping-ai-search-generative-experience-1851028975">AI is hallucinating</a></span> answers to several user queries, creating a less-than-trustworthy experience across Google’s flagship product. In the last week, Gizmodo received AI overviews from Google that reference <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/worst-google-ai-answers-glue-pizza-dogs-playing-sports-1851495298&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/worst-google-ai-answers-glue-pizza-dogs-playing-sports-1851495298">glue-topped pizza</a></span> and suggest Barack Obama was Muslim.<br></p><p>The hallucinations are concerning, but not entirely surprising. Like we’ve seen before with AI chatbots, this technology seems to confuse satire with journalism – several of the incorrect AI overviews we found seem to reference <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://www.theonion.com/geologists-recommend-eating-at-least-one-small-rock-per-1846655112&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theonion.com/geologists-recommend-eating-at-least-one-small-rock-per-1846655112">The Onion</a></span>. The problem is that this AI offers an authoritative answer to millions of people who turn to Google Search daily to just look something up. Now, at least some of these people will be presented with hallucinated answers.</p><p>“The vast majority of AI Overviews provide high quality information, with links to dig deeper on the web,” said a Google spokesperson in an emailed statement to Gizmodo, noting many of the examples the company has seen have been from uncommon queries. “We’re taking swift action where appropriate under our content policies, and using these examples to develop broader improvements to our systems, some of which have already started to roll out.<strong>”</strong>&nbsp;</p><p>In my experience, AI overviews are more often right than wrong.  However, every wrong answer I get makes me question my entire experience on Google Search even more – I have to asses each answer carefully. Google notes that AI is “experimental” but they’ve opted everyone into this experiment by default.</p><p>“The thing with Search — we handle billions of queries,” Google CEO Sundar Pichai told <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theverge.com/24158374/google-ceo-sundar-pichai-ai-search-gemini-future-of-the-internet-web-openai-decoder-interview&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theverge.com/24158374/google-ceo-sundar-pichai-ai-search-gemini-future-of-the-internet-web-openai-decoder-interview" target="_blank" rel="noopener noreferrer">The Verge</a></span> on Monday when asked about the AI overview rollout. “You can absolutely find a query and hand it to me and say, ‘Could we have done better on that query?’ Yes, for sure. But in many cases, part of what is making people respond positively to AI Overviews is that the summary we are providing clearly adds value and helps them look at things they may not have otherwise thought about.”</p><p>Strangely, Google Search occasionally responds to a query with “An AI overview is not available for this search,” while other times, Google will just not say anything and show traditional search results. I got this answer when I searched “what ethnicity are most US presidents” and when I searched “what fruits end in me.”</p><figure id="" data-id="f70bb6ae125cd44692ce2178afc54c5e" data-recommend-id="image://f70bb6ae125cd44692ce2178afc54c5e" data-format="png" data-width="746" data-height="218" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/f70bb6ae125cd44692ce2178afc54c5e.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" data-srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/f70bb6ae125cd44692ce2178afc54c5e.jpg"><img alt="Image for article titled Google Search Is Now a Giant Hallucination" data-chomp-id="f70bb6ae125cd44692ce2178afc54c5e" data-format="png" data-height="218" data-alt="Image for article titled Google Search Is Now a Giant Hallucination" data-anim-src="" data-src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/f70bb6ae125cd44692ce2178afc54c5e.jpg" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/f70bb6ae125cd44692ce2178afc54c5e.jpg"></picture></div><p><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="f70bb6ae125cd44692ce2178afc54c5e" data-recommend-id="image://f70bb6ae125cd44692ce2178afc54c5e" data-format="png" data-width="746" data-height="218" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>A Google spokesperson says its systems occasionally start generating an AI overview, but stop it from appearing when it doesn’t meet its quality threshold. Notably, Google had to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/google-pauses-gemini-ai-image-generator-white-racism-1851277547&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/google-pauses-gemini-ai-image-generator-white-racism-1851277547">pause Gemini’s answers and image generation</a></span> around racial topics for months after it upset large swaths of the country. It’s unclear if this “stop and start” AI overview generation is related.</p><p>What is clear is that Google felt pressured to put its money where its mouth is, and that means putting AI into Search. People are increasingly choosing ChatGPT, Perplexity, or other AI offerings as their main way to find information on the internet. Google views this race existentially, but it may have just jeopardized the Search experience by trying to catch up.</p><p>This week, Google Search has told people a lot of strange things through AI overviews. Here are some of the weirdest ones Gizmodo has found.</p><h2 id="h22225"><a id=""></a><br></h2></div></div><div><figure id="" data-id="920367822abe29cfad0a86fce4e999c9" data-recommend-id="image://920367822abe29cfad0a86fce4e999c9" data-format="png" data-width="701" data-height="397" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/920367822abe29cfad0a86fce4e999c9.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/920367822abe29cfad0a86fce4e999c9.jpg"><img alt="Query: Are parachutes effective" data-chomp-id="920367822abe29cfad0a86fce4e999c9" data-format="png" data-height="397" data-alt="Query: Are parachutes effective" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/920367822abe29cfad0a86fce4e999c9.jpg"></picture></div><p><figcaption>Query: Are parachutes effective</figcaption><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="920367822abe29cfad0a86fce4e999c9" data-recommend-id="image://920367822abe29cfad0a86fce4e999c9" data-format="png" data-width="701" data-height="397" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>Maybe they’re not perfect, but parachutes are definitely more effective than backpacks.</p></div><div><figure id="" data-id="2e6b3f90e73cee3394925560bafd4f8f" data-recommend-id="image://2e6b3f90e73cee3394925560bafd4f8f" data-format="png" data-width="687" data-height="330" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/2e6b3f90e73cee3394925560bafd4f8f.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/2e6b3f90e73cee3394925560bafd4f8f.jpg"><img alt="Query: How does sandy cheeks die" data-chomp-id="2e6b3f90e73cee3394925560bafd4f8f" data-format="png" data-height="330" data-alt="Query: How does sandy cheeks die" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/2e6b3f90e73cee3394925560bafd4f8f.jpg"></picture></div><p><figcaption>Query: How does sandy cheeks die</figcaption><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="2e6b3f90e73cee3394925560bafd4f8f" data-recommend-id="image://2e6b3f90e73cee3394925560bafd4f8f" data-format="png" data-width="687" data-height="330" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure></div><div><figure id="" data-id="0ff22e38823c6883f8f368b94ae58b0a" data-recommend-id="image://0ff22e38823c6883f8f368b94ae58b0a" data-format="png" data-width="693" data-height="434" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/0ff22e38823c6883f8f368b94ae58b0a.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/0ff22e38823c6883f8f368b94ae58b0a.jpg"><img alt="Image for article titled Google Search Is Now a Giant Hallucination" data-chomp-id="0ff22e38823c6883f8f368b94ae58b0a" data-format="png" data-height="434" data-alt="Image for article titled Google Search Is Now a Giant Hallucination" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/0ff22e38823c6883f8f368b94ae58b0a.jpg"></picture></div><p><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="0ff22e38823c6883f8f368b94ae58b0a" data-recommend-id="image://0ff22e38823c6883f8f368b94ae58b0a" data-format="png" data-width="693" data-height="434" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>These are great sources by the way. For reference, Responsibilityuns is a fake snack invented by a satirical Onion article.</p></div><div><figure id="" data-id="9ce1a31b4f504cfd5cbca3c6acb45c07" data-recommend-id="image://9ce1a31b4f504cfd5cbca3c6acb45c07" data-format="png" data-width="697" data-height="427" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/9ce1a31b4f504cfd5cbca3c6acb45c07.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/9ce1a31b4f504cfd5cbca3c6acb45c07.jpg"><img alt="Query: How many hours are spent plotting revenge" data-chomp-id="9ce1a31b4f504cfd5cbca3c6acb45c07" data-format="png" data-height="427" data-alt="Query: How many hours are spent plotting revenge" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/9ce1a31b4f504cfd5cbca3c6acb45c07.jpg"></picture></div><p><figcaption>Query: How many hours are spent plotting revenge</figcaption><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="9ce1a31b4f504cfd5cbca3c6acb45c07" data-recommend-id="image://9ce1a31b4f504cfd5cbca3c6acb45c07" data-format="png" data-width="697" data-height="427" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>I don’t think anyone is this petty.</p></div><div><figure id="" data-id="a6fe08be38961d5f2ebc1da4a0cd93a1" data-recommend-id="image://a6fe08be38961d5f2ebc1da4a0cd93a1" data-format="png" data-width="721" data-height="262" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/a6fe08be38961d5f2ebc1da4a0cd93a1.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/a6fe08be38961d5f2ebc1da4a0cd93a1.jpg"><img alt="Image for article titled Google Search Is Now a Giant Hallucination" data-chomp-id="a6fe08be38961d5f2ebc1da4a0cd93a1" data-format="png" data-height="262" data-alt="Image for article titled Google Search Is Now a Giant Hallucination" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/a6fe08be38961d5f2ebc1da4a0cd93a1.jpg"></picture></div><p><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="a6fe08be38961d5f2ebc1da4a0cd93a1" data-recommend-id="image://a6fe08be38961d5f2ebc1da4a0cd93a1" data-format="png" data-width="721" data-height="262" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>In fairness, Google’s AI got one right.</p></div><div><figure id="" data-id="d7177d3a77b383526a6747fe0558f9fb" data-recommend-id="image://d7177d3a77b383526a6747fe0558f9fb" data-format="png" data-width="738" data-height="457" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/d7177d3a77b383526a6747fe0558f9fb.jpg"><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/d7177d3a77b383526a6747fe0558f9fb.jpg"><img alt="Query: can i use gasoline in cooking spaghetti" data-chomp-id="d7177d3a77b383526a6747fe0558f9fb" data-format="png" data-height="457" data-alt="Query: can i use gasoline in cooking spaghetti" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/d7177d3a77b383526a6747fe0558f9fb.jpg"></picture></div><p><figcaption>Query: can i use gasoline in cooking spaghetti</figcaption><figcaption>Screenshot<!-- -->: <!-- -->Google Search</figcaption></p></div><span data-id="d7177d3a77b383526a6747fe0558f9fb" data-recommend-id="image://d7177d3a77b383526a6747fe0558f9fb" data-format="png" data-width="738" data-height="457" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>Wouldn’t recommend this recipe.</p></div><div><figure id="" data-id="350364f965e392229f360172aa13d3cd" data-recommend-id="image://350364f965e392229f360172aa13d3cd" data-format="jpg" data-width="1125" data-height="906" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/350364f965e392229f360172aa13d3cd.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/350364f965e392229f360172aa13d3cd.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/350364f965e392229f360172aa13d3cd.jpg"><img alt="Query: How many Muslim presidents has the United States had?" data-chomp-id="350364f965e392229f360172aa13d3cd" data-format="jpg" data-height="906" data-alt="Query: How many Muslim presidents has the United States had?" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/350364f965e392229f360172aa13d3cd.jpg"></picture></div><p><figcaption><strong>Query: How many Muslim presidents has the United States had?</strong></figcaption><figcaption>Screenshot<!-- -->: <!-- -->Matt Novak/Google Search</figcaption></p></div><span data-id="350364f965e392229f360172aa13d3cd" data-recommend-id="image://350364f965e392229f360172aa13d3cd" data-format="jpg" data-width="1125" data-height="906" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>This answer is false, and the product of a conspiracy theory. The United States has only had Christian presidents as of 2024.</p></div><div><figure id="" data-id="91d615b36fcb00af69da5b570b5ebabf" data-recommend-id="image://91d615b36fcb00af69da5b570b5ebabf" data-format="png" data-width="828" data-height="563" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/91d615b36fcb00af69da5b570b5ebabf.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/91d615b36fcb00af69da5b570b5ebabf.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/91d615b36fcb00af69da5b570b5ebabf.jpg"><img alt="Query: How do cats teleport?" data-chomp-id="91d615b36fcb00af69da5b570b5ebabf" data-format="png" data-height="563" data-alt="Query: How do cats teleport?" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/91d615b36fcb00af69da5b570b5ebabf.jpg"></picture></div><p><figcaption><strong>Query: How do cats teleport?</strong></figcaption><figcaption>Screenshot<!-- -->: <!-- -->Matt Novak/Google Search</figcaption></p></div><span data-id="91d615b36fcb00af69da5b570b5ebabf" data-recommend-id="image://91d615b36fcb00af69da5b570b5ebabf" data-format="png" data-width="828" data-height="563" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>Sadly, this is not true either. Cats are incapable of teleporting as far as humans know.</p></div><div><figure id="" data-id="dc85f51123862c3d5f72f747928c3672" data-recommend-id="image://dc85f51123862c3d5f72f747928c3672" data-format="png" data-width="833" data-height="598" data-lightbox="false" data-recommended="false" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-link-reference="" data-link-target="" data-syndicationrights="false" data-imagerights="other-license" data-hide="false" data-hidecredit="false"><div><picture><source media="(max-width: 49.94em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_965/dc85f51123862c3d5f72f747928c3672.jpg"><source media="(min-width: 50em) and (max-width: 63.69em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/dc85f51123862c3d5f72f747928c3672.jpg"><source media="(min-width: 63.75em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1600/dc85f51123862c3d5f72f747928c3672.jpg"><img alt="Query: How many rocks should I eat?" data-chomp-id="dc85f51123862c3d5f72f747928c3672" data-format="png" data-height="598" data-alt="Query: How many rocks should I eat?" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/dc85f51123862c3d5f72f747928c3672.jpg"></picture></div><p><figcaption><strong>Query: How many rocks should I eat?</strong></figcaption><figcaption>Screenshot<!-- -->: <!-- -->Matt Novak/Google Search</figcaption></p></div><span data-id="dc85f51123862c3d5f72f747928c3672" data-recommend-id="image://dc85f51123862c3d5f72f747928c3672" data-format="png" data-width="833" data-height="598" data-lightbox="false" data-recommended="false" data-hide="false"></span></figure><p>Ideally, no rocks should be eaten on any given day.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICQ will stop working from June 26 (805 pts)]]></title>
            <link>https://icq.com/desktop/en#windows</link>
            <guid>40467625</guid>
            <pubDate>Fri, 24 May 2024 16:16:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://icq.com/desktop/en#windows">https://icq.com/desktop/en#windows</a>, See on <a href="https://news.ycombinator.com/item?id=40467625">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" class="page">
		<div id="section0" data-section="">
				
				<p>You can chat with friends in VK Messenger, <br>and with colleagues in VK WorkSpace</p>
			</div>
		<section id="section1" data-section="">
			<div id="section1SlideImg">
				<p><img src="https://icq.com/cached/img/landing/desktop/eng/section1-img-dekstop.png" alt=""></p>
				<p><img src="https://icq.com/cached/img/landing/desktop/eng/section1-img-phone.png" alt=""></p>
			</div>
			<p><img src="https://icq.com/cached/img/landing/desktop/eng/video1_lastframe.png" alt=""></p>
		</section>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing a Unix clone in about a month (282 pts)]]></title>
            <link>https://drewdevault.com/2024/05/24/2024-05-24-Bunnix.html</link>
            <guid>40467297</guid>
            <pubDate>Fri, 24 May 2024 15:41:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drewdevault.com/2024/05/24/2024-05-24-Bunnix.html">https://drewdevault.com/2024/05/24/2024-05-24-Bunnix.html</a>, See on <a href="https://news.ycombinator.com/item?id=40467297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <article>
    <p>I needed a bit of a break from “real work” recently, so I started a new
programming project that was low-stakes and purely recreational. On April 21st,
I set out to see how much of a Unix-like operating system for x86_64 targets
that I could put together in about a month. The result is
<a href="https://git.sr.ht/~sircmpwn/bunnix">Bunnix</a>. Not including days I didn’t work
on Bunnix for one reason or another, I spent 27 days on this project.</p>
<p>Here’s a little demo of the results…</p>

<p>You can try it for yourself if you like:</p>
<ul>
<li><a href="https://cyanide.ayaya.dev/bunnix.iso">Bunnix 0.0.0 iso</a></li>
</ul>
<p>To boot this ISO with qemu:</p>
<pre tabindex="0"><code>qemu-system-x86_64 -cdrom bunnix.iso -display sdl -serial stdio
</code></pre><p>You can also write the iso to a USB stick and boot it on real hardware. It will
probably work on most AMD64 machines – I have tested it on a ThinkPad X220 and
a Starlabs Starbook Mk IV. Legacy boot and EFI are both supported. There are
some limitations to keep in mind, in particular that there is no USB support, so
a PS/2 keyboard (or PS/2 emulation via the BIOS) is required. Most laptops rig
up the keyboard via PS/2, and <abbr title="your milage may vary">YMMV</abbr>
with USB keyboards via PS/2 emulation.</p>
<p><em>Tip: the DOOM keybindings are weird. WASD to move, right shift to shoot, and
space to open doors. Exiting the game doesn’t work so just reboot when you’re
done playing. I confess I didn’t spend much time on that port.</em></p>
<h2 id="whats-there">What’s there?</h2>
<p>The Bunnix kernel is (mostly) written in <a href="https://harelang.org/">Hare</a>, plus some
C components, namely lwext4 for ext4 filesystem support and libvterm for the
kernel video terminal.</p>
<p>The kernel supports the following drivers:</p>
<ul>
<li>PCI (legacy)</li>
<li>AHCI block devices</li>
<li>GPT and MBR partition tables</li>
<li>PS/2 keyboards</li>
<li>Platform serial ports</li>
<li>CMOS clocks</li>
<li>Framebuffers (configured by the bootloaders)</li>
<li>ext4 and memfs filesystems</li>
</ul>
<p>There are numerous supported kernel features as well:</p>
<ul>
<li>A virtual filesystem</li>
<li>A /dev populated with block devices, null, zero, and full psuedo-devices,
/dev/kbd and /dev/fb0, serial and video TTYs, and the /dev/tty controlling
terminal.</li>
<li>Reasonably complete terminal emulator and somewhat passable termios support</li>
<li>Some 40 syscalls, including for example clock_gettime, poll, openat et al,
fork, exec, pipe, dup, dup2, ioctl, etc</li>
</ul>
<p>Bunnix is a single-user system and does not currently attempt to enforce Unix
file modes and ownership, though it could be made multi-user relatively easily
with a few more days of work.</p>
<p>Included are two bootloaders, one for legacy boot which is multiboot-compatible
and written in Hare, and another for EFI which is written in C. Both of them
load the kernel as an ELF file plus an initramfs, if required. The EFI
bootloader includes zlib to decompress the initramfs; multiboot-compatible
bootloaders handle this decompression for us.</p>
<p>The userspace is largely assembled from third-party sources. The following
third-party software is included:</p>
<ul>
<li>Colossal Cave Adventure (advent)</li>
<li>dash (/bin/sh)</li>
<li>Doom</li>
<li>gzip</li>
<li>less (pager)</li>
<li>lok (/bin/awk)</li>
<li>lolcat</li>
<li>mandoc (man pages)</li>
<li>sbase (core utils)<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></li>
<li>tcc (C compiler)</li>
<li>Vim 5.7</li>
</ul>
<p>The libc is derived from musl libc and contains numerous modifications to suit
Bunnix’s needs. The curses library is based on netbsd-curses.</p>
<p>The system works but it’s pretty buggy and some parts of it are quite slapdash:
your milage will vary. Be prepared for it to crash!</p>
<h2 id="how-bunnix-came-together">How Bunnix came together</h2>
<p>I started documenting the process on Mastodon on day 3 – check out <a href="https://fosstodon.org/@drewdevault/112319697309218275">the
Mastodon thread</a> for the
full story. Here’s what it looked like on day 3:</p>
<p><img src="https://cdn.fosstodon.org/media_attachments/files/112/319/693/110/194/041/original/2c0bd7006a74aece.png" alt="Screenshot of an early Bunnix build, which boots up, sets up available memory, and exercises an early in-memory filesystem"></p>
<p>Here’s some thoughts after the fact.</p>
<p>Some of Bunnix’s code stems from an earlier project,
<a href="https://sr.ht/~sircmpwn/helios">Helios</a>. This includes portions of the kernel
which are responsible for some relatively generic CPU setup (GDT, IDT, etc), and
some drivers like AHCI were adapted for the Bunnix system. I admit that it would
probably not have been possible to build Bunnix so quickly without prior
experience through Helios.</p>
<p>Two of the more challenging aspects were ext4 support and the virtual terminal,
for which I brought in two external dependencies, lwext4 and libvterm. Both
proved to be challenging integrations. I had to rewrite my filesystem layer a
few times, and it’s still buggy today, but getting a proper Unix filesystem
design (including openat and good handling of inodes) requires digging into
lwext4 internals a bit more than I’d have liked. I also learned a lot about
mixing source languages into a Hare project, since the kernel links together
Hare, assembly, and C sources – it works remarkably well but there are some
pain points I noticed, particularly with respect to building the ABI integration
riggings. It’d be nice to automate conversion of C headers into Hare forward
declaration modules. Some of this work already exists in hare-c, but has a ways
to go. If I were to start again, I would probably be more careful in my design
of the filesystem layer.</p>
<p>Getting the terminal right was difficult as well. I wasn’t sure that I was going
to add one at all, but I eventually decided that I wanted to port vim and that
was that. libvterm is a great terminal state machine library, but it’s poorly
documented and required a lot of fine-tuning to integrate just right. I also
ended up spending a lot of time on performance to make sure that the terminal
worked smoothly.</p>
<p>Another difficult part to get right was the scheduler. Helios has a simpler
scheduler than Bunnix, and while I initially based the Bunnix scheduler on
Helios I had to throw out and rewrite quite a lot of it. Both Helios and Bunnix
are single-CPU systems, but unlike Helios, Bunnix allows context switching
within the kernel – in fact, even preemptive task switching enters and exits
via the kernel. This necessitates multiple kernel stacks and a different
approach to task switching. However, the advantages are numerous, one of which
being that implementing blocking operations like disk reads and pipe(2) are much
simpler with wait queues. With a robust enough scheduler, the rest of the kernel
and its drivers come together pretty easily.</p>
<p>Another source of frustration was signals, of course. Helios does not attempt to
be a Unix and gets away without these, but to build a Unix, I needed to
implement signals, big messy hack though they may be. The signal implementation
which ended up in Bunnix is pretty bare-bones: I mostly made sure that SIGCHLD
worked correctly so that I could port dash.</p>
<p>Porting third-party software was relatively easy thanks to basing my libc on
musl libc. I imported large swaths of musl into my own libc and adapted it to
run on Bunnix, which gave me a pretty comprehensive and reliable C library
pretty fast. With this in place, porting third-party software was a breeze, and
most of the software that’s included was built with minimal patching.</p>
<h2 id="what-i-learned">What I learned</h2>
<p>Bunnix was an interesting project to work on. My other project, Helios, is a
microkernel design that’s Not Unix, while Bunnix is a monolithic kernel that is
much, much closer to Unix.</p>
<p>One thing I was surprised to learn a lot about is filesystems. Helios, as a
microkernel, spreads the filesystem implementation across many drivers running
in many separate processes. This works well enough, but one thing I discovered
is that it’s quite important to have caching in the filesystem layer, even if
only to track living objects. When I revisit Helios, I will have a lot of work
to do refactoring (or even rewriting) the filesystem code to this end.</p>
<p>The approach to drivers is also, naturally, much simpler in a monolithic kernel
design, though I’m not entirely pleased with all of the stuff I heaped into ring
0. There might be room for an improved Helios scheduler design that incorporates
some of the desirable control flow elements from the monolithic design into a
microkernel system.</p>
<p>I also finally learned how signals work from top to bottom, and boy is it ugly.
I’ve always felt that this was one of the weakest points in the design of Unix
and this project did nothing to disabuse me of that notion.</p>
<p>I had also tried to avoid using a bitmap allocator in Helios, and generally
memory management in Helios is a bit fussy altogether – one of the biggest pain
points with the system right now. However, Bunnix uses a simple bitmap allocator
for all conventional pages on the system and I found that it works really,
really well and does not have nearly as much overhead as I had feared it would.
I will almost certainly take those lessons back to Helios.</p>
<p>Finally, I’m quite sure that putting together Bunnix in just 30 days is a feat
which would not have been possible with a microkernel design. At the end of the
day, monolithic kernels are just much simpler to implement. The advantages of a
microkernel design are compelling, however – perhaps a better answer lies in a
hybrid kernel.</p>
<h2 id="whats-next">What’s next</h2>
<p>Bunnix was (note the past tense) a project that I wrote for the purpose of
recreational programming, so it’s purpose is to be fun to work on. And I’ve had
my fun! At this point I don’t feel the need to invest more time and energy into
it, though it would definitely benefit from some. In the future I may spend a
few days on it here and there, and I would be happy to integrate improvements
from the community – send patches to my <a href="https://lists.sr.ht/~sircmpwn/public-inbox">public inbox</a>. But for the most
part it is an art project which is now more-or-less complete.</p>
<p>My next steps in OS development will be a return to Helios with a lot of lessons
learned and some major redesigns in the pipeline. But I still think that Bunnix
is a fun and interesting OS in its own right, in no small part due to its
demonstration of Hare as a great language for kernel hacking. Some of the
priorities for improvements include:</p>
<ul>
<li>A directory cache for the filesystem and better caching generally</li>
<li>Ironing out ext4 bugs</li>
<li>procfs and top</li>
<li>mmaping files</li>
<li>More signals (e.g. SIGSEGV)</li>
<li>Multi-user support</li>
<li>NVMe block devices</li>
<li>IDE block devices</li>
<li>ATAPI and ISO 9660 support</li>
<li>Intel HD audio support</li>
<li>Network stack</li>
<li>Hare toolchain in the base system</li>
<li>Self hosting</li>
</ul>
<p>Whether or not it’s me or one of you readers who will work on these first
remains to be seen.</p>
<p>In any case, have fun playing with Bunnix!</p>


  </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Samsung WB850F Firmware Reverse Engineering (131 pts)]]></title>
            <link>https://op-co.de/blog/posts/samsung_wb850f_firmware/</link>
            <guid>40467232</guid>
            <pubDate>Fri, 24 May 2024 15:35:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://op-co.de/blog/posts/samsung_wb850f_firmware/">https://op-co.de/blog/posts/samsung_wb850f_firmware/</a>, See on <a href="https://news.ycombinator.com/item?id=40467232">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pagebody" role="main" class="page">
<p><span>Georg Lukas, <span>2024-05-24 17:30</span></span></p>
<p>Samsung's <a href="https://news.samsung.com/global/ces-2012-cameras-for-any-situation-with-wi-fi-and-long-zoom">WB850F compact camera</a>
was the first model to combine the DRIMeIII SoC with WiFi. Together with the
EX2F it features an uncompressed firmware binary where Samsung helpfully added
a <code>partialImage.o.map</code> file with a full linker dump and all symbol names into
the firmware ZIP. We are using this gift to reverse-engineer the main SoC
firmware, so that we can make it pass the WiFi hotspot detection and use
<a href="https://github.com/ge0rg/samsung-nx-emailservice">samsung-nx-emailservice</a>.</p>

<p>This is a follow-up to the
<a href="https://op-co.de/blog/posts/samsung_wifi_cameras/">Samsung WiFi cameras</a>
article and part of the <a href="https://op-co.de/blog/tags/samsung-nx/">Samsung NX series</a>.</p>

<div>
	<ol>
		<li><a href="#index1h2">WB850F_FW_210086.zip - the outer container</a>
		<ol>
			<li><a href="#index1h3">partialImage.o.map - the linker dump</a>
			</li>
			<li><a href="#index2h3">WB850-FW-SR-210086.bin - header analysis</a>
			</li>
			<li><a href="#index3h3">WB850-FW-SR-210086.bin - code and data partitions</a>
			</li>
		</ol>
		</li>
		<li><a href="#index2h2">Loading the code in Ghidra</a>
		<ol>
			<li><a href="#index4h3">Loading and mapping Main_Image</a>
			</li>
			<li><a href="#index5h3">Loading function names from partialImage.o.map</a>
			</li>
			<li><a href="#index6h3">Reverse engineering DevHTTPResponseStart</a>
			</li>
			<li><a href="#index7h3">Interpreting the hotspot detection</a>
			</li>
		</ol>
		</li>
		<li><a href="#index3h2">Summary: the real treasure</a>
		</li>
	</ol>
</div>


<h2><a name="index1h2"></a><code>WB850F_FW_210086.zip</code> - the outer container</h2>

<p>The WB850F is one of the few models where Samsung still publishes
<a href="https://www.samsung.com/at/support/model/EC-WB850FBPBE3/">firmware and support files</a>
after discontinuing the iLauncher application.</p>

<p>The <code>WB850F_FW_210086.zip</code> archive we can get there contains quite a few files
(as identified by <code>file</code>):</p>

<div><pre>GPS_FW<span>/</span>BASEBAND_FW_Flash.mbin<span>:</span> data
GPS_FW<span>/</span>BASEBAND_FW_Ram.mbin<span>:</span>   data
GPS_FW<span>/</span>Config.BIN<span>:</span>             data
GPS_FW<span>/</span>flashBurner.mbin<span>:</span>       data
FWUP<span>:</span>                          ASCII text<span>,</span> with CRLF line terminators
partialImage.o.map<span>:</span>            ASCII text
WB850-FW-SR-210086.bin<span>:</span>        data
wb850f_adj.txt<span>:</span>                ASCII text<span>,</span> with CRLF line terminators
</pre></div>


<p>The <code>FWUP</code> file just contains the string <code>upgrade all</code> which is a script for
the firmware testing/automation module. The <code>wb850f_adj.txt</code> file is a similar
but more complex script to upgrade the GPS firmware and delete the respective
files. Let's skip the GPS-related script and <code>GPS_FW</code> folder for now.</p>

<h3><a name="index1h3"></a><code>partialImage.o.map</code> - the linker dump</h3>

<p>The <code>partialImage.o.map</code> is a text file with &gt;300k lines, containing the
linker output for <code>partialImage.o</code>, including a full memory map of the linked
file:</p>

<div><pre>output          input           virtual
section         section         address         size     <span>file</span>

.text                           <span>00000000        01301444</span>
                .text           <span>00000000        000001</span>a4 sysALib.o
                             <span>$a</span> <span>00000000        00000000</span>
                        sysInit <span>00000000        00000000</span>
                   L<span>$_Good_Boot</span> <span>00000090        00000000</span>
                    archPwrDown <span>00000094   00000000</span>
...
           DevHTTPResponseStart <span>00321</span>a84        <span>000002</span>a4
            DevHTTPResponseData <span>00321</span>d28        <span>00000100</span>
             DevHTTPResponseEnd <span>00321</span>e28        <span>00000170</span>
...
.data                           <span>00000000        004</span>ed40c
                .data           <span>00000000        00000874</span> sysLib.o
                         sysBus <span>00000000        00000004</span>
                         sysCpu <span>00000004        00000004</span> 
                    sysBootLine <span>00000008        00000004</span>
</pre></div>


<p>This goes on and on and on, and it's a real treasure map! Now we just need to
find the island that it belongs to.</p>

<h3><a name="index2h3"></a><code>WB850-FW-SR-210086.bin</code> - header analysis</h3>

<p>Looking into <code>WB850-FW-SR-210086.bin</code> with <code>binwalk</code> yields a long list of
file headers (HTML, PNG, JPEG, ...), a VxWorks header, quite a number of Unix
paths, but nothing that looks like partitions or filesystems.</p>

<p>Let's hex-dump the first kilobyte instead:</p>

<div><pre><span>00000000</span><span>:</span> <span>3231 3030 3836 0006 4657 5</span>f55 <span>502</span>f <span>4</span>f4e  <span>210086</span>..FW_UP<span>/</span>ON
<span>00000010</span><span>:</span> <span>424</span>c <span>312</span>e <span>6269 6</span>e00 <span>0000 0000 0000 0000</span>  BL1.bin.........
<span>00000020</span><span>:</span> <span>0000 0000 0000 0000</span> c400 <span>0000 0008 0000</span>  ................
<span>00000030</span><span>:</span> <span>4</span>f4e <span>424</span>c <span>3100 0000 0000 0000 0000 0000</span>  ONBL1...........
<span>00000040</span><span>:</span> <span>0000 0000 4657 5</span>f55 <span>502</span>f <span>4</span>f4e <span>424</span>c <span>322</span>e  ....FW_UP<span>/</span>ONBL2.
<span>00000050</span><span>:</span> <span>6269 6</span>e00 <span>0000 0000 0000 0000 0000 0000</span>  bin.............
<span>00000060</span><span>:</span> <span>0000 0000 30</span>b6 <span>0000</span> c408 <span>0000 4</span>f4e <span>424</span>c  ...<span>.0</span>.......ONBL
<span>00000070</span><span>:</span> <span>3200 0000 0000 0000 0000 0000 0000 0000  2</span>...............
<span>00000080</span><span>:</span> <span>5</span>b57 <span>4238 3530 5</span>d44 <span>5343 5</span>f35 <span>4</span>b45 <span>595</span>f  <span>[</span>WB850<span>]</span>DSC_5KEY_
<span>00000090</span><span>:</span> <span>5742 3835 3000 0000 0000 0000 0000 0000</span>  WB850...........
<span>000000</span>a0<span>:</span> <span>38</span>f4 d101 f4be <span>0000 4</span>d61 <span>696</span>e <span>5</span>f49 <span>6</span>d61  <span>8</span>.......Main_Ima
<span>000000</span>b0<span>:</span> <span>6765 0000 0000 0000 0000 0000 526</span>f <span>6</span>d46  ge..........RomF
<span>000000</span>c0<span>:</span> <span>532</span>f <span>5350 4944 2</span>e52 <span>6</span>f6d <span>0000 0000 0000</span>  S<span>/</span>SPID.Rom......
<span>000000</span>d0<span>:</span> <span>0000 0000 0000 0000 0000 0000 00</span>ac f402  ................
<span>000000</span>e0<span>:</span> <span>2</span>cb3 d201 <span>5265 736</span>f <span>7572 6365 0000 0000</span>  <span>,</span>...Resource....
<span>000000</span>f0<span>:</span> <span>0000 0000 0000 0000 4657 5</span>f55 <span>502</span>f <span>5742</span>  ........FW_UP<span>/</span>WB
<span>00000100</span><span>:</span> <span>3835 302</span>e <span>4845 5800 0000 0000 0000 0000  850</span>.HEX.........
<span>00000110</span><span>:</span> <span>0000 0000 0000 0000 864</span>d <span>0000 2</span>c5f c704  .........M..<span>,</span>_..
<span>00000120</span><span>:</span> <span>4</span>f49 <span>5300 0000 0000 0000 0000 0000 0000</span>  OIS.............
<span>00000130</span><span>:</span> <span>0000 0000 4657 5</span>f55 <span>502</span>f <span>736</span>b <span>696</span>e <span>2</span>e62  ....FW_UP<span>/</span>skin.b
<span>00000140</span><span>:</span> <span>696</span>e <span>0000 0000 0000 0000 0000 0000 0000</span>  <span>in</span>..............
<span>00000150</span><span>:</span> <span>0000 0000 48</span>d0 <span>2</span>f02 b2ac c704 <span>534</span>b <span>494</span>e  ....H.<span>/</span>.....SKIN
<span>00000160</span><span>:</span> <span>0000 0000 0000 0000 0000 0000 0000 0000</span>  ................
<span>*</span>
<span>000003</span>f0<span>:</span> <span>0000 0000 0000 0000 0000 0000 5041 5254</span>  ............PART
</pre></div>


<p>This looks very interesting. It starts with the firmware version, <code>210086</code>,
then <code>0x00 0x06</code>, directly followed by <code>FW_UP/ONBL1.bin</code> at the offset
<code>0x008</code>, which very much looks like a file name. The next file name,
<code>FW_UP/ONBL2.bin</code> comes at <code>0x044</code>, so this is probably a 60-byte "partition"
record:</p>

<div><pre><span>00000008</span><span>:</span> <span>4657 5</span>f55 <span>502</span>f <span>4</span>f4e <span>424</span>c <span>312</span>e <span>6269 6</span>e00  FW_UP<span>/</span>ONBL1.bin.
<span>00000018</span><span>:</span> <span>0000 0000 0000 0000 0000 0000 0000 0000</span>  ................
<span>00000028</span><span>:</span> c400 <span>0000 0008 0000 4</span>f4e <span>424</span>c <span>3100 0000</span>  ........ONBL1...
<span>00000038</span><span>:</span> <span>0000 0000 0000 0000 0000 0000</span>            ............
</pre></div>


<p>After the file name, there is quite a bunch of zeroes (making up a 32-byte
zero-padded string), followed by two little-endian integers <code>0xc4</code> and
<code>0x800</code>, followed by a 20-byte zero-padded string <code>ONBL1</code>, which is
probably the respective partition name. After that, the next records of the
same structure follow. The integers in the second record (<code>ONBL2</code>) are
<code>0xb630</code> and <code>0x8c4</code>, so we can assume the first number is the length, and the
second one is the offset in the file (the offset of one record is always
offset+length of the previous one).</p>

<p>In total, there are six records, so the <code>0x00 0x06</code> between the version string
and the first record is probably a termination or pading byte for the firmware
version and a one-byte number of partitions.</p>

<p>With this knowledge, we can reconstruct the partition table as follows:</p>

<table>
    <thead>
        <tr>
            <th>File name</th>
            <th>size</th>
            <th>offset</th>
            <th>partition name</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>FW_UP/ONBL1.bin</td>
            <td>196 (0xc4)</td>
            <td><code>0x0000800</code></td>
            <td>ONBL1</td>
        </tr>
        <tr>
            <td>FW_UP/ONBL2.bin</td>
            <td>46 KB (0xb630)</td>
            <td><code>0x00008c4</code></td>
            <td>ONBL2</td>
        </tr>
        <tr>
            <td>[WB850]DSC_5KEY_WB850</td>
            <td>30 MB (0x1d1f438)</td>
            <td><code>0x000bef4</code></td>
            <td>Main_Image</td>
        </tr>
        <tr>
            <td>RomFS/SPID.Rom</td>
            <td>48 MB (0x2f4ac00)</td>
            <td><code>0x1d2b32c</code></td>
            <td>Resource</td>
        </tr>
        <tr>
            <td>FW_UP/WB850.HEX</td>
            <td>19 KB (0x4d86)</td>
            <td><code>0x4c75f2c</code></td>
            <td>OIS</td>
        </tr>
        <tr>
            <td>FW_UP/skin.bin</td>
            <td>36 MB (0x22fd048)</td>
            <td><code>0x4c7acb2</code></td>
            <td>SKIN</td>
        </tr>
    </tbody>
</table>


<p>Let's write a
<a href="https://github.com/ge0rg/samsung-nx-hacks/blob/master/tools/drime3-firmware.py">tool to extract DRIMeIII firmware partitions</a>, and use it!</p>

<h3><a name="index3h3"></a><code>WB850-FW-SR-210086.bin</code> - code and data partitions</h3>

<p>The tool is extracting partitions based on their partition names, appending
<code>".bin"</code> respectively. Running <code>file</code> on the output is not very helpful:</p>

<div><pre>ONBL1.bin<span>:</span>      data
ONBL2.bin<span>:</span>      data
Main_Image.bin<span>:</span> OpenPGP Secret Key
Resource.bin<span>:</span>   MIPSEB-LE MIPS-III ECOFF executable stripped <span>-</span> version <span>0.0</span>
OIS.bin<span>:</span>        data
SKIN.bin<span>:</span>       data
</pre></div>


<ul>
<li><p><code>ONBL1</code> and <code>ONBL2</code> are probably the stages 1 and 2 of the bootloader (as
confirmed by a string in <code>Main_Image</code>: <code>"BootLoader(ONBL1, ONBL2) Update
Done"</code>).</p></li>
<li><p><code>Main_Image</code> is the actual firmware: the OpenPGP Secret Key is a false
positive, <code>binwalk -A</code> reports quite a number of ARM function prologues in
this file.</p></li>
<li><p><code>Resource</code> and <code>SKIN</code> are pretty large containers, maybe provided by the SoC
manufacturer to "skin" the camera UI?</p></li>
<li><p><code>OIS</code> is not really hex as claimed by its file name, but it might
be the firmware for a dedicated
<a href="https://en.wikipedia.org/wiki/Image_stabilization#Optical_image_stabilization">optical image stabilizer</a>.</p></li>
</ul>


<p>Of all these, <code>Main_Image</code> is the most interesting one.</p>

<h2><a name="index2h2"></a>Loading the code in Ghidra</h2>

<p>The three partitions <code>ONBL1</code>, <code>ONBL2</code> and <code>Main_Image</code> contain actual ARM code.
A typical ARM firmware will contain the
<a href="https://developer.arm.com/documentation/dui0552/a/the-cortex-m3-processor/exception-model/vector-table">reset vector table</a>
at address <code>0x0000000</code> (usually the beginning of flash / ROM), which is a
series of jump instructions. All three binaries however contain actual linear
code at their respective beginning, so most probably they need to be
re-mapped to some yet unknown address.</p>

<p>To find out how and why the camera is mis-detecting a hotspot, we need to:</p>

<ol>
<li>Find the right memory address to map <code>Main_Image</code> to</li>
<li>Load the symbol names from <code>partialImage.o.map</code> into Ghidra</li>
<li>Find and analyze the function that is mis-firing the hotspot login</li>
</ol>


<h3><a name="index4h3"></a>Loading and mapping <code>Main_Image</code></h3>

<p>By default, Ghidra will assume that the binary loads to address <code>0x0000000</code>
and try to analyze it this way. To get the correct memory address, we need to
find a function that accesses some known value from the binary using an
absolute address. Given that there are 77k functions, we can start with
something that's close to task #3, and search in the "Defined Strings" tab of
Ghidra for <code>"yahoo"</code>:</p>

<p><img src="https://op-co.de/blog/posts/samsung_wb850f_firmware/ghidra-wb850f-yahoo-strings.png" alt="Screenshot of Ghidra with some Yahoo!  strings"></p>

<p>Excellent! Ghidra identified a few strings that look like an annoyed
developer's printf debugging, probably from a function called
<code>DevHTTPResponseStart()</code>, and it seems to be the function that checks whether
the camera can properly access Yahoo, Google or Samsung:</p>

<pre><code>0139f574    DevHTTPResponseStart: url=%s, handle=%x, status=%d\n, headers=%s\r\n
0139f5b8    DevHTTPResponseStart: This is YAHOO check !!!\r\n
0139f5f4    DevHTTPResponseStart: THIS IS GOOGLE/YAHOO/SAMSUNG PAGE!!!! 111\n\n\n
0139f638    DevHTTPResponseStart: 301/302/307! cannot find yahoo!  safapi_is_browser_framebuffer_on : %d , safapi_is_browser_authed(): %d  \r\n
</code></pre>

<p>According to <code>partialImage.o.map</code>, a function with that name actually exists
at address <code>0x321a84</code>, and Ghidra also found a function at <code>0x321a84</code>. There
are some more matching function offsets between the map and the binary, so we
can assume that the <code>.text</code> addresses from the map file actually correspond
1:1 to <code>Main_Image</code>! We found the right island for our map!</p>

<p>Here's the beginning of that function:</p>

<div><pre><span>bool</span> <span>FUN_00321a84</span><span>(</span>undefined4 param_1<span>,</span>ushort param_2<span>,</span><span>int</span> param_3<span>,</span><span>int</span> param_4<span>) {</span>
  <span>/* snip variable declarations */</span>
  <span>FUN_0031daec</span><span>(*(</span>DAT_00321fd4 <span>+</span> <span>0x2c</span><span>),</span>DAT_00322034<span>,</span>param_3<span>,</span>param_1<span>,</span>param_2<span>,</span>param_4<span>);</span>
  <span>FUN_0031daec</span><span>(*(</span>DAT_00321fd4 <span>+</span> <span>0x2c</span><span>),</span>DAT_00322038<span>);</span>
  <span>FUN_00326f84</span><span>(</span><span>0x68</span><span>);</span>
</pre></div>


<p>It starts with two calls to <code>FUN_0031daec()</code> with different
numbers of parameters - this smells very much of <code>printf</code> debugging again.
According to the memory map, it's called <code>opd_printf()</code>! The first parameter
is some sort of context / destination, and the second one must be a reference
to the format string. The two <code>DAT_</code> values are detected by Ghidra as 32-bit
undefined values:</p>

<pre><code>DAT_00322034:
    74 35 3a c1     undefined4 C13A3574h
DAT_00322038:
    b8 35 3a c1     undefined4 C13A35B8h
</code></pre>

<p>However, the respective last three digits match the <code>"DevHTTPResponseStart: "</code>
debug strings encountered earlier:</p>

<ul>
<li><code>0xc13a3574 - 0x0139f574 = 0xc0004000</code> (first format string with four parameters)</li>
<li><code>0xc13a35b8 - 0x0139f5b8 = 0xc0004000</code> (second format strings without parameters)</li>
</ul>


<p>From that we can reasonably conclude that <code>Main_Image</code> needs to be loaded to
the memory address <code>0xc0004000</code>. This cannot be changed after the fact in
Ghidra, so we need to remove the binary from the project, re-import it, and
set the base address accordingly:</p>

<p><img src="https://op-co.de/blog/posts/samsung_wb850f_firmware/ghidra-base-address.png" alt="Screenshot of Ghidra import options dialog"></p>

<h3><a name="index5h3"></a>Loading function names from <code>partialImage.o.map</code></h3>

<p>Ghidra has a script to bulk-import data labels and function names from a text
table,
<a href="https://github.com/NationalSecurityAgency/ghidra/blob/master/Ghidra/Features/Python/ghidra_scripts/ImportSymbolsScript.py">ImportSymbolScript.py</a>.
It expects each line to contain three variables, separated by arbitrary
amounts of whitespace (as determined by python's <code>string.split()</code>):</p>

<ol>
<li>symbol name</li>
<li>(hexadecimal) address</li>
<li>"f" for "function" or "l" for "label"</li>
</ol>


<p>Our symbol map contains multiple sections, but we are only interested in the
functions defined in <code>.text</code> (for now), which are mapped 1:1 to addresses in
<code>Main_Image</code>. Besides of function names, it also contains empty lines, object
file offsets (with <code>.text</code> as the label), labels (prefixed with <code>"L$_"</code>) and
local symbols (prefixed with <code>"$"</code>).</p>

<p>We need to limit our symbols to the <code>.text</code> section (everything after <code>.text</code>
and before <code>.debug_frame</code>), get rid of the empty lines and non-functions, then
add <code>0xc0004000</code> to each address so that we match up with the base address in
Ghidra. We can do this very obscurely with an awk one-liner:</p>

<div><pre><span>awk</span> <span>'/^\.text /{t=1;next}/^\.debug_frame /{t=0} ; !/[$.]/ { if (t &amp;&amp;</span> <span>$1</span><span>) { printf "%s %x f</span><span>\n</span><span>",</span> <span>$1</span><span>, (strtonum("0x"</span><span>$2</span><span>)+0xc0004000) } }'</span>
</pre></div>


<p>Or slightly less obscurely with a much slower shell loop:</p>

<div><pre><span>sed</span> <span>'1,/^\.text /d;/^\.debug_frame /,</span><span>$d</span><span>'</span> | <span>grep</span> <span>-v</span> <span>'^$'</span> | <span>grep</span> <span>-v</span> <span>'[.$]'</span> | \
<span>while</span> <span>read</span> sym addr f <span>;</span> <span>do</span>
    <span>printf</span> <span>"%s %x f</span><span>\n</span><span>"</span>  <span>$sym</span> $<span>((</span><span>0xc0004000</span> <span>+</span> <span>0</span>x<span>$addr</span><span>))</span>
<span>done</span>
</pre></div>


<p>Both will generate the same output that can be loaded
into Ghidra via "Window" / "Script Manager" / "ImportSymbolsScript.py":</p>

<div><pre>sysInit c0004000 f
archPwrDown c0004094 f
MMU_WriteControlReg c00040a4 f
MMU_WritePageTableBaseReg c00040b8 f
MMU_WriteDomainAccessReg c00040d0 f
...
</pre></div>


<h3><a name="index6h3"></a>Reverse engineering <code>DevHTTPResponseStart</code></h3>

<p>Now that we have the function names in place, we need to manually set the type
of quite a few <code>DAT_</code> fields to "pointer", rename the parameters according to
the debug string, and we get a reasonably usable decompiler output.</p>

<p>The following is a commented version, edited for better readability (inlined
the string references, rewrote some conditionals):</p>

<div><pre><span>bool</span> <span>DevHTTPResponseStart</span><span>(</span>undefined4 handle<span>,</span>ushort status<span>,</span><span>char</span> <span>*</span>url<span>,</span><span>char</span> <span>*</span>headers<span>) {</span>
  <span>bool</span> result<span>;</span>
  
  <span>opd_printf</span><span>(</span>ctx<span>,</span><span>"DevHTTPResponseStart: url=%s, handle=%x, status=%d</span><span>\n</span><span>, headers=%s</span><span>\r\n</span><span>"</span><span>,</span>
      url<span>,</span>handle<span>,</span>status<span>,</span>headers<span>);</span>
  <span>opd_printf</span><span>(</span>ctx<span>,</span><span>"DevHTTPResponseStart: This is YAHOO check !!!</span><span>\r\n</span><span>"</span><span>);</span>
  <span>safnotify_page_load_status</span><span>(</span><span>0x68</span><span>);</span>
  <span>if</span> <span>((</span>url <span>==</span> NULL<span>) || (</span>status <span>!=</span> <span>301</span> <span>&amp;&amp;</span> status <span>!=</span> <span>302</span> <span>&amp;&amp;</span> status <span>!=</span> <span>307</span><span>)) {</span>
    <span>/* this is not a HTTP redirect */</span>
    <span>if</span> <span>(</span>status <span>==</span> <span>200</span><span>) {</span>
      <span>/* HTTP 200 means OK */</span>
      <span>if</span> <span>(</span>headers <span>==</span> NULL <span>||</span>
          <span>(</span><span>strstr</span><span>(</span>headers<span>,</span><span>"domain=.yahoo"</span><span>) ==</span> NULL <span>&amp;&amp;</span>
           <span>strstr</span><span>(</span>headers<span>,</span><span>"Domain=.yahoo"</span><span>) ==</span> NULL <span>&amp;&amp;</span>
           <span>strstr</span><span>(</span>headers<span>,</span><span>"domain=kr.yahoo"</span><span>) ==</span> NULL <span>&amp;&amp;</span>
           <span>strstr</span><span>(</span>headers<span>,</span><span>"Domain=kr.yahoo"</span><span>) ==</span> NULL<span>)) {</span>
        <span>/* no response headers or no yahoo cookie --&gt; check fails! */</span>
        result <span>=</span> <span>true</span><span>;</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>/* we found a yahoo cookie bit in the headers */</span>
        <span>opd_printf</span><span>(</span>ctx<span>,</span><span>"DevHTTPResponseData: THIS IS GOOGLE/YAHOO PAGE!!!! 3333</span><span>\n\n\n</span><span>"</span><span>);</span>
        <span>*</span>p_request_ongoing <span>=</span> <span>0</span><span>;</span>
        <span>if</span> <span>(!</span><span>safapi_is_browser_authed</span><span>())</span>
          <span>safnotify_auth_ap</span><span>(</span><span>0</span><span>);</span>
        result <span>=</span> <span>false</span><span>;</span>
      <span>}</span>
    <span>}</span> <span>else if</span> <span>(</span>status <span>&lt;</span> <span>0</span><span>) {</span>
      <span>/* negative status = aborted? */</span>
      result <span>=</span> <span>false</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>/* positive status, not a redirect, not "OK" */</span>
      result <span>= !</span><span>safapi_is_browser_framebuffer_on</span><span>();</span>
    <span>}</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>/* this is a HTTP redirect */</span>
    <span>char</span> <span>*</span>match <span>=</span> <span>strstr</span><span>(</span>url<span>,</span><span>"yahoo."</span><span>);</span>
    <span>if</span> <span>(</span>match <span>==</span> NULL <span>||</span> match <span>&gt; (</span>url<span>+</span><span>11</span><span>)) {</span>
      <span>opd_printf</span><span>(</span>ctx<span>,</span> <span>"DevHTTPResponseStart: 301/302/307! cannot find yahoo! safapi_is_browser_framebuffer_on : %d , safapi_is_browser_authed(): %d</span>  <span>\r\n</span><span>"</span><span>,</span>
          <span>safapi_is_browser_framebuffer_on</span><span>(),</span> <span>safapi_is_browser_authed</span><span>());</span>
      <span>if</span> <span>(!</span><span>safapi_is_browser_framebuffer_on</span><span>() &amp;&amp; !</span><span>safapi_is_browser_authed</span><span>()) {</span>
        <span>opd_printf</span><span>(</span>ctx<span>,</span><span>"DevHTTPResponseStart: 302 auth failed!!! kSAFAPIAuthErrNotAuth!!</span> <span>\r\n</span><span>"</span><span>);</span>
        <span>safnotify_auth_ap</span><span>(</span><span>1</span><span>);</span>
      <span>}</span>
      result <span>=</span> <span>false</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>/* found "yahoo." in url */</span>
      <span>opd_printf</span><span>(</span>ctx<span>,</span> <span>"DevHTTPResponseStart: THIS IS GOOGLE/YAHOO/SAMSUNG PAGE!!!! 111</span><span>\n\n\n</span><span>"</span><span>);</span>
      <span>*</span>p_request_ongoing <span>=</span> <span>0</span><span>;</span>
      <span>if</span> <span>(!</span><span>safapi_is_browser_authed</span><span>())</span>
        <span>safnotify_auth_ap</span><span>(</span><span>0</span><span>);</span>
      result <span>=</span> <span>false</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> result<span>;</span>
<span>}</span>
</pre></div>


<h3><a name="index7h3"></a>Interpreting the hotspot detection</h3>

<p>So to summarize, the code in <code>DevHTTPResponseStart</code> will check for one of two
conditions and call <code>safnotify_auth_ap(0)</code> to mark the WiFi access point as
authenticated:</p>

<ol>
<li><p>on a HTTP 200 OK response, the server must set a cookie on the domain
<code>".yahoo<em>.something</em>"</code> or <code>"kr.yahoo<em>.something</em>"</code></p></li>
<li><p>on a HTTP 301/302/307 redirect, the URL (presumably the redirect location?)
must contain <code>"yahoo."</code> close to its beginning.</p></li>
</ol>


<p>If we manually contact the queried URL, <code>http://www.yahoo.co.kr/</code>, it will
redirect us to <code>https://www.yahoo.com/</code>, so everything is fine?</p>

<div><pre>GET <span>/</span> HTTP<span>/</span><span>1.1</span>
Host<span>:</span> www.yahoo.co.kr

HTTP<span>/</span><span>1.1 301</span> Moved Permanently
Location<span>:</span> https<span>://</span>www.yahoo.com<span>/</span>
</pre></div>


<p>Well, the substring <code>"yahoo."</code> is on position 12 in the url
<code>"https://www.yahoo.com/"</code>, but the code is requiring it to be in one of the
first 11 positions. This check has been killed by TLS!</p>

<p>To pass the hotspot check, we must unwind ten years of HTTPS-everywhere, or
point the DNS record to a different server that will either HTTP-redirect to a
different, more yahooey name, or set a cookie on the yahoo domain.</p>

<p>After <a href="https://github.com/ge0rg/samsung-nx-emailservice/commit/2ede8d065bf5c9ea76d9c18484aab921814b2f71">patching samsung-nx-emailservice accordingly</a>,
the camera will actually connect and upload photos:</p>

<p><img src="https://op-co.de/blog/posts/samsung_wb850f_firmware/wb850f-email-sending.jpg" alt="WB850F sending a photo"></p>

<h2><a name="index3h2"></a>Summary: the real treasure</h2>

<p>This deep-dive allowed to understand and circumvent the hotspot detection in
Samsung's WB850F WiFi camera based on one reverse-engineered function. The
resulting patch was tiny, but guessing the workaround just from the packet
traces was impossible due to the "detection method" implemented by Samsung's
engineers. Once knowing what to look for, the same workaround was applied to
cameras asking for MSN.com, thus also
<a href="https://op-co.de/blog/posts/samsung_wifi_cameras/#index2h2">adding EX2F, ST200F, WB3xF and WB1100F to the supported cameras list</a>.</p>

<p>However, the real treasure is still waiting! <code>Main_Image</code> contains over 77k
functions, so there is more than enough for a curious treasure hunter to
explore in order to better understand how digital cameras work.</p>

<hr>

<p><em><a href="https://infosec.exchange/@ge0rg/112496790871724311">Discuss on Mastodon</a></em></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Thermodynamic Natural Gradient Descent (138 pts)]]></title>
            <link>https://arxiv.org/abs/2405.13817</link>
            <guid>40466826</guid>
            <pubDate>Fri, 24 May 2024 14:50:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2405.13817">https://arxiv.org/abs/2405.13817</a>, See on <a href="https://news.ycombinator.com/item?id=40466826">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2405.13817">View PDF</a>
    <a href="https://arxiv.org/html/2405.13817v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>Second-order training methods have better convergence properties than gradient descent but are rarely used in practice for large-scale training due to their computational overhead. This can be viewed as a hardware limitation (imposed by digital computers). Here we show that natural gradient descent (NGD), a second-order method, can have a similar computational complexity per iteration to a first-order method, when employing appropriate hardware. We present a new hybrid digital-analog algorithm for training neural networks that is equivalent to NGD in a certain parameter regime but avoids prohibitively costly linear system solves. Our algorithm exploits the thermodynamic properties of an analog system at equilibrium, and hence requires an analog thermodynamic computer. The training occurs in a hybrid digital-analog loop, where the gradient and Fisher information matrix (or any other positive semi-definite curvature matrix) are calculated at given time intervals while the analog dynamics take place. We numerically demonstrate the superiority of this approach over state-of-the-art digital first- and second-order training methods on classification tasks and language model fine-tuning tasks.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Maxwell Aifer [<a href="https://arxiv.org/show-email/ce560447/2405.13817">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 22 May 2024 16:47:03 UTC (1,674 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sharing details on a recent incident impacting one of our customers (118 pts)]]></title>
            <link>https://cloud.google.com/blog/products/infrastructure/details-of-google-cloud-gcve-incident/</link>
            <guid>40466810</guid>
            <pubDate>Fri, 24 May 2024 14:48:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cloud.google.com/blog/products/infrastructure/details-of-google-cloud-gcve-incident/">https://cloud.google.com/blog/products/infrastructure/details-of-google-cloud-gcve-incident/</a>, See on <a href="https://news.ycombinator.com/item?id=40466810">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="tx2NYc"><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><p>A Google Cloud incident earlier this month impacted our customer, UniSuper, in Australia. While our first priority was to work with our customer to get them fully operational, soon after the incident started, we publicly acknowledged the incident in a joint statement with the customer.</p><p>With our customer’s systems fully up and running, we have completed our internal review. We are sharing information publicly to clarify the nature of the incident and ensure there is an accurate account in the interest of transparency. Google Cloud has taken steps to ensure this particular and isolated incident cannot happen again. The impact was very disappointing and we deeply regret the inconvenience caused to our customer.</p></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h2><span>Scope of the impact</span></h2>
<p><span>The below listed impacted technologies and services is a description of only Google managed services.</span></p>
<p><span>This incident impacted:&nbsp;</span></p>
<ul>
<li>
<p><span>One customer in one cloud region.&nbsp;</span></p>
</li>
<li>
<p><span>That customer’s use of one Google Cloud service - Google Cloud VMware Engine (GCVE).</span></p>
</li>
<li>
<p><span>One of the customer’s multiple GCVE Private Clouds (across two zones).</span></p>
</li>
</ul>
<p><span>This incident </span><strong>did not</strong><span> impact:</span></p>
<ul>
<li>
<p><span>Any other Google Cloud service.</span></p>
</li>
<li>
<p><span>Any other customer using GCVE or any other Google Cloud service.</span></p>
</li>
<li>
<p><span>The customer’s other GCVE Private Clouds, Google Account, Orgs, Folders, or Projects.&nbsp;&nbsp;&nbsp;</span></p>
</li>
<li>
<p><span>The customer’s data backups stored in Google Cloud Storage (GCS) in the same region.&nbsp;</span></p>
</li>
</ul></span></section><section><span jsaction="rcuQ6b:npT2md" jscontroller="YSybTb" data-track-type="" soy-skip="" ssk="5:kbe95"><h2><span>What happened?</span></h2>
<h4><span>TL;DR</span></h4>
<p><span>During the initial deployment of a Google Cloud VMware Engine (GCVE) Private Cloud for the customer using an internal tool, there was an inadvertent misconfiguration of the GCVE service by Google operators due to leaving a parameter blank. This had the unintended and then unknown consequence of defaulting the customer’s GCVE Private Cloud to a fixed term, with automatic deletion at the end of that period. The incident trigger and the downstream system behavior have both been corrected to ensure that this cannot happen again.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p>
<p><span>This incident did not impact any Google Cloud service other than this customer’s one GCVE Private Cloud. Other customers were not impacted by this incident.&nbsp;</span></p>
<h3><span>Diving Deeper:</span></h3>
<p><strong>Deployment using an exception process</strong></p>
<p><span>In early 2023, Google operators used an internal tool to deploy one of the customer’s GCVE Private Clouds to meet specific capacity placement needs. This internal tool for capacity management was deprecated and fully automated in Q4 2023 and is therefore no longer required (i.e. no need for human intervention).&nbsp; </span></p>
<p><strong>Blank input parameter led to unintended behavior</strong></p>
<p><span>Google operators followed internal control protocols. However, one input parameter was left blank when using an internal tool to provision the customer’s Private Cloud. As a result of the blank parameter, the system assigned a then unknown default fixed 1 year term value for this parameter.&nbsp;&nbsp;&nbsp;</span></p>
<p><span>After the end of the system-assigned 1 year period, the customer’s GCVE Private Cloud was deleted. No customer notification was sent because the deletion was triggered as a result of a parameter being left blank by Google operators using the internal tool, and not due a customer deletion request. Any customer-initiated deletion would have been preceded by a notification to the customer.</span></p>
<h3><span>Recovery</span></h3>
<p><span>The customer and Google teams worked 24x7 over several days to recover the customer’s GCVE Private Cloud, restore the network and security configurations, restore its applications, and recover data to restore full operations.&nbsp;&nbsp;</span></p>
<p><span>This was assisted by the customer’s robust and resilient architectural approach to managing risk of outage or failure.&nbsp;&nbsp;</span></p>
<p><span>Data backups that were stored in Google Cloud Storage in the same region were not impacted by the deletion, and, along with third party backup software, were instrumental in aiding the rapid restoration.</span></p>
<h3><span>Remediation</span></h3>
<p><span>Google Cloud has since taken several actions to ensure that this incident does not and can not occur again, including:</span></p>
<ol>
<li>
<p><span>We deprecated the internal tool that triggered this sequence of events. This aspect is now fully automated and controlled by customers via the user interface, even when specific capacity management is required.&nbsp;&nbsp;</span></p>
</li>
<li>
<p><span>We scrubbed the system database and manually reviewed all GCVE Private Clouds to ensure that no other GCVE deployments are at risk.&nbsp;&nbsp;&nbsp;&nbsp;</span></p>
</li>
<li>
<p><span>We corrected the system behavior that sets GCVE Private Clouds for deletion for such deployment workflows.</span></p>
</li>
</ol>
<h3><span>Conclusions&nbsp;&nbsp;</span></h3>
<ul>
<li>
<p><span>There has not been an incident of this nature within Google Cloud prior to this instance</span><span>. </span><span>It is </span><span>not</span><span> a systemic issue.&nbsp;&nbsp;</span></p>
</li>
<li>
<p><span>Google Cloud services have strong safeguards in place with a combination of soft delete, advance notification, and human-in-the-loop, as appropriate.&nbsp;</span></p>
</li>
<li>
<p><span>We have confirmed these safeguards continue to be in place.&nbsp;&nbsp;</span></p>
</li>
<li>
<p><span>Closely partnering with customers is essential to rapid recovery. The customer’s CIO and technical teams deserve praise for the speed and precision with which they executed the 24x7 recovery, working closely with Google Cloud teams.&nbsp;&nbsp;&nbsp;</span></p>
</li>
<li>
<p><span>Resilient and robust risk management with fail safes is essential to rapid recovery in case of unexpected incidents.&nbsp;</span></p>
</li>
<li>
<p><span>Google Cloud continues to have the most resilient and stable cloud infrastructure in the world. Despite this one-time incident, our uptime and resiliency is </span><a href="https://futurumgroup.com/research-reports/2023-cloud-downtime-incident-report/" rel="noopener" target="_blank"><span>independently validated</span></a><span> to be the best among leading clouds.</span></p>
</li>
</ul></span></section><section><span>Posted in</span><ul><li><a href="https://cloud.google.com/blog/products/infrastructure" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/infrastructure" track-metadata-module="tag list" track-metadata-module_headline="posted in">Infrastructure</a></li><li><a href="https://cloud.google.com/blog/topics/customers" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/topics/customers" track-metadata-module="tag list" track-metadata-module_headline="posted in">Customers</a></li><li><a href="https://cloud.google.com/blog/products/identity-security" track-metadata-position="body" track-metadata-eventdetail="cloud.google.com/blog/products/identity-security" track-metadata-module="tag list" track-metadata-module_headline="posted in">Security &amp; Identity</a></li></ul></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Morgan Spurlock has died (112 pts)]]></title>
            <link>https://www.theguardian.com/film/article/2024/may/24/super-size-me-director-morgan-spurlock-dies-aged-53</link>
            <guid>40466429</guid>
            <pubDate>Fri, 24 May 2024 14:07:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/film/article/2024/may/24/super-size-me-director-morgan-spurlock-dies-aged-53">https://www.theguardian.com/film/article/2024/may/24/super-size-me-director-morgan-spurlock-dies-aged-53</a>, See on <a href="https://news.ycombinator.com/item?id=40466429">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><figure id="7614d976-5bdd-47a5-8853-30f1dd4359a3" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:0,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot; Super Size Me was a terrific cheeky stunt – small wonder Morgan Spurlock never matched it&quot;,&quot;elementId&quot;:&quot;7614d976-5bdd-47a5-8853-30f1dd4359a3&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/film/article/2024/may/24/morgan-spurlock-cheeky-super-size-me&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:3,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"></gu-island></figure><p>Documentary-maker <a href="https://www.theguardian.com/film/morgan-spurlock" data-link-name="in body link" data-component="auto-linked-tag">Morgan Spurlock</a>, the director of films including Super Size Me and Where in the World Is Osama bin Laden? died on Thursday aged 53.</p><p>His family announced in a statement that he “passed away peacefully surrounded by family and friends in New York from complications of cancer.”</p><p>His brother Craig Spurlock said: “It was a sad day, as we said goodbye to my brother Morgan. Morgan gave so much through his art, ideas, and generosity. The world has lost a true creative genius and a special man. I am so proud to have worked with him.”</p><figure id="13302746-1f0e-45db-8fb2-20d74f9617e4" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Super Size Me in which Spurlock ate only McDonald’s for a month was nominated for best documentary at the Academy Awards." src="https://i.guim.co.uk/img/media/a3daa5a56bec2609c7c65ea07dda873b404a2f73/41_205_2926_1755/master/2926.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.9087491455913" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Super Size Me, in which Spurlock ate only McDonald’s for a month, was nominated for best documentary at the Academy Awards.</span> Photograph: Linda Nylind/The Guardian</figcaption></figure><p><a href="https://www.theguardian.com/film/2004/dec/31/dvdreviews1" data-link-name="in body link">Super Size Me</a>, released in 2004, was his first film as director, and marked a new direction in accessible, personalised gimmick-oriented documentary-making. In it, Spurlock said he planned to eat only McDonald’s food for a month, and chart the effect on his physical and mental health. It was nominated for the best documentary Oscar and was credited with raising awareness of the US’s obesity crisis. A sequel, Super Size Me 2: Holy Chicken!, in 2017, saw Spurlock running his own fast food restaurant to examine the way the food industry had changed since the first film.</p><figure id="c51baf3f-b543-4ad6-82a9-dbf2b2737a9c" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Spurlock behind bars for his 30 Days series." src="https://i.guim.co.uk/img/media/dac31dd2dd6a64c1c4017955d3a7fb9d97aa1fe0/0_217_1091_654/master/1091.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="266.75527039413385" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Spurlock behind bars for his 30 Days series.</span> Photograph: Channel 4</figcaption></figure><figure id="e84b6f84-089f-4d41-8616-32d985b1d941" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:7,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related:&quot;,&quot;text&quot;:&quot;Morgan Spurlock: ‘I asked cigarette and gun companies for money to make a film’&quot;,&quot;elementId&quot;:&quot;e84b6f84-089f-4d41-8616-32d985b1d941&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/film/2011/oct/13/morgan-spurlock&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:3,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"></gu-island></figure><p>Born and raised in West Virginia, Spurlock earned a BFA at New York university and created the stunt webcast I Bet You Will in 2002, which subsequently became a TV show. After Super Size Me’s success, Spurlock made <a href="https://www.theguardian.com/culture/2008/may/09/documentary" data-link-name="in body link">Where in the World Is Osama bin Laden?</a>, in which he attempted to track down the then-fugitive leader of al-Qaida. He also contributed to the 2010adaptation of Steven D Levitt and Stephen J Dubner’s Freakonomics (with a segment asking if names influence people’s lives) and POM Wonderful Presents: The Greatest Movie Ever Sold in 2011, investigating product placement. In 2013 Spurlock released One Direction: This Is Us, a film shot in 3D featuring the British boyband in concert and behind the scenes.</p><p>Spurlock also directed the TV show The Simpsons 20th Anniversary Special – In 3-D! On Ice!, shown in 2010. Arguably his most successful TV work was the FX series 30 Days, which ran between 2005 and 2008, in which participants took on an unlikely task or lifestyle, such as a devout Christian living with a Muslim family, or Spurlock himself living on minimum wage.</p><p>In 2017 Spurlock <a href="https://www.theguardian.com/film/2017/dec/14/super-size-me-morgan-spurlock-sexual-misconduct-twitter" data-link-name="in body link">published an open letter in which he admitted sexual misconduct</a> and <a href="https://www.washingtonpost.com/news/morning-mix/wp/2017/12/14/super-size-me-director-morgan-spurlock-wonders-when-will-they-come-for-me-and-confesses-sexual-misdeeds/" data-link-name="in body link">resigned from his production company Warrior Poets</a>.</p><p>Spurlock was formerly married to Alexandra Jamieson and Sara Bernstein, and had two sons Laken and Kallen.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't microservice, do module (102 pts)]]></title>
            <link>https://yekta.dev/posts/dont-microservice-do-module/</link>
            <guid>40465841</guid>
            <pubDate>Fri, 24 May 2024 13:09:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yekta.dev/posts/dont-microservice-do-module/">https://yekta.dev/posts/dont-microservice-do-module/</a>, See on <a href="https://news.ycombinator.com/item?id=40465841">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" role="article"> <p>The excessive use of microservices is still widespread, and this is bad for the earth! I assumed it was common knowledge
by now, but I was wrong. This article aims to clearly explain why you should <strong>minimize or eliminate</strong> the use of
microservices and opt for properly structured modular systems instead.</p>
<p><img src="https://yekta.dev/assets/rect-building.jpg.jpg" alt="Rectangular white building under blue sky" fetchpriority="high" decoding="async" width="7932" height="5291" srcset="https://yekta.dev/assets/rect-building.jpg.jpg 7932w, https://yekta.dev/assets/rect-building@3540w.jpeg 3540w, https://yekta.dev/assets/rect-building@3240w.jpeg 3240w, https://yekta.dev/assets/rect-building@2940w.jpeg 2940w, https://yekta.dev/assets/rect-building@2640w.jpeg 2640w, https://yekta.dev/assets/rect-building@2340w.jpeg 2340w, https://yekta.dev/assets/rect-building@2040w.jpeg 2040w, https://yekta.dev/assets/rect-building@1740w.jpeg 1740w, https://yekta.dev/assets/rect-building@1440w.jpeg 1440w, https://yekta.dev/assets/rect-building@1140w.jpeg 1140w, https://yekta.dev/assets/rect-building@840w.jpeg 840w" sizes="100vw"></p>
<h3 id="table-of-contents">Table of Contents</h3>
<details><summary>Open Table of Contents</summary>
<ul>
<li><a href="#importance">Importance</a></li>
<li><a href="#what-are-microservices">What are Microservices?</a></li>
<li><a href="#microservices-are-the-wrong-answer">Microservices are the Wrong Answer</a></li>
<li><a href="#microservices-vs-modules">Microservices vs. Modules</a>
<ul>
<li><a href="#team-autonomy">Team Autonomy</a></li>
<li><a href="#debugging">Debugging</a></li>
<li><a href="#fault-isolation">Fault Isolation</a></li>
<li><a href="#runtime">Runtime</a></li>
<li><a href="#versioning">Versioning</a></li>
<li><a href="#deployment">Deployment</a></li>
<li><a href="#understanding-the-codebase">Understanding the Codebase</a></li>
<li><a href="#ease-of-monitoring">Ease of Monitoring</a></li>
<li><a href="#modularity--separation">Modularity / Separation</a></li>
<li><a href="#scalability">Scalability</a></li>
<li><a href="#latency">Latency</a></li>
<li><a href="#communication">Communication</a></li>
<li><a href="#data-consistency">Data Consistency</a></li>
<li><a href="#languages">Languages</a></li>
</ul>
</li>
<li><a href="#when-should-you-consider-using-microservices">When Should You Consider Using Microservices?</a>
<ul>
<li><a href="#the-system-already-consists-of-microservices">The System Already Consists of Microservices.</a></li>
<li><a href="#there-are-already-separate-teams-each-proficient-in-a-different-tech-stack">There Are Already Separate Teams, Each Proficient in a Different Tech Stack.</a></li>
<li><a href="#you-want-to-host-already-made-services">You Want To Host Already-Made Services.</a></li>
<li><a href="#the-tooling-isnt-there">The Tooling Isn’t There.</a></li>
<li><a href="#you-want-to-increase-job-security-by-introducing-complexity">You Want To Increase Job Security by Introducing Complexity!</a></li>
</ul>
</li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
</details>
<h2 id="importance">Importance</h2>
<p>There’s a Persian proverb that goes:</p>
<blockquote>
<p>خشت اول گر نهد معمار کج ― تا ثریا می‌رود دیوار کج</p>
</blockquote>
<p>Which is a shorter form of a poem by <a href="https://en.wikipedia.org/wiki/Saib_Tabrizi">Saib Tabrizi</a>:</p>
<blockquote>
<p>چون گذارد خشت اول بر زمین معمار کج</p>
<p>گر رساند بر فلک، باشد همان دیوار کج</p>
</blockquote>
<p>Meaning:</p>
<blockquote>
<p>When the builder lays the first brick crooked on the ground,
Even if he raises it to the sky, the wall will still be crooked.</p>
</blockquote>
<p>There’s an equivalent proverb in English:</p>
<blockquote>
<p>A good beginning makes a good ending.</p>
</blockquote>
<p>Once you open the door to microservices, all the problems that come with them will follow. You suddenly “upgrade” your
monolithic software into a distributed system, and God forbid if it’s only for the hype and hearsay! This transition
suddenly makes the system more complex, harder to maintain, and harder to debug, and you’re doomed to carry that burden
for the rest of the system’s life or your career, whichever comes first. The problem is that microservices are much more
hyped than they have actual use. This chart compares some random computer science terms to show their search interest
over time, just to give you an idea of the relative hype:</p>
<figure>
  <img src="https://yekta.dev/assets/microservices-graph.png.jpg" alt="" fetchpriority="high" decoding="async" width="1959" height="554" srcset="https://yekta.dev/assets/microservices-graph.png.jpg 1959w, https://yekta.dev/assets/microservices-graph@1659w.jpeg 1659w, https://yekta.dev/assets/microservices-graph@1359w.jpeg 1359w, https://yekta.dev/assets/microservices-graph@1059w.jpeg 1059w" sizes="100vw">
  <figcaption>
    A Google Trends chart from May 2023 to May 2024, indicating the popularity of Microservices, Monolith, TDD, DDD, and
    Functional Programming. The chart shows that microservices are the most popular term among the others, with the data
    based on topics rather than literal search terms.
  </figcaption>
</figure>
<p>Microservices are a trend, but they don’t <em>deserve</em> to be. The frequency with which a developer encounters the term
“microservices” should be as rare as hearing a name like <a href="https://en.wikipedia.org/wiki/SNOBOL">SNOBOL</a>, and yet, here
we are, drowning in the microservices hype.</p>
<h2 id="what-are-microservices">What are Microservices?</h2>
<p>Before we start dissecting microservices, it’s essential to clearly establish a common ground. We’ll use the definition
provided by <a href="https://microservices.io/">microservices.io</a> as our reference point:</p>
<blockquote>
<p>What are microservices?</p>
<p>Microservices - also known as the microservice architecture - is an architectural style that structures an application
as a collection of services that are:</p>
<ul>
<li>Independently deployable</li>
<li>Loosely coupled</li>
</ul>
</blockquote>
<h2 id="microservices-are-the-wrong-answer">Microservices are the Wrong Answer</h2>
<p>A better solution by far is to use <strong>modules</strong>. Modules have been around forever, and they offer a superior approach to
addressing the problems microservices aim to solve. Let’s do a 1:1 comparison of microservices and modules. Spoiler
alert: the argument favors modules, as there is little to be said in support of microservices when pitted against
modules!</p>
<h2 id="microservices-vs-modules">Microservices vs. Modules</h2>
<h3 id="team-autonomy">Team Autonomy</h3>
<p>Is it really that challenging to instruct a team to work within a specific directory? At the end of the day, a module
can simply be a directory within the same project. Once the interface is established, each team can operate
independently, just like in microservices, as long as they adhere to the defined bounds. In this regard, there is no
difference between modular monoliths and microservices in terms of team autonomy, as clearly defined boundaries are a
requirement in both approaches.</p>
<blockquote>
<p>Hi, Jake, listen. All you need to do is to work within the <code>auth</code> directory. Implement the <code>AuthGateway</code> interface,
and you’re good to go. Meanwhile, Mike’s team can work on the <code>payment</code> directory, and Kate’s team can focus on the
<code>sync</code> directory. You have the freedom to do whatever you want within the <code>auth</code> directory, as long as you implement
the <code>AuthGateway</code> interface correctly and pass the tests.</p>
</blockquote>
<p>It’s not that complicated, is it?</p>
<h3 id="debugging">Debugging</h3>
<p>Debugging a modular monolith is undoubtedly easier than tracing a bug through a network of systems. Good luck
identifying a logical bug in a use case that spans 100 microservices - it’s a daunting task that can be a huge waste of
time. We don’t live forever, do we?</p>
<h3 id="fault-isolation">Fault Isolation</h3>
<p>When it comes to fault isolation, microservices may seem to have an advantage, but if you properly isolate modules and
keep responsibilities and concerns separate, fault isolation can be just as effective, ensuring correctness by testing
the contracts.</p>
<h3 id="runtime">Runtime</h3>
<p>I suppose there is little debate on the aspect of runtime performance. Modular monoliths introduce negligible overhead,
typically just a single function call. In contrast, microservices incur the full runtime cost for each service, from the
ground up. This includes both the operating system overhead (whether a Docker image or, worse, a virtual machine) and
the language runtime overhead (which can be particularly problematic with virtual machines, especially those like the
JVM).</p>
<h3 id="versioning">Versioning</h3>
<p>In a modular monolith, the entire system is versioned as a single unit, eliminating the need to manage each library’s
version separately. This simplification greatly reduces the time spent on versioning, saving many hours that would
otherwise be devoted to managing multiple service versions and ensuring compatibility between them. By minimizing manual
steps, the risk of human error is also decreased. In contrast, microservices require each service to be versioned
independently, allowing for more granular updates and greater flexibility. The problem is, this usually unneeded
flexibility is a liability. It introduces significant overhead in maintaining compatibility between different service
versions, ensuring consistent communication protocols, and managing multiple deployment pipelines. As a result, the
versioning aspect of microservices becomes more labor-intensive compared to a modular monolith, with increased
challenges in coordination and a higher risk of errors.</p>
<h3 id="deployment">Deployment</h3>
<p>One common claim about microservices is that they <em>can</em> be developed, deployed, and scaled independently. A more
accurate way to put it is that they <strong><em>must</em></strong> be developed, deployed, and scaled independently. This is not a benefit,
but a requirement that introduces unnecessary complexity and overhead. Before adopting microservices, you could scale
the system as a whole; now, you <strong>must</strong> inspect every container to determine if any require additional resources. The
entire system has become larger and more resource-intensive. Not only do you need to consider the runtime requirements
of each container, but also the fact that we typically allocate more resources than each service needs. This is
necessary for a monolith but becomes excessively wasteful with hundreds of microservices.</p>
<p>Now compare the ease of shipping: is it harder to ship a modular monolith or hundreds of interconnected services? The
answer is clear. The <a href="#what-are-microservices">very definition</a> of microservices is to be independently deployable. Even
if deploying each service is as easy as deploying a monolith, there are still <em>N</em> of them in a system with a
microservices architecture.</p>
<h3 id="understanding-the-codebase">Understanding the Codebase</h3>
<p>When working with a modular monolith, you don’t want to navigate through all directories to understand a specific part
of the system. The main difference in terms of understanding the codebase is that instead of knowing the name of the
repository or project, you need to know the directory in which the module is located. This is the only major difference
when it comes to comprehending the subsystem.</p>
<h3 id="ease-of-monitoring">Ease of Monitoring</h3>
<p>With a monolithic architecture, your system is either <code>UP</code> or <code>DOWN</code>, with no in-between. With microservices, you need
to monitor every service. All the services need to be <code>UP</code>, and they need to be able to communicate with each other, all
for you to be able to say the system is <code>UP</code>. If even one out of your 888 services is down, the system can no longer be
called <code>UP</code>!</p>
<h3 id="modularity--separation">Modularity / Separation</h3>
<p>Separation is probably the most helpful concept in understanding and maintaining a system. However, if one uses
microservices solely as a solution for separation, it signals a skill issue. The division unit of software is, and
always has been, modules. Software should be separated by modules. If one doesn’t properly use modules to split the code
because they <em>can</em> avoid it, that’s another story! Compared to modules, microservices should count as a
hack. Think about it. It’s like you don’t like to have two chairs in your room, and instead of moving one chair to
another room, you build a new house (hopefully in your own neighborhood) with an empty room just to put that chair in
it. To put it bluntly, this is precisely what microservices are most of the time. They are a hack to avoid properly
modularizing the project or for teams that lack effective communication to do so. So, to separate software that has
high-level concerns (which it usually has), modules are most of the time the better solution, not microservices, unless
it is not reasonable, which is explained at the end. The key point in both is to <strong>properly</strong> separate the concerns. If
you cannot do it with modules, you won’t be able to do it with microservices either.</p>
<h3 id="scalability">Scalability</h3>
<p>Why would you ever want to allocate more resources to one particular part? It’s not like the other parts will eat up the
extra resources. If your system needs more RAM, it needs more RAM. Why would you care about <em>which</em> part needs more
RAM?</p>
<h3 id="latency">Latency</h3>
<p>Microservices introduce a <strong>lot</strong> of overhead in terms of communication latency. We’re comparing something like a
function call to a network call. Even if fully emulated, there should be around an order of magnitude difference in
terms of latency, let alone the actual network overhead.</p>
<h3 id="communication">Communication</h3>
<p>When microservices communicate with one another, a simple function call in a monolithic system becomes a network call,
requiring a network protocol, serialization, message brokers, or even a service mesh. This makes your system as a whole
harder to debug. Not only do you need to debug the functionality of different parts, but you also need to debug the
communication between them, which most likely would otherwise be a push into a call stack. It’s worth reminding
ourselves of the “crooked wall” proverb here!</p>
<h3 id="data-consistency">Data Consistency</h3>
<p>If you implement microservices correctly, you will most likely need to duplicate some data (microservices
by <a href="#what-are-microservices">definition</a> are loosely coupled). The data consistency that was once the responsibility of
the RDBMS is now the responsibility of the developer. This is a huge, unnecessary burden. Apart from this, if you ever
need to join two tables, you’re in for a treat! You need to reinvent some of the RDBMS features in the application
layer.</p>
<h3 id="languages">Languages</h3>
<p>If you <strong>need</strong> to use different languages, that could be an actual benefit of microservices over modules, depending on
your tech stack, since some technologies might allow the easy use of different languages in the same project. However,
one should ensure that this is an actual need. Diversity might sound cool, but it is not what you want in software. It
is even painful at the level of different timestamp types, let alone different languages for each subsystem.</p>
<h2 id="when-should-you-consider-using-microservices">When Should You Consider Using Microservices?</h2>
<p><img src="https://yekta.dev/assets/green-rope-meshwork.jpg.webp" alt="Green rope mesh work" loading="lazy" decoding="async" width="5184" height="3456" srcset="https://yekta.dev/assets/green-rope-meshwork.jpg.webp 5184w, https://yekta.dev/assets/green-rope-meshwork@3540w.webp 3540w, https://yekta.dev/assets/green-rope-meshwork@3240w.webp 3240w, https://yekta.dev/assets/green-rope-meshwork@2940w.webp 2940w, https://yekta.dev/assets/green-rope-meshwork@2640w.webp 2640w, https://yekta.dev/assets/green-rope-meshwork@2340w.webp 2340w, https://yekta.dev/assets/green-rope-meshwork@2040w.webp 2040w, https://yekta.dev/assets/green-rope-meshwork@1740w.webp 1740w, https://yekta.dev/assets/green-rope-meshwork@1440w.webp 1440w, https://yekta.dev/assets/green-rope-meshwork@1140w.webp 1140w, https://yekta.dev/assets/green-rope-meshwork@840w.webp 840w" sizes="100vw"></p>
<p>You may consider using microservices when:</p>
<h3 id="the-system-already-consists-of-microservices">The System Already Consists of Microservices.</h3>
<p>If it ain’t broke, don’t fix it, unless you plan a rewrite.</p>
<h3 id="there-are-already-separate-teams-each-proficient-in-a-different-tech-stack">There Are Already Separate Teams, Each Proficient in a Different Tech Stack.</h3>
<p>To avoid the overhead of teaching another team the new stack, it may be better to consider the trade-off of pushing that
overhead into the communication between the two services.</p>
<p><strong>⚠️ Heads up!</strong></p>
<p>If there are no teams yet, but you’re planning to have them, it would be wise to plan to use a single language if there
is no severe need for multiple languages. As mentioned <a href="#languages">above</a>, technology diversity for the sake of
diversity brings nothing but problems. Yes, the teams won’t need to know what happens in other systems, but that’s only
true until a change in the team happens. Teams are not immutable! If there are multiple teams with different stacks in
the future, unless you have a clear, strong reason for it, stop it and decrease some pain for your future.</p>
<h3 id="you-want-to-host-already-made-services">You Want To Host Already-Made Services.</h3>
<p>If you’re planning to use a service that is already made, you won’t have a better option; use that part as a separate
service.</p>
<h3 id="the-tooling-isnt-there">The Tooling Isn’t There.</h3>
<p>When the tooling you need for a particular task isn’t available or isn’t good enough based on your requirements in the
language you’re using, and you really need to write one part in a particular language, go for it, with caution.</p>
<h3 id="you-want-to-increase-job-security-by-introducing-complexity">You Want To Increase Job Security by Introducing Complexity!</h3>
<p>No explanation is needed! Please don’t!</p>
<h2 id="conclusion">Conclusion</h2>
<p>Microservices have gained significant popularity, driven more by hype than necessity, and often introduce more
complexity and overhead than they resolve. A modular monolith offers the same benefits of independence and separation
without the additional challenges. By focusing on proper modularization, teams can achieve these benefits without the
drawbacks. Unless your specific use case demands the unique advantages of microservices, it is wiser to stick with a
well-structured monolith. Remember, a solid foundation is crucial; laying the first brick correctly is the first step to
avoid building a crooked wall.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Unacceptable": Spotify bricking Car Thing devices in Dec. without refunds (131 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/05/pleas-for-open-sourcing-refunds-as-spotify-plans-to-brick-car-thing-devices/</link>
            <guid>40465102</guid>
            <pubDate>Fri, 24 May 2024 11:38:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/05/pleas-for-open-sourcing-refunds-as-spotify-plans-to-brick-car-thing-devices/">https://arstechnica.com/gadgets/2024/05/pleas-for-open-sourcing-refunds-as-spotify-plans-to-brick-car-thing-devices/</a>, See on <a href="https://news.ycombinator.com/item?id=40465102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      Car Thing becoming nothing    —
</h4>
            
            <h2 itemprop="description">Spotify stopped making Car Things in July 2022 but kept selling them. </h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2022/07/car-thing-800x600.jpg" alt="“Unacceptable”: Spotify bricking Car Thing devices in Dec. without refunds">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 110:single/related:7a0f5441cc0709fcb3e60bcfb5e0750a --><!-- empty -->
<p>Owners of Spotify's soon-to-be-bricked Car Thing device are begging the company to open-source the gadgets to save some the landfill. Spotify hasn't responded to pleas to salvage the hardware, which was originally intended to connect to car dashboards and auxiliary outlets to enable drivers to listen to and navigate Spotify.</p>
<p>Spotify announced today that it's bricking all purchased Car Things on December 9 and not offering refunds or trade-in options. On a <a href="https://support.spotify.com/us/article/car-thing-discontinued/">support page</a>, Spotify says:</p>
<blockquote><p>We're discontinuing Car Thing as part of our ongoing efforts to streamline our product offerings. We understand it may be disappointing, but this decision allows us to focus on developing new features and enhancements that will ultimately provide a better experience to all Spotify users.</p></blockquote>
<p>Spotify has no further guidance for device owners beyond asking them to reset the device to factory settings and “safely” get rid of the bricked gadget by “following local electronic waste guidelines.”</p>
<p>The company also said that it doesn’t plan to release a follow-up to the Car Thing.</p>
<h2>Early demise</h2>
<p>Car Thing came out to limited subscribers in October 2021 before <a href="https://arstechnica.com/gadgets/2022/02/spotify-car-thing-is-a-90-thing-that-plays-spotify-in-your-car/">releasing to the general public</a> in February 2022.</p>
<p>In its Q2 2022 earnings report released in July, Spotify revealed that it <a href="https://arstechnica.com/gadgets/2022/07/spotify-is-no-longer-making-its-car-thing-music-player/">stopped making Car Things. </a>In a chat with <a href="https://techcrunch.com/2022/07/27/spotify-exits-short-lived-car-thing-hardware-play-as-reports-q2-maus-of-433m-offsetting-russia-exit-and-service-outage/">TechCrunch</a>, it cited "several factors, including product demand and supply chain issues." A Spotify rep also told the publication that the devices would continue to “perform as intended,” but that was apparently a temporary situation.</p>
<p>Halted production was a warning sign that Car Thing was in peril. However, at that time, Spotify also cut the device’s price from $90 to $50, which could have encouraged people to buy a device that would be useless a few years later.</p>
<p>Car Thing's usefulness was always dubious, though. The device has a 4-inch touchscreen and knob for easy navigation, as well as support for Apple CarPlay, Android Auto, and voice control. But it also required users to subscribe to Spotify Premium, which starts at $11 per month. Worse, Car Thing requires a phone using data or Wi-Fi connected via Bluetooth in order to work, making the Thing seem redundant.</p>                                            
                                                        
<p>In its Q1 2022 report, Spotify said that quitting Car Thing hurt gross margins and that it took a 31 million euro (about $31.4 million at the time) hit on the venture.</p>
<h2>Open source pleas</h2>
<p>Spotify's announcement has sent some Car Thing owners to online forums to share their disappointment with Spotify and beg the company to open-source the device instead of dooming it for recycling centers at best. As of this writing, there are over 50 posts on the <a href="https://community.spotify.com/t5/forums/searchpage/tab/message?advanced=false&amp;allow_punctuation=false&amp;q=car%20thing">Spotify Community</a> forums showing concern about the discontinuation, with many demanding a refund and/or calling for open-sourcing. There are similar discussions happening elsewhere online, <a href="https://www.reddit.com/r/CarThing/">like on Reddit</a>, where users have used phrases like "<a href="https://www.reddit.com/r/spotify/comments/1cyx5fs/comment/l5ckxkv/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button">entirely unnacceptable</a>" to describe the news.</p>
<p>A Spotify Community member going by AaronMickDee, for example, <a href="https://community.spotify.com/t5/Live-Ideas/With-Car-Thing-being-sunsetted-would-you-open-source-the-device/idi-p/6088742">said</a>:</p>
<blockquote><p>I'd rather not just dispose of the device. I think there is a community that would love the idea of having a device we can customize and use for other uses other than a song playback device.</p>
<p>Would Spotify be willing to maybe unlock the system and allow users to write/flash 3rd party firmware to the device?</p></blockquote>
<p>A Spotify spokesperson declined to answer Ars' questions about why Car Thing isn't being open-sourced and concerns around e-waste and wasted money.</p>
<p>Instead, a company rep told Ars, in part: “The goal of our Car Thing exploration in the US was to learn more about how people listen in the car. <a href="https://newsroom.spotify.com/2022-07-27/spotify-reports-second-quarter-2022-earnings/">In July 2022,</a> we announced we’d stop further production and now it’s time to say goodbye to the devices entirely." I followed up with Spotify's rep to ask again about making the device open source but didn't hear back.</p>
<p>At this point, encouraging customers to waste nearly $100 on a soon-obsolete device hasn't resulted in any groundbreaking innovations or lessons around "how people listen in the car." In their initial response, Spotify's rep pointed me to a <a href="https://newsroom.spotify.com/?s=how+to+listen+to+spotify+in+the+car">Spotify site</a> that searches Spotify's newsroom for "how to listen to Spotify in the car." One of the <a href="https://newsroom.spotify.com/2019-08-26/how-to-listen-to-spotify-in-the-car/">top posts </a>is from 2019 and states that “if your car has an AUX or USB socket, using a cable is probably one of the fastest ways to connect by using your phone."</p>
<p>As for Spotify, using customer dollars for company-serving learning experiences isn't the best business plan. And for regular users, it's best to avoid investing in an unproven hardware venture from a software company.</p>
<p>As Redditor Wemie1420 <a href="https://www.reddit.com/r/CarThing/comments/1cywpze/comment/l5ccejb/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button">put it</a>:</p>
<blockquote><p>Doesn’t feel great that there is literally no alternative other than trashing it. Feels like we’re being punished for supporting them. Dissuades me from buying anything Spotify puts out in the future. I feel like there would be some way to approach this without being like, 'yeah we’re done. Just throw it out it’s a waste of money now.'</p></blockquote>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple's M4 has reportedly adopted the ARMv9 architecture (147 pts)]]></title>
            <link>https://wccftech.com/apple-m4-adopts-armv9-run-complex-workloads-efficiently/</link>
            <guid>40465090</guid>
            <pubDate>Fri, 24 May 2024 11:37:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wccftech.com/apple-m4-adopts-armv9-run-complex-workloads-efficiently/">https://wccftech.com/apple-m4-adopts-armv9-run-complex-workloads-efficiently/</a>, See on <a href="https://news.ycombinator.com/item?id=40465090">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

			

			
			
			
			<p>The <a href="https://wccftech.com/apple-m4-officially-announced/">M4</a>&nbsp;was officially announced during Apple’s ‘Let Loose’ event, with the company praising the 10-core CPU version in droves. What thoroughly impressed us was when we reported that the latest chipset <a href="https://wccftech.com/apple-m4-multi-score-faster-than-m3-and-m2/">beat the M3 and M2 comprehensively</a>&nbsp;while also managing a healthy lead against the M3 Pro and Snapdragon X Elite.</p>
<p>While some might attribute these performance gains to Apple switching to TSMC’s second-generation 3nm process for the M4, various findings reveal that the company has switched to the ARMv9 architecture with this release. In short, the new Apple Silicon can now run more complex tasks efficiently, which may also explain its high single-core and multi-core scores in Geekbench 6.</p>
<h2>The biggest advantage that M4 has against the competition is support for Scalable Matrix Extension (SME), which helps raise performance across the board</h2>
<p>With a 45 percent multi-core lead against the M2, raising the performance cores’ frequency to 4.40GHz and increasing the overall CPU core count is not the only change that Apple had to implement to reach a new score in Geekbench 6. According to YouTuber <a href="https://twitter.com/VadimYuryev/status/1788607053361189307" target="_blank" rel="noopener">Vadim Yuryev</a>, the M4 is now made using the ARMv9 instructions set, which is superior to NEON and allows the chipset to run complex workloads efficiently.</p>
<p>The content creator is not the only one who shared similar findings on X because a tipster going by the handle <a href="https://twitter.com/negativeonehero/status/1788576876468007209" target="_blank" rel="noopener">@negativeonehero</a> also revealed through an external rumor that the M4 has support for SME or Scalable Matrix Extension. A discussion is happening under the tipster’s thread, contemplating if SME has actually benefitted the M4 in Geekbench 6’s single-core and multi-core performance runs.</p>
<blockquote data-width="500" data-dnt="true">
<p lang="en" dir="ltr">M4 chip is finally using ARMv9 architecture which supports SME/SVE2 which means it can more efficiently run more complex workloads compared to previous NEON.</p>
<p>This means Geekbench scores might be higher than regular CPU rendering performance.</p>
<p>But for consumers, Geekbench is KING <a href="https://t.co/UZz01XpXl2">https://t.co/UZz01XpXl2</a> <a href="https://t.co/cKX9qSBLr2">pic.twitter.com/cKX9qSBLr2</a></p>
<p>— Vadim Yuryev (@VadimYuryev) <a href="https://twitter.com/VadimYuryev/status/1788607053361189307?ref_src=twsrc%5Etfw">May 9, 2024</a></p></blockquote>

<p>The replies given seem to indicate that this is the case while also mentioning that the Snapdragon 8 Gen 4 will lack SME since it is based on the Snapdragon X Elite. This claim suggests that Qualcomm’s upcoming SoC could potentially be slower than the A18 Pro since the latter is also said to switch to the ARMv9 architecture, granting it similar performance attributes to the M4.</p>
<blockquote data-width="500" data-dnt="true">
<p lang="en" dir="ltr">It might be true 👀 <a href="https://t.co/dEtFS7JJpl">https://t.co/dEtFS7JJpl</a> <a href="https://t.co/FtfU8QJ4QV">pic.twitter.com/FtfU8QJ4QV</a></p>
<p>— Nguyen Phi Hung (@negativeonehero) <a href="https://twitter.com/negativeonehero/status/1788576876468007209?ref_src=twsrc%5Etfw">May 9, 2024</a></p></blockquote>

<p>The interesting thing about these findings is that Apple did not mention that the M4 supports the new ARMv9 architecture. Stating this intricate detail while delivering on some benchmark comparisons might have excited more people about the latest release. It is possible that the company will divulge this information when it unveils the A18 and A18 Pro for the iPhone 16 family later this year, as that might force consumers to upgrade to the latest models. We will view more findings to be positively sure that the M4’s adoption of ARMv9 architecture is the reason for its massive performance gains, so stay tuned for more updates.</p>

				

			

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anger Does a Lot More Damage to Your Body Than You Realize (106 pts)]]></title>
            <link>https://www.wsj.com/health/wellness/anger-health-effects-risks-heart-brain-mental-f4105ed7</link>
            <guid>40464887</guid>
            <pubDate>Fri, 24 May 2024 11:02:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/health/wellness/anger-health-effects-risks-heart-brain-mental-f4105ed7">https://www.wsj.com/health/wellness/anger-health-effects-risks-heart-brain-mental-f4105ed7</a>, See on <a href="https://news.ycombinator.com/item?id=40464887">Hacker News</a></p>
Couldn't get https://www.wsj.com/health/wellness/anger-health-effects-risks-heart-brain-mental-f4105ed7: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Voxel Displacement Renderer – Modernizing the Retro 3D Aesthetic (280 pts)]]></title>
            <link>https://blog.danielschroeder.me/2024/05/voxel-displacement-modernizing-retro-3d/</link>
            <guid>40464558</guid>
            <pubDate>Fri, 24 May 2024 09:54:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.danielschroeder.me/2024/05/voxel-displacement-modernizing-retro-3d/">https://blog.danielschroeder.me/2024/05/voxel-displacement-modernizing-retro-3d/</a>, See on <a href="https://news.ycombinator.com/item?id=40464558">Hacker News</a></p>
Couldn't get https://blog.danielschroeder.me/2024/05/voxel-displacement-modernizing-retro-3d/: Error: Request failed with status code 502]]></description>
        </item>
        <item>
            <title><![CDATA[Kabosu, the Dog Behind the 'Doge' Meme, Has Died (245 pts)]]></title>
            <link>https://www.ign.com/articles/kabosu-the-dog-behind-the-doge-meme-has-died</link>
            <guid>40464495</guid>
            <pubDate>Fri, 24 May 2024 09:40:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ign.com/articles/kabosu-the-dog-behind-the-doge-meme-has-died">https://www.ign.com/articles/kabosu-the-dog-behind-the-doge-meme-has-died</a>, See on <a href="https://news.ycombinator.com/item?id=40464495">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Kabosu, the dog behind the ‘doge’ meme, has died at the age of 18, according to her owner. The Japanese shiba inu had been suffering from leukaemia and liver disease.</p><p>"To all of you who loved Kabosu, on the morning of the 24 May, Kabosu crossed the rainbow bridge. Thank you all so much for your support over the years," Atsuko Sato, her owner, said in a post on Instagram as well as in a <a href="https://kabochan.blog.jp/archives/51831907.html" target="_blank" rel="noopener noreferrer">blog post</a>.</p><p>"She went very peacefully without suffering, as if falling asleep while feeling the warmth of my hands petting her. Thank you all so much for loving Kabosu all these years. I am certain Kabosu was the happiest dog in the world. That makes me the happiest owner in the world. I would like to express my deepest appreciation to everyone who has sent us much love to us."</p><output><figure><a href="https://assets-prd.ignimgs.com/2024/05/24/screenshot-20240524-092546-instagram-1716539261237.jpg" target="_blank" rel="noopener noreferrer"><img decoding="async" alt="Image credit: Instagram." src="https://assets-prd.ignimgs.com/2024/05/24/screenshot-20240524-092546-instagram-1716539261237.jpg?width=1280&amp;fit=bounds&amp;height=720&amp;quality=20&amp;dpr=0.05"></a><figcaption>Image credit: Instagram.</figcaption></figure></output><p>Sato, a teacher in Japan, adopted Kabosu in 2008 when she was sent to an animal shelter after her puppy mill shut down. Kabosu became an internet sensation after a 2010 photo of her posted to Sato's personal blog showing Kabosu appearing to smirk was referred to online as “Doge”, an intentional misspelling of dog. The meme itself includes comic sans text that represents an internal monologue deliberately written in broken English.</p><p>Doge would go on to inspire a cryptocurrency called Dogecoin which Elon Musk has repeatedly tweeted about — often corresponding with a brief surge in value, and a non-fungible token (NFT) that sold for $4 million.</p><output><figure><a href="https://assets-prd.ignimgs.com/2024/05/24/big-dog-1716540169886.jpg" target="_blank" rel="noopener noreferrer"><img decoding="async" alt="Image credit: Atsuko Sato." src="https://assets-prd.ignimgs.com/2024/05/24/big-dog-1716540169886.jpg?width=1280&amp;fit=bounds&amp;height=720&amp;quality=20&amp;dpr=0.05"></a><figcaption>Image credit: Atsuko Sato.</figcaption></figure></output><p>In December 2022, Sato revealed that Kabosu was seriously sick with cancer and an acute liver disease, saying she was in a "very dangerous condition" after being diagnosed with chronic lymphoma leukemia and acute cholangiohepatitis, which is characterized by an inflamed liver.</p><p><em>Wesley is the UK News Editor for IGN. Find him on Twitter at @wyp100. You can reach Wesley at wesley_yinpoole@ign.com or confidentially at wyp100@proton.me.</em></p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lewis Carroll – computing the day of the week for any given date (1887) (155 pts)]]></title>
            <link>https://www.futilitycloset.com/2024/05/24/day-tripper/</link>
            <guid>40464303</guid>
            <pubDate>Fri, 24 May 2024 08:56:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.futilitycloset.com/2024/05/24/day-tripper/">https://www.futilitycloset.com/2024/05/24/day-tripper/</a>, See on <a href="https://news.ycombinator.com/item?id=40464303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
		<main id="main" role="main">

		
			
<article id="post-67489">
	
	<div>
			<p>A letter from Lewis Carroll to <a href="https://www.nature.com/articles/035517a0"><em>Nature</em></a>, March 31, 1887:</p>
<blockquote><p>
Having hit upon the following method of mentally computing the day of the week for any given date, I send it you in the hope that it may interest some of your readers. I am not a rapid computer myself, and as I find my average time for doing any such question is about 20 seconds, I have little doubt that a rapid computer would not need 15.</p>
<p>Take the given date in 4 portions, viz. the number of centuries, the number of years over, the month, the day of the month.</p>
<p>Compute the following 4 items, adding each, when found, to the total of the previous items. When an item or total exceeds 7, divide by 7, and keep the remainder only.</p>
<p><em>The Century-Item.</em> — For Old Style (which ended September 2, 1752) subtract from 18. For New Style (which began September 14) divide by 4, take overplus from 3, multiply remainder by 2. [The Century-Item is the first two digits of the year, so for 1811 take 18.]</p>
<p><em>The Year-Item.</em> — Add together the number of dozens, the overplus, and the number of 4’s in the overplus.</p>
<p><em>The Month-Item.</em> — If it begins or ends with a vowel, subtract the number, denoting its place in the year, from 10. This, plus its number of days, gives the item for the following month. The item for January is ‘0’; for February or March (the 3rd month), ‘3’; for December (the 12th month), ’12.’ [So, for clarity, the required final numbers after division by 7 are January, 0; February, 3; March, 3; April, 6; May, 1; June, 4; July, 6; August 2; September, 5; October, 0; November, 3; and December, 5.]</p>
<p><em>The Day-Item</em> is the day of the month.</p>
<p>The total, thus reached, must be corrected, by deducting ‘1’ (first adding 7, if the total be ‘0’), if the date be January or February in a Leap Year: remembering that every year, divisible by 4, is a Leap Year, excepting only the century-years, in New Style, when the number of centuries is <em>not</em> so divisible (<em>e.g.</em> 1800).</p>
<p>The final result gives the day of the week, ‘0’ meaning Sunday, ‘1’ Monday, and so on.</p>
<p>Examples</p>
<p>1783, <em>September</em> 18</p>
<p>17, divided by 4, leaves ‘1’ over; 1 from 3 gives ‘2’; twice 2 is ‘4.’</p>
<p>83 is 6 dozen and 11, giving 17; plus 2 gives 19, <em>i.e.</em> (dividing by 7) ‘5.’ Total 9, <em>i.e.</em> ‘2.’</p>
<p>The item for August is ‘8 from 10,’ <em>i.e.</em> ‘2’; so, for September, it is ‘2 plus 3,’ <em>i.e.</em> ‘5.’ Total 7, <em>i.e.</em> ‘0,’ which goes out.</p>
<p>18 gives ‘4.’ Answer, <em>‘Thursday.’</em></p>
<p>1676, <em>February</em> 23</p>
<p>16 from 18 gives ‘2.’</p>
<p>76 is 6 dozen and 4, giving 10; plus 1 gives 11, <em>i.e.</em> ‘4.’ Total ‘6.’</p>
<p>The item for February is ‘3.’ Total 9, <em>i.e.</em> ‘2.’</p>
<p>23 gives ‘2.’ Total ‘4.’</p>
<p>Correction for Leap Year gives ‘3.’ Answer, <em>‘Wednesday.’</em>
</p></blockquote>
<p>(Via Edward Wakeling, <a href="https://archive.org/details/rediscoveredlewi00carr/page/10/mode/2up"><em>Rediscovered Lewis Carroll Puzzles</em></a>, 1995.)</p>

					</div><!-- .entry-content -->
</article><!-- #post-## -->
				<!-- .navigation -->
	
			
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[2D Rigid Body Collision Resolution (433 pts)]]></title>
            <link>https://www.sassnow.ski/rigid-body-collisions/1</link>
            <guid>40463764</guid>
            <pubDate>Fri, 24 May 2024 07:23:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sassnow.ski/rigid-body-collisions/1">https://www.sassnow.ski/rigid-body-collisions/1</a>, See on <a href="https://news.ycombinator.com/item?id=40463764">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="_2d-rigid-body-collision-resolution-part-1-defining-the-problem"><!--[-->
    <span>2D Rigid Body Collision Resolution</span><br>
    <span>Part 1: Defining the problem</span><!--]--></h2><p><!--[-->From Mario bouncing off a Goomba to two cars bumping into each other in a racing
game, dealing with collisions is such an integral part of most video games that
we often take it for granted.<!--]--></p><p><!--[-->In this series of blog posts, I want to show you what actually goes on behind the
scenes in a physics simulation like the one above.
While we're going to look at this through the lens video games, this post is
really about the actual math and physics of collisions.
Video games are just a nice way to contextualize these concepts and help make
things a little less abstract.<!--]--></p><div><p>A word about math</p><!--[--><p><!--[-->While these articles will involve a fair bit of math, please don't be discouraged
by that if you don't consider yourself to be a "math person".
I think this kind of thinking is harmful and actively prevents you from engaging
with topics that you might actually enjoy!<!--]--></p><p><!--[-->Many times, it's the math <em><!--[-->notation<!--]--></em> that makes things look more complicated
than they actually are because it's so information-dense and unfamiliar.
Most of the math in these articles will be fairly straight-forward arithmetic
but dressed up to look fancy!<!--]--></p><p><!--[-->This is something that's really dear to my heart.
I think too many people have this instinctive reaction of
<em><!--[-->"I'm not smart enough to understand this"<!--]--></em> whenever they see any kind of math
notation.
While I can definitely empathize with this, I encourage you to fight this
reaction because at some point it becomes a self-fulfilling prophecy.<!--]--></p><!--]--></div><h2 id="before-we-start"><a href="#before-we-start"><!--[-->Before we start<!--]--></a></h2><p><!--[-->Let's set our expectations and define a few terms.<!--]--></p><h3 id="rigid-bodies"><a href="#rigid-bodies"><!--[-->Rigid bodies<!--]--></a></h3><p><!--[-->The specific kind of physics simulation we are going to cover is called
<strong><!--[-->rigid body physics<!--]--></strong>.
A <strong><!--[-->rigid body<!--]--></strong> is a body that does not deform when subjected to forces.
This is an idealized model because true rigid bodies do not exist in the real
world; everything deforms on the molecular level even if this deformation
is not visible to the naked eye.<!--]--></p><p><!--[-->For most physics simulations, trying to simulate this level of detail is not
only extremely difficult (if not flat out impossible) and computationally
expensive, it's also unnecessary.
As long as our bodies behave realistically, we're allowed to simplify as much
as we want.
Rigid bodies are one such simplification.<!--]--></p><p><!--[-->This might sound a little abstract at the moment but will hopefully start to
make sense as we work through our examples.<!--]--></p><h3 id="collision-detection-vs-collision-resolution"><a href="#collision-detection-vs-collision-resolution"><!--[-->Collision detection vs. collision resolution<!--]--></a></h3><p><!--[-->In a video game engine, dealing with collisions can be broken down into two
distinct phases: <strong><!--[-->collision detection<!--]--></strong> and <strong><!--[-->collision resolution<!--]--></strong>.<!--]--></p><p><!--[-->Collision detection is about determining which bodies in our scene are
colliding.
This usually involves a bunch of geometry to check if two shapes are
intersecting or overlapping.
Depending on how many objects there are in our scene, this can be quite
computationally expensive and is usually heavily optimized.
The result of this step is then used in the collision resolution step.<!--]--></p><p><!--[-->Collision resolution is the process of figuring out what needs to happen to
two colliding bodies based on things like their current movement directions,
speeds, materials, and many other things.<!--]--></p><p><!--[-->In this series of blog posts, we're only looking at the <strong><!--[-->collision resolution<!--]--></strong>
phase as this where all the interesting physics happens.<!--]--></p><p><!--[-->Ok, enough preamble. Let's get started!<!--]--></p><h2 id="what-are-we-trying-to-do"><a href="#what-are-we-trying-to-do"><!--[-->What are we trying to do?<!--]--></a></h2><p><!--[-->Let's start out by trying to define the problem we're trying to solve.<!--]--></p><p><!--[-->Most games run in a big loop. In order to make things move on the screen, the
game engine needs to continually calculate the positions of the various objects
in the scene.
So on each iteration of the game loop, the position of each of object
gets updated a tiny amount based on its current <strong><!--[-->velocity<!--]--></strong>.<!--]--></p><p><!--[-->Velocity is a vector quantity, meaning it has both a magnitude and a direction.
We can represent an object's current velocity with an arrow where the length of
the arrow represents the object's current speed and the direction the arrow
is pointing its travel direction.<!--]--></p><p><!--[-->In the demonstration below, you can change the box's
<strong><!--[--><span>velocity</span><!--]--></strong> by dragging the <strong><!--[--><span>arrow</span><!--]--></strong> around.
If you ever get lost in space, you can always reset the simulation with the
<span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor"><path fill-rule="evenodd" d="M10 4.5c1.215 0 2.417.055 3.604.162a.68.68 0 01.615.597c.124 1.038.208 2.088.25 3.15l-1.689-1.69a.75.75 0 00-1.06 1.061l2.999 3a.75.75 0 001.06 0l3.001-3a.75.75 0 10-1.06-1.06l-1.748 1.747a41.31 41.31 0 00-.264-3.386 2.18 2.18 0 00-1.97-1.913 41.512 41.512 0 00-7.477 0 2.18 2.18 0 00-1.969 1.913 41.16 41.16 0 00-.16 1.61.75.75 0 101.495.12c.041-.52.093-1.038.154-1.552a.68.68 0 01.615-.597A40.012 40.012 0 0110 4.5zM5.281 9.22a.75.75 0 00-1.06 0l-3.001 3a.75.75 0 101.06 1.06l1.748-1.747c.042 1.141.13 2.27.264 3.386a2.18 2.18 0 001.97 1.913 41.533 41.533 0 007.477 0 2.18 2.18 0 001.969-1.913c.064-.534.117-1.071.16-1.61a.75.75 0 10-1.495-.12c-.041.52-.093 1.037-.154 1.552a.68.68 0 01-.615.597 40.013 40.013 0 01-7.208 0 .68.68 0 01-.615-.597 39.785 39.785 0 01-.25-3.15l1.689 1.69a.75.75 0 001.06-1.061l-2.999-3z" clip-rule="evenodd"></path></svg></span>
button.<!--]--></p><p><!--[-->Velocity describes the <strong><!--[-->change in position<!--]--></strong> of an object over a certain time
interval <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\Delta t</annotation></semantics></math></span></span></span>.
In physics, this change in position is called <strong><!--[-->displacement<!--]--></strong> and is usually
denoted <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>s</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{s}</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->Whenever you see a little arrow over a variable like this <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>s</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{s}</annotation></semantics></math></span></span></span>,
this means that the variable is a vector.
Therefore, we can see that displacement is also a vector quantity, meaning it
has both magnitude and direction.<!--]--></p><p><!--[-->In order to find an object's new position, we first calculate the displacement
based on the object's current velocity.<!--]--></p><p><!--[-->Where <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\Delta t</annotation></semantics></math></span></span></span> is the time that has passed since the last iteration
of our game loop.
So if our game loop runs 60 times per second, then <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">\Delta t</annotation></semantics></math></span></span></span> would
be <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mn>60</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{60}</annotation></semantics></math></span></span></span> of a second.
We then add the displacement to the object's current position to get its new
position for the current frame.<!--]--></p><p><!--[-->We do this for every object in our scene and lo' and behold. Things are moving!<!--]--></p><p><!--[-->What happens if the new positions of two objects would cause their geometries to
overlap?<!--]--></p><p><!--[-->The scene below shows two objects and their current
<strong><!--[--><span>velocities</span><!--]--></strong> on a certain frame in our game loop.<!--]--></p><!--[--><!----><!--]--><p><!--[-->Let's think about what would happen if we didn't do anything special and simply
continued with the next iteration of our game loop.<!--]--></p><p><!--[-->In this case, the physics engine would update each objects' positions as usual
based on its current <strong><!--[--><span>velocity</span><!--]--></strong>.
This would cause the objects to penetrate each other and eventually pass through
each other.<!--]--></p><p><!--[-->You can see this happening in the demonstration below by dragging the
<strong><!--[--><span>slider</span><!--]--></strong> to progress time.<!--]--></p><!--[--><div><p>Without collision resolution</p></div><!--]--><p><!--[-->This situation, where continuing to update the objects' positions would cause
the objects to penetrate, is called a <strong><!--[-->collision<!--]--></strong>.<!--]--></p><p><!--[-->Part of a physics engine's job is to <em><!--[-->resolve<!--]--></em> collisions between objects.<!--]--></p><p><!--[-->Conceptually, this is actually quite simple.
The goal of collision resolution is to change each object's velocity so that
as the simulation progresses the objects will no longer penetrate each other.<!--]--></p><!--[--><div><div><p>After collision resolution</p></div><p><label><span> After collision </span></label></p></div><!--]--><p><!--[-->We can define two equations for the respective post-collision velocities of our
bodies.<!--]--></p><p><!--[-->Where <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>a</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{a, i}</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>b</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{b,i}</annotation></semantics></math></span></span></span> are the
velocities of bodies <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span></span> before the collision,
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>a</mi><mo separator="true">,</mo><mi>f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{a,f}</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>b</mi><mo separator="true">,</mo><mi>f</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{b,f}</annotation></semantics></math></span></span></span> the velocities
after the collision, and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \vec{v}_{a}</annotation></semantics></math></span></span></span> and
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \vec{v}_{b}</annotation></semantics></math></span></span></span> the respective changes in velocity caused by
the collision.
The subscripts <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow></mrow><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">_i</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow></mrow><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">_f</annotation></semantics></math></span></span></span> stand for <em><!--[-->initial<!--]--></em> and
<em><!--[-->final<!--]--></em>, respectively.<!--]--></p><div><p>Collision Resolution</p><!--[--><p><!--[-->The goal of collision resolution is to find the values of
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \vec{v}_{a}</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \vec{v}_{b}</annotation></semantics></math></span></span></span>.<!--]--></p><!--]--></div><p><!--[-->If we want our collision behavior to look realistic, we have to ensure that
whatever values we pick for <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \vec{v}_{a}</annotation></semantics></math></span></span></span> and
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Δ</mi><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">\Delta \vec{v}_{b}</annotation></semantics></math></span></span></span> satisfy the relevant laws of physics.
What are these laws?
Well, that's what the majority of this series of articles is going to be about!<!--]--></p><p><!--[-->To start, let's try defining what a collision is a little more rigorously.<!--]--></p><p><!--[-->Take a look at the scene below.
This scene shows two bodies on a specific frame of our game.
We can see that the bodies are touching, but are they <em><!--[-->colliding<!--]--></em>?<!--]--></p><p><!--[-->In the last section we learned that two bodies are said to be colliding if
continuing to move them along their current velocities would cause them to
penetrate each other.
So, with the information we've been given, can we actually determine if the
scene above depicts a collision or not?<!--]--></p><p><!--[-->We can't!
All we know is that the bodies are touching.
We haven't been given any information about their velocities.<!--]--></p><p><!--[-->To see why this matters, take a look at the demonstration below.<!--]--></p><p><!--[-->You can change the velocities of the bodies by dragging the
<strong><!--[--><span>arrows</span><!--]--></strong> around.
The indicator tells you if the current configuration would lead to a
<span>collision</span>
or <span>no&nbsp;collision</span>.
You can verify the result by playing the simulation.<!--]--></p><p><!--[-->We can see that depending on the velocities of the bodies, the same scene can
either represent a collision or not.<!--]--></p><div><p>That doesn't look right</p><!--[--><p><!--[-->You might have noticed that the way the two boxes bounce off each other looks
a little strange.
This is because, in order to keep things simple for now, we're not yet
making the boxes spin when they hit each other.
Don't worry we'll add that in a later post, but let's try and keep the
complexity to a minimum for now.<!--]--></p><!--]--></div><h3 id="towards-a-definition"><a href="#towards-a-definition"><!--[-->Towards a definition<!--]--></a></h3><p><!--[-->In order for two bodies to be colliding, two conditions have to be met:<!--]--></p><ol><!--[--><li><!--[-->The bodies' geometries have to be touching or overlapping<!--]--></li><li><!--[-->The bodies are still moving <em><!--[-->towards the collision<!--]--></em><!--]--></li><!--]--></ol><p><!--[-->Let's assume that point 1 is true for now and focus on point 2, instead.
What does it mean for two bodies to be moving "towards the collision"?
This seems like a pretty circular definition.<!--]--></p><p><!--[-->Instead of asking what it means to move towards the collision, let's ask what it
means to move <em><!--[-->away<!--]--></em> from the collision.
In fact, let's ignore collisions entirely for a moment.
What does it mean to move away from a <em><!--[-->surface<!--]--></em>?<!--]--></p><p><!--[-->The image below shows a box sitting on the floor.
What direction would you have to move the box in order to move it away from the
floor?<!--]--></p><p><!--[-->At first glance, this seems like a silly question.
Obviously, we'd have to move the box <em><!--[-->up<!--]--></em>.<!--]--></p><p><!--[-->However, there are an infinite number of directions that we could move the box!
As long as we are moving it <em><!--[-->generally<!--]--></em> upwards, we are increasing the distance
between the box and the floor.<!--]--></p><p><!--[-->Notice that while the box was moved the exact same distance in each
direction—that is, the length of the <strong><!--[--><span>arrows</span><!--]--></strong> is the
same—some of the boxes are clearly further away from the floor than others.<!--]--></p><p><!--[-->So, are some of these directions more "up" than others?
Is there a direction that is <em><!--[-->most<!--]--></em> "up"?<!--]--></p><p><!--[-->To explore this idea, let's play a little game.<!--]--></p><h3 id="surface-normals"><a href="#surface-normals"><!--[-->Surface normals<!--]--></a></h3><p><!--[-->You are given a box sitting on the floor.
Your goal is to move the box so that its distance to the floor is as close as
possible to the total distance the box was moved.
It doesn't matter how far you move the box, just that these two distances are
as close to each other as possible.<!--]--></p><p><!--[-->To make things a little more challenging, the angle of inclination of the floor
is going to change every time you reset the game.<!--]--></p><p><!--[-->I know, I know, Game of the Year material right here.
But hopefully you were able to figure out that the direction that maximizes the
distance between the box and the floor is the direction that is <em><!--[-->perpendicular<!--]--></em>
to the floor, which isn't necessarily straight up!<!--]--></p><p><!--[-->This direction is called the <strong><!--[-->normal direction<!--]--></strong>, often referred to as simply
the <strong><!--[-->normal<!--]--></strong> of the surface.
The normal direction of a surface is always perpendicular to the surface.
It is the direction that points <em><!--[-->directly away<!--]--></em> from the surface.<!--]--></p><p><!--[-->Normal directions are represented with a <strong><!--[-->normalized vector<!--]--></strong>; that is, a
vector with length <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></span>.
A vector with length <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></span> is also called a <strong><!--[-->unit vector<!--]--></strong>.
To make it clear that a vector is normalized, we often add a little hat on top
of the variable like this <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>n</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{n}</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->If our surface is perfectly straight, the normal direction is the same
everywhere on the surface.
However, if the surface is curved, the normal direction will be different for
each point on the surface.
The easiest way to demonstrate this is with a circle.
If we stick with the idea that the normal direction points directly away from
a surface, then the normal direction for any point on the circle's circumference
is the direction from the center of the circle to that point.<!--]--></p><p><!--[-->More generally, the <strong><!--[--><span>normal</span><!--]--></strong> direction for a point on a
surface is perpendicular to the <strong><!--[--><span>tangent</span><!--]--></strong> of the surface
at that point.<!--]--></p><!--[--><!--]--><p><!--[-->We saw earlier that it isn't necessary to move the box <em><!--[-->directly<!--]--></em> in the normal
direction in order to move it away from the floor.<!--]--></p><p><!--[-->What all these directions have in common, is that they all generally point in
the same direction as the surface normal.
We say that these directions have <em><!--[-->some component in the normal direction<!--]--></em>.
Let's take a closer look at what this means, exactly.<!--]--></p><h3 id="the-dot-product"><a href="#the-dot-product"><!--[-->The dot product<!--]--></a></h3><p><!--[-->To calculate how much of one vector is pointing in the same direction as another
vector, we can use the <strong><!--[-->dot product<!--]--></strong> of the two vectors.
In our example, the two vectors are the direction we move the box and the
surface normal.
The dot product between two vectors <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>a</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{a}</annotation></semantics></math></span></span></span> and
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{b}</annotation></semantics></math></span></span></span> is written as <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>a</mi><mo>⃗</mo></mover><mo>⋅</mo><mover accent="true"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{a} \cdot \vec{b}</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->The dot product can be defined either algebraically or geometrically.<!--]--></p><p><!--[-->Algebraically, the dot product is defined as the sum of the products of the
corresponding components of the two vectors.
For two-dimensional vectors such as the ones we're dealing with, we can write
this as:<!--]--></p><p><!--[-->Note that the result of the dot product is a <em><!--[-->scalar<!--]--></em>, not another vector.<!--]--></p><p><!--[-->While this is fairly straight-forward to calculate, it's not exactly obvious
what this scalar <em><!--[-->represents<!--]--></em>.
Luckily, there is also a geometric interpretation of the dot product that can be
visualized nicely.<!--]--></p><p><!--[-->Say we have two vectors <strong><!--[--><span>a</span><!--]--></strong> and <strong><!--[--><span>b</span><!--]--></strong> that
have some angle <strong><!--[--><span>θ</span><!--]--></strong> between them.<!--]--></p><!--[--><!----><!--]--><p><!--[-->Next, starting from the tip of <strong><!--[--><span>a</span><!--]--></strong> let's draw a line
perpendicular to <strong><!--[--><span>b</span><!--]--></strong> connecting the two vectors.<!--]--></p><!--[--><!----><!--]--><p><!--[-->The length from the base of <strong><!--[--><span>b</span><!--]--></strong> to the point where the
perpendicular line intersects <strong><!--[--><span>b</span><!--]--></strong> is called the
<strong><!--[--><span>scalar projection</span><!--]--></strong> <strong><!--[--><span>s</span><!--]--></strong> of <strong><!--[--><span>a</span><!--]--></strong>
onto <strong><!--[--><span>b</span><!--]--></strong>.<!--]--></p><!--[--><!----><!--]--><p><!--[-->Imagine a light that's perfectly perpendicular to <strong><!--[--><span>b</span><!--]--></strong> shining
down on <strong><!--[--><span>a</span><!--]--></strong>.
The scalar projection is the length of the shadow that <strong><!--[--><span>a</span><!--]--></strong>
casts on <strong><!--[--><span>b</span><!--]--></strong>.<!--]--></p><p><!--[-->Since we now have a right triangle, trigonometry tells us that the length of
this <strong><!--[--><span>projection</span><!--]--></strong> is the product of the length of
<strong><!--[--><span>a</span><!--]--></strong> (the hypotenuse) and the cosine of the angle between the
two vectors.<!--]--></p><p><!--[-->To be precise, it's the <em><!--[-->absolute value<!--]--></em> of the scalar projection that gives us
the length of the shadow, since we will see in a moment that the scalar
projection can also be negative.<!--]--></p><p><!--[-->This is equivalent to the dot product of <strong><!--[--><span>a</span><!--]--></strong> and the unit
vector <strong><!--[--><span><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>b</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{b}</annotation></semantics></math></span></span></span></span><!--]--></strong> in the direction of
<strong><!--[--><span>b</span><!--]--></strong>.<!--]--></p><p><!--[-->Well hold on, that's a bit of a bait and switch!
Why are we suddenly talking about the <em><!--[-->unit vector in the direction of
<strong><!--[--><span>b</span><!--]--></strong><!--]--></em>?
That's not what we wanted to find!
How do we get the dot product between <strong><!--[--><span>a</span><!--]--></strong> and
<strong><!--[--><span>b</span><!--]--></strong> itself?<!--]--></p><p><!--[-->By definition, <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>b</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{b}</annotation></semantics></math></span></span></span> and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{b}</annotation></semantics></math></span></span></span> are already
pointing in the same direction.
The only difference between them is their length.
Since unit vectors have a length of 1, all we have to do is multiply
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>b</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{b}</annotation></semantics></math></span></span></span> by the length of <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>b</mi><mo>⃗</mo></mover></mrow><annotation encoding="application/x-tex">\vec{b}</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->Therefore, multiplying both sides of <span></span> by
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∥</mi><mover accent="true"><mi>b</mi><mo>⃗</mo></mover><mi mathvariant="normal">∥</mi></mrow><annotation encoding="application/x-tex">\| \vec{b} \|</annotation></semantics></math></span></span></span> gives us the full geometric definition of the dot
product.<!--]--></p><p><!--[-->In English, the dot product of two vectors is the length of the scalar
projection of one vector onto the other, multiplied by the length of the vector
we're projecting onto.<!--]--></p><p><!--[-->Before moving on, take a second to think about the following questions.
You can click on them to reveal the answers.<!--]--></p><p><!--[-->I mentioned earlier that the scalar projection, and therefore the dot product,
can also be negative.
A lot of the time, we're actually more interested in the <em><!--[-->sign<!--]--></em> of the dot
product rather than its actual value.<!--]--></p><p><!--[-->The demonstration below shows the <strong><!--[--><span>dot product</span><!--]--></strong> between
<strong><!--[--><span>two</span><!--]--></strong> <strong><!--[--><span>vectors</span><!--]--></strong> as well as the
<strong><!--[--><span>angle</span><!--]--></strong> between them.
You can control the <strong><!--[--><span>angle</span><!--]--></strong> between the vectors with the
<strong><!--[--><span>slider</span><!--]--></strong> below.
The angle is normalized to always be between 0° and 180°.<!--]--></p><p><!--[-->Pay attention to the <strong><!--[-->sign<!--]--></strong> of the <strong><!--[--><span>dot product</span><!--]--></strong> as you
change the <strong><!--[--><span>angle</span><!--]--></strong>.
Can you tell at what <strong><!--[--><span>angles</span><!--]--></strong> the
<strong><!--[--><span>dot product</span><!--]--></strong> is negative or positive?
How about when it's zero?
Think about how looking at the sign of the <strong><!--[--><span>dot product</span><!--]--></strong>
can help us determine if two vectors are generally pointing in the same
direction or not.<!--]--></p><!--[--><!--]--><p><!--[-->If the angle between the vectors is <strong><!--[-->acute<!--]--></strong> (less than <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><msup><mn>0</mn><mo lspace="0em" rspace="0em">∘</mo></msup></mrow><annotation encoding="application/x-tex">90^{\circ}</annotation></semantics></math></span></span></span>),
the dot product is <strong><!--[-->positive<!--]--></strong>.
A positive dot product indicates that the vectors are generally pointing in the
same direction.<!--]--></p><p><!--[-->If the angle is <strong><!--[-->obtuse<!--]--></strong> (greater than <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><msup><mn>0</mn><mo lspace="0em" rspace="0em">∘</mo></msup></mrow><annotation encoding="application/x-tex">90^{\circ}</annotation></semantics></math></span></span></span>), the dot product
is <strong><!--[-->negative<!--]--></strong>.
A negative dot product indicates that the vectors are generally pointing in
opposite directions.<!--]--></p><p><!--[-->If the angle is <strong><!--[-->exactly <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><msup><mn>0</mn><mo lspace="0em" rspace="0em">∘</mo></msup></mrow><annotation encoding="application/x-tex">90^{\circ}</annotation></semantics></math></span></span></span><!--]--></strong>, the dot product is <strong><!--[-->zero<!--]--></strong>.<!--]--></p><h3 id="tying-it-all-together"><a href="#tying-it-all-together"><!--[-->Tying it all together<!--]--></a></h3><p><!--[-->We started out by asking what it means for two bodies to be moving <em><!--[-->towards<!--]--></em>
the collision.
To answer this, we took a slight detour and looked at what it means to move away
from a <em><!--[-->surface<!--]--></em>.<!--]--></p><p><!--[-->Using the dot product, we can now answer the second question.
As long as the velocity vector of the body has some component in the normal
direction of the surface normal, i.e. the dot product between these vectors is
positive, the body is moving <em><!--[-->away<!--]--></em> from the surface.<!--]--></p><p><!--[-->Even so, it might not be immediately obvious how this helps us answer the
original question.
Let's look at our two boxes again.<!--]--></p><p><!--[-->This situation differs from the previous example of the box and the floor in two
ways:<!--]--></p><ol><!--[--><li><!--[-->We have <em><!--[-->two<!--]--></em> <strong><!--[--><span>velocity vectors</span><!--]--></strong> instead of one, one for
each box. Which one do we use?<!--]--></li><li><!--[-->There is no "surface", is there? What is our surface normal?<!--]--></li><!--]--></ol><p><!--[-->To answer the first question, instead of using the individual velocities of the
boxes, we use their <em><!--[-->relative velocity<!--]--></em>.
As the name implies, the relative velocity tells us the velocities of the bodies
relative to each other.
The relative velocity is the vector difference between the individual velocities.
In this article, I will denote the relative velocity of bodies <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span></span></span>
and <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span></span> as <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>a</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{ab}</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->Geometrically, the relative velocity <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>a</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{ab}</annotation></semantics></math></span></span></span> is the vector
that points from the tip of the velocity vector <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>b</mi></msub></mrow><annotation encoding="application/x-tex">\vec{v}_b</annotation></semantics></math></span></span></span> to the
tip of the velocity vector <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">\vec{v}_a</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->All other things being equal, two cars hitting each other head-on at
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mfrac><mtext>km</mtext><mtext>h</mtext></mfrac></mrow><annotation encoding="application/x-tex">50 \frac{\text{km}}{\text{h}}</annotation></semantics></math></span></span></span> each is the same as one car
hitting a stationary car at <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mfrac><mtext>km</mtext><mtext>h</mtext></mfrac></mrow><annotation encoding="application/x-tex">100 \frac{\text{km}}{\text{h}}</annotation></semantics></math></span></span></span>.<!--]--></p><p><!--[-->What about the second question?
What's our surface and its corresponding normal?
What we're looking for is called the <em><!--[-->collision normal<!--]--></em>.
Unfortunately, the way you calculate the collision normal depends on the shapes
(or geometries) of the colliding bodies, so I can't just show you a single
formula.<!--]--></p><p><!--[-->What we're dealing with is called a <em><!--[-->vertex-edge collision<!--]--></em>.
In this type of collision, a point (or vertex) on one body collides with a
side (or edge) of another body.
We'll talk more about collision normals when we take a look at the forces that
act during the collision.
For now, you'll have to take my word that in a vertex-edge collision, the
collision normal is perpendicular to the edge.<!--]--></p><p><!--[-->In our example, the <strong><!--[--><span>collision normal</span><!--]--></strong> looks like this:<!--]--></p><p><!--[-->If we label our bodies <strong><!--[-->a<!--]--></strong> and <strong><!--[-->b<!--]--></strong>, by convention, the collision normal
points toward body <strong><!--[-->a<!--]--></strong>.
It's fairly arbitrary which body is called <strong><!--[-->a<!--]--></strong> or <strong><!--[-->b<!--]--></strong> as long as we're
consistent throughout our calculations.<!--]--></p><p><!--[-->Based on what we learned about surface normals earlier, the
<strong><!--[--><span>collision normal</span><!--]--></strong> tells us the direction that points
directly away from the surface of the collision.<!--]--></p><p><!--[-->We can now calculate the dot product between the relative velocity of the bodies
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>v</mi><mo>⃗</mo></mover><mrow><mi>a</mi><mi>b</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\vec{v}_{ab}</annotation></semantics></math></span></span></span> and the collision normal <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>n</mi><mo>^</mo></mover></mrow><annotation encoding="application/x-tex">\hat{n}</annotation></semantics></math></span></span></span> to
determine if the bodies are moving towards the collision or not.<!--]--></p><p><!--[-->We'll call this value the <em><!--[-->relative normal velocity<!--]--></em>.
It is the component of the relative velocity in the direction of the collision
normal.
For now, we only care about the sign of the relative normal velocity, but we'll
see later on that it plays an important part in calculating the forces that act
during the collision.<!--]--></p><p><!--[-->Using our understanding of the dot product, we can say that<!--]--></p><ul><!--[--><li><!--[-->if the relative normal velocity is <strong><!--[-->positive<!--]--></strong>, the bodies are already
separating<!--]--></li><li><!--[-->if the relative normal velocity is <strong><!--[-->negative<!--]--></strong>, the bodies are still smashing
into each other<!--]--></li><!--]--></ul><p><!--[-->The demonstration below combines all concepts we've learned so far.
As before, you can change the <strong><!--[--><span>velocities</span><!--]--></strong> of the boxes by
dragging the arrowheads.
The top right corner shows the <strong><!--[--><span>collision normal</span><!--]--></strong> and
<strong><!--[--><span>relative velocity</span><!--]--></strong> of the bodies.<!--]--></p><p><!--[-->You can see that as soon as the angle between the
<strong><!--[--><span>relative velocity</span><!--]--></strong> and the
<strong><!--[--><span>collision normal</span><!--]--></strong> is less than or equal to
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><msup><mn>0</mn><mo lspace="0em" rspace="0em">∘</mo></msup></mrow><annotation encoding="application/x-tex">90^{\circ}</annotation></semantics></math></span></span></span>—and therefore the dot product is positive—the bodies are
no longer colliding.<!--]--></p><p><!--[-->So, finally, we can formally define what a collision is:<!--]--></p><div><p>Definition</p><!--[--><p><!--[-->A collision occurs when a point on one body touches a point on another body
with a negative relative normal velocity.<!--]--></p><!--]--></div><p><!--[-->Neat!<!--]--></p><h2 id="conclusion"><a href="#conclusion"><!--[-->Conclusion<!--]--></a></h2><p><!--[-->If you made it to this point, pat yourself on the back!
We now have a formal definition of what a collision is, as well as the set of
equations we're ultimate trying to solve when resolving collisions
(see <span></span>).
Not bad at all!<!--]--></p><p><!--[-->In the next post, we'll dive into the actual physics behind collisions.
If you enjoyed this article, you'll love the next part!<!--]--></p><p><!--[-->This is all I have for you today.
Thank you so much for reading and I hope I'll see you again for the next post.<!--]--></p><p><!--[--><em><!--[-->If you want to discuss this article, feel free to either reach out to me on
<a href="https://twitter.com/warsh33p" rel="nofollow"><!--[-->Twitter<!--]--></a> or shoot me an email at
<strong><!--[--><a href="mailto:me@kai-sassnowski.com" rel="noopener noreferrer"><!--[-->me@kai-sassnowski.com<!--]--></a><!--]--></strong>.<!--]--></em><!--]--></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Perplexica: Open-Source Perplexity Alternative (325 pts)]]></title>
            <link>https://github.com/ItzCrazyKns/Perplexica</link>
            <guid>40462369</guid>
            <pubDate>Fri, 24 May 2024 02:49:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ItzCrazyKns/Perplexica">https://github.com/ItzCrazyKns/Perplexica</a>, See on <a href="https://news.ycombinator.com/item?id=40462369">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Perplexica - An AI-powered search engine 🔎 </h2><a id="user-content--perplexica---an-ai-powered-search-engine--" aria-label="Permalink: 🚀 Perplexica - An AI-powered search engine 🔎 " href="#-perplexica---an-ai-powered-search-engine--"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ItzCrazyKns/Perplexica/blob/master/.assets/perplexica-screenshot.png"><img src="https://github.com/ItzCrazyKns/Perplexica/raw/master/.assets/perplexica-screenshot.png" alt="preview"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents </h2><a id="user-content-table-of-contents-" aria-label="Permalink: Table of Contents " href="#table-of-contents-"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#preview">Preview</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#getting-started-with-docker-recommended">Getting Started with Docker (Recommended)</a></li>
<li><a href="#non-docker-installation">Non-Docker Installation</a></li>
<li><a href="#ollama-connection-errors">Ollama connection errors</a></li>
</ul>
</li>
<li><a href="#using-as-a-search-engine">Using as a Search Engine</a></li>
<li><a href="#one-click-deployment">One-Click Deployment</a></li>
<li><a href="#upcoming-features">Upcoming Features</a></li>
<li><a href="#support-us">Support Us</a>
<ul dir="auto">
<li><a href="#donations">Donations</a></li>
</ul>
</li>
<li><a href="#contribution">Contribution</a></li>
<li><a href="#help-and-support">Help and Support</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">Perplexica is an open-source AI-powered searching tool or an AI-powered search engine that goes deep into the internet to find answers. Inspired by Perplexity AI, it's an open-source option that not just searches the web but understands your questions. It uses advanced machine learning algorithms like similarity searching and embeddings to refine results and provides clear answers with sources cited.</p>
<p dir="auto">Using SearxNG to stay current and fully open source, Perplexica ensures you always get the most up-to-date information without compromising your privacy.</p>
<p dir="auto">Want to know more about its architecture and how it works? You can read it <a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/architecture/README.md">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Preview</h2><a id="user-content-preview" aria-label="Permalink: Preview" href="#preview"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ItzCrazyKns/Perplexica/blob/master/.assets/perplexica-preview.gif"><img src="https://github.com/ItzCrazyKns/Perplexica/raw/master/.assets/perplexica-preview.gif" alt="video-preview" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Local LLMs</strong>: You can make use local LLMs such as Llama3 and Mixtral using Ollama.</li>
<li><strong>Two Main Modes:</strong>
<ul dir="auto">
<li><strong>Copilot Mode:</strong> (In development) Boosts search by generating different queries to find more relevant internet sources. Like normal search instead of just using the context by SearxNG, it visits the top matches and tries to find relevant sources to the user's query directly from the page.</li>
<li><strong>Normal Mode:</strong> Processes your query and performs a web search.</li>
</ul>
</li>
<li><strong>Focus Modes:</strong> Special modes to better answer specific types of questions. Perplexica currently has 6 focus modes:
<ul dir="auto">
<li><strong>All Mode:</strong> Searches the entire web to find the best results.</li>
<li><strong>Writing Assistant Mode:</strong> Helpful for writing tasks that does not require searching the web.</li>
<li><strong>Academic Search Mode:</strong> Finds articles and papers, ideal for academic research.</li>
<li><strong>YouTube Search Mode:</strong> Finds YouTube videos based on the search query.</li>
<li><strong>Wolfram Alpha Search Mode:</strong> Answers queries that need calculations or data analysis using Wolfram Alpha.</li>
<li><strong>Reddit Search Mode:</strong> Searches Reddit for discussions and opinions related to the query.</li>
</ul>
</li>
<li><strong>Current Information:</strong> Some search tools might give you outdated info because they use data from crawling bots and convert them into embeddings and store them in a index. Unlike them, Perplexica uses SearxNG, a metasearch engine to get the results and rerank and get the most relevant source out of it, ensuring you always get the latest information without the overhead of daily data updates.</li>
</ul>
<p dir="auto">It has many more features like image and video search. Some of the planned features are mentioned in <a href="#upcoming-features">upcoming features</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">There are mainly 2 ways of installing Perplexica - With Docker, Without Docker. Using Docker is highly recommended.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Getting Started with Docker (Recommended)</h3><a id="user-content-getting-started-with-docker-recommended" aria-label="Permalink: Getting Started with Docker (Recommended)" href="#getting-started-with-docker-recommended"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Ensure Docker is installed and running on your system.</p>
</li>
<li>
<p dir="auto">Clone the Perplexica repository:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/ItzCrazyKns/Perplexica.git"><pre>git clone https://github.com/ItzCrazyKns/Perplexica.git</pre></div>
</li>
<li>
<p dir="auto">After cloning, navigate to the directory containing the project files.</p>
</li>
<li>
<p dir="auto">Rename the <code>sample.config.toml</code> file to <code>config.toml</code>. For Docker setups, you need only fill in the following fields:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>OPENAI</code>: Your OpenAI API key. <strong>You only need to fill this if you wish to use OpenAI's models</strong>.</p>
</li>
<li>
<p dir="auto"><code>OLLAMA</code>: Your Ollama API URL. You should enter it as <code>http://host.docker.internal:PORT_NUMBER</code>. If you installed Ollama on port 11434, use <code>http://host.docker.internal:11434</code>. For other ports, adjust accordingly. <strong>You need to fill this if you wish to use Ollama's models instead of OpenAI's</strong>.</p>
</li>
<li>
<p dir="auto"><code>GROQ</code>: Your Groq API key. <strong>You only need to fill this if you wish to use Groq's hosted models</strong></p>
<p dir="auto"><strong>Note</strong>: You can change these after starting Perplexica from the settings dialog.</p>
</li>
<li>
<p dir="auto"><code>SIMILARITY_MEASURE</code>: The similarity measure to use (This is filled by default; you can leave it as is if you are unsure about it.)</p>
</li>
</ul>
</li>
<li>
<p dir="auto">Ensure you are in the directory containing the <code>docker-compose.yaml</code> file and execute:</p>

</li>
<li>
<p dir="auto">Wait a few minutes for the setup to complete. You can access Perplexica at <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a> in your web browser.</p>
</li>
</ol>
<p dir="auto"><strong>Note</strong>: After the containers are built, you can start Perplexica directly from Docker without having to open a terminal.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Non-Docker Installation</h3><a id="user-content-non-docker-installation" aria-label="Permalink: Non-Docker Installation" href="#non-docker-installation"></a></p>
<ol dir="auto">
<li>Clone the repository and rename the <code>sample.config.toml</code> file to <code>config.toml</code> in the root directory. Ensure you complete all required fields in this file.</li>
<li>Rename the <code>.env.example</code> file to <code>.env</code> in the <code>ui</code> folder and fill in all necessary fields.</li>
<li>After populating the configuration and environment files, run <code>npm i</code> in both the <code>ui</code> folder and the root directory.</li>
<li>Install the dependencies and then execute <code>npm run build</code> in both the <code>ui</code> folder and the root directory.</li>
<li>Finally, start both the frontend and the backend by running <code>npm run start</code> in both the <code>ui</code> folder and the root directory.</li>
</ol>
<p dir="auto"><strong>Note</strong>: Using Docker is recommended as it simplifies the setup process, especially for managing environment variables and dependencies.</p>
<p dir="auto">See the <a href="https://github.com/ItzCrazyKns/Perplexica/tree/master/docs/installation">installation documentation</a> for more information like exposing it your network, etc.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ollama connection errors</h3><a id="user-content-ollama-connection-errors" aria-label="Permalink: Ollama connection errors" href="#ollama-connection-errors"></a></p>
<p dir="auto">If you're facing an Ollama connection error, it is often related to the backend not being able to connect to Ollama's API. How can you fix it? You can fix it by updating your Ollama API URL in the settings menu to the following:</p>
<p dir="auto">On Windows: <code>http://host.docker.internal:11434</code><br>
On Mac: <code>http://host.docker.internal:11434</code><br>
On Linux: <code>http://private_ip_of_computer_hosting_ollama:11434</code></p>
<p dir="auto">You need to edit the ports accordingly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using as a Search Engine</h2><a id="user-content-using-as-a-search-engine" aria-label="Permalink: Using as a Search Engine" href="#using-as-a-search-engine"></a></p>
<p dir="auto">If you wish to use Perplexica as an alternative to traditional search engines like Google or Bing, or if you want to add a shortcut for quick access from your browser's search bar, follow these steps:</p>
<ol dir="auto">
<li>Open your browser's settings.</li>
<li>Navigate to the 'Search Engines' section.</li>
<li>Add a new site search with the following URL: <code>http://localhost:3000/?q=%s</code>. Replace <code>localhost</code> with your IP address or domain name, and <code>3000</code> with the port number if Perplexica is not hosted locally.</li>
<li>Click the add button. Now, you can use Perplexica directly from your browser's search bar.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">One-Click Deployment</h2><a id="user-content-one-click-deployment" aria-label="Permalink: One-Click Deployment" href="#one-click-deployment"></a></p>
<p dir="auto"><a href="https://repocloud.io/details/?app_id=267" rel="nofollow"><img src="https://camo.githubusercontent.com/9ba16e9c3d97ee3e809848cd104bf5bdbde29bba809291784db2cd1c599a20f2/68747470733a2f2f64313674307063343834367835322e636c6f756466726f6e742e6e65742f6465706c6f796c6f62652e737667" alt="Deploy to RepoCloud" data-canonical-src="https://d16t0pc4846x52.cloudfront.net/deploylobe.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Upcoming Features</h2><a id="user-content-upcoming-features" aria-label="Permalink: Upcoming Features" href="#upcoming-features"></a></p>
<ul>
<li> Finalizing Copilot Mode</li>
<li> Add settings page</li>
<li> Adding support for local LLMs</li>
<li> Adding Discover and History Saving features</li>
<li> Introducing various Focus Modes</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support Us</h2><a id="user-content-support-us" aria-label="Permalink: Support Us" href="#support-us"></a></p>
<p dir="auto">If you find Perplexica useful, consider giving us a star on GitHub. This helps more people discover Perplexica and supports the development of new features. Your support is greatly appreciated.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Donations</h3><a id="user-content-donations" aria-label="Permalink: Donations" href="#donations"></a></p>
<p dir="auto">We also accept donations to help sustain our project. If you would like to contribute, you can use the following button to make a donation in cryptocurrency. Thank you for your support!</p>
<a href="https://nowpayments.io/donation?api_key=RFFKJH1-GRR4DQG-HFV1DZP-00G6MMK&amp;source=lk_donation&amp;medium=referral" rel="nofollow">
  <img src="https://camo.githubusercontent.com/1a5894a561e70bbbb4b4bd43e03eca655457f177b2ffb54655869a3838b386b5/68747470733a2f2f6e6f777061796d656e74732e696f2f696d616765732f656d626564732f646f6e6174696f6e2d627574746f6e2d77686974652e737667" alt="Crypto donation button by NOWPayments" data-canonical-src="https://nowpayments.io/images/embeds/donation-button-white.svg">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contribution</h2><a id="user-content-contribution" aria-label="Permalink: Contribution" href="#contribution"></a></p>
<p dir="auto">Perplexica is built on the idea that AI and large language models should be easy for everyone to use. If you find bugs or have ideas, please share them in via GitHub Issues. For more information on contributing to Perplexica you can read the <a href="https://github.com/ItzCrazyKns/Perplexica/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a> file to learn more about Perplexica and how you can contribute to it.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Help and Support</h2><a id="user-content-help-and-support" aria-label="Permalink: Help and Support" href="#help-and-support"></a></p>
<p dir="auto">If you have any questions or feedback, please feel free to reach out to us. You can create an issue on GitHub or join our Discord server. There, you can connect with other users, share your experiences and reviews, and receive more personalized help. <a href="https://discord.gg/EFwsmQDgAu" rel="nofollow">Click here</a> to join the Discord server. To discuss matters outside of regular support, feel free to contact me on Discord at <code>itzcrazykns</code>.</p>
<p dir="auto">Thank you for exploring Perplexica, the AI-powered search engine designed to enhance your search experience. We are constantly working to improve Perplexica and expand its capabilities. We value your feedback and contributions which help us make Perplexica even better. Don't forget to check back for updates and new features!</p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>