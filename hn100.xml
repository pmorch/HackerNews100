<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 22 Jul 2023 09:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Compromised Microsoft Key: More Impactful Than We Thought (171 pts)]]></title>
            <link>https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</link>
            <guid>36823007</guid>
            <pubDate>Sat, 22 Jul 2023 03:40:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr">https://www.wiz.io/blog/storm-0558-compromised-microsoft-key-enables-authentication-of-countless-micr</a>, See on <a href="https://news.ycombinator.com/item?id=36823007">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">Microsoft</a> and <a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">CISA</a> recently disclosed a security incident impacting multiple customers of Exchange Online and Outlook.com. According to Microsoft, this incident stemmed from a threat actor attributed to China, Storm-0558, acquiring a private encryption key (MSA key) and using it to forge access tokens for Outlook Web Access (OWA) and Outlook.com. Additionally, the threat actor reportedly exploited two security issues in Microsoft’s token verification process. </p><p>Microsoft have said that Outlook.com and Exchange Online were the only applications known to have been affected via the token forging technique, but Wiz Research has found that the compromised signing key was more powerful than it may have seemed, and was not limited to just those two services. Our researchers concluded that the compromised MSA key could have allowed the threat actor to forge access tokens for multiple types of Azure Active Directory applications, including every application that supports personal account authentication, such as SharePoint, Teams, OneDrive, customers’ applications that support the “login with Microsoft” functionality, and multi-tenant applications in certain conditions.</p><p>In addition, while Microsoft mitigated this risk by revoking the impacted encryption key and publishing <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">attacker IOCs,</a> we discovered that it may be difficult for customers to detect the use of forged tokens against their applications due to lack of logs on crucial fields related to the token verification process.</p><p>Why is it so impactful?&nbsp; Identity provider’s signing keys are probably the most powerful secrets in the modern world.&nbsp; For example, they are much more powerful than TLS keys. Even if an attacker got access to the google.com TLS key, they would still need to somehow impersonate a google.com server to gain significant impact. With identity provider keys, one can gain immediate single hop access to everything, any email box, file service or cloud account. This isn’t a Microsoft specific issue, if a signing key for Google, Facebook, Okta or any other major identity provider leaks, the implications are hard to comprehend. Our industry – and especially cloud service providers – must commit to a greater level of security and transparency concerning how they protect critical keys such as this one, to prevent future incidents and limit their potential impact.&nbsp;</p><p>In this post, we will share how we were able to confirm which private key was acquired by the threat actor and how we determined its permissions. We will also unpack some of the technical aspects of this incident and help detect potential use of this compromised key within your environments.</p><h2><span></span><a id="compromised-consumer-signing-key--who-are-you-5"></a>Compromised consumer signing key – who are you?&nbsp;</h2><p>On July 11th, 2023, Microsoft revealed that a malicious actor had obtained an MSA consumer signing key, allowing them to forge access tokens for Exchange Online and Outlook.com accounts.</p><p>Determined to learn more about the incident, we launched an investigation.</p><p>First, we checked which keys could sign OpenID tokens for Microsoft accounts and Azure Active Directory applications. We therefore examined Microsoft’s <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official documentation for OpenID token verification</a>. Interestingly, we discovered that all Azure personal account v2.0 applications depend on a list of <a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">8 public keys</a>, and all Azure multi-tenant v2.0 applications with Microsoft account enabled depend on a list of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">7 public keys</a> (at the time of writing).</p><p>Using the Internet Archive’s Wayback Machine, we noticed that one of the listed public keys that had been present <a href="http://web.archive.org/web/20160801114452/https:/login.microsoftonline.com/common/discovery/v2.0/keys">since at least 2016</a> was replaced sometime between <a href="http://web.archive.org/web/20230627150747/https:/login.microsoftonline.com/common/discovery/v2.0/keys">June 27th</a> and <a href="http://web.archive.org/web/20230705095601/https:/login.microsoftonline.com/common/discovery/v2.0/keys">July 5th</a>, 2023, matching the time frame in which Microsoft replaced the acquired key according to their blog post.</p><p><em>Metadata of the public key replaced between June 27th and July 5th</em>&nbsp;</p><p>The old public key’s certificate revealed it was issued on April 5th, 2016, and expired on April 4th, 2021, and its thumbprint matched the thumbprint of the key Microsoft <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=d4b4cccda9228624656bff33d8110955779632aa">listed in their latest blog post</a>, named “Thumbprint of acquired signing key”:</p><div><p>The decoded certificate of the old key (1LTMzakihiRla_8z2BEJVXeWMqo). Obtained from the list intended June 27th, 2023 version of the certificate list for Azure common (mixed audience) applications.</p></div><p>This led us to believe that although the compromised key acquired by Storm-0558 was a private key designed for Microsoft's MSA tenant in Azure, it was also able to sign OpenID v2.0 tokens for multiple types of Azure Active Directory applications.</p><h2><span></span><a id="what-is-the-significance-of-a-compromised-openid-signing-key-16"></a>What is the significance of a compromised OpenID signing key?&nbsp;</h2><p>The Azure identity platform publishes multiple lists of trusted keys scoped to different application types. These serve to validate the integrity of tokens which are issued by Azure Active Directory (AAD). During the authentication process for an AAD application, the application must confirm the token's authenticity by verifying its signature against the correct trusted public key list. This verification determines whether the token should be trusted.</p><p># Azure Active Directory multi-tenant applications:&nbsp;<br></p><p><em>Azure Active Directory public certificates’ lists</em>&nbsp;</p><p>If any of the keys from one of these lists are compromised, there is a significant risk for applications using that list for validation. Such a compromise could enable unauthorized parties to forge valid access tokens for consumption by any application that depends on the Azure identity platform under certain conditions (see below).</p><div><p>The risks of compromised OpenID signing key </p></div><p>Based on what we can deduce from Microsoft’s blog post, Storm-0558 seemingly managed to obtain access to one of <a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">several keys</a> that were intended for signing and verifying AAD access tokens. The compromised key was trusted to sign any OpenID v2.0 access token for personal accounts and mixed-audience (multi-tenant or personal account) AAD applications.</p><div><p>The types of applications that could trust the key acquired by Storm-0558</p></div><p>In other words, Storm-0558 could have theoretically used the private key it acquired to forge tokens to authenticate as any user to any affected application that trusts Microsoft OpenID v2.0 mixed audience and personal-accounts certificates.</p><h2><span></span><a id="which-applications-are-affected-27"></a>Which applications are affected?&nbsp;</h2><p>Based on our analysis, only Azure Active Directory applications that work with Microsoft’s OpenID v2.0 were affected. Version 1.0 applications were not using the compromised key for token validation and therefore were not affected.</p><h3><span></span><a id="applications-supporting-personal-microsoft-accounts-only-29"></a><strong>Applications supporting Personal Microsoft accounts only</strong></h3><p>Any Azure Active Directory application that supports “Personal Microsoft accounts only” and works against Microsoft’s v2.0 protocol was affected<strong>. This includes </strong>managed Microsoft applications, such as Outlook, SharePoint, OneDrive, and Teams, as well as customers’ applications that support Microsoft Account authentication, including those who allow the “Login with Microsoft” functionality.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-and-personal-microsoft-accounts-eg-skype-xbox-31"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant) and personal Microsoft accounts (e.g. Skype, Xbox)</strong></h3><p>Any Azure Active Directory application that supported “mixed audience” and works against Microsoft’s v2.0 protocol was affected as well. The threat actor could forge valid access tokens and impersonate application users who signed in with their Personal Microsoft account.</p><p>To restrict the power of MSA keys in impersonating organizational accounts, Microsoft introduced an extension to the OpenID protocol. This extension advises developers to validate the issuer claim by comparing it with the issuer field in the list of the OpenID public keys. By doing this, it aims to prevent an MSA key from signing access tokens with an issuer different than the MSA tenant (9188040d-6c67-4c5b-b112-36a304b66dad). This extension is specific to Microsoft and the responsibility of its implementation rests with the application owner. Therefore, there is a concern that many applications lack this procedure and as a result, the threat actor could potentially impersonate organizational accounts as well (according to Microsoft’s blogpost, OWA was affected by a similar issue).</p><p>To assist Azure developers with adopting this validation functionality, Microsoft added it to their <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/issues/2134">official Azure SDK</a> on July 12.</p><h3><span></span><a id="applications-supporting-accounts-in-any-organizational-directory-any-azure-ad-directory--multi-tenant-35"></a><strong>Applications supporting accounts in any organizational directory (Any Azure AD directory – Multi-tenant)</strong></h3><p>IIf the multi-tenant application is configured to rely on the “<a href="https://login.microsoftonline.com/common/discovery/v2.0/keys">common</a>” v2.0 keys endpoint (instead of “Organizations”), then it is affected but also should be considered misconfigured. The official Microsoft <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">documentation</a> is not clear on when the “common” endpoint should be used, and therefore, some multi-tenant applications could be affected as well.</p><h3><span></span><a id="applications-supporting-accounts-in-this-organizational-directory-only-singletenant-37"></a><strong>Applications supporting accounts in this organizational directory only (Singletenant)</strong></h3><p>Single tenant applications were not affected.&nbsp;</p><div><p>How different types of users may have been affected depending on the application type and whether it was properly validating access tokens</p></div><h2><span></span><a id="how-does-key-forging-work-40"></a>How does key forging work?&nbsp;</h2><p>OpenID keys are fundamentally JWTs signed by an authorized private key. As part of the Azure Active Directory token validation procedure, the app developer must confirm that the key is indeed signed by the relevant authority for the intended scope, and that the token's <code>aud</code> field matches the targeted application’s scope.</p><p>To confirm whether the token was truly signed by a trusted Azure authority, the application developer queries a metadata endpoint (named <code>jwks_uri</code>) to pull the permitted certificates for signature verification and verify the token against it.</p><p>To forge a valid access token, the threat actor could have crafted a JWT token, populated it with a victim’s data (e.g. email address), and finally signed it with the trusted compromised key that is listed under the Azure Active Directory public certificates’ endpoint. By submitting the signed token to a targeted application, the malicious actor could have then impersonated the victim.</p><p>Here is a fictitious example of such a forged OpenID token signed by the compromised encryption key, <code>1LTMzakihiRla_8z2BEJVXeWMqo</code>:</p><p>According to Microsoft's guidelines, in order for the token to be considered valid, the issuer claim (<code>iss</code>) must be set to https: //sts.windows.net/9188040d-6c67-4c5b-b112-36a304b66dad/v2.0 since it was specified in the issuer field within the <code>jwks_uri</code> endpoint. As for the tenant ID claim (<code>tid</code>), it must accordingly be set to <code>9188040d-6c67-4c5b-b112-36a304b66dad</code>, the MSA tenant’s ID.</p><p>For AAD mixed-audience applications (multi-tenant and personal-account), any token signed by the MSA tenant for an Azure AD account could be deemed valid, as long as it impersonates a personal account.</p><p>For additional details, check out Microsoft's <a href="https://learn.microsoft.com/en-us/azure/active-directory/develop/access-tokens#validating-tokens">official guidelines</a> on how to verify ID Tokens.</p><h2><span></span><a id="are-azure-customers-still-at-risk-49"></a>Are Azure customers still at risk?&nbsp;</h2><p>Due to Microsoft's revocation of the compromised key, Azure Active Directory applications will no longer accept forged tokens as valid tokens. Tokens with extended expiration dates will also be rejected by these applications.</p><p>However, during previously established sessions with customer applications prior to the revocation, the malicious actor could have leveraged its access to establish persistence. This could have occurred by leveraging the obtained application permissions to issue application-specific access keys or setting up application-specific backdoors. A notable example of this is how, prior to Microsoft’s mitigation, Storm-0558 issued valid Exchange Online access tokens by forging access tokens for Outlook Web Access (OWA).</p><p>There is another potential risk to applications that retained copies of the AAD public keys prior to Microsoft's certificate revocation. Applications that rely on local certificate stores or cached keys and still trust the compromised key remain susceptible to token forgery. It is imperative for these applications to immediately refresh the list of trusted certificates. Microsoft advises refreshing the cache of local stores and certificates at least once a day.</p><h2><span></span><a id="recommendations-for-azure-users-53"></a>Recommendations for Azure users&nbsp;</h2><p>To identify whether a compromised key was used in your environment, identify all potentially affected applications in your environment, search for forged tokens usage (as explained in the next section) and leverage the Indicators of Compromise (IoCs) <a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=Indicators%20of%20compromise">published by Microsoft</a> on their blog to look for any activity that originates from the IP addresses provided by Microsoft.</p><p>In addition, make sure that none of the applications use a cached version of the Microsoft OpenID public certificates, and if so, refresh the cache.</p><p>Microsoft has added additional verifications to the official Azure SDK, which are designed to prevent the use of MSA keys to authenticate to organization accounts. Users of the package are advised to update it to the <a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet">latest version</a>.</p><h2><span></span><a id="how-to-detect-the-compromised-key-in-your-environment-57"></a>How to detect the compromised key in your environment&nbsp;</h2><p>Since the threat actor can forge access tokens offline, there is no trail in the Azure portal for token issuance. The only way for cloud customers to identify whether the key was used to target their apps or users is by reviewing application-specific logs for potentially affected AAD apps. Therefore, application owners who want to protect their systems will have to check whether a forged token has been used against their applications.</p><p>To the best of our knowledge, the only affected applications were those that utilized Microsoft v2.0 access token verification using the endpoints ”<a href="https://login.microsoftonline.com/common/discovery/v2.0/keyshttps:/login.microsoftonline.com/common/discovery/v2.0/keys%20common">https://login.microsoftonline.com/common/discovery/v2.0/keyscommon</a>“ and “<a href="https://login.microsoftonline.com/consumers/discovery/v2.0/keys">https://login.microsoftonline.com/consumers/discovery/v2.0/keys</a>“. These parameters make it feasible to filter out applications that were not exposed to this issue.&nbsp;</p><p>First, to identify which AAD applications in your environment might be affected, you can run the following Azure CLI command:&nbsp;</p><p>Additionally, your AAD applications might also be associated with Azure WebApps. To identify which AAD apps are redirecting to any of your WebApps, you can run the following CLI command:&nbsp;</p><p>Next, to identify potentially malicious activities in applications, it is necessary to examine suspicious authentication attempts via OpenID tokens signed by the compromised key. This can be done by unpacking the access tokens used against the application and searching for the string <code>1LTMzakihiRla_8z2BEJVXeWMqo</code> within the <code>kid</code> field of the JOSE Header.&nbsp;</p><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/#:~:text=inactive%20MSA">According to Microsoft</a>, the compromised key was inactive and therefore any access token signed by this key must be considered suspicious.</p><p>Unfortunately, there is a lack of standardized practices when it comes to application-specific logging. Therefore, in most cases, application owners do not have detailed logs containing the raw access token or its signing key. As a result, identifying and investigating such events can prove exceedingly challenging for app owners.</p><p>When examining an AAD application configured solely for multi-tenant authentication (without support for Microsoft personal accounts), it is possible to detect forged tokens by filtering for `iss` and `tid` claims within the access token. Applications commonly use these fields and they are more likely to be present in application logs. Moreover, any attempt to connect with an access token signed by the MSA tenant ID <code>9188040d-6c67-4c5b-b112-36a304b66dad</code> may indicate the use of a compromised key.</p><p>Finally, if you’ve enabled <a href="https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables/appservicehttplogs">HTTP Logs</a> in your WebApp, you might be able to see which IP addresses have accessed your application. Based on Microsoft’s blogpost, the following IP addresses are associated with the threat actor, so you should validate if your WebApp might have been impacted by running the following query in Log Analytics for each of your potentially affected Web Apps:&nbsp;</p><p>For additional guidance on searching for signs of persistence in your environment, see our <a href="https://www.wiz.io/blog/hunting-for-signs-of-persistence-in-the-cloud-an-ir-guide#hunting-for-signs-of-persistence-in-azure-24">“CircleCI Incident Sign of Persistence” blog</a>.&nbsp;</p><h2><span></span><a id="key-takeaways-72"></a>Key Takeaways&nbsp;</h2><p>The full impact of this incident is much larger than we Initially understood it to be. We believe this event will have long lasting implications on our trust of the cloud and the core components that support it, above all, the identity layer which is the basic fabric of everything we do in cloud. We must learn from it and improve.</p><p>At this stage, it is hard to determine the full extent of the incident as there were millions of applications that were potentially vulnerable, both Microsoft apps and customer apps, and the majority of them lack the sufficient logs to determine if they were compromised or not. However there are some critical actions items that application owners should perform. The first and foremost is to update their Azure SDK to the latest version and ensure their application cache is updated, otherwise their apps may still be vulnerable to a threat actor using the compromised key.</p><p>We will continue to closely monitor this incident and provide updates; this is still an ongoing investigation and there are many unanswered questions (how did the threat actor acquire the key? When exactly did it happen? Were other keys compromised as well?). Finally, we want to thank the Microsoft team for working closely with us on this blog and helping us ensure it is technically accurate.</p><div><div><p><span>See for yourself...</span></p><p>Learn what makes Wiz the platform to enable your cloud security operation</p></div><svg viewBox="0 0 162 177" fill="none" xmlns="http://www.w3.org/2000/svg"><g clip-path="url(#request-demo-block_svg__a)"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect><path fill="#0254EC" d="M1 1h160v22H1z"></path><g clip-path="url(#request-demo-block_svg__b)"><path d="M23.151 7.883c.202.21.593.315.825.36a.03.03 0 0 1 .017.011.032.032 0 0 1 .007.02.032.032 0 0 1-.007.02.03.03 0 0 1-.017.01c-.232.047-.623.152-.825.361-.19.197-.29.57-.337.815a.03.03 0 0 1-.011.018.029.029 0 0 1-.038-.001.031.031 0 0 1-.01-.019c-.034-.228-.123-.572-.354-.813-.202-.21-.593-.314-.825-.36a.03.03 0 0 1-.017-.01.032.032 0 0 1 0-.04.03.03 0 0 1 .017-.011c.233-.046.624-.15.825-.36.2-.21.302-.617.346-.859a.031.031 0 0 1 .01-.018.029.029 0 0 1 .038 0c.005.005.009.011.01.018.044.242.145.649.346.858Zm-8.61 1.626v6.395c0 .025.01.05.027.068a.09.09 0 0 0 .065.028h1.365a.09.09 0 0 0 .065-.028.098.098 0 0 0 .027-.068V9.509c0-.025-.01-.05-.027-.067a.09.09 0 0 0-.065-.028h-1.365a.089.089 0 0 0-.065.028.096.096 0 0 0-.027.067Zm2.132 6.367a.087.087 0 0 0 .034.113c.012.007.026.01.04.01h4.957a.09.09 0 0 0 .066-.027.098.098 0 0 0 .027-.068v-1.252a.098.098 0 0 0-.027-.068.093.093 0 0 0-.066-.028h-2.5a.08.08 0 0 1-.041-.01.087.087 0 0 1-.032-.115l2.6-4.892a.087.087 0 0 0-.002-.084.083.083 0 0 0-.03-.03.08.08 0 0 0-.04-.011h-4.91a.089.089 0 0 0-.066.027.099.099 0 0 0-.028.068v1.387a.1.1 0 0 0 .028.068.09.09 0 0 0 .066.028h2.18c.015 0 .029.003.041.01a.087.087 0 0 1 .034.113l-2.331 4.761Zm-2.706-6.463h-1.435a.09.09 0 0 0-.052.017.095.095 0 0 0-.033.045l-1.01 2.755a.034.034 0 0 1-.012.015.031.031 0 0 1-.037.002.033.033 0 0 1-.012-.015L10.17 9.494a.166.166 0 0 0-.056-.069.157.157 0 0 0-.081-.03h-.002a.157.157 0 0 0-.084.03.166.166 0 0 0-.057.07l-1.207 2.737a.033.033 0 0 1-.012.015.032.032 0 0 1-.036-.001.033.033 0 0 1-.012-.016l-1.01-2.755a.095.095 0 0 0-.034-.045.09.09 0 0 0-.052-.017H6.092a.09.09 0 0 0-.043.011.094.094 0 0 0-.033.031.099.099 0 0 0-.01.09l2.373 6.431a.032.032 0 0 0 .029.022.031.031 0 0 0 .019-.005.034.034 0 0 0 .012-.014l1.446-3.013a.166.166 0 0 1 .06-.069.157.157 0 0 1 .17 0c.027.017.047.04.06.069l1.446 3.013c.003.006.008.011.013.014a.032.032 0 0 0 .036-.001.035.035 0 0 0 .011-.016l2.372-6.432a.1.1 0 0 0-.01-.089.09.09 0 0 0-.076-.042Z" fill="#fff"></path></g><path fill="#fff" d="M-22 34h192v136H-22z"></path><path d="M111 45.416h21.6" stroke="url(#request-demo-block_svg__c)" stroke-linecap="round"></path><path d="M76.2 45.416h31.2" stroke="#FFAB31" stroke-linecap="round"></path><ellipse cx="142.2" cy="46.631" rx="9.6" ry="9.715" fill="#0073CF"></ellipse><path d="M145.674 37.96c-.022-.123-.043-.243 0-.363a.854.854 0 0 0-.059-.048 9.412 9.412 0 0 0-1.286-.393c-.402-.085-.801-.15-1.195-.195a9.608 9.608 0 0 0-.934-.045c-3.792 0-7.071 2.225-8.631 5.456.172.289.231.631.283.927.012.072.024.14.037.205.16.79.418 1.501.988 2.107.19.2.339.436.489.672.198.31.396.622.689.86.358.293.738.546 1.195.606 1.473.196 2.378 2.156 1.608 3.373-.244.386-.187.732.14 1.09a6.8 6.8 0 0 1 .546.712c.228.327.457.654.757.924.181.164.205.4.201.635a11.3 11.3 0 0 1-.16 1.68 9.534 9.534 0 0 0 2.264.174c-.011-.45.139-.77.627-.87a.993.993 0 0 0 .617-.462c.378-.611.917-1.05 1.466-1.483.443-.351.736-.789.8-1.37.07-.637 0-.737-.614-.808-.183-.021-.366-.038-.549-.054l-.28-.026c-.024-.003-.05-.004-.076-.006-.145-.01-.308-.02-.341-.152-.122-.488-.486-.64-.85-.793-.14-.059-.28-.117-.407-.195-.614-.375-1.249-.65-1.982-.733-.629-.07-1.387-.304-1.59-.86-.101-.276-.299-.47-.494-.662-.252-.249-.499-.491-.516-.895-.004-.131-.164-.291-.341-.28-.154.009-.163.127-.172.24a.797.797 0 0 1-.009.089c-.031.164-.077.324-.258.355-.21.033-.308-.133-.393-.289-.247-.455-.193-1.234.098-1.492.505-.444 1.246-.47 1.75-.055l.047.04c.077.07.155.14.268.1.164-.06.166-.22.153-.358-.033-.38.092-.683.36-.948.287-.282.429-.628.392-1.048-.022-.24.032-.504.332-.495.386.011.685-.164.989-.342.067-.04.135-.08.204-.117.273-.151.391-.276.251-.613-.151-.36.081-.642.485-.657.075-.002.15.008.225.018.081.011.161.022.241.017.225-.013.419-.144.483-.348.058-.193-.06-.21-.18-.228-.06-.009-.12-.017-.159-.047a2.994 2.994 0 0 0-.21-.144c-.12-.077-.24-.154-.336-.256-.319-.338-.697-.573-1.104-.782-.872-.448-1.536-.026-1.523.975.002.14.002.282-.004.422-.007.13-.048.25-.175.302-.153.062-.306-.002-.361-.131-.186-.437-.549-.652-.914-.868a7.05 7.05 0 0 1-.239-.145c-.387-.246-.387-.548-.081-.872.29-.306.601-.586.948-.824.175-.117.345-.237.402-.464.07-.268.188-.517.496-.537.238-.015.322.158.405.33.025.052.051.105.08.152.284.453.63.87 1.11 1.085.179.08.333-.028.493-.14.111-.078.224-.158.351-.18.142-.024.345-.064.332-.27-.013-.211-.208-.26-.38-.3a1.786 1.786 0 0 0-.09-.017.844.844 0 0 1-.164-.04c-.19-.078-.347-.207-.295-.436.051-.217.236-.293.444-.293.264-.002.461.14.631.324.122.133.241.27.359.405.25.287.501.574.778.83.544.504 1.234.357 1.521-.26.066-.142.041-.28.017-.417ZM150.261 41.353a9.749 9.749 0 0 1 1.539 5.278c0 .436-.028.866-.084 1.288a.311.311 0 0 1-.176.088 5.561 5.561 0 0 1-.115-.102c-.092-.082-.184-.165-.283-.236-.142-.1-.304-.128-.389.074l-.044.115c-.073.202-.149.412-.399.397l-.082-.004c-.343-.017-.693-.034-1.004-.273-1.036-.8-1.198-2.298-.483-3.188.096-.12.185-.278.199-.426.052-.666.526-.902 1.04-1.11.031-.013.062-.025.094-.036.082-.03.164-.061.24-.104.094-.054.162-.147.131-.265-.033-.12-.138-.148-.249-.14-.035.003-.07.009-.105.015a.905.905 0 0 1-.1.014c-.046.003-.093.008-.141.013-.221.024-.453.049-.563-.19-.093-.202.041-.27.179-.34.076-.038.154-.077.195-.14a7.55 7.55 0 0 1 .499-.61l.101-.118Z" fill="#71D96A"></path><path d="M139.704 46.19a.398.398 0 0 1 .112.014l.081.026h.001c.283.088.624.195.539.527-.05.194-.272.125-.481.06a1.659 1.659 0 0 0-.207-.056.56.56 0 0 1-.195-.073 1.113 1.113 0 0 0-.135-.061c-.144-.057-.294-.117-.256-.29.035-.165.18-.156.32-.148.06.004.118.007.167-.003l-.002.002.056.003ZM141.204 46.935a1.417 1.417 0 0 1-.142-.025l-.002-.002c-.029.004-.06.006-.091.008-.149.01-.307.02-.289.223.022.24.266.246.452.237.034-.001.073.002.114.005.157.012.336.025.319-.205-.014-.19-.192-.216-.361-.24Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM75 39.344c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.072c0-3.353-2.687-6.071-6-6.071ZM136.2 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path d="M45 87.919v25.501" stroke="url(#request-demo-block_svg__d)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251-30 7.286-30 25.502" stroke="url(#request-demo-block_svg__e)" stroke-linecap="round"></path><path d="M45 87.918c0 21.251-30 7.286-30 25.501" stroke="url(#request-demo-block_svg__f)" stroke-linecap="round"></path><path d="M75 51.488c0 21.251 30 7.286 30 25.502" stroke="#FFAB31" stroke-linecap="round"></path><path d="M45 87.918c0 21.251 30 7.286 30 25.501" stroke="url(#request-demo-block_svg__g)" stroke-linecap="round"></path><path d="M105 87.918c0 21.251 31.2 7.286 31.2 25.501" stroke="#FFAB31" stroke-linecap="round"></path><path d="M136 126c0 21.667-30 7.429-30 26" stroke="url(#request-demo-block_svg__h)" stroke-linecap="round"></path><path d="M75 126c0 21.251 31.2 7.286 31.2 25.501" stroke="url(#request-demo-block_svg__i)" stroke-linecap="round"></path><path d="M79.8 81.846h20.4" stroke="url(#request-demo-block_svg__j)" stroke-linecap="round"></path><path d="M111 81.846h19.2" stroke="url(#request-demo-block_svg__k)" stroke-linecap="round"></path><path d="M70.2 81.846H51" stroke="url(#request-demo-block_svg__l)" stroke-linecap="round"></path><path d="M81 156h19.2" stroke="url(#request-demo-block_svg__m)" stroke-linecap="round"></path><path d="M69.2 156H50" stroke="url(#request-demo-block_svg__n)" stroke-linecap="round"></path><path d="M39 81.846H21" stroke="url(#request-demo-block_svg__o)" stroke-linecap="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M15 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FF1721"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#3679DB"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM75 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072ZM45 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM135 75.775c-3.314 0-6 2.718-6 6.072s2.686 6.072 6 6.072 6-2.718 6-6.072c0-3.353-2.687-6.072-6-6.072Z" fill="#FFAB31"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M105 150c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM15 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#71D96A"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M45 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072ZM75 113.42c-3.314 0-6 2.718-6 6.072 0 3.353 2.686 6.071 6 6.071s6-2.718 6-6.071c0-3.354-2.687-6.072-6-6.072Z" fill="#36AD82"></path></g><rect x="0.5" y="0.574" width="161" height="175" rx="3" stroke="#fff"></rect><defs><linearGradient id="request-demo-block_svg__c" x1="134.657" y1="45.416" x2="111.514" y2="45.416" gradientUnits="userSpaceOnUse"><stop stop-color="#0073CF"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__d" x1="0" y1="113.42" x2="0" y2="95.569" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__e" x1="45.001" y1="77.168" x2="60.065" y2="84.104" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__f" x1="15.001" y1="113.598" x2="30.065" y2="120.534" gradientUnits="userSpaceOnUse"><stop stop-color="#71D96A"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__g" x1="45" y1="87.918" x2="75.294" y2="113.065" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#36AD82"></stop></linearGradient><linearGradient id="request-demo-block_svg__h" x1="121" y1="134" x2="121" y2="144.5" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__i" x1="90.6" y1="126" x2="90.6" y2="151.501" gradientUnits="userSpaceOnUse"><stop stop-color="#36AD82"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__j" x1="79.8" y1="81.846" x2="103.037" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__k" x1="111" y1="81.846" x2="130.2" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__l" x1="70.327" y1="81.846" x2="48.457" y2="81.846" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#3679DB"></stop></linearGradient><linearGradient id="request-demo-block_svg__m" x1="80.873" y1="156" x2="102.743" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#71D96A"></stop></linearGradient><linearGradient id="request-demo-block_svg__n" x1="69.327" y1="156" x2="47.457" y2="156" gradientUnits="userSpaceOnUse"><stop stop-color="#FFAB31"></stop><stop offset="1" stop-color="#FFAB31"></stop></linearGradient><linearGradient id="request-demo-block_svg__o" x1="37.925" y1="81.719" x2="21" y2="81.719" gradientUnits="userSpaceOnUse"><stop stop-color="#3679DB"></stop><stop offset="1" stop-color="#FF1721"></stop></linearGradient><clipPath id="request-demo-block_svg__a"><rect x="1" y="1.074" width="160" height="174" rx="2.5" fill="#fff"></rect></clipPath><clipPath id="request-demo-block_svg__b"><path fill="#fff" transform="translate(6 7)" d="M0 0h18v9H0z"></path></clipPath></defs></svg></div><h2><span></span><a id="references-77"></a>References&nbsp;</h2><ul><li><p><a href="https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/">https://msrc.microsoft.com/blog/2023/07/microsoft-mitigates-china-based-threat-actor-storm-0558-targeting-of-customer-email/</a>&nbsp;</p></li><li><p><a href="https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a">https://www.cisa.gov/news-events/cybersecurity-advisories/aa23-193a</a>&nbsp;</p></li><li><p><a href="https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/">https://blogs.microsoft.com/on-the-issues/2023/07/11/mitigation-china-based-threat-actor/</a>&nbsp;</p></li><li><p><a href="https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/">https://www.microsoft.com/en-us/security/blog/2023/07/14/analysis-of-storm-0558-techniques-for-unauthorized-email-access/</a>&nbsp;</p></li><li><p><a href="https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files">https://github.com/AzureAD/azure-activedirectory-identitymodel-extensions-for-dotnet/pull/2136/files</a>&nbsp;</p></li><li><p><a href="https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c">https://github.com/MicrosoftDocs/azure-docs/commit/f17445bb9202a89964ea7311c4374806adfcb28c</a>&nbsp;</p></li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI improperly used 702 surveillance powers on US senator (185 pts)]]></title>
            <link>https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</link>
            <guid>36822654</guid>
            <pubDate>Sat, 22 Jul 2023 02:39:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/">https://thehill.com/homenews/administration/4110850-fbi-improperly-used-702-surveillance-powers-on-us-senator/</a>, See on <a href="https://news.ycombinator.com/item?id=36822654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
<p>The FBI improperly used surveillance powers to conduct searches for information on a U.S. senator, a state lawmaker and a state judge, according to court records released Friday as part of a public records request.&nbsp;</p>



<p>The FBI’s improper use of Section 702 of the Foreign Intelligence Surveillance Act was documented in an opinion from the Foreign Intelligence Surveillance Court (FISC) and is sure to pose challenges for an intelligence community lobbying for the reauthorization for what it sees as one of its most vital tools.</p>





<p>The tool – which allowed for warrantless spying on foreigners located abroad – has long been criticized as a backdoor tool for gaining information on Americans who may be communicating with those being surveilled.</p>



<p>And critics complain the information gathered by the agency through 702 is too easily tapped for investigations with no foreign nexus.</p>



<p>The surveillance court outlined three examples of instances where FBI personnel conducted searches of “sensitive query terms,” like those of U.S. public officials or candidates, without first seeking approval from the FBI’s deputy director.</p>



<p>“In June 2022, an analyst conducted four queries of Section 702 information using the last names of a U.S. Senator and a state senator, without further limitation,” the opinion states.&nbsp;</p>



<p>While the two were believed to be targets of “a specific foreign intelligence service,” the National Security Division at the Department of Justice determined the FBI did not meet the needed standard for running such a query.&nbsp;</p>



<p>And in October of that year, “a Staff Operations Specialist ran a query using the Social Security number of a state judge who “had complained to [the] FBI about alleged civil right violations perpetrated by a municipal chief of police.”</p>





<p>The opinion does not make clear the identity of those searched.</p>



<p>The American Civil Liberties Union (ACLU), whose efforts prompted the release of the court opinion, highlighted other alarming patterns.</p>



<p>“These disturbing new revelations show how Section 702 surveillance, a spy program the government claims is focused on foreign adversaries, is routinely used against Americans, immigrants, and people who are not accused of any wrongdoing,” Patrick Toomey, deputy director of the ACLU’s National Security Project, said in a statement.</p>





<p>“The FBI continues to break the rules put in place to protect Americans, running illegal searches on public officials including a U.S. senator, and it’s long past time for Congress to step in. As Congress debates reauthorizing Section 702, these opinions make clear why fundamental reforms are urgently needed.”</p>



<p>The FBI and Justice Department in recent weeks have noted the roll out of some FISA reforms – pointing to a&nbsp;<a href="https://thehill.com/policy/national-security/3978746-fisa-702-searches-foreign-nationals-rise-citizen-queries-drop/" target="_blank" rel="noreferrer noopener">drop in overall queries</a>&nbsp;that involved U.S. citizens.</p>



<p>The opinion, originally filed in April, does comment on improvements from the bureau.</p>





<p>“Despite the reported errors, there is reason to believe that the FBI has been doing a better job in applying the querying standard,” Judge Rudolph Contreras writes in the opinion.</p>



<p>“In some cases, F.B.I. personnel apparently misapplied the querying standard to a group of similarly situated persons, but those violations do not approach the scale of a number of prior ones.”</p>



<p>The FBI stressed that detail in its response to the opinion’s release.</p>





<p>“The 2023 FISC Opinion confirms the significant improvement in the FBI’s Section 702 querying compliance since the implementation of our substantial reforms,” FBI Director Christopher Wray said in a statement.&nbsp;</p>



<p>“Section 702 is critical in our fight against foreign adversaries. We take seriously our role in protecting national security and we take just as seriously our responsibility to be good stewards of our Section 702 authorities. Compliance is an ongoing endeavor, and we recently announced new additional accountability measures. We will continue to focus on using our Section 702 authorities to protect American lives and keeping our Homeland safe, while safeguarding civil rights and liberties.”</p>



<p>It’s not the first time a lawmaker has been improperly searched via FISA 702, with Rep. Darin LaHood (R-Ill.) saying in March that his name was searched using the tool.</p>





<p>Section 702 is set to expire at the end of the year, and lawmakers on both sides of the aisle have said they will refuse to back its reauthorization without significant reforms.</p>



<p>The FBI on Friday sent a letter to House and Senate leaders noting that several different reviews found agents have complied with FISA guidelines at least 98 percent of the time.</p>



<p>But in a call with reporters Friday, a senior FBI official said the agency is working on building trust with lawmakers who may feel personally impacted by the issue.</p>





<p>“We are communicating as much as we can to build that level of confidence so that they understand how we are using the tool and how we are holding people accountable for when they are not using the tool correctly. But also to make sure they understand when we do and do not do such things as query members of Congress,” the official said in response to a question from The Hill.</p>



<p>“There was an unacceptably high level of non compliance and various non compliance queering behavior that was going on,” the official added.&nbsp;</p>



<p>“We’ve been very open about [how] we accepted the fact that that was unacceptable. That’s not what we expect from ourselves as an organization.”&nbsp;</p>







<p>Sen. Ron Wyden (D-Ore.), however, said lawmakers are not assured that intelligence agencies are being fully forthcoming about how they use FISA.</p>



<p>“For years, as government officials have provided misleadingly narrow testimony about who is targeted under Section 702, I have pushed to get the government to come clean.&nbsp; The revelation that 702 is used against ‘foreign governments and related entities’ directly impacts Americans’ privacy, as American journalists, businesspeople, students and others all have legitimate reason to communicate with foreign governments,” Wyden said in a statement.</p>



<p>“The fact they can be swept up in 702 collection further highlights the need for reforms to protect their privacy.”</p>

</div><p>Copyright 2023 Nexstar Media Inc. All rights reserved. This material may not be published, broadcast, rewritten, or redistributed.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Employees Bid on Anchor Brewery (146 pts)]]></title>
            <link>https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</link>
            <guid>36821861</guid>
            <pubDate>Sat, 22 Jul 2023 00:23:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/">https://vinepair.com/booze-news/anchor-employees-brewery-takeover-bid/</a>, See on <a href="https://news.ycombinator.com/item?id=36821861">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
		<p><em>This is a developing story, check back for updates.</em></p>
<p>At a meeting last Wednesday at Anchor Brewing Co., executives told brewery employees that the historic San Francisco firm would be shut down after over a century and a half in business. One week later, employees have something to tell the executives: if you’ll sell us Anchor, we’ll figure out a way to buy it.</p>
<p>In a brief letter sent Wednesday evening and shared with VinePair, the business agent for Anchor Brewing Union advised Sapporo USA president Mike Minami “that workers of Anchor Brewing have met, discussed, and decided to launch an effort to purchase the brewery and run it as a worker co-op.”</p>
<p>“We are not asking for a handout or charity,” wrote Pedro de Sá, a business agent at International Longshore and Warehouse Union Local 6, which represents roughly 40 workers at the brewery. “All we want is a fair shot at being able to continue to do our jobs, make the beer we love, and keep this historic institution open. We do not want the brewery and brand we love to be sold off before we even had a chance.”</p>
<p>de Sá, speaking on behalf of union workers who voted earlier in the day to take this step, asked Minami to respond by the end of the day on Friday, July 21 indicating whether Sapporo USA was open to working “cooperatively and transparently through this process” with the union, specifically with regards to “creat[ing] the framework and rais[ing] the funds necessary for this purchase.”</p>
<p>Patrick Machel, a production worker at the brewery and a shop steward for the Anchor Brewing Union, says that the vast majority of the union’s rank-and-file workers, as well as an unspecified number of managers, support the longshot effort. “Most of us that work here were born and raised here. We work here because we love it, we grew up with Steam Beer,” he tells VinePair. Now, they’ll try to save Anchor from the scrap heap.</p>
<p>VinePair first <a href="https://vinepair.com/booze-news/anchor-brewing-company-sale/">reported</a> that Sapporo USA was on the verge of selling or shuttering Anchor on the evening of July 11. Less than 12 hours after our initial report, Sam Singer, a representative for Anchor and Sapporo USA, issued a press release announcing the brewery would “cease operations and liquidate the business following a combination of challenging economic factors and declining sales.” (The release did not mention Sapporo USA, but current and former workers were quick to tell <a href="https://vinepair.com/articles/sapporo-usa-anchor-brewing-liquidation-analysis/">VinePair’s Hop Take column</a> that the parent company mismanaged the brewery into dysfunction.)</p>
<p>As word spread of Anchor’s imminent closure last week, San Franciscans <a href="https://www.sfgate.com/food/article/anchor-brewing-final-beers-flying-off-shelves-sf-18199789.php">flocked</a> to the unmistakable Art Deco plant on Potrero Hill to pay their respects to the brewery that has kept the City by The Bay stocked with steam beer since 1871. Lines at the neighboring Anchor Public Taps stretched around the block as people clamored to buy whatever beer was left in the tanks.</p>
<p>What would happen to Anchor? In a year of searching, the company’s release claims, no buyer had emerged to acquire it whole, as a going concern. (The release does not state the price Sapporo USA was asking for the firm; it acquired Anchor six years ago in a provisional $85 million deal.) Last week, Narragansett Beer <a href="https://vinepair.com/booze-news/narragansett-beer-petition-anchor-brewing/">circulated</a> a petition to drum up support for rescuing the brewery, and several private-equity investors, perhaps impressed by the outpouring of local love for the august old brand, expressed interest to this reporter about acquiring it.</p>
<p>This past weekend, a handful of San Francisco entrepreneur types <a href="https://www.sfchronicle.com/food/wine/article/save-anchor-steam-18199818.php">described</a> to the hometown paper their plans for resurrecting Anchor; the ideas included a website to tease future crowdfunding opportunities, and a reality show about bringing the idiosyncratic brewery back to life working-titled “How hard could it be.” But the plan outlined last week in the release still stands: to turn Anchor over to an assignee for the benefit of creditors (A.B.C.), a third-party manager tasked with the orderly wind-down and sale of the business and its assets to whoever would buy them, and for whatever purpose.</p>
<p>Workers want to preempt Anchor’s real estate, equipment, and intellectual property being sold off piecemeal to the highest bidders by acquiring it from Sapporo USA and running it as a co-op, says Machel.</p>
<p>“We couldn’t go down without some way of fighting for ourselves and the community we love.”</p>
<p><em><strong>This story is a part of <a href="https://vinepair.com/business-of-drinks/">VP Pro</a>, our free content platform and newsletter for the drinks industry, covering wine, beer, and liquor — and beyond. <a href="https://vinepair.com/vp-pro-join/">Sign up for VP Pro now!</a></strong></em></p>		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hollywood is on strike because CEOs fell for Silicon Valley’s magical thinking (143 pts)]]></title>
            <link>https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</link>
            <guid>36821347</guid>
            <pubDate>Fri, 21 Jul 2023 23:19:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking">https://www.latimes.com/business/technology/story/2023-07-21/column-hollywood-sag-aftra-strike-strike-silicon-valleys-magical-thinking</a>, See on <a href="https://news.ycombinator.com/item?id=36821347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-element="story-body" data-subscriber-content=""> <p>In one respect, the <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-16/sag-aftra-strike-actors-writers-strike-hollywood-production-film-tv-disruption-fall-season"><u>actors and writers of Hollywood</u></a> uniting on the picket lines in <a href="https://www.latimes.com/entertainment-arts/business/story/2023-07-14/actors-strike-sag-aftra-joins-writers-guild-picket-lines"><u>a historic, industry-shaking strike</u></a> is a tale as old as time: one of workers fighting bosses for better pay. Yet the reason this battle is shaping up to be so uniquely intractable and momentous — as you might have gathered from all the headlines about  artificial intelligence and streaming economics — is very much of our moment.</p><p>But it’s not, ultimately, technology that’s at the root of the problem. It’s that the studio executives both new and old have embraced the powerful — and ultimately disastrous — magical thinking pumped out by Silicon Valley for the last  10 years.</p><p>Studio heads are touting the disruptive properties of digital streaming, the transformative power of AI, a brave, unpredictable new world for entertainment writ large — and how writers and actors must adapt to this new future. But just as it did when it was issuing from the tech sector during the 2010s, this talk too often amounts to a smokescreen that lets executives and investors line their pockets and risks leaving workers holding the bag.</p><p>“These companies blew up a successful business model that the public enjoyed,  that was immensely profitable,  and they replaced it with a mishmash that we have now,” Adam Conover, the star of “Adam Ruins Everything”<i> </i>and a  negotiating committee member of the Writers Guild of America, tells me. “And now, they’re refusing to update the contract to reflect those changes.”</p><p>We’ve heard a lot about the ways that studios want to reserve the right to use AI — to create endlessly usable digital replicas of actors, to generate scripts that writers <a href="https://www.latimes.com/business/technology/story/2023-05-11/column-the-writers-strike-is-only-the-beginning-a-rebellion-against-ai-is-underway"><u>will be paid lower rates to fix up</u></a>. We’ve also heard about the new economic picture ushered in by streaming, about an industry in the throes of change, and the necessity of belt-tightening as a result. </p><p>We’ve heard Disney Chief Executive Bob Iger saying the  demand by the Screen Actors Guild for fair payment in the new digital landscape “isn’t realistic,” and heard how Netflix saw declining user sign-ups and stock prices last year. Yet  Iger reportedly makes <a href="https://www.rollingstone.com/tv-movies/tv-movie-features/disney-staffers-angry-ceo-bob-iger-actors-strike-writers-strike-1234789713/" target="_blank"><u>$27 million a year</u></a>, while Netflix <a href="https://www.wsj.com/articles/netflix-nflx-q2-earnings-report-2023-92a620c8" target="_blank"><u>just raked in $1.5 billion in net profit in the last quarter</u></a>.</p><p>So what’s really going on? And how did we get here?</p><p>First, we need to understand why the 2010s may well come to be remembered as the great decade of magical thinking for Silicon Valley. Drunk on a truly transformational first decade of the 21st century — one that saw Google, Amazon, the iPhone and social media storm the world stage — flush tech investors turned their sights toward the next generation of startups, eager to see them do the same.</p><p>The formula for seeking out that next multibillion-dollar “unicorn,” in hindsight, was pretty simple: The next wave of startups had to promise that it would disrupt a stale industry with a newer, high-tech, app-driven alternative, promise the potential for vast scale and promise that it could do so fast. So we saw the rise of Uber and Lyft, each of which vowed to revolutionize transit, and we got the likes of WeWork, which set out to usher in the future of co-working, and Theranos, which would do the same for at-home blood testing.</p><p>We know how it ended. Uber and Lyft have never been sustainably profitable, WeWork collapsed dramatically when it became clear that it was merely a wildly over-leveraged real estate company, and Theranos’ futuristic medical technology was outright fraudulent. </p><p>Unlike many of the 21st century’s first-wave tech companies and products, which found both markets and roads to profitability, these were pipe dreams, propped up by a fire hose of investment cash, big-talking founders and the very real — and at the time, quite understandable! — sense that Silicon Valley was the place that determined how the future was made.</p><p>As the 2010s began, Netflix sat somewhere between the old guard and the new. It introduced online streaming in 2007, and had a real product with real demand, as well as an established business in its DVD-by-mail rental service. Yet its ambitions were hypercharged by a newfangled sense that it could disrupt the old school Hollywood industry and scale endlessly — there was no reason everyone in the world with access to a screen couldn’t subscribe.</p><p><a href="https://www.reuters.com/article/us-netflix-stock/netflix-shares-soar-after-icahn-reports-10-percent-stake-purchase-idUSBRE89U1GA20121101" target="_blank"><u>Big-name investors</u></a> sank hundreds of millions into Netflix’s new vision. As it began producing original content in 2013, it applied a distinctly next-wave Silicon Valley ethos. It would make massive upfront investments, bankrolling huge productions such as the David Fincher-helmed, Kevin Spacey-starring “House of Cards,” elbowing its way into the prestige TV pack, promising not only to compete but also to do it better: It would offer all the episodes at once, on demand, and viewers could consume them whenever and however they wanted. Cable would become obsolete. The future was cutting the cord.</p><p>As with Uber and Lyft, whose bottomless chests of venture capital allowed them to conquer new markets once dominated by stodgy old competitors — in their case, the taxi cartels and livery cab companies — price was no object.</p><p>Right out the gate, episodes for original Netflix shows such as “House of Cards” and “Orange Is the New Black”<i> </i>cost $4 million a pop. (So did episodes of shows that few remember today, such as “Hemlock Grove.”) The spending was profligate — it soon rose to rates of <a href="https://www.indiewire.com/features/general/netflix-originals-budget-15-billion-1202036683/" target="_blank"><u>$15 billion a year</u></a> on new content — but as it did for the magical valley startups, the strategy “worked.”</p><p>“What happens is Netflix becomes the Wall Street darling, and all these other companies,” like Amazon, Disney, Apple, HBO, Paramount and NBC, “race to adopt Netflix’s business model,” Conover says. </p><p>Herein lies the trouble. Amid this boom, which for a few years ushered in a gold rush for writers and talent, Netflix et al. adopted another key ingredient of Silicon Valley’s approach: secrecy. Data about shows’ performance and viewer habits were kept proprietary; we  knew only what the streamers wanted us to know. That went for customers, performers, writers and for investors. Streaming is an inscrutable black box, about which so many stories might be told.</p><p>It’s a sticking point in the negotiations — actors and writers on streaming series want a better way to calculate the value of their work, given that the residuals they earn are so much lower than for network or cable shows. The studios have resisted. “The reason nobody really wants to open the books on this is because if Wall Street got a look,” one Hollywood insider <a href="https://www.vulture.com/2023/06/streaming-industry-netflix-max-disney-hulu-apple-tv-prime-video-peacock-paramount.html" target="_blank"><u>told New York Magazine</u></a>, “they’d have a collective stroke.”</p><p>What we’re seeing now is the fantastical thinking that Netflix and its followers could continue endless expansion running up against the physics of the real world — there are now 238 million Netflix subscribers, but those numbers <a href="https://www.latimes.com/entertainment-arts/business/story/2022-04-19/lat-et-ct-netflix-loses-subscriber-first-quarter">dropped for the first time</a> last year, and the company had to claw them back by nibbling at the corners, <a href="https://www.latimes.com/entertainment-arts/business/story/2021-03-11/netflix-password-sharing-policing">cutting off password sharing</a> and launching new, cheaper tiers that run ads.</p><p>The boom times are over. Executives know it. Wall Street knows it. And the story that we’re in a revolutionary moment of technological transformation will run out of gas soon. So the bosses are using that moment to do what Silicon Valley wound up doing when its other big swings didn’t pan out: squeeze labor. </p><p>Just as Uber and Lyft, which promised drivers rich rewards and flexible fares, started reducing rates and making it harder to earn those rewards, Netflix and the streaming cohort cut in its mold are now trying to square their promises of world conquest by slashing worker pay under the fog of magical thinking.</p><p>It’s been noted, and correctly so, that entertainment industry labor disputes often erupt when there’s a change in technology — from theaters screening projected films to the cathode ray tube of the home television, say, or the rise of YouTube and other online content in the 2000s  — and that happens for a reason. Historically, executives and management use a disorienting new technology to try to justify lowering wages of their workers, and they have done so since the days of the Industrial Revolution. </p><p>“The old CEOs knew they had to work with the unions, bargain with us,” Conover says. “The new ones don’t. So part of the point of the strike is us as labor showing the tech CEOs that no, you actually do have to deal fairly with the unions.”</p><p>Conover notes that it’s jarring to see the streamers plead poverty as an excuse not to negotiate with talent in good faith, given that show budgets and profits have both gone up. </p><p>“Netflix lied to the public and Wall Street,” he says, telling them, “‘you can watch every show ever made in perpetuity, with no ads, for $15.99 a month forever.’ That’s like Movie Pass” (the much-hyped app that allowed users to see unlimited movies for a monthly fee, before quickly going bankrupt). “That’s ludicrous.” </p><p>Ludicrous if you want to pay the people who actually create those shows for you, anyway.</p><p>What Netflix and the streamers are trying to do now is seal in a new standard under which writers and actors are treated in much the way that Uber and the gig app companies treat their independent contractor drivers. </p><p>“Uber is a perfect example,” Conover says. “Its drivers need to supply their own cars, their own gas, their own insurance and so on.” The drivers are on their own, with few to no benefits or protections, and are expected to maximize profits for the company. “And Netflix is trying to do the same thing.”</p><p>Unlike Uber, Netflix really <i>is </i>quite profitable. But in order to sustain the mythical levels of growth it has promised investors, it is turning to similar tactics — cutting workers’ hours, making work more precarious and unpredictable and reducing pay. It’s a far cry from the sleek, automated futures promised by the studio executives.</p><p>As with the biggest companies of Silicon Valley’s magical thinking era, it’s often hard to parse whether the ones touting the game-changing technologies themselves even believe in these visions — do studio execs really think consumers want to watch a parade of digital replicas of their favorite actors parroting lines from an AI-generated script? Or are they simply aware that the mere threat of such a future gives them leverage and power over the workers of today?</p><p>In the end, the answer is immaterial. Silicon Valley’s invasion of Hollywood brought with it science fictional notions of growth for the industry, a penchant for secrecy and unaccountability and the expectation that it could get away with treating workers like robots or invisible code. We’re seeing what happens when those notions meet, for one of the first times, with a powerful, organized resistance.</p><p>Personally, I’m hoping this one gets a Hollywood ending — and not the ending so many Silicon Valley startups got over the last 10 years.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NativePHP: A framework for building desktop apps using PHP (118 pts)]]></title>
            <link>https://nativephp.com/docs/1/getting-started/introduction</link>
            <guid>36820555</guid>
            <pubDate>Fri, 21 Jul 2023 22:06:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nativephp.com/docs/1/getting-started/introduction">https://nativephp.com/docs/1/getting-started/introduction</a>, See on <a href="https://news.ycombinator.com/item?id=36820555">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>⚠️</span>
                    <span>
                        NativePHP is currently an <em>alpha</em> release and is not ready for production applications
                        yet.
                    </span>
                </p><div>
                    <h2 id="hello-nativephp"><a href="#hello-nativephp"><p>#</p></a>Hello, NativePHP!</h2>
<p>NativePHP is a new framework for rapidly building rich, native desktop applications using PHP. If you're already a PHP
developer, you'll feel right at home. If you're new to PHP, we think you'll find NativePHP easy to pick up and use.
Whatever your path, we think you're going to be productive quickly.</p>
<p>NativePHP is taking the world by storm, enabling PHP developers to create true cross-platform, native apps
using the tools and technologies they already know: HTML, CSS, Javascript, and, of course, PHP.</p>
<p>And they said PHP was dead.</p>
<h2 id="what-exactly-is-nativephp"><a href="#what-exactly-is-nativephp"><p>#</p></a>What exactly is NativePHP?</h2>
<p>Strictly speaking, NativePHP is a combination of elements:</p>
<ol>
<li>A collection of easy-to-use classes - abstractions - to enable you to interact with a variety of host operating
system features.</li>
<li>A set of tools to enable building and bundling your native application using either the Electron or Tauri browser
environment.</li>
<li>A static PHP runtime that allows your app to run on any user's system with zero effort on their part.</li>
</ol>
<h2 id="what-nativephp-isnt"><a href="#what-nativephp-isnt"><p>#</p></a>What NativePHP isn't</h2>
<p>NativePHP is not an especially opinionated way to build native apps. Right now, we only support a Laravel driver, but
we're already working on making it work whatever framework you're using - and even if you're not using a framework at
all.</p>
<p>NativePHP is not a GUI framework. We don't want to tell you how to build your app. You can choose whatever UI toolset
makes you and your team feel most productive.</p>
<p>Building a React front-end? No problem. Vue? Sure. Livewire or Inertia? Doesn't matter! Plain old HTML and CSS?
You got it. Tailwind? Bootstrap? Material UI? Whatever you want.</p>
<p>NativePHP is not some new custom fork of PHP. This is the good old PHP you know and love.</p>
<h2 id="whats-in-the-box"><a href="#whats-in-the-box"><p>#</p></a>What's in the box?</h2>
<p>NativePHP comes with a bunch of useful features out of the box, including:</p>
<ul>
<li>Window management</li>
<li>Menu management</li>
<li>File management</li>
<li>Database support (SQLite)</li>
<li>Native notifications</li>
</ul>
<p>All of this and more is explored in the rest of these docs.</p>
<h2 id="what-can-i-build-with-nativephp"><a href="#what-can-i-build-with-nativephp"><p>#</p></a>What can I build with NativePHP?</h2>
<p>Honestly, anything you want. We believe NativePHP is going to empower thousands of developers to build all kinds of
applications. The only limit is your imagination.</p>
<p>You could build a menubar app that lets you manage your cron jobs, or a cool new launcher app, or a screen recorder
that puts cowboy hats on every smiley-face emoji it sees.</p>
<p>(You should totally build that last one.)</p>
<h2 id="whats-next"><a href="#whats-next"><p>#</p></a>What's next?</h2>
<p>Go read the docs! We've tried to make them as comprehensive as possible, but if you find something missing, please
feel free to <a href="https://github.com/nativephp/nativephp.com">contribute</a>.</p>
<p>This site and all the NativePHP are open source and available on <a href="https://github.com/nativephp">GitHub</a>.</p>
<p>Ready to jump in? <a href="https://nativephp.com/docs/1/getting-started/installation">Let's get started</a>.</p>
<h2 id="credits"><a href="#credits"><p>#</p></a>Credits</h2>
<p>NativePHP wouldn't be possible without the following projects and the hard work of all of their wonderful contributors:</p>
<ul>
<li>
<a href="https://php.net/">PHP</a>
</li>
<li>
<a href="https://electronjs.org/">Electron</a>
</li>
<li>
<a href="https://tauri.studio/">Tauri</a>
</li>
<li>
<a href="https://laravel.com/">Laravel</a>
</li>
<li>
<a href="https://symfony.com/">Symfony</a>
</li>
<li>
<a href="https://github.com/crazywhalecc/static-php-cli/">Static PHP CLI</a>
</li>
</ul>
<p>NativePHP is a copyright of and maintained by <a href="https://twitter.com/marcelpociot">Marcel Pociot</a> and
<a href="https://twitter.com/simonhamp">Simon Hamp</a>.</p>

                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Managing Kitchen Fruit Flies with a Little Shop of Horrors (264 pts)]]></title>
            <link>https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</link>
            <guid>36820469</guid>
            <pubDate>Fri, 21 Jul 2023 21:58:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/">https://blog.zaccohn.com/Fruitflies-and-the-Little-Shop-of-Horrors/</a>, See on <a href="https://news.ycombinator.com/item?id=36820469">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><img src="https://blog.zaccohn.com/images/blog_pitcherplants.jpeg" alt=""></p>

<p>I live in Seattle on a fairly wooded property. Every summer since we’ve moved here, we end up with <em>swarms</em> of fruit flies in the kitchen. They congregate around the compost bin and the fruit bowl (where there are always lots of bananas). We aren’t slobbish - I do the dishes and wipe down the counters every night, take the compost out and wash the bin 2-3x a week. Keeping everything washed and clean helps, but the fruit flies still build up over time. And if there’s even the slightest deviation from the cleaning schedule, within 2-3 days the fruit flies have built up exponentially and there are 50-100 of them swarming around.</p>

<p>Our previous remedy, iterated on and honed over years, was to leave a few traps out. We found what worked best was a short, wide brimmed glass (or tuppaware container) with a little bit of wine, a splash of apple cider vinegar, a drop of dish soap, then hit it with a spray of hot water to get a lot of suds and bubbles. When the swarms were particularly bad, one of these traps could catch dozens overnight, but we had to refill and refresh them constantly and the mass-graves of floating fruit flies were somewhat unsightly.</p>

<p>Earlier this Spring I was reading about symbotic relationships between humans and nature, and that gave me an idea to try some carnivorous plants.</p>

<p>Venus Fly Traps are the most well known type of carnivorous plant. They have sensitive little trigger hairs in their leaves, and when a fly lands and disturbs one of the hairs, the two lobes snap shut to trap the fly. The plant digests the fly before opening back up, ready for its next meal. The downside is they can take a week or more to open back up! That’s not nearly high-volume enough to deal with my fruit fly problem.</p>

<p>Some additional research taught me about a more passive type of carnivorous plant called a “pitcher plant.” There are many varieties, but generally their leaves form tubes that are open on top. These tubes are full of liquid - a mixture of rainwater and digestive fluids. Flies are attracted to the scent, fly in, then fall into the liquid. They’re trapped there until they drown, then are slowly digested. The same pitcher can catch many, many flies, and even smaller pitcher plants can have between 6 and 12 pitchers.</p>

<p>These sounded perfect! I ran up to the local plant nursery and got three carnivorous “Pitcher plants.” I got two different varieties - which internet research suggests are a Purple Pitcher Plant (<a href="https://en.m.wikipedia.org/wiki/Sarracenia_purpurea">Sarracenia Purpurea</a>) and what I think is a <a href="https://en.wikipedia.org/wiki/Sarracenia_leucophylla">Sarracenia Leucophylla</a> (but could be a <a href="https://en.wikipedia.org/wiki/Sarracenia_flava">Sarracenia Flava</a>).</p>

<p>I named them Audrey III, Audrey IV, and Audrey V. They were about the size in the photos when I got them. They were mature enough to have 6-8 open pitchers, and were growing another 6-8 juvenile pitchers. Each plant was roughly $10 each.</p>

<p>I’ve been disappointed by Audrey III and V’s performance (they’re either the Leucophylla or Flava species), but Audrey IV (the Purple Pitcher Plant) is a <strong>beast</strong>. These days I see one fruit fly buzzing around sometimes, but never more than that. When I look in Audrey IV’s pitchers, she’s been busy - just now I counted ten or eleven fruitflies and two house flies.</p>

<p>Passive countermeasures like Audrey IV works great because it prevents them from going exponential. If you’re taking fruit flies out early and continuously, they don’t have a chance to reproduce. A female fruit fly starts mating 8 hours after it emerges from the larval state, and lays about 400 eggs, which take 12-15 hours to hatch at typical room temperature. Needless to say - you gotta keep these under control!</p>

<p><img src="https://blog.zaccohn.com/images/blog_lavender.jpeg" width="100"> I did notice for a time they were still congregating by the compost and weren’t being drawn to Audrey’s sweet scents. More internet research seemed to indicate they didn’t like don’t like the smell of lavender, so I cut some lavender flowers and put them between the compost bin’s lid and filter. That didn’t seem to be effective, so I spritzed some much higher density lavender essential oil on the compost bin filter. Later that night I watched as a fly kept going into the holes in the lid, then back out, then in, but then back out. It didn’t like the smell! Success!</p>

<p>Since then, there’s been no congregation of fruit flies around the compost. I still see one or two flying around the kitchen, but Audrey IV is keeping them under control.</p>

<p>So that’s my official two-part recommendation for managing fruit flies: get yourself an Audrey IV and spritz some lavender essential oil on your compost bin filter to keep them out.</p>

<h2 id="taking-care-of-a-pitcher-plant">Taking care of a Pitcher Plant</h2>
<p>A few notes on taking care of your new Audrey.</p>
<ol>
  <li><strong>You have to use distilled water.</strong> If you water them with sink water they’ll be dead within a day or two. These plants evolved in swampy, very nutrient-poor soils (that’s why they evolved to get their nutrients from their prey). The minerals in sink water are enough to overwhelm and poison your pitcher plants.</li>
  <li><strong>Damp, but not soaked, soil.</strong> When you water them, you want the soil to be damp but not waterlogged. Although you should look up the needs of your specific species of Audrey.</li>
  <li><strong>Filling the pitcher.</strong> For certain types of pitcher plants, you’ll want to fill up their pitchers with (distilled) water. Some types of pitcher plants have an opening at the top without any sort of leaf covering it (like Audrey IV). These types of plants are designed to supplement their digestive juices with rain water they catch. Since it presumably doesn’t rain inside your house like it does outside, you’ll want to use an eye dropper or a straw to drip some distilled water into the pitchers. Generally try to fill them 3/4 of the way. If your pitcher plant has a “hood” - or part of the leaf that’s covering the opening - that’s designed to shield it from the rain and you may not need to fill it up. Look up your particular species for specific instructions.</li>
  <li><strong>Hand-feeding your pitcher plant.</strong> Outside of fruit fly season, you’ll want to feed your pitcher plant a snack every so often. I use dehydrated mealworms or bloodworms from the pet food store (typically used to feed reptiles, etc). Use tweezers to grab one and drop it into a pitcher. Keep an eye on how fast they digest to figure out the optimal feeding schedule for your plant - but it’s probably going to be close to 3-4 per plant once every 2-3 weeks.</li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Book Review: The Laws of Trading (101 pts)]]></title>
            <link>https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading</link>
            <guid>36820105</guid>
            <pubDate>Fri, 21 Jul 2023 21:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading">https://astralcodexten.substack.com/p/your-book-review-the-laws-of-trading</a>, See on <a href="https://news.ycombinator.com/item?id=36820105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>[</span><em>This is one of the finalists in the 2023 book review contest, written by an ACX reader who will remain anonymous until after voting is done. I’ll be posting about one of these a week for several months. When you’ve read them all, I’ll ask you to vote for a favorite, so remember which ones you liked</em><span>]</span></p><p><span>A book about trading isn’t ever </span><strong>actually</strong><span> about trading</span></p><p><span>. It is either:</span></p><ul><li><p><span>A former trader sharing stories from their glory days, e.g. </span><em>Liar’s Poker</em><span>, the exposé that morphed into a how-to guide, or</span></p></li><li><p><span>Tales of Icarus flying too close to the sun, where readers revel in schadenfreude, e.g., </span><em>When Genius Failed</em><span>.</span></p></li></ul><p><span>With </span><em><a href="https://www.amazon.com/Laws-Trading-Traders-Decision-Making-Everyone/dp/1119574218/ref=sr_1_1?crid=1CFYGH6Q0TUPK&amp;keywords=the+laws+of+trading&amp;qid=1689973717&amp;sprefix=the+laws+of+trading%2Caps%2C144&amp;sr=8-1" rel="">The Laws of Trading</a></em><span>, Agustin Lebron has written something different: part love letter to trading, part philosophical treatise on epistemology and modeling the world around us, and part guide to applied decision-making. Lebron’s Laws are Laws of the Jungle, not Laws of Nature. He views financial markets as the most competitive Darwinian environment on Earth, where participants must adapt or die.</span></p><p><span>According to Lebron, the book is for people working in finance and trading, as well as anyone in the business of making rational decisions.</span><em> </em><span>This explicitly rationalist bent is similar to Julia Galef’s </span><em>The Scout Mindset </em><span>or Annie Duke’s </span><em>Thinking in Bets. </em><span>Where </span><em>The Laws of Trading </em><span>sets itself apart is with the best description of financial market dynamics that I’ve ever seen while diving deep into philosophical concepts.</span></p><p><span>Why trust Lebron? He is an engineer, worked as a quantitative trader and researcher at Jane Street, and has a deep understanding of trading. He has what Taleb would describe as </span><strong>skin in the game</strong><em>.</em><span> You and I may read Astral Codex Ten in our spare time, post on LessWrong, and navel gaze about our epistemic certainty, but at the end of the day most of us are pursuing rationality for fun, as a hobby. Traders like Lebron pursue rationality as a profession: Their livelihood depends on having a better model of the world than their competition. There are lessons to learn from them that apply to our daily lives.</span></p><p><em>Know why you are doing a trade before you trade.</em><span>&nbsp;</span></p><blockquote><p>“What is trading about? Fundamentally, it’s about the relationship between you and the rest of the world.”</p></blockquote><p>Right now, you’re making a trade.&nbsp;</p><p>You’re trading your time to read this book review. You have a cost: you could be spending time with your loved ones, exercising, working, sleeping. You might be hoping to learn something, to take away lessons that you can apply to your life, or simply to entertain yourself. Here, off the bat, are two key insights:</p><ol><li><p>We are all making trades, all of the time.</p></li><li><p>We need a framework for thinking about these trades.</p></li></ol><p>Lebron’s first law states that we must know ourselves and our motivations for trading before we trade. We tell ourselves many stories, but someone with intellectual honesty – the person with the most alignment between their motivations and actions – will take money from the person who didn’t go through the work to understand their own motivations.&nbsp;</p><p><span>There is a reason that Citadel and other hedge funds </span><a href="https://www.investopedia.com/terms/p/paymentoforderflow.asp" rel="">pay millions of dollars to trade with retail</a><span>. They know why they are trading: to maximize profit. And the dilettante who “trades for fun” will be eaten alive by a firm with a much better model of a) the world and b) the dilettante themself.</span></p><p>Why did I write this book review? To test my intellectual mettle. I could easily have posted this book review elsewhere, but no, I wanted to see how I stack up against other ACX Book Review contest participants.&nbsp;</p><p>Similarly, this is often the reason people get into trading. One motivation that Lebron explicitly calls out is intellectual validation. You can toil in obscurity for years as an academic. But in trading, there is a quick feedback loop. If your P&amp;L showed $10M last year and the guy sitting next to you showed $8M, you have demonstrated who is “cleverer” and established a clear hierarchy.&nbsp;</p><p><span>What lessons here transfer to our daily lives? Like Paul Graham, Lebron encourages us to </span><a href="http://www.paulgraham.com/identity.html" rel="">keep our identities small</a><span>. He gives the standard decision-making advice to write down your framework and reasoning for why you made a decision at a specific point in time, in order to avoid biases after the fact.&nbsp;</span></p><p>This section of the book contained good general advice, but nothing that will be particularly new for the median ACX reader.&nbsp;&nbsp;</p><p><em>You’re never happy with the amount you traded.</em></p><p><span>Now we start to get into the good stuff. Financial markets are an information aggregation mechanism, relying on multiple parties’ beliefs and recursive Bayesian updates of an individual actor’s beliefs based on the beliefs of others</span></p><p><span>.</span></p><p><span>Market mechanics demonstrate Bayesian beliefs in action. The following quote is quite long, so skip over it if you don’t want to dive deep into the psychology of making a market. I retained it in full because this is quite literally the best description I’ve ever seen of the Bayesian dance between two </span><a href="https://www.investopedia.com/terms/m/marketmaker.asp" rel="">market makers</a><span>:</span></p><blockquote><p><em>“You are a market maker in South African mining companies. Through years of effort and continual improvement, you have built a trading model for the company Veldt Resources. You walk into work one day, ready to set up your trading for the day. It's a stock that doesn't trade much, and usually there are only two market makers: you and another (we'll call her Jo). She's sharp, and she competes well to trade against customer orders that come in.</em></p><p><em>Your model has Veldt valued at 54.35 ZAR (South African rand). You're going to start quoting the stock, so you're about to turn on your machine making a market 54.25 - 54.45 (1000x)</em></p><em>. Before you turn on, you check the current market and notice that Jo has already turned on and she's making her market 53.50 - 54.00 (2000x). If you were to turn on your machine, your market would cross her market, and you would buy 1000 shares from her for 54.00.</em><p><em>You now need to make a decision. Whose model do you believe more, yours or Jo's? If you believe yours, you should turn on your machine, trade at 54.00, and expect to make money. If you believe Jo's model, you should adjust your own model parameters to match her market and turn on, making a similar market to hers.</em></p><p><em>What to do? As with many dichotomies, this is a false one. And as with many decision processes, Bayesian reasoning lights the way…</em></p><p><em>…Jo presumably believes Veldt is worth around 53.75 (the average of her bid and offer). But how confident is she in her belief? The width of her market can give you a clue. It's 0.50 ZAR, whereas yours was going to be 0.20 ZAR wide. All other things equal, you should think that Jo only has 40% (0.20/0.50) of the confidence in her fair value as you do in yours.</em></p><p><em>On some absolute scale of confidence, you can say you had a belief-strength of 100 in your fair value of 54.35 (before seeing Jo's market), and Jo has a belief-strength of 40 in her fair value of 53.75 (before seeing yours). And it turns out the weighted average of these two beliefs is quite a reasonable way to combine them: 100/140 * 54.35 + 40/140 * 53.75 = 54.18. Your updated fair value, having seen Jo's market, is thus 54.18 ZAR.</em></p><p><em>This procedure is a quick, heuristic, and reduced version of Bayesian belief-updating, and a good reference on the subject is A.L. Barker's 1995 paper.</em></p><p><em>After updating, you now believe that the stock is worth 54.18. Assuming your trading costs, risk limits, and return requirements are satisfied, buying 1000 shares for 54.00 is a good trade. Naively, you might just put out a 54.00 bid for 1000 shares, trade with half the 2000 share offer, and hope to collect your expected-value ZAR.</em></p><p><em>In practice, however, you might be able to make even more. If Jo is making a 0.50 wide market, maybe she'd be willing to sell lower than 54.00. It's conceivable that if you put out a 53.90 bid for 1000 shares, Jo will sell at that price, and you collect an extra 100 ZAR!</em></p><p><em>Of course, Jo could react differently. She could see your bid and use that information to change her market, in much the same way you did before turning on. These are difficult decisions, ones where experience with the product and the market make a big difference in being able to eke out a little extra edge. Let's play it safe however and pay 54.00 for 1000 shares.</em></p><p><em>You trade, and Jo reacts by immediately canceling her market. This is not an uncommon occurrence in illiquid stocks, especially in emerging markets, so you're not too surprised. You wait a couple of minutes, mentally visualizing Jo in front of her six monitors, evaluating her trade and her model.</em></p><p><em>Finally, she turns back on. Her new market is 53.50 - 54.05 (10000x)! You reason that Jo has seen that someone (you) disagrees with her valuation of the stock. Jo is a good Bayesian like you, and so she has incorporated that information into her model and updated her beliefs about the fair value of the stock. Her updated belief is that she now wants to sell even more stock, at a marginally higher price. Clearly, she almost entirely discounts the information you've communicated to her with your trade.</em></p><p><em>How should you react? It seems fairly clear that, assuming Jo is not a crazy or incompetent market maker (usually a fair assumption), your trade was a bad one. You bought 1000 shares, when in retrospect, you would have wanted to buy much less, probably zero.</em></p><p><em>Imagine instead that Jo had turned back on with a market of 54.00 - 54.50 (1000x). Her reaction now clearly indicates the information you gave her with your trade is valuable, and she has adjusted her beliefs accordingly. Your trade was probably a good one. Don't you wish you had bought all 2000 shares on offer?</em></p><p><em>No matter what Jo's reaction is, you will be unhappy with your trade. Note that Jo will be unhappy too, since retrospectively she should have either made her initial market bigger or smaller. Welcome to the joyous world of trading!”</em></p></blockquote><p>Whether or not you make money, you have regrets! If you profited, you could have made more. If you lost money, you shouldn’t have made the trade at all. Like death and taxes, you can’t avoid adverse selection.&nbsp;</p><p>Lebron continues to highlight a few areas of trading that have adverse selection problems.</p><p><span>First, IPOs. If you buy the stock in an IPO, you expect the share price to “pop” on the first day of trading. However, if others also have this expectation, the round will be oversubscribed. You can only get the quantity of shares that you bid for when the market </span><strong>doesn’t</strong><span> think the shares will go up. So if you are able to get the shares that you want, the IPO is likely a dud. See also: Venture Capital fundraising.&nbsp;</span></p><p>Second, powerful entities that change the rules of the game while you’re playing. Exchanges nullify “erroneous” trades. Brokerages limit buying. Anyone who tried to buy GameStop stock on Robinhood on January 28, 2021, knows this form of adverse selection all too well.</p><p>Lebron also highlights “special trades”, in which you should throw the “normal rules” out of the window. This advice generalizes to other areas of life:&nbsp;</p><blockquote><p><em>“The normal rules do not apply. If you remove yourself from our usual routine, if you think hard and clearly about the specific situation, maybe you can do something good. Perhaps even great. Others will be paralyzed by inaction, but perhaps you won’t be. Crises can be opportunities.”</em></p></blockquote><p><em>Take only the risks you’re being paid to take. Hedge the others.</em><span>&nbsp;</span></p><p>In trading, as in life, you can make the right call in expected value terms but still lose due to randomness. Some of that randomness is avoidable. Some of it is not — and can be accounted for by hedging. Here, Lebron encourages us to rely on multiple risk measures and actively seek to understand the risks that we might be subject to.&nbsp;</p><p>That’s all well and good in the world of finance, with derivatives contracts. But how might this apply in other areas of life?</p><p>If you work for a publicly traded company and are compensated in stock, sell your shares as soon as you receive them. This is not because I don’t expect the share price of Microsoft/Meta/Apple/etc. to go up. The stock may very well outperform the market. But you are not being compensated for the added risk that you take on here. Your employment prospects at Microsoft/Meta/Apple/etc. are highly correlated with the share price. When the share price is down is when layoffs happen. Former Enron employees can chime in here.</p><p>Similarly, it makes sense to hedge anything that is outside of your control. Let’s say you’ve decided the crypto bear market of 2023 is a great time to start a new crypto company. Your success depends on things within your control, such as:</p><ul><li><p>Your idea</p></li><li><p>Your hard work and ability to execute</p></li><li><p>Your network for hiring</p></li><li><p>Your ability to fundraise</p></li><li><p>Etc.</p></li></ul><p>As well as some things outside of your control, such as:</p><ul><li><p>Interest rates</p></li><li><p>The current VC fundraising environment&nbsp;</p></li><li><p>The performance of crypto as a sector&nbsp;</p></li><li><p>The performance of tech overall</p></li><li><p>Etc.</p></li></ul><p><span>It might make sense to </span><strong>short </strong><span>the overall tech sector or a basket of publicly traded crypto-related companies so that your trade of time and foregone income to start your new crypto company is associated with only the risks you can control.</span></p><p>But some risks you can’t hedge. These are the more interesting ones. There is counterparty risk (your trading partner blows up), liquidity risk (the market you used to hedge dries up), or even political risk:</p><blockquote><p><em>“Living in the developed world, it’s easy to fall into the seductive assumption that the rule of law applies strongly everywhere. This is far from the case. A foreigner trading in an emerging market is frequently among the first “victims” of any political turmoil.”</em></p></blockquote><p>Lebron is meticulous in the ways that he thinks about risk. He highlights that in the markets, you need to be exceedingly paranoid to survive:</p><blockquote><p><em>“Certainly, the modern compendium of mental illnesses (DSM-5) takes a dim view of people who think everyone is out to get them. Yet financial markets are different: people really are out to get you, after all.”</em></p></blockquote><p>I don’t think enough people consider risk and the hedges you can take in the context of a career. I’ve spent the past several years working at startups, where I’ve placed a hugely levered career bet. I’m trading my time and the opportunity cost of another job to work at my current employer. My salary, stock options, expertise, and social capital that I build from working 10 hours per day is fundamentally long (and has risks associated with):</p><ul><li><p>The tech industry</p></li><li><p>My startup’s industry</p></li><li><p>My individual startup&nbsp;</p></li><li><p>Our customers’ business viability&nbsp;</p></li></ul><blockquote><p><em>“Many trades that look different on the surface can in fact be the same trade in disguise, and trades whose edge appears to derive from one risk are actually bets on another risk.”</em></p></blockquote><p><span>It might make sense to hedge some of that risk – simply having friends that work at other companies and in other industries so that all of my social capital isn’t in one basket is a start</span></p><p><span>.&nbsp;</span></p><p>My only gripe here is that I would have liked to see Lebron call out ergodicity more explicitly. Blowing up your account might be fine as a trader – if you have a decent prior track record, you can probably just get a job at a different firm – but in life other losses are less reversible. As far as we know, this is the only universe we have access to. It doesn’t matter if your bet was positive EV and you won in 51% or 75% or even 99% of universes. You should place a high premium on staying alive and having enough bankroll to play the next round of the game. This is more important outside of finance than in the world of trading.</p><p><em>Put on a risk using the most liquid instrument for that risk.</em><span>&nbsp;</span></p><p>Liquidity isn’t something I think about in daily life. But I probably should. A personal example: I gave up the liquidity of a month-to-month gym contract in New York City in February 2020. I paid one year upfront for a 10% discount. Oops.</p><p><span>Lebron also reminds us that the </span><a href="https://byrnehobart.medium.com/the-30-year-mortgage-is-an-intrinsically-toxic-product-200c901746a" rel="">30-Year Mortgage is an Intrinsically Toxic Product</a><span>, a concept that will resonate with all of the Georgists here.&nbsp;</span></p><blockquote><p><em>“The usual path to homeownership exposes people to a financial decision that would, it seems clear, be ridiculed if it were taken by any self-respecting public company.”&nbsp;</em></p></blockquote><p>Among other issues:</p><ul><li><p><em>“The home is bought and sold through an opaque cartel of brokers whose interests are demonstrably not aligned with those of their customers”</em></p></li><li><p><em>“The ability to service the debt (the mortgage) is highly correlated with local economic conditions. This means that if you lose your job and need to sell your house, you will typically find it an exceedingly bad time to try to sell your house.”</em></p></li><li><p><em>“Residential real estate has historically returned significantly below equity markets over long time horizons”&nbsp;</em></p></li></ul><p><span>But I’m not so sure that these lessons are directly applicable to other areas of life. Some of the best things in life come from lashing yourself to the mast, burning the boats behind you, </span><strong>willingly giving up</strong><span> liquidity. The deepest monogamous relationships are built from an irrational investment in one other person, saying “In sickness and in health, until death do us part.” How many scientific problems were solved because one person had an irrational willingness to: Just. Keep. Going.&nbsp;</span></p><p>Sometimes it’s powerful to use the sunk cost fallacy to your advantage. Investing in relationships, subject matter expertise, even putting down roots via *gulp* homeownership reduces your liquidity, but also leads to some of the best (if intangible) things in life.</p><p>If you can’t explain your edge in five minutes, you don’t have a very good one.&nbsp;</p><p>OR&nbsp;</p><p>The long-term profitability of an edge is inversely proportional to how long it takes to explain it.</p><p><span>The Efficient Market Hypothesis is one of the core concepts taught in Finance 101. The Efficient Market Hypothesis is a </span><strong>lie</strong><span>. The person that better understands the nature of a small sliver of the world (e.g. Apple’s share price) will make more money than others.</span></p><p>Modern financial markets are exceedingly competitive. This means that the bigger you think your edge is, the more likely it is that you’re wrong.&nbsp;</p><blockquote><p><em>“Evolutionary thinking applies quite directly when thinking about the evolution of markets. Having an edge in a mature market means understanding the world better than other traders, even ones who are already highly skilled. In fact, the marginal trader in modern financial markets is quite sophisticated and skilled indeed.”</em></p></blockquote><p><span>Lebron here warns us of getting too cute with data, of changing variables. Enough randomness will produce an “edge” that is likely to break down the second a trading strategy hits the real world. You can always find a statistical correlation if you change enough variables. But this is fundamentally the same problem facing the </span><a href="https://slatestarcodex.com/2014/04/28/the-control-group-is-out-of-control/" rel="">replication crisis</a><span> in social sciences.&nbsp;</span></p><p>Lebron argues that we need stories here. Edge is expressed in stories: an edge does not exist without a clear mental representation of that edge. Pure linear algebra does not suffice.</p><p><span>I’m not so sure. It seems like AI companies are pushing forward technology in a way that suggests that mental representations are not the only path to intelligence. Lebron discounts “black box” trading strategies without much discussion of their potential merits. Are all of </span><a href="https://en.wikipedia.org/wiki/Renaissance_Technologies" rel="">RenTech’s</a><span> models explainable by a story? The firm is notoriously secretive, so I don’t know, but I’d guess not.</span></p><blockquote><p><em>“Frequently a good trade appears, has a seemingly insurmountable difficulty, and it is mere persistence that knocks down the final barrier. There may have been many others who looked at the idea, wanted to do it, but couldn’t get past that last hurdle.”</em></p></blockquote><p><span>Before Sam Bankman-Fried was the face of Why Effective Altruism is Bad, before he even founded FTX, he made money </span><a href="https://www.bloomberg.com/news/articles/2021-04-01/the-ex-jane-street-trader-who-s-building-a-multi-billion-crypto-empire" rel="">arbitraging the difference between Bitcoin prices on Japanese and American exchanges</a><span>. I’m reminded of that trade here. It isn’t a particularly elegant trade, it doesn’t require deep technical knowledge or any models. It was a </span><strong>schlep</strong><span>. It was all operational work: figuring out how to open a Japanese bank account, transferring money between the US and Japan, standing in line for hours every day at both US and Japanese banks (presumably this wasn’t the same person).&nbsp;</span></p><p>In as technical a field as trading, sheer willpower is often what gets things done in the end.</p><p><em>The model expresses the edge.</em><span>&nbsp;</span></p><p>Lebron drills into us that a model is the tool for expressing an edge. The model is not the edge. The model does not give us unique knowledge about the world. The map is not the territory.&nbsp;</p><p>He dives into the difference between generative (G) and phenomenological (P) models. G models express a worldview and fit data into that way of thinking, whereas P models solely look at the empirical data to build a worldview.</p><p>Models of the world differ from models of markets, though. Markets have quick feedback loops, are explicit in terms of what they measure, and are easy to quantify at a specific point in time. Most of our models for the world, though, are ill-defined and explicit.</p><p><span>Models are only as good as our assumptions. As an aside, this is a common criticism of rationality or Effective Altruism – you can justify any worldview if you assign your model input weights in just the right way</span></p><p><span>. I also tend to think that “traditional” EA is overly dependent on P models, and doesn’t embrace the G models that led to economic reforms in India in the 1990s or the economic policies that led to rapid economic development in Southeast Asia in the second half of the 20th Century. Interestingly, I think a lot of longtermist EA, specifically AI alignment, leans the other way, relying on G models which explicitly assume a certain P(doom) and work backwards from there. (Though I won’t pretend to be an expert here or to understand everything, so take this with a grain of salt.)&nbsp;</span></p><p><span>Overall, startups and tech seem to take heed to Lebron’s lesson much better than the folks hanging out on this part of the internet: </span><em>“Even if a model makes good predictions about some future value or event, that knowledge is useless without also knowing how to take advantage of that prediction.”</em></p><p>Now we get a bit philosophical. By acting, you change the nature of the market. Your model predicts things that might not be true as soon as you start trading (and changing the environment) based on it.&nbsp;</p><p>When you’re right, everyone else sees the same trades that your model does and will beat you to them. When your model is wrong, others don’t act, meaning adverse selection rears its ugly head once again. So your model shows you with an edge, but in practice you only make the trades where you don’t have an edge.&nbsp;</p><p>Lebron closes by arguing that G models are best for understanding other people, and are good in and of themselves:&nbsp;</p><blockquote><p><em>“You can also see connections to traditional moral philosophy in thinking about modeling the behavior of others. To have a good G model about someone else is to have some measure of empathy and compassion for that person: what they’re like, what they think and feel, putting yourself in their shoes. Pragmatically, developing the skill of empathy and compassion for others is, aside from a moral good in itself, an excellent way to understand better the people who surround you. More people working to develop good G models of others is surely a small step to a better world.”</em></p></blockquote><p><em>If you think your costs are negligible relative to your edge, you’re wrong about at least one of them.</em></p><p>This section of the book displayed a good amount of epistemic humility, words that I didn’t expect to be typing in the context of a book about trading.</p><p><span>Lebron tells us that trades don’t exist independently in the universe — in the n-dimensional space of all possible trades seeking to optimize profitability, if you have a gigantic mountain of profitability, someone else has probably at least discovered the base. So you probably </span><strong>don’t</strong><span> have a profitable trade; rather, you are misunderstanding something about your trade. You’ve either overestimated profitability or underestimated cost.</span></p><p>Lebron highlights four types of trading costs: </p><p>[graph that didn’t show up correctly here: two axes and four quadrants, with the axes being visible ←→ invisible costs and linear ←→ nonlinear costs]</p><p>Here, we’ll focus on Quadrant 4, where he highlights a few interesting phenomena.</p><p>Herding. It’s likely that if you have a profitable trading strategy, either:</p><ol><li><p>Other firms discovered a similar strategy independently and/or</p></li><li><p>You’ve “stolen” the idea from someone else (say if you leave a firm), or vice versa</p></li></ol><p>Lebron highlights Long Term Capital Management (LTCM) as an example here, which suffered a famous blowup in 1998. This hedge fund is often discussed in the context of betting on Russia just before it defaulted on its debt, but an under-discussed aspect is the market mechanics. Other firms were copying LTCM’s trades, so there was a liquidity issue and a cascade of failures when the firm’s margin positions needed to be unwound.&nbsp;</p><p>Lebron also discusses opportunity cost, a concept with which most will be familiar. But here, he discusses the cost in the context of trading. Ultimately, this is an explore/exploit problem. How should a trading firm weigh maximizing profit for today’s strategies, as opposed to working on organizational efficiencies so that you can have the capacity to work on tomorrow’s strategies?</p><p>There is a clear career parallel here: I’ve seen so many people get locked into their current role due to inertia, whereas the ones who succeed long-term appear to prioritize their own learning and exploration.</p><p>As a case study, Lebron discusses how Bell Labs (AT&amp;T) maintained a position of dominance for half a century. He attributes this to four things:</p><p>First, they hired the best. There was interaction between three groups that did not interact at most organizations.</p><ol><li><p>Scientists and engineers who conducted exploratory research.</p></li><li><p>More applied engineers, who took the work of the first group and integrated their discoveries into existing problems at AT&amp;T.</p></li><li><p>A third group of engineers who put the work from the first two groups into production.</p></li></ol><p>This seems to have been cargo-culted at most modern tech companies. Ping-pong tables and nap pods don’t replace a true culture of cross-pollination of ideas in a boring cafeteria.&nbsp;</p><p><span>I’m reminded of the story of Richard Feynman in academia</span></p><p><span>. His colleagues who kept their office doors closed made progress on their research in the short-term, but hit stumbling blocks. Those who kept their doors open didn’t seem to make much progress initially, but eventually outpaced the “closed door” scientists. They had new ideas and research directions based on all the interesting conversations they were having with others.</span></p><p>The simple lesson here is to get outside of your bubble a bit more. Maybe the normies have something valuable to say once in a while.&nbsp;</p><p>Second, an emphasis on continuing education. This blew me away: Bell Labs developed a syllabus of graduate-level courses and taught it to any interested employee. They didn’t outsource the curriculum or the teaching.</p><p><span>Third, a technical staff that was held in just as high of an esteem as the PhDs who managed them. This seems to be why there is little innovation in government: talented engineers are treated as second-class citizens in research labs, so they work for Stripe and OpenAI instead. Similarly, one can attribute the lack of innovation in hospitals to doctors holding all of the institutional power. Often, all a hospital needs to save lives is </span><a href="https://en.wikipedia.org/wiki/The_Checklist_Manifesto" rel="">simple practices that other businesses figured out long ago</a><span>, but the hubris of MDs prevents this from happening. But I digress.&nbsp;&nbsp;</span></p><p>Fourth, a culture that embraced failure. While many companies say they have a culture of “failing fast”, how many actually mean it?&nbsp;</p><p>Some of the best parts of this book are the diversions. This book is in a sense nostalgic – edges are lost over time, trading firms come and go, entire markets disappear. All you have along the way is the knowledge that for one instant, in one market, you had knowledge that the rest of the world didn’t and used it to make one profitable trade.</p><p><em>Just because something has never happened doesn’t mean it can’t.&nbsp;</em></p><p><em>Corollary: Enough people relying on something being true makes it false.</em></p><p><span>“Impossible” and </span><a href="https://arxiv.org/pdf/1103.5672.pdf" rel="">“25-standard deviation” events</a><span> sure seem to happen awfully often in the financial industry.&nbsp;</span></p><p>Consider an airplane engine that has a 1/1,000 chance of failing. Each plane has two engines, so that if one fails the other can still operate and get everyone to the ground safely. That’s great if the engines act as completely independent variables, but what if failures are correlated?&nbsp;</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png" width="1200" height="742" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:742,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:&quot;Chart&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" title="Chart" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4c83fb0a-dce8-47ca-9dd7-276236fa4a69_1200x742.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The key insight here is that small correlations create large changes in failure probabilities. Namely, a relatively “small” correlation of 0.1 increases the probability of engine failure 100x.&nbsp;</p><p>The feedback loop of markets is great at hiding these correlations until something goes wrong. When it does, you have highly-correlated mortgage-backed securities kicking off the 2008 Financial Crisis.</p><p>One of Lebron’s more interesting insights is that markets are stochastic, self-organized feedback systems, which means that both momentum trades (a price that is going up will continue to go up) and mean-reversion trades (the exact opposite) are valuable at different points in time.</p><p>I found this to be a good framework for thinking about AI. Some folks are clearly betting on momentum – that GPT-X products will continue to improve, reaching AGI (if it hasn’t already). The other side of the coin is bets on mean-reversion, which focus on the S-curves of technology and take a historical view. I’m old enough to remember that in 2016 everyone was talking about how self-driving cars would mean the end of truckers, and there’s more demand than ever for them today.</p><p><em>Working to align everyone’s interests is time well spent.</em><span>&nbsp;</span></p><p>This is the principal-agent problem. Whenever the person investing the money is not also providing the capital, you’re going to have problems.&nbsp;</p><p>Follow the incentives. When a fund manager is paid 2% of assets under management (AUM), the incentive is to raise as much money as possible. When they are paid 20% of profits, they’re incentivized to make high-risk investments, as their upside is uncapped but their downside is capped at $0.</p><p>High-water mark provisions help with this. Basically if your fund had $1 billion AUM last year and you lost 30% this year, you now have $700 million. As the fund manager, you don’t get paid until you’re back to the $1 billion mark.</p><p>But…then you just shut down your fund, return the $700 million, and start a new fund.</p><p>Lebron argues that the only way to resolve this problem is to perfectly align capital and labor.</p><p>I wonder how much of the Renaissance Medallion fund’s success comes from a) this perfect alignment of incentives vs. b) capital limits, meaning that strategies can be executed that would not work at a larger scale.&nbsp;</p><p>Lebron argues that everyone acting as an owner is a good thing. And I tend to agree! But there’s a free-rider problem here that he doesn’t address. I’m writing this book review instead of working at my day job as a tech employee. I’m an owner — but my salary and equity was negotiated a few years ago when I signed my job offer. If I were a salesperson working on commission, perhaps I’d be singing a different tune. Aligning incentives is easier when you’re working at a job where performance is a) easily measurable and b) a direct output of your labor (say, as the Portfolio Manager at a hedge fund).</p><p>Lebron also argues that, within an organization, consistency of culture is more important than the specific culture. I fully agree – this is particularly egregious at tech companies. Many claim to support work-life balance but then ask you to work weekends, or say “we’re a family” but then lay off employees the second they have trouble raising the next round of funding. Employees can see right through this. Put your flag in the ground and say what you actually stand for. If you stand for everything, you stand for nothing.&nbsp;</p><p><em>If you don’t master technology and data, you’re losing to someone who does.</em></p><p>This point is self-explanatory and I don’t think it needs further exploration for the average Astral Codex Ten reader.&nbsp;</p><p>Will machines take over the world? Lebron straddles the line here and states in the context of trading, a human-machine hybrid still does the best work, given our complementary skill sets. Humans have higher-level thinking and understanding context, whereas computers possess the speed and iteration ability necessary to implement models. This book was released in 2019 — I’d love to see if Lebron has updated his priors at all based on recent developments in AI.</p><p>There’s also an interesting diversion here into software development. Specifically, Lebron tries to quantify technical debt, which I haven’t seen done before.</p><p><em>If you’re not getting better, you’re getting worse.</em></p><p>The markets are a very scary place, and you are in an existential arms race with your competitors.&nbsp; Adapt or die. At the individual level, group (trading desk/business unit) level, firm level, and market level. Adapt or die.&nbsp;</p><p>That may seem harsh. But no – Lebron praises trading as a positive-sum game. International financial markets allow the flow of capital from rich to poor countries, giving rich investors a return and raising the standard of living in the developing world.&nbsp;</p><p>This is a striking perspective to have on trading. I’ve heard traders describe the work they do as “net neutral” and “adding no value to the world”. Conversely, Lebron views trading as an act of creativity, a way to make the world, in one small way, a better place through creating efficiencies in markets. His philosophical approach to markets is best demonstrated through this story of a trader named Mark,&nbsp;</p><blockquote><p><em>“Tomorrow will be more difficult than today, and the day after more difficult still, and on until the day he decides to retire from the business. There is no respite and there are no pauses to the inexorable adaptation of markets.</em></p><p><em>It’s easy to view Mark’s job as a soul-destroying, almost Sisyphean effort. And indeed, it’s this ceaseless competition that does, over time, break the will of many market participants. But I will argue in what follows that the best traders view their situation with very much the opposite perspective: as a liberating and redemptive force…</em></p><p><em>…Profitable traders are some of the most intelligent, driven, perceptive, and adaptable people on earth. To relegate such a person to a life of maintenance and literally trading on past glories sounds and is soul-destroying. The essence of trading, the thing that makes it such an interesting and stimulating undertaking, is this very process of adaptation and competition.”</em></p></blockquote><p><span>One can imagine Lebron, in a previous life, penning the words </span><a href="https://en.wikipedia.org/wiki/The_Myth_of_Sisyphus" rel="">“One must imagine Sisyphus happy.”</a></p><p>Beyond the philosophy, while reading this book I was struck by the fact that trading is one of the few true apprenticeship systems that remains for white-collar work. You can career switch into the technology industry without a degree. There is a clear educational path to becoming a doctor or a lawyer. But trading is a bunch of dudes (and it’s almost always men) behind closed doors working on intellectually challenging problems. Lebron recognizes this as well:</p><blockquote><p><em>“Autodidacts in trading are like jailhouse lawyers: for every person who’s truly discovered and developed a successful strategy sui generis, there is an army of people who either significantly undervalued the teaching that others provided, or they are deluding themselves about the profitability of their trading.”</em></p></blockquote><p><em>The Laws of Trading</em><span> opens the door to this world a crack and allows the rest of us to peek in, ever so slightly.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama: Add grammar-based sampling (309 pts)]]></title>
            <link>https://github.com/ggerganov/llama.cpp/pull/1773</link>
            <guid>36819906</guid>
            <pubDate>Fri, 21 Jul 2023 21:17:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ggerganov/llama.cpp/pull/1773">https://github.com/ggerganov/llama.cpp/pull/1773</a>, See on <a href="https://news.ycombinator.com/item?id=36819906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">EDITED after updates</p>
<p dir="auto">Inspired by <a data-error-text="Failed to load title" data-id="1704730522" data-permission-text="Title is private" data-url="https://github.com/ggerganov/llama.cpp/issues/1397" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/1397/hovercard" href="https://github.com/ggerganov/llama.cpp/pull/1397">#1397</a> and <a href="https://github.com/grantslatton/llama.cpp/commit/007e26a99d485007f724957fa8545331ab8d50c3">grantslatton's CFG work</a>, this adds an API that takes a serialized context-free grammar to guide and constrain sampling. Also adds a sample Backus-Naur form (BNF)-like syntax in <code>main</code> for specifying a grammar for generations.</p>
<h2 dir="auto">Testing</h2>
<p dir="auto">(M2 Max, 30B)</p>
<details>
<summary>Chess</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [<U+000A>] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [<U+000A>] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n' --grammar-file grammars/chess.gbnf
main: build = 674 (e550234)
main: seed  = 1688014137
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= [1] [.] [ ] move [ ] move [&lt;U+000A&gt;] root_4 
move ::= move_5 move_9 
root_2 ::= [1-9] root_3 [.] [ ] move [ ] move [&lt;U+000A&gt;] 
root_3 ::= [0-9] | 
root_4 ::= root_2 root_4 | root_2 
move_5 ::= pawn | nonpawn | castle 
pawn ::= pawn_14 [a-h] [1-8] pawn_16 
nonpawn ::= [NBKQR] nonpawn_10 nonpawn_11 nonpawn_12 [a-h] [1-8] 
castle ::= [O] [-] [O] castle_17 
move_9 ::= [+#] | 
nonpawn_10 ::= [a-h] | 
nonpawn_11 ::= [1-8] | 
nonpawn_12 ::= [x] | 
pawn_13 ::= [a-h] [x] 
pawn_14 ::= pawn_13 | 
pawn_15 ::= [=] [NBKQR] 
pawn_16 ::= pawn_15 | 
castle_17 ::= [-] [O] | 

 A good game:

1. e4 e5
2. Nf3 Nc6
3. Bb5 a6
4. Ba4 Nf6

llama_print_timings:        load time =  1144.33 ms
llama_print_timings:      sample time =    35.87 ms /    32 runs   (    1.12 ms per token)
llama_print_timings: prompt eval time =  1126.34 ms /     7 tokens (  160.91 ms per token)
llama_print_timings:        eval time =  5214.99 ms /    31 runs   (  168.23 ms per token)
llama_print_timings:       total time =  6398.45 ms
</code></pre></div>
</details>
<details>
<summary>"Chess" without grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A good game:\n\n'  

main: build = 645 (fd0eb66)
main: seed  = 1686286016
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A good game:

Sir Thomas Gresham, when he was building his famous Exchange at London, had the following dialogue with a mason, whose name was Richard B
llama_print_timings:        load time =  1185.47 ms
llama_print_timings:      sample time =    21.57 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1167.67 ms /     7 tokens (  166.81 ms per token)
llama_print_timings:        eval time =  4977.97 ms /    31 runs   (  160.58 ms per token)
llama_print_timings:       total time =  6188.21 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr &quot;=&quot; ws num &quot;\n&quot;)+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | &quot;(&quot; ws expr &quot;)&quot; ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [<U+000A>] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ <U+0009><U+000A>] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n' \                      
--grammar 'root  ::= (expr "=" ws num "\n")+
expr  ::= term ([-+*/] term)*
term  ::= ident | num | "(" ws expr ")" ws
ident ::= [a-z] [a-z0-9_]* ws
num   ::= [0-9]+ ws
ws    ::= [ \t\n]*'
main: build = 674 (e550234)
main: seed  = 1688014196
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_5 
root_1 ::= expr [=] ws num [&lt;U+000A&gt;] 
expr ::= term expr_8 
ws ::= ws_12 
num ::= num_11 ws 
root_5 ::= root_1 root_5 | root_1 
term ::= ident | num | [(] ws expr [)] ws 
expr_7 ::= [-+*/] term 
expr_8 ::= expr_7 expr_8 | 
ident ::= [a-z] ident_10 ws 
ident_10 ::= [a-z0-9_] ident_10 | 
num_11 ::= [0-9] num_11 | [0-9] 
ws_12 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws_12 | 

 Some arithmetic practice:

10 *a*1 +b*2 =640

10 *a*2 +b*3 =656


llama_print_timings:        load time =  1165.00 ms
llama_print_timings:      sample time =    41.11 ms /    32 runs   (    1.28 ms per token)
llama_print_timings: prompt eval time =  1147.76 ms /     7 tokens (  163.97 ms per token)
llama_print_timings:        eval time =  5113.92 ms /    31 runs   (  164.97 ms per token)
llama_print_timings:       total time =  6323.27 ms
</code></pre></div>
</details>
<details>
<summary>Arithmetic - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    &quot;fmt&quot;
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Some arithmetic practice:\n\n'                                            
main: build = 645 (fd0eb66)
main: seed  = 1686286388
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Some arithmetic practice:

\begin{code}
package main

import (
    "fmt"
)

func main() {
    fmt.Println(
llama_print_timings:        load time =  1171.65 ms
llama_print_timings:      sample time =    21.37 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1153.88 ms /     7 tokens (  164.84 ms per token)
llama_print_timings:        eval time =  4991.68 ms /    31 runs   (  161.02 ms per token)
llama_print_timings:       total time =  6187.91 ms
</code></pre></div>
</details>
<details>
<summary>JSON</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= [&quot;] string_16 [&quot;] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ <U+0009><U+000A>] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ <U+0009>!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	&quot;fullName&quot;: &quot;Ramon Rodriguez&quot;,
	&quot;username&quot;: &quot;ramon&quot;,
	&quot;email&quot;: &quot;ramon@mail.com&quot;,
	&quot;phoneNumber&quot;: &quot;+1234567890&quot;,
	&quot;address&quot;: {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 64 -p $'A bit about me:\n\n' --grammar-file grammars/json.gbnf
main: build = 674 (e550234)
main: seed  = 1688014289
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 64, n_keep = 0


main: grammar:
root ::= object 
object ::= [{] ws object_11 [}] 
value ::= object | array | string | number | boolean 
array ::= [[] ws array_15 []] 
string ::= ["] string_16 ["] ws 
number ::= number_17 number_18 ws 
boolean ::= boolean_19 ws 
ws ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] ws | 
object_8 ::= string [:] ws value object_10 
object_9 ::= [,] ws string [:] ws value 
object_10 ::= object_9 object_10 | 
object_11 ::= object_8 | 
array_12 ::= value array_14 
array_13 ::= [,] ws value 
array_14 ::= array_13 array_14 | 
array_15 ::= array_12 | 
string_16 ::= [ &lt;U+0009&gt;!#-[]-~] string_16 | 
number_17 ::= [-] | 
number_18 ::= [0-9] number_18 | [0-9] 
boolean_19 ::= [t] [r] [u] [e] | [f] [a] [l] [s] [e] 

 A bit about me:

{
	"fullName": "Ramon Rodriguez",
	"username": "ramon",
	"email": "ramon@mail.com",
	"phoneNumber": "+1234567890",
	"address": {
		
llama_print_timings:        load time =  1273.70 ms
llama_print_timings:      sample time =    82.93 ms /    64 runs   (    1.30 ms per token)
llama_print_timings: prompt eval time =  1256.36 ms /     8 tokens (  157.04 ms per token)
llama_print_timings:        eval time = 10432.05 ms /    63 runs   (  165.59 ms per token)
llama_print_timings:       total time = 11795.36 ms
</code></pre></div>
</details>
<details>
<summary>"JSON" - no grammar</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'A bit about me:\n\n'                                                                          
main: build = 645 (fd0eb66)
main: seed  = 1686286615
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 A bit about me:

A former teacher, now a full-time writer. I am the author of two novels: _The Man in the Moon_ and _The Riddle
llama_print_timings:        load time =  1291.32 ms
llama_print_timings:      sample time =    21.48 ms /    32 runs   (    0.67 ms per token)
llama_print_timings: prompt eval time =  1274.63 ms /     8 tokens (  159.33 ms per token)
llama_print_timings:        eval time =  4990.01 ms /    31 runs   (  160.97 ms per token)
llama_print_timings:       total time =  6306.01 ms
</code></pre></div>
</details>
<details>
<summary>Japanese</summary>
<div data-snippet-clipboard-copy-content=" % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ <U+0009><U+000A>] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [<U+3041>-<U+309F>] 
katakana ::= [<U+30A1>-<U+30FF>] 
punctuation ::= [<U+3001>-<U+303E>] 
cjk ::= [<U+4E00>-<U+9FFF>] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms"><pre><code> % ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' --grammar-file grammars/japanese.gbnf
main: build = 674 (e550234)
main: seed  = 1688013430
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


main: grammar:
root ::= root_2 root_5 
jp-char ::= hiragana | katakana | punctuation | cjk 
root_2 ::= jp-char root_2 | jp-char 
root_3 ::= [ &lt;U+0009&gt;&lt;U+000A&gt;] root_4 
root_4 ::= jp-char root_4 | jp-char 
root_5 ::= root_3 root_5 | 
hiragana ::= [&lt;U+3041&gt;-&lt;U+309F&gt;] 
katakana ::= [&lt;U+30A1&gt;-&lt;U+30FF&gt;] 
punctuation ::= [&lt;U+3001&gt;-&lt;U+303E&gt;] 
cjk ::= [&lt;U+4E00&gt;-&lt;U+9FFF&gt;] 

 Building a website can be done in 10 simple steps (from the original Japanese):

一、目的は何なのか
二、お客さまを思い出して
三、お客さまのこと
llama_print_timings:        load time =  2957.19 ms
llama_print_timings:      sample time =    42.67 ms /    32 runs   (    1.33 ms per token)
llama_print_timings: prompt eval time =  2941.56 ms /    21 tokens (  140.07 ms per token)
llama_print_timings:        eval time =  5384.28 ms /    31 runs   (  173.69 ms per token)
llama_print_timings:       total time =  8387.61 ms
</code></pre></div>
</details>
<details>
<summary>Japanese - no grammar</summary>
<div data-snippet-clipboard-copy-content="% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms"><pre><code>% ./main -m $LLAMA_30B_Q4_0 -n 32 -p $'Building a website can be done in 10 simple steps (from the original Japanese):\n\n' 
main: build = 674 (e550234)
main: seed  = 1688013483
llama.cpp: loading model from /Users/evan/llama-models/30B/ggml-model-q4_0.bin
llama_model_load_internal: format     = ggjt v3 (latest)
llama_model_load_internal: n_vocab    = 32000
llama_model_load_internal: n_ctx      = 512
llama_model_load_internal: n_embd     = 6656
llama_model_load_internal: n_mult     = 256
llama_model_load_internal: n_head     = 52
llama_model_load_internal: n_layer    = 60
llama_model_load_internal: n_rot      = 128
llama_model_load_internal: ftype      = 2 (mostly Q4_0)
llama_model_load_internal: n_ff       = 17920
llama_model_load_internal: n_parts    = 1
llama_model_load_internal: model size = 30B
llama_model_load_internal: ggml ctx size =    0.13 MB
llama_model_load_internal: mem required  = 19756.66 MB (+ 3124.00 MB per state)
.
llama_init_from_file: kv self size  =  780.00 MB

system_info: n_threads = 8 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 
sampling: repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.800000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000
generate: n_ctx = 512, n_batch = 512, n_predict = 32, n_keep = 0


 Building a website can be done in 10 simple steps (from the original Japanese):

1. Determine your goal for your site.
2. Make a plan.
3. Select the domain name.
4. Choose web
llama_print_timings:        load time =  2955.05 ms
llama_print_timings:      sample time =    22.96 ms /    32 runs   (    0.72 ms per token)
llama_print_timings: prompt eval time =  2937.10 ms /    21 tokens (  139.86 ms per token)
llama_print_timings:        eval time =  5032.41 ms /    31 runs   (  162.34 ms per token)
llama_print_timings:       total time =  8013.71 ms
</code></pre></div>
</details>
<h2 dir="auto">Approach</h2>
<h3 dir="auto">Grammar API</h3>
<p dir="auto">The <code>llama</code> API accepts a data structure representing a context-free grammar over 32-bit code points:</p>
<div data-snippet-clipboard-copy-content="    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);"><pre><code>    // grammar element type
    enum llama_gretype {
        // end of rule definition
        LLAMA_GRETYPE_END            = 0,

        // start of alternate definition for rule
        LLAMA_GRETYPE_ALT            = 1,

        // non-terminal element: reference to rule
        LLAMA_GRETYPE_RULE_REF       = 2,

        // terminal element: character (code point)
        LLAMA_GRETYPE_CHAR           = 3,

        // modifies a preceding LLAMA_GRETYPE_CHAR or LLAMA_GRETYPE_CHAR_ALT to
        // be an inclusive range ([a-z])
        LLAMA_GRETYPE_CHAR_RNG_UPPER = 4,

        // modifies a preceding LLAMA_GRETYPE_CHAR or
        // LLAMA_GRETYPE_CHAR_RNG_UPPER to add an alternate char to match ([ab], [a-zA])
        LLAMA_GRETYPE_CHAR_ALT       = 5,
    };

    typedef struct llama_grammar_element {
        enum llama_gretype type;
        uint32_t           value; // Unicode code point or rule ID
    } llama_grammar_element;

    LLAMA_API struct llama_grammar * llama_grammar_init(
            const llama_grammar_element ** rules,
                                 size_t    n_rules,
                                 size_t    start_rule_index);
</code></pre></div>
<h3 dir="auto">Sampling</h3>
<p dir="auto">The grammar sampling code models a nondeterministic pushdown automaton, maintaining N stacks for the possible parse states. Sampling a token is done in two steps: a sampling API that filters candidates to those that match one of the parse stacks (<code>llama_sample_grammar</code>) and adding the chose token to the grammar (<code>llama_grammar_accept_token</code>).</p>
<h3 dir="auto">Examples</h3>
<p dir="auto">Adds <code>--grammar</code> and <code>--grammar-file</code> arguments to <code>main</code> taking a simple extended BNF to constrain generations. The parser for this format is implemented in <code>examples/grammar-parser.{h,cpp}</code>:</p>
<div data-snippet-clipboard-copy-content="// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | &quot;(&quot; space expr &quot;)&quot; space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*"><pre><code>// ... Supports character
// ranges, grouping, and repetition operators. As an example, a grammar for
// arithmetic might look like:
//
// root  ::= expr
// expr  ::= term ([-+*/] term)*
// term  ::= num | "(" space expr ")" space
// num   ::= [0-9]+ space
// space ::= [ \t\n]*
</code></pre></div>
<p dir="auto">The <code>root</code> rule identifies the start of the grammar.</p>
<p dir="auto"><del>## Caveats</del></p>
<ul dir="auto">
<li><del>the binary format makes the code harder to understand and more brittle</del></li>
<li><del>the grammar contemplates 16-bit chars but it's just being applied to the 8-bit UTF-8 chars in token strings currently</del></li>
<li><del>the 1-char lookahead sampling is probably biasing generations in a weird way; further investigation on quality of outputs is probably needed</del></li>
</ul>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FreeWilly 1 and 2, two new open-access LLMs (102 pts)]]></title>
            <link>https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models</link>
            <guid>36818923</guid>
            <pubDate>Fri, 21 Jul 2023 20:03:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models">https://stability.ai/blog/freewilly-large-instruction-fine-tuned-models</a>, See on <a href="https://news.ycombinator.com/item?id=36818923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-92ab10ed08f1f3488e0d">
  <p>Stability AI and its <a href="https://carper.ai/" target="_blank"><span>CarperAI lab</span></a> are proud to announce <a href="https://huggingface.co/stabilityai/FreeWilly1-Delta-SafeTensor" target="_blank"><span>FreeWilly1</span></a> and its successor <a href="https://huggingface.co/stabilityai/FreeWilly2" target="_blank"><span>FreeWilly2</span></a>, two powerful new, open access, Large Language Models (LLMs). Both models demonstrate exceptional reasoning ability across varied benchmarks. FreeWilly1 leverages the original LLaMA 65B foundation model and was carefully fine-tuned with a new synthetically-generated dataset using Supervised Fine-Tune (SFT) in standard Alpaca format. Similarly, FreeWilly2 leverages the LLaMA 2 70B foundation model to reach a performance that compares favorably with GPT-3.5 for some tasks.</p><p>Both models are research experiments, and are released to foster open research under a non-commercial license. While we have conducted internal red-teaming to ensure the model remains polite and harmless, we welcome the community's feedback and help in further red-teaming.</p><p><strong>Data Generation and Collection</strong></p><p>The training for the FreeWilly models was directly inspired by the methodology pioneered by Microsoft in its paper: "Orca: Progressive Learning from Complex Explanation Traces of GPT-4.” While our data generation process is similar, we differ in our data sources.</p><p>Our variant of the dataset, containing 600,000 data points (roughly 10% of the dataset size the original Orca paper used), was created by prompting language models with high-quality instructions from the following datasets created by <a href="https://huggingface.co/conceptofmind" target="_blank"><span>Enrico Shippole</span></a>:</p><ol data-rte-list="default"><li><p><a href="https://huggingface.co/datasets/conceptofmind/cot_submix_original" target="_blank"><span>COT Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/niv2_submix_original" target="_blank"><span>NIV2 Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/flan2021_submix_original" target="_blank"><span>FLAN 2021 Submix Original</span></a></p></li><li><p><a href="https://huggingface.co/datasets/conceptofmind/t0_submix_original" target="_blank"><span>T0 Submix Original</span></a></p></li></ol><p>With this approach, we generated 500,000 examples with one simpler LLM model and an additional 100,000 with a more sophisticated LLM model. To ensure fair comparisons, we carefully filtered these datasets and removed examples that originated from evaluation benchmarks. Despite training on one-tenth the sample size of the original Orca paper (significantly reducing the cost and carbon footprint of training the model compared to the original paper), the resulting FreeWilly models demonstrate exceptional performance across various benchmarks – validating our approach to synthetically generated datasets.</p><p><strong>Performance Evaluation</strong></p><p>To internally evaluate these models, we used EleutherAI’s <a href="https://github.com/EleutherAI/lm-evaluation-harness" target="_blank"><span>lm-eval-harness</span></a>, to which we added <a href="https://github.com/dmahan93/lm-evaluation-harness/tree/add-agieval" target="_blank"><span>AGIEval</span></a>.</p><p>Both FreeWilly models excel in many areas, including intricate reasoning, understanding linguistic subtleties, and answering complex questions related to specialized domains, e.g. Law and mathematical problem-solving.</p><p><strong>Open LLM Leaderboard benchmarks:</strong></p><p>These FreeWilly results were evaluated by Stability AI researchers and independently reproduced by Hugging Face on July 21st, 2023, and published in their leaderboard.</p>
</div><div data-block-type="2" id="block-yui_3_17_2_1_1689965544627_21970">
  <p><strong>Contributing to an open future</strong></p><p>FreeWilly1 and FreeWilly2 set a new standard in the field of open access Large Language Models. They both significantly advance research, enhance natural language understanding, and enable complex tasks. We are excited about the endless possibilities that these models will bring to the AI community, and the new applications they will inspire.</p><p>We would like to express our sincere gratitude to our passionate team of researchers, engineers, and collaborators, whose remarkable efforts and dedication have enabled us to reach this significant milestone.</p><p>Stay tuned for more exciting developments, and begin exploring the incredible potential of FreeWilly today!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Journalists should be skeptical of all sources including scientists (398 pts)]]></title>
            <link>https://natesilver.substack.com/p/journalists-should-be-skeptical-of</link>
            <guid>36818896</guid>
            <pubDate>Fri, 21 Jul 2023 20:01:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://natesilver.substack.com/p/journalists-should-be-skeptical-of">https://natesilver.substack.com/p/journalists-should-be-skeptical-of</a>, See on <a href="https://news.ycombinator.com/item?id=36818896">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>I’m not usually one for scandals. My eyes glaze over at Congressional hearings. I’ve never read the Mueller Report. There are usually too many threads to unwind, and too many competing claims to evaluate. But I’m going to make an exception here, because we have a scandal where the facts are relatively simple and clear — but which was nevertheless extremely consequential.</p><p><span>Here’s the scandal. In March 2020, a group of scientists — in particular</span></p><p><span>, Kristian G. Andersen the of The Scripps Research Institute, Andrew Rambaut of The University of Edinburgh, Edward C. Holmes of the University of Sydney, and Robert F. Garry of Tulane University — published a paper in </span><em>Nature Medicine</em><span> that seemingly contradicted their true beliefs about COVID’s origins and which they knew to be misleading. The </span><a href="https://www.nature.com/articles/s41591-020-0820-9" rel="">paper</a><span>, “The proximal origin of SARS-CoV-2”, has been </span><a href="https://scholar.google.com/scholar?cites=4180430536993184356&amp;as_sdt=5,33&amp;sciodt=0,33&amp;hl=en" rel="">cited more than 5,900 times</a><span> and was enormously influential in shaping the debate about the origins of COVID-19.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp" width="820" height="385" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:385,&quot;width&quot;:820,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:31870,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e937c74-f2b6-478a-aa5d-c485635efa71_820x385.webp 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We know this because of a series of leaked and </span><a href="https://foia.state.gov/learn/foia.aspx" rel="">FOIAed</a><span> emails and Slack messages that have been reported on by </span><em>Public</em><span>, </span><em>Racket News, The Intercept </em><span>and </span><em>The Nation </em><span>along with other small, independent media outlets. You can find a detailed summary of the claims and a copy of the emails and messages </span><a href="https://public.substack.com/p/covid-origins-scientist-denounces" rel="">here</a><span> at </span><em>Public</em><span>. There’s also good context around the messages </span><a href="https://usrtk.org/covid-19-origins/timeline-the-proximal-origin-of-sars-cov-2/" rel="">here</a><span> (very detailed) or </span><a href="https://rogerpielkejr.substack.com/p/covidgate" rel="">here</a><span> and </span><a href="https://rogerpielkejr.substack.com/p/the-truth-is-never-going-to-come" rel="">here</a><span> (more high-level). </span></p><p><span>The messages show that the authors were highly uncertain about COVID’s origins — and if anything, they leaned more toward a lab leak than a spillover from an animal source. But none of that was expressed in the “Proximal Origin” paper, which instead said that </span><strong>“we do not believe that any type of laboratory-based scenario is plausible”.</strong><span> Granted, there is a little bit of ass-covering — “More scientific data could swing the balance of evidence to favor one hypothesis over another,” they also wrote in the paper. But the message — natural origin good, lab leak bad — was received clearly enough by mainstream news outlets. “No, the new coronavirus wasn't created in a lab, scientists say”, </span><a href="https://www.cbc.ca/news/science/coronavirus-wasnt-created-in-lab-no-signs-genetic-engineering-1.5508735" rel="">reported</a><span> the CBC in covering the paper. “COVID-19 coronavirus epidemic has a natural origin” was the </span><a href="https://www.sciencedaily.com/releases/2020/03/200317175442.htm" rel="">headline</a><span> at Science Daily.</span></p><p><span>In the Slack and email messages, the authors worked to manipulate the media narrative about COVID-19’s origins and to ensure that their private uncertainty wasn’t conveyed in conversations with reporters. They also thought they were going to get away with it. “The truth is never going to come out ”, </span><a href="https://twitter.com/mbalter/status/1679098392587255809/photo/1" rel="">wrote</a><span> Rambaut in one message. This went beyond mere motivated reasoning. There was an enormous gap between what the authors believed privately and what they stated publicly, including in the “Proximal Origin” paper — again, see the above links for more detail.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png" width="1456" height="182" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png&quot;,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:182,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:93385,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4312ffc-15ad-4abb-98af-dfcad3409f40_1600x200.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span>What were the authors’ motivations to mislead the public? I think that’s also pretty straightforward. In fact, you can find prominent virologists </span><a href="https://www.nature.com/articles/d41586-021-01383-3" rel="">quoted on record</a><span> as to why the lab leak theory was so </span><em>problematic</em><span> — even if it wasn’t necessarily </span><em>wrong</em><span>. The problems fall into three buckets:</span></p><ol><li><p><span>Evidence of a lab leak could cause a political backlash — understandably, given that COVID has killed almost 7 million people — resulting in a reduction in funding for gain-of-function research and other virological research. That’s potentially important to the authors or the authors’ bosses — and the authors were </span><a href="https://twitter.com/HansMahncke/status/1682193300055285760?s=20" rel="">very aware</a><span> of the career implications for how the story would play out;</span></p></li><li><p><span>Evidence of a lab leak could </span><a href="https://www.nytimes.com/2023/02/27/business/energy-department-theory-coronavirus-china.html" rel="">upset China and undermine research collaborations</a><span>;</span></p></li><li><p><span>Evidence of a lab leak could provide validation to Trump and Republicans who </span><a href="https://www.politico.com/news/2021/06/15/wuhan-lab-trump-officials-covid-494700" rel="">touted the theory</a><span> — remember, all of this was taking place during an election year, and medical, epidemiological and public health experts had few reservations about </span><a href="https://www.cnn.com/2020/06/05/health/health-care-open-letter-protests-coronavirus-trnd/index.html" rel="">weighing in on political matters</a><span>.</span></p></li></ol><p><span>To be clear, I’m not sure how COVID originated either. I’d “buy” the lab leak at a 50 percent likelihood (I think </span><a href="https://alexwasburne.substack.com/p/the-short-case-for-a-lab-origin" rel="">this</a><span> is pretty convincing) and sell it at 80 percent, which still leaves a lot of wiggle room for me to be persuaded one way or the other.</span></p><p>But I think this is a big scandal either way. As someone who has spent a lot of time trying to convey statistical and epistemic uncertainty to the public, I’m deeply disappointed by the scientists’ conduct here and how unmoored they were from any attempt at truth-seeking.</p><p><span>The COVID origins story has also been a </span><a href="https://www.slowboring.com/p/the-medias-lab-leak-fiasco" rel="">journalistic fiasco</a><span>, with the lab leak having been dismissed as a “</span><a href="https://www.nytimes.com/2020/02/17/business/media/coronavirus-tom-cotton-china.html" rel="">conspiracy theory</a><span>” and as </span><a href="https://www.nytimes.com/2020/03/08/technology/coronavirus-misinformation-social-media.html" rel="">misinformation</a><span> even though many prominent scientists believed it to be plausible all along. Perhaps it’s tempting to give the media a pass — they </span><em>were</em><span> manipulated by the “Proximal Origin” authors, after all. But I’m not inclined to, for two reasons.</span></p><p><span>First, the coverage of the recently leaked emails and Slack messages at major center-left outlets like The New York Times has been pathetic. The Times </span><a href="https://www.nytimes.com/2023/07/11/us/politics/covid-lab-leak-fauci.html" rel="">portrayed</a><span> Andersen as the victim of a Republican witch-hunt — rather than someone at the center of a major scientific scandal of his own making.</span></p><p><span>And second, journalists ought to have decent bullshit detectors — including toward scientists, academics and other experts.</span></p><p><span>Maybe you think Andersen </span><em>et. al.</em><span> are bad apples, but the messages make clear that they were speaking for a pretty broad swath of the scientific community. Still — and maybe this is wishful thinking — but I’m going to assert that people like him are in the minority among scientists. I fairly often speak with scientists and academics myself — especially when I’m working on a research-driven book project, as I am now — and those experiences are overwhelmingly positive.</span></p><p><span>And yet, even if the incidence of bad apples is relatively rare among scientists and academics — rarer than it might be among politicians or other groups that journalists intrinsically treat with more skepticism — it’s clearly not </span><em>exceedingly</em><span> rare. It was just this week that the </span><a href="https://stanforddaily.com/2023/07/19/stanford-president-resigns-over-manipulated-research-will-retract-at-least-3-papers/" rel="">president of Stanford was forced to resign in a research scandal</a><span>. (Perhaps not coincidently, the scandal was broken by the student newspaper, </span><em>The Stanford Daily</em><span>, and not by a major center-left outlet like The Times.)</span></p><p><span>I also think journalists are more prone toward being manipulated by bad apples in academia and science than they were ten or twenty years ago. As a result of</span><a href="https://www.nytimes.com/2021/09/08/us/politics/how-college-graduates-vote.html" rel=""> increasing educational polarization</a><span>, both journalists and the expert class of scientists and academics are far more aligned politically than they once were (the very large majority are left-of-center and vote Democratic in American elections). Even if “trust the science” or “trust the experts” is </span><em>usually</em><span> right — and I think it </span><em>usually</em><span> is right! — it leaves an opening for bad apples like Andersen to exploit the trust that honest scientists have worked so hard to earn.</span></p><p><span>There’s also a generational divide in journalism, with younger journalists tending to be more openly left/progressive than their older peers — and tending to be more </span><a href="https://www.vocabulary.com/dictionary/Manichean" rel="">Manichean</a><span> in dividing the world between good and evil rather than proceeding from the notion that people and news stories are complicated and it’s not particularly their job to pass moral judgment. It’s slightly amusing that The Times fired their Pulitzer Prize-winning coronavirus reporter in middle of the pandemic — a reporter who </span><a href="https://donaldgmcneiljr1954.medium.com/how-i-learned-to-stop-worrying-and-love-the-lab-leak-theory-f4f88446b04d" rel="">saw the lab leak theory as credible</a><span> — and replaced him with another reporter who </span><a href="https://www.cnn.com/2021/05/27/media/covid-19-origins-lab-leak-media/index.html" rel="">dismissed discussion of the lab leak as “racist”</a><span>. </span></p><p>But this really isn’t complicated. All I’m suggesting is that journalists ought to treat scientists like they do any other source — that is to say, with an appropriate dose of skepticism.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Big Tech as the New Big Tobacco (174 pts)]]></title>
            <link>https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</link>
            <guid>36818640</guid>
            <pubDate>Fri, 21 Jul 2023 19:44:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco">https://www.bigtechwiki.com/index.php/Big_Tech_as_the_New_Big_Tobacco</a>, See on <a href="https://news.ycombinator.com/item?id=36818640">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="bodyContent">
				<p>From BigTechWiki</p>
				
				
				<p><a href="#column-one">Jump to navigation</a><a href="#searchInput">Jump to search</a></p><!-- start content -->
				<div id="mw-content-text" lang="en" dir="ltr"><ul><li>Republicans and Democrats began to view Big Tech in the light Big Tobacco was, with one saying the comparison was “an appropriate analogy”</li></ul>
<ul><li>Lawmakers like Republicans Ken Buck and Cynthia Lummis and Democrat Ed Markey compared Facebook and Big Tech to Big Tobacco. Markey described Instagram as “that first childhood cigarette, meant to get teens hooked early.” Lummis agreed that comparing Facebook and Big Tech to Big Tobacco was an “appropriate analogy.” Republican Rep. Bill Johnston compared Big Tech CEOs to those from large tobacco companies, accusing the tech firms of being equally dangerous to society. Buck compared big tech to big tobacco, saying they were “harming our kids for profit.” Richard Blumenthal, who led a lawsuit against Big Tobacco in the 1990s as AG of CT, said Facebook and Big Tech were facing a “Big Tobacco moment,” comparing Facebook’s strategy papers with those done by Tobacco companies on reaching middle schoolers.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></li></ul>
<ul><li>Big Tech directly followed in Big Tobacco’s footsteps by funding academic research
<ul><li>Big Tobacco had a long history of commissioning and funding academic research to pull focus away from the proven harms of their products. Big Tech similarly started to fund institutions to ensure the “ethical development” of their technology, which led to questions about conflicts of interest and research independence. Researchers from Cornell noted that Big Tech and Big Tobacco’s funding of scientific research and development were similar in both industries: “Pump vast sums of money” into researching the problems they were creating.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></li>
<li>Both Big Tech and Big Tobacco wanted to influence research to ensure their industries sustained support and were seen as socially responsible. Researchers from Cornell said Big Tobacco invested in Academia in order to influence the research questions of those studying tobacco, hoping to find friendly academics who could be leveraged and recast the companies as socially responsible. Big Tobacco’s funding agencies worked to maintain an impartial and scientific image, even as it mainly funded research that was not about tobacco’s health impacts.</li>
<li>Much like Big Tobacco, the Academics that Big Tech invested in routinely failed to disclose their funding from Big Tech, which created a false impression of independence. The whole goal of funding the research was to exploit the confidence that is had in academia and research, because Think Tanks and organizations were treated as “neutral arbiters” by journalists and lawmakers.</li>
<li>At Big Tech funded agencies, public relations officials and lawyers were involved in plotting the overall research direction and tone. Internal Google documents directed scientists to “strike a positive tone” in their research. Further internal memos from Google showed that the company intended to use friendly academics as a key aim in its strategy to lobby against the EU’s Digital Markets Act. Big Tobacco has given hundreds of millions to research over the years and their efforts spanned across the globe. Big tobacco started its own research group, The Tobacco Industry Research Committee, in 1964 and pumped more than $130 million into the effort by 1986.</li>
<li>Big Tobacco continued this trend of investing in research across the globe, giving tens of thousands of Pounds to two think tanks in the UK that advised the government on Tobacco laws. The two think tanks criticized plans to force retailers to sell cigarettes in unbranded cartons, which was a measure supported by cancer charities and opposed by Big Tobacco. In 2019, it was reported that Tobacco companies had contributed to at least 106 think tanks in two dozen countries. The think tanks they contributed to were found to oppose plain cigarette packaging, had written to regulators in support of new tobacco products or promoted industry funded research. Big Tobacco also contributed to The Heritage Foundation, the Cato Institute and Americans For Tax Reform. As Big Tech faced pressure from proposed tech legislation, they significantly increased their spending on outside organizations, giving to nearly 771 third party organizations since 2015. A significant spike in funding of outside groups by Big Tech after federal and state officials increased scrutiny on their anti-competitive behaviors. Amazon went from contributing to 45 outside organizations in 2015 to 251 outside organizations in 2020. Google more than doubled the amount of outside groups it gave to in 2018 and 2019 compared to 2017 as it faced pressures from California’s consumer privacy law. All of this increased spending by Big Tech put a heavy pressure on academic staff to seek external sources of funding.<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup></li>
<li>Who Big Tech gives to and how much they contributed is murky, as think tanks and nonprofits aren’t required to disclose their funding. Despite Amazon, Facebook and Google voluntarily disclosing who they contributed to, the companies did not divulge the amounts of their contributions.</li>
<li>However, it was found that in the past 5 years, six leading academic institutes in the EU had taken tens of millions of pounds of funding from Google, Facebook, Amazon and Microsoft to research issues linked to the tech firm’s business models. The Institute For Ethics In Artificial Intelligence at the Technical University of Munich received a $7.5 million grant from Facebook in 2019. The Humboldt Institute for Internet and Society in Berlin accepted almost 14 million Euros from Google since it was founded in 2012.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup></li>
<li>In the U.S., Big Tech individually contributed to various renowned and highly influential think tanks and nonprofits. Those think tanks and nonprofits included but are not limited to the Cato Institute, Heritage Foundation, International Center for Law &amp; Economics, the Information Technology &amp; Innovation foundation and the Global Antitrust Institute at George Mason University.</li>
<li>Big Tech was rewarded handsomely for their contributions to nonprofits and think tanks. Some lobbyists, scholars and think tank officials argued that Google’s donations to nonprofit groups helped explain why it had avoided damaging regulatory and enforcement decisions in the U.S. Further, the major nonprofits that Big Tech had contributed to helped facilitate introductions between the government and Big Tech.</li>
<li>The Global Antitrust Institute at George Mason University had trained more than 850 foreign judges and regulators on Antitrust at their seminars.</li>
<li>While not all of the nonprofits and think tanks held events on behalf of Big Tech, many did advocate for Big Tech in other ways. The Cato Institute argued publicly that people should be “extremely skeptical about predictions of entrenched monopoly power” for big tech. The Progressive Policy Institute president and founder Will Marshall published an op-ed arguing against breaking up Big Tech monopolies while simultaneously calling them “innovative and successful.”</li></ul></li>
<li>Big Tobacco was a lobbying “juggernaut” that invented the special interest lobbying model Big Tech used
<ul><li>In 1998, the Big Tobacco spent nearly $73 million on federal lobbying and employed over 200 lobbyists. When adjusted for inflation, the #73 million in 1998 equated to $122 million in 2021. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco had “invested in the kind of special interest lobbying” that characterized the late 20th and early 21st century American politics. Big Tobacco was known for their “giant spending” and effective lobbying.</li>
<li>Big Tobacco was said to have a “substantial” presence on Capitol Hill and had a lobbying effort so large it could only be described as a “juggernaut” by OpenSecrets. The Dean of Harvard’s graduate school of arts and sciences said Big Tobacco spent “boatloads” of money in Congress to prevent regulation as more information became public about the harm their products caused. Still to this day, Big Tobacco employed a massive amount of lobbyists, with Altria employing at least 409 lobbyists in 49 states and Reynolds employing 257 lobbyists in 39 states.</li>
<li>Big Tobacco were also big spenders politically in the 90’s and early 2000’s. In 1996, the tobacco industry contributed more than $10 million to political campaigns. In 1998, they contributed more than $8.6 million. In 2000, Big Tobacco again spent more than $8.6 million on political campaigns. And in 2002, Big Tobacco spent $9.29 million on political campaigns. Reynolds American and Altria Group also donated $1.5 million to Donald Trump’s inauguration.</li></ul></li>
<li>Big Tech invested in lobbying to the same degree that Big Tobacco did and have similarly become Washington lobbyists biggest cash cow
<ul><li>A June 2021 NY Times headline read “Tech Giants, Fearful of Proposals to Curb Them, Blitz Washington With Lobbying.” And in 2020, Big Tech spent more on lobbying than any other industry at a combined $51.72 million. Facebook spent the most out of any company in 2020 and the same year spent the most it ever had on lobbying: $19.68 million. Following in second was Amazon, who spent $17.86 million on lobbying, which was also the most the company had ever spent in a year on lobbying. Google spent $7.53 million on lobbying and Apple spent $6.6 million on lobbying in 2020. When asked what they were looking to achieve with their lobbying, none of the tec companies would detail their targets.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup></li></ul></li>
<li>Big Tobacco created the model for Big Tech’s pre-empting legislation and regulation Big Tobacco offered to fund research and write legislation that would carve ou several loopholes and prevent stricter rules in the future
<ul><li>Starting in the 1980s, Big Tobacco worked to pre-empt legislation with their own corporate-written legislation, a trend that continued into recent policy debates over the legal age to buy tobacco products. Big Tobacco had worked to pre-empt laws to raise the legal age to buy smoking products from 18 to 21 by pushing new legislation that would make enforcement difficult and nullify tougher local laws. A spokesman for the Campaign For Tobacco-Free Kids argued that Big Tobacco were “masters at proposing or supporting a bill that looked good on the surface but often included provisions that [were] harmful to public health.”</li>
<li>By pre-empting legislation, Tobacco was able to halt any local efforts to limit how tobacco used. It was said that by pre-empting legislation with their own corporate-backed bills, Big Tobacco could effectively tie the hands of city governments who wanted to limit tobacco use further. Tobacco companies had been working to pre-empt legislation for decades, including pre-empting versions of the Clean Indoor Air Acts in the 1980s and 1990s. In 1994, a Philip Morris Employee even wrote that the company was “dead serious about achieving pre-emption in all 50 states.”</li></ul></li>
<li>Big Tech followed suit and began supporting legislation they felt they could control to build goodwill after scandals ravaged the industry
<ul><li>Following the Cambridge Analytica scandal, Facebook appeared to back some government regulation. The company launched a new campaign that offered concessions on the Big Tech regulatory debate to generate some goodwill while trying to reframe the larger debate on its own terms. Zuckerberg said in testimony that he welcomed privacy and misinformation regulation as long as it was the “right regulation.”</li>
<li>Zuckerberg went so far as to call on congress to make “thoughtful reform” of Section 230, which safeguarded tech platforms from being held liable for content individual users posted. Zuckerberg said a company’s liability protection under Section 230 should be conditional on their ability to prove they can moderate harmful content – regardless if it successfully removed all harmful content. Zuckerberg's proposal for Section 230 immunity reforms “could theoretically shore up Facebook’s power” as it forced smaller social media companies and startups to develop costly content moderation systems. However, Facebook executives testified before Congress that they wanted Congress to pre-empt local laws that likely included stricter privacy protections than a federal bill.</li>
<li>Ironically, just weeks before Zuckerberg’s 2018 testimony, Facebook poured hundreds of thousands into fighting a privacy ballot initiative in California. Facebook gave $200,000 to a PAC dedicated to defeating “a state ballot initiative that would expand Californian’s privacy controls. After his testimony, Facebook withdrew support for the group and then declined to say if they were involved in other efforts to oppose privacy legislation.</li></ul></li>
<li>Big Tech also used more subtle means to influence policy, like leaning heavily and quietly on trade associations.
<ul><li>A Big Tech lobbyist admitted that there was “strength in numbers” and said Big Tech could use trade associations to “do a little bit of heavy lifting.” Big Tech had increasingly been leaning on industry associations to influence public policy in Washington. Lobbyist Kate Mills, a partner at a Amazon-hired lobbying firm, admitted that Big Tech’s strategy involved leaning heavily and quietly on trade associations.</li>
<li>Amazon, Facebook and Google funded a bevy of political groups that had helped push positive polling and engaged in other “fingerprint-free tactics” designed to deter regulators seeking to break up or penalize the industry. An advocacy group funded by Big Tech had secretly written an op-ed for a local small businessman in Arizona that opposed the state’s investigation into Google. The small business owner was unaware Google had backed the group that approached him to publish the op-ed.</li>
<li>In a single year, Amazon reported spending $6.36 million on state focused “government relations efforts” in 44 states.</li></ul></li></ul>
<ul><li>Big Tech supported a wide range of industry associations that advocated and lobbied for them in D.C.
<ul><li>Big Tech has contributed to a wide range of industry associations, including but not limited to NetChoice, U.S. Chamber of Commerce, The Consumer Technology Association, The Competitive Enterprise Institute, Americans for Tax Reform, TechNet, The Small Business &amp; Entrepreneurship Council, The Internet Association and ComPITA</li>
<li>The various organizations pushed for Big Tech’s goals and defended them when they came under fire. NetChoice, “Tech’s most aggressive lobbying presence in D.C.” was a vocal opponent of antitrust action against Google. NetChoice attacked Texas’ lawsuit against Google’s anticompetitive advertising practices and attacked the DOJ’s antitrust lawsuit against Google.</li>
<li>The Consumer Technology Association spent $10 million on lobbying for Big Tech and opposed local tech regulations on their behalf. The Consumer Technology Association counted Facebook, Alphabet, Apple and Amazon as members. The group opposed proposed right to repair laws in Nevada and elsewhere.</li>
<li>Other organizations provided extra support for Big Tech when they were railing against antitrust or privacy legislation. The Progressive Policy Institute joined Google, Facebook and Amazon (all of which were donors) when the companies were fighting back against Senator Warren’s call to break up Big Tech. Facebook’s Lobbyist co-chaired a technology council at the Illinois Chamber of Commerce as the Chamber was backing the gutting of an online privacy law.</li>
<li>Facebook turned to a lower-profile trade groups such as The Internet Association and CompTIA to help block privacy legislation. 21 days after a judge ruled against Facebook in a biometric privacy act lawsuit, a Facebook backed law weakening Illinois’ biometric privacy act was introduced in the Illinois state legislature. Facebook and CompTIA were directly described as “having a hand in blocking or weakening biometric privacy bills in Montana, Washington, And Illinois.”</li>
<li>CompTIA pushed for changes to the biometric information privacy act on Facebook’s behalf, along with donating to the Republican Party of Texas, where the Republican Attorney General was the sole enforcer of the State’s Biometric Privacy Regulations</li>
<li>In 2020, Facebook launched an astroturf organization to convince federal regulators that Facebook was crucial to free speech. Facebook created American Edge to combat potential federal regulations through advertising and other means. After American Edge was formed as a nonprofit organization, it set up an accompanying social welfare group, which was a common tactic used to obscure donors. American Edge said it was important to create policies that don’t weaken companies that “share American values” as they competed globally.</li></ul></li>
<li>Much like Big Tobacco was in the 90s, Big Tech became mammoth political donors, collectively spending more than $100 million between 2016-2020
<ul><li>Most of Big Tech’s campaign contributions went towards Democrats, which increased year by year as Democrats grew louder about tech reform. Between 2016-2020, Alphabet, Google’s parent company, contributed more than $44 million in political donations. Between 2018-2020, Amazon contributed more than $26 million to political campaigns. Apple contributed more than $12 million to political campaigns between 2016-2020 and Facebook contributed more than $18 million to political campaigns between 2016-2020. Facebook also donated to all four co-sponsors of an Illinois bill to weaken the 2008 biometric information privacy act.</li></ul></li>
<li>Adding to their influence campaigns, Big Tech followed Big Tobacco’s playbook of employing revolving door techniques both Big Tobacco and Big Tech have had former employees in high level government positions and have hired former high level government officials
<ul><li>Big Tobacco found a way to deeply ingratiate themselves with the Trump and Bush administrations. Several top Bush administration staffers had backgrounds in Tobacco, including Senior Adviser Karl Rove. Vice President Pence had extensive ties to the Tobacco industry, receiving $39k in donations from RJ Reynolds and more than $60k from the industry group National Association of Convenience Stores. Senator Blumenthal noted that many of Trump’s appointees had “deep commitments to the Tobacco industry.” Former head of the FDA Scott Gottlieb worked for the e-cigarette company Kure and condemned the influence of Anti-tobacco “activists” in the FDA. The former Solicitor General Noel Francisco represented RJ Reynolds on behalf of the corporate law firm Jones Day prior to joining the federal government.</li>
<li>Big Tobacco also hired former Trump Officials as lobbyists. RJ Reynolds hired former Health and Human Services Secretary Tom Price’s deputy Chief of Staff as their lobbyists.</li>
<li>Google had an ally in the DOJ’s antitrust division during the Trump Administration and a former FTC commissioner joined a law firm Google had hired. Makan Delrahim, who led the DOJ antitrust division under Donald Trump, formerly worked on behalf of Google. After leaving office, former FTC commissioner Joshua Wright joined a law firm that represented Google before the FTC.</li></ul></li>
<li>Big Tobacco and Big Tech had a habit of running from their names after losing public trust in 2003, Philip Morris changed its name to ‘Altria Group’ after public started to feel their name “meant death”
<ul><li>Philip Morris said the name change brought “clarity” to its corporation and operating companies. In 2003, Philip Morris changed its name to ‘Altria Group’. The company said the name change brought “clarity” to its corporate structure and the relationship between the parent company to its operating companies. Philip Morris’ Senior Vice President at the time said “When people say ‘Philip Morris’, people don’t know which company you’re talking about [...] We’re more than a tobacco company.”</li>
<li>Philip Morris also owned Kraft Foods along with their tobacco company</li>
<li>In reality, the name change was a financial decision brought as a way to distance the company from the “death” people associated with them. A former FDA commissioner said Philip Morris was “running away from tobacco” with their name change. The company’s connection with Tobacco had long depressed its stock price, despite being the largest packaged goods company. To consumers, Philip Morris meant tobacco, and tobacco meant death.</li></ul></li>
<li>Facebook planned to change its company name to ‘Meta’ after facing fire for spreading misinformation
<ul><li>Facebook planned to change the name of its company to ‘Meta’ as a signal of its ambition to be known for more than social media. Facebook was reportedly investing in what it called the ‘Metaverse’ which was a digital world where people used various devices to engage with each other in a 3d environment.</li>
<li>The name change came after internal memos leaked showing the company knew about the damage it caused society. At the time of the name change, Facebook was facing some of the most intense scrutiny in its history after an internal whistleblower had leaked internal documents showing Facebook knew about the harmful effects it was having.</li>
<li>Much like Philip Morris, Facebook’s renaming was seen as a way to distance itself from the social networking controversies it was facing. TV personality Jim Cramer kind of let the cat out of the bag when he said the secret of Facebook’s valuation was because of its “habit of reinvention” Facebook’s name change was seen as directly resembling Philip Morris’ decision to change their name after controversies plagued the company. Fast Company said “for a company that brisle[d] at references to its services being akin to cigarettes, taking a page from the Big Tobacco playbook [was] a stunner.” But at the end of the day, the name change would have no impact on Facebook’s operations or executive structure. The change was largely cosmetic.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup></li></ul></li>
<li>Big Tech spent more on federal lobbying from 2010-202 than the nation’s largest banks from 2000-2010 or Big Tobacco from 1996-1999
<ul><li>Since 2000, the four largest Big Tech companies – Amazon, Apple, Alphabet/Google, and Facebook – have spent $465,026,307 on federal lobbying. $434,474,221 of that total has come since 2010.</li>
<li>Additionally, nine groups that the four Big Tech companies fund have spent $98,061,827 on federal lobbying since 2000. $80,400,019 of that total has come since 2010.</li>
<li>Big Tech’s federal lobbying total eclipses that of other major toxic industries: Since 2010, the nation’s largest opioid manufacturers have spent $282,292,834 on federal lobbying. America’s seven largest banks in the leadup to the financial crisis spent $194,193,858 on federal lobbying from 2000 to 2010. From 1996 to 1999, the nation’s largest tobacco companies spent $155,750,398 on federal lobbying, or $261,306,596 in 2021 dollars.</li></ul></li></ul>
<div><ol>
<li id="cite_note-1"><span><a href="#cite_ref-1">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html">https://www.nytimes.com/2021/10/09/technology/facebook-big-tobacco-regulation.html</a></span>
</li>
<li id="cite_note-2"><span><a href="#cite_ref-2">↑</a></span> <span><a rel="nofollow" href="https://arxiv.org/abs/2009.13676">https://arxiv.org/abs/2009.13676</a></span>
</li>
<li id="cite_note-3"><span><a href="#cite_ref-3">↑</a></span> <span><a rel="nofollow" href="https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry">https://www.theguardian.com/business/ng-interactive/2019/jan/23/free-market-thinktanks-tobacco-industry</a></span>
</li>
<li id="cite_note-4"><span><a href="#cite_ref-4">↑</a></span> <span><a rel="nofollow" href="https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes">https://www.newstatesman.com/science-tech/big-tech/2021/07/how-google-quietly-funds-europe-s-leading-tech-policy-institutes</a></span>
</li>
<li id="cite_note-5"><span><a href="#cite_ref-5">↑</a></span> <span><a rel="nofollow" href="https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html">https://www.nytimes.com/2021/06/22/technology/amazon-apple-google-facebook-antitrust-bills.html</a></span>
</li>
<li id="cite_note-6"><span><a href="#cite_ref-6">↑</a></span> <span><a rel="nofollow" href="https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc">https://www.fastcompany.com/90424503/facebook-google-amazon-are-ramping-up-their-secretive-influence-campaigns-in-dc</a></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Cached time: 20230721193631
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.034 seconds
Real time usage: 0.037 seconds
Preprocessor visited node count: 51/1000000
Post‐expand include size: 0/2097152 bytes
Template argument size: 0/2097152 bytes
Highest expansion depth: 2/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 498/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%    0.000      1 -total
-->

<!-- Saved in parser cache with key btwiki_db:pcache:idhash:29-0!canonical and timestamp 20230721193631 and revision id 413. Serialized with JSON.
 -->
</div>
				
				<!-- end content -->
				
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don’t Make Fun of Renowned Dan Brown (2013) (161 pts)]]></title>
            <link>https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</link>
            <guid>36818501</guid>
            <pubDate>Fri, 21 Jul 2023 19:35:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/">https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/</a>, See on <a href="https://news.ycombinator.com/item?id=36818501">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
			
<article id="post-945">
	
	<!-- .entry-header -->

	<div>
		<div>
<p><a href="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg"><img data-attachment-id="946" data-permalink="https://onehundredpages.wordpress.com/2013/06/12/dont-make-fun-of-renowned-dan-brown/dan-brown/" data-orig-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg" data-orig-size="236,363" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dan brown" data-image-description="" data-image-caption="" data-medium-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=195" data-large-file="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=236" alt="dan brown" src="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=768" srcset="https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg 236w, https://onehundredpages.files.wordpress.com/2013/06/dan-brown.jpg?w=98 98w" sizes="(max-width: 236px) 100vw, 236px"></a></p>
<p>Renowned author Dan Brown woke up in his luxurious four-poster bed in his expensive $10 million house – and immediately he felt angry. Most people would have thought that the 48-year-old man had no reason to be angry. After all, the famous writer had a new book coming out. But that was the problem. A new book meant an inevitable attack on the rich novelist by the wealthy wordsmith’s fiercest foes. The critics.</p>
</div>
<p>Renowned author Dan Brown hated the critics. Ever since he had become one of the world’s top renowned authors they had made fun of him. They had mocked bestselling book&nbsp;<i>The Da Vinci Code</i>, successful novel&nbsp;<i>Digital Fortress</i>, popular tome&nbsp;<i>Deception Point</i>, money-spinning volume&nbsp;<i>Angels &amp; Demons</i>&nbsp;and chart-topping work of narrative fiction&nbsp;<i>The Lost Symbol</i>.</p>
<p>The critics said his writing was clumsy, ungrammatical, repetitive and repetitive. They said it was full of unnecessary tautology. They said his prose was swamped in a sea of mixed metaphors. For some reason they found something funny in sentences such as “His eyes went white, like a shark about to attack.”&nbsp;<i>They even say my books are packed with banal and superfluous description</i>, thought the 5ft 9in man. He particularly hated it when they said his imagery was nonsensical. It made his insect eyes flash like a rocket.</p>
<p>Renowned author Dan Brown got out of his luxurious four-poster bed in his expensive $10 million house and paced the bedroom, using the feet located at the ends of his two legs to propel him forwards. He knew he shouldn’t care what a few jealous critics thought. His new book Inferno was coming out on Tuesday, and the 480-page hardback published by Doubleday with a recommended US retail price of $29.95 was sure to be a hit. Wasn’t it?</p>
<div>
<p><i>I’ll call my agent</i>, pondered the prosperous scribe. He reached for the telephone using one of his two hands. “Hello, this is renowned author Dan Brown,” spoke renowned author Dan Brown. “I want to talk to literary agent John Unconvincingname.”</p>
<p>“Mr Unconvincingname, it’s renowned author Dan Brown,” told the voice at the other end of the line. Instantly the voice at the other end of the line was replaced by a different voice at the other end of the line. “Hello, it’s literary agent John Unconvincingname,” informed the new voice at the other end of the line.</p>
<p>“Hello agent John, it’s client Dan,” commented the pecunious scribbler. “I’m worried about new book Inferno. I think critics are going to say it’s badly written.”</p>
<p>The voice at the other end of the line gave a sigh, like a mighty oak toppling into a great river, or something else that didn’t sound like a sigh if you gave it a moment’s thought. “Who cares what the stupid critics say?” advised the literary agent. “They’re just snobs. You have millions of fans.”</p>
<p><i>That’s true</i>, mused the accomplished composer of thrillers that combined religion, high culture and conspiracy theories. His books were read by everyone from renowned politician President Obama to renowned musician Britney Spears. It was said that a copy of&nbsp;<i>The Da Vinci Code</i>&nbsp;had even found its way into the hands of renowned monarch the Queen. He was grateful for his good fortune, and gave thanks every night in his prayers to renowned deity God.</p>
<p>“Think of all the money you’ve made,” recommended the literary agent. That was true too. The thriving ink-slinger’s wealth had allowed him to indulge his passion for great art. Among his proudest purchases were a specially commissioned landscape by acclaimed painter Vincent van Gogh and a signed first edition by revered scriptwriter William Shakespeare.</p>
<p>Renowned author Dan Brown smiled, the ends of his mouth curving upwards in a physical expression of pleasure. He felt much better. If your books brought innocent delight to millions of readers, what did it matter whether you knew the difference between a transitive and an intransitive verb?</p>
<p>“Thanks, John,” he thanked. Then he put down the telephone and perambulated on foot to the desk behind which he habitually sat on a chair to write his famous books on an Apple iMac MD093B/A computer. New book Inferno, the latest in his celebrated series about fictional Harvard professor Robert Langdon, was inspired by top Italian poet Dante. It wouldn’t be the last in the lucrative sequence, either. He had all the sequels mapped out. The Mozart Acrostic. The Michelangelo Wordsearch. The Newton Sudoku.</p>
<p>The 190lb adult male human being nodded his head to indicate satisfaction and returned to his bedroom by walking there. Still asleep in the luxurious four-poster bed of the expensive $10 million house was beautiful wife Mrs Brown. Renowned author Dan Brown gazed admiringly at the pulchritudinous brunette’s blonde tresses, flowing from her head like a stream but made from hair instead of water and without any fish in. She was as majestic as the finest sculpture by Caravaggio or the most coveted portrait by Rodin.&nbsp;<i>I like the attractive woman</i>, thought the successful man.</p>
<p>Perhaps one day, inspired by beautiful wife Mrs Brown, he would move into romantic poetry, like market-leading British rhymester John Keats.<i>That would be good</i>, opined the talented person, and got back into the luxurious four-poster bed. He felt as happy as a man who has something to be happy about and is suitably happy about it.</p>
<p>Inferno by Dan Brown 470pp, Bantam Press, rrp £20</p>

</div>

			
						</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article><!-- #post-## -->

			
<!-- #comments -->

				<!-- .navigation -->
	
		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Slackware Linux distribution turns 30 years old (201 pts)]]></title>
            <link>https://www.theregister.com/2023/07/20/slackware_turns_30/</link>
            <guid>36818233</guid>
            <pubDate>Fri, 21 Jul 2023 19:17:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/07/20/slackware_turns_30/">https://www.theregister.com/2023/07/20/slackware_turns_30/</a>, See on <a href="https://news.ycombinator.com/item?id=36818233">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>This week the Slackware Linux project is celebrating its 30th anniversary. It is the oldest Linux distribution that is still in active maintenance and development.</p>
<p>Version 1.0 of Slackware was <a href="http://www.slackware.com/announce/1.0.php" rel="nofollow">announced</a> on the July 16, 1993, and project lead Patrick Volkerding, who still maintains the distribution today, celebrated with a <a href="https://www.patreon.com/posts/thirty-years-86196804" rel="nofollow">modest announcement</a>:</p>

<p>The current version, Slackware 15, <a href="https://www.theregister.com/2021/04/16/slackware_15_beta/">went into beta in 2021</a> and <a href="https://www.theregister.com/2022/02/07/slackware/">was released early last year</a>.</p>
<p>It wasn't the first distribution; that was arguably MCC Interim Linux, whose first release candidate, <a href="http://debian.mcc.ac.uk/non-debian/mcc-interim/old/0.97-p2-12/README" rel="nofollow">version 0.97</a> appeared just a couple of months after the kernel itself in 1991. Interim lacked a lot of characteristics which today are givens, such as a package manager. Several other distros <a href="https://www.linuxjournal.com/article/2755" rel="nofollow">followed</a> closely behind it, notably including SLS, the Softlanding Linux system. As this 2020 <a href="https://casadevall.pro/articles/2020/06/softlanding-linux-system-1.0.5/" rel="nofollow">write-up</a> shows, SLS was pretty basic, but it quickly inspired two offspring.</p>
<p>The <a href="https://www.theregister.com/2015/12/30/ian_murdock_debian_founder/">late Ian Murdock</a> was inspired to begin work on Debian by his dissatisfaction with SLS, as his original 1993 <a href="https://groups.google.com/g/comp.os.linux.development/c/Md3Modzg5TU/m/xty88y5OLaMJ" rel="nofollow">announcement</a> says. It took a couple of months to get that first release together, though, meaning that Debian is just very slightly younger. Its first release arrived about two months after Slackware 1.0, as <a href="https://www.theregister.com/2018/08/16/debian_at_25/">we noted for Debian's 25th anniversary</a>.</p>

    

<p>Slackware Linux began as a project to clean up and improve upon SLS, and since it's still going today, we have to say that it's succeeded in that mission. There are three variants of Slackware these days. The eponymous form remains an x86-32 system, whereas Slackware64 targets 21st century 64-bit x86 hardware. (There's also an <a href="https://arm.slackware.com/" rel="nofollow">Arm64 version</a> too, but the former PowerMac and IBM S/390 versions have been discontinued.) <em>The Reg</em> FOSS Desk put it onto one of our older machines for a test drive, and came away pleasantly surprised.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack-15-boot.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack-15-boot.png?x=648&amp;y=360&amp;infer_y=1" alt="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." title="Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next." height="360" width="648"></a></p><p>Slackware64 v15 has an unwelcoming boot screen, but it's not 1996 any more. You can always just Google what to do next</p>
</div>
<p>Way back in about 1996, emboldened by his success with <a href="https://techmonitor.ai/technology/lasermoon_touts_inexpensive_standard_linux_system_for_scientific_academic_users_unix_95_branding_in_prospect" rel="nofollow">Lasermoon Linux/FT</a> on his work PC, Slackware 3 was the first ever distro that this vulture tried to install on his own home PC: a Sunrace laptop, with external hard disk and CD-ROM drives on its built-in Adaptec SCSI interface. (Its internal IDE hard disk was occupied by OS/2 2.0, which was our personal go-to operating system of the time.) We never managed to find the correct incantation to get kernel 1.2 to load its <code>aha152x</code> driver correctly, and retired defeated.</p>
<ul>

<li><a href="https://www.theregister.com/2023/07/19/mint_212/">Mint 21.2 is desktop Linux without the faff</a></li>

<li><a href="https://www.theregister.com/2023/07/18/linux_desktop_debate/">Linux has nearly half of the desktop OS Linux market</a></li>

<li><a href="https://www.theregister.com/2023/07/17/almalinux_project_switches_focus/">AlmaLinux project climbs down from being a one-to-one RHEL clone</a></li>

<li><a href="https://www.theregister.com/2023/07/13/wayland_is_coming/">Three signs that Wayland is becoming the favored way to get a GUI on Linux</a></li>
</ul>
<p>What's surprising about Slackware today is that in some ways, it's superficially quite similar to how it was back then. There are no fripperies such as live graphical desktops here. It boots to a login prompt, and then you're expected to manually run a <code>setup</code> program, and use very 1990s DOS-style text-mode menus to tick boxes for the components that you want installed.</p>
<div><p><a href="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png" target="_blank"><img src="https://regmedia.co.uk/2023/07/19/slack64-15-setup.png?x=648&amp;y=353&amp;infer_y=1" alt="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " title="The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away. " height="353" width="648"></a></p><p>The Slackware setup program doesn't look much different since the 20th century, but behind the scenes, it automates a ton of stuff away</p>
</div>
<p>The flipside of this is that all of our hardware was automatically detected, and it was all remarkably easy from then on. The setup program includes a choice of graphical desktop environments, and we particularly appreciated the jokey description of Xfce as a "Cholesterol Free Desktop Environment." In fact, quite a few elements of the setup program are jokily informal – for instance, the option for individual confirmation of every package warns that installing this way will take a couple of years.</p>
<p>It didn't configure a graphical login screen by default, or even an ordinary user account, but all that was needed was to type <code>startx</code> and the desktop launched, complete with AMD Radeon graphics drivers preconfigured, and ready to connect to a wireless network. To be honest, we expected substantially more manual effort than this. It's not all a complete doddle: for example, in order to run an online update, you have to manually edit a provided list of mirrors, and uncomment one (and only one) of them.</p>

        

<p>Slackware 15 is very much <em>not</em> a lightweight distribution. Running a full update brought us perilously close to filling up our 16GB root partition, and it wasn't particularly snappy on the elderly Thinkpad W500 that we chose to test it on – although it was a bit quicker than the <a href="https://www.theregister.com/2023/07/19/mint_212/">copy of Linux Mint 21.2</a> it was dual-booting alongside. However, all the controls and config is right there, laid out for you, and if you manually prune some things, you could trim it to size quite easily.</p>
<p>It has online repositories, automatic dependency resolution, and all the bells and whistles that you'd expect from a 21st century distro – just with some of the look and feel of an original 1990s distro. It even still uses LILO by default. Running that first update, we found some worrying warnings online about building a corresponding <code>initrd</code> after you update the kernel… but all that stuff has gone away. In version 15, it's just taken care of for you, automatically.</p>

        

<p>Slackware today is in fact a modern distro, which just happens to look old fashioned due to its simple text-mode installation program, lack of a graphical desktop manager, and a few other cosmetic details. We're not sure if this is from tradition, or whether it's intentional (perhaps to scare away annoying newbies) – or, of course, it may be both. Today it's considerably easier to install than much younger distributions such as Alpine Linux or Arch Linux – or indeed than any of the BSDs, of which it's faintly reminiscent. Oh, and like BSD, it's systemd-free as well. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IMAX emulates PalmPilot software to power Oppenheimer’s 70 mm release (211 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</link>
            <guid>36817900</guid>
            <pubDate>Fri, 21 Jul 2023 18:52:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/">https://arstechnica.com/gadgets/2023/07/imax-emulates-palmpilot-software-to-power-oppenheimers-70-mm-release/</a>, See on <a href="https://news.ycombinator.com/item?id=36817900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      The other kind of PDA    —
</h4>
            
            <h2 itemprop="description">IMAX TikTok shows an emulated Palm PDA controlling <em>Oppenheimer's</em> 600-lb reel. </h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-800x362.jpg" alt="Cillian Murphy in">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/oppenheimer-scaled.jpg" data-height="1157" data-width="2560">Enlarge</a> <span>/</span> Cillian Murphy in <em> Oppenheimer</em>.</p></figcaption>  </figure>

  




<!-- cache hit 296:single/related:d5a2ef92719af72bf29e17b49d627ab5 --><!-- empty -->
<p>It's a big week for IMAX, which has been promoting today's release of <em>Oppenheimer</em>. It's a particularly big deal for IMAX because the film is the first to get a 70 mm IMAX release since 2020's <em>Tenet</em>. So, you could understand why the company took to social media to boast of the size and magnitude of running the film, which is <a href="https://apnews.com/article/oppenheimer-christopher-nolan-0f8c1fdc4a358decee6105cac91a90ae">said</a> to be 11 miles long and 600 pounds. But in addition to the blockbuster IMAX release is something that hasn't been a showstopper in ages: a PDA.</p>
<p>And you can't discuss personal digital assistants (PDAs) without mentioning PalmPilots. The Palm computing devices were once the epitome of handheld technological organization. But Palm Computing, which endured a series of acquisitions before HP <a href="https://www.businessinsider.com/live-hps-earnings-call-2011-8">sunset the brand</a> in 2011, made other devices besides PalmPilots. One of those is the Palm m130, which is apparently IMAX projectionists' ideal controller for running 70 mm film.</p>
<p>As shown in IMAX's TikTok video below, the 70 mm print for <em>Oppenheimer</em> is so large that they had to extend their film platter. That's fascinating and all, but so is the emulated 2002 PDA apparently running things:</p>
<blockquote cite="https://www.tiktok.com/@imax/video/7255327705313430830" data-video-id="7255327705313430830">
<section><a title="@imax" href="https://www.tiktok.com/@imax?refer=embed" target="_blank" rel="noopener">@imax</a> Constantly pushing the boundaries of film . <a title="oppenheimer" href="https://www.tiktok.com/tag/oppenheimer?refer=embed" target="_blank" rel="noopener">#Oppenheimer</a> <a title="christophernolan" href="https://www.tiktok.com/tag/christophernolan?refer=embed" target="_blank" rel="noopener">#ChristopherNolan</a> <a title="imax" href="https://www.tiktok.com/tag/imax?refer=embed" target="_blank" rel="noopener">#IMAX</a> <a title="♬ original sound - IMAX" href="https://www.tiktok.com/music/original-sound-7255327683477883690?refer=embed" target="_blank" rel="noopener">♬ original sound - IMAX</a></section>
</blockquote>
<p><br>
The m130 wasn't even <a href="https://www.wired.com/2002/03/new-palm-a-tough-sell-for-biz/">top of the line</a> when it came out in 2002. It did, however, bring color (12-bit, to be exact) to Palm's M-series of handhelds. It debuted at $279 with a 2-inch, 160×160 screen and a 33 Motorola Dragonball VZ processor. But that was just the magic needed for IMAX's purposes, and so it hasn't changed a thing. The only difference is that it's using emulations in at least some cases. According to <a href="https://www.theverge.com/23801118/imax-movie-palm-pilot-oppenheimer">The Verge</a>, the TikTok video shows the PDA emulated on a 10.1-inch Windows tablet for businesses, the Winmate W10IB3S-PCH2AC-POE Panel PC. It's easy to find Palm OS emulators <a href="https://cloudpilot-emu.github.io/">online</a>, as noted by <a href="https://www.vice.com/en/article/88x5gb/imax-still-runs-on-palmpilot-operating-system">Vice's Motherboard</a>.</p>                                            
                                                        
<p>The PDA emulation controls the theater's Quick Turn Reel Units (where workers <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">load the physical film reels</a>), which can also have integrated controllers instead.</p>
<p>Motherboard contacted IMAX about the antiquity and a company spokesperson said, "The original Quick Turn Reel Units operated on PalmPilots. In advance of the release of <em>Oppenheimer</em>, IMAX Engineering designed and manufactured an emulator that mimics the look and feel of a PalmPilot to keep it simple and familiar for IMAX film projectionists."</p>
<p>It's possible that some IMAX theaters still have physical PDAs. Ars Technica reached out to IMAX for clarification and will update this story if we hear back. As The Verge noted, a YouTuber named Yves Leibowitz, who shares video from an IMAX theater at an aquarium with 70 mm support, has physical Palm devices in his <a href="https://www.youtube.com/watch?v=_uFyp1WS1Fw">videos</a>.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215" alt="A closer look at the emulated PDA. "><img alt="A closer look at the emulated PDA. " src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled-640x534.jpg" width="640" height="534" srcset="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg 2x"></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/07/Untitled.jpg" data-height="1014" data-width="1215">Enlarge</a> <span>/</span> A closer look at the emulated PDA. </p></figcaption></figure>
<p>So what does the timeless emulator do? An IMAX rep told The Verge that it includes controls for the left and right sides of a 3D projector, which is "from the days of the 45-minute 3D documentaries, where there was a right eye print and a left eye print which both ran through the projector at the same time.” Workers can use the emulator to set which platter is ready for film or for feeding the projector film. The emulator can also tell a worker when the platters are available to run.</p>
<h2>If it ain't broke...</h2>
<p>Twenty-one-year-old emulated PDAs may not be what you'd expect to power one of the year's most publicized movie releases, but if you look at the converse speeds at which technology and business processes tend to evolve, it feels less surprising.</p>                                            
                                                        
<p>Earlier this year, we got a sneak peek at a Chuck E. Cheese that was <em>finally</em> moving its animatronics off <a href="https://arstechnica.com/information-technology/2023/01/chuck-e-cheese-still-uses-floppy-disks-in-2023-but-not-for-long/">floppy disks</a> and into the modern age of ... DVDs. The company's not alone in using dated technologies that mainstream consumers have largely forgotten. Businesses with long-standing procedures and systems often rely on technologies prominent when those systems were created. It's common for machines for things like medical equipment, aircraft, embroidery machines, and plastic molding to <a href="https://arstechnica.com/gadgets/2023/03/why-the-floppy-disk-just-wont-die/">rely on floppy disks</a>.</p>
<p>Similarly, IMAX is seemingly working with technology it's familiar with and, thus, doesn't require new or advanced training or big purchases and upgrades.</p>
<p>Meanwhile, 70 mm IMAX film releases like <em>Oppenheimer</em> don't come often, and when they do, only 30 theaters in the world can support them, <a href="https://www.cnbc.com/2023/07/19/where-to-watch-oppenheimer-in-70mm-imax-.html">CNBC</a> reported, and not necessarily all of them will (<em>Tenet's</em> 70 mm release, for example, was limited to 11 theaters due to pandemic restrictions, CNBC said). That makes any need for upgrades and overhauls less urgent.</p>
<p>“If 70mm IMAX had a resurgence then I’d expect that they’d update the [Quick Turn Reel Unit] controllers. Until then, it’s best to ride it until the wheels fall off,” an IMAX rep told The Verge.</p>
<p>For anyone still wondering what the big deal is about <a href="https://www.filmlinc.org/daily/what-is-70mm/">70 mm film</a> (besides the size), the movie's <a href="https://www.oppenheimermovie.com/tickets/formats/">website</a> says <em>Oppenheimer</em> was "shot using a combination of 5-perf 65 mm and 15 perf IMAX film." The site claims that "when presented on 70 mm IMAX, the sequences shot on 15 perf IMAX are printed full quality in their native format—the highest quality imaging format ever devised, offering 10 times the resolution of standard formats, and filling the giant IMAX screens from top to bottom."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MiniZinc (216 pts)]]></title>
            <link>https://www.minizinc.org/</link>
            <guid>36817628</guid>
            <pubDate>Fri, 21 Jul 2023 18:32:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.minizinc.org/">https://www.minizinc.org/</a>, See on <a href="https://news.ycombinator.com/item?id=36817628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p>
                    MiniZinc is a <a href="https://www.minizinc.org/license.html">free and open-source</a> <b>constraint modeling language</b>.  
                </p>
                <p>
                    You can use MiniZinc to model constraint satisfaction and optimization problems in a <b>high-level</b>,
                    <b>solver-independent</b> way, taking advantage of a large
                    <a href="https://www.minizinc.org/doc-latest/en/lib.html">library of pre-defined constraints</a>.
                    Your model is then compiled into FlatZinc, a solver input language that is understood by
                    <a href="https://www.minizinc.org/software.html#flatzinc">a wide range of solvers</a>.
                </p>
                
                <p>
                    MiniZinc is developed at <a href="http://www.monash.edu/">Monash University</a> with support from <a href="https://optima.org.au/">OPTIMA</a>.

                </p><h2>Getting started</h2>
                <p>  
                  To get started with MiniZinc, <a href="https://www.minizinc.org/software.html">download the MiniZinc distribution
                  and the IDE</a> and have a look at the <a href="https://www.minizinc.org/doc-latest/en/index.html">MiniZinc Handbook</a>,
                  which contains a tutorial introduction (also available in <a href="https://www.minizinc.org/doc-latest/chi/index.html">Chinese</a>).
                </p>

                <h2>Learn MiniZinc</h2>
                <p>We have developed an extensive online course!
                    Head over to Coursera's <a href="https://www.coursera.org/learn/basic-modeling">Basic Modeling for Discrete Optimization</a>
                    and <a href="https://www.coursera.org/learn/advanced-modeling">Advanced Modeling for Discrete Optimization</a>
                    courses for an in-depth introduction to constraint modeling using MiniZinc.
                </p>
                
                <p>The book <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace
                    introduces readers to the principles of intelligent decision support systems (IDSS) and how to build them with MiniZinc.</p>

                <h2>Merchandise</h2>
                <p>Get your <a href="https://www.redbubble.com/people/guidodiug/works/32129494-minizinc">MiniZinc stickers, mugs, t-shirts</a> etc. (sold at cost price)!</p>

                <h2>News</h2>

                <ul>
                <li><b>2023-06-20</b> MiniZinc 2.7.6 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.6">change log</a>).</li>
                <li><b>2023-06-07</b> MiniZinc 2.7.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.5">change log</a>).</li>
                <li><b>2023-05-11</b> MiniZinc 2.7.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.4">change log</a>).</li>
                <li><b>2023-04-20</b> MiniZinc 2.7.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.3">change log</a>).</li>    
                <li><b>2023-04-05</b> MiniZinc 2.7.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.2">change log</a>).</li>    
                <li><b>2023-03-31</b> MiniZinc 2.7.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.1">change log</a>).</li>    
                <li><b>2023-02-23</b> MiniZinc 2.7.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.7.0">change log</a>).</li>
                <li><b>2023-02-13</b> First <a href="https://www.minizinc.org/challenge2023/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2023.</li>
                <li><b>2022-08-04</b> The MiniZinc Challenge 2022 results available <a href="https://www.minizinc.org/challenge2022/results2022.html">here</a>. </li>
                <li><b>2022-06-23</b> MiniZinc 2.6.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.4">change log</a>).</li>
                <li><b>2022-05-06</b> MiniZinc 2.6.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.3">change log</a>).</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.2">change log</a>).</li>
                <li><b>2022-03-10</b> First <a href="https://www.minizinc.org/challenge2022/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2022.</li>
                <li><b>2022-03-03</b> MiniZinc 2.6.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.1">change log</a>).</li>
                <li><b>2022-02-22</b> MiniZinc 2.6.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.6.0">change log</a>).</li>
                <li><b>2021-10-29</b> The MiniZinc Challenge 2021 results available <a href="https://www.minizinc.org/challenge2021/results2021.html">here</a>. </li>
                <li><b>2021-05-07</b> First <a href="https://www.minizinc.org/challenge2021/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2021.</li>
                <li><b>2021-03-19</b> MiniZinc 2.5.5 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.5">change log</a>).</li>
                <li><b>2021-03-16</b> MiniZinc 2.5.4 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.4">change log</a>).</li>
                <li><b>2020-11-24</b> MiniZinc 2.5.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.3">change log</a>).</li>
                <li><b>2020-11-09</b> MiniZinc 2.5.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.2">change log</a>).</li>
                <li><b>2020-10-22</b> MiniZinc 2.5.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.1">change log</a>).</li>
                <li><b>2020-10-06</b> MiniZinc 2.5.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.5.0">change log</a>).</li>
                <li><b>2020-05-22</b> <a href="https://www.springer.com/gp/book/9783030417314"><i>Building Decision Support Systems using MiniZinc</i></a> by Mark Wallace is now available</li>
                <li><b>2020-03-04</b> MiniZinc 2.4.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.3">change log</a>).</li>
                <li><b>2020-01-10</b> MiniZinc 2.4.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.2">change log</a>).</li>
                <li><b>2019-12-20</b> MiniZinc 2.4.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.1">change log</a>).</li>
                <li><b>2019-12-13</b> MiniZinc 2.4.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.4.0">change log</a>).</li>
                <li><b>2019-10-03</b> The MiniZinc Challenge 2019 results available <a href="https://www.minizinc.org/challenge2019/results2019.html">here</a>. </li>
                <li><b>2019-09-12</b> MiniZinc 2.3.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.2">change log</a>).</li>
                <li><b>2019-07-10</b> MiniZinc 2.3.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.1">change log</a>).</li>
                <li><b>2019-06-26</b> MiniZinc 2.3.0 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.3.0">change log</a>).</li>
                <li><b>2019-03-07</b> First <a href="https://www.minizinc.org/challenge2019/call_for_problems.html">Call for MiniZinc problem submissions</a> has been made for the MiniZinc Challenge 2019.</li>
                <li><b>2018-10-31</b> MiniZinc 2.2.3 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.3">change log</a>).</li>
                <li><b>2018-10-26</b> MiniZinc 2.2.2 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.2">change log</a>).</li>
                <li><b>2018-09-20</b> Amendments of the MiniZinc Challenge 2018 results had to be made due to an issue with the solution checker. More details are available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. Thanks to Gustav Björdal and Michael Marte for reporting.</li>
                <li><b>2018-09-06</b> MiniZinc 2.2.1 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.1">change log</a>).</li>
                <li><b>2018-08-28</b> The MiniZinc Challenge 2018 results available <a href="https://www.minizinc.org/challenge2018/results2018.html">here</a>. </li>
                <li><b>2018-08-24</b> MiniZinc 2.2.0, a major release with many new features has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.2.0">change log</a>).</li>
                <li><b>2018-03-08</b> 11th edition of the <a href="https://www.minizinc.org/challenge2018/challenge.html">MiniZinc Challenge</a> has been announced.</li>
                <li><b>2018-01-10</b> MiniZinc 2.1.7 has been released (<a href="https://www.minizinc.org/doc-2.7.6/en/changelog.html#v2.1.7">change log</a>).</li>
                <li><a href="https://www.minizinc.org/oldnews.html">Older news items</a></li>
                </ul>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[For BSD Unix, It's Sayonara (1992) (117 pts)]]></title>
            <link>https://www.tech-insider.org/unix/research/1992/0622.html</link>
            <guid>36817482</guid>
            <pubDate>Fri, 21 Jul 2023 18:22:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tech-insider.org/unix/research/1992/0622.html">https://www.tech-insider.org/unix/research/1992/0622.html</a>, See on <a href="https://news.ycombinator.com/item?id=36817482">Hacker News</a></p>
<div id="readability-page-1" class="page">
<b>News</b><p><b>For BSD Unix, It's Sayonara </b></p>
<p>Jason Levitt and Evan Schuman<br>
Open Systems Today </p>
<p>June 22, 1992</p>
<p>Berkeley, Calif. -- The end of a major computing era will come next month 
when the final release of BSD Unix gets shipped, marking the University of 
California at Berkeley's withdrawal from the operating system business. </p>
<p>A lack of funding and the increasing sophistication of commercial Unix 
implementations have combined to halt Unix development at the university, 
meaning that 4.4BSD Unix-set to go Alpha by next month, with general 
availability by December-will be Berkeley's last OS. </p>
<p>BSD has been popular in the academic community for many reasons, mostly 
because-since 1988-it has not required a license fee and often features 
cutting-edge technology years before commercial computer vendors' versions. </p>
<p>"With any commercial version of Unix, you usually have to sign your life 
away," said Evi Nemeth, an associate professor of computer science at the 
University of Colorado at Boulder, adding that this no-license feature made BSD 
ideal for teaching students about operating systems and networking. </p>
<p>BSD Unix was responsible for much of the Unix innovation during the 1980s and 
came into being around 1978 when Berkeley graduate student Bill Joy added 
virtual memory capability to a VAX 11/780 port of Unix. The resulting system was 
named 3BSD (4BSD in 1980) and became the dominant Unix version at universities.
</p>
<p>Since that time, nearly all of the important Unix enhancements have come from 
the BSD releases of Unix. Collectively, these enhancements are often referred to 
as the Berkeley "extensions" and are now part of System V Release 4. The 
programming API for OSF/1 is based on 4.3BSD libraries and system calls. </p>
<p>Originally, BSD was funded by the government through DARPA. But that funding 
was cut off in 1988 when the vendor community started to show a strong interest 
in doing its own development. </p>
<p>Since 1988, BSD research and staffing has been supplied through vendor 
grants, mostly from Hewlett-Packard, the Open Software Foundation and Cray 
Research. </p>
<p>Kirk McKusick, the Berkeley research computer scientist who is in charge of 
the BSD project, added that NASA Ames also has been a major sponsor. </p>
<p>"It's becoming increasingly difficult to get funding from the private 
sector," he said. "With the recession, these companies are obviously looking at 
the bottom line and external research is an item that can be easily reduced."
</p>
<p>While fund raising has gotten more difficult, today's technology has forced 
the operating system to grow substantially more complicated, with the 100 
different commands from a few years ago now at 500 commands, McKusick said. </p>
<p>"The complexity has grown almost exponentially," he said, adding that his 
staff of four would need be doubled to "continue the level of quality." </p>
<p>Also, McKusick said, the university itself "is not as interested in having us 
around as they did 10 years ago" because vendors today-such as Cisco 
Systems-have packaged some of the networking technology that made his team so 
indispensable before for systems administration. </p>
<p>"We are so good at getting our stuff disseminated that we are no longer 
needed," he said. </p>
<p>Another factor contributing to the OS' demise, said Keith Bostic, fellow 
Berkeley programmer and the project's second-in-command, was the increasing 
sophistication of vendors in working with Unix. </p>
<p>In the early 1980s, Bostic said, just about the entire Unix community was 
either using a form of BSD or AT&amp;T's System V. "If you bought {Unix} from DEC, 
you were running BSD. If you bought {Unix} from Sun, you were running BSD," he 
said. "In today's climate, it is not the same as 1980." </p>
<p>Bostic said that today's Unix vendors are more sophisticated and are making 
many more changes to whatever version of Unix they are starting with. </p>
<p>BSD 4.3 "was the last version that major vendors shipped right out of the 
box. Vendors now tend to pick and choose," he said. "The vendors are basically 
going to lose a research group." </p>
<p>There are still options to secure BSD code, with one company, Berkeley 
Software Design (Falls Church, Va.), a company employing former Berkeley 
programmer Mike Karels, planning to offer a commercial version of Unix for SPARC 
systems based on the 4.4BSD code but free of AT&amp;T source licensing requirements. 
It currently offers BSD/386, a version of Unix for 386 machines based on the 
Berkeley NET2 release. </p>
<p>And there are several outfits that will distribute the code freely, often 
directly on the net. </p>
<p>The University of Colorado's Nemeth, regarded as an expert on Unix security 
and perhaps best known for having co-authored the Unix System Administration 
Handbook, said last week that she would like to have her university conduct some 
of the operating system research that Berkeley is now abandoning. </p>
<p>One of the most popular accomplishments of the BSD team, said Nemeth and 
others, was its sifting through mountains of software out in the industry, 
finding the best examples and incorporating them into a BSD version. McKusick 
said it was often a matter of convincing contributors "that they would rather 
have fame than fortune." </p>
<p>Nemeth cited a more colorful-and oft-cited-description: "It was a matter of 
their taking it in and peeing on it until it smelled like Berkeley." </p>
<p>"This is a valuable function and the community needs the service," she said, 
adding that she is trying to convince DARPA to resume funding BSD research at 
her university with it paying for three to four full-time staff, two or three 
graduate students and two or three undergraduate students. Nemeth estimated that 
she would need about $700,000. </p>
<p>But she said last week that she now is leaning toward securing interim 
funding from industry, in an attempt to demonstrate to DARPA that her people can 
do the job effectively. </p>
<p>Nemeth said that she is hesitant, though, to have vendor support made 
permanent. "I don't see having to constantly hustle for money."</p>

<p>Copyright 1992 CMP Publications, Inc. All rights reserved.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web Environment Integrity API (406 pts)]]></title>
            <link>https://github.com/RupertBenWiser/Web-Environment-Integrity</link>
            <guid>36817305</guid>
            <pubDate>Fri, 21 Jul 2023 18:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity">https://github.com/RupertBenWiser/Web-Environment-Integrity</a>, See on <a href="https://news.ycombinator.com/item?id=36817305">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content">Skip to content</a>
      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  

  <div>
    <div>
      <a href="https://github.com/" aria-label="Homepage" data-ga-click="(Logged out) Header, go to homepage, icon:logo-wordmark">
        
      </a>

        <div>
          <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d70e84e9f9dca6c4052317ffe225baad48a9b2d4823c9c6c4d304f38494e8473">
            Sign&nbsp;up
          </a>
        </p></div>

      
    </div>


    <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Copilot&quot;,&quot;label&quot;:&quot;ref_cta:Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="product-explore-heading">Explore</span></p><ul aria-labelledby="product-explore-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to All features&quot;,&quot;label&quot;:&quot;ref_cta:All features;&quot;}" href="https://github.com/features">
      All features

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Documentation&quot;,&quot;label&quot;:&quot;ref_cta:Documentation;&quot;}" href="https://docs.github.com/">
      Documentation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Skills&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Skills;&quot;}" href="https://skills.github.com/">
      GitHub Skills

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Blog&quot;,&quot;label&quot;:&quot;ref_cta:Blog;&quot;}" href="https://github.blog/">
      Blog

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
              <p><span id="solutions-for-heading">For</span></p><ul aria-labelledby="solutions-for-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Enterprise&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise;&quot;}" href="https://github.com/enterprise">
      Enterprise

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Teams&quot;,&quot;label&quot;:&quot;ref_cta:Teams;&quot;}" href="https://github.com/team">
      Teams

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Startups&quot;,&quot;label&quot;:&quot;ref_cta:Startups;&quot;}" href="https://github.com/enterprise/startups">
      Startups

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Education&quot;,&quot;label&quot;:&quot;ref_cta:Education;&quot;}" href="https://education.github.com/">
      Education

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-by-solution-heading">By Solution</span></p><ul aria-labelledby="solutions-by-solution-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to CI/CD &amp;amp; Automation&quot;,&quot;label&quot;:&quot;ref_cta:CI/CD &amp;amp; Automation;&quot;}" href="https://github.com/solutions/ci-cd/">
      CI/CD &amp; Automation

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevOps&quot;,&quot;label&quot;:&quot;ref_cta:DevOps;&quot;}" href="https://resources.github.com/devops/">
      DevOps

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to DevSecOps&quot;,&quot;label&quot;:&quot;ref_cta:DevSecOps;&quot;}" href="https://resources.github.com/devops/fundamentals/devsecops/">
      DevSecOps

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="solutions-resources-heading">Resources</span></p><ul aria-labelledby="solutions-resources-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Customer Stories&quot;,&quot;label&quot;:&quot;ref_cta:Customer Stories;&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to White papers, Ebooks, Webinars&quot;,&quot;label&quot;:&quot;ref_cta:White papers, Ebooks, Webinars;&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Solutions&quot;,&quot;action&quot;:&quot;click to go to Partners&quot;,&quot;label&quot;:&quot;ref_cta:Partners;&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
              <p><span id="open-source-repositories-heading">Repositories</span></p><ul aria-labelledby="open-source-repositories-heading">
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Topics&quot;,&quot;label&quot;:&quot;ref_cta:Topics;&quot;}" href="https://github.com/topics">
      Topics

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Trending&quot;,&quot;label&quot;:&quot;ref_cta:Trending;&quot;}" href="https://github.com/trending">
      Trending

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to Collections&quot;,&quot;label&quot;:&quot;ref_cta:Collections;&quot;}" href="https://github.com/collections">
      Collections

    
</a></li>

            </ul>
          </div>
      </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:RupertBenWiser/Web-Environment-Integrity" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="TOFqL3IsSOkP2RP7Whs-FRbAKNymOsfTq1lEcorjNQ_UqiuwYjvFpkj7Mf5KZWKttIePXlBbsmxJzfzA_D6Amg" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="RupertBenWiser/Web-Environment-Integrity" data-current-org="" data-current-owner="RupertBenWiser" data-logged-in="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="feedback-dialog" aria-modal="true" aria-disabled="true" aria-describedby="feedback-dialog-title feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
    </p>
    
  </div>
      <div data-view-component="true">        <!-- '"` --><!-- </textarea></xmp> --><form id="code-search-feedback-form" data-turbo="false" action="/search/feedback" accept-charset="UTF-8" method="post">
          <p>We read every piece of feedback, and take your input very seriously.</p>
          
          
          <label for="include_email">Include my email address so I can be contacted</label>
</form></div>
      
</modal-dialog></div>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<div data-modal-dialog-overlay="">
  <modal-dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" role="dialog" id="custom-scopes-dialog" aria-modal="true" aria-disabled="true" aria-describedby="custom-scopes-dialog-title custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      
      
</modal-dialog></div>
    </custom-scopes>
  </div>
</qbsearch-input><div>
            <p><a href="https://github.com/login?return_to=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-ga-click="(Logged out) Header, clicked Sign in, text:sign-in">
              Sign in
            </a>
          </p></div>

            <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=RupertBenWiser%2FWeb-Environment-Integrity" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="01e3ed5febbe8bc7ce93175543274d99ddddc9287a0c31d4bea8d40f578b6b71" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
              Sign up
            </a>
        </p></div>
      </div>
  </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  




    






  
  <div id="repository-container-header" data-turbo-replace="">

      <div>

        <div>
      
    
    <p><span itemprop="author">
      <a rel="author" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        RupertBenWiser
</a>    </span>
    <span>/</span>
    <strong itemprop="name">
      <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity">Web-Environment-Integrity</a>
    </strong>

    <span></span><span>Public</span>
  </p></div>

        <div id="repository-details-container" data-turbo-replace="">
            <ul>
    
      

  <li>
            <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
  </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="5aa5809df7db030699b13deecdd19445904a135559f2af25249dddf6be869a54" data-view-component="true">    Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="21" data-view-component="true">21</span>
</a>
  </li>

  <li>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>          <span id="repo-stars-counter-star" aria-label="64 users starred this repository" data-singular-suffix="user starred this repository" data-plural-suffix="users starred this repository" data-turbo-replace="true" title="64" data-view-component="true">64</span>
</a>        </div>
  </li>


    

</ul>

        </div>
      </div>

        <div id="responsive-meta-container" data-turbo-replace="">

    

    <p>
        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers">
          
          <span>64</span>
          stars
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks">
          
          <span>21</span>
          forks
</a>        <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity">
          
          <span>Activity</span>
</a>    </p>

      <div>
        <div data-view-component="true">
        <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;star button&quot;,&quot;repository_id&quot;:632520759,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="63d22802c5b163a4f30d19ed6eef47b4d81941c9749061a904d7b89bc133e5db" aria-label="You must be signed in to star a repository" data-view-component="true">    <span data-view-component="true">
          Star
</span>
</a>        </div>
        <p>
                <a href="https://github.com/login?return_to=%2FRupertBenWiser%2FWeb-Environment-Integrity" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="293d9a82a60f90833694d5820eee59ef0df39d68f49e83d7e5b15d78ce605170" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>
        </p>
      </div>
  </div>


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true">

  <ul data-view-component="true">
      <li data-view-component="true">
  <a id="code-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity" data-tab-item="i0code-tab" data-selected-links="repo_source repo_downloads repo_commits repo_releases repo_tags repo_branches repo_packages repo_deployments /RupertBenWiser/Web-Environment-Integrity" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g c" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Code&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" aria-current="page" data-view-component="true">
    
              
        <span data-content="Code">Code</span>
          <span id="code-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="issues-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/issues" data-tab-item="i1issues-tab" data-selected-links="repo_issues repo_labels repo_milestones /RupertBenWiser/Web-Environment-Integrity/issues" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g i" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Issues&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Issues">Issues</span>
          <span id="issues-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="51" data-view-component="true">51</span>


    
</a></li>
      <li data-view-component="true">
  <a id="pull-requests-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulls" data-tab-item="i2pull-requests-tab" data-selected-links="repo_pulls checks /RupertBenWiser/Web-Environment-Integrity/pulls" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g p" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Pull requests&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Pull requests">Pull requests</span>
          <span id="pull-requests-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="2" data-view-component="true">2</span>


    
</a></li>
      <li data-view-component="true">
  <a id="actions-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/actions" data-tab-item="i3actions-tab" data-selected-links="repo_actions /RupertBenWiser/Web-Environment-Integrity/actions" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g a" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Actions&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Actions">Actions</span>
          <span id="actions-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
      <li data-view-component="true">
  <a id="projects-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/projects" data-tab-item="i4projects-tab" data-selected-links="repo_projects new_repo_project repo_project /RupertBenWiser/Web-Environment-Integrity/projects" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g b" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Projects&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Projects">Projects</span>
          


    
</a></li>
      <li data-view-component="true">
  <a id="security-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/security" data-tab-item="i5security-tab" data-selected-links="security overview alerts policy token_scanning code_scanning /RupertBenWiser/Web-Environment-Integrity/security" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-hotkey="g s" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Security&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Security">Security</span>
          <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/security/overall-count" accept="text/fragment+html"></include-fragment>

    
</a></li>
      <li data-view-component="true">
  <a id="insights-tab" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/pulse" data-tab-item="i6insights-tab" data-selected-links="repo_graphs repo_contributors dependency_graph dependabot_updates pulse people community /RupertBenWiser/Web-Environment-Integrity/pulse" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-analytics-event="{&quot;category&quot;:&quot;Underline navbar&quot;,&quot;action&quot;:&quot;Click tab&quot;,&quot;label&quot;:&quot;Insights&quot;,&quot;target&quot;:&quot;UNDERLINE_NAV.TAB&quot;}" data-view-component="true">
    
              
        <span data-content="Insights">Insights</span>
          <span id="insights-repo-tab-count" data-pjax-replace="" data-turbo-replace="" title="Not available" data-view-component="true"></span>


    
</a></li>
</ul>
    <div data-view-component="true">        <details data-view-component="true">
    <summary role="button" data-view-component="true">          <div>
            
            <p><span>More</span>
          </p></div>
</summary>
    <details-menu role="menu" data-view-component="true">          <ul>
              
              
              
              
              
              
              
          </ul>
</details-menu>
</details></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container">
  


  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/spoofed_commit_check/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-test-selector="spoofed-commit-check"></include-fragment>

  <div data-view-component="true">
  <div data-view-component="true">        
        
        <div>
  
<div>
  <details id="branch-select-menu" data-hydro-click-payload="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;target&quot;:&quot;REFS_SELECTOR_MENU&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="44d089c48373dc35e4e44d462abd09000039cc8c32fc11bab9faf0bfe1d7ba67">
    <summary data-hotkey="w" title="Switch branches or tags">
      
      <span data-menu-button="">main</span>
      <span></span>
    </summary>

    
<div>
    <header>
      <span>Switch branches/tags</span>
      
    </header>

    <input-demux data-action="tab-container-change:input-demux#storeInput tab-container-changed:input-demux#updateInput">
      <tab-container>
        

        

        <div role="tabpanel" id="ref-list-branches" data-filter-placeholder="Filter branches/tags" tabindex="">
          <ref-selector type="branch" data-targets="input-demux.sinks" data-action="
              input-entered:ref-selector#inputEntered
              tab-selected:ref-selector#tabSelected
              focus-list:ref-selector#focusFirstListMember
            " query-endpoint="/RupertBenWiser/Web-Environment-Integrity/refs" cache-key="v0:1689925634.0" current-committish="bWFpbg==" default-branch="bWFpbg==" name-with-owner="UnVwZXJ0QmVuV2lzZXIvV2ViLUVudmlyb25tZW50LUludGVncml0eQ==" prefetch-on-mouseover="">

            <template data-target="ref-selector.fetchFailedTemplate">
              <div class="SelectMenu-message" data-index="{{ index }}">Could not load branches</div>
            </template>

              <template data-target="ref-selector.noMatchTemplate">
    <div class="SelectMenu-message">Nothing to show</div>
</template>


            

              

<template data-target="ref-selector.itemTemplate">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/{{ urlEncodedRefName }}" class="SelectMenu-item" role="menuitemradio" rel="nofollow" aria-checked="{{ isCurrent }}" data-index="{{ index }}">
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check SelectMenu-icon SelectMenu-icon--check">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    <span class="flex-1 css-truncate css-truncate-overflow {{ isFilteringClass }}">{{ refName }}</span>
    <span hidden="{{ isNotDefault }}" class="Label Label--secondary flex-self-start">default</span>
  </a>
</template>


              
          </ref-selector>

        </div>

        
      </tab-container>
    </input-demux>
  </div>

  </details>

</div>


<div data-modal-dialog-overlay="">
  <modal-dialog role="dialog" id="warn-tag-match-create-branch-dialog" aria-modal="true" aria-labelledby="warn-tag-match-create-branch-dialog-header" data-view-component="true">
      <header>
        <div>
          <p>
            <h2 id="warn-tag-match-create-branch-dialog-header">Name already in use</h2>
          </p>
          
        </div>
      </header>
    <div>
      
          <p>      A tag already exists with the provided branch name. Many Git commands accept both tag and branch names, so creating this branch may cause unexpected behavior. Are you sure you want to create this branch?
</p>

    </div>
      
</modal-dialog></div>



  <p>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/branches">
          
          <strong>2</strong>
          <span>branches</span>
    </a>
    <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tags">
      
        <strong>0</strong>
        <span>tags</span>
    </a>
  </p>

  

  <include-fragment src="/RupertBenWiser/Web-Environment-Integrity/overview_actions/main"></include-fragment>


    <p><span>
        
<get-repo>
    
    <details data-action="
               toggle:get-repo#onDetailsToggle
               keydown:get-repo#onDetailsKeydown">
        <summary data-hydro-click="{&quot;event_type&quot;:&quot;repository.click&quot;,&quot;payload&quot;:{&quot;repository_id&quot;:632520759,&quot;target&quot;:&quot;CLONE_OR_DOWNLOAD_BUTTON&quot;,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="2a850bb66106159d97ab9bd5e4e79b14c52c6a46a2f26d039aa174ad06cbde5f" data-view-component="true">    <span>
      <span>Code</span>
    </span>
      <span>
        
      </span>
</summary>  
      <div data-target="get-repo.modal">
    <tab-container data-view-component="true">
  <div with_panel="true" data-view-component="true">
    
    <ul role="tablist" aria-label="Choose where to access your code" data-view-component="true">
        <li role="presentation" data-view-component="true">
  </li>
        <li role="presentation" data-view-component="true">
  </li>
</ul>    
</div>    <div id="local-panel" role="tabpanel" tabindex="0" aria-labelledby="local-tab" data-view-component="true">          <ul>
              <li>
  <a href="https://docs.github.com/articles/which-remote-url-should-i-use" target="_blank" aria-label="Which remote URL should I use?">
  
</a>

<div>
  <p>
  Clone
</p></div>

<tab-container>

  

  <div role="tabpanel">
    

    <p>
        Use Git or checkout with SVN using the web URL.
    </p>
  </div>


  
</tab-container>

</li>
<li data-platforms="windows,mac">
  <a data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;OPEN_IN_DESKTOP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="0e082088e719e3706dceff570cd728dcc71018e70b8c36e4cd0ce22013aec0f8" data-action="click:get-repo#showDownloadMessage" href="https://desktop.github.com/">
    
    Open with GitHub Desktop
</a></li>
<li>
  <a rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;clone_or_download.click&quot;,&quot;payload&quot;:{&quot;feature_clicked&quot;:&quot;DOWNLOAD_ZIP&quot;,&quot;git_repository_type&quot;:&quot;REPOSITORY&quot;,&quot;repository_id&quot;:632520759,&quot;originating_url&quot;:&quot;https://github.com/RupertBenWiser/Web-Environment-Integrity&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="3228739be0257e0437c387b54e0f4d4c40aeacbd38fbcf1c77cc602cca3390f7" data-ga-click="Repository, download zip, location:repo overview" data-open-app="link" data-turbo="false" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/archive/refs/heads/main.zip">
    
    Download ZIP
</a></li>

          </ul>
</div>
    
</tab-container></div>
    </details>


</get-repo>

    </span>

    <span>
        

    </span>
</p></div>




        


<div>
  <div>
    <h2>Latest commit</h2>
    <div data-issue-and-pr-hovercards-enabled="">
      
  <div>
  <p><a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/yoavweiss">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/786187?s=48&amp;v=4" width="24" height="24" alt="@yoavweiss">
</a>      <a data-test-selector="commits-avatar-stack-avatar-link" data-hovercard-type="user" data-hovercard-url="/users/RupertBenWiser/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/RupertBenWiser">
        <img data-test-selector="commits-avatar-stack-avatar-image" src="https://avatars.githubusercontent.com/u/26461279?s=48&amp;v=4" width="24" height="24" alt="@RupertBenWiser">
</a>  </p>
</div>
  <div>
    <div>
          <p><a title="View all commits by yoavweiss" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=yoavweiss">yoavweiss</a>
    
   and
  <a title="View all commits by RupertBenWiser" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits?author=RupertBenWiser">RupertBenWiser</a>
  

        <span>
          <a data-pjax="true" data-test-selector="commit-tease-commit-message" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
        </span>
    </p></div>
    <div>
        <include-fragment accept="text/fragment+html" src="/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4/rollup?direction=sw"></include-fragment>
      <p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        7998217
      </a></p><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4" data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
        <relative-time datetime="2023-07-21T07:46:43Z">Jul 21, 2023</relative-time>
      </a>
    </div>
  </div>
  <div>
      <div>
        <p><a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" data-test-selector="commit-tease-commit-message" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
      </p></div>
    <p><code>7998217</code>
    </p>
  </div>
      <div>
        <h2>Git stats</h2>
        <ul>
          <li>
            <a data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commits/main">
              
              <span>
                    <strong>22</strong>
                    <span aria-label="Commits on main">
                      commits
                    </span>
              </span>
            </a>
          </li>
        </ul>
      </div>
    </div>
  </div>
    <h2 id="files">Files</h2>
    


    <p><a data-hotkey="y" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Permalink</a></p><div data-view-component="true">
  <p>
    Failed to load latest commit information.


  
</p></div>  <div role="grid" aria-labelledby="files" data-hpc="">
      <div role="row">
        <p>Type</p>
        <p>Name</p>
        <p>Latest commit message</p>
        <p>Commit time</p>
      </div>

        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="This path skips through empty directories" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/.github/workflows"><span>.github/</span>workflows</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add github workflow to publish to gh-pages branch

This should auto process the bikeshed on push to main and publish
to the gh-pages branch.

Also updating the WebIDL to pass validation." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f8448c38fd41470d828ad1b1ec691a2b424f1118">Add github workflow to publish to gh-pages branch</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T14:19:28Z" data-view-component="true">June 20, 2023 14:19</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="docs" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/tree/main/docs">docs</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add hash type and DOMException" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/f6bf35350c59e856deafdac65569b71a3413155b">Add hash type and DOMException</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-17T10:55:18Z" data-view-component="true">July 17, 2023 10:55</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title=".gitignore" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/.gitignore">.gitignore</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Add gitignore

Ignoring local spec files generated in the docs directory." href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/1866c954426f2529f008362b6b7686cbff605388">Add gitignore</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-20T15:20:21Z" data-view-component="true">June 20, 2023 15:20</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="CODE_OF_CONDUCT.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md">CODE_OF_CONDUCT.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Create CODE_OF_CONDUCT.md" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4">Create CODE_OF_CONDUCT.md</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-07-21T09:46:43+02:00" data-view-component="true">July 21, 2023 09:46</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="README.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/README.md">README.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="Update spec link to be github page instead" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/b8a049e76e04de712993a821a7482a85e281adbc">Update spec link to be github page instead</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-06-21T10:00:27Z" data-view-component="true">June 21, 2023 10:00</relative-time>
          </p>

        </div>
        <div role="row">
          

          <div role="rowheader">
            <p><span><a title="explainer.md" data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer.md</a></span>
          </p></div>

          <div role="gridcell">
              <p><span>
                    <a data-pjax="true" title="use eTLD+1, not TLD" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/commit/c7366e82ecdba4c49aef945175ef90e8c9d6b47d">use eTLD+1, not TLD</a>
              </span>
          </p></div>

          <p role="gridcell">
              <relative-time tense="past" datetime="2023-04-27T10:01:28+01:00" data-view-component="true">April 27, 2023 10:01</relative-time>
          </p>

        </div>
    </div>




</div>

  
    
      <div id="readme" data-tagsearch-path="README.md" data-tagsearch-lang="Markdown">

        <div>
          <p>
            <h2>
              <a href="#readme" data-view-component="true">README.md</a>
            </h2>
          </p>
        </div>

          <div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Web Environment Integrity API</h2>
<p dir="auto">This repository details the proposal to add a new API for determining the integrity
of web environments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const attestation = await navigator.getEnvironmentIntegrity(&quot;...&quot;);"><pre><span>const</span> <span>attestation</span> <span>=</span> <span>await</span> <span>navigator</span><span>.</span><span>getEnvironmentIntegrity</span><span>(</span><span>"..."</span><span>)</span><span>;</span></pre></div>
<p dir="auto">The <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md">explainer</a> goes gives a high level overview of the proposal.</p>
<p dir="auto">The <a href="https://rupertbenwiser.github.io/Web-Environment-Integrity/" rel="nofollow">spec</a> currently describes how this is being prototyped in Chromium.</p>
</article>
          </div>
      </div>



</div>
  <div data-pjax="" data-view-component="true">
        <div>
            <h2>About</h2>

    <p>
      No description, website, or topics provided.
    </p>


    <h3>Resources</h3>
    <p>
      <a data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:readme&quot;}" href="#readme">
        
        Readme
</a>    </p>

  

    <h3>Code of conduct</h3>
    <p>
      <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/CODE_OF_CONDUCT.md" data-analytics-event="{&quot;category&quot;:&quot;Repository Overview&quot;,&quot;action&quot;:&quot;click&quot;,&quot;label&quot;:&quot;location:sidebar;file:code of conduct&quot;}">
        
        Code of conduct
      </a>
    </p>


<include-fragment src="/RupertBenWiser/Web-Environment-Integrity/hovercards/citation/sidebar_partial?tree_name=main">
</include-fragment>



<p>
  <a data-turbo-frame="repo-content-turbo-frame" href="https://github.com/RupertBenWiser/Web-Environment-Integrity/activity" data-view-component="true">
    
    <span>Activity</span>
</a></p>

<h3>Stars</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/stargazers" data-view-component="true">
    
    <strong>64</strong>
    stars
</a></p>

<h3>Watchers</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/watchers" data-view-component="true">
    
    <strong>20</strong>
    watching
</a></p>

<h3>Forks</h3>
<p>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/forks" data-view-component="true">
    
    <strong>21</strong>
    forks
</a></p>

  <div>
    <p><a href="https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FRupertBenWiser%2FWeb-Environment-Integrity&amp;report=RupertBenWiser+%28user%29">
        Report repository
</a>  </p></div>

          </div>

        
        
            <div>
                <h2 data-pjax="#repo-content-pjax-container" data-turbo-frame="repo-content-turbo-frame">
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/releases" data-view-component="true">
    Releases
</a></h2>

    <p>No releases published</p>

              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/users/RupertBenWiser/packages?repo_name=Web-Environment-Integrity" data-view-component="true">
    Packages
      
</a></h2>


      <p>
        No packages published <br>
      </p>



              </div>

        
        
            <div>
                <h2>
  <a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/graphs/contributors" data-view-component="true">
    Contributors
      <span title="3" data-view-component="true">3</span>
</a></h2>


    
  <ul>
    <li>
      <a href="https://github.com/apps/github-actions">
        <img src="https://avatars.githubusercontent.com/in/15368?s=64&amp;v=4" alt="@github-actions[bot]" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/apps/github-actions">
          <strong>github-actions[bot]</strong>
          
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/yoavweiss" data-hovercard-type="user" data-hovercard-url="/users/yoavweiss/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/786187?s=64&amp;v=4" alt="@yoavweiss" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/yoavweiss">
          <strong>yoavweiss</strong>
          <span>Yoav Weiss</span>
        </a>
</span>    </li>
    <li>
      <a href="https://github.com/bakkot" data-hovercard-type="user" data-hovercard-url="/users/bakkot/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self">
        <img src="https://avatars.githubusercontent.com/u/1653598?s=64&amp;v=4" alt="@bakkot" size="32" height="32" width="32" data-view-component="true">
      </a>
      <span data-view-component="true">
        <a href="https://github.com/bakkot">
          <strong>bakkot</strong>
          <span>Kevin Gibbons</span>
        </a>
</span>    </li>
</ul>





              </div>

        
        
              </div>
  
</div></div>

</turbo-frame>


    </main>
  </div>

          




  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0 tooltipped-no-delay" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 tooltipped-no-delay d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What are the best papers you read in your life? (179 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=36817231</link>
            <guid>36817231</guid>
            <pubDate>Fri, 21 Jul 2023 18:04:01 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=36817231">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="36818754"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818754" href="https://news.ycombinator.com/vote?id=36818754&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Claude Shannon's "A Mathematical Theory of Communication"[1] is often considered a classic. I think this is because:<p>1. It's quite readable as a narrative.</p><p>2. The maths is not pages of first principle derivations as if the reader is not familiar with the basics of algebraic substitution.</p><p>3. The diagrams and graphs are genuinely useful and remove the need for many, many thousands of words that others may have used instead of, or in addition to, the core narrative.</p><p>4. It deals with an abstract concept but roots it in concrete mathematical and physical terms. He touches on specific examples.</p><p>5. It's quite short given the breadth of subject area.</p><p>[1] <a href="https://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf" rel="nofollow noreferrer">https://people.math.harvard.edu/~ctm/home/text/others/shanno...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36819339"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819339" href="https://news.ycombinator.com/vote?id=36819339&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>His easily-understandable yet mind-blowing ideas of hyperspheres of information (and a reliable communications channel having a definition!? What?) changed my brain permanently.<p>This is the paper I was going to cite as well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819215"><td></td></tr>
            <tr id="36818482"><td></td></tr>
            <tr id="36818350"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818350" href="https://news.ycombinator.com/vote?id=36818350&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>If you are looking for quality I suggest you look at the IPCC reports. Each word is carefully chosen, every claim backed by mountains of evidence. They're written to be read and understood by non-experts. They exist to inform decision making that will literally determine the fate of our species. As such, they may be failing at their goal, but not for a lack of effort by the authors.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818777"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818777" href="https://news.ycombinator.com/vote?id=36818777&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, with one caveat. Over time governments have more and more been trying to influence the reports. It all came to a head with the last one, where a set of researchers released their draft ahead of time in protest over undue influence. They still synthesize relevant research from past years, but there are some problems now. Research published after the first draft cannot be included, so the report is somewhat outdated by the time it's released. Beautifully crafted though.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818726"><td></td></tr>
                  <tr id="36821453"><td></td></tr>
            <tr id="36818660"><td></td></tr>
            <tr id="36819037"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819037" href="https://news.ycombinator.com/vote?id=36819037&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Gillian Russell, “Epistemic Viciousness in the Martial Arts,”<p>It is about traditional martial arts masters, trapped in their echo chamber, sniffing their own farts. The whole industry gets its ass kicked by mixed martial arts. Basically street thugs versus shaolin kung fu masters.</p><p>it describes in-group bias, echo chambers, and cognitive dissonance in large groups. Very applicable in modern science, politics and so on.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36817581"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36817581" href="https://news.ycombinator.com/vote?id=36817581&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper. It started my curiosity in the computer security industry (employed for 5 years now) and the rabbithole of trying to understand every design decision behind the cryptosystem.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818276"><td></td></tr>
            <tr id="36818960"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818960" href="https://news.ycombinator.com/vote?id=36818960&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Agreed, this is a must-read, very well-written paper. Even though it turned out the world didn't really need cryptocurrencies.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820340"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_36820340" href="https://news.ycombinator.com/vote?id=36820340&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Agree with your assessment of cryptocurrencies in general but having seen the adoption of Bitcoin in authoritarian and inflationary regimes, the world most certainly does need access to a digital peer-to-peer currency that is censorship-resistant and virtually immune to debasement.<p>Even if you argue that Bitcoin as it has evolved has flaws, it is the best implementation we’ve come up with so far. Like democracy, it isn’t perfect but it is much better for its use case than anything else we have come up with to date.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36820043"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820043" href="https://news.ycombinator.com/vote?id=36820043&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>The Bitcoin whitepaper is one of my cherished reads. The other is the BitTorrent whitepaper. Both technologies changed the technical and non-technical worlds, and the fundamental protocols are clearly explained in their respective papers.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818851"><td></td></tr>
            <tr id="36818368"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818368" href="https://news.ycombinator.com/vote?id=36818368&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Not sure anybody here appreciates social science, but I will never not give a shout-out to "Decoupling Rape" by Whiteman and Cooper. Such an authentic account, while still managing to stay relevant to abstract and higher-order debates in my field. I suspect many have not read it because it is so heart-wrenching though.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36818521"><td></td></tr>
                <tr id="36818709"><td></td></tr>
                        <tr id="36818604"><td></td></tr>
            <tr id="36821359"><td></td></tr>
            <tr id="36818397"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818397" href="https://news.ycombinator.com/vote?id=36818397&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Like Kleobis and Biton, we won't know until I am dead.<p>However thus far, a paper that literally changed my life: "Value Dependence Graphs: Representation Without Taxation", D. Weise, R. F. Crew, M. Ernst, B. Steensgaard, POPL 1994.  (This was the proverbial butterfly flap that moved me through three countries).</p><p>There are many many other good papers and it's not a one-dimension metric so it's hard to pick out winners.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819045"><td></td></tr>
                <tr id="36819896"><td></td></tr>
                  <tr id="36820899"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820899" href="https://news.ycombinator.com/vote?id=36820899&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Probably this paper [1] is very well known among the classic HN audience, but I dare to leave this link here for the ones who missed it. It is an easy read and it just explains with plain words the backbone of the UNIX system as it was envisioned 50 years ago.<p>[1] <a href="https://dsf.berkeley.edu/cs262/unix.pdf" rel="nofollow noreferrer">https://dsf.berkeley.edu/cs262/unix.pdf</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819051"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819051" href="https://news.ycombinator.com/vote?id=36819051&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"A Security Kernel Based on the Lambda-Calculus" by Jonathan A. Rees is pretty high up there: <a href="https://dspace.mit.edu/handle/1721.1/5944" rel="nofollow noreferrer">https://dspace.mit.edu/handle/1721.1/5944</a><p>I read this a few years back as I was going down an object-capability rabbit hole and found it extremely compelling. (And also made me disappointed that most of the systems we use today do not work like this! Code execution vulnerabilities would be so much less immediately hazardous if they did.)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818522"><td></td></tr>
            <tr id="36819113"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819113" href="https://news.ycombinator.com/vote?id=36819113&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>This is probably among the best I have read: <a href="https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;context=dissertation" rel="nofollow noreferrer">https://scholars.unh.edu/cgi/viewcontent.cgi?article=1462&amp;co...</a><p>In a system with growing inequality where the rich benefit at the expense of the poor, this artificial redistribution can go on for some time, but once the inequality gets so bad that people revolt, then the amount of "guard labor" that needs to be performed goes up. Poverty and desperation makes people more likely to perform "guard labor" because it gives them a chance to escape poverty and avoid being targeted themselves which further feeds into authoritarian politicians gaining more power as they have no trouble finding soldiers willing to maintain the inequality. This works but only until guard labor reaches such a critical mass that half the population engages in it. Once that point is crossed, guard labor will start defecting against the current political leadership and conduct a military coup.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36818472"><td></td></tr>
            <tr id="36819993"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819993" href="https://news.ycombinator.com/vote?id=36819993&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Congestion Avoidance and Control (1988) by Van Jacobson: <a href="https://ee.lbl.gov/papers/congavoid.pdf" rel="nofollow noreferrer">https://ee.lbl.gov/papers/congavoid.pdf</a><p>Often called "the paper which saved the internet" due to solving congestion collapse on the ARPANET, and inventing the fundamentals of TCP Congestion Control still used countless times every single day on all computers everywhere. It's very readable and presents complex math in easily understood graphs for non-math people.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36820767"><td></td></tr>
            <tr id="36818724"><td></td></tr>
            <tr id="36818995"><td></td></tr>
                <tr id="36820616"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36820616" href="https://news.ycombinator.com/vote?id=36820616&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>I remember seeing “Possible Girls” cited somewhere as an example of the pointlessness of contemporary academic philosophy, but for years I couldn't find it again. A very entertaining re-read, thanks for sharing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819937"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819937" href="https://news.ycombinator.com/vote?id=36819937&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>A quantitative description of membrane current and its application to conduction and excitation in nerve
A L HODGKIN, A F HUXLEY
J Physiol. 1952 Aug;117(4):500-44.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36818376"><td></td></tr>
                <tr id="36818908"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36818908" href="https://news.ycombinator.com/vote?id=36818908&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Didn't think I'd come across a DTW paper here.<p>Have you seen anything worth reading in that line of literature which addresses a more practical issue of segment sizing and segment overlap on accuracy?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819023"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819023" href="https://news.ycombinator.com/vote?id=36819023&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>“What is it like to be a bat” (Nagel)<p>“The Spandrels of San Marco and the Panglossian Paradigm”, (Gould et al)</p><p>“ A quantitative description of membrane current and its application to conduction and excitation in nerve” (hodgkin and huxley)</p><p>a few other that don’t come to mind right now
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819126"><td></td></tr>
            <tr id="36818311"><td></td></tr>
            <tr id="36819093"><td></td></tr>
                <tr id="36821415"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36821415" href="https://news.ycombinator.com/vote?id=36821415&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>There's a lot of non-Chomskian linguistics out there. Basically if you look for "linguistic typology" there's a probably at least 90% chance that Chomsky will be totally irrelevant.<p>(Some of my favourites in that area used to be Martin Haspelmath, Balthasar Bickel, Gilbert Lazard, ... - but I haven't kept myself up to date with the literature for years now)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="36819313"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819313" href="https://news.ycombinator.com/vote?id=36819313&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>My idea of being explicit and clear changed dramatically after I was exposed to D. Harel's "Statecharts: a visual formalism for complex systems".<p>Ironically, I think the paper presents more than just the idea and examples of statecharts, rather it also _implicitly_ contains a _method_ for discovering mechanism - the long winded example of the author's digital watch, in my eyes, is a marvel.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819208"><td></td></tr>
            <tr id="36819111"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819111" href="https://news.ycombinator.com/vote?id=36819111&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Have most people read a paper? I see threads like these with some many interesting suggestion, but are they read by people outside of their general area of study or expertise? I read quite a bit of fiction, but I've never really been able to read anything much past an abstract which much understanding. I have no science background. Am I missout on something?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="36820644"><td></td></tr>
            <tr id="36819246"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_36819246" href="https://news.ycombinator.com/vote?id=36819246&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Generally you need background knowledge to read papers. A quick way to gain necessary background knowledge is to read literature reviews or surveys. If you can't understand even reviews, surveys, or introductions, it is time to read textbooks.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="36818920"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36818920" href="https://news.ycombinator.com/vote?id=36818920&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>"Retinoic Acid and Arsenic Trioxide for Acute Promyelocytic Leukemia" by Lo-Coco et al. from 2013.[0]<p>This paper presents a cure for an extremely aggressive cancer using vitamin A and arsenic. Its a unique, relatively benign treatment strategy that completely avoids chemotherapy. As far as I know this is the best result in all of oncology, though the cancer it treats is very rare.</p><p>The most well known paper in oncology that is probably more interesting to a general audience is "The Hallmarks of Cancer" by Hanahan and Weinberg.[1]</p><p>[0] <a href="https://www.nejm.org/doi/full/10.1056/nejmoa1300874" rel="nofollow noreferrer">https://www.nejm.org/doi/full/10.1056/nejmoa1300874</a></p><p>[1] <a href="https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0092867400816839%3Fshowall%3Dtrue" rel="nofollow noreferrer">https://www.cell.com/cell/fulltext/S0092-8674(00)81683-9?_re...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="36819128"><td></td></tr>
            <tr id="36818962"><td></td></tr>
            <tr id="36818985"><td></td></tr>
            <tr id="36818688"><td></td></tr>
                <tr id="36818888"><td></td></tr>
                <tr id="36818987"><td></td></tr>
                        <tr id="36819024"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819024" href="https://news.ycombinator.com/vote?id=36819024&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>I can give example of one of worst papers.<p>Original IPFS paper is one of worst papers that I had read.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="36820673"><td></td></tr>
                  <tr id="36819087"><td></td></tr>
            <tr id="36819066"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36819066" href="https://news.ycombinator.com/vote?id=36819066&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><br><div>
                  <p><span>Lisanne Bainbridge, Ironies of Automation. Especially timely now when every company is bolting a LLM onto the side of their software.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="36820388"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_36820388" href="https://news.ycombinator.com/vote?id=36820388&amp;how=up&amp;goto=item%3Fid%3D36817231"></a></center>    </td><td><p><span>Not a paper, but <i>The Extravagant Universe</i> by Robert Kirschner describes decades worth of observation and data collection in astronomy, coming together with experimental discoveries from particle colliders and evolving theory in order to eventually converge upon the now-standard ΛCDM model in cosmology. Also includes an enormous background on the century worth of discoveries that eventually resulted in the type-1A supernova becoming a sufficiently reliable standard candle to measure the distance to galaxies far enough away that the redshift demonstrated accelerating expansion of the universe. So many things they needed to work out, from dust diffraction patterns to the differences in how spectrum evolves over the two weeks or so from the initial explosion event to figure out exactly when in the timeline each observation is taking place. Combine that with the logistics of telescope scheduling and the sparsity of observations when you're looking at something as large as the entire universe and your telescope can only cover so much at any one time. It gives you a tremendous appreciation for the sheer amount of work and patience that goes into this, slowly collecting evidence over decades, waiting for technology to develop before certain evidence is even possible to collect, and eventually seeing lines of evidence all point in the same direction, but only after a literal lifetime of work to get there.<p>Nothing else has ever made me appreciate how hard science really is and how little the general public understands it.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mali Government takes back .ml domain, brings down one of largest Lemmy servers (122 pts)]]></title>
            <link>https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</link>
            <guid>36817179</guid>
            <pubDate>Fri, 21 Jul 2023 18:00:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr">https://very.bignutty.xyz/notes/9hfv05qcs5xf7irr</a>, See on <a href="https://news.ycombinator.com/item?id=36817179">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="splash"><p><img id="splashIcon" src="https://very.bignutty.xyz/static-assets/splash.svg?1689984012144"><span id="splashText">Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Death Valley Just Had the Hottest Midnight on Record (106 pts)]]></title>
            <link>https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</link>
            <guid>36817046</guid>
            <pubDate>Fri, 21 Jul 2023 17:50:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W">https://www.msn.com/en-us/weather/topstories/death-valley-just-had-the-hottest-midnight-on-record/ar-AA1e2u4W</a>, See on <a href="https://news.ycombinator.com/item?id=36817046">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[There’s a heatwave in the sea and scientists are worried (146 pts)]]></title>
            <link>https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</link>
            <guid>36816982</guid>
            <pubDate>Fri, 21 Jul 2023 17:45:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried">https://www.bbc.com/future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried</a>, See on <a href="https://news.ycombinator.com/item?id=36816982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="headline-futurearticle20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried"><div><p>(Image credit: </p><!-- --><p>European Union/Copernicus Sentinel-2</p><!-- --><p>)</p></div><div><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237hm.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" src="https://ychef.files.bbci.co.uk/976x549/p0g237hm.jpg" alt="Satellite image of coral bleaching at Islamorada, Florida (Credit: European Union/Copernicus Sentinel-2)" id=""></picture></div></div><div><article><div><p>Could warmer ocean temperatures be a sign climate change has progressed further than we thought?</p><div><p>T</p><div><p>The month of June and the first few days of July were hotter than any in recorded history, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">according to the World Meteorological Organization (WMO)</a>. Residents in the south of the US and <a href="https://www.bbc.com/news/world-europe-66242277">southern Europe</a> have been enduring sweltering temperatures, bringing <a href="https://www.bbc.co.uk/news/world-us-canada-66218321">excessive heat warnings</a>, <a href="https://www.bbc.com/news/science-environment-66237960">wildfires</a> and <a href="https://www.bbc.com/reel/video/p0fz7y12/why-extreme-heat-makes-air-quality-worse">plummeting air quality</a>. However, records are not just being broken on land – but in the water.</p>
<p>Global ocean sea surface temperatures were higher than any previous June on record, according to a <a href="https://climate.copernicus.eu/copernicus-record-north-atlantic-warmth-hottest-june-record-globally">report by the Copernicus Climate Change Service</a>, with satellite readings in the <a href="https://climate.copernicus.eu/record-breaking-north-atlantic-ocean-temperatures-contribute-extreme-marine-heatwaves">North Atlantic in particular "off the charts</a>". Last month also <a href="https://www.noaa.gov/news/earth-just-had-its-hottest-june-on-record">set a record</a> at the US National Oceanic and Atmospheric Administration (NOAA) for the biggest difference between expected and actual sea surface temperatures.</p>
<p><a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">Water temperatures around Florida</a>, in particular, <a href="https://twitter.com/BMcNoldy/status/1678095286206382086">have been particularly warm</a>. Scientists have also been <a href="https://www.integratedecosystemassessment.noaa.gov/regions/california-current/california-current-marine-heatwave-tracker-blobtracker">tracking a large ongoing marine heatwave off the west coast of the US and Canada</a>&nbsp;since it formed in May.</p>
<p>While the heatwave has since lessened in the north-east Atlantic, according to non-profit science organisation&nbsp;<a href="https://www.mercator-ocean.eu/en/news/mercator-ocean-marine-heatwave-bulletin-for-11-july-2023">Mercator Ocean</a> International, another in the western Mediterranean now appears to be intensifying, particularly around the Strait of Gibraltar. This week, sea surface temperatures along the coasts of Southern Spain and North Africa were 2-4C (3.6-7.2F) higher than they would normally be at this time of year, with some spots 5C (9F) above the long-term average.</p>
<p>Extreme marine temperatures have also recently been observed around <a href="https://www.esa.int/ESA_Multimedia/Images/2023/06/UK_suffers_marine_heatwave">Ireland, the UK and in the Baltic Sea</a>, as well as <a href="https://www.mercator-ocean.eu/en/news/sea-surface-temperatures-record-high-2023/">areas near New Zealand and Australia</a>. More recently, scientists <a href="https://www.mercator-ocean.eu/en/news/marine-heatwaves-europe-july-18-2023/">suspect a possible heatwave</a> south of Greenland in the Labrador Sea.</p>
<p>"We are having these huge marine heatwaves in different areas of the ocean unexpectedly evolve very early in the year, very strong and over large areas," says Karina von Schuckmann, an oceanographer at Mercator Ocean.</p></div></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237dg"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237dg.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" src="https://ychef.files.bbci.co.uk/976x549/p0g237dg.jpg" alt="The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)" id=""></picture><div><p>The northern Atlantic Ocean and Mediterranean Sea have experienced record-breaking sea temperatures over the past few months (Credit: European Union/Copernicus)</p></div></div><div><p>Carlo Buontempo, director of the European Union's Copernicus Climate Change Service, says scientists expect big temperature variations in the Pacific Ocean associated with the <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">El Niño weather</a> pattern, a phase of planet-warming weather <a href="https://www.bbc.co.uk/news/science-environment-65839060">which is just beginning</a><em>, </em>although NOAA is <a href="https://www.noaa.gov/news/ongoing-marine-heat-waves-in-us-waters-explained">monitoring</a> a large heatwave in the Gulf of Alaska that has been sitting offshore since late 2022. (<em>Read more from BBC Future about <a href="https://www.bbc.com/future/article/20230525-what-will-an-el-nino-in-2023-mean-for-you">what another El Niño will mean for you</a></em>.)</p>
<p>But what we're currently seeing in the North Atlantic is "truly unprecedented", says Buontempo.</p>
<p>Scientists are still trying to unravel its full causes.</p>
<p>Short-term changes in regional atmospheric and ocean circulation patterns can provide the conditions for periods of intense heat in the sea lasting for weeks, months or even years.</p>
<p>But long-term increases in ocean temperature driven by an increase in greenhouse gas emissions are a key factor in recent heatwaves. About 90% of excess heat generated by anthropogenic climate change has been stored in the ocean, and the past two decades have seen a <a href="https://essd.copernicus.org/articles/15/1675/2023/essd-15-1675-2023.html">doubling in the rate of heat</a> accumulating in the Earth's climate system.</p>
<p><em>You might also like:</em></p>
<ul>
<li><strong><a href="https://www.bbc.com/future/article/20230706-the-simple-ways-cities-can-adapt-to-heatwaves">The simple ways cities can adapt to heatwaves</a>)</strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230718-the-fiery-row-behind-europes-mythological-heatwave-names">The fiery row behind Europe's mythological heatwave names</a></strong></li>
<li><strong><a href="https://www.bbc.com/future/article/20230630-will-texas-become-too-hot-for-humans">Will Texas become too hot for humans?</a></strong></li>
</ul>
<p>A 2021 <a href="https://www.ipcc.ch/report/ar6/wg1/chapter/chapter-9/">expert report</a> by the Intergovernmental Panel on Climate Change (IPCC) found marine heatwaves doubled in frequency between 1982 and 2016, and have become both more intense and longer since the 1980s.</p>
<p>Another potential contributing factor is the volume of aerosols in the atmosphere, which <a href="https://earthobservatory.nasa.gov/features/Aerosols">have a slight cooling effect</a> but appear to <a href="https://www.nasa.gov/feature/esnt/2022/nasa-study-finds-evidence-that-fuel-regulation-reduced-air-pollution-from-shipping">have dropped</a> as a result of a drive to clean up the shipping industry. More recently, there has been an unusual lack of dust blown from the Sahara, which also normally has <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2021JC017282">a cooling impact</a>.</p></div><div><p>The current marine heatwaves could even get worse. While experts do not think <a href="https://public.wmo.int/en/media/press-release/world-meteorological-organization-declares-onset-of-el-ni%C3%B1o-conditions">El Niño</a> itself was a driver of the North Atlantic event, <a href="https://public.wmo.int/en/media/news/preliminary-data-shows-hottest-week-record-unprecedented-sea-surface-temperatures-and">the WMO expects it</a> to add fuel to wider ocean heating.</p>
<p>Experts are concerned because marine heatwaves can affect ocean life, fisheries and weather patterns.</p>
<p>Record high temperatures along the Western Australian coast during the summer of 2010/2011 resulted in "<a href="https://www.sciencedirect.com/science/article/abs/pii/S0924796312002059?via%3Dihub">devastating" fish mortality</a>&nbsp;and destroyed kelp forests, <a href="https://link.springer.com/chapter/10.1007/978-3-030-71330-0_12">fundamentally changing the coastal ecosystem</a>. Several years later, an unprecedented marine heatwave caused by climate change and amplified by a strong El Niño caused <a href="https://elibrary.gbrmpa.gov.au/jspui/bitstream/11017/3206/1/Final-report-2016-coral-bleaching-GBR.pdf">the worst coral bleaching ever seen</a> on the Great Barrier Reef in 2016.</p>
<p>Marine heatwaves can <a href="https://www.nature.com/articles/s41598-018-24530-9">trigger mass coral bleaching events</a> and have already been increasing the <a href="https://www.nature.com/articles/s41586-018-0041-2">stress that reef ecosystems</a> are under around the world. The high termpeatures can cause the coral polyps to expel the zooxanthellae living inside their tissue, causing them to turn white and leaving them <a href="https://oceanservice.noaa.gov/facts/coral_bleach.html">more vulnerable to disease and other threats</a>.</p>
<p>In the Mediterranean Sea, exceptional temperatures over the 2015-19 period led to <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/gcb.16301">repeated mass deaths</a> of key species such as corals and seaweed. <a href="https://www.annualreviews.org/doi/abs/10.1146/annurev-marine-032122-121437">One recent study</a> described marine heatwaves such as these as "pervasive stressors to marine ecosystems globally".</p>
<p>Marine heatwaves are also making it easier for <a href="https://www.iucn.org/resources/issues-briefs/invasive-alien-species-and-climate-change">invasive species</a> to thrive. Japanese kelp, for example, <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">proliferated in New Zealand</a> when a marine heatwave in 2017-2018 in the Tasman Sea killed off <a href="https://www.frontiersin.org/articles/10.3389/fmars.2019.00084/full">native southern bull kelp</a> in the area.</p>
<p>Dan Smale, a marine ecologist at the UK's Marine Biological Association and a member of the <a href="http://www.marineheatwaves.org/">Marine Heatwaves International Working Group</a>, says "short, sharp shocks" do not give species time to redistribute and <a href="https://www.nature.com/articles/s41558-019-0412-1">those at the limit of temperatures their bodies can cope with are particularly at risk</a>. But even around the UK coastline, which is not considered to be an extreme environment and where scientists expect ecosystems to gradually change, a marine heatwave could end up being lethal if it continues through the summer.&nbsp;</p>
<p>However, there is still a lot to learn about the impact of marine heatwaves compared with those on land because monitoring is more difficult and there is a lack of long-term records, says Smale. "The data we get from satellites since the early 1980s has been amazing… but the problem is trying to then go deeper," he says.</p></div><div id="future/article/20230720-theres-a-heatwave-in-the-sea-and-scientists-are-worried-p0g237j6"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0g237j6.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" src="https://ychef.files.bbci.co.uk/976x549/p0g237j6.jpg" alt="High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)" id=""></picture><div><p>High water temperatures can destroy vital marine habitats such as kelp forests, which offer sanctuary and provide food for many fish species (Credit: Getty Images)</p></div></div><div><p>A significant drop in phytoplankton <a href="https://www.mercator-ocean.eu/en/news/record-high-sea-surface-temperatures-north-atlantic-drop-in-phytoplankton-el-nino-costal-el-nino/">has already been seen</a> in the western North Atlantic, which Mercator Ocean attributes to the recent heatwave. This spring bloom is crucial because it <a href="https://www.mccip.org.uk/sites/default/files/2021-07/15_plankton_2020.pdf">provides most of the energy</a> needed to sustain the region's marine food chain and makes a substantial contribution to global ocean CO2 uptake.</p>
<p>The economics of regional fisheries could be affected too. A 2012 heatwave over the north-west Atlantic led marine species that favour warm water to move northwards and migrate earlier, <a href="https://tos.org/oceanography/article/fisheries-management-in-a-changing-climate-lessonsfrom-the-2012-ocean-heat-">changing when and how much</a> seafood could be caught.</p>
<p>The North Atlantic is also a key driver of extreme weather. High sea surface temperatures <a href="https://www.nasa.gov/audience/forstudents/k-4/stories/nasa-knows/what-are-hurricanes-k4.html">can fuel hurricanes</a>, although whether the developing El Niño will exacerbate or <a href="https://doi.org/10.1175/JCLI-D-13-00687.1">dampen this effect</a> over the next year remains to be seen. Further inland, the warmth of the North Atlantic is the most important factor behind the alternating cycle of drought and heavy rain in <a href="https://earthobservatory.nasa.gov/images/88670/atlantic-multi-decadal-oscillation-and-drought-in-africa">central Africa</a>.</p>
<p>More broadly, experts say the persistence of recent marine heatwaves is a worrying sign about how climate change is unfolding, alongside <a href="https://www.bbc.co.uk/news/world-europe-66197368">heatwaves on land</a>, unusual <a href="https://www.researchgate.net/publication/371731505_Water_ice_society_and_ecosystems_in_the_Hindu_Kush_Himalaya_An_outlook">melting of snow cover in the Himalayas</a> and a <a href="https://www.bbc.com/news/science-environment-64649596">loss of sea ice</a>. Von Schuckmann notes that, even if humans stopped pumping CO2 into the air tomorrow, the oceans would continue to warm up for many years yet. "I am concerned as a climate scientist that we are further than we thought we are."</p>
<p>--</p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><strong><em>Facebook</em></strong></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><strong><em>Twitter</em></strong></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><strong><em>Instagram</em></strong></a><em>.</em></p>
<p><em>If you liked this story, </em><a href="https://cloud.email.bbc.com/SignUp10_08"><strong><em>sign up for the weekly bbc.com features newsletter</em></strong></a><em>, called "The Essential List" – a handpicked selection of stories from BBC </em><a href="https://www.bbc.com/future/"><strong><em>Future</em></strong></a><em>, </em><a href="https://www.bbc.com/culture/"><strong><em>Culture</em></strong></a><em>, </em><a href="https://www.bbc.com/worklife/"><strong><em>Worklife</em></strong></a><em>, </em><a href="https://www.bbc.com/travel/"><strong><em>Travel</em></strong></a> <em>and </em><a href="https://www.bbc.com/reel"><strong><em>Reel</em></strong></a><em> delivered to your inbox every Friday.</em></p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['Mystery company' buys land worth $800M near Travis AFB, raising concerns (110 pts)]]></title>
            <link>https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</link>
            <guid>36816387</guid>
            <pubDate>Fri, 21 Jul 2023 17:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/">https://abc7news.com/travis-afb-air-force-base-flannery-associates-llc-john-garamendi/13527836/</a>, See on <a href="https://news.ycombinator.com/item?id=36816387">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-testid="prism-article-body"><p><span>FAIRFIELD, Calif. (KGO) -- </span>The United States Air Force is investigating a company that's purchased $800 million of land near Travis Air Force Base, one of the most critical military bases in the U.S. But after eight months of investigation, government officials have been unable to identify who's behind it nor rule out any threat to national security.</p><p>"We're very, very concerned about this," said Rep. John Garamendi (D-CA08). "It's so extensive and so secret and it's impossible to get any information about what's happening here."</p><p>Congressman Garamendi raised the alarm to the U.S. Air Force -- prompting a federal investigation.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/chinese-surveillance-balloon-antony-blinken-spy-operation-photos/12788242/">Chinese surveillance balloon part of massive program over 5 continents: Blinken</a></b></p><p><b>Stephanie Sierra:</b> "In your briefings on the matter, do you have any reason to believe the purchase of this land is for spying?"</p><p><b>Rep. Garamendi:</b> "I have every reason in the world to believe that this land is adjacent to a critical national security platform Travis Air Force Base. Therefore -- an area where spy operations or any other nefarious activity could take place...that could detrimentally impact the ability of Travis Air Force Base to operate in a moment of national emergency."</p><p>Public records show the company "Flannery Associates LLC" began purchasing land around the military base in 2018. The controversy was first reported by the <a data-testid="prism-linkbase" rel="nofollow" href="https://www.wsj.com/articles/investors-bought-nearly-1-billion-in-land-near-a-california-air-force-base-officials-want-to-know-who-exactly-they-are-fd868e38" target="_blank">Wall Street Journal</a>. Investigators say those acquisitions ramped up in 2023.</p><p>"Now literally three sides of that base are totally controlled by the Flannery group," Rep. Garamendi said.</p><p>Yet no one - including local, state, and federal officials -- can seem to track down who's behind the group.</p><p>"Who are these people?" Garamendi said. "Where did they get the money where they could pay five to ten times the normal value that others would pay for this farmland?"</p><p>Even after eight months of investigation, Garamendi says federal authorities are still struggling to get those answers.</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/jonathan-and-diana-toebbe-spy-couple-nuclear-submarine-navy-engineer/12435396/">Navy engineer, wife sentenced after trying to sell US nuclear submarines secrets</a></b></p><p>"To this day we don't know where these people are coming from," Garamendi said.</p><p><a data-testid="prism-linkbase" href="https://abc7news.com/about/newsteam/stephanie-sierra/">I-Team reporter Stephanie Sierra</a> asked Garamendi if there is any reason to believe China is tied to this group.</p><p>"I have reason to be concerned," he responded.</p><p>Last year 300 acres of farmland were purchased near Minot Air Force Base in North Dakota. Garamendi called it a '"spy base."</p><p>"That base is where we launch our airplanes to figure out what's going on across the world," he said. "A company in China was acquiring land around that base and wanted to build a 400-foot silo that could look directly into the base... and we were like 'whoa, whoa, whoa, what's going on there?'"</p><p>Garamendi says the attorney representing Flannery Associates indicated the firm is made up of a group of families, 97 percent of whom are allegedly American, looking to diversify their portfolio from equities to real assets - including agricultural land.</p><p>But the congressman is skeptical.</p><p>"We have heard scheme after scheme that makes no sense at all," Rep. Garamendi said. "We're going to build a deep water port. Really? Around Travis Air Force Base? Which is 10 miles from the Bay. No, you're not... We're going to farm... well at that price you're going to lose a lot of money farming. Well, we're going to build a city... No, you're not going to build a city...so none of the reasons why the land is being acquired make any sense at all."</p><p><b>MORE: <a data-testid="prism-linkbase" href="https://abc7news.com/homes-near-travis-air-force-base-affordable-housing-solano-county-houses-in-fairfield-georgetown-project/9016432/">Why 300 homes next to Travis AFB have been sitting empty for a decade</a></b></p><p>The attorney representing Flannery Associates sent a letter to the U.S. Dept. of Agriculture, one of several agencies investigating the matter, issuing a formal response.</p><p><i>"No foreign person or group holds any significant interest or substantial control over Flannery, either now or at the time of any land purchase made by Flannery,"</i> the letter said.</p><p>The company added they don't comment on its investments.</p><p><b>Sierra:</b> "What do you think is happening?"</p><p><b>Rep. Garamendi:</b> "I don't know, it doesn't make any sense... It's the secrecy... Why are you doing this in secret? If you're not a nefarious operation, why are you keeping it secret?"</p><p>According to Garamendi, Flannery Associates has also acquired land around the interstate electrical grid system stemming from the Columbia River into Central California - including land that houses wind turbines that provide significant power into Northern California.</p><p>In the meantime, Garamendi says the company continues to negatively impact the farming community in Solano County. He says at least 10 landowners are being sued by Flannery, accused of being engaged in an illegal scheme to prevent the company from buying their land.</p><p><b>Take a look at more <a data-testid="prism-linkbase" href="https://abc7news.com/iteam/">stories and videos by the ABC7 News I-Team.</a></b> </p><div data-testid="prism-inline-image"><figure data-testid="prism-figure"><a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/"><img alt="Now Streaming 24/7 Click Here" data-testid="prism-image" draggable="false" src="https://cdn.abcotvs.com/dip/images/11518842_247-NOWSTREAMING_1280x720.png"></a><figcaption></figcaption></figure></div><p> <i>If you're on the ABC7 News app, <a data-testid="prism-linkbase" href="https://abc7news.com/abc-news-live-local-watch/11513295/">click here to watch live</a></i></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Diablo (226 pts)]]></title>
            <link>https://www.filfre.net/2023/07/diablo/</link>
            <guid>36815781</guid>
            <pubDate>Fri, 21 Jul 2023 16:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filfre.net/2023/07/diablo/">https://www.filfre.net/2023/07/diablo/</a>, See on <a href="https://news.ycombinator.com/item?id=36815781">Hacker News</a></p>
Couldn't get https://www.filfre.net/2023/07/diablo/: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[‘World of Warcraft’ players trick AI-scraping website into publishing nonsense (324 pts)]]></title>
            <link>https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/</link>
            <guid>36815744</guid>
            <pubDate>Fri, 21 Jul 2023 16:22:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/">https://www.forbes.com/sites/paultassi/2023/07/21/world-of-warcraft-players-trick-ai-scraping-games-website-into-publishing-nonsense/</a>, See on <a href="https://news.ycombinator.com/item?id=36815744">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure role="presentation"><figcaption><fbs-accordion><p>The story</p></fbs-accordion><small>Zleague, I mean reddit</small></figcaption></figure>
<p>As someone who writes about video games for a living, I am deeply annoyed/terrified about the prospect of AI-run websites not necessarily replacing me, but doing things like at the very least, crowding me out of Google, given that Google does not seem to care whatsoever whether content is AI-generated or not.</p>


<p>That’s why it’s refreshing to see a little bit of justice dished out in a very funny way from a gaming community. The <em>World of Warcraft</em> subreddit recently realized that a website, zleague.gg (I am not linking to it), which runs a blog attached to some of sort of gaming app which is its main business, has been scraping reddit threads, feeding them through an AI and summarizing them with “key takeaways” and regurgitated paragraphs that all follow the same format. It’s gross, and yet it generates an article long enough with enough keywords to show up on Google.</p>

<p>Well, the redditors got annoyed and decided to mess with the bots. On r/WoW, they made <a href="https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" target="_blank" title="https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.reddit.com/r/wow/comments/154umm2/im_so_excited_they_finally_introduced_glorbo/" aria-label="a lengthy thread discussing the arrival of Glorbo in the game">a lengthy thread discussing the arrival of Glorbo in the game</a>, a new feature that, as you may be able to guess from the name, is not real.</p>


<blockquote>
 “I have to say, since they started hinting at it in Hearthstone in 1994, it was obvious that they would introduce Glorbo to World of Warcraft sooner or later. I feel like Dragonflight has been win after win so far, like when they brought back Chen Stormstout as the end boss of the new Karazhan? Absolutely amazing!”
</blockquote>
<p>And it…worked. Zleague auto-published a post titled “World of Warcraft Players Excited For Glorbo’s Introduction. Here’s are the “key takeaways”:</p>


<ul>
 <li>“Players express excitement for Glorbo’s arrival and its potential impact on the game.”</li>
 <li>“Some players have reservations about the mandatory item Klikclac and its effect on casual players.”</li>
 <li>“Rumors of Stormsong Valley becoming the new location for the Halfhill Market and farming sim mini-game generate enthusiasm.”</li>
 <li>“Appreciation for previous game changes, such as the inclusion of Klaxxi as a playable race.”</li>
</ul>


<p>That is… all essentially nonsense. The article was left online for a while but has finally been taken down (<a href="https://archive.ph/4mOWr#selection-1103.139-1103.245" target="_blank" title="https://archive.ph/4mOWr#selection-1103.139-1103.245" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://archive.ph/4mOWr#selection-1103.139-1103.245" aria-label="here’s a mirror, it’s hilarious">here’s a mirror, it’s hilarious</a>). All the authors listed as having bylines on the site are fake. It appears this entire thing is run with close to zero oversight.</p>

<p>It’s a weird situation because the site is not “stealing” in the traditional sense, directly plagiarizing without credit. It is citing reddit threads and their authors and even embedding the reddit post a lot of the time. But while getting story ideas from reddit and expanding on them is one thing, given that these are often the biggest communities for individual games on the internet, it’s a different matter to simply auto-feed reddit threads into an AI and have them spit this out. But again, there’s nothing to stop this. These subreddits can’t <em>only</em> fill themselves with joke articles to screw up a site like this, even if this one specific example is good for a laugh.</p>


<p>The only way this will ever be stopped is if Google steps in and dramatically deranks or bans AI-based sites like this, as begging for Google traffic crumbs is the only reason these sites exist in the first place. But since Google has its own very obvious vested interest in AI, I am not holding my breath.</p>
<p>Anyway, get hyped for Glorbo, I hear it’s the best change since the quest to depose Quackion, the Aspect of Ducks.</p>
<p><strong><em>Follow me </em></strong><a href="https://twitter.com/PaulTassi" target="_blank" title="https://twitter.com/PaulTassi" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://twitter.com/PaulTassi" aria-label="on Twitter"><strong data-ga-track="ExternalLink:https://twitter.com/PaulTassi"><em data-ga-track="ExternalLink:https://twitter.com/PaulTassi">on Twitter</em></strong></a><strong><em>, </em></strong><a href="https://www.threads.net/@paul.tassi" target="_blank" title="https://www.threads.net/@paul.tassi" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi" aria-label="Threads"><strong data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi"><em data-ga-track="ExternalLink:https://www.threads.net/@paul.tassi">Threads</em></strong></a><strong><em>, </em></strong><a href="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" target="_blank" title="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" aria-label="YouTube"><strong data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1"><em data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1">YouTube</em></strong></a><a href="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ" target="_blank" title="https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ?sub_confirmation=1" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ" aria-label=","><strong data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ"><em data-ga-track="ExternalLink:https://www.youtube.com/channel/UCg6K8i6OGobyZNoPIsCW9uQ">,</em></strong></a> <strong><em>and </em></strong><a href="https://www.instagram.com/paul.tassi/?hl=en" target="_blank" title="https://www.instagram.com/paul.tassi/?hl=en" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en" aria-label="Instagram"><strong data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en"><em data-ga-track="ExternalLink:https://www.instagram.com/paul.tassi/?hl=en">Instagram</em></strong></a><strong><em>. Subscribe to my free weekly content round-up newsletter, </em></strong><a href="https://paultassi.substack.com/welcome" target="_blank" title="https://paultassi.substack.com/welcome" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://paultassi.substack.com/welcome" aria-label="God Rolls"><strong data-ga-track="ExternalLink:https://paultassi.substack.com/welcome"><em data-ga-track="ExternalLink:https://paultassi.substack.com/welcome">God Rolls</em></strong></a><strong><em>.</em></strong></p>
<p><strong><em>Pick up my sci-fi novels the </em></strong><a href="https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" target="_blank" title="https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition" aria-label="Herokiller series"><strong data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition"><em data-ga-track="ExternalLink:https://www.amazon.com/gp/product/B08G1MRFTM?ref_=dbs_dp_rwt_sb_tkin&amp;binding=kindle_edition">Herokiller series</em></strong></a> <strong><em>and </em></strong><a href="https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" target="_blank" title="https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk" aria-label="The Earthborn Trilogy"><strong data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk"><em data-ga-track="ExternalLink:https://www.amazon.com/dp/B08KYDGG73?binding=paperback&amp;ref=dbs_dp_rwt_sb_pc_tpbk">The Earthborn Trilogy</em></strong></a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RFC 9420 a.k.a. Messaging Layer Security (164 pts)]]></title>
            <link>https://blog.phnx.im/rfc-9420-mls/</link>
            <guid>36815705</guid>
            <pubDate>Fri, 21 Jul 2023 16:19:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.phnx.im/rfc-9420-mls/">https://blog.phnx.im/rfc-9420-mls/</a>, See on <a href="https://news.ycombinator.com/item?id=36815705">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Today, the Messaging Layer Security (MLS) protocol has been published as <a href="https://datatracker.ietf.org/doc/html/rfc9420?ref=blog.phnx.im">RFC 9420</a>, a standards track document by the Internet Engineering Task Force (IETF). MLS is the first standardized and fully specified end-to-end encryption protocol. The specification is freely accessible, and its security has been analyzed in a series of academic publications.</p><p>Our team has been involved in the design and development of the MLS protocol since the very beginning. Over the course of five years, along with others from the MLS IETF working group, we have iterated to combine modern academic proposals with real-life requirements from the industry. The protocol has already proven its aptitude in large-scale deployments with major companies like Cisco and RingCentral having already integrated an early version of MLS into their products, serving millions of users.</p><p>This blog post gives a high-level overview of MLS, its practical applications, and why it matters.</p><h2 id="the-early-days-and-the-standardization-process">The early days and the standardization process</h2><p>Prior to MLS, a comprehensive specification of a protocol for end-to-end encryption informed by industry-wide input did not exist.</p><p>Protocols like the <a href="https://otr.cypherpunks.ca/?ref=blog.phnx.im">Off-the-Record protocol</a>, the <a href="https://wickr.com/wickrs-messaging-protocol/?ref=blog.phnx.im">Wickr protocol</a>, and the <a href="https://www.signal.org/docs/?ref=blog.phnx.im">Signal protocol</a> paved the way with modern security properties and asynchronous messaging capabilities.</p><p>The Signal protocol introduced the asynchronous mode of operation the Off-the-Record protocol was lacking and has made end-to-end encryption available to mobile messaging. It has since become the reference for practical and high-quality end-to-end encryption. However, a <a href="https://github.com/SilentCircle/libzina?ref=blog.phnx.im">few</a> <a href="https://github.com/wireapp/proteus?ref=blog.phnx.im">derivatives</a> <a href="https://gitlab.matrix.org/matrix-org/olm?ref=blog.phnx.im">emerged</a> due to the lack of both a full specification and permissively licensed implementations. These derivatives have seen different levels of analysis and every provider has had to maintain their own libraries.</p><p>Generally, existing protocols were typically focused on end-to-end encryption between two peers. Using them to protect group chats with many peers proved difficult and either meant compromising on security properties or accepting high computational and bandwidth costs.</p><p><a href="https://www.mozilla.org/?ref=blog.phnx.im">Various</a> <a href="http://cisco.com/?ref=blog.phnx.im">stakeholders</a> <a href="http://facebook.com/">from</a> <a href="http://google.com/?ref=blog.phnx.im">the</a> <a href="http://wire.com/?ref=blog.phnx.im">industry</a> <a href="https://www.ox.ac.uk/?ref=blog.phnx.im">and</a> <a href="http://inria.fr/?ref=blog.phnx.im">academia</a> identified these gaps and started initial talks for an open standard for asynchronous group messaging with modern security properties solving an entire range of issues. In March 2018, these “<a href="https://datatracker.ietf.org/meeting/101/materials/minutes-101-mls-00?ref=blog.phnx.im">Birds of a Feather” finally flocked together</a> and the MLS working group was subsequently established.</p><p>During the protocol design process, the working group followed an iterative approach that involved multiple rounds of review, feedback, and refinement. Regular members of the working group, as well as other interested individuals, carefully reviewed the Internet-Drafts, providing feedback, suggesting changes, and engaging in technical discussions. Numerous cryptographic experts from academia and industry analyzed MLS and the different security guarantees it aims to provide, sharing their findings in <a href="https://datatracker.ietf.org/doc/html/draft-ietf-mls-architecture-10?ref=blog.phnx.im#name-cryptographic-analysis-of-t">several academic publications</a>. This was particularly beneficial to mitigate security issues before deploying it in production environments.</p><h2 id="how-is-mls-different-from-existing-protocols">How is MLS different from existing protocols?</h2><p>Compared to existing protocols such as the Off-the-Record and the Signal protocol, MLS offers improvements in multiple ways.</p><h2 id="efficiency-do-more-with-less">Efficiency: Do more with less</h2><p>Secure messaging protocols in use today were designed as one-to-one protocols, with group messaging functionality built directly from one-to-one channels between all group members. This leaves the sender of a message to encrypt and upload a message for each other group member individually, leading to a complexity of O(n), where n is the number of members in a group. In contrast, MLS typically has costs of O(log n) for the same scenario, making it well-suited even for large groups.</p><p>Constructions such as <a href="https://www.whatsapp.com/security/WhatsApp-Security-Whitepaper.pdf?ref=blog.phnx.im">Sender Keys</a> improve the efficiency of the approach of one-to-one protocols, however, their security guarantees do not reach those of the base protocol. In particular, achieving good <em>Post-Compromise Security</em> guarantees is prohibitively expensive with Sender Keys. In other words, removing users from a group chat or ensuring a compromised device has no long-term negative impact incurs high bandwidth and computation costs for all members of the group. To recover from a compromise of a single member of the group, all other members have to broadcast an update of their key material. This leads to an overall cost of computation and bandwidth of O(n^2) for a group size of n and requires all group members to come online at least once. In contrast, MLS has an update operation with complexity of O(log n) &nbsp;that requires only the compromised member to be online for the group to recover from the compromise.</p><p>MLS achieves its low complexity through the use of a binary tree. This means that the number of required operations and the payload size do not increase linearly with the group size but rather only logarithmically after a short warm-up period. Example: In a group with 1000 members, the number of required operations to calculate new group keys would only be 10 as opposed to 1000 with existing protocols. With an assumed base payload size of 100 B per key negotiation, the total payload size would only be 1 KB instead of 100 KB.</p><figure><img src="https://blog.phnx.im/content/images/2023/07/MLS-performance-projection-1.png" alt="" loading="lazy" width="2000" height="1600" srcset="https://blog.phnx.im/content/images/size/w600/2023/07/MLS-performance-projection-1.png 600w, https://blog.phnx.im/content/images/size/w1000/2023/07/MLS-performance-projection-1.png 1000w, https://blog.phnx.im/content/images/size/w1600/2023/07/MLS-performance-projection-1.png 1600w, https://blog.phnx.im/content/images/size/w2400/2023/07/MLS-performance-projection-1.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Performance projection: Number of operations required to calculate new group keys with MLS (blue) versus existing group messaging protocols (red).</figcaption></figure><h2 id="a-new-security-notion-group-integrity">A new security notion: Group Integrity</h2><p>As existing protocols don’t have a notion of groups, messaging apps either manage group membership on the server side in plain text or combine the end-to-end encryption protocol with an additional group management protocol such as <a href="https://eprint.iacr.org/2019/1416.pdf?ref=blog.phnx.im">Signal’s Private Group System</a>.</p><p>In MLS, all group members cryptographically agree on the current state of the group, including who is a part of it. As a consequence, a group member can only decrypt messages from other group members if the sender and the receiver generally agree on the group state and specifically on who is in the group. In other words, it becomes impossible for a third party to add a member to a group without all existing members of the group being aware of it.</p><h2 id="synchronizing-data-in-a-distributed-system-a-hard-problem-becomes-easier">Synchronizing data in a distributed system: A hard problem becomes easier</h2><p>Distributing and synchronizing data across multiple clients can be a daunting task. Aside from confidentiality, MLS also addresses the issue of synchronizing data between members of a group. The corresponding mechanism is directly derived from the group integrity property. Instead of only agreeing on a member list, members of a group can agree on arbitrary data. MLS relies on a component called Delivery Service that ensures an in-order delivery of MLS messages. This ordering then dictates how clients move incrementally from one group state to the next. </p><p>With that, an MLS group can become a distribution channel for whatever data needs to be synchronized between different entities by guaranteeing cryptographical agreement on previous extension messages. In other words, this simply means that members of a group can be sure all other members saw the same messages previously.</p><h2 id="extensible-tune-it-for-your-needs">Extensible: Tune it for your needs</h2><p>MLS is also extensible, which means that the protocol can be modified, or additional data can be added to the state of a group. The latter can be used, for example, to attach data such as a group name or an image to the group state.</p><p>The protocol has a negotiation mechanism that ensures that extensions are only used if they are supported by all members of a group. Group members also agree on which extensions are mandatory in a group.</p><p>Since MLS is fundamentally also a group key negotiation protocol, additional cryptographic key material can be exported by all members of a group. This mechanism – called Exporter – can be used to derive encryption keys. For example, participants of audio/video calls or conferences can use MLS to generate encryption keys for end-to-end encryption of the media streams.</p><h2 id="future-proof-version-and-cipher-suite-agility">Future-proof: Version and cipher suite agility</h2><p>In contrast to many existing end-to-end encryption protocols, MLS allows members to signal which versions of MLS and which MLS cipher suites they support. In the future, this lets applications safely transition to a newer version of MLS or gradually roll out support for new cipher suites without confusion between individual clients. An example of such a transition could be that a secure messaging application rolls out MLS and later wants to transition to a post-quantum secure cipher suite.</p><h2 id="the-next-steps">The next steps</h2><p>Now that the standard is established, we focus more on making end-to-end encryption ubiquitous. We believe that accessibility to the technology is paramount, and we want to complement the specification with a general-purpose implementation published under a permissive license: <a href="https://openmls.tech/?ref=blog.phnx.im">OpenMLS</a>. Along with our partners at <a href="https://cryspen.com/?ref=blog.phnx.im">Cryspen</a>, we have evolved OpenMLS over the years into a software library that can be used in various projects. OpenMLS is licensed under the <a href="https://opensource.org/license/mit/?ref=blog.phnx.im">MIT license</a> to minimize friction and make it broadly accessible.</p><h2 id="additional-resources">Additional resources</h2><ul><li>See the full specification: <a href="https://datatracker.ietf.org/doc/html/rfc9420?ref=blog.phnx.im">RFC 9420</a></li><li>Don’t want to read anymore? Listen to the <a href="https://scw.quest/2023/04/22/mls/?ref=blog.phnx.im">Security Cryptography Whatever Podcast episode about MLS</a></li><li>Tired of listening? Watch the <a href="https://www.youtube.com/watch?v=zrjmpyc8YrE&amp;ref=blog.phnx.im">Black Hat talk on MLS: Towards a New Era of Secure Group Messaging</a></li></ul><hr><p>Our team has been active in the secure messaging field for over a decade and co-authored the MLS protocol specification. If you are interested in using MLS in general or our MLS implementation (<a href="https://openmls.tech/?ref=blog.phnx.im">OpenMLS</a>) in particular in your application, do not hesitate to <a href="mailto:hello@phnx.im">contact us</a> and let us know how we can help. We offer consulting services around MLS and messaging architecture as well as development services related to OpenMLS.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In the LLM space, "open source" is being used to mean "downloadable weights" (344 pts)]]></title>
            <link>https://www.alessiofanelli.com/blog/llama2-isnt-open-source</link>
            <guid>36815255</guid>
            <pubDate>Fri, 21 Jul 2023 15:49:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.alessiofanelli.com/blog/llama2-isnt-open-source">https://www.alessiofanelli.com/blog/llama2-isnt-open-source</a>, See on <a href="https://news.ycombinator.com/item?id=36815255">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>LLaMA2 isn't "Open Source" - and why it doesn't matter<br><span>Posted on <!-- -->7/20/2023</span></h2><p>Almost a decade ago I started an open source company, and I’ve since been involved in the OSS community as a founder, contributor, speaker, and investor. The internet wouldn’t be what it is today if it wasn’t for the amazing open source projects that power most of the digital infrastructure of our world, so it’s a topic that has always been close to my heart.</p><p>When LLaMA2 came out, many of the folks I respect in the community were upset about misusing the term “open source” when referring to the model.</p><p><img src="https://www.alessiofanelli.com/images/yann.png" alt="Yann" parentname="p"></p><p>While it’s mostly open, there are caveats such as you can’t use the model commercially if you had more than 700M MAUs as of the release date, and you also cannot use the model output to train another large language model. These types of restrictions don’t play well with the open source ethos. But while I agree that LLaMA2 cannot be called open source in the traditional meaning of the word, I also think that it doesn’t matter. The term “open source” needs to evolve (once again) in the world of AI models.</p><h2>From Free to Open</h2><p>I wrote a long history of the free software and open source movement <a href="https://www.alessiofanelli.com/blog/history-of-open-source-licensing" parentname="p">here</a>, so I won’t bore you with the details again. What you need to know is that since the 1976 “Open Letter to Hobbyists”, there’s always been tension between the commercial interests of software companies and the curiosity of hackers who wanted to circumvent its restriction. The “free software” movement started in the 70s in the MIT AI lab with Richard Stallman and eventually the GNU project in 1983. The GPL “copyleft” license was created, and projects like Red Hat, MySQL, Git, and Ubuntu adopted it.</p><p>The term “open source” came to be in 1998 thanks to MIT’s Christine Peterson; at the “Freeware Summit”, the term “free software” was officially deprecated in favor of “open source software”. As time went by, the “free” and “open source” software communities diverged as they had different ideas of what free and open meant. Free software, as specified by the Free Software Foundation, is only a subset of open source software and uses very permissive licenses such as GPL and Apache.</p><p>In the last decade, there was another bifurcation, this time created by the tension between commercial open source companies and the cloud hyperscalers. Elastic and MongoDB transitioned their open source projects to the “Server-Side Public License” (SSPL) which allows developers to use the product commercially, as long as what they are offering isn’t a hosted version of the product. The goal was to block AWS from re-hosting their products as cloud services and profiting from them. The SSPL also infringes on the OSS ideals and is not recognized by the OSI as an open source license. Yet, the majority of developers still say that MongoDB is open source. More and more the term "open source" is losing its freedom connotations and turning almost synonymous with "source available" in developers' minds.</p><h2>From Source to Weights</h2><p>With the rise of open models like Dolly, MPT, LLaMA, etc., we are seeing a similar bifurcation in the community. For most AI engineers, “open source” today means “downloadable weights”, nothing more. Heather Meeker has proposed a definition for <a href="https://github.com/Open-Weights/Definition" parentname="p">“open weights”</a>, but there’s still no community consensus. The question is whether or not open weights are enough for a model to be called open source; a software analogy would be a project releasing its binaries without the source code to re-build it from scratch.</p><p>For a model to be truly open source and retrainable from scratch, the creators would need to share all their training code, pre-training dataset, fine-tuning preferences, RLHF examples, etc. The problem is the cost of these training runs: even if someone were to release everything, it’s cost-prohibitive to train models from scratch for most developers and companies, so having access to the final weights is preferred anyway.</p><p><img src="https://www.alessiofanelli.com/images/open-models.png" alt="Open Models" parentname="p"></p><p>In the LLMs space, the term "open source" is used interchangeably to define a wide range of openness levels:</p><ul><li parentname="ul"><strong parentname="li">Open models:</strong> these are models like RedPajama and MPT-7B, they have open weights available for commercial use (under Apache 2.0 license), but can also be re-trained from scratch since the dataset is open source. You can find a guide on how to train your own RedPajama model <a href="https://github.com/Lightning-AI/lit-llama/blob/main/howto/train_redpajama.md" parentname="li">here</a>.</li><li parentname="ul"><strong parentname="li">Open weights:</strong> StableLM is an open model trained by StabilityAI. While the weights are available and are licensed under Apache 2.0, the dataset used to train isn’t available to the public. From their README: “StableLM-Base-Alpha is pre-trained on a new experimental dataset built atop The Pile and is threes times larger at approximately 1.5T tokens.”</li><li parentname="ul"><strong parentname="li">Restricted weights:</strong> this is LLaMA2. The pre-training dataset is also unavailable, and while the weights are supposed to be open for commercial use, they have specific limitations that we mentioned above.</li><li parentname="ul"><strong parentname="li">Contaminated weights:</strong> models like Dolly 1.0 and LLaMA1 are part of this category. The weights are released openly, but the dataset used to train them doesn’t allow for commercial use, making it technically open but practically unusable.</li></ul><p>For the foreseeable future, open source and open weights will be used interchangeably, and I think that’s okay. The important thing is that more and more of this work is done as openly as possible. It’s okay to be disappointed with the LLaMA2 license, but Meta just packaged ~$2M worth of FLOPS into a Github repo, and I think that will be a net positive for the progress of this space.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[By 2028 there must be fast chargers every 60 km on the EU’s key motorways (120 pts)]]></title>
            <link>https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&amp;t%5B0%5D=Charging&amp;curl=1</link>
            <guid>36814754</guid>
            <pubDate>Fri, 21 Jul 2023 15:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&#x26;t%5B0%5D=Charging&#x26;curl=1">https://www.fleeteurope.com/en/new-energies/europe/article/fast-chargers-every-60-km-key-eu-motorways?a=FJA05&#x26;t%5B0%5D=Charging&#x26;curl=1</a>, See on <a href="https://news.ycombinator.com/item?id=36814754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div property="content:encoded">
        <p>By 2028, there must be fast chargers at least every 60 km on the EU’s key motorways. That is the most eyecatching measure of several approved by the European Parliament to improve EV charging. Others focus on increasing charging speed and making it easier to pay for charging. All are part of the EU’s ‘Fit for 55’ package, aimed at reducing emissions by 55% by 2030.</p>  <p>The maximum-distance rule for fast chargers applies to TEN-T (<em>pictured)</em>, an EU-wide network of key traffic corridors with a total length of 24,500 km. The mandated fast chargers along these roads all must have an output of at least 400 kW by 2026, and 600 kW by 2028.&nbsp;</p>  <p>Specifically for electric buses and trucks, the European Parliament mandated charging points at most 120 km apart by 2028 on at least half the network, each heavy-duty charger with an output of 1,400 to 2,800 kW, depending on the road.&nbsp;</p>  <p>In addition to these minimum requirements for the density and speed of the fast charger network, the European parliament also wants more simplicity and transparency when it comes to payment:</p>  <ul> 	<li>All customers must be able to pay with cards or contactless devices (at present, some charging networks require subscriptions or app downloads).&nbsp;</li> 	<li>All prices must be clearly displayed to the customers: in euros per kW or per minute/session. &nbsp;</li> 	<li>By 2027, the EU will develop a public database of charging stations, with information on pricing, availability, and waiting times.&nbsp;</li> </ul>  <p>Not forgetting other sustainable alternatives to ICEs, the European Parliament mandated at least one hydrogen refueling station every 200 km along TEN-T motorways by 2031.&nbsp;</p>  <p>The new alternative fuel infrastructure rules have already been approved by the European Parliament, but will only enter into force six months after approval by the European Council.&nbsp;</p>  <p>In a separate move, the UK has formulated similar proposals to improve the availability and reliability of public EV charging. For example: the British government wants to reduce the share of charging stations out of service from 8% in 2019 to 1% (as is already the case in the Netherlands), and will require that charging station operators provide a 24-hour helpline for their customers.</p>  <p><em>Image: Directorate-General for Mobility and Transport, European Commission – CC BY-SA 4.0</em></p> 
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[India’s ban on rice exports raises fear of global food price rises (121 pts)]]></title>
            <link>https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises</link>
            <guid>36814627</guid>
            <pubDate>Fri, 21 Jul 2023 15:01:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises">https://www.theguardian.com/business/2023/jul/21/india-ban-on-rice-exports-raises-fear-of-global-food-price-rises</a>, See on <a href="https://news.ycombinator.com/item?id=36814627">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>India has banned non-basmati white rice exports to curb domestic inflation, raising fears of further increases in global food prices just days after <a href="https://www.theguardian.com/business/2023/jul/20/rising-grain-prices-russia-pullout-black-sea-deal-food-crisis-fears" data-link-name="in body link">wheat and corn prices were sent climbing</a> by Russia’s termination of a key grain deal.</p><p>The immediate ban, introduced after heavy rains hit domestic crops, follows the failure of a 20% duty on international exports introduced in September to curb foreign demand, which has soared after extreme climate conditions hit production in countries.</p><p>India is the world’s largest rice exporter, accounting for more than 40% of global shipments. While the ban does not apply to higher-grade basmati rice – India’s best-known variety – non-basmati white rice accounts for about 25% of exports.</p><p>International sales of Indian rice soared by 35% in the year to June, contributing to a 3% rise in domestic prices over the past month alone. People in India are paying 11.5% more for rice than a year ago, according to its ministry of consumer affairs, food and public distribution.</p><p>The Indian government said the ban, <a href="https://www.pib.gov.in/PressReleasePage.aspx?PRID=1941139" data-link-name="in body link">introduced on Thursday evening</a>, would “ensure adequate availability of non-basmati white rice in the Indian market” and lead to lowering of prices for domestic consumers.</p><p>Soaring food inflation has put pressure on the BJP government in Delhi in the run-up to national elections next year and state-level elections in the months to come.</p><p>India’s move sent the price of rice from several Asian countries higher on global markets, while traders said they expected prices to rise substantially in the coming days.</p><p>The price of India’s 5% broken parboiled variety had already been hovering this week close to a five-year peak between $421 and $428 (£328-334) a metric tonne, and on Friday it stood at about $424.50.</p><p>Thailand and Vietnam, respectively the world’s second and third-largest rice exporters, have also experienced rises in the prices of their 5% broken rice in recent times. Even before the announcement, Vietnam’s rice was trading at its highest level since 2011, and has since moved higher, while Thailand’s variety jumped to levels not seen for more than two years.</p><p>Global food supplies have been hit by Russia’s war in Ukraine, which has driven up commodity and grain prices around the world.</p><p>Russia’s decision earlier in the week to <a href="https://www.theguardian.com/world/2023/jul/17/russia-decision-not-extend-black-sea-grain-deal-final" data-link-name="in body link">pull out of the year-old UN-brokered Black Sea grain initiative</a>, which guaranteed safe passage for vessels carrying cereals, has prompted fresh concerns about a global food crisis.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-11">skip past newsletter promotion</a><p id="EmailSignup-skip-link-11" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Before the move by the Kremlin, the grain price had fallen by more a third (35%), while the wheat price had declined 14% since January and corn prices had been trading 20% lower.</p><p>The US has pledged a further $250m (£194m) to create and expand other routes for Ukrainian grain to leave the country, but Russia’s defence ministry has in effect said any ship leaving a Ukrainian port <a href="https://www.theguardian.com/world/2023/jul/20/what-was-the-black-sea-grain-deal-and-why-did-it-collapse" data-link-name="in body link">will be a legitimate military target</a>, raising fears that supplies could face further disruption.</p><p>The interruption of Ukrainian grain exports comes as important growing regions in the US have been hit by unusually hot weather and lack of rain, leading to a reduction in forecasts for the US wheat harvest, with stocks estimated to fall to a 16-year low.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Turborepo is porting from Go to Rust (110 pts)]]></title>
            <link>https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust</link>
            <guid>36814019</guid>
            <pubDate>Fri, 21 Jul 2023 14:14:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust">https://vercel.com/blog/how-turborepo-is-porting-from-go-to-rust?nxtPslug=how-turborepo-is-porting-from-go-to-rust</a>, See on <a href="https://news.ycombinator.com/item?id=36814019">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In <a href="https://vercel.com/blog/turborepo-migration-go-rust" rel="noopener" target="_blank">a previous blog post</a>, we talked about <b>why</b> we are porting <a href="https://turbo.build/?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">Turborepo, the high-performance build system for JavaScript and TypeScript</a>, from Go to Rust. Now, let's talk about <b>how</b>.</p><p>Today, our porting effort is in full swing, moving more and more code to Rust. But when we were starting out, we had to make sure that porting was feasible for us to accomplish. A migration from one language to another is no small task and there's a lot of research to do up front to ensure that the end goal is attainable. </p><p>Here’s how we started the process, validated our current porting strategy, and made the call to port Turborepo to Rust.</p><h2><span id="port-vs.-full-rewrite"></span><a href="#port-vs.-full-rewrite">Port vs. full rewrite</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>When we were planning our migration, we briefly considered a full, ground-up rewrite. But, talking the idea through, we realized it wouldn't fit our goals as well as an incremental port would.</p><h3><span id="what-is-an-incremental-port"></span><a href="#what-is-an-incremental-port">What is an incremental port?</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Incremental porting moves code piece-by-piece, running new and old code together at the same time. The goal for the chunk of code being moved is to keep the behavior exactly the same as before it was ported.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319409.png" loading="lazy" width="2880" height="2113" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FmZz2Um8re3MZXucpSZdoV%2F890469916054b2f0b364c13514e825b4%2FFrame_427319409.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FmZz2Um8re3MZXucpSZdoV%2F890469916054b2f0b364c13514e825b4%2FFrame_427319409.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319402 (1).png" loading="lazy" width="1920" height="1409" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2Fc17bo47fBBuBQztRawrOp%2Fe16450ef2ef20d0c7bf2dc709912fc1b%2FFrame_427319402__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 6.png" loading="lazy" width="621" height="628" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F6ZaHYc4GhEIKfRL2c1erpl%2F59f7fc484abd77f372331aec1f583d84%2FiPhone_8_Plus_-_6.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 2.png" loading="lazy" width="621" height="628" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1b7106hvxHFzTGUpGnkJtO%2F33e299c2b1216be88278d462c085e32e%2FiPhone_8_Plus_-_2.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>In our case, this means we need to have our Go code and Rust code interoperating with each other. We want to do a simple translation, explicitly avoiding making improvements or changing functionality when we're swapping out languages for the slice of code. That way, we can do intensive testing against both sets of code, and complete the migration as quickly as possible.</p><h3><span id="why-we-didn't-do-a-full-rewrite"></span><a href="#why-we-didn't-do-a-full-rewrite">Why we didn't do a full rewrite</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Full rewrites are very tempting. They are more simple to write and ship, as you don't need to worry about your "before" and "after" code working together. You also get a clean slate to write a new and improved version, without the warts and technical debt of the previous iteration. However, full rewrites also come with some serious downsides.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319410.png" loading="lazy" width="1920" height="735" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7nb5vSuSQZXEKsUUsYGNVl%2Ff0f6be9ab08484fb087d5583d5720278%2FFrame_427319410.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319404 (1).png" loading="lazy" width="1920" height="735" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7bF6sXF2wD092FiiuBXyGV%2Ff5f57209b1f25030cb3e106a2a6189d1%2FFrame_427319404__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 11.png" loading="lazy" width="414" height="459" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F365RREyHsEytwZlyGKa985%2F24ca1793a87a50ac37bdfea84c2964a5%2FiPhone_8_Plus_-_11.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 16.png" loading="lazy" width="414" height="459" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FWdkdfyBr5TwUufLIYBxRf%2Ff5066270eea29c7ef149ba6eb3c95528%2FiPhone_8_Plus_-_16.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>First, a full rewrite tends to require a complete halt to shipping new features. Otherwise, you run the risk of chasing a moving target as the old codebase grows while you try to catch up with your new code. </p><p>A full rewrite also does not guarantee a better user experience. Often, a rewrite ends up less than seamless, as it's not feasible for the new version to match the old one, feature for feature, edge case for edge case. As the surface area of the rewrite grows, there's more room for error and users can end up frustrated with breaking changes and missing features.</p><p>Full rewrites also require building up an entirely new codebase, which is a large quantity of unused code. In our experience, unused code, even when verified with tests, can be a breeding ground for bugs. We wanted to make sure that any new Rust code was properly exercised as we moved through our porting effort.</p><h2><span id="we-chose-to-port"></span><a href="#we-chose-to-port">We chose to port</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>Therefore, we decided to <b>port</b> Turborepo to Rust instead of doing a full rewrite.</p><p>Porting did necessitate some tradeoffs. We had to introduce a significant amount of complexity into our codebase, so that we could interoperate between Go and Rust. This complexity meant slower developer velocity to start, but we look forward to workflow improvements going forward, particularly when our porting effort has finished.</p><p>More importantly, we knew we could continue shipping features to Turborepo users while porting. All things considered, we determined that this was a reasonable compromise and the path that we would take.</p><h3><span id="starting-the-port"></span><a href="#starting-the-port">Starting the port </a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>We chose to start by writing a small, new Turborepo feature in Rust. This way, we could add new functionality from the roadmap for users, integrate Rust into our build process, and interact with existing Go code as little as possible to reduce our initial complexity.</p><p>Once we'd laid this groundwork, we knew that we could slowly port more and more code to Rust over time.</p><h2><span id="global-turbo"></span><a href="#global-turbo">Global <code>turbo</code></a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>We decided to have our first Rust feature be <a href="https://turbo.build/blog/turbo-1-7-0#global-turbo?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">global <code>turbo</code></a>, a feature that allows users to install Turborepo as a globally available command on their machine. </p><p>A global installation of <code>turbo</code> will look for a locally installed <code>turbo</code> program in the repository, execute it if it exists, and otherwise fallback to the global <code>turbo</code> binary. That way, you can easily run <code>turbo</code> from anywhere in your repository, but also keep a specific version of <code>turbo</code> pinned in your <code>package.json</code>.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319413.png" loading="lazy" width="1650" height="740" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2FqPT2LsrOLLG4ISEyuv92G%2F2427d2381392e4acc95dc51d1cf9edca%2FFrame_427319413.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319414.png" loading="lazy" width="1650" height="740" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2gbJI96SblT7dXxZWZDYsD%2F6877030625b5c53c3523ad96db1d468d%2FFrame_427319414.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 19.png" loading="lazy" width="414" height="647" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3DzjEq5stkry2IiCm6zh4U%2Fd5f38eda9664709a42fbbc2e8707ec74%2FiPhone_8_Plus_-_19.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 5.png" loading="lazy" width="414" height="647" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7beQhPRdj8OYxzfUcYgEbU%2Fd2e5d1a6a0d94b65231122a21672217e%2FiPhone_8_Plus_-_5.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>This feature is implemented through what we started calling "the Rust shim," a bit of Rust code that wraps the existing Go code. The Go portion is compiled via CGO as a C static library and then linked to the Rust binary. Luckily, global <code>turbo</code> only required a few features from the rest of Turborepo's code, such as reading configuration and navigating the file system. </p><h2><span id="cli-parsing"></span><a href="#cli-parsing">CLI parsing</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>As we implemented global <code>turbo</code>, we realized we needed to parse a few command line arguments like <code>--cwd</code>, the argument for setting <code>turbo</code>'s current working directory.</p><p>After global <code>turbo</code>, it made sense to continue by porting the rest of the CLI argument parser to Rust. To parse arguments, we use the <a href="https://docs.rs/clap/latest/clap/" rel="noopener" target="_blank"><code>clap</code> crate</a> (Rust’s equivalent of an npm package). <code>clap</code> lets you define a data type with the arguments, annotate it a little bit, and it will automatically create a parser.</p><p>With the pieces in place, we had to work on sending the args from the Rust entry point to the Go code. For better or worse, <a href="https://faultlore.com/blah/c-isnt-a-language/" rel="noopener" target="_blank">C is the standard for foreign function interfacing (FFI)</a>, so we had to use C to communicate between Rust and Go.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (1).png" loading="lazy" width="1920" height="1084" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2FGPm6ksIA7bGzZzY7CYkd%2F06b7d487cbcf5237ae9f917574cf7a51%2FInlineGraphic_1920xVariable__1_.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable.png" loading="lazy" width="1920" height="1084" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7sVbowOCnYSjNrOyxfD5NF%2F0fdf484cf4ced36f67e0ab879514d099%2FInlineGraphic_1920xVariable.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (3).png" loading="lazy" width="414" height="416" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1M9EpwZDGRt4PqXnS41B6p%2F0cc3e7336ee39882508a6dd112db9a5f%2FInlineGraphic_1920xVariable__3_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="InlineGraphic_1920xVariable (2).png" loading="lazy" width="414" height="416" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F7s2Gq0JKjOQkBQ9ZAOqEGw%2F4b0db3626aa7e7b7b10b95e8fdf8d631%2FInlineGraphic_1920xVariable__2_.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>We wanted to avoid having too many types in C, as we weren’t confident that we could write cross-platform C types that played well with both Rust and Go. Instead, we decided to serialize our arguments to JSON and send it to Go as a string. Even though JSON serialization does have some overhead, we knew that the arguments struct would only be a few hundred bytes in size, so the performance impact would be minimal.</p><p>On the Rust side, we used another cornerstone crate of the Rust ecosystem, <a href="https://docs.rs/serde/latest/serde/" rel="noopener" target="_blank"><code>serde</code></a>, which lets you serialize and deserialize data in various different formats, using some minimal annotation. For the Go side, we were already using JSON in the codebase, so it was easy to receive the JSON string and deserialize it into a Go struct. </p><h2><span id="ship-it"></span><a href="#ship-it">Ship it?</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>With these two features ported, we were ready to ship our first hybrid Go-Rust release.</p><p>However, before we could release, we needed to make sure the Go-Rust binary worked in all the various contexts that Turborepo is used, <a href="https://turbo.build/repo/docs/installing?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">like the different operating systems and  Linux distros that we support</a>. As we tested our code, we started noticing some issues on a couple platforms.</p><h3><span id="windows-difficulties"></span><a href="#windows-difficulties">Windows difficulties</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>On Windows, there are two main toolchains, <a href="https://en.wikipedia.org/wiki/Microsoft_Visual_C%2B%2B" rel="noopener" target="_blank">Microsoft Visual C++ (MSVC)</a> and <a href="https://en.wikipedia.org/wiki/MinGW" rel="noopener" target="_blank">Minimalist GNU for Windows (MinGW)</a>.</p><p>Go <b>only</b> uses MinGW, but we were using Rust with MSVC. This caused some runtime issues, but, luckily, the solution was simple: we moved our Rust toolchain to MinGW.</p><p>Next up, we had some issues with paths. Windows has a couple concepts of paths, including what’s called a Universal Naming Convention (UNC) path. When you ask Windows to canonicalize a path (resolve all symlinks and normalize components of the path), it gives you a UNC path.</p><p>However, despite the name, UNC paths are not supported everywhere—sometimes not even by Windows itself! This caused a few bugs where we’d provide a UNC path and get an invalid path error. The solution was to use a helpful Rust crate called <a href="https://docs.rs/dunce/latest/dunce/" rel="noopener" target="_blank">dunce</a> that lets you canonicalize a path and get a non-UNC path back, handling the intricacies of this problem for us.</p><h3><span id="alpine-linux"></span><a href="#alpine-linux">Alpine Linux</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The second set of challenges came with Alpine Linux. At Vercel, we use Alpine, a common operating system for cloud computing, to create lightweight containers for building your projects.</p><p>Alpine, though, does not come with <code>glibc</code>, the de-facto implementation of the C standard library. This is a problem because many binaries assume <code>glibc</code> is installed and don’t package it themselves. There are some libraries that pave over this issue using packages like <code>gcompat</code> or <code>libc6-compat</code>, but they didn’t end up working for us because the version of <code>glibc</code> that Rust requires was too modern for our supported targets. When we’d try to run the binary, we’d get errors that the required <code>glibc</code> version was not available.</p><p>As a result, we decided to compile Turborepo as a fully static binary. This meant that we packaged our own C standard library implementation using <code>musl</code> (since you can't statically link <code>glibc</code> due to licensing issues). This seems to work just fine for both Rust and Go: Rust lets you set the C standard library in the target (<code>aarch64-unknown-linux-musl</code> vs. <code>aarch64-unknown-linux-gnu</code>) and Go does not use a C standard library by default.</p><p>However, when we ran this statically linked binary, it would return a segmentation fault. Even worse, when we inspected with a debugger, we’d find a corrupted stack. And, even worser, the segfault appeared to be coming from the Go runtime itself!</p><hr><p>After a lot of searching, we tracked down a <a href="https://github.com/golang/go/issues/13492" rel="noopener" target="_blank">seven year-old GitHub issue</a> which explained that Go cannot be compiled as a C static library with <code>musl</code>. This posed a significant challenge, as Alpine Linux is an essential platform for Turborepo and its users. We had to go back to the drawing board and figure out how we could ship our Go-Rust combination.</p><p>Eventually, after a ton more deliberation, we came up with a solution: we’d compile our Go code and our Rust code as two separate binaries. The Rust code would call the Go code and pass the args serialized to JSON via the CLI.</p><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319412.png" loading="lazy" width="1920" height="917" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F1VOl0eTFS33pkNLbtrzhY%2F6811cbf8065443e0ba46c5c365b9fca4%2FFrame_427319412.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="Frame 427319408.png" loading="lazy" width="1920" height="917" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F3KbndugMu2gM4Nu8Eoq3dj%2F41cb0b6578dbd822c77f08f2bada4066%2FFrame_427319408.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 14.png" loading="lazy" width="414" height="506" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F5QibrcV35p6zu0Rpzriwn5%2F57872cf4a380ba9c3ec780a02c370775%2FiPhone_8_Plus_-_14.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div><div><figure data-vercel-edit-target="true"><p><img data-version="v1" alt="iPhone 8 Plus - 18.png" loading="lazy" width="414" height="506" decoding="async" data-nimg="1" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1x, https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2x" src="https://vercel.com/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fe5382hct74si%2F2547NHodIcPCgR7ITmjnM0%2F4366bba1f016889729cfc1c729554907%2FiPhone_8_Plus_-_18.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></figure></div></div><p>We knew that the args were small enough that they could be passed via CLI without too much of a performance hit. And because we were using a serialization format, the code changes were extremely small. All we had to do was change how Rust was sending the JSON string to Go.</p><p>With that, we were able to get our first hybrid Go-Rust release out the door. The first version of <code>turbo</code> that was shipped to you using these compilation strategies was <a href="https://turbo.build/blog/turbo-1-7-0?utm_source=turbo&amp;utm_medium=blog&amp;utm_campaign=turborepo_porting" rel="noopener" target="_blank">version 1.7.0</a>.</p><h2><span id="what-we-learned"></span><a href="#what-we-learned">What we learned</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>Through this effort, we've learned a lot about moving from one language to another. Let's take note of what we've found.</p><h3><span id="serialization-is-useful-for-ffi"></span><a href="#serialization-is-useful-for-ffi">Serialization is useful for FFI</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Our first takeaway is that serialization formats are very useful for interoperability. By serializing to JSON, a format with robust support in both Go and Rust, we were able to minimize our FFI surface area, and avoid a whole class of cross-platform, cross-language bugs. When we had to switch from a single, linked binary to two binaries, we were able to do so with relative ease because our FFI surface area was so small.</p><p>The tradeoff here is that serialization and deserialization is slow. You can only depend on this technique if either you know your serialized payloads will be small or you don't care about the performance hit for your use case.</p><h3><span id="porting-takes-preparation"></span><a href="#porting-takes-preparation">Porting takes preparation</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The second takeaway is that incremental porting is feasible but requires lots of careful testing and strategizing. We ran into quite a few tricky bugs and we caught these issues through lots of automated and manual testing. You can <a href="https://github.com/vercel/turbo/tree/main/.github/workflows" rel="noopener" target="_blank">check out our (and Turbopack's) testing suites in our GitHub workflows</a>.</p><p>Testing is also extremely important for nailing down the behavior of your code, whether it’s the exact edge cases of CLI parsing, or the order in which configuration is loaded. These exact details are not so crucial when you’re writing your first implementation, but they’re absolutely paramount to avoid breaking changes during a port or rewrite. You should aim to write tests <b>before</b> you start porting code, so that you have a known specification to work against.</p><h3><span id="cross-compatibility-is-difficult"></span><a href="#cross-compatibility-is-difficult">Cross-compatibility is difficult</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>The third takeaway is that cross-platform, cross-language release engineering is extremely challenging. Every platform, language, and compiler has their own quirks that can make interoperability difficult and, the more things you have working together, the more opportunities you have for a new complication.</p><h3><span id="porting-is-worth-it-for-us"></span><a href="#porting-is-worth-it-for-us">Porting is worth it for us</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h3><p>Finally, while porting from Go to Rust has been challenging, it has proven to be the correct choice for us strategically. Even with our porting effort going on, we've been able to ship new features, handle bugs in existing functionality, and keep helping our users while we migrate. It's required some extraordinarily tricky debugging, careful planning, and rigorous testing, but we believe it has been worth it.</p><h2><span id="try-out-(ported)-turborepo"></span><a href="#try-out-(ported)-turborepo">Try out (ported) Turborepo</a><span><svg data-testid="geist-icon" fill="none" height="24" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" viewBox="0 0 24 24" width="24" style="color:currentColor;width:0.75em;height:0.75em"><path d="M10 13a5 5 0 007.54.54l3-3a5 5 0 00-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 00-7.54-.54l-3 3a5 5 0 007.07 7.07l1.71-1.71"></path></svg></span></h2><p>This week, Turborepo saved 5,742 hours of time for the product engineers and CI machines at Vercel. If you want to try out the same technology in just a few minutes, <a href="https://vercel.com/blog/vercel-remote-cache-turbo" rel="noopener" target="_blank">check out our article</a> on how you can get started with <a href="https://vercel.com/docs/concepts/monorepos/remote-caching" rel="noopener" target="_blank">Vercel Remote Cache</a>.</p><div><p data-version="v1">Explore more</p><div><a href="https://vercel.com/templates/next.js/turborepo-next-basic"><div><p><img data-version="v1" alt="Screenshot of template" loading="lazy" decoding="async" data-nimg="fill" sizes="25vw" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=256&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 256w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=384&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 384w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 640w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=750&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 750w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 828w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1080&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1080w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1200&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1200w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1920w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=2048&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2048w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 3840w" src="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F2JxNyYATuuV7WPuJ31kF9Q%2F433990aa4c8e7524a9095682fb08f0b1%2FBasic.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></div></a><a href="https://turbo.build/" rel="noopener" target="_blank"><div><p><img data-version="v1" alt="Visit turbo.build" loading="lazy" decoding="async" data-nimg="fill" sizes="25vw" srcset="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=256&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 256w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=384&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 384w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=640&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 640w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=750&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 750w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=828&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 828w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1080&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1080w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1200&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1200w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=1920&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 1920w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=2048&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 2048w, https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy 3840w" src="https://vercel.com/_next/image?url=https%3A%2F%2Fassets.vercel.com%2Fimage%2Fupload%2Fcontentful%2Fimage%2Fe5382hct74si%2F6AXDBERJ8a3qkQkJbDMojJ%2F47691b985c3f224b0e2742564a3a5ef1%2FCleanShot_2023-07-13_at_14.50.43_2x.png&amp;w=3840&amp;q=75&amp;dpl=dpl_BU9DYiunKC5XdoQeFV1hJ8Zr4LDy"></p></div></a></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dementia risk linked to blood-protein imbalance in middle age (302 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-023-02374-2</link>
            <guid>36813564</guid>
            <pubDate>Fri, 21 Jul 2023 13:34:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-023-02374-2">https://www.nature.com/articles/d41586-023-02374-2</a>, See on <a href="https://news.ycombinator.com/item?id=36813564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <figure>
 <picture>
  <source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px">
  <img alt="Visualization showing a brain affected by Alzheimer's disease." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25825424.jpg">
  <figcaption>
   <p><span>A slice through the brain of a person with Alzheimer’s disease, the most common cause of dementia.</span><span>Credit: Anatomical Travelogue/Science Photo Library</span></p>
  </figcaption>
 </picture>
</figure><p>A study that followed thousands of people over 25 years has identified proteins linked to the development of dementia if their levels are unbalanced during middle age.</p><p>The findings, published in <i>Science Translational Medicine </i>on 19 July<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>, could contribute to the development of new diagnostic tests, or even treatments, for dementia-causing diseases.</p><p>Most of the proteins have functions unrelated to the brain.</p><p>“We’re seeing so much involvement of the peripheral biology decades before the typical onset of dementia,” says study author Keenan Walker, a neuroscientist at the US National Institute on Aging in Bethesda, Maryland.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-023-00954-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_25434040.jpg"><p>Conquering Alzheimer’s: a look at the therapies of the future</p></a>
 </article><p>Equipped with blood samples from more than 10,000 participants, Walker and his colleagues questioned whether they could find predictors of dementia years before its onset by looking at a person’s proteome — the collection of all the proteins expressed throughout the body. They searched for any signs of dysregulation — when proteins are at levels much higher or lower than normal.</p><p>The samples were collected as part of an ongoing study that began in 1987. Participants returned for examination six times over three decades, and during this time, around 1 in 5 of them developed dementia.</p><p>The researchers found 32 proteins that, if dysregulated in people aged 45 to 60, were strongly associated with an elevated chance of developing dementia in later life. It is unclear how exactly these proteins might be involved in the disease, but the link is “highly unlikely to be due to just chance alone”, says Walker.</p><p>“Not all the proteins showed changes in both plasma and brain tissues,” says Nicholas Seyfried, a biochemist and neurologist at Emory University in Atlanta, Georgia. For example, one of the proteins found with the strongest association with dementia risk — called GDF15 — was not detected in the brain, suggesting that “mechanisms below the neck could also play a role”, he adds.</p><p>Walker says that although a person’s proteome by itself cannot predict their risk of getting dementia, it could perhaps bolster the strength of existing predictors — such as age and family history.</p><h2>Protein balance</h2><p>As expected, some of the proteins that researchers identified are active in the brain — but most have other roles in the body. A handful were linked to proteostasis — the process of carefully balancing protein levels in the proteome.</p><p>This regulation is important in preventing proteins from going rogue and clumping together, which is what happens to the amyloid and tau proteins in the brains of people with Alzheimer’s disease, the most common cause of dementia.</p><article data-label="Related">
  <a href="https://www.nature.com/news/how-to-defeat-dementia-1.20949" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-023-02374-2/d41586-023-02374-2_15713358.jpg"><p>How to defeat dementia</p></a>
 </article><p>The study found altered levels of many of the proteins both in the brain tissues of those who had died with Alzheimer’s disease, and in the blood of those still living with it. These were associated with the presence of amyloid and tau proteins, which suggests they are somehow involved in processes specific to the disease.</p><p>Other proteins identified in the study were linked to the immune system, adding to “growing evidence for the role of innate and adaptive immune function in dementia”, says Jin-Tai Yu, a physician-scientist who specializes in dementia at Fudan University in Shanghai, China. Yu and his team have previously found that people with immune diseases are more vulnerable to Alzheimer’s later in life<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>.</p><p>There is still a long way to go in understanding exactly how any of these proteins fit into the physiology of dementia, and a much better understanding of the underlying mechanisms is needed before people can benefit. Such insights “could potentially open doors for early interventions”, says Seyfried. For Walker, the aim in future is to determine whether these proteins could potentially be used as markers to identify various dysregulated pathways in people with dementia and to help provide more personalized treatments.</p>
                </div><div id="references" aria-labelledby="Bib1"><h2 id="Bib1">References</h2></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[90s Internet: When 20 hours online triggered an email from my ISP’s president (195 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/</link>
            <guid>36813210</guid>
            <pubDate>Fri, 21 Jul 2023 12:56:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/">https://arstechnica.com/gadgets/2023/07/the-90s-internet-when-20-hours-online-triggered-an-email-from-my-isps-president/</a>, See on <a href="https://news.ycombinator.com/item?id=36813210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/07/banj-edwards-terminally-online2-800x450.jpg" alt="The ‘90s Internet: When 20 hours online triggered an email from my ISP’s president">
      <figcaption><p>Banj Edwards | Aurich Lawson | Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 288:single/related:a53e128e87d5db82176cc5af52b3d616 --><!-- empty -->
<p>"When checking the system this morning, I noticed your account logged in for over 20 hours," begins a December 1998 email from the president of my dial-up Internet service provider (ISP) at the time. "Our service is unlimited, but we ask that you actually be using the connection while logged in."</p>

<p>Today, when it seems like everyone is online 24/7 through smartphones and broadband, I'd be weird if I <em>wasn't online</em> for 20 hours straight. But 1998 in Raleigh, North Carolina, was different. In an age of copper telephone lines and dial-up modems, Internet access wasn't usually an always-on situation for a home user in the US. Each occupied telephone line meant another ISP customer couldn't use it—and no one could call you, either.</p>
<p>But I'm getting ahead of myself—why do I have an email from 1998?</p>
<h2>A voice from the past</h2>

<p>I save everything. It's just <a href="https://www.pcmag.com/news/gear-envy-my-collection-of-500-plus-pieces-of-computer-and-gaming-hardware">what I do</a>.</p>
<p>Being an amateur data archivist has served me well during my <a href="https://benjedwards.com/works.php">career</a> writing about tech. About eight years ago, I decided to search my archives for old email files and import them all into Apple Mail for OS X, organizing them chronologically so I could look at them all in one place. I found Internet emails going as far back as 1995, when I started using a POP3 client instead of <a href="https://en.wikipedia.org/wiki/Pine_(email_client)">Pine</a>. While browsing emails from 1998, I found a curious nugget from another era that blew me away.</p>
<blockquote><p>From: Eugene J. Fourney III<br>
Date: December 18, 1998 11:21 AM<br>
Subject: Online for 20 hours straight</p>
<p>Thank you for allowing NetWorks to provide Internet service.</p>
<p>I am writing because when checking the system this morning, I<br>
noticed your account logged in for over 20 hours.</p>
<p>Our service is unlimited, but we ask that you actually be using the<br>
connection while logged in. This has not been the case on occasion with<br>
your account.</p>
<p>We must ask that you take measures to ensure that you disconnect after<br>
any given session. Our resources must be shared between many customers,<br>
and the only way to accomplish that is for people to close the<br>
connection when they are not actively using it.</p>
<p>Please help with this by checking your dialer settings, and setting it<br>
to disconnect after 30 minutes of inactivity. Please also uncheck the<br>
option in your email program that automatically checks mail every 10<br>
minutes, or set it to some number higher than 30 minutes.</p>
<p>If you need help in locating these settings or want to discuss this<br>
further, please contact me at this email address or at our offices at<br>
518-0351 or 518-8034.</p>
<p>Gene Fourney</p></blockquote>
<p>I vaguely remember getting this email and thinking it was ridiculous because the connection was supposedly "unlimited." My family paid NetWorks a monthly fee (a $24.95 "Family Plan" for three user IDs) that allowed me, my dad, and my brother to connect to the Internet as much as we wanted—or so I thought. I showed the email to my father, who shrugged it off.</p>                                            
                                                        

<p>Between 1995 and 2000, I used a dial-up ISP, which meant that I had to call in to the ISP using a regular copper phone line and a dial-up modem running at anywhere between 14.4Kbps to 56Kbps over the years. Since most people also used their telephone lines for talking with their voice, there was a basic assumption that most calls to the ISP would be temporary. If your line was occupied, you would miss incoming calls. In my situation, my parents had set up a second phone line exclusively for my BBS in 1993 so I could spend as much time online as necessary without worrying about blocking incoming phone calls to my family.</p>
<p>A key issue I had with the email was the implication that I wasn't using my Internet connection during those 20 hours. I'm pretty sure I was using it, and not just for automatically checking my email every 30 minutes, as the email suggests.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Primo – a visual CMS with Svelte blocks, a code editor, and SSG (274 pts)]]></title>
            <link>https://primocms.org</link>
            <guid>36813086</guid>
            <pubDate>Fri, 21 Jul 2023 12:38:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://primocms.org">https://primocms.org</a>, See on <a href="https://news.ycombinator.com/item?id=36813086">Hacker News</a></p>
<div id="readability-page-1" class="page">

    
    <div id="section-885d7628">
        <header>
            
            <div>
                <h2><!-- HTML_TAG_START -->
                    <p>Primo is a visual CMS that makes it a blast to build <strong>pages</strong>, manage <strong>content</strong>, and edit <strong>code</strong> - one block at a time.</p><!-- HTML_TAG_END -->
                </h2>


                
            </div>
            <div>
                <figure><iframe src="https://player.vimeo.com/video/838469641?h=df40df2d2c&amp;badge=0&amp;loop=1&amp;autopause=0&amp;player_id=0&amp;autoplay=1&amp;muted=1&amp;loop=1&amp;title=0&amp;sidedock=0&amp;controls=&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen="" title="Landing Page Demo"></iframe></figure>
                
            </div>
        </header>

    </div>
    <section id="section-ddd59217">
            <header>
                <h2>The modern monolithic CMS</h2>
                <h3>Primo combines delightful content management with the power of modern development</h3>
            </header>
            <div>
                <div>
                    <div>
                        <h2>Drag-n-drop page building</h2>
                        <p>Build your site's pages by dragging and dropping your directly blocks onto the page, unencumbered by overwhelming design options.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/1682111950401Screen%20Shot%202023-04-21%20at%205.17.27%20PM.png" alt=""></figure>
                </div>
                <div>
                    <div>
                        <h2>Visual content editing</h2>
                        <p>Update your text, images, and links directly on the page or open up the Fields view to manage your content from a structured view.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/Screen%20Shot%202023-04-21%20at%205.22.39%20PM.png1682112222228" alt=""></figure>
                </div>
                <div>
                    <div>
                        <h2>Integrated development</h2>
                        <p>Access each block's code with a click - right from your browser. And since each block is a <a href="https://svelte.dev/">Svelte</a> component, there's no limit to what you can make.</p>
                    </div>
                    <figure><img src="https://kdtzsoeklezpgshpzqtf.supabase.co/storage/v1/object/public/images/7c1dc1a3-c9eb-4364-b31b-951ecfc2641d/Screen%20Shot%202023-04-21%20at%205.25.06%20PM.png1682112330379" alt=""></figure>
                </div>
            </div>
        </section>
    <div id="section-d294b81b">
                <ul>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 256 256"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="m213.66 66.34l-40-40A8 8 0 0 0 168 24H88a16 16 0 0 0-16 16v16H56a16 16 0 0 0-16 16v144a16 16 0 0 0 16 16h112a16 16 0 0 0 16-16v-16h16a16 16 0 0 0 16-16V72a8 8 0 0 0-2.34-5.66ZM136 192H88a8 8 0 0 1 0-16h48a8 8 0 0 1 0 16Zm0-32H88a8 8 0 0 1 0-16h48a8 8 0 0 1 0 16Zm64 24h-16v-80a8 8 0 0 0-2.34-5.66l-40-40A8 8 0 0 0 136 56H88V40h76.69L200 75.31Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Static Sites<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Your websites are secure, scalable to millions, and fast-loading - no fancy plugins necessary.</p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9A3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42c-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3a3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3a3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.536 5.536 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13v-1.75M0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9c-.59.68-.95 1.62-.95 2.65V20H0m24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65c2.56.34 4.45 1.51 4.45 2.9V20Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Real-time collaboration<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Invite any number of collaborators as developers or content editors and edit your pages together. </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path fill-rule="evenodd" d="M14 7a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1h-4Zm3 2h-2v6h2V9Z" clip-rule="evenodd"></path>
                                    <path d="M6 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H6Zm0 4a1 1 0 1 0 0 2h4a1 1 0 1 0 0-2H6Zm-1 5a1 1 0 0 1 1-1h4a1 1 0 1 1 0 2H6a1 1 0 0 1-1-1Z"></path>
                                    <path fill-rule="evenodd" d="M4 3a3 3 0 0 0-3 3v12a3 3 0 0 0 3 3h16a3 3 0 0 0 3-3V6a3 3 0 0 0-3-3H4Zm16 2H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V6a1 1 0 0 0-1-1Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Multisite to the max<!-- HTML_TAG_END --></span>
                        </h3>
                        <p data-key="items[2].description"><!-- HTML_TAG_START -->
                            <h2>Create an unlimited number of websites on a single server and start new sites in seconds.</h2><!-- HTML_TAG_END -->
                        </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <path fill="currentColor" d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5c.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34c-.46-1.16-1.11-1.47-1.11-1.47c-.91-.62.07-.6.07-.6c1 .07 1.53 1.03 1.53 1.03c.87 1.52 2.34 1.07 2.91.83c.09-.65.35-1.09.63-1.34c-2.22-.25-4.55-1.11-4.55-4.92c0-1.11.38-2 1.03-2.71c-.1-.25-.45-1.29.1-2.64c0 0 .84-.27 2.75 1.02c.79-.22 1.65-.33 2.5-.33c.85 0 1.71.11 2.5.33c1.91-1.29 2.75-1.02 2.75-1.02c.55 1.35.2 2.39.1 2.64c.65.71 1.03 1.6 1.03 2.71c0 3.82-2.34 4.66-4.57 4.91c.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"></path><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Deploy to Github<!-- HTML_TAG_END --></span>
                        </h3>
                        <p data-key="items[3].description"><!-- HTML_TAG_START -->
                            <h2 id="deployyoursitetoagithubrepositoryfromthereyoucaneasilydeployittoanywebhost">Deploy your site to a Github repository. From there you can easily deploy it to any web host.</h2><!-- HTML_TAG_END -->
                        </p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path fill-rule="evenodd" d="M14 7a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h4a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1h-4Zm3 2h-2v6h2V9Z" clip-rule="evenodd"></path>
                                    <path d="M6 7a1 1 0 0 0 0 2h4a1 1 0 1 0 0-2H6Zm0 4a1 1 0 1 0 0 2h4a1 1 0 1 0 0-2H6Zm-1 5a1 1 0 0 1 1-1h4a1 1 0 1 1 0 2H6a1 1 0 0 1-1-1Z"></path>
                                    <path fill-rule="evenodd" d="M4 3a3 3 0 0 0-3 3v12a3 3 0 0 0 3 3h16a3 3 0 0 0 3-3V6a3 3 0 0 0-3-3H4Zm16 2H4a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h16a1 1 0 0 0 1-1V6a1 1 0 0 0-1-1Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->
                                Themes
                                <!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Hit the ground running with one of Primo's free themes and customize it in seconds using CSS variables.</p>
                    </li>
                    <li>
                        <h3><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                                <g fill="currentColor">
                                    <path d="M8.51 2h6.98c.232 0 .41 0 .566.015c1.108.109 2.015.775 2.4 1.672H5.544c.385-.897 1.292-1.563 2.4-1.672C8.098 2 8.276 2 8.51 2Zm-2.2 2.723c-1.39 0-2.53.84-2.91 1.954a2.587 2.587 0 0 0-.024.07c.398-.12.813-.2 1.232-.253c1.08-.139 2.446-.139 4.032-.139h6.892c1.586 0 2.951 0 4.032.139c.42.054.834.132 1.232.253a2.173 2.173 0 0 0-.023-.07c-.38-1.114-1.52-1.954-2.911-1.954H6.31Z"></path>
                                    <path fill-rule="evenodd" d="M8.672 7.542h6.656c3.374 0 5.062 0 6.01.987c.947.987.724 2.511.278 5.56l-.422 2.892c-.35 2.391-.525 3.587-1.422 4.303c-.897.716-2.22.716-4.867.716h-5.81c-2.646 0-3.97 0-4.867-.716c-.897-.716-1.072-1.912-1.422-4.303l-.422-2.891c-.447-3.05-.67-4.574.278-5.561c.948-.987 2.636-.987 6.01-.987ZM8 18c0-.414.373-.75.833-.75h6.334c.46 0 .833.336.833.75s-.373.75-.833.75H8.833c-.46 0-.833-.336-.833-.75Z" clip-rule="evenodd"></path>
                                </g><!-- HTML_TAG_END -->
                            </svg>
                            <span><!-- HTML_TAG_START -->Primo Library<!-- HTML_TAG_END --></span>
                        </h3>
                        <p>Access a growing library of pre-built blocks which automatically adapt to your site's design.</p>
                    </li>
                </ul>

                </div>
    <div id="section-3d86c4f7">
                <h2>Spin up speedy, secure, scalable static sites in seconds.</h2>
                <p><!-- HTML_TAG_START -->
                    <h2>Set up your own Primo server in under 5 minutes and manage unlimited sites with ease. Don't want to manage your own server? Try Primo Cloud for free.</h2><!-- HTML_TAG_END -->
                </p>
                <p><a href="https://docs.primocms.org/getting-started"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 512 512"><!-- HTML_TAG_START -->
                            <ellipse cx="256" cy="128" fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" rx="192" ry="80"></ellipse>
                            <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M448 214c0 44.18-86 80-192 80S64 258.18 64 214m384 86c0 44.18-86 80-192 80S64 344.18 64 300"></path>
                            <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M64 127.24v257.52C64 428.52 150 464 256 464s192-35.48 192-79.24V127.24"></path><!-- HTML_TAG_END -->
                        </svg>
                        Self-host
                    </a>
                    <a href="https://primocms.org/cloud"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="" role="img" width="1em" height="1em" viewBox="0 0 24 24"><!-- HTML_TAG_START -->
                            <path fill="currentColor" d="M12 6c2.62 0 4.88 1.86 5.39 4.43l.3 1.5l1.53.11A2.98 2.98 0 0 1 22 15c0 1.65-1.35 3-3 3H6c-2.21 0-4-1.79-4-4c0-2.05 1.53-3.76 3.56-3.97l1.07-.11l.5-.95A5.469 5.469 0 0 1 12 6m0-2C9.11 4 6.6 5.64 5.35 8.04A5.994 5.994 0 0 0 0 14c0 3.31 2.69 6 6 6h13c2.76 0 5-2.24 5-5c0-2.64-2.05-4.78-4.65-4.96A7.49 7.49 0 0 0 12 4z"></path><!-- HTML_TAG_END -->
                        </svg>
                        Primo Cloud
                    </a>
                </p>
            </div>
    <section id="section-dbc84ff9">
            <h2>Frequently Asked Questions</h2>
            <div><p>Primo is under full-time development and is in the process of becoming a nonprofit organization. Any funds generated from White Glove and Cloud will go towards funding further development, in the same vein as <a href="https://ghost.org/">Ghost CMS</a>.</p>
                    
                </div>
        </section>
    <div id="section-b18b744b">
                <div>
                    <h2>Hear about future updates, including:</h2>
                    <h3><!-- HTML_TAG_START -->
                        <ul>
                            <li>
                                <p><strong>Using it headless</strong> alongside SvelteKit, NextJS, etc.</p>
                            </li>
                            <li>
                                <p><strong>Design fields</strong> to give content editors predefined style options.</p>
                            </li>
                            <li>
                                <p><strong>Cloud functions</strong> for writing backend code from Primo.</p>
                            </li>
                        </ul><!-- HTML_TAG_END -->
                    </h3>
                </div>
                <div>
                    
                    <p><img src="https://track.mailerlite.com/webforms/o/5039306/j2m2z7?v1637419080" width="1" height="1" alt=".">
                </p></div>
                
                
            </div>
    

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tell HN: Upgrade your Metabase installation immediately (196 pts)]]></title>
            <link>https://github.com/metabase/metabase/releases/tag/v0.46.6.1</link>
            <guid>36812256</guid>
            <pubDate>Fri, 21 Jul 2023 10:45:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/metabase/metabase/releases/tag/v0.46.6.1">https://github.com/metabase/metabase/releases/tag/v0.46.6.1</a>, See on <a href="https://news.ycombinator.com/item?id=36812256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p><strong>Upgrade your Metabase installation IMMEDIATELY.</strong></p>
<p>A recently discovered security vulnerability almost certainly affects you, and we recommend you upgrade your Metabase Installation right away.</p>
<p><strong>Upgrading</strong></p>
<p>You can download a .jar of the release, or get the latest on Docker. Make sure to back up your Metabase<br>
database before you upgrade! Need help? Check out our<br>
<a href="https://metabase.com/docs/latest/operations-guide/upgrading-metabase.html" rel="nofollow">upgrading instructions</a>.</p>
<p>Docker image: <code>metabase/metabase:v0.46.6.1</code><br>
Download the JAR here: <a href="https://downloads.metabase.com/v0.46.6.1/metabase.jar" rel="nofollow">https://downloads.metabase.com/v0.46.6.1/metabase.jar</a></p>
<p><strong>Notes</strong></p>
<p>SHA-256 checksum for the v0.46.6.1 JAR:</p>
<div data-snippet-clipboard-copy-content="12d267bf515a238944bb65fceed1ef83f5ae63451c11ad5b7f7adbeaf612e5c6"><pre><code>12d267bf515a238944bb65fceed1ef83f5ae63451c11ad5b7f7adbeaf612e5c6
</code></pre></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Small joys of programming in Odin (118 pts)]]></title>
            <link>http://www.zannzen.com/blog/small_joys_with_odin_1/</link>
            <guid>36812175</guid>
            <pubDate>Fri, 21 Jul 2023 10:30:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.zannzen.com/blog/small_joys_with_odin_1/">http://www.zannzen.com/blog/small_joys_with_odin_1/</a>, See on <a href="https://news.ycombinator.com/item?id=36812175">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Update (2023-07-21): I was being a bit overly brief with liberal use of <code>...</code> to mean “unimportant” in the code examples. Ginger Bill (creator of Odin) noted it might be clearer to have more correct/explicit Odin and Zig code for the examples given people would be less familiar. Those has been updated</em></p>
<p>For the past few months I’ve been using the programming language <a href="http://odin-lang.org/">Odin</a> in my spare time regularly. I’ve been off and on with it for a year or so but after this past year’s Advent of Code I decided to stick with it. Briefly, Odin is a C-like language that is data-oriented and pragmatic. Or as the website says “The Data-Oriented Language for Sane Software Development”. In my mind, the reason I’ve enjoyed it so much is: it’s the systems programming language with the fewest “wtf"s I’ve experienced so far<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. In fact one of Odin’s guiding principles is “The Joy of Programming” and after getting the basics down, I’ve found Odin to be pretty intuitive.</p>
<p>On that note, this post is a showcase of a couple features that brought me small moments of joy while using the language. I’m not going to do a full overview of Odin – if you want that the <a href="http://odin-lang.org/docs/overview/">overview</a>, <a href="https://github.com/odin-lang/Odin/blob/master/examples/demo/demo.odin">demo.odin</a>, and <a href="https://pkg.odin-lang.org/">package docs</a> have you covered – instead I’m going to explain some small pain points I’ve had with other languages and then explain how Odin removed those minor pains.</p>
<p>While there isn’t anything super technical in here, I’m probably assuming some knowledge and I do swap between three different languages to show examples (Odin, C++, and Zig). A general programming background might be helpful to see the structure over the details.</p>
<hr>
<h2 id="overview">Overview</h2>
<p>Odin has a number of built-in quality of life features that enhances day to day coding: <a href="http://odin-lang.org/docs/overview/#bit-sets">bit_sets</a> for flags (which work when interop-ing with C!), or <a href="http://odin-lang.org/docs/overview/#array-programming">array programming</a> which makes anything graphics related very nice. The language doesn’t have everything – the big example being there’s no compile-time execution of functions – but the features it does have are well integrated. Below are just two smaller features that led to moments where I thought “that’s fantastic.”</p>
<h2 id="caller_locationhttpodin-langorgdocsoverviewcaller_location"><a href="http://odin-lang.org/docs/overview/#caller_location">#caller_location</a></h2>
<p>Odin has the compiler directive <code>#caller_location</code> which, as the name suggests, creates a struct containing the current file name, procedure name, line, and column of the caller of a procedure (proc). The type is <a href="https://pkg.odin-lang.org/core/runtime/#Source_Code_Location">Source_Code_Location</a> and, as with all of Odin’s built-in types, you can find its definition in the <a href="https://github.com/odin-lang/Odin/blob/master/core/runtime/core.odin#L291C1-L291C1">runtime</a> package. <code>#caller_location</code> isn’t just an afterthought: Odin’s core collection (what Odin calls its standard library) uses it in most allocations, asserts, or logging. It’s fairly well integrated.</p>
<p>For your own procs, you can capture caller information by assigning <code>#caller_location</code> to an argument like so:</p>
<div><pre tabindex="0"><code data-lang="odin"><span><span><span>// odin calls functions procedures
</span></span></span><span><span><span></span>some_procedure <span>::</span> <span>proc</span>(x, y<span>:</span> <span>int</span>, loc <span>:=</span> <span>#caller_location</span>) {}
</span></span></code></pre></div><p>You can then pass the location information on to downstream proc calls if you want.</p>
<p>For a while the directive sat resoundly in my “…neat” category. I could see how maybe it would be nice to have when you want it. But also I figured it’s essentially just <code>__LINE__</code> and the like from C… so I promptly ignored it.</p>
<p>Until I was writing some tests<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> while following along with <a href="https://interpreterbook.com/">Writing an Interpreter in Go</a></p>
<h3 id="small-annoyances-when-testing-in-c3">Small annoyances when testing in C++<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></h3>
<p>When writing tests in C++ (and other languages), often times you want to verify the state of some object multiple times in a test. Perhaps the type has many values or you’re trying to assert some invariant between the members. Maybe you just want your test framework to tell you which member had the incorrect value rather than the struct as a whole. When the combinations of values to check start getting large you might write a helper check function that asserts the validity. The following is a stripped down example<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> (i.e. don’t expect it to compile):</p>
<div><pre tabindex="0"><code data-lang="cpp"><span><span><span>// C++
</span></span></span><span><span><span></span><span>struct</span> <span>Quotes</span> {
</span></span><span><span>    <span>int32_t</span> bid_price;
</span></span><span><span>    <span>int32_t</span> bid_size;
</span></span><span><span>    <span>int32_t</span> ask_price;
</span></span><span><span>    <span>int32_t</span> ask_size;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>void</span> <span>assert_quotes_safe</span>(<span>const</span> Quotes <span>&amp;</span>quote, <span>const</span> Safeties <span>&amp;</span>safeties) {
</span></span><span><span>    <span>if</span> (quote.bid_price <span>&lt;</span> <span>0</span> <span>&amp;&amp;</span> quote.ask_price <span>&lt;</span> <span>0</span>) {
</span></span><span><span>        <span>// requires writing an `operator&lt;&lt;` overload for Quotes
</span></span></span><span><span><span></span>        <span>// this is apparently how you send error strings to the test framework for gtest
</span></span></span><span><span><span></span>        EXPECT_TRUE(false) <span>&lt;&lt;</span> <span>"Quotes had negative prices: "</span> <span>&lt;&lt;</span> quote;
</span></span><span><span>        ASSERT_TRUE(false); <span>// exits the test case immediately
</span></span></span><span><span><span></span>    }
</span></span><span><span>    
</span></span><span><span>    EXPECT_TRUE(quote.bid_price <span>&lt;=</span> quote.ask_price);
</span></span><span><span>    EXPECT_TRUE(quote.bid_price <span>*</span> quote.bid_size <span>&lt;=</span> safeties.max_dollars);
</span></span><span><span>    <span>// more checks
</span></span></span><span><span><span></span>}
</span></span><span><span>
</span></span><span><span>TEST(TestSomeQuoteGeneration) {
</span></span><span><span>    <span>// setup
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// trigger a quote gen
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// do some follow up that may or may not gen new quote
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>}
</span></span></code></pre></div><p>When <code>TestSomeQuoteGeneration</code> fails, the test framework will print out something similar to:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>TestSomeQuoteGeneration - test.cpp:13:assert_quotes_safe Quotes had negative prices: bid_price <span>=</span> ....
</span></span></code></pre></div><p>That is it prints the line where the <code>EXPECT()</code> failed. The issue is every test now fails in the <code>assert_quotes_safe</code> function and you need to go figure out where exactly the failure came from. With C++ you can usually run the test in gdb and then just step up one frame when the test fails. Unless you’ve been compiling with undefined behavior sanitizer (ubsan) in which case your debug information is useless and you have to recompile the entire project (thankfully there’s ccache).</p>
<p>There are definitely solutions to this problem. You could have <code>assert_quotes_safe</code> return a bool or error enum and then have an additional <code>ASSERT_TRUE(assert_quotes_safe(...))</code> in the calling code. Again we aren’t discussing a massive issue here. It’s a small pain point you have to do a little more work for, plan for ahead of time, and/or add something at all locations you call <code>assert_quotes_safe</code>.</p>
<h3 id="a-small-joy-when-testing-in-odin">A small joy when testing in Odin</h3>
<p>Odin, like many modern languages, has built-in testing support. To add a test you use the attribute <code>@(test)</code> on any procedure. To make code organization slightly easier, Odin detects when a filename ends with <code>_test.odin</code> and will drop those files during a normal build. Odin also has a core package called <a href="https://pkg.odin-lang.org/core/testing/">testing</a> which contains a number of useful utilities.</p>
<p>If you’re familiar with Go, the code will look very familiar.</p>
<div><pre tabindex="0"><code data-lang="odin"><span><span><span>// Odin
</span></span></span><span><span><span></span><span>package</span> some_financial_thing
</span></span><span><span>
</span></span><span><span><span>import</span> <span>"core:testing"</span>
</span></span><span><span>
</span></span><span><span>Quotes <span>::</span> <span>struct</span> {
</span></span><span><span>    bid_price, bid_size, ask_price, ask_size<span>:</span> <span>i32</span>,
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>// this code is even nicer after https://github.com/odin-lang/Odin/pull/2597
</span></span></span><span><span><span></span>assert_quotes_safe <span>::</span> <span>proc</span>(t<span>:</span> <span>^</span>testing.T, quotes<span>:</span> Quotes, safeties<span>:</span> Safeties, loc <span>:=</span> <span>#caller_location</span>) {
</span></span><span><span>    <span>if</span> quotes.ask_price <span>&lt;</span> <span>0</span> <span>&amp;&amp;</span> quotes.bid_price <span>&lt;</span> <span>0</span> {
</span></span><span><span>        testing.errorf(t, <span>"quotes had negative prices: %#v"</span>, quotes, loc <span>=</span> loc)
</span></span><span><span>        testing.fail_now(t, loc <span>=</span> loc) <span>// returns from test immediately
</span></span></span><span><span><span></span>    }
</span></span><span><span>    
</span></span><span><span>    testing.expect(t, quotes.bid_price <span>&lt;=</span> quotes.ask_price, loc <span>=</span> loc)
</span></span><span><span>    testing.expect(t, quotes.bid_price <span>*</span> quotes.bid_size <span>&lt;=</span> safeties.max_dollars, loc <span>=</span> loc)
</span></span><span><span>    <span>// more tests
</span></span></span><span><span><span></span>}
</span></span><span><span>
</span></span><span><span><span>@(test)</span>
</span></span><span><span>test_some_quote_genration <span>::</span> <span>proc</span>(t<span>:</span> <span>^</span>testing.T) {
</span></span><span><span>    <span>// setup
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// send some trigger
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>    <span>// do some follow up that may or may not gen new quote
</span></span></span><span><span><span></span>    assert_quotes_safe(current_quotes, safeties);
</span></span><span><span>}
</span></span></code></pre></div><p>The procedures in the testing package such as <code>expect_value</code> or <code>errorf</code> all have a <code>loc := #caller_location</code> argument. By passing the location information we captured, we’ll get a more useful error message on failures such as:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>test.odin:<span>(</span>27:5<span>)</span> - quotes had negative prices: Quotes<span>{</span>bid_price <span>=</span> ...<span>}</span>
</span></span></code></pre></div><p>The line number is where we actually call <code>assert_quotes_safe</code>! So now we can just set our breakpoint before the second call to <code>assert_quotes_safe</code> rather than spending time figuring out which one it was.</p>
<p>Again, this isn’t massive. But given the amount I’ve had to trace back tests before it’s very welcome.</p>
<h2 id="disabled--conditionhttpsodin-langorgdocsoverviewdisabledboolean"><a href="https://odin-lang.org/docs/overview/#disabledboolean">@(disabled = &lt;condition&gt;)</a></h2>
<p>I’ve used a few C / C++ replacement languages that don’t have macros. I’m always pretty happy with the result. Even in C++ I try to avoid writing macros unless I actually have to (constexpr all the things!). <a href="https://ziglang.org/">Zig</a> was the first C replacement I tried and I immediately loved its <code>comptime</code> (compile time evaluation/execution). It was essentially everything I wanted from C++ and then some but in a simpler form<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>. The fact Zig can create an <a href="https://zig.news/kristoff/struct-of-arrays-soa-in-zig-easy-in-userland-40m0">SoA</a> type in userspace with comptime is amazing. If I were actively using Zig at work I’d be very happy<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</p>
<p>But there are certain things I’m used to from C++ that are a pain in most of these languages that don’t have macros. The immediate example that never really has a good solution is logging.</p>
<h3 id="a-brief-look-at-logging">A brief look at logging</h3>
<p>Just a brief talk on why logging is a prime example - logging is <em>expensive</em>. Even fast logging frameworks still require time to copy data onto some queue so another thread can do the formatting. On the other hand, having debug logs in your code is fantastic for debugging (shocker). To balance that, you want some system to enable or disable debug logging at build time. In C++ you’d do this with macros. Note I’m leaving a lot of the code as <code>...</code> for brevity and because it’s irrelevant to the point.</p>
<div><pre tabindex="0"><code data-lang="cpp"><span><span><span>enum</span> <span>class</span> <span>LogLevel</span> {
</span></span><span><span>    Debug,
</span></span><span><span>    Info
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>void</span> <span>log_something</span>(LogLevel level, ...);
</span></span><span><span>
</span></span><span><span><span>#ifndef LOG_LEVEL_DEBUG
</span></span></span><span><span><span>#define LOG_DEBUG(...)
</span></span></span><span><span><span>#else
</span></span></span><span><span><span>#define LOG_DEBUG(...) log_something(LogLevel::Debug, ...);
</span></span></span><span><span><span>#endif
</span></span></span><span><span><span></span>
</span></span><span><span><span>#define LOG_INFO(...) log_something(LogLevel::Info, ...);
</span></span></span><span><span><span></span>
</span></span><span><span><span>void</span> <span>some_function</span>() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo();
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    LOG_DEBUG(<span>"some sort of verbose information: %s"</span>, expensive_to_string(my_data_type));
</span></span><span><span>}
</span></span></code></pre></div><p>If you’re not familiar, the above <code>LOG_DEBUG</code> macro is essentially “If <code>LOG_LEVEL_DEBUG</code> is defined, replace <code>LOG_DEBUG</code> with a call to <code>log_something</code> and forward all arguments. If it’s not defined replace the whole thing with an empty string including the arguments.” It’s a pretty simple macro to use, you just call it like a function.</p>
<p>Zig doesn’t have a macro system though, so you might define your logging in a similar way using <code>comptime</code><sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>// probably use @import("root") in actual code
</span></span></span><span><span><span></span><span>const</span> LOG_LEVEL <span>=</span> LogLevel.debug;
</span></span><span><span>
</span></span><span><span><span>const</span> LogLevel <span>=</span> <span>enum</span> {
</span></span><span><span>    debug,
</span></span><span><span>    info,
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>pub</span> <span>fn</span> logSomething(<span>comptime</span> level<span>:</span> LogLevel, <span>comptime</span> format<span>:</span> []<span>const</span> <span>u8</span>, args<span>:</span> anytype) {
</span></span><span><span>    <span>if</span> level <span>&gt;=</span> LOG_LEVEL {
</span></span><span><span>        actuallyLogTheThing(level, format, args);
</span></span><span><span>    }
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>pub</span> <span>fn</span> logDebug(<span>comptime</span> format<span>:</span> []<span>const</span> <span>u8</span>, args<span>:</span> anytype) {
</span></span><span><span>    logSomething(LogLevel.debug, format, anytype);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>fn</span> someFunction() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo();
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    logDebug(<span>"some sort of verbose information {s}"</span>, .{expensiveToString(my_data_type)});
</span></span><span><span>}
</span></span></code></pre></div><p>Zig’s <code>comptime</code> is fantastic and the above is very similar to the C++. At compile time if you’ve defined <code>LOG_LEVEL</code> to be <code>info</code> then <code>logDebug</code> becomes a noop. No copies to a queue, no formatting. It seems essentially the same as the C++.</p>
<h3 id="a-minor-annoyance-with-macroless-languages">A minor annoyance with macroless languages</h3>
<p>It’s great that <code>logDebug</code> is a noop. It sounds like exactly what we want. However, what happens to the arguments you pass that noop? As the name implies <code>expensiveToString</code> is costly. In the C++ version the call is removed by the preprocessor, but what about the Zig version? Maybe the compiler notices they’re unused and optimizes them out in a release build. But what if your expensive used-for-debug-logging-only function has side effects like incrementing some debug metrics? What if the function is from a C library so it can’t be inlined at all? In a lot of code few extraneous calls might not be the end of the world as long as the log itself gets dropped downstream (what’s a few hundred nanos or a mic or two between friends?<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>), but sometimes it’s unnacceptable.</p>
<p>The solution in Zig is to wrap everything in a comptime if:</p>
<div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span> someFunction() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo();
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    <span>if</span> (log_level <span>&lt;=</span> LogLevel.debug) {
</span></span><span><span>        <span>const</span> s <span>=</span> expensiveToString(my_data_type);
</span></span><span><span>        logDebug(<span>"some verbose information: %s"</span>, .{s})    
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>Which is fine, but you need to litter your code with the <code>if log_level &lt;= LogLevel.debug</code>. You also need to know at every call site either the value the logger uses to enable/disable debug logging, or you need to define your own aliases e.g. <code>LOG_LEVEL_DEBUG</code> and use those. For production level code this is, again, a minor annoyance at worst. But it’s just annoying enough that I don’t really enjoy it either for my personal projects (which are just for fun anyway).</p>
<h3 id="a-small-joy-with-an-odin-attribute">A small joy with an Odin attribute</h3>
<p>At first I thought I’d need to do the same thing in Odin. It <em>does</em> have <code>when</code> which does conditional compilation. I was somewhat resigned to wraping all debug logging in a <code>when LOG_LEVEL &lt;= .Debug {}</code> and calling it a day. However, one of the things that I like about Odin is it’s very pragmatic. It doesn’t necessarily try to solve every problem with the same hammer.</p>
<p>I figured I’d post my annoyance in <code>#beginners</code> on the Odin discord in case someone had a good solution, and that’s when I was told about <code>@disabled</code>. <code>@disabled</code> is an attribute that removes all uses of a procedure when true. It doesn’t just turn the proc into a noop, it specifically removes the usage at call sites including any arguments passed to the procedure. The end result is similar to C++’s string replacement macros without the macros. The above example can be solved in Odin with e.g.:</p>
<div><pre tabindex="0"><code data-lang="odin"><span><span>Log_Level <span>::</span> <span>enum</span> {
</span></span><span><span>    Debug,
</span></span><span><span>    Info,
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>LOG_LEVEL <span>::</span> Log_Level.Debug
</span></span><span><span>
</span></span><span><span>log_something <span>::</span> <span>proc</span>(level<span>:</span> Log_Level, fmt<span>:</span> <span>string</span>, args<span>:</span> ..<span>any</span>, loc <span>:=</span> <span>#caller_location</span>) {}
</span></span><span><span>
</span></span><span><span><span>@(disabled = LOG_LEVEL &gt; .Debug)</span>
</span></span><span><span>log_debug <span>::</span> <span>proc</span>(fmt<span>:</span> <span>string</span>, args<span>:</span> ..<span>any</span>, loc <span>:=</span> <span>#caller_location</span>) { <span>// and a nice #caller_location
</span></span></span><span><span><span></span>    log_something(.Debug, fmt, ..args, loc <span>=</span> loc)
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>some_function <span>::</span> <span>proc</span>() {
</span></span><span><span>    <span>// do things
</span></span></span><span><span><span></span>    foo()
</span></span><span><span>    <span>// log some data
</span></span></span><span><span><span></span>    log_debug(<span>"some verbose information: %s"</span>, expensive_to_string(my_data_type))
</span></span><span><span>}
</span></span></code></pre></div><p>In the above, any invocation of <code>log_debug</code> will be stripped out if <code>LOG_LEVEL</code> is <code>.Info</code>. That includes any arguments passed to the proc. That means any expensive or non-inlineable procedures (like <code>expensive_to_string</code>) also won’t be called. It doesn’t rely on <code>-o:speed</code> optimizations to figure out the call is unused. A debug build with <code>log_debug</code> disabled will have the same behavior. In addition, user code just has to call <code>log_debug</code> and not worry about how the logging procs determine if they are enabled or not.</p>
<p>This example in particular was maybe a little more than just a small joy. It was an exact solution to what I wanted. Even without <code>expensive_to_string</code>, it’s nice to just log without having to think about it. The logging procs I write will handle it properly. There are most likely other cases where you still need a <code>when</code> like the Zig solution but it’s at least an 80/20 solution that works well.</p>
<h2 id="wrapping-up">Wrapping up</h2>
<p>To hammer the point again, nothing above is a game changer in programming. They’re just small, quality of life bonuses in Odin that sparked a tiny amount of joy for me personally.</p>
<p>If you are interested in Odin, I recommend reading over the main website to get a better idea if it’s something for you. If you decide it’s interesting then you should probably also join the <a href="https://discord.com/invite/sVBPHEv">discord</a>. There are dozens of us!</p>

</div></div>]]></description>
        </item>
    </channel>
</rss>