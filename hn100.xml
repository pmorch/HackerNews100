(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 23 Sep 2025 17:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[If you are reading this obituary, it looks like I'm dead (119 pts)]]></title>
            <link>https://framinghamsource.com/index.php/2025/09/22/linda-m-brossi-murphy/</link>
            <guid>45348700</guid>
            <pubDate>Tue, 23 Sep 2025 15:47:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://framinghamsource.com/index.php/2025/09/22/linda-m-brossi-murphy/">https://framinghamsource.com/index.php/2025/09/22/linda-m-brossi-murphy/</a>, See on <a href="https://news.ycombinator.com/item?id=45348700">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                    <p>Well, if you are reading this obituary, it looks like I’m dead. WOW, it actually happened … I died of FOMO due to complications of Bulbar ALS.</p>
<p>My name is Linda Brossi Murphy, and I was just 60 years old when I died on Sunday evening, September 21, 2025 – way too young!&nbsp; As the saying goes, I “died peacefully while surrounded by loved ones” … &nbsp;I was loved, comforted, and hugged until my last breath by my beautiful family and a couple of my besties!</p>
<p>My stupid Bulbar ALS got me to the sad point of not being able to talk. Never speaking means never being able to say, “I love you!” It means not being able to call my Mr. BoJangles over for a snack, and it means not being able to order at the Dunkin’ drive through.&nbsp;As far as eating, it totally stinks to sit at the table while people around you are eating juicy burgers hot off the grill, heaping piles of Chinese food, a healthy portion of pasta Alfredo, or Chipotle — and I just have to smile and act like I’m enjoying my bowl of puréed baby mush! Living had gotten to be such an overwhelming burden every day, day after day. I always did my very best not to let anyone know “the back story” of my daily suffering and struggles with ALS. Hubby and I just plowed through each day trying to put our best selves out there for the public eye. Hair and make up done, smiles on….</p>
<p>I am leaving behind some amazing people. My husband, David, aka “Hubby,” who I have adored, unconditionally from the first moment I laid eyes on him 42 years ago! We were together from teenagers to grandparents. Our marriage was mostly good and crazy fun. We both agreed, I was an “A” wife and he was a “B+” husband for a total “A-” which is pretty decent for 42 years together!!! We became a thruple about 1.5 years ago when, Hosee, (my respirator) moved into our marital bed. From then on, David woke up next to what looked like a fighter pilot with smooshed hair!</p>
<p>I had a wonderful family, David Jr. and Ali (Bragg) &amp; Bode and Scottie Murphy of Charlestown, Doug and Kate (Farrell) &amp; Connall Murphy of Milton and Adam and Justine (Murphy) &amp; Harvey Hastings of Bolton. My family has been amazing and the absolute best thing about my life. These peeps have filled my heart to overflowing levels! Michael Brossi of Marlborough and Dave Brossi of Westboro, my brothers, have been my life long support system and partners, I loved them deeply.&nbsp;A lot of dear cousins, my wonderful Auntie Terry Ciarcia, Aunt Pam Nicolazzo, and lots of nieces and nephews.&nbsp;I was recently predeceased by my amazing father, David Brossi. The salt of the earth- a pillar of wisdom, grace, and character. He was always my example of exemplary integrity and as well as one of my favorite humans. Sadly, he lost his mother and daughter of the same sucky disease, Bulbar Onset ALS.</p>
<p>Sticking with formality for a moment… I was born March 7, 1965 in Boston to David and the late Patricia Brossi. I grew up in Framingham, MA. I attended St. Bridget’s School, Marian High School, and Assumption University (Class of 1987). After I graduated, I had a brief stint as a Nursing Home Administrator until David Jr. was born, then stayed home and hatched a couple more pups over the next few years.&nbsp;In 2000, I formally joined the family real estate business and worked there until I was diagnosed… with ALS (I kept working through my long battle with cancer 12 years ago) … Yikes!! Cancer…THEN ALS. Ugh, Honestly, you can’t make this stuff up! I am very proud of the book I wrote about my journey through cancer. Check it out, it’s called “F Off Cancer” by Linda Brossi Murphy.</p>
<p>My favorite pastime was being with my family &amp; friends, hence why FOMO did me in! I also adored having fun, anytime, anywhere! No matter what I was doing, I had fun. I was a very happy person to the core. I also enjoyed feeding the birds, gardening, “playing” the piano when no one was home, playing games on my phone (especially Words With Friends! Overall, I think I was a nice person, except on ‘WWF’- sorry, losers!) drinking wine, boating, playing Rummikub with great friends, walking 9 holes of golf on a lovely day, a half-day of skiing, traveling and dancing every chance I could (with my arms in the air, of course).</p>
<p>I lived my life with two super powers. My first, of which everyone was jealous, was that I could drink as much as I wanted and never seemed to get a hangover … the real wonder is why I didn’t die of liver failure. My second super power is that I was always genuinely happy and absolutely loved to be with nice people.</p>
<p>In addition to my awesome family, I leave a bunch of very dear Murphy in-laws, too many to name, and my father-in-law, Joseph Murphy, who was married to my awesome late mother-in-law and dear friend, Betty Murphy. I was blessed to have had the very mostest bestie Michelle Loranger, along with with a plethora of very dear friends, too many to mention, you know who you are and how important you were to me… My advice is to say “yes” to the party, the trip, the adventure – and while you are there, please raise a glass and “Cheers” for me!</p>
<p>Please be kind to everyone: the telemarketer, the grocery clerk, the Dunkin’s staff, the tailgater, your family, your friends. Speak nicely and positively. Is there really ever a reason to be negative? I don’t think so…</p>
<p>My last donation was made on the way to the funeral home. They swung my body through Massachusetts General Hospital so I could drop off my brain and spinal cord for ALS research. I sincerely ask you all,&nbsp;in lieu of flowers, please consider a generous donation to Compassionate Care ALS.org &nbsp;<a href="https://ccals.org/in_memory_of/linda-murphy/">https://ccals.org/in_memory_of/linda-murphy/</a>&nbsp; as CCALS has helped me and so many other live a better life while struggling with ALS.</p>
<p>So to my earthly existence, I say farewell. It was a blast while it lasted. We sure did have fun!</p>
<p>If you want to come and say hi to my peeps, calling hours are at the McCarthy, McKinney &amp; Lawler Funeral Home, 11 Lincoln Street in Framingham on Sunday, September 28, 2025 from 3:00 – 7:00 pm.</p>
<p>If you were a stinker and meanie to me or my family or friends during my lifetime … Please do everyone a favor and STAY AWAY, we don’t want your negative drama &amp; energy. Only nice, loving people are welcome!</p>
<p>The family will have a private burial.</p>
<p>PLEASE PLEASE PLEASE don’t waste money on flowers.&nbsp;Buy a bunch of scratch tickets and give them out to strangers along your way.&nbsp;Make people happy, that is the best way that you can honor my memory.</p>
<p>A celebration of life will be held at The Verve Hotel, 1360 Worcester St. Natick, on Monday, September 29, 2025 from&nbsp;6:00 – 9:00 pm. Please join my family to celebrate my life, have a glass of wine…some tasty nibbles… and don’t forget to bring your dancing shoes and your favorite story to share about me and my shenanigans! This is a great location for out-of-town guests to stay in a hotel as well.</p>
<p>To share a memory with the Murphy/Brossi Families, kindly visit www.mccarthyfh.com</p>



        

        
                        
                    
	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>                </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Shopify, pulling strings at Ruby Central, forces Bundler and RubyGems takeover (149 pts)]]></title>
            <link>https://joel.drapper.me/p/rubygems-takeover/</link>
            <guid>45348390</guid>
            <pubDate>Tue, 23 Sep 2025 15:25:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joel.drapper.me/p/rubygems-takeover/">https://joel.drapper.me/p/rubygems-takeover/</a>, See on <a href="https://news.ycombinator.com/item?id=45348390">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>Ruby Central recently took over a collection of open source projects from their maintainers without their consent. <a href="https://pup-e.com/goodbye-rubygems.pdf">News</a> of the takeover was first <a href="https://bsky.app/profile/duckinator.bsky.social/post/3lz6exzgtcc2j">broken</a> by <a href="https://pup-e.com/">Ellen</a> on 19 September.</p>
<p>I have spoken to about a dozen people directly involved in the events, and seen a recording of a key meeting between Ruby Gems maintainers and Ruby Central, to uncover what went on.</p>
<p>Here’s a quick summary of what I know:</p>
<ol>
<li>Ruby Central was <a href="https://www.youtube.com/watch?v=9S6l_RZwuxM">struggling for money</a>.</li>
<li>Sidekiq withdrew its $250,000/year sponsorship for Ruby Central because they <a href="https://ruby.social/@rubycentral/114585914969796428">platformed DHH at RailsConf 2025</a>.</li>
<li>Shopify demanded that Ruby Central take full control of the RubyGems GitHub repositories and the <code>bundler</code> and <code>rubygems-update</code> gems, threatening to withdraw funding if Ruby Central did not comply.</li>
<li>HSBT jumped the gun and implemented the takeover plan adding Marty Haught as an owner and reducing maintainers permissions before Marty had discussed this with the maintainers.</li>
<li>Marty met with the maintainers after their access was temporarily restored.</li>
<li>Marty (and by extension, Ruby Central) understood that Ruby Central did not have the right to take over these GitHub repositories or gems from their long established community maintainers.</li>
<li>Marty presented alternatives such as making a fork of the relevant RubyGems projects and warned Ruby Central of the consequences of doing the takeover.</li>
<li>The board voted to execute the takeover anyway and Marty executed it immediately.</li>
<li>A number of board members subsequently misrepresented the takeover to the Ruby community on social media.</li>
<li>This was premeditated. Shopify had organised an on-call rotation to take over from the previous maintainers, some of which at the time were also operating the RubyGems Service.</li>
<li>Shopify specifically demanded that at least one of the RubyGems maintainers, André Arko, be excluded from returning to the project. André has been working on RubyGems for over a decade and was also one of the founders of Ruby Together, an organization that merged with Ruby Central.</li>
</ol>
<h2 id="the-takeover">The Takeover</h2>
<p>On <strong>9 September</strong>, HSBT (Hiroshi Shibata) — a member of Ruby core and maintainer of RubyGems — renamed the RubyGems GitHub enterprise to “Ruby Central”, added a new owner, Marty Haught, and downgraded the permissions of several other maintainers.</p>
<p>According to one of the maintainers, when HSBT was challenged, he refused to revert these changes claiming he needed permission from Marty. On <strong>15 September</strong>, Marty said the changes were a mistake and HSBT reverted <em>some</em> of the changes. However, Marty was not removed as an owner, even though the other maintainers never agreed to him being added.</p>
<p>On <strong>17 September</strong>, RubyGems maintainers met with Marty on Zoom.</p>
<p>Marty explained he’s been working on “operational planning” for the RubyGems Service. He was putting together a new Operator Agreement that all the operators of the RubyGems Service would need to sign.</p>
<p>He also mentioned that it had been identified as a risk that there were external individuals with ownership permissions over repositories that are necessary for running the RubyGems Service. He said HSBT prematurely changed the ownership permissions before the operational plan was complete.</p>
<p>During the discussion, the maintainers clarified with Marty the distinction between the RubyGems source code and the RubyGems Service.</p>
<p><strong>RubyGems</strong> is a collection of community owned, community maintained repositories of code that are held in commons for everyone in the Ruby community to use.</p>
<p>The <strong>RubyGems Service</strong> is entirely separate from that. It’s a specific deployment: a domain name and servers that happen to be running RubyGems source code. It is operated by Ruby Central.</p>
<p>This distinction is important. Anyone else could run the RubyGems source code on their own servers with their own domains. And Ruby Central could decide to run <em>different</em> source code on its servers — whether that be a fork of the RubyGems source code or otherwise.</p>
<p>The RubyGems maintainers have been developing this software for decades, predating Ruby Central’s operation of the RubyGems Service. Their contributions represent countless hours of unpaid work, establishing a clear history of community ownership and stewardship.</p>
<p>Ruby Central did contribute financially towards RubyGems maintenance, but these contributions did not confer ownership. Ruby Central’s funding of RubyGems development is no different than if they had contributed to the development of Rails, RSpec, or any other open source project. In no case would such funding grant them ownership rights over the project itself.</p>
<p>Similarly, Ruby Central’s employment of some RubyGems maintainers to operate the RubyGems Service does not transfer ownership of the separate open source projects.</p>
<p>Having personally reviewed a recording of this meeting, I have no doubt that Marty understood this distinction. The RubyGems source code and GitHub organisation was <em>not</em> owned by Ruby Central, even though Ruby Central operated a service with the same name.</p>
<p>On <strong>18 September</strong>, the team started losing access again. This time they were <em>removed</em> from the GitHub organisation, their <code>rubygems.org</code> email accounts were disabled and they were removed as owners of the <code>bundler</code> and <code>rubygems-update</code> gems. One maintainer, André Arko, was on-call for the RubyGems Service at the time when his access to GitHub and Fastly was revoked.</p>
<p>The Ruby Central board had voted for Ruby Central to take control of the RubyGems GitHub repositories and gems. And since Marty was now an owner, he was able to execute this order.</p>
<h2 id="ruby-central-becomes-mostly-dependent-on-shopify">Ruby Central becomes mostly dependent on Shopify</h2>
<p>When Ruby Central decided to platform DHH at the final RailsConf, they lost $250,000 USD of annual sponsorship from Sidekiq, and this I understand left them almost entirely dependent on Shopify.</p>
<p>An anonymous source told me that during Rails World, members of Ruby Central, Ruby Core, Rails Core and representatives from major companies (Shopify, GitHub) discussed possible funding options.</p>
<p>According to this source, Ruby Central was presented with a proposal for long-term support, but this would only happen if certain RubyGems maintainers were removed.</p>
<p>Another source has confirmed to me that a meeting between Rails Foundation and Ruby Central did take place at Rails World, however they were not able to verify the agenda or who was in attendance.</p>
<p>I do know that the Rails World conference was attended by HSBT, DHH, Aaron Patterson, Amanda Perino, Shan Cureton, Marty Haught, Ufuk Kayserilioglu and Rafael França.</p>
<p>I also know that Shopify specifically put immense financial pressure on Ruby Central to take full control of the RubyGems GitHub organisation and Ruby gems.</p>
<p>Freedom Dumlao, a Ruby Central board member, described the board vote saying “if I had voted the other way, I felt I’d be voting to start the process of shutting down Ruby Central”.</p>
<p>A source familiar with the events told me that Shopify’s pressure was both carrot and stick. Essentially, do what we ask and we’ll reward you with <em>more</em> funding, long-term financial stability. Don’t do this and you’ll never see a dollar of enterprise money again.</p>
<p>This to me strongly suggests that other companies were involved, perhaps through the Rails Foundation. But I have not been able to confirm anything beyond Shopify’s involvement.</p>
<h2 id="the-vote">The Vote</h2>
<p>According to a source familiar with the events, the Ruby Central board was made aware by Marty of the risks and damage this takeover would likely do to the community. Apparently he also highlighted other options besides the takeover, such as forking some of the projects.</p>
<p>Despite this, the board voted in favour of carrying out the takeover and Marty executed it immediately with his new owner privileges.</p>
<p>Shopify had given Ruby Central a hard deadline and it seems that Ruby Central only capitulated at the last moment.</p>
<p>I don’t know if the timing was intentional, but this takeover happened on the second day of the EuRuKo conference in Europe, which meant many outspoken European Rubyists were distracted at the time.</p>
<p>Because this takeover meant locking out most of the RubyGems Service operators including André who was on-call at the time, Shopify had contributed engineers to a new on-call rotation ready to spring into action after the takeover.</p>
<p>Shopify developers had been warming up with their <a href="https://github.com/rubygems/rubygems/commits/master/?author=tenderlove">first commits in six years</a> coming in at the same time as the takeover.</p>
<h2 id="the-response">The Response</h2>
<p>About six hours after Ellen broke the news, Ruby Central published their response: <a href="https://rubycentral.org/news/strengthening-the-stewardship-of-rubygems-and-bundler/">Strengthening the Stewardship of RubyGems and Bundler</a>.</p>
<p>A post that feels like AI-generated corporate speak and bears no signature from anyone at Ruby Central willing to take responsibility.</p>
<p>The response says, “To strengthen supply chain security, we are taking important steps to ensure that administrative access to the RubyGems.org, RubyGems, and Bundler is securely managed. This includes both our production systems and GitHub repositories. In the near term we will temporarily hold administrative access to these projects while we finalize new policies that limit commit and organization access rights. This decision was made and approved by the Ruby Central Board as part of our fiduciary responsibility.”</p>
<p>But while Ruby Central has the right to lock down the RubyGems Service infrastructure, it never owned the RubyGems GitHub repositories.</p>
<p>DHH ignored Ellen’s post but instead retweeted the Ruby Central announcement with the caption “Ruby Central is making the right moves to ensure the Ruby supply chain is beyond reproach both technically and organisationally.”</p>
<p>A position that seems to stand in stark contrast to his other opinions. For example, he criticised <a href="https://www.hey.com/apple/">Apple’s control of the App Store</a> and takes the <a href="https://world.hey.com/dhh/the-open-source-gift-exchange-2171e0f0">ownership of his own open source projects</a> seriously.</p>
<p>Ruby Central board member and Shopify employee Ufuk Kayserilioglu misrepresented what happened, responding to Bluesky threads. For example he <a href="https://bsky.app/profile/ufuk.dev/post/3lz757f6zlc2s">said</a>, “Ruby Central has been running the rubygems.org system for years now, so this can hardly be considered a supply chain attack. On the contrary, we have a legal obligation to all the users of the system to keep it safe and secure.”</p>
<p>But no one accused Ruby Central of taking over the RubyGems Service and the takeover of the RubyGems GitHub organization and gems was not required to meet Ruby Central’s legal obligations. Remember, Ruby Central was in full control of what source code it deployed to the RubyGems Service which it operated.</p>
<p>He also said “How is limiting access to critical and shared infra &amp; code a supply chain attack?” once again conflating the RubyGems source code with the RubyGems Service.</p>
<p>On 21 September, Freedom Dumlao published <a href="https://apiguy.substack.com/p/a-board-members-perspective-of-the?triedRedirect=true">A board member’s perspective of the RubyGems controversy</a> in which he claimed “Ruby Central has been responsible for RubyGems and Bundler for a long time. This isn’t a new development, and I’m honestly very confused about the confusion.”</p>
<p>This is a misrepresentation of the real situation where Ruby Central was responsible for operating the RubyGems Service but did not own the RubyGems source code, repositories or gems.</p>
<p>He goes on to talk about supply chain attacks, which I admit is a convenient cover, but I don’t believe is the genuine reason for the takeover.</p>
<p>He then confirms that a deadline loomed. “Either Ruby Central puts controls in place to ensure the safety and stability of the infrastructure we are responsible for, or lose the funding that we use to keep those things online and going. With less than 24 hours to go, we were still working on this. Conversations with some maintainers were still happening as far as I know but the cooperation we were hoping for was not emerging.”</p>
<p>He doesn’t mention Shopify, but based on my other sources, I know it was Shopify that applied this pressure.</p>
<p>“It was clear that we weren’t quite ready yet, but in the end we were out of time. A vote had to be cast so we could ensure we did not lose funding necessary to operate RubyGems. What I voted for, was to direct Marty, Ruby Central’s Director of Open Source, to temporarily remove access and lock down the systems, get operator agreements in place with maintainers, and then re-enable access to those folks who needed and wanted it. Marty did exactly what the board asked of him.”</p>
<p>This again highlights the pressure Shopify put on Ruby Central.</p>
<p>Two sources directly involved told me that access specifically would not be re-enabled for André who had been singled out. Sources have also suggested that Shopify had been pressuring Ruby Central to end their relationship with André and remove him from the RubyGems project for some period of time prior to this taking place.</p>
<p>On 23 September, Ruby Central shared a video address by Shan Cureton (Executive Director, Ruby Central) on behalf of Ruby Central’s board and team.</p>
<p>In it she claims that Bundler and RubyGems came under Ruby Central’s responsibility through the merger with Ruby Together. But Ruby Together never owned Bundler or RubyGems.</p>
<p>She mentioned the departure of a “lead maintainer” [André] and transition of security engineer [Samuel Giddins] as raising questions around access to RubyGems, Bundler and the RubyGems Service.</p>
<p>She says sponsors (plural) and companies who depend on Ruby tooling came to them with supply chain concerns. She explained that they couldn’t reach agreement with existing maintainers in the timelines they were facing.</p>
<p>I have seen the meeting with the maintainers and can tell you the conversation was primarily about ownership, not security. None of the maintainers had a problem with Ruby Central restricting access to the RubyGems Service that it operated.</p>
<p>They had a problem with Ruby Central taking control of the RubyGems open source code repositories and gems, which Ruby Central never owned.</p>
<p>She explains that the board voted to remove administrative and commit privileges until agreements could be put in place. She said it was never meant to be permanent.</p>
<p>She said “this is not a shutdown of community contribution and it’s not permanent”. However, my sources tell me this will be permanent for at least André and likely Samuel.</p>
<p>She said on-call coverage remains in place. We know that André was on-call when his access was revoked, so she must be talking about the new on-call rotation which Shopify contributed to.</p>
<p>She said “all of these changes are being made in good faith.” But we know that these changes were made at Shopify’s request to take control of the RubyGems projects and specifically to exclude André (and likely Samuel too).</p>
<p>She also talked about two new agreements: <strong>Operator Agreements</strong> cover access to production systems for on-call and maintenance responsibilities. <strong>Contributor Agreements</strong> cover access to Bundler and RubyGem code repositories, covering both paid and volunteer maintainers.</p>
<p>The Operator Agreements make sense, but it is not Ruby Central’s place to run the RubyGems projects including Bundler and the RubyGems.org source code, which are community owned as explained previously.</p>
<p>She said, “in most open source projects where the code is a library or framework, you usually don’t see formal operator agreements. People contribute under contributor license agreements, codes of conduct or decisions made by a steering committee. But RubyGems.org is different. It’s not just code, it’s a production service. It runs critical infrastructure for the Ruby ecosystem, processes billions of downloads, stores sensitive metadata and is relied on by companies that have compliance requirements. Because it’s a service, Ruby Central carries the legal liability, the financial exposure and the operational risk. This is why Operator Agreements are necessary. They ensure access is tied to responsibility and accountability.”</p>
<p>Here she conflates RubyGems.org (the source code) with the RubyGems Service operated by Ruby Central and running on the domain name <code>rubygems.org</code>.</p>
<p>Claiming that Ruby Central owns the RubyGems.org repository because it operates a service that uses the source code is like claiming you own Rails because you have a Rails app and sponsored someone who contributed a PR to the project.</p>
<p>It’s confusing because of how the projects are named, and Ruby Central are taking advantage of that confusion.</p>
<p>The reality is Ruby Central never owned the Ruby Gems source code. They could only take it because Marty was added by HSBT without the consent of other maintainers.</p>
<h2 id="rv">RV</h2>
<p>An important piece of context is that André and Samuel started a new cooperative with Kasper Timm Hansen and Sam Stephenson called <a href="https://spinel.coop/">Spinel</a>.</p>
<p>Spinel is developing a new Ruby management tool called <code>rv</code>. It was <a href="https://andre.arko.net/2025/08/25/rv-a-new-kind-of-ruby-management-tool/">introduced</a> on 25 August 2025, right before Rails World.</p>
<p>In his blog post, André says, “For the last ten years or so of working on Bundler, I’ve had a wish rattling around: I want a better dependency manager. It doesn’t just manage your gems, it manages your ruby versions, too. It doesn’t just manage your ruby versions, it installs pre-compiled rubies so you don’t have to wait for ruby to compile from source every time. And more than all of that, it makes it completely trivial to run any script or tool written in ruby, even if that script or tool needs a different ruby than your application does.”</p>
<p><a href="https://bsky.app/profile/rmfranca.bsky.social/post/3lz7alpobhc2x">Bluesky threads</a> reveal that Rafael França (Shopify / Rails Core) saw this tool as a threat, saying “some of the “admins” even announced publicly many days ago they were launching a competitor tool [rv] and were funding raising for it. I’d not trust the system to such “admin”.”</p>
<p>He also quoted the <code>rv</code> README which says, “Get rid of rvm, rbenv, chruby, asdf, mise, ruby-build, ruby-install, bundler, and rubygems, all at once”, adding the caption “I’m not so sure I trust them to not sabotage rubygems or bundler.”</p>
<h2 id="what-i-dont-know">What I don’t know</h2>
<ol>
<li>I don’t know how each member voted or exactly how the information was presented to the board. I was hoping that someone would leak it to me, but so far that has not happened.</li>
<li>I don’t know if other groups or companies were involved, though circumstantial evidence and hearsay seems to point to this.</li>
</ol>
<p>If you have any information you can provide, please <a href="https://signal.me/#eu/APOpciMlK7Ek66pnVBSl2kFCZeh3QgemN_lcFjMrHJVjI6Ibyi9PZZToA_jl715i">contact me on Signal</a>.</p>
<h2 id="conclusion">Conclusion</h2>
<p>It is not clear that Ruby Central’s plans include returning control of the RubyGems codebases to their original owners.</p>
<p>I am concerned that Ruby Central seems to be vulnerable to coercion by Shopify.</p>
<p>I am concerned that Ruby Central’s board with full knowledge of the consequences and the alternatives voted to take over a collection of open source projects from their maintainers without consent. Especially when these maintainers were acting in good faith at the time. This is the organisation we are meant to trust to host our Ruby gems.</p>
<p>I am concerned that Rails Core seems to consider <code>rv</code> a “threat” rather than an exciting development, and I wonder if the “threat” is more Spinel than <code>rv</code>. It seems likely that Spinel would be less susceptible to enterprise coercion and could offer a genuine alternative to RubyCentral’s RubyGems Service.</p>
<hr>
<h3 id="disclosure">Disclosure</h3>
<p>I was employed by Shopify between 2017 and 2022.</p>
<h3 id="disclaimer">Disclaimer</h3>
<p>I have put this story together to the best of my ability based on hours of conversations with many different people involved. But I am not a professional journalist and I may have missed something. If I have made a mistake, please <a href="https://joel.drapper.me/cdn-cgi/l/email-protection#ec86838980ac889e8d9c9c899ec28189">let me know</a>.</p>
<p>I am willing to talk to anyone involved to make sure the community has a fair and honest understanding of the events that took place.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[x402 — An open protocol for internet-native payments (116 pts)]]></title>
            <link>https://www.x402.org/</link>
            <guid>45347335</guid>
            <pubDate>Tue, 23 Sep 2025 14:14:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.x402.org/">https://www.x402.org/</a>, See on <a href="https://news.ycombinator.com/item?id=45347335">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><p><a target="_blank" rel="noopener noreferrer" href="https://forms.gle/VZKvX93ifiew1ksW9">Get In Touch</a><a target="_blank" rel="noopener noreferrer" href="https://www.x402.org/x402.pdf">One-pager</a><a target="_blank" rel="noopener noreferrer" href="https://www.x402.org/x402_brand_kit.zip">Brand kit</a><a target="_blank" rel="noopener noreferrer" href="https://github.com/coinbase/x402"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg>GitHub</a><a target="_blank" rel="noopener noreferrer" href="https://discord.gg/invite/cdp"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 126.644 96" fill="currentColor"><path fill="#fff" d="M81.15 0a74 74 0 0 0-3.36 6.794 97.9 97.9 0 0 0-28.994 0A68 68 0 0 0 45.437 0a105.6 105.6 0 0 0-26.14 8.057C2.779 32.53-1.691 56.373.53 79.887a105 105 0 0 0 32.05 16.088 77 77 0 0 0 6.87-11.063c-3.737-1.389-7.35-3.131-10.81-5.152.91-.657 1.794-1.339 2.653-1.995a75.26 75.26 0 0 0 64.075 0c.86.707 1.743 1.389 2.652 1.995a69 69 0 0 1-10.835 5.178A77 77 0 0 0 94.056 96a105 105 0 0 0 32.051-16.063c2.626-27.277-4.496-50.917-18.817-71.855A104 104 0 0 0 81.175.051zM42.28 65.414c-6.238 0-11.416-5.657-11.416-12.653s4.976-12.679 11.391-12.679 11.517 5.708 11.416 12.679-5.026 12.653-11.39 12.653m42.078 0c-6.264 0-11.391-5.657-11.391-12.653s4.975-12.679 11.39-12.679S95.85 45.79 95.749 52.761c-.1 6.97-5.026 12.653-11.39 12.653"></path></svg>Discord</a></p></section><div><p><h3>The best way to accept digital payments.</h3></p><div><p>Built around the<!-- --> <a target="_blank" rel="noopener noreferrer" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/402">HTTP 402</a> <!-- -->status code,<!-- --> <span>x402 enables users to pay for resources via API</span> <!-- -->without registration, emails, OAuth, or complex signatures.</p><div><div><h4>No fees</h4><p>x402 as a protocol has 0 fees for either the customer or the merchant.</p></div><div><h4>Instant settlement</h4><p>Accept payments at the speed of the blockchain. Money in your wallet in 2 seconds, not T+2.</p></div><div><h4>Blockchain Agnostic</h4><p>x402 is not tied to any specific blockchain or token, its a neutral standard open to integration by all.</p></div><div><h4>Frictionless</h4><p>As little as 1 line of middleware code or configuration in your existing web server stack and you can start accepting payments. Customers and agents aren't required to create an account or provide any personal information.</p></div><div><h4>Security &amp; trust via an open standard</h4><p>Anyone can implement or extend x402. It's not tied to any centralized provider, and encourages broad community participation.</p></div><div><h4>Web native</h4><p>Activates the dormant 402 HTTP status code and works with any HTTP stack. It works simply via headers and status codes on your existing HTTP server.</p></div></div></div></div><div><p><h3>Powering Next-Gen Digital Commerce</h3></p><div><p><span>x402 unlocks new monetization models,</span> offering developers and content creators a frictionless way to earn revenue from small transactions without forcing subscriptions or showing ads.</p><div><div><h4>AI Agents</h4><p>Agents can use the x402 Protocol to pay for API requests in real-time.</p></div><div><h4>Cloud Storage Providers</h4><p>Using x402, customers can easily access storage services without account creation.</p></div><div><h4>Content Creators</h4><p>x402 unlocks instant transactions, enabling true micropayments for content.</p></div></div></div></div><div><p><h3>1 Line of Code to Accept Digital Dollars</h3></p><div><p>Just add a <span>single line of code</span> in your app, and you can require a USDC payment for each incoming request.</p><div><pre><span>paymentMiddleware</span><span>(</span><span>"0xYourAddress"</span><span>, <!-- -->{</span><span>"/your-endpoint"</span><span>: </span><span>"$0.01"</span><span>}</span><span>);</span>
<span>// and thats it!</span></pre></div><p>If a request arrives without payment, the server responds with HTTP 402, prompting the client to pay and retry.</p><div><pre><span>HTTP</span><span>/1.1 </span><span>402</span><span> Payment Required</span></pre></div><p>x402 allows any web developer to accept crypto payments without the complexity of having to interact with the blockchain.</p></div></div><p><img alt="x402 button" loading="lazy" width="320" height="160" decoding="async" data-nimg="1" srcset="https://www.x402.org/_next/image?url=%2Fx402-button-large.png&amp;w=384&amp;q=75 1x, https://www.x402.org/_next/image?url=%2Fx402-button-large.png&amp;w=640&amp;q=75 2x" src="https://www.x402.org/_next/image?url=%2Fx402-button-large.png&amp;w=640&amp;q=75"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Restrictions on house sharing by unrelated roommates (195 pts)]]></title>
            <link>https://marginalrevolution.com/marginalrevolution/2025/08/the-war-on-roommates-why-is-sharing-a-house-illegal.html</link>
            <guid>45347043</guid>
            <pubDate>Tue, 23 Sep 2025 13:51:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marginalrevolution.com/marginalrevolution/2025/08/the-war-on-roommates-why-is-sharing-a-house-illegal.html">https://marginalrevolution.com/marginalrevolution/2025/08/the-war-on-roommates-why-is-sharing-a-house-illegal.html</a>, See on <a href="https://news.ycombinator.com/item?id=45347043">Hacker News</a></p>
Couldn't get https://marginalrevolution.com/marginalrevolution/2025/08/the-war-on-roommates-why-is-sharing-a-house-illegal.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[MrBeast Failed to Disclose Ads and Improperly Collected Children's Data (293 pts)]]></title>
            <link>https://bbbprograms.org/media/newsroom/decisions/mrbeast-feastables</link>
            <guid>45346950</guid>
            <pubDate>Tue, 23 Sep 2025 13:44:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bbbprograms.org/media/newsroom/decisions/mrbeast-feastables">https://bbbprograms.org/media/newsroom/decisions/mrbeast-feastables</a>, See on <a href="https://news.ycombinator.com/item?id=45346950">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
                

                New York, NY – September 18, 2025 - Following its marketplace monitoring of children’s advertising, BBB National Programs’ Children’s Advertising Review Unit (CARU) recommended that MrBeastYouTube, LLC, and its affiliate Feastables, update their advertising and data collection practices for the MrBeast YouTube channel, Feastables’ Sweepstakes, and the Feastables website to comply with CARU’s Advertising Guidelines, CARU’s Privacy Guidelines, and the Children’s Online Privacy Protection Act (COPPA).</p><p>

MrBeast, the online persona of Jimmy Donaldson, is one of the world's most popular content creators on the YouTube platform, with a large fan base of children and young adults. The MrBeast YouTube channel has over 400 million subscribers. In 2022, MrBeast launched Feastables, a chocolate brand that generated over $215 million in revenue in 2024.</p><p>

CARU’s inquiry focused on whether certain advertising on the MrBeast YouTube channel was identifiable as advertising; whether certain claims for Feastables chocolate bars were misleading; whether promotions for Feastables sweepstakes clearly disclosed free means of entry, odds of winning, and minimum age requirements; and whether personally identifiable information was collected from children prior to obtaining verifiable parental consent (VPC).</p><h2>MrBeast YouTube Advertising</h2><p>
CARU observed several MrBeast YouTube videos where the video descriptions and pinned comments contained advertising content unrelated to the videos. This content was not clearly labeled or otherwise identifiable as advertising to children in the audience.&nbsp;</p><p>

Because it would not be clear to children that the video descriptions and pinned comments were advertising messages, CARU determined that MrBeast’s YouTube channel did not comply with CARU’s Ad Guidelines’ provision that advertising should be presented in a way that makes clear to the child audience that it is advertising.&nbsp;</p><p>

CARU accordingly recommended that the channel update its advertising practices to ensure that all advertisements are identifiable as ads to children.</p><p>
In a promotional video later removed from his YouTube channel, MrBeast posted a “Massive Announcement!” where MrBeast debuted the new Feastables chocolate bars and purported to conduct a blind taste test between the new Feastables chocolate bars and “top European chocolates” that showed all tasters preferring the Feastables bar.</p><p>

Although MrBeast contended the taste test demonstration was not intended to be taken seriously, CARU concluded that it would appear to be a valid taste test to children.&nbsp;</p><p>

CARU determined Feastables violated CARU’s Ad Guidelines by misrepresenting that the taste test was a valid demonstration that consumers prefer Feastables chocolate bars’ taste compared to similar chocolates. &nbsp;&nbsp;</p><p>

CARU recommended that Feastables ensure ad claims are truthful and not misleading to children.&nbsp;</p><h2>Feastables Sweepstakes</h2><p>
At the end of the “Massive Announcement” Feastables video, MrBeast announced the “Blue Wave $10K sweepstakes” saying, “…for 30 days straight, we are giving away $10,000 to a lucky customer who scans the QR code on the back of any new Feastables bar…You might win 10 grand…” and to “Upload Your Receipt &amp; Enter to Win. Confirm your purchase below to enter for a chance to win 10k + a year’s supply of our new chocolate. MORE BARS = MORE ENTRIES.”&nbsp;</p><p>

Contrary to CARU’s Ad Guidelines’ provision that sweepstakes promotions must clearly and conspicuously disclose a free means of entry, the free means of entering the sweepstakes was only disclosed in the FAQ section linked to halfway down the page. The FAQ also stated that the minimum age of participation is 16.&nbsp;</p><p>

Based on the overall net impression of the ads for the Blue Wave sweepstakes, CARU determined that the free method of entry was not adequately disclosed. CARU determined that a child may have the reasonable takeaway that they must purchase Feastables chocolate bars to enter the sweepstakes. A second reasonable takeaway is that a child should purchase as many as 10 chocolate bars every day and scan the QR codes to maximize their chances of winning.</p><p>

In MrBeast’s 2024 Halloween sweepstakes, Feastables encouraged participants to submit up to 24 entries daily until October 30 for a chance to win $10,000, with a grand prize of $1,000,000 on Halloween Day. The ad copy stated, “$10,000 USD Daily Winner. Enter with Purchase Through October 30.” In very small print was the disclaimer, “No purchase necessary, Click below for details.” The official rules stated that participants must be at least 13 years old with parental permission and entrants under 13 are not allowed.&nbsp;</p><p>

CARU noted the sweepstakes did not include an age gate to ensure that participants were at least 13 years old, nor did the sweepstakes provide a method, at any point in the sweepstakes entry flow, where participants could enter their parent or guardian’s information to obtain VPC. The entry form required a participant to enter personal information including full name, phone number, address, and email address. To upload the receipt photo, the prompt, “I affirm that I have read, understand and agree to the Official Rules,” was pre-checked.&nbsp;</p><p>

Additionally, the advertisement featured a large countdown timer with the text “Time is Running Out. Buy Feastables for a chance to win $10K,” which CARU determined constituted sales pressure.&nbsp;</p><h2>Sweepstakes Advertising Issues</h2><p>
CARU determined that the Feastables Blue Wave $10K and Halloween $10K sweepstakes did not comply with CARU’s Ad Guidelines by failing to clearly and conspicuously disclose the free means of entry, the minimum age requirements, and the likelihood of winning, and by promoting the overconsumption of chocolate bars.&nbsp;</p><p>

CARU recommended ensuring that material information is disclosed clearly and conspicuously to children in language they can understand, that advertising is clearly identifiable as advertising to the children, and that advertising is truthful, not misleading, and appropriate to the child audience.</p><h2>Sweepstakes Privacy Issues</h2><p>
CARU’s Privacy Guidelines and COPPA require websites directed to children, including mixed audience sites, to obtain VPC before collecting, using, or disclosing personal information from children under 13. Pursuant to COPPA, mixed audience sites may implement a neutral age-screening mechanism to ensure the site does not collect personally identifiable information from children under 13 without first obtaining VPC.</p><p>

CARU determined that the Feastables website was a mixed audience site that appealed to children under the age of 13 as a secondary audience and, therefore, Feastables had a reasonable expectation that children under 13 would visit the website.&nbsp;</p><p>

Therefore, CARU determined that the Feastables Blue Wave $10K and Halloween $10K sweepstakes did not comply with CARU’s Privacy Guidelines and potentially COPPA by failing to provide a neutral age-screening mechanism to ensure the sweepstakes website did not collect personally identifiable information from children under the age of 13 without first obtaining VPC.&nbsp;</p><h2>Other Feastables Website Privacy Issues</h2><p>
In its review of the Feastables website, CARU observed a full-page popup that repeatedly solicited the user’s email address with a call to action stating, “MrBeast Wants You to Join the Crew.” When CARU provided an email address through this popup, it discovered that a second popup would generate, soliciting the user’s phone number this time. When testing the network traffic of the site during this interaction, CARU saw evidence that the email and phone contact information was sent to non-affiliate third parties.</p><p>

In light of Feastables’ future plans to solely run sweepstakes for ages 18 and up, CARU further recommended that Feastables consider whether a neutral and effective age gate would be appropriate for future sweepstakes and promotions.</p><p>

Since the opening of the inquiry, CARU has worked with the MrBeast team, which has cooperated to implement CARU’s recommendations regarding CARU’s Advertising Guidelines, CARU’s Privacy Guidelines, and COPPA.</p><p>

In the advertiser statement, MrBeast and Feastables stated that it “appreciates CARU’s mission to promote responsible children's advertising. However, they do not agree with all the conclusions made in the decision or the premises on which they were based. Furthermore, a variety of the issues raised by CARU relate to practices long since revised and/or discontinued. Notwithstanding, MrBeast and Feastables certainly will take CARU's concerns under advisement as it develops future advertisements which appear in children's media.”</p><p>

All BBB National Programs case decision summaries can be found in the <a href="https://bbbprograms.org/media/newsroom/decisions">case decision library</a>. For the full text of NAD, NARB, and CARU decisions, subscribe to the <a href="https://bbbprograms.org/media/online-archive">Online Archive</a>.&nbsp;

                    </p><p>
                    <time datetime="9/18/2025 12:00:00 AM">September 18, 2025</time></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zig feels more practical than Rust for real-world CLI tools (122 pts)]]></title>
            <link>https://dayvster.com/blog/why-zig-feels-more-practical-than-rust-for-real-world-cli-tools/</link>
            <guid>45346387</guid>
            <pubDate>Tue, 23 Sep 2025 12:56:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dayvster.com/blog/why-zig-feels-more-practical-than-rust-for-real-world-cli-tools/">https://dayvster.com/blog/why-zig-feels-more-practical-than-rust-for-real-world-cli-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=45346387">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div> <div>  <!-- Responsive flex: row on md+, column on mobile --> <div> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M8 2v4"></path><path d="M16 2v4"></path><rect width="18" height="18" x="3" y="4" rx="2"></rect><path d="M3 10h18"></path></svg> <p><span>Tuesday, September 23, 2025</span> </p></div>  <p> Why I reach for Zig first for my CLI tools lately </p> <hr> </div>  <h2 id="introduction">Introduction</h2>
<p>So when it comes to memory management there are two terms you really need to know, the stack and the heap.</p>
<p>The stack is a region of memory that stores temporary data that is only needed for a short period of time. It operates in a last-in, first-out (LIFO) manner, meaning that the most recently added data is the first to be removed, as the name suggests. Basically imagine a stack of plates, if you wanna remove one plate you remove the top one, remove the middle plate and disaster awaits in this analogy. The stack is typically used for storing function parameters, local variables, and return addresses. It is fast and efficient because it has a fixed size and does not require dynamic memory allocation.</p>
<p>The size of the stack is usually limited, and if a program tries to use more stack space than is available, it can result in a stack overflow error. This can happen if a function calls itself recursively too many times or if a program allocates too much memory on the stack.</p>
<p>Whereas the heap as the name suggests is a region of memory that is used for dynamic memory allocation. Unlike the stack, the heap does not have a fixed size and can grow or shrink as needed. The heap is typically used for storing data that needs to persist beyond the lifetime of a single function call, such as objects or data structures that are created at runtime. Imagine the heap as a pile of clothes in a disorganized household, you can add or remove clothes as needed and as long as the pile isn’t too big you can find what you need with relative speed and ease. But it will quickly become a nightmare if you let it grow out of control. The heap is managed by the operating system and requires dynamic memory allocation, which can be slower and less efficient than stack allocation.</p>
<p>The heap can also become fragmented over time, since we do not always store data in a contiguous block of memory. This can lead to performance issues and make it more difficult to allocate large blocks of memory.</p>
<h3 id="rusts-borrow-checker">Rust’s Borrow Checker</h3>
<p>Rust’s borrow checker is a a pretty powerful tool that helps ensure memory safety during compile time. It enforces a set of rules that govern how references to data can be used, preventing common programming memory safety errors such as null pointer dereferencing, dangling pointers and so on. However you may have notice the word <strong>compile time</strong> in the previous sentence. Now if you got any experience at systems programming you will know that compile time and runtime are two very different things. Basically compile time is when your code is being translated into machine code that the computer can understand, while runtime is when the program is actually running and executing its instructions. The borrow checker operates during compile time, which means that it can only catch memory safety issues that can be determined statically, before the program is actually run.</p>
<p>This means that basically the borrow checker can only catch issues at comptime but it will not fix the underlying issue that is developers misunderstanding memory lifetimes or overcomplicated ownership. The compiler can only enforce the rules you’re trying to follow; it can’t teach you good patterns, and it won’t save you from bad design choices.</p>
<h3 id="story-time">Story Time</h3>
<p>Last weekend I’ve made a simple CLI tool for myself to help me manage my notes it parses <code>~/.notes</code> into a list of notes, then builds a tag index mapping strings to references into that list. Straightforward, right? Not in Rust. The borrow checker blocks you the moment you try to add a new note while also holding references to the existing ones. Mutability and borrowing collide, lifetimes show up, and suddenly you’re restructuring your code around the compiler instead of the actual problem.</p>
<p>In Zig, we would just allocate the list with an allocator, store pointers into it for the tag index, and mutate freely when we need to add or remove notes. No lifetimes, no extra wrappers, no compiler gymnastics, that’s a lot more straightforward.</p>
<h3 id="but-dave-isnt-that-the-exact-point-of-rusts-borrow-checker">But Dave isn’t that the exact point of Rust’s borrow checker?</h3>
<p>Yes it is, however by using Zig I managed to get most of the benefits of Rust’s memory safety without the complexity or ceremony of the borrow checker. All it took was some basic understanding of memory management and a bit of discipline. I was able to produce two CLI’s that are both memory safe and efficient however the Zig one was way more straightforward and easier to reason about and took less time to write.</p>

<p>This is where a lot of developers trip up, Rust markets itself as a language that produces safe software, great marketing hook, but one tiny problem, memory safety is one puzzle piece of overall software safety. I’m not sure if the Rust foundation does this on purpose sort of a blanket statement to make it seem like memory safety is the end all be all of software safety, or if they just don’t want to constantly prefix safety with memory safety(even though they should).</p>
<p>But back to the main point, memory safety is just one aspect of software safety. You can argue if it’s a big or small piece of the puzzle, I’d say it depends on the software and use-case but it’s definitely not the only piece.</p>
<p>So What exactly is safety in terms of CLI tools?</p>
<p>Memory safety alone does not make a program safe. Your CLI tool can still crash, produce wrong results, corrupt files, leak sensitive data, be vulnerable to various types of attacks or just behave in a way that is not expected. Let’s go back to my <code>Notes CLI</code> it’s rust version may never segfault but it could silently overwrite my index or tags or corrupt my files if I make a mistake in my logic, or perhaps it could store my file in a temporary location that is world readable, exposing my notes to anyone on the system. Is that safe? No.</p>
<p>Would using Zig solve any of those issues automatically, also no.
Is my example a bit contrived, yes, but it illustrates the point that memory safety is not the only thing that matters when it comes to software safety.</p>
<p>In fact you should also consider other aspects of safety such as:</p>
<ul>
<li>
<p><strong>Predictable Behavior</strong>: The program should do what the user expects, even when input is malformed or unexpected. A CLI that panics on a missing file or fails silently on a corrupted note is not safe.</p>
</li>
<li>
<p><strong>Avoiding Crashes or Silent Corruption</strong>: The program should handle errors gracefully, providing meaningful feedback to the user instead of crashing or corrupting data. A CLI that crashes on a malformed note or silently overwrites existing notes is not safe.</p>
</li>
<li>
<p><strong>Manageable Performance</strong>: The program should perform well under expected workloads, avoiding excessive resource consumption or slowdowns. A CLI that becomes unresponsive when managing a large number of notes is not safe. This is where it really helps to understand memory allocations and performance characteristics of your language of choice.</p>
</li>
<li>
<p><strong>Sensitive Data Handling</strong>: The program should protect sensitive data from unauthorized access or exposure. A CLI that stores notes in a world-readable temporary file is not safe.</p>
</li>
<li>
<p><strong>Robustness Against Attacks</strong>: The program should be resilient against common attack vectors, such as injection attacks or buffer overflows. A CLI that can be exploited to execute arbitrary code or corrupt data is not safe. And this is precisely where Rust’s memory safety shines, it can help prevent certain types of vulnerabilities that arise from memory mismanagement. However, it’s not a silver bullet that guarantees overall safety.</p>
</li>
</ul>
<h2 id="the-borrow-checker-strengths-and-limitations">The Borrow Checker: Strengths and Limitations</h2>
<p>The borrow checker is impressive. It prevents dangling references, double frees, and mutable aliasing at compile time, things that would otherwise cause segfaults or undefined behavior. It’s why Rust can claim “memory safe without a garbage collector.”</p>
<h3 id="strengths">Strengths:</h3>
<ul>
<li>
<p><strong>Zero data races / mutable aliasing issues</strong>: The compiler guarantees that only one mutable reference exists at a time, and that immutable references cannot be combined with mutable ones.</p>
</li>
<li>
<p><strong>Strong compile-time guarantees</strong>: Many memory-related bugs are caught before you even run the program.</p>
</li>
<li>
<p><strong>Early bug detection</strong>: You find mistakes before shipping code, which is a huge win in long-lived services or concurrent systems.</p>
</li>
</ul>
<h3 id="limitations--pain-points">Limitations / Pain Points:</h3>
<p><strong>Cognitive overhead</strong>: You’re constantly thinking about lifetimes, ownership, and borrow scopes, even for simple tasks. A small CLI like my notes tool suddenly feels like juggling hot potatoes.</p>
<p><strong>Boilerplate and contortions</strong>: You end up introducing clones, wrappers (Rc, RefCell), or redesigning data structures just to satisfy the compiler. Your code starts serving the compiler, not the problem.</p>
<p><strong>Compile-time only</strong>: The borrow checker cannot fix logic bugs, prevent silent corruption, or make your CLI behave predictably. It only ensures memory rules are followed.</p>
<ul>
<li><strong>Edge cases get messy</strong>: Shared caches, global state, or mutable indexes often trigger lifetime errors that are annoying to work around.</li>
</ul>
<p>At this point, the Rust borrow checker can feel more like a mental tax than a helpful tool, especially for short-lived CLI projects. You’re trading developer ergonomics for a compile-time guarantee that, in many CLI scenarios, may be overkill.</p>
<h2 id="zigs-approach-to-safety-and-simplicity">Zig’s Approach to Safety and Simplicity</h2>
<p>Zig takes a different approach to safety and simplicity. It provides manual memory management with optional safety checks, allowing developers to choose the level of control they need. This can lead to more straightforward code for certain use cases, like CLI tools. However where it really shines is how it does manual memory management, I’ve briefly touched upon this in my other blog post <a href="https://dayvster.com/blog/zig-allocators-explained/">Zig Allocators Explained</a>.</p>
<p>But basically long story short Zig gives you allocators, a set of tools that helps you manually manage your memory in a more structured and predictable way. You can choose to use a general purpose allocator like the <code>std.heap.GeneralPurposeAllocator</code> or you can create your own custom allocator that fits your specific needs. This allows you to have more control over how memory is allocated and deallocated, which can lead to more efficient and predictable memory usage. This combined with Zig’s <code>defer</code> statement which allows you to schedule cleanup code to run when a scope is exited, makes it easy to manage resources gives you most of the power of Rust’s borrow checker at your disposal without the complexity and ritual. However it asks one thing in return of you, discipline, your software will be only as safe as you make it. We can make the same claim about Rust, you can throw <code>copy</code> and <code>clone</code> and <code>unsafe</code> around your code and throw away all the benefits of the borrow checker in a heartbeat.</p>
<p>The two languages are polar opposites in this regard, Zig places the burden on the developer and makes it easy for them to produce memory safe software, whereas Rust places the burden on the compiler and makes it hard for developers to produce memory unsafe software.</p>
<p>Back to the main point, zig’s approach to memory management is in my subjective opinion more practical for most of my use cases, especially for CLI tools. It allows me to write straightforward code that is easy to reason about and maintain, without the overhead of the borrow checker. I can allocate a list of notes, store pointers to them in a tag index, and mutate the list freely when I need to add or remove notes. No lifetimes, no extra wrappers, no compiler gymnastics, that’s a lot more straightforward.</p>
<p>Oh I almost forgot, Zig also has the <code>comptime</code> feature which allows you to execute code at compile time. This can be useful for generating code, performing static analysis, or optimizing performance and even for testing which is a really nice bonus and can be a small helper when it comes to memory safety.</p>
<h2 id="developer-ergonomics-matter-and-developers-are-not-idiots">Developer Ergonomics Matter and Developers are not Idiots</h2>
<p>When developing software we want to be productive and efficient, most of all we want to be correct and produce good software, however we also want to enjoy the process of creation and not feel like we are fighting the tools we use. Developer ergonomics is a term that refers to how easy and comfortable it is to use a programming language or framework. It encompasses things like syntax, tooling, documentation, and community support. A language with good developer ergonomics can make it easier to write correct code, while a language with poor developer ergonomics can make it harder to do so. I’d say as it currently stands Rust has poor developer ergonomics but produces memory safe software, whereas Zig has good developer ergonomics and allows me to produce memory safe software with a bit of discipline.</p>
<p>I personally usually prefer languages where I do not have to succumb to too much ceremony and ritual to get things done, I want to be able to express my ideas in code without having to constantly think about the underlying mechanics of the language and yet I want to be responsible and produce good software. So with C and C++ this was a tiny bit harder as you basically had to learn some useful and practical memory management patterns and techniques, Zig comes with them baked in.</p>
<p>I feel like Zig really respects it’s developers and treats them like adults, it gives you the tools and expects you to use them wisely. Rust on the other hand feels like it treats developers like children that need to be constantly supervised and guided, which can be frustrating and demotivating.</p>
<p>Developers are not idiots, sure even the smartest amongst us still produce memory safety issues or bugs in their software and it’s silly to assume that with enough training and practice we can become perfect developers, but we can become better developers. We can learn from our mistakes and improve our skills, we can learn to write better code and produce better software.</p>
<p>It’s not good to abstract that away to the compiler and assume that it will magically make us better developers, I don’t personally think it will. In fact not to sound too cliche but I think that the journey to becoming a better developer is a series of mistakes and fixes, we learn from our mistakes and improve our skills. What does it say about a language that tries to abstract away the mistakes we make, does it really help us become better developers ?</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>Rust is amazing, if you’re building something massive, multithreaded, or long-lived, where compile-time guarantees actually save your life. The borrow checker, lifetimes, and ownership rules are a boon in large systems.</p>
<p>But for small, practical CLI tools? Rust can feel like overkill. That’s where Zig shines. Lightweight, fast, and straightforward, you get memory safety without constantly bending over backward for the compiler. You can allocate a list, track pointers, and mutate freely without extra wrappers, lifetimes, or contortions. Iterating feels natural, the code is easier to reason about, and you get stuff done faster.</p>
<p>Memory safety is important, but it’s just one piece of the puzzle. Predictable behavior, maintainable code, and robustness are just as critical, and that’s exactly why Zig often feels more practical for real-world CLI tools.</p>
<p>At the end of the day, it’s not about which language is “better.” It’s about what fits your workflow and the kinds of projects you build. For me, Zig hits the sweet spot: memory safe, low ceremony, and developer-friendly, perfect for small tools that actually get things done.</p>
<h2 id="references">References</h2>
<ul>
<li><a href="https://www.geeksforgeeks.org/stack-vs-heap-memory-allocation/" target="_blank">The Stack and the Heap</a></li>
<li><a href="https://dayvster.com/blog/zig-allocators-explained/" target="_blank">Zig Allocators Explained</a></li>
<li><a href="https://doc.rust-lang.org/nomicon/" target="_blank">Rustonomicon - The Dark Arts of Unsafe Rust</a></li>
<li><a href="https://ziglang.org/documentation/master/#Memory-Management" target="_blank">Zig Documentation - Memory Management</a></li>
<li><a href="https://doc.rust-lang.org/book/" target="_blank">Rust Documentation - The Rust Programming Language</a></li>
<li><a href="https://ziglang.org/documentation/master/#Comptime" target="_blank">Zig Documentation - Comptime</a></li>
<li><a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html" target="_blank">Rust Documentation - Ownership</a></li>
<li><a href="https://ziglang.org/documentation/master/#Defer" target="_blank">Zig Documentation - Defer</a></li>
<li><a href="https://doc.rust-lang.org/book/ch09-00-error-handling.html" target="_blank">Rust Documentation - Error Handling</a></li>
<li><a href="https://ziglang.org/documentation/master/#Error-Handling" target="_blank">Zig Documentation - Error Handling</a></li>
<li><a href="https://doc.rust-lang.org/book/ch16-00-concurrency.html" target="_blank">Rust Documentation - Concurrency</a></li>
<li><a href="https://ziglang.org/documentation/master/#Concurrency" target="_blank">Zig Documentation - Concurrency</a></li>
<li><a href="https://doc.rust-lang.org/book/ch11-00-testing.html" target="_blank">Rust Documentation - Testing</a></li>
<li><a href="https://ziglang.org/documentation/master/#Testing" target="_blank">Zig Documentation - Testing</a></li>
<li><a href="https://doc.rust-lang.org/book/ch20-00-final-project-a-web-server.html#performance-considerations" target="_blank">Rust Documentation - Performance</a></li>
</ul>    </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cache of Devices Capable of Crashing Cell Network Is Found Near U.N (188 pts)]]></title>
            <link>https://www.nytimes.com/2025/09/23/us/politics/secret-service-sim-cards-servers-un.html</link>
            <guid>45345514</guid>
            <pubDate>Tue, 23 Sep 2025 11:29:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/09/23/us/politics/secret-service-sim-cards-servers-un.html">https://www.nytimes.com/2025/09/23/us/politics/secret-service-sim-cards-servers-un.html</a>, See on <a href="https://news.ycombinator.com/item?id=45345514">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/09/23/us/politics/secret-service-sim-cards-servers-un.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Structured Outputs in LLMs (150 pts)]]></title>
            <link>https://parthsareen.com/blog.html#sampling.md</link>
            <guid>45345207</guid>
            <pubDate>Tue, 23 Sep 2025 10:40:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://parthsareen.com/blog.html#sampling.md">https://parthsareen.com/blog.html#sampling.md</a>, See on <a href="https://news.ycombinator.com/item?id=45345207">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <div>
        <header>
            <a href="https://parthsareen.com/index.html">
                <img src="https://parthsareen.com/zukohere.png" alt="Profile Image">
            </a>
            <h2>Writings</h2>
        </header>
        <main>
            <article id="post-content"></article>
            <section>
                <ul id="post-list"></ul>
            </section>
        </main>
        
    </div>
    




</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go has added Valgrind support (353 pts)]]></title>
            <link>https://go-review.googlesource.com/c/go/+/674077</link>
            <guid>45344708</guid>
            <pubDate>Tue, 23 Sep 2025 09:26:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go-review.googlesource.com/c/go/+/674077">https://go-review.googlesource.com/c/go/+/674077</a>, See on <a href="https://news.ycombinator.com/item?id=45344708">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The YAML Document from Hell (142 pts)]]></title>
            <link>https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell</link>
            <guid>45344554</guid>
            <pubDate>Tue, 23 Sep 2025 09:04:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell">https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell</a>, See on <a href="https://news.ycombinator.com/item?id=45344554">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope=""><header><p>written by <br>published <time datetime="2023-01-11" itemprop="datePublished">11 January 2023</time></p></header><p><span>For a data format</span>, yaml is extremely complicated. It aims to be a human-friendly format, but in striving for that it introduces so much complexity, that I would argue it achieves the opposite result. Yaml is full of footguns and its friendliness is deceptive. In this post I want to demonstrate this through an example.</p><p>This post is a rant, and more opinionated than my usual writing.</p><h2 id="yaml-is-really-really-complex"><a href="#yaml-is-really-really-complex"></a>Yaml is really, really complex</h2><p>Json is simple. <a href="https://www.json.org/json-en.html">The entire json spec</a> consists of six railroad diagrams. It’s a simple data format with a simple syntax and that’s all there is to it. Yaml on the other hand, is complex. So complex, that <a href="https://yaml.org/spec/1.2.2/">its specification</a> consists of <em>10 chapters</em> with sections numbered four levels deep and a dedicated <a href="https://yaml.org/spec/1.2/errata.html">errata page</a>.</p><p>The json spec is not versioned. There were <a href="https://youtu.be/-C-JoyNuQJs?t=965">two changes</a> to it in 2005 (the removal of comments, and the addition of scientific notation for numbers), but it has been frozen since — almost two decades now. The yaml spec on the other hand is versioned. The latest revision is fairly recent, 1.2.2 from October 2021. Yaml 1.2 differs substantially from 1.1: the same document can parse differently under different yaml versions. We will see multiple examples of this later.</p><p>Json is so obvious that Douglas Crockford claims <a href="https://www.youtube.com/watch?v=-C-JoyNuQJs">to have discovered it</a> — not invented. I couldn’t find any reference for how long it took him to write up the spec, but it was probably hours rather than weeks. The change from yaml 1.2.1 to 1.2.2 on the other hand, was <a href="https://yaml.com/blog/2021-10/new-yaml-spec/">a multi-year effort by a team of experts</a>:</p><blockquote><p>This revision is the result of years of work by the new <abbr>YAML</abbr> language development team. Each person on this team has a deep knowledge of the language and has written and maintains important open source <abbr>YAML</abbr> frameworks and tools.</p></blockquote><p>Furthermore this team plans to actively evolve yaml, rather than to freeze it.</p><p>When you work with a format as complex as yaml, it is difficult to be aware of all the features and subtle behaviors it has. There is <a href="https://yaml-multiline.info/">an entire website</a> dedicated to picking one of <a href="https://stackoverflow.com/a/21699210/135889">the 63 different multi-line string syntaxes</a>. This means that it can be very difficult for a human to predict how a particular document will parse. Let’s look at an example to highlight this.</p><h2 id="the-yaml-document-from-hell"><a href="#the-yaml-document-from-hell"></a>The yaml document from hell</h2><p>Consider the following document.</p><pre><code>server_config:
  port_mapping:
    # Expose only ssh and http to the public internet.
    - 22:22
    - 80:80
    - 443:443

  serve:
    - /robots.txt
    - /favicon.ico
    - *.html
    - *.png
    - !.git  # Do not expose our Git repository to the entire world.

  geoblock_regions:
    # The legal team has not approved distribution in the Nordics yet.
    - dk
    - fi
    - is
    - no
    - se

  flush_cache:
    on: [push, memory_pressure]
    priority: background

  allow_postgres_versions:
    - 9.5.25
    - 9.6.24
    - 10.23
    - 12.13</code></pre><p>Let’s break this down section by section and see how the data maps to json.</p><h2 id="sexagesimal-numbers"><a href="#sexagesimal-numbers"></a>Sexagesimal numbers</h2><p>Let’s start with something that you might find in a container runtime configuration:</p><pre><code>port_mapping:
  - 22:22
  - 80:80
  - 443:443</code></pre><div id="cb3"><pre><code><span id="cb3-1"><span>{</span><span>"port_mapping"</span><span>:</span> <span>[</span><span>1342</span><span>,</span> <span>"80:80"</span><span>,</span> <span>"443:443"</span><span>]</span><span>}</span></span></code></pre></div><p>Huh, what happened here? As it turns out, numbers from 0 to 59 separated by colons are <a href="https://yaml.org/spec/1.1/#id858600">sexagesimal (base 60) number literals</a>. This arcane feature was present in yaml 1.1, but silently removed from yaml 1.2, so the list element will parse as <code>1342</code> or <code>"22:22"</code> depending on which version your parser uses. Although yaml 1.2 is more than 10 years old by now, you would be mistaken to think that it is widely supported: the latest version libyaml at the time of writing (which is used among others by <a href="https://pypi.org/project/PyYAML/6.0/">PyYAML</a>) implements yaml 1.1 and parses <code>22:22</code> as <code>1342</code>.</p><p>The following snippet is actually invalid:</p><pre><code>serve:
  - /robots.txt
  - /favicon.ico
  - *.html
  - *.png
  - !.git</code></pre><p>Yaml allows you to create an <em>anchor</em> by adding an <code>&amp;</code> and a name in front of a value, and then you can later reference that value with an <em>alias</em>: a <code>*</code> followed by the name. In this case no anchors are defined, so the aliases are invalid. Let’s avoid them for now and see what happens.</p><pre><code>serve:
  - /robots.txt
  - /favicon.ico
  - !.git</code></pre><div id="cb6"><pre><code><span id="cb6-1"><span>{</span><span>"serve"</span><span>:</span> <span>[</span><span>"/robots.txt"</span><span>,</span> <span>"/favicon.ico"</span><span>,</span> <span>""</span><span>]</span><span>}</span></span></code></pre></div><p>Now the interpretation depends on the parser you are using. The element starting with <code>!</code> is a <a href="https://yaml.org/spec/1.2.2/#3212-tags">tag</a>. This feature is intended to enable a parser to convert the fairly limited yaml data types into richer types that might exist in the host language. A tag starting with <code>!</code> is up to the parser to interpret, often by calling a constructor with the given name and providing it the value that follows after the tag. This means that <strong>loading an untrusted yaml document is generally unsafe</strong>, as it may lead to arbitrary code execution. (In Python, you can avoid this pitfall by using <code>yaml.safe_load</code> instead of <code>yaml.load</code>.) In our case above, PyYAML fails to load the document because it doesn’t know the <code>.git</code> tag. Go’s yaml package is less strict and returns an empty string.</p><h2 id="the-norway-problem"><a href="#the-norway-problem"></a>The Norway problem</h2><p>This pitfall is so infamous that it became known as “<a href="https://hitchdev.com/strictyaml/why/implicit-typing-removed/">the Norway problem</a>”:</p><pre><code>geoblock_regions:
  - dk
  - fi
  - is
  - no
  - se</code></pre><div id="cb8"><pre><code><span id="cb8-1"><span>{</span><span>"geoblock_regions"</span><span>:</span> <span>[</span><span>"dk"</span><span>,</span> <span>"fi"</span><span>,</span> <span>"is"</span><span>,</span> <span>false</span><span>,</span> <span>"se"</span><span>]</span><span>}</span></span></code></pre></div><p>What is that <code>false</code> doing there? The literals <code>off</code>, <code>no</code>, and <code>n</code>, in various capitalizations (<a href="https://yaml.org/type/bool.html">but not any capitalization</a>!), are all <code>false</code> in yaml 1.1, while <code>on</code>, <code>yes</code>, and <code>y</code> are true. In yaml 1.2 these alternative spellings of the boolean literals are no longer allowed, but they are so pervasive in the wild that a compliant parser would have a hard time reading many documents. Go’s yaml library therefore <a href="https://github.com/go-yaml/yaml/tree/v3.0.1#compatibility">made the choice</a> of implementing a custom variant somewhere in between yaml 1.1 and 1.2 that behaves differently depending on the context:</p><blockquote><p>The yaml package supports most of <abbr>YAML</abbr> 1.2, but preserves some behavior from 1.1 for backwards compatibility. <abbr>YAML</abbr> 1.1 bools (yes/no, on/off) are supported as long as they are being decoded into a typed bool value. Otherwise they behave as a string.</p></blockquote><p>Note that it only does that since version 3.0.0, which was released in May 2022. <a href="https://github.com/go-yaml/yaml/commit/b145382a4cda47600eceb779844b8090b5807c4f">Earlier versions behave differently</a>.</p><h2 id="non-string-keys"><a href="#non-string-keys"></a>Non-string keys</h2><p>While keys in json are always strings, in yaml they can be any value, including booleans.</p><pre><code>flush_cache:
  on: [push, memory_pressure]
  priority: background</code></pre><div id="cb10"><pre><code><span id="cb10-1"><span>{</span></span>
<span id="cb10-2">  <span>"flush_cache"</span><span>:</span> <span>{</span></span>
<span id="cb10-3">    <span>"True"</span><span>:</span> <span>[</span><span>"push"</span><span>,</span> <span>"memory_pressure"</span><span>]</span><span>,</span></span>
<span id="cb10-4">    <span>"priority"</span><span>:</span> <span>"background"</span></span>
<span id="cb10-5">  <span>}</span></span>
<span id="cb10-6"><span>}</span></span></code></pre></div><p>Combined with the previous feature of interpreting <code>on</code> as a boolean, this leads to a dictionary with <code>true</code> as one of the keys. It depends on the language how that maps to json, if at all. In Python it becomes the string <code>"True"</code>. The key <code>on</code> is common in the wild because <a href="https://docs.github.com/en/actions/using-workflows/workflow-syntax-for-github-actions#on">it is used in GitHub Actions</a>. I would be really curious to know whether GitHub Actions’ parser looks at <code>"on"</code> or <code>true</code> under the hood.</p><h2 id="accidental-numbers"><a href="#accidental-numbers"></a>Accidental numbers</h2><p>Leaving strings unquoted can easily lead to unintentional numbers.</p><pre><code>allow_postgres_versions:
  - 9.5.25
  - 9.6.24
  - 10.23
  - 12.13</code></pre><div id="cb12"><pre><code><span id="cb12-1"><span>{</span><span>"allow_postgres_versions"</span><span>:</span> <span>[</span><span>"9.5.25"</span><span>,</span> <span>"9.6.24"</span><span>,</span> <span>10.23</span><span>,</span> <span>12.13</span><span>]</span><span>}</span></span></code></pre></div><p>Maybe the list is a contrived example, but imagine updating a config file that lists a single value of 9.6.24 and changing it to 10.23. Would you remember to add the quotes? What makes this even more insidious is that many dynamically typed applications implicitly convert the number to a string when needed, so your document works fine most of the time, except in some contexts it doesn’t. For example, the following Jinja template accepts both <code>version: "0.0"</code> and <code>version: 0.0</code>, but it only takes the true-branch for the former.</p><pre><code>{% if version %}
  Latest version: {{ version }}
{% else %}
  Version not specified
{% endif %}</code></pre><h2 id="runners-up"><a href="#runners-up"></a>Runners-up</h2><p>There is only so much I can fit into one artifical example. Some arcane yaml behaviors that did not make it in are <a href="https://yaml.org/spec/1.2.2/#68-directives">directives</a>, integers starting with <code>0</code> being octal literals (but only in yaml 1.1), <code>~</code> being an alternative spelling of <code>null</code>, and <code>?</code> introducing a <a href="https://yaml.org/spec/1.2.2/#example-mapping-between-sequences">complex mapping key</a>.</p><h2 id="syntax-highlighting-will-not-save-you"><a href="#syntax-highlighting-will-not-save-you"></a>Syntax highlighting will not save you</h2><p>You may have noticed that none of my examples have syntax highlighting enabled. Maybe I am being unfair to yaml, because syntax highlighting would highlight special constructs, so you can at least see that some values are not normal strings. However, due to multiple yaml versions being prevalent, and highlighters having different levels of sophistication, you can’t rely on this. I’m not trying to nitpick here: Vim, my blog generator, GitHub, and Codeberg, all have a unique way to highlight the example document from this post. No two of them pick out the same subset of values as non-strings!</p><h2 id="templating-yaml-is-a-terrible-terrible-idea"><a href="#templating-yaml-is-a-terrible-terrible-idea"></a>Templating yaml is a terrible, terrible idea</h2><p>I hope it is clear by now that working with yaml is subtle at the very least. What is even more subtle is concatenating and escaping arbitrary text fragments in such a way that the result is a valid yaml document, let alone one that does what you expect. Add to this the fact that whitespace is significant in yaml, and the result is a format that is <a href="https://twitter.com/memenetes/status/1600898397279502336">meme-worthily</a> difficult to template correctly. I truly do not understand why <a href="https://helm.sh/docs/chart_best_practices/templates/">tools based on such an error-prone practice</a> have gained so much mindshare, when there is a safer, easier, and more powerful alternative: generating json.</p><h2 id="alternative-configuration-formats"><a href="#alternative-configuration-formats"></a>Alternative configuration formats</h2><p>I think the main reason that yaml is so prevalent despite its pitfalls, is that for a long time it was the only viable configuration format. Often we need lists and nested data, which rules out flat formats like ini. Xml is noisy and annoying to write by hand. But most of all, we need comments, which rules out json. (As we saw before, json had comments very early on, but they were removed because people started putting parsing directives in there. I think this is the right call for a serialization format, but it makes json unsuitable as a configuration language.) So if what we really need is the json data model but a syntax that allows comments, what are some of the options?</p><ul><li><a href="https://toml.io/en/"><strong>Toml</strong></a> — Toml is similar to yaml in many ways: it has mostly the same data types; the syntax is not as verbose as json; and it allows comments. Unlike yaml it is not full of footguns, mostly because strings are always quoted, so you don’t have values that look like strings but aren’t. Toml is widely supported, you can probably find a toml parser for your favorite language. It’s even in the Python standard library — unlike yaml! A weak spot of toml is deeply nested data.</li><li><a href="https://code.visualstudio.com/docs/languages/json#_json-with-comments"><strong>Json with comments</strong></a>, <a href="https://nigeltao.github.io/blog/2021/json-with-commas-comments.html"><strong>Json with commas and comments</strong></a> — There exist various extensions of json that extend it just enough to make it a usable config format without introducing too much complexity. Json with comments is probably the most widespread, as it is used as the config format for Visual Studio Code. The main downside of these is that they haven’t really caught on (yet!), so they aren’t as widely supported as json or yaml.</li><li><strong>A simple subset of yaml</strong> — Many of the problems with yaml are caused by unquoted things that look like strings but behave differently. This is easy to avoid: always quote all strings. (Indeed, you can tell that somebody is an experienced yaml engineer when they defensively quote all the strings.) We can choose to always use <code>true</code> and <code>false</code> rather than <code>yes</code> and <code>no</code>, and generally stay away from the arcane features. The challenge with this is that any construct not explicitly forbidden will eventually make it into your codebase, and I am not aware of any good tool that can enforce a sane yaml subset.</li></ul><h2 id="generating-json-as-a-better-yaml"><a href="#generating-json-as-a-better-yaml"></a>Generating json as a better yaml</h2><p>Often the choice of format is not ours to make, and an application only accepts yaml. Not all is lost though, because yaml is a superset of json, so any tool that can produce json can be used to generate a yaml document.</p><p>Sometimes an application will start out with a need for just a configuration format, but over time you end up with many many similar stanzas, and you would like to share parts between them, and abstract some repetition away. This tends to happen in for example Kubernetes and GitHub Actions. When the configuration language does not support abstraction, people often reach for templating, which is a bad idea for the reasons explained earlier. Proper programming languages, possibly domain-specific ones, are a better fit. Some of my favorites are Nix and Python:</p><ul><li><a href="https://nixos.org/manual/nix/stable/language/index.html"><strong>Nix</strong></a> — Nix is the language used by the <a href="https://nixos.org/">Nix package manager</a>. It was created for writing package definitions, but it works remarkably well as a configuration format (and indeed it is used to configure NixOS). Functions, let-bindings, and string interpolation make it powerful for abstracting repetitive configuration. The syntax is light like toml, and it can <a href="https://nixos.org/manual/nix/stable/language/builtins.html#builtins-toJSON">export to json</a> or xml. It works well for simplifying a repetitive GitHub Actions workflow file, for example.</li><li><a href="https://www.python.org/"><strong>Python</strong></a> — Json documents double as valid Python literals with minimal adaptation, and Python supports trailing commas and comments. It has variables and functions, powerful string interpolation, and <a href="https://docs.python.org/3/library/json.html?highlight=json%20dump#json.dump"><code>json.dump</code></a> built in. A self-contained Python file that prints json to stdout goes a long way!</li></ul><p>Finally there are some tools in this category that I haven’t used enough to confidently recommend, but which deserve to be mentioned:</p><ul><li><a href="https://dhall-lang.org/"><strong>Dhall</strong></a> — Dhall is like Nix, but with types. It is less widespread, and personally I find the built-in function names unwieldy.</li><li><a href="https://cuelang.org/"><strong>Cue</strong></a> — Like Dhall, Cue integrates type/schema information into the config format. Cue is a superset of json, but despite that, I find the files that actually use Cue’s features to look foreign to me. Cue is on my radar to evaluate further, but I haven’t encountered a problem where Cue looked like the most suitable solution yet.</li><li><a href="https://github.com/hashicorp/hcl"><strong>Hashicorp Configuration Language</strong></a> — I haven’t used <abbr>HCL</abbr> extensively enough to have a strong opinion on it, but in the places where I worked with it, the potential for abstraction seemed more limited than what you can achieve with e.g. Nix.</li></ul><p><strong>2025 update:</strong> After having used <abbr>HCL</abbr> more in practice, I consider it too ad-hoc to seriously recommend. My frustration with <abbr>HCL</abbr> is what prompted me to create <a href="https://rcl-lang.org/"><abbr>RCL</abbr></a>. It <a href="https://ruudvanasseldonk.com/2024/a-reasonable-configuration-language">started as a toy project</a>, but is now at a point where it is both usable and useful.</p><h2 id="conclusion"><a href="#conclusion"></a>Conclusion</h2><p>Yaml aims to be a more human-friendly alternative to json, but with all of its features, it became such a complex format with so many bizarre and unexpected behaviors, that it is difficult for humans to predict how a given yaml document will parse. If you are looking for a configuration format, toml is a friendly format without yaml’s footguns. For cases where you are stuck with yaml, generating json from a more suitable language can be a viable approach. Generating json also opens up the possibility for abstraction and reuse, in a way that is difficult to achieve safely by templating yaml.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Altoids by the Fistful (196 pts)]]></title>
            <link>https://www.scottsmitelli.com/articles/altoids-by-the-fistful/</link>
            <guid>45343449</guid>
            <pubDate>Tue, 23 Sep 2025 06:24:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scottsmitelli.com/articles/altoids-by-the-fistful/">https://www.scottsmitelli.com/articles/altoids-by-the-fistful/</a>, See on <a href="https://news.ycombinator.com/item?id=45343449">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>“Wh— what did you say?”</p><p>It’s close to six o’clock on a weekday afternoon and the bar is starting to get noisy with the after-work crowd. It’s entirely possible I misheard that last part.</p><p>“Altoids! I find the spearmint works a little better overall, but recently I’ve started switching flavors depending on the situation.”</p><p>I’ve worked with James—“Jim” as everyone on the team knows him—for a little over two years and I’m used to this dance now. He gets a kind of tunnel vision in his excitement about whatever shiny new thing has captured his attention. It’s usually pretty easy to shake him out of it.</p><p>“No, Jim, the part before that.”</p><p>He looks at me for a moment, inquisitive, before pushing his beer aside. “Here, let me show you.” He reaches underneath the table and produces his beige-on-brown Timbuk2 messenger bag. There is a small wet spot left behind from his drink, and the bag plops right onto it. I watch as one of his stubby hands unbuckles the outermost pouch while the other one pulls out a small green and white tin. I am obviously intended to see this as clearly as possible, evidenced by the way he places it front and center between us.</p><p>“Regular everyday Altoids, right? You take about four of them, maybe five.” He flips the lid open and traps the requisite number of small white mints between his fingertips, which he then pops into his mouth. “This is the trick; you gotta half-chew it first.” At least two tiny shards fly in my direction as he speaks these words. It is like listening to a slow K-turn executed on a road covered in gravel and seashells. Three more slow and deliberate chomps, then his bite eases. “Mmm.” The communication style switches to mime: an index finger raised in a “one moment” gesture, followed by an exaggerated point downwards while unzipping the main pouch of the bag. It takes a few seconds of rooting around before the star of this particular show is found.</p><p>My eyes barely have enough time to resolve the object under the dismal light at this end of the bar before it’s in his mouth. He’s chewing the full concoction now—mouth closed, thank God. The crunching softens, then fades into the din from a nearby table of sales bros laughing at their sales bro anecdote. Jim is looking at me with a kind of confident smugness I haven’t seen since I bet my buddy at Guitar Center that he couldn’t spontaneously play “Everlong” from memory. A bet I lost, I might add.</p><p>There is a degree of intentional spectacle to this, I’d have to imagine. Each jaw movement is deliberate. Precise. He does not break eye contact with me, though I desperately want to break it with him. I can’t though. The absurdity of the scene is absolutely hypnotizing. One final swallow, a smack of his lips, then he opens his mouth wide like a child proving that they finished all their vegetables and have earned their dessert. “Easy peasy, no problem.”</p><p>“That was…” It’s like a significant piece of my brain has just completely locked up. I’m just saying words without thinking, filling the empty air.</p><p>“A cat turd!” he proclaims, finishing my sentence.</p><p>A beat.</p><p>“You just ate a cat turd.” It’s all I can do in this moment to plainly restate the facts as I understand them, although the sense of alarm is definitely carrying in my voice.</p><p>“Yup, and it didn’t taste bad at all. The spearmint masks it <em>completely.</em> Watch, I’ll do another one.” My eyes widen in dread as I shake my head weakly. I didn’t want to see him do that the first time; I sure as shit don’t want to see it again.</p><p>“No, that’s alright,” I balk.</p><p>There is an awkward reach across the bag as he grabs his glass, tips it toward me in a silent toast, then takes a long swill. Whether he admits it or not, there’s evidently something that needs to be washed down. He lets out a contented sigh as the almost-empty glass thumps back down on the table. I glance down at the chicken wings and carrot sticks I had been picking at. A minute ago, they were kinda bland—merely <em>okay</em> by the standards of pub food. With the abrupt loss of my appetite, now they are destined for the dumpster out back.</p><p>He lifts the small tin of mints and gives it a little shake in front of my face. It sounds a lot more papery and a lot less metallic than I would’ve guessed. “Altoids. I’m not exaggerating when I say these have completely changed the way I work.” I follow this little miracle box as they get tucked back into the bag, the buckles snapping shut to shield them from the lustful gaze of an angry world. He pauses and looks up at me again. “Would you like to try?”</p><p>“No, Jim, I don’t want your cat turds.”</p><p>I don’t want <em>your</em> cat turds. Why did I say it like that? I don’t want <em>anybody’s</em> cat turds!</p><p><em>…Right?</em></p><p>“Completely changed the way I work,” he repeats mechanically, sliding his bag onto the empty seat to his left. I’m finding it quite difficult to look at Jim, so I instead follow the motions of the bag until it is completely out of my view. How many more are in there?</p><p>“I used to spend so much of my day on cat turds, psyching myself up, trying strategies that didn’t work, all the cleanup when I was finished. That’s all gone now. I can never go back to the old way.”</p><p>“I just… I mean…” My brain has started working again, at least superficially, and it has generated so many questions that I’m having a hard time selecting which one to ask first. “How long have you been eating cat turds?” A fine question for this moment, I suppose.</p><p>“What do you mean? I’ve always had to eat cat turds. Since I was a kid in school, on through college, in all my jobs… They keep giving me cat turds and I keep having to eat them, otherwise it starts to pile up and then things really get messy.”</p><p>His face turns slightly serious as he parses my expression, his head tilting in suspicion. “You eat cat turds too, yeah?” I choose not to answer that question. He continues anyway. “Sure. We all do. We have to, ya know?”</p><hr><p><em>We all do.</em></p><p>Those words have been repeating in my head with the consistency of a drumline cadence. <em>We all do.</em></p><p>“Walk sign is on to cross Pawk Avenue. Walk sign is on to cross Pawk Avenue.” I’ve heard this prerecorded voice, clearly belonging to the most disgruntled DOT Traffic Signals employee available at the time of this crosswalk’s construction, at least twice per workday for the last two years. It stirs up a half-remembered dream of a career spent shoveling dirt into a hole—something that feels more like the idea of “honest work” than what I get paid to do every day. I bet nobody on the construction crew spent an entire workday fighting around with brittle, poorly designed automation tooling like I did today.</p><p>I’m quickly but unintentionally refilling my conscious mind with the task I had gleefully abandoned when Jim invited me out to after-work drinks. Normally I’d be irritated to spend more of my waking life thinking about this stuff, but after what I witnessed at the bar I welcome <em>any</em> distraction at all.</p><p>“Okay. So, usually we have a string. This is one of many values inside a mapping type, within a list of similar mappings.” I’m narrating to myself silently, imagining little bits of JSON syntax stamped on rectangles that are kind of stacked on top of each other like playing cards. “But ever since the schema change in V3, sometimes the value is another mapping type that wraps the string we want…” I’m visualizing another square to the right of the existing one. This one is yellow, distinct from the light blue of all the others, and it never occurs to me to question why that is.</p><p>“But because this is actually YAML, and the value comes from a template call, both the string form and the mapping form need to be escaped and indented in a way that works in both cases.” I’m chewing on the problem in pretty much the same mindset I had during work, only now I’m walking across midtown instead of staring at a computer screen. “We could just revert that change, keep the value as JSON like it used to be and insert it verbatim… but DevEx owns that part and I wouldn’t want to have to fight to get that PR approved.”</p><p>“Piece of shit.” I speak that bit out loud without really intending to. I snap back into awareness of my surroundings and look around. Nobody was near enough to hear it. They probably wouldn’t have cared if they were.</p><p>It occurs to me that, whenever anybody asks me what I do for a living and I wave my hand and say “Computers,” this is what I’m trying to avoid needing to have to explain. None of these words are being used in a way that would mean anything to most people. If one were to take the time to carefully define them all and how they fit together semantically, they describe concepts so abstract and detached from any kind of tangible shared experience that you’d hit a second wall trying to explain <em>that</em>.</p><p>“Oh, but wait, we have the <code>nindent</code> function. I could just count up the indentation level of the outer list and… Ah, hell, I forgot this template is transcluded into pod <em>and</em> deployment specs and the nesting levels would be different between the two.” I briefly try to think of which chucklefuck I could blame this design on, but truth be told I rubber-stamped enough questionable pull requests in my time here that a fair amount of this situation is a mess of my own damn making.</p><p>Huh. I really do wonder what I would sound like trying to explain this to somebody who had no experience in the industry. I suppose if I was very excited about it, I might come across like an energetic kid going on and on about all the different Pokémon they know about and all the special attacks and vulnerabilities. But without that spark of passion, and in its place a jaded voice tinged with frustration and contempt, I would probably just sound like a raving lunatic. These words don’t mean anything. I’m not describing something that actually exists. I’m playing the part of an observer in a universe of little floating boxes, becoming physically agitated about a superficial difference within the yellow one, and <em>none of it is real.</em></p><p>I’m definitely not feeling the passion on this one. This code runs deep inside a build-deploy pipeline that I have no hope of ever running directly on the computer I’m using. So I write the code, push it to CI, wait for a bunch of stuff I’m not interested in to finish running, then get to watch my change fail to work for either the stupidest typo that I never should’ve made in the first place, or due to some error that is so novel that even the search engines assume I must really be having some other <em>much more popular</em> error instead of the one I provided. It feels like I am performing surgery using a scalpel held by a boardwalk arcade claw machine, complete with the constant squawking and shitting of project management seagulls.</p><p>And even if I could concisely explain all of that to my hypothetical interlocutor, there’s the even higher-level question: <em>Why?</em> Why did we even make this change? What was so irredeemably wrong with the last two versions of this thing that we’re now doing it all again a third time? What exactly is the goal we’re trying to achieve here? I can’t really say. It’s a question I never asked, partly because I learned a long time ago that asking questions just causes friction. Just nod and shut up. Put a +1 on a sketchy PR and get it out of here. Don’t hold up the pipeline. Recover enough stamina to face down the next eldritch nightmare that slithers its way to the top of my Jira swimlane. “Sounds great, thanks.” Thumbs-up. Grit my teeth through to the next direct deposit, convince myself it’s not so bad. Do it over and over until some ill-defined end condition is met. I’ll know it when I see it. I hope.</p><p>I catch myself at the tail end of a sigh. I fake like I’m yawning to stretch my upper body for a second. Approximately every muscle in my back now aches.</p><p>There’s this very real sense that I don’t… I don’t want to solve this problem. There is no intellectual reward at the end of this journey. It’s not interesting to me. This isn’t something that needs to be fixed, because it’s not a situation that ever should’ve been permitted to happen in the first place. This is just a bunch of contrived nonsense that I <em>must</em> work through because the broader situation dictates it. It doesn’t matter if the solution is good or elegant. It doesn’t matter if it barely works. It doesn’t matter if it causes another problem that I stub my toe on in three weeks. It’s just… what I have to do.</p><p>I stop in my tracks.</p><p>These kinds of problems are <em>my cat turds.</em></p><p>Unlike Jim, though, I can’t just cram a bunch of breath mints into my face to make this go away.</p><hr><p>The “down” escalator into the train station is out of service, and it has been this way all summer. A pair of orange plastic barricades block the landings at both ends. I walk down two flights of stairs alongside a half-dozen other commuters. Having concluded that the template problem simply isn’t worth thinking any further about, I’m back on the cat turds. I understand what Jim was talking about now. This has been happening for almost my entire life, even going back to my days in elementary school.</p><p>All of the homework assignments that were blindly graded against answer keys from the back of a Teacher Edition of the textbook: Cat turds. College admission essays where I profused a longing desire to attend the distinguished universities that my parents and guidance counselor told me I should set my ambitions toward: Cat turds. Probably hundreds of cover letters submitted alongside job applications throughout the years, skimmed by perhaps tens of internal recruiters and hiring managers: Cat turds.</p><p>The notion that it was a good idea to manipulate highly whitespace-sensitive YAML data with the Go <code>text/template</code> package. CI workflows that take 75 minutes to reach the one step in the entire process that fails. Tools and interfaces that force-update and introduce breaking changes for seemingly no justifiable reason, removing or kneecapping features that were being relied on, with issue trackers guarded by thickheaded bots that dismissively auto-close feature requests that kindly ask for consideration for those use cases. Massively over-complicated software that tries to be everything to everybody, but in reality ends up being a gigantic lumbering pile of failure and frustration. <em>Cat turds.</em></p><p>I used to love this stuff. I still do. Except… I don’t. Not lately, anyway. A long time ago, this was unquestionably what I wanted to do with my life. I would stay up late, pushing back my bedtime for a few more minutes with these glorious machines, hacking away on some little project. Then I’d get up early the following morning, excited to jump back into the project before my day out in the world began. I don’t even clearly remember what I was building toward, but I know it had basically zero utility or market potential. The point of doing the project was simply to <em>do the project</em>—to press through problems, to learn new things, and to end the day with more skills and experience than I started with.</p><p>At one point, I had the 7-bit ASCII table memorized. Just the decimal codes; I didn’t really understand the usefulness of the hexadecimal representations, and it never occurred to me that the hex values would work much better in mnemonics. I don’t know why I took the time to learn that. I never really used that knowledge in any real day-to-day work, and it began to fade from my mind as soon as I found some other pointless esoterica to wallpaper over it.</p><p>Look at me now, having to Google how to read a text file line-by-line in Python despite having done it a hundred times at this point. The knowledge is up there somewhere, I’m sure of it. I just can’t always think of the idiom in the heat of the moment. Just a little hint to jog the old brain, that’s all I need.</p><p>I often wonder what my Younger Self would think of me now, failing to remember a two-line snippet of code that you’d find in the first ten pages of any beginner’s guide to the language. He’d probably sneer and say I need to devote more time to studying. But I’m an adult with things to do; I can’t spend all my time just memorizing things just in case I might need the information someday. Oh, and by the way: Younger Self, if you were such a friggin’ hotshot, why did it take you <em>fifteen years</em> to finally wrap your head around regular expressions? What’s that? Because they were <em>hard?</em> So you spent all your time memorizing easy and pointless trivia rather than tackling anything that was genuinely challenging? And then building up a whole air of superiority based on the number of discrete facts you could rattle off, rather than their practical utility? What, were you trying to become a contestant on <em>Computer Jeopardy!</em> or something?</p><p>No wonder Younger Self grew up to be kind of an asshole.</p><p>I mean, I didn’t <em>try</em> to be an asshole. It’s just that I tended to gauge my own self-worth relative to others based on the only social currency we could accurately compare: the amount of “stuff” we knew. Some people memorize car engine displacements, others carry in their noggins enough digits of pi to resolve the observable universe down to the width of a hydrogen atom. I had a litany of command-line switches that I never used for anything, HTML character entity names for writing systems I couldn’t comprehend, and tales of tweaking settings deep inside the Windows 98 Device Manager just so I could brag about having been in there in the first place. I also at one time sincerely believed that maybe if I taught myself to—I’m picking one example out of many—decode Code 39 barcodes in my head, it would somehow make me cool and desirable during otherwise awkward social functions. (I did get reasonably good at it. All it takes is memorizing a couple of three-digit sequences. Having a teenager’s near-field visual acuity certainly helped.)</p><p>Everybody else who didn’t know those little pieces of nothing? They were the lessers. They didn’t put in the time to grind for this knowledge. They had never scaled the peaks of Mount AltaVista, nor had they knelt in the temple of the <em>MSDN Library for Visual Studio</em> on a banged-up pair of CD-Rs. I knew things they did not, therefore I felt I was higher-and-mightier than they were. I and I alone <em>suffered</em> for this knowledge. This attitude manifested itself in one of two ways: In the first case, I would barge my way into situations where my involvement wasn’t needed or appreciated, thinking I could “save” others from the pain I once had to contend with. More often than not, though, I would simply mock people for not knowing things—usually inside my own head, but sometimes outwardly on mailing lists and message boards. There were times when I judged a person to have failed to put in the necessary amount of work, so therefore they did not deserve to rise anywhere near where I considered my own level to be. It didn’t matter if the subject was deeply technical or a disagreement on the precise phrasing of a <em>Simpsons</em> quote. Somebody got something wrong, and it was my job to rectify that.</p><p>I feel bad for the people who worked on teams where Younger Self was the senior engineer. I was full of ideals and convictions back then. “No, we’re not doing that. We’re going to Do It Right instead.” I was full of piss and vinegar. “Here, give me that; I’ll just do it myself.” I was full of shit.</p><p>I now realize that everything I lorded over other people—all the things I gatekept without consciously understanding that this was what I was doing—I didn’t need to do that. It really didn’t help anything. For some number of people who interacted with me, <em>I</em> was the problem. I could’ve been more tolerant or forgiving, I could’ve said “let’s find out together,” I could’ve let other people have the fun once in a while. I could have minded my own damn business and saved everybody the hassle.</p><p>There were people out there who must’ve felt that <em>I was their cat turds.</em></p><p>I’ll never be able to track down and apologize to every person I treated that way. And why did I even build that fiefdom and protect it so jealously? Why was I so insecure? Why did I have to always be right and have a ready justification for why everybody else was wrong?</p><p>It was just me, alone in my tiny sandbox, safe and secure behind my towering fortress of cat turds.</p><hr><p>My usual train, the one packed so full that some riders have to stand in the aisles until after the first or second stop, usually leaves at 5:50. Now about three hours later, one can sometimes get an entire car to themselves. I settle down in a window seat looking out at the desolate platform. Evidently there aren’t all that many people interested in traveling across the river at this hour on a Wednesday evening. It feels nice to sit, despite the fact that I’ve probably sat for a cumulative ten hours—at least—over the course of this day.</p><p>As sometimes happens, another rider boards the train and enters what had up to this point been my personal rail car. He selects the aisle seat in the row directly in front of me. At least 110 other seats in this car, every single one of them empty, and his choice is to sit right here. <em>Sigh.</em> I could get up and move to another seat but I’m… exhausted. I’m here, I’m settled in, and above all I’m just completely out of ambition. I guess it’s fine as long as he doesn’t start playing music or TikTok videos without headphones.</p><p>A long blow from the locomotive horn, and the train begins to creep forward. Right on schedule. We’re in a tunnel deep below the city’s west side, and the view out the window is pitch black aside from the occasional glow from a mercury-vapor emergency light. On the wall beneath each of these lights, patches of graffiti framed by concrete pillars. I wouldn’t say I’ve memorized them all by heart; I can’t even read the tags on the majority of them. But they are at least familiar, and I’ve found some of them serve as convenient signposts along this portion of the trip. I’m not really paying attention to any of them tonight, instead I’m staring blankly at a little patch of window glass as the scene rolls past.</p><p>I refocus my eyes a bit and realize I’m looking at the reflection of a screen, or at least the top corner of one. I turn away from the window and find the source of the light. The man in front of me has opened his laptop—a chunky Dell Latitude or something very close to it—and perched it on a small lap desk fashioned from his leather bag. He opens a web browser and logs into a Microsoft account, one key at a time, hunt-and-peck style. It prompts him for his second factor and he shifts awkwardly in the seat to retrieve his phone. The login process succeeds and, after a few clicks and a fair bit of both of our finite lifetimes spent staring at loading spinners, opens what appears to be a Word document. I can’t read anything on his screen, which is more a testament to how wrecked my eyes have become than anything else, but I can see that there’s about four, perhaps five lines of unformatted text up there already. He strokes his chin while giving it a good read-through, then his hands take their position on the trackpad. Right index finger moves the cursor, left index finger does the clicking. The screen flips to another browser tab, his left hand gratuitously double-clicks on the website suggested by the first tile on the screen, and the page loads.</p><p>I never learned to tell any of these sites apart from each other. I see lots of people using the one with the spirograph logo. The one that looks like a cartoon butthole is also quite popular among some departments at my job. This guy is using the one that’s represented by a symmetrical color blob. Not that one, the other color blob one. Yeah.</p><p>He has opened a chat session that has evidently been going for some time. The text entry box at the bottom of the window waits patiently for fresh input. Letter by agonizing letter, the keys needed to express his thoughts are pressed. The most-pressed key, however, is Backspace. This man is, using the most generous language possible, not a particularly fast or accurate typist. In total, he enters about ten words before pressing Enter. A short moment later, the machine responds. Entire sentences appear in the time it took him to type a single word. Multiple paragraphs with subheadings and bulleted lists scroll into view. The screen fills completely with this fresh text. He looks at this for a moment, moves his hands back to the trackpad, and selects a complete paragraph. His finger presses down with immense force as he drags the selection area ever wider, as if his catch is in danger of wriggling through his fingers if he doesn’t hold the button down hard enough. He flips back to his Word document and pastes the paragraph. Then back to the chat window. He begins typing again. Slowly. Excruciatingly.</p><p>This cycle repeats several times, incrementally building his document up to four or five double-spaced pages in length. It’s not exactly a fast process, but certainly faster than if he had thought up and typed out all that content the old-fashioned way. It’s certainly plausible that he at least read everything that went into the document, but I wouldn’t be able to prove it.</p><p>He selects another piece of text, this one substantially smaller than the other specimens that he’d been handling up until this point. This one is pasted into a discussion thread on Teams. He waits a moment for responses, closes the lid, and the laptop goes back into his bag. The man stands up, wraps the strap over his shoulder, and walks to the front of the car as the train brakes to a full stop. This is where our paths diverge, it would seem. The doors open and he steps out into the night.</p><p>Alone in the train car again, with nothing interesting to eavesdrop on, my mind begins to wander again. I wonder what the purpose of that document was. Why was it being prepared? Who dictated that a half-dozen input phrases needed to be inflated into a thousand-word wall of text? Who was going to sit and read all of that, anyway? And for what purpose?</p><p>I really don’t know. But I do know one thing: It’s cat turds.</p><p>This guy obviously didn’t want to do that task. Whether that was due to lack of passion and interest, or lack of skill and ability, he had a cat turd to eat and he found a little pack of Altoids that he could use to get through it with minimal suffering. The people who have to read it? There’s a good chance they’ll be dealing with a cat turd too. Maybe they can choose to employ a chatbot to summarize it back down to his original inputs. Maybe it’ll even do a passable job preserving the essence of the guy’s prompts.</p><p>It makes sense why a person or group of people would flock to anything that makes life’s demands a little less difficult for themselves. You’d have to be pretty dumb to want to do a task like that manually.</p><p>There’s still the question, though. Why are we all eating cat turds? When did we all collectively agree that we were all a-okay with the idea that we had to subject ourselves to this constant grind of doing shit that doesn’t really need to be done to satisfy requirements that were put in place simply “because” and that seemingly only create more pointless work for other people (or ourselves!) to have to do later?</p><p>One of the defining characteristics of humanity is its ability to build and wield tools that make difficult tasks easier. One would presume there would also be a certain wisdom in knowing which of the difficult tasks were worth doing in the first place but… Well. When you presume, you make a pres out of u and me.</p><hr><p>If I had known ahead of time that I’d be out this late, I would’ve brought a jacket. The early autumn air is calm but crisp, and my borough’s train platform offers very little protection from the chill. The crickets are still chirping, but their song has slowed substantially compared to how they sounded a few weeks back. I stopped parking at the station a long time ago—the monthly pass costs well over $150 now, and most days the parking lot is completely full before six o’clock in the morning anyway. It’s only a mile to the house, and this twenty-minute walk is pretty much the only exercise I get nowadays.</p><p>Once I cross the main boulevard at the four-way stop, it’s all suburban residential side streets. There is basically no traffic at this time of night in my sleepy little bedroom community. All the dogs have been walked, the kids have been put to bed, and the adults… Well, I’m sure there are at least a couple people around here drinking or smoking the memory of their cat turds away.</p><p>I’m no closer to anything resembling inner peace. I find I’ve grown to despise large swaths of the only thing I’ve ever been able to earn reliable income from. I tire of walking a path that has seemingly shifted beneath my feet to point toward a destination I no longer recognize. I’m embarrassed by the jerk my Younger Self used to be, and simultaneously ashamed of the energy I lost as I matured. I don’t really want to do most of what I have to do, while feeling a deep unsated need to achieve something that I have neither the stamina nor the freedom to pursue. At some point I’m going to reach down deep into the well of ambition to discover there ain’t nothing there to pull out anymore. And then?</p><p><em>Something</em> percent of success is simply showing up. That’s roughly how the quote goes, right? I’ve heard seventy percent, ninety percent, hell, let’s call it seventy-eight. It doesn’t matter because it isn’t a real thing that can be measured in any objective way. The idea is to inspire people to at least try. Put your butt in the chair, log into Teams, trick yourself into thinking, well, I made it all the way here, might as well prune my stale Git branches or something so I can feel like I’m doing real work. Push aside distractions, shake off procrastination, kindle that tiny spark into enough momentum to break through whatever barrier is standing in the way of getting something done. If only that worked with any degree of predictability.</p><p>There’s a metaphor that talks about painting the backs of cabinets. The idea is that, when you’re putting paint, stain, varnish, <em>whatever</em> on some cabinets, there’s no need to paint the surfaces that face toward the wall. From the day the units are mounted, to a day forty years from now when they are ripped down and thrown into a construction dumpster during a subsequent kitchen renovation, nobody will see the backs of any of those cabinets. Painting them would be a waste of time and materials. Nobody would know if it was done or not.</p><p>“Yes, but <em>I</em> would know.” That’s something my Dad would often say. His tendency has always been to be overly thorough, exacting and precise in any craft he partakes in. Everything—from the doors in the house to the stripes cut into the front lawn—was always level, plumb, square, centered, polished, dust-free, squeak-free, <em>fingerprint</em>-free… He even demonstrated meticulous care in breaking down cardboard and filling up the waste bins at the curb. I still have no idea how he was able to raise two kids in that house without exploding from the chaos we brought.</p><p>Maybe it was genetic, or maybe I voluntarily developed it so my dad would be proud of me just like he was proud of the other things he made. Either way, I definitely started to take after him in those ways and I now recognize this same kind of care in myself all the time. Not just in the way I prefer all my clocks to read the exact correct time or my knack for always noticing the way the receptacle face isn’t exactly flush with the wall plate… but in a fundamental inability to <em>not care</em> about quality or craft. Even when the task doesn’t matter. Even if it results in an entire afternoon spent painting a piece of carpentry that nobody will ever see. I can’t not care.</p><p>All that stuff Younger Self struggled with—the self-superiority, the sense that I had to be the one who did it if it needed to be done correctly, the derision and borderline abuse I gave others—that was all just a big dogmatic ball of caring a whole lot about quality and craft, being rolled around by a kid who didn’t understand what to do with it. I had to work so hard to care so much, and these other people didn’t, and everything worked out for them anyway, and <em>that wasn’t fair.</em> Decades later, I still feel that way sometimes.</p><p>My parents still live in that house, surrounded by all the things my dad cared so much about. Aside from a whole bunch of trees that died and needed to be cut down to stumps, everything is still pretty much pristine. But if you start to look around, really scrutinize, you’ll start to notice some things have slipped. There’s a film of dust on the higher wall decorations. Some of the brass knobs are becoming tarnished. A few of the light bulbs in the hallway fixtures don’t match. My dad seemed tired the last time we talked, and more than once he expressed the sentiment that “everything he owns is falling apart.” Is it simply the onset of physical old age that has limited his ability to stay on top of these things, or is he beginning to leave behind his era of caring?</p><p>Now that I think about it, I don’t think we’ve ever really talked about how care factored into his career philosophy. I had always implicitly assumed that it was the same as it currently is with me: Work or play, it’s always there. Can’t turn it off even if I wanted to. But what if he could? What if all the care he demonstrated in projects around the house was compensation for all the things he deliberately avoided caring about at work? It would certainly explain how he was able to consistently sustain those standards. But then, that would mean that I modeled my own principles and tastes on a distorted view of my dad, untempered by whatever he didn’t let me see about his workplace persona.</p><p>How would I begin to—well, I don’t want to say “not care,” that sounds too extreme. But maybe… <em>selectively</em> care? To care about the things that matter, the things that spark passion and joy and remind me why I spent so much time practicing this godforsaken occupation. While at the same time recognizing the things that don’t matter, the problems for which the optimal solution is to stop insisting on having that problem in the first place. The kinds of tasks for which the 78% showing-up baseline score is plenty good enough. Tasks on which care would be utterly wasted, the cases where the cabinets are so irredeemably fucked up that the lack of paint on the back is the last thing anybody’s going to worry about. Those are the tasks that hurt the most, because I find it basically impossible to make myself care about them. It offends my soul to try to force it, and it drains me of all ambition to move onto the next potentially heartening opportunity. It’s a real problem, and I find it always has been: If I can’t care about it, I have an extremely hard time bringing myself to do it at all.</p><p>Well, I suppose that’s when I open a chatbot session of my own. “Hey there Chat. Uh, we’ve never spoken before but, uh… Well, my entire system of self-motivation just completely broke down but I still need to keep moving forward. Can you help me out of this bind?” There’s a whole discipline—they call it Prompt Engineering—that’s just a fancy form of throwing your hands up and pressing the Care About It For Me button. That’s pretty much how it works. Provide it with any cat turd under the sun, it doesn’t matter. Chat will gobble them all up for you like a coprophagic dog.</p><p>I’d be lying if I said the idea didn’t make my skin crawl a little. Every fiber of my being says that this is a weight to be borne by me and me alone. This is <em>my</em> cat turd to eat; they gave it to <em>me</em>. When it’s done, I can open my grinning maw and say without equivocation that I was the one who got through it. I painted the back of this cabinet. I worked way too hard and poured far too much of my blood, sweat and tears into this thing. And my reward for a job well done is… debilitating exhaustion, most of the time. Getting a fresh cat turd to eat tomorrow. And the day after.</p><p>Of course, Chat can’t really care. It does a passable job <em>pretending</em> like it cares, saying the words that convey the illusion of care to any reader not paying very close attention. Where do I draw the line between fostering real care, versus passing off a degraded third-generation photocopy of some tokenization of what may have at one point been somebody else’s care? Is the line simply the boundary between the tasks I’m excited to do and the ones I put off until I’ve depleted enough mental reserves to <em>sorta</em> care?</p><p>It really does feel like the average person has made a choice to abandon a great deal of care, at least in their professional capacity. Take a look around at all these people with their fake shit-eating grins, passing off a machine’s effort as their own and experiencing no consequences. Sometimes they’re rewarded for doing so. There are organizations that are beginning to mandate it now. These people aren’t eating their cat turds anymore, why am I still sitting here eating mine?</p><p>I round the final curve leading to the corner of my block. As I pass under the streetlight, I cast a shadow on the asphalt ahead. With each step it grows longer and more distorted. There’s a rustle from the shrubs bordering my neighbor’s driveway, and a small dark form emerges. It crosses the street halfway then abruptly stops. I stop as well. A pair of glowing yellow eyes look back at me. I stare at it, it stares at me. A possum, perhaps? Somebody’s outdoor cat? It’s just watching me, seemingly peering straight into my very soul. Can it see what I’m grappling with here? Is it passing judgement on me for thinking these thoughts? It sizes me up for a moment longer, turns its head, and becomes a black apparition once more. I struggle to track it as it continues across the street, and I lose sight of it entirely.</p><p>I arrive at home and shut the door behind me. Sunset was over two hours ago and it’s nearly pitch black in the hallway. I fumble around for the light switch, kick my shoes off next to the doorway, and hang my bag on its hook in the coat closet. Something grabs my attention, just above eye level, slightly overhanging the edge of the top shelf. I slide it out of its resting place and carry it into the kitchen. I sit down at the table and inspect it.</p><p>This object is a round metal cookie tin about twelve inches in diameter. Beneath a thin coat of dust, it is a deep red with a repeating pattern of snowmen and white snowflakes, and quite obviously once held winter holiday–themed cookies. I repurposed it many years ago to hold the only vice I currently permit myself to indulge in: a meticulously curated collection of all different types of chocolate candies. I remove the lid and set it aside. I survey the contents, a sea of differently-shaped naked chocolate morsels. I don’t remember why I chose to remove all the foil and paper wrapping before putting these in here. From my vantage point, everything looks vaguely the same—I can’t readily spot any differences between milk chocolate and dark, or those filled with caramel versus crème.</p><p>One particular piece near the edge catches my eye, and I carefully select it for inspection. It’s not a very pleasing color or shape—oddly asymmetrical. I roll it around between my fingers. There’s a hair on it. I hold it up to my nose and take a whiff, hoping to detect the aroma of the cacao. Try as I might, I can’t pick up any trace of its scent.</p><p>Come to think of it, I can’t remember the last time I smelled anything.</p><a href="https://www.scottsmitelli.com/articles/" title="Articles">«&nbsp;Back to Articles</a></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delete FROM users WHERE location = 'Iran'; (807 pts)]]></title>
            <link>https://gist.github.com/avestura/ce2aa6e55dad783b1aba946161d5fef4</link>
            <guid>45343108</guid>
            <pubDate>Tue, 23 Sep 2025 05:30:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/avestura/ce2aa6e55dad783b1aba946161d5fef4">https://gist.github.com/avestura/ce2aa6e55dad783b1aba946161d5fef4</a>, See on <a href="https://news.ycombinator.com/item?id=45343108">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="file-delete-from-users-where-location-iran-md" tabindex="0" role="region" aria-label="delete-from-users-where-location-iran.md content, created by avestura on 05:27AM today.">
    <article itemprop="text"><p dir="auto"><h2 dir="auto"><code>DELETE FROM users WHERE location = 'IRAN';</code></h2><a id="user-content-delete-from-users-where-location--iran" aria-label="Permalink: DELETE FROM users WHERE location = 'IRAN';" href="#delete-from-users-where-location--iran"></a></p>
<p dir="auto">Hi! I am an Iranian Software Engineer, and in this torn paper note, I want to talk about
some funny moments I had online related to the fact that I was spawned in this specific region of the world: Iran.</p>
<p dir="auto"><h2 dir="auto">Microsoft deleted my app, ignored my mails</h2><a id="user-content-microsoft-deleted-my-app-ignored-my-mails" aria-label="Permalink: Microsoft deleted my app, ignored my mails" href="#microsoft-deleted-my-app-ignored-my-mails"></a></p>
<p dir="auto">Back when I was a student, I got access to the <a href="https://imaginecup.microsoft.com/en-us" rel="nofollow">Microsoft Imagine</a>, and as a result, I got
access to the Microsoft Store as a developer. This inspired me write one of my open-source projects called <a href="https://github.com/avestura/EyesGuard">EyesGuard</a>
and publish it on Microsoft Store. However, one day, somebody told me that they can no longer find EyesGuard on the store.</p>
<p dir="auto">I came to the realization that Microsoft deleted my app, my developer account, and all those comments on my app supporting me and suggesting
ideas on how to improve the program. I tried to contact the support and email whoever I could, but I was ghosted.
Nobody ever explained to me why, but I assume it's because of the sanctions.</p>
<p dir="auto"><h2 dir="auto">Notion wiped me out of existence</h2><a id="user-content-notion-wiped-me-out-of-existence" aria-label="Permalink: Notion wiped me out of existence" href="#notion-wiped-me-out-of-existence"></a></p>
<p dir="auto">Notion is a great product, and it was the primary tool I used to manage my personal notes. Not until they suddenly decided to
wipe out every data related to the users residing in Iran. Hopefully, they actually responded to my support message:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/9091958/492630193-dae97147-1dce-4619-8e3a-91ea51d1a506.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg2MDkzMDIsIm5iZiI6MTc1ODYwOTAwMiwicGF0aCI6Ii85MDkxOTU4LzQ5MjYzMDE5My1kYWU5NzE0Ny0xZGNlLTQ2MTktOGUzYS05MWVhNTFkMWE1MDYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDkyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA5MjNUMDYzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZWJlNTIwYmNiZGQwNTUwNmQyNzVmMmYzYzJiYWY2ZDc4NDgyMjdmYjQxZmQ4ZDI0OWIzOGY0MjllZDYzNzQ5MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.qGT2Dm1lgvCTESM1K6DgzwP55Tv40w_2kS7CL0jno_I"><img width="408" height="398" alt="image" src="https://private-user-images.githubusercontent.com/9091958/492630193-dae97147-1dce-4619-8e3a-91ea51d1a506.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg2MDkzMDIsIm5iZiI6MTc1ODYwOTAwMiwicGF0aCI6Ii85MDkxOTU4LzQ5MjYzMDE5My1kYWU5NzE0Ny0xZGNlLTQ2MTktOGUzYS05MWVhNTFkMWE1MDYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDkyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA5MjNUMDYzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZWJlNTIwYmNiZGQwNTUwNmQyNzVmMmYzYzJiYWY2ZDc4NDgyMjdmYjQxZmQ4ZDI0OWIzOGY0MjllZDYzNzQ5MCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.qGT2Dm1lgvCTESM1K6DgzwP55Tv40w_2kS7CL0jno_I"></a>
<p dir="auto">It was because of sanctions. However, they told me that they will not restore the data, even if I leave Iran someday:</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/9091958/492630571-c934ce8b-ca83-471c-991a-269548a9e584.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg2MDkzMDIsIm5iZiI6MTc1ODYwOTAwMiwicGF0aCI6Ii85MDkxOTU4LzQ5MjYzMDU3MS1jOTM0Y2U4Yi1jYTgzLTQ3MWMtOTkxYS0yNjk1NDhhOWU1ODQucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDkyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA5MjNUMDYzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjMwOWQ2NDAzYmU1NzBiOWY0Mzg3YTkxYzg4NzE4Zjg4NzkxYjM4ZTNkNjdlM2UxMzA5ZTQxZGRiZTdjM2FiZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.AFrKoAhkapFhYHrIBuRAPkgqpnyx3MPOIp9ElPC1qWM"><img width="429" height="675" alt="image" src="https://private-user-images.githubusercontent.com/9091958/492630571-c934ce8b-ca83-471c-991a-269548a9e584.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg2MDkzMDIsIm5iZiI6MTc1ODYwOTAwMiwicGF0aCI6Ii85MDkxOTU4LzQ5MjYzMDU3MS1jOTM0Y2U4Yi1jYTgzLTQ3MWMtOTkxYS0yNjk1NDhhOWU1ODQucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDkyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA5MjNUMDYzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YjMwOWQ2NDAzYmU1NzBiOWY0Mzg3YTkxYzg4NzE4Zjg4NzkxYjM4ZTNkNjdlM2UxMzA5ZTQxZGRiZTdjM2FiZCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.AFrKoAhkapFhYHrIBuRAPkgqpnyx3MPOIp9ElPC1qWM"></a>
<p dir="auto">That said, I am very happy with my own self-hosted <a href="https://github.com/siyuan-note/siyuan">Siyuan</a> now.</p>
<p dir="auto"><h2 dir="auto">Mike Cardwell kindly asked me to fuck off</h2><a id="user-content-mike-cardwell-kindly-asked-me-to-fuck-off" aria-label="Permalink: Mike Cardwell kindly asked me to fuck off" href="#mike-cardwell-kindly-asked-me-to-fuck-off"></a></p>
<p dir="auto">I read hackernews on a daily basis and I visit lots of different websites regularly. I am almost always on my VPN as I am internally firewalled by
the government and externally shooed because of the sanctions, so I am probably missing some of these heart-warming messages:</p>
<blockquote>
<p dir="auto">Iranian IPs are blocked here, due to your decision to arm Russia with drones so that they can indiscriminately massacre civilians.</p>
</blockquote>
<p dir="auto">My VPN turned off, and opening <a href="https://www.grepular.com/" rel="nofollow">https://www.grepular.com</a> showed me this message. I actually do not blame the people who do this. I think there is
a fundamental misconception that people think because "Islamic Republic" has the word "Republic" in it, it must be a government of people in charge. That's not the case. I have yet to see anyone who actually supports Russian aggression in my real life in Iran.
Funny enough, Iran's history is full of backstabs by the Russian government.</p>
<p dir="auto">I tried contacting the author by sending this email:</p>
<pre><code>Hi Mark,

I hope this message finds you well.

While browsing HackerNews, I came across your website but was greeted with this message:

&gt; Iranian IPs are blocked here, due to your decision to arm Russia with drones so that they can indiscriminately massacre civilians.

I wanted to clarify that the decision to support Russia does not represent the Iranian people. That "your decision" refers to the regime, a theocratic minority that rules Iran without democratic legitimacy. The people of Iran have long protested and revolted against this regime, but unfortunately, they face brutal suppression while unarmed.

In my experience, most Iranians around me, including myself, stand firmly with Ukraine and against Russian aggression.

I’m not asking you to reconsider the IP restriction, you have your reasons and I respect that. I simply wanted to share this perspective and express my solidarity with Ukraine.

Slava Ukraini!

Best regards,
Avestura
</code></pre>
<p dir="auto">I got no replies from them, and I actually didn't expect one.</p>
<p dir="auto"><h2 dir="auto">GitHub freaked me out</h2><a id="user-content-github-freaked-me-out" aria-label="Permalink: GitHub freaked me out" href="#github-freaked-me-out"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/9091958/492637005-641fc0ea-69f7-4fcd-acdd-0e51fc805f85.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg2MDkzMDIsIm5iZiI6MTc1ODYwOTAwMiwicGF0aCI6Ii85MDkxOTU4LzQ5MjYzNzAwNS02NDFmYzBlYS02OWY3LTRmY2QtYWNkZC0wZTUxZmM4MDVmODUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDkyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA5MjNUMDYzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWMzNjRhYWYwOTRiYjkwYjNkMDcwODJlOTUzODE3OTQ1YjYzZDc2MGQ3ZDJjNjc4MTA4NzZjYTYzMWM1ZWI5NCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.iGhqNMK8FIXGztELHd2ZcypMrZejiPHcDtSVz9aGYTM"><img width="2000" height="321" alt="image" src="https://private-user-images.githubusercontent.com/9091958/492637005-641fc0ea-69f7-4fcd-acdd-0e51fc805f85.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NTg2MDkzMDIsIm5iZiI6MTc1ODYwOTAwMiwicGF0aCI6Ii85MDkxOTU4LzQ5MjYzNzAwNS02NDFmYzBlYS02OWY3LTRmY2QtYWNkZC0wZTUxZmM4MDVmODUucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDkyMyUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTA5MjNUMDYzMDAyWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NWMzNjRhYWYwOTRiYjkwYjNkMDcwODJlOTUzODE3OTQ1YjYzZDc2MGQ3ZDJjNjc4MTA4NzZjYTYzMWM1ZWI5NCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.iGhqNMK8FIXGztELHd2ZcypMrZejiPHcDtSVz9aGYTM"></a>
<p dir="auto">I woke up to the news that GitHub has removed the access of Iranians to their private repositories. Well, that was not good. I tried to launch my own self-hosted instance of Gitea to reduce the damage. However, later, GitHub announced that <a href="https://github.blog/news-insights/policy-news-and-insights/advancing-developer-freedom-github-is-fully-available-in-iran/" rel="nofollow">github is now available in Iran</a> by securing a license from the US government, and we're now good. You see? The weather is good, the birds are singing, GitHub is free again. Fantastic!</p>
<p dir="auto"><h2 dir="auto">GitLab freaked me out</h2><a id="user-content-gitlab-freaked-me-out" aria-label="Permalink: GitLab freaked me out" href="#gitlab-freaked-me-out"></a></p>
<p dir="auto">Similarly, GitLab banned every account that once accessed from an Iranian IP, however, to this day, they never lifted the
ban, even on public repositories. I guess they couldn't secure a license from the US government, or they simply never cared.
Good luck to them in either case, though. GitLab is an amazing software. One can always self-host it.</p>
<p dir="auto"><h2 dir="auto">List goes on</h2><a id="user-content-list-goes-on" aria-label="Permalink: List goes on" href="#list-goes-on"></a></p>
<p dir="auto">The list goes on, and almost all of the services you probabelly heard of is banned here: Cloud platforms (AWS, GCP, Azure, ...),
Educational platforms (coursera, udemy, etc), Payment software (stripe, paypal, ...).</p>
<p dir="auto"><h2 dir="auto">Lessons Learned for me</h2><a id="user-content-lessons-learned-for-me" aria-label="Permalink: Lessons Learned for me" href="#lessons-learned-for-me"></a></p>
<p dir="auto">I don't think any of these companies have bad intentions towards any group of people. They are a business after all. They don't hate their customers; they are just playing the game, and the game has such rules.
But if someday some law or government forces me to prevent my services from a group, I'll think twice before writing those <code>if</code> statements. I'll try to have more empathy. People behind those screens are more important than just some rows in my tables.</p>
<p dir="auto"><h2 dir="auto">Footnote</h2><a id="user-content-footnote" aria-label="Permalink: Footnote" href="#footnote"></a></p>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">In this text, I am NOT asking for the removal of
the sanctions targeted at the Islamic Republic of Iran. I am merely remembering some moments on top of my head.
For the record, I do not support
the actions of the Islamic Republic, and on the contrary, I am in favor of the movements that release the people from such
a mafia-like cult ruling a country with thousands of years of history.
The actions of the group in charge of Iran are not defensible, and as a matter of fact,
the people of Iran are the first layer of victims. Some examples are listed <a href="https://en.wikipedia.org/wiki/Human_rights_in_the_Islamic_Republic_of_Iran" rel="nofollow">here</a>.
I especially feel it differently, as regime thugs put a gun to the throat of a dear person to me, and threatened to kill him if he showed up in
<a href="https://en.wikipedia.org/wiki/Mahsa_Amini_protests" rel="nofollow">protests</a>.</p>
</div>
<hr>
<p dir="auto">By the way, did you know you could return <code>451 Unavailable For Legal Reasons</code> instead of <code>403 Forbidden</code> when you're going to ban me next time?</p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zoxide: A Better CD Command (260 pts)]]></title>
            <link>https://github.com/ajeetdsouza/zoxide</link>
            <guid>45342943</guid>
            <pubDate>Tue, 23 Sep 2025 04:48:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ajeetdsouza/zoxide">https://github.com/ajeetdsouza/zoxide</a>, See on <a href="https://news.ycombinator.com/item?id=45342943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<div dir="auto">
<p dir="auto"><sup>Special thanks to:</sup></p>

<p><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-03.png"><img alt="Sponsored by Warp" width="230" src="https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-03.png"></a></p>
<p><sup><b>Warp, built for coding with multiple AI agents.</b></sup></p>
<p><sup>Available for macOS, Linux, and Windows.</sup></p>

<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">zoxide</h2><a id="user-content-zoxide" aria-label="Permalink: zoxide" href="#zoxide"></a></p>
<p dir="auto"><a href="https://crates.io/crates/zoxide" rel="nofollow"><img src="https://camo.githubusercontent.com/c600cc259ea1db64e40df12e33b80707dd3a383f09bbd72c1315225d8b29183f/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f7a6f786964653f6c6f676f3d72757374266c6f676f436f6c6f723d7768697465267374796c653d666c61742d737175617265" alt="crates.io" data-canonical-src="https://img.shields.io/crates/v/zoxide?logo=rust&amp;logoColor=white&amp;style=flat-square"></a>
<a href="https://github.com/ajeetdsouza/zoxide/releases"><img src="https://camo.githubusercontent.com/4724c9dca44447f4a8b3d5e8e36354c960f0642ef2c7bf75ee4a406d334f5690/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f616a65657464736f757a612f7a6f786964652f746f74616c3f6c6f676f3d676974687562266c6f676f436f6c6f723d7768697465267374796c653d666c61742d737175617265" alt="Downloads" data-canonical-src="https://img.shields.io/github/downloads/ajeetdsouza/zoxide/total?logo=github&amp;logoColor=white&amp;style=flat-square"></a>
<a href="https://builtwithnix.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/1020260f225ef60f8901026b2dea1ce80fa2208b469b11b03a140e779e65de13/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6275696c74776974682d6e69782d3764383166373f6c6f676f3d6e69786f73266c6f676f436f6c6f723d7768697465267374796c653d666c61742d737175617265" alt="Built with Nix" data-canonical-src="https://img.shields.io/badge/builtwith-nix-7d81f7?logo=nixos&amp;logoColor=white&amp;style=flat-square"></a></p>
<p dir="auto">zoxide is a <strong>smarter cd command</strong>, inspired by z and autojump.</p>
<p dir="auto">It remembers which directories you use most frequently, so you can "jump" to
them in just a few keystrokes.<br>
zoxide works on all major shells.</p>
<p dir="auto"><a href="#getting-started">Getting started</a> •
<a href="#installation">Installation</a> •
<a href="#configuration">Configuration</a> •
<a href="#third-party-integrations">Integrations</a></p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/ajeetdsouza/zoxide/blob/main/contrib/tutorial.webp"><img src="https://github.com/ajeetdsouza/zoxide/raw/main/contrib/tutorial.webp" alt="Tutorial"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="z foo              # cd into highest ranked directory matching foo
z foo bar          # cd into highest ranked directory matching foo and bar
z foo /            # cd into a subdirectory starting with foo

z ~/foo            # z also works like a regular cd command
z foo/             # cd into relative path
z ..               # cd one level up
z -                # cd into previous directory

zi foo             # cd with interactive selection (using fzf)

z foo<SPACE><TAB>  # show interactive completions (zoxide v0.8.0+, bash 4.4+/fish/zsh only)"><pre>z foo              <span><span>#</span> cd into highest ranked directory matching foo</span>
z foo bar          <span><span>#</span> cd into highest ranked directory matching foo and bar</span>
z foo /            <span><span>#</span> cd into a subdirectory starting with foo</span>

z <span>~</span>/foo            <span><span>#</span> z also works like a regular cd command</span>
z foo/             <span><span>#</span> cd into relative path</span>
z ..               <span><span>#</span> cd one level up</span>
z -                <span><span>#</span> cd into previous directory</span>

zi foo             <span><span>#</span> cd with interactive selection (using fzf)</span>

z foo<span>&lt;</span>SPACE&gt;&lt;TAB<span>&gt;</span>  <span><span>#</span> show interactive completions (zoxide v0.8.0+, bash 4.4+/fish/zsh only)</span></pre></div>
<p dir="auto">Read more about the matching algorithm <a href="https://github.com/ajeetdsouza/zoxide/wiki/Algorithm#matching">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">zoxide can be installed in 4 easy steps:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Install binary</strong></p>
<p dir="auto">zoxide runs on most major platforms. If your platform isn't listed below,
please <a href="https://github.com/ajeetdsouza/zoxide/issues/new">open an issue</a>.</p>
<details>
<summary>Linux / WSL</summary>
<blockquote>
<p dir="auto">The recommended way to install zoxide is via the install script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh"><pre>curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh <span>|</span> sh</pre></div>
<p dir="auto">Or, you can use a package manager:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Distribution</th>
<th>Repository</th>
<th>Instructions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><em>Any</em></strong></td>
<td><strong><a href="https://crates.io/crates/zoxide" rel="nofollow">crates.io</a></strong></td>
<td><code>cargo install zoxide --locked</code></td>
</tr>
<tr>
<td><em>Any</em></td>
<td><a href="https://github.com/asdf-vm/asdf">asdf</a></td>
<td><code>asdf plugin add zoxide https://github.com/nyrst/asdf-zoxide.git</code> <br> <code>asdf install zoxide latest</code></td>
</tr>
<tr>
<td><em>Any</em></td>
<td><a href="https://anaconda.org/conda-forge/zoxide" rel="nofollow">conda-forge</a></td>
<td><code>conda install -c conda-forge zoxide</code></td>
</tr>
<tr>
<td><em>Any</em></td>
<td><a href="https://packages.guix.gnu.org/packages/zoxide/" rel="nofollow">guix</a></td>
<td><code>guix install zoxide</code></td>
</tr>
<tr>
<td><em>Any</em></td>
<td><a href="https://formulae.brew.sh/formula-linux/zoxide" rel="nofollow">Linuxbrew</a></td>
<td><code>brew install zoxide</code></td>
</tr>
<tr>
<td><em>Any</em></td>
<td><a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/zo/zoxide/package.nix">nixpkgs</a></td>
<td><code>nix-env -iA nixpkgs.zoxide</code></td>
</tr>
<tr>
<td>AlmaLinux</td>
<td></td>
<td><code>dnf install zoxide</code></td>
</tr>
<tr>
<td>Alpine Linux 3.13+</td>
<td><a href="https://pkgs.alpinelinux.org/packages?name=zoxide" rel="nofollow">Alpine Linux Packages</a></td>
<td><code>apk add zoxide</code></td>
</tr>
<tr>
<td>Arch Linux</td>
<td><a href="https://archlinux.org/packages/extra/x86_64/zoxide/" rel="nofollow">Arch Linux Extra</a></td>
<td><code>pacman -S zoxide</code></td>
</tr>
<tr>
<td>CentOS Stream</td>
<td></td>
<td><code>dnf install zoxide</code></td>
</tr>
<tr>
<td><del>Debian 11+</del><sup><a href="#user-content-fn-1-fad79386de4d55dbdbd472811d9bcdf2" id="user-content-fnref-1-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></td>
<td><del><a href="https://packages.debian.org/stable/admin/zoxide" rel="nofollow">Debian Packages</a></del></td>
<td><del><code>apt install zoxide</code></del></td>
</tr>
<tr>
<td>Devuan 4.0+</td>
<td><a href="https://pkginfo.devuan.org/cgi-bin/package-query.html?c=package&amp;q=zoxide" rel="nofollow">Devuan Packages</a></td>
<td><code>apt install zoxide</code></td>
</tr>
<tr>
<td>Exherbo Linux</td>
<td><a href="https://gitlab.exherbo.org/exherbo/rust/-/tree/master/packages/sys-apps/zoxide" rel="nofollow">Exherbo packages</a></td>
<td><code>cave resolve -x repository/rust</code> <br> <code>cave resolve -x zoxide</code></td>
</tr>
<tr>
<td>Fedora 32+</td>
<td><a href="https://src.fedoraproject.org/rpms/rust-zoxide" rel="nofollow">Fedora Packages</a></td>
<td><code>dnf install zoxide</code></td>
</tr>
<tr>
<td>Gentoo</td>
<td><a href="https://packages.gentoo.org/packages/app-shells/zoxide" rel="nofollow">Gentoo Packages</a></td>
<td><code>emerge app-shells/zoxide</code></td>
</tr>
<tr>
<td>Linux Mint</td>
<td><a href="https://apt.cli.rs/" rel="nofollow">apt.cli.rs</a> (unofficial)</td>
<td><a href="https://github.com/emmatyping/apt.cli.rs#how-to-add-the-repo">Setup the repository</a>, then <code>apt install zoxide</code></td>
</tr>
<tr>
<td>Manjaro</td>
<td></td>
<td><code>pacman -S zoxide</code></td>
</tr>
<tr>
<td>openSUSE Tumbleweed</td>
<td><a href="https://build.opensuse.org/package/show/openSUSE:Factory/zoxide" rel="nofollow">openSUSE Factory</a></td>
<td><code>zypper install zoxide</code></td>
</tr>
<tr>
<td><del>Parrot OS</del><sup><a href="#user-content-fn-1-fad79386de4d55dbdbd472811d9bcdf2" id="user-content-fnref-1-2-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></td>
<td></td>
<td><del><code>apt install zoxide</code></del></td>
</tr>
<tr>
<td><del>Raspbian 11+</del><sup><a href="#user-content-fn-1-fad79386de4d55dbdbd472811d9bcdf2" id="user-content-fnref-1-3-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></td>
<td><del><a href="https://archive.raspbian.org/raspbian/pool/main/r/rust-zoxide/" rel="nofollow">Raspbian Packages</a></del></td>
<td><del><code>apt install zoxide</code></del></td>
</tr>
<tr>
<td>RHEL 8+</td>
<td></td>
<td><code>dnf install zoxide</code></td>
</tr>
<tr>
<td>Rhino Linux</td>
<td><a href="https://pacstall.dev/packages/zoxide-deb" rel="nofollow">Pacstall Packages</a></td>
<td><code>pacstall -I zoxide-deb</code></td>
</tr>
<tr>
<td>Rocky Linux</td>
<td></td>
<td><code>dnf install zoxide</code></td>
</tr>
<tr>
<td>Slackware 15.0+</td>
<td><a href="https://slackbuilds.org/repository/15.0/system/zoxide/" rel="nofollow">SlackBuilds</a></td>
<td><a href="https://slackbuilds.org/howto/" rel="nofollow">Instructions</a></td>
</tr>
<tr>
<td>Solus</td>
<td><a href="https://github.com/getsolus/packages/tree/main/packages/z/zoxide/">Solus Packages</a></td>
<td><code>eopkg install zoxide</code></td>
</tr>
<tr>
<td>Ubuntu</td>
<td><a href="https://apt.cli.rs/" rel="nofollow">apt.cli.rs</a> (unofficial)</td>
<td><a href="https://github.com/emmatyping/apt.cli.rs#how-to-add-the-repo">Setup the repository</a>, then <code>apt install zoxide</code></td>
</tr>
<tr>
<td>Void Linux</td>
<td><a href="https://github.com/void-linux/void-packages/tree/master/srcpkgs/zoxide">Void Linux Packages</a></td>
<td><code>xbps-install -S zoxide</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</blockquote>
</details>
<details>
<summary>macOS</summary>
<blockquote>
<p dir="auto">To install zoxide, use a package manager:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Repository</th>
<th>Instructions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="https://crates.io/crates/zoxide" rel="nofollow">crates.io</a></strong></td>
<td><code>cargo install zoxide --locked</code></td>
</tr>
<tr>
<td><strong><a href="https://formulae.brew.sh/formula/zoxide" rel="nofollow">Homebrew</a></strong></td>
<td><code>brew install zoxide</code></td>
</tr>
<tr>
<td><a href="https://github.com/asdf-vm/asdf">asdf</a></td>
<td><code>asdf plugin add zoxide https://github.com/nyrst/asdf-zoxide.git</code> <br> <code>asdf install zoxide latest</code></td>
</tr>
<tr>
<td><a href="https://anaconda.org/conda-forge/zoxide" rel="nofollow">conda-forge</a></td>
<td><code>conda install -c conda-forge zoxide</code></td>
</tr>
<tr>
<td><a href="https://ports.macports.org/port/zoxide/summary" rel="nofollow">MacPorts</a></td>
<td><code>port install zoxide</code></td>
</tr>
<tr>
<td><a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/zo/zoxide/package.nix">nixpkgs</a></td>
<td><code>nix-env -iA nixpkgs.zoxide</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Or, run this command in your terminal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh"><pre>curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh <span>|</span> sh</pre></div>
</blockquote>
</details>
<details>
<summary>Windows</summary>
<blockquote>
<p dir="auto">zoxide works with PowerShell, as well as shells running in Cygwin, Git
Bash, and MSYS2.</p>
<p dir="auto">The recommended way to install zoxide is via <code>winget</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="winget install ajeetdsouza.zoxide"><pre>winget install ajeetdsouza.zoxide</pre></div>
<p dir="auto">Or, you can use an alternative package manager:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Repository</th>
<th>Instructions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><a href="https://crates.io/crates/zoxide" rel="nofollow">crates.io</a></strong></td>
<td><code>cargo install zoxide --locked</code></td>
</tr>
<tr>
<td><a href="https://community.chocolatey.org/packages/zoxide" rel="nofollow">Chocolatey</a></td>
<td><code>choco install zoxide</code></td>
</tr>
<tr>
<td><a href="https://anaconda.org/conda-forge/zoxide" rel="nofollow">conda-forge</a></td>
<td><code>conda install -c conda-forge zoxide</code></td>
</tr>
<tr>
<td><a href="https://github.com/ScoopInstaller/Main/tree/master/bucket/zoxide.json">Scoop</a></td>
<td><code>scoop install zoxide</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">If you're using Cygwin, Git Bash, or MSYS2, you can also use the install script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh"><pre>curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh <span>|</span> sh</pre></div>
</blockquote>
</details>
<details>
<summary>BSD</summary>
<blockquote>
<p dir="auto">To install zoxide, use a package manager:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Distribution</th>
<th>Repository</th>
<th>Instructions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong><em>Any</em></strong></td>
<td><strong><a href="https://crates.io/crates/zoxide" rel="nofollow">crates.io</a></strong></td>
<td><code>cargo install zoxide --locked</code></td>
</tr>
<tr>
<td>DragonFly BSD</td>
<td><a href="https://github.com/DragonFlyBSD/DPorts/tree/master/sysutils/zoxide">DPorts</a></td>
<td><code>pkg install zoxide</code></td>
</tr>
<tr>
<td>FreeBSD</td>
<td><a href="https://www.freshports.org/sysutils/zoxide/" rel="nofollow">FreshPorts</a></td>
<td><code>pkg install zoxide</code></td>
</tr>
<tr>
<td>NetBSD</td>
<td><a href="https://pkgsrc.se/sysutils/zoxide" rel="nofollow">pkgsrc</a></td>
<td><code>pkgin install zoxide</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Or, run this command in your terminal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash"><pre>curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh <span>|</span> bash</pre></div>
</blockquote>
</details>
<details>
<summary>Android</summary>
<blockquote>
<p dir="auto">To install zoxide, use a package manager:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Repository</th>
<th>Instructions</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/termux/termux-packages/tree/master/packages/zoxide">Termux</a></td>
<td><code>pkg install zoxide</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Or, run this command in your terminal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash"><pre>curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh <span>|</span> bash</pre></div>
</blockquote>
</details>
</li>
<li>
<p dir="auto"><strong>Setup zoxide on your shell</strong></p>
<p dir="auto">To start using zoxide, add it to your shell.</p>
<details>
<summary>Bash</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (usually <code>~/.bashrc</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="eval &quot;$(zoxide init bash)&quot;"><pre><span>eval</span> <span><span>"</span><span><span>$(</span>zoxide init bash<span>)</span></span><span>"</span></span></pre></div>
</blockquote>
</details>
<details>
<summary>Elvish</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (usually <code>~/.elvish/rc.elv</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="eval (zoxide init elvish | slurp)"><pre><span>eval</span> (zoxide init elvish <span>|</span> slurp)</pre></div>
<p dir="auto"><strong>Note</strong>
zoxide only supports elvish v0.18.0 and above.</p>
</blockquote>
</details>
<details>
<summary>Fish</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (usually
<code>~/.config/fish/config.fish</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="zoxide init fish | source"><pre>zoxide init fish <span>|</span> <span>source</span></pre></div>
</blockquote>
</details>
<details>
<summary>Nushell</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your env file (find it by running <code>$nu.env-path</code>
in Nushell):</p>
<div dir="auto" data-snippet-clipboard-copy-content="zoxide init nushell | save -f ~/.zoxide.nu"><pre>zoxide init nushell <span>|</span> save -f <span>~</span>/.zoxide.nu</pre></div>
<p dir="auto">Now, add this to the <ins><strong>end</strong></ins> of your config file (find it by running
<code>$nu.config-path</code> in Nushell):</p>

<p dir="auto"><strong>Note</strong>
zoxide only supports Nushell v0.89.0+.</p>
</blockquote>
</details>
<details>
<summary>PowerShell</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (find it by running
<code>echo $profile</code> in PowerShell):</p>
<div dir="auto" data-snippet-clipboard-copy-content="Invoke-Expression (&amp; { (zoxide init powershell | Out-String) })"><pre><span>Invoke-Expression</span> (<span>&amp;</span> { (zoxide init powershell <span>|</span> <span>Out-String</span>) })</pre></div>
</blockquote>
</details>
<details>
<summary>Tcsh</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (usually <code>~/.tcshrc</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="zoxide init tcsh > ~/.zoxide.tcsh
source ~/.zoxide.tcsh"><pre>zoxide init tcsh <span>&gt;</span> <span>~</span>/.zoxide.tcsh
<span>source</span> <span>~</span>/.zoxide.tcsh</pre></div>
</blockquote>
</details>
<details>
<summary>Xonsh</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (usually <code>~/.xonshrc</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="execx($(zoxide init xonsh), 'exec', __xonsh__.ctx, filename='zoxide')"><pre><span>execx</span>($(<span>zoxide</span> <span>init</span> <span>xonsh</span>), <span>'exec'</span>, <span>__xonsh__</span>.<span>ctx</span>, <span>filename</span><span>=</span><span>'zoxide'</span>)</pre></div>
</blockquote>
</details>
<details>
<summary>Zsh</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file (usually <code>~/.zshrc</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="eval &quot;$(zoxide init zsh)&quot;"><pre><span>eval</span> <span><span>"</span><span><span>$(</span>zoxide init zsh<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto">For completions to work, the above line must be added <em>after</em> <code>compinit</code> is
called. You may have to rebuild your completions cache by running
<code>rm ~/.zcompdump*; compinit</code>.</p>
</blockquote>
</details>
<details>
<summary>Any POSIX shell</summary>
<blockquote>
<p dir="auto">Add this to the <ins><strong>end</strong></ins> of your config file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="eval &quot;$(zoxide init posix --hook prompt)&quot;"><pre><span>eval</span> <span><span>"</span><span><span>$(</span>zoxide init posix --hook prompt<span>)</span></span><span>"</span></span></pre></div>
</blockquote>
</details>
</li>
<li>
<p dir="auto"><strong>Install fzf</strong> <sup>(optional)</sup></p>
<p dir="auto"><a href="https://github.com/junegunn/fzf">fzf</a> is a command-line fuzzy finder, used by zoxide for completions /
interactive selection. It can be installed from <a href="https://github.com/junegunn/fzf#installation">here</a>.</p>
<blockquote>
<p dir="auto"><strong>Note</strong>
The minimum supported fzf version is v0.51.0.</p>
</blockquote>
</li>
<li>
<p dir="auto"><strong>Import your data</strong> <sup>(optional)</sup></p>
<p dir="auto">If you currently use any of these plugins, you may want to import your data
into zoxide:</p>
<details>
<summary>autojump</summary>
<blockquote>
<p dir="auto">Run this command in your terminal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="zoxide import --from=autojump &quot;/path/to/autojump/db&quot;"><pre>zoxide import --from=autojump <span><span>"</span>/path/to/autojump/db<span>"</span></span></pre></div>
<p dir="auto">The path usually varies according to your system:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>OS</th>
<th>Path</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux</td>
<td><code>$XDG_DATA_HOME/autojump/autojump.txt</code> or <code>$HOME/.local/share/autojump/autojump.txt</code></td>
<td><code>/home/alice/.local/share/autojump/autojump.txt</code></td>
</tr>
<tr>
<td>macOS</td>
<td><code>$HOME/Library/autojump/autojump.txt</code></td>
<td><code>/Users/Alice/Library/autojump/autojump.txt</code></td>
</tr>
<tr>
<td>Windows</td>
<td><code>%APPDATA%\autojump\autojump.txt</code></td>
<td><code>C:\Users\Alice\AppData\Roaming\autojump\autojump.txt</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</blockquote>
</details>
<details>
<summary>fasd, z, z.lua, zsh-z</summary>
<blockquote>
<p dir="auto">Run this command in your terminal:</p>
<div dir="auto" data-snippet-clipboard-copy-content="zoxide import --from=z &quot;path/to/z/db&quot;"><pre>zoxide import --from=z <span><span>"</span>path/to/z/db<span>"</span></span></pre></div>
<p dir="auto">The path usually varies according to your system:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plugin</th>
<th>Path</th>
</tr>
</thead>
<tbody>
<tr>
<td>fasd</td>
<td><code>$_FASD_DATA</code> or <code>$HOME/.fasd</code></td>
</tr>
<tr>
<td>z (bash/zsh)</td>
<td><code>$_Z_DATA</code> or <code>$HOME/.z</code></td>
</tr>
<tr>
<td>z (fish)</td>
<td><code>$Z_DATA</code> or <code>$XDG_DATA_HOME/z/data</code> or <code>$HOME/.local/share/z/data</code></td>
</tr>
<tr>
<td>z.lua (bash/zsh)</td>
<td><code>$_ZL_DATA</code> or <code>$HOME/.zlua</code></td>
</tr>
<tr>
<td>z.lua (fish)</td>
<td><code>$XDG_DATA_HOME/zlua/zlua.txt</code> or <code>$HOME/.local/share/zlua/zlua.txt</code> or <code>$_ZL_DATA</code></td>
</tr>
<tr>
<td>zsh-z</td>
<td><code>$ZSHZ_DATA</code> or <code>$_Z_DATA</code> or <code>$HOME/.z</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</blockquote>
</details>
<details>
<summary>ZLocation</summary>
<blockquote>
<p dir="auto">Run this command in PowerShell:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$db = New-TemporaryFile
(Get-ZLocation).GetEnumerator() | ForEach-Object { Write-Output ($_.Name+'|'+$_.Value+'|0') } | Out-File $db
zoxide import --from=z $db"><pre><span>$db</span> <span>=</span> <span>New-TemporaryFile</span>
(<span>Get-ZLocation</span>).GetEnumerator() <span>|</span> <span>ForEach-Object</span> { <span>Write-Output</span> (<span>$_<span>.Name</span></span><span>+</span><span><span>'</span>|<span>'</span></span><span>+</span><span>$_<span>.Value</span></span><span>+</span><span><span>'</span>|0<span>'</span></span>) } <span>|</span> <span>Out-File</span> <span>$db</span>
zoxide import <span>--</span>from<span>=</span>z <span>$db</span></pre></div>
</blockquote>
</details>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Flags</h3><a id="user-content-flags" aria-label="Permalink: Flags" href="#flags"></a></p>
<p dir="auto">When calling <code>zoxide init</code>, the following flags are available:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>--cmd</code></p>
<ul dir="auto">
<li>Changes the prefix of the <code>z</code> and <code>zi</code> commands.</li>
<li><code>--cmd j</code> would change the commands to (<code>j</code>, <code>ji</code>).</li>
<li><code>--cmd cd</code> would replace the <code>cd</code> command.</li>
</ul>
</li>
<li>
<p dir="auto"><code>--hook &lt;HOOK&gt;</code></p>
<ul dir="auto">
<li>
<p dir="auto">Changes how often zoxide increments a directory's score:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Hook</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>none</code></td>
<td>Never</td>
</tr>
<tr>
<td><code>prompt</code></td>
<td>At every shell prompt</td>
</tr>
<tr>
<td><code>pwd</code> (default)</td>
<td>Whenever the directory is changed</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
</ul>
</li>
<li>
<p dir="auto"><code>--no-cmd</code></p>
<ul dir="auto">
<li>Prevents zoxide from defining the <code>z</code> and <code>zi</code> commands.</li>
<li>These functions will still be available in your shell as <code>__zoxide_z</code> and
<code>__zoxide_zi</code>, should you choose to redefine them.</li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Environment variables</h3><a id="user-content-environment-variables" aria-label="Permalink: Environment variables" href="#environment-variables"></a></p>
<p dir="auto">Environment variables<sup><a href="#user-content-fn-2-fad79386de4d55dbdbd472811d9bcdf2" id="user-content-fnref-2-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> can be used for configuration. They must be set before
<code>zoxide init</code> is called.</p>
<ul dir="auto">
<li>
<p dir="auto"><code>_ZO_DATA_DIR</code></p>
<ul dir="auto">
<li>
<p dir="auto">Specifies the directory in which the database is stored.</p>
</li>
<li>
<p dir="auto">The default value varies across OSes:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>OS</th>
<th>Path</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux / BSD</td>
<td><code>$XDG_DATA_HOME</code> or <code>$HOME/.local/share</code></td>
<td><code>/home/alice/.local/share</code></td>
</tr>
<tr>
<td>macOS</td>
<td><code>$HOME/Library/Application Support</code></td>
<td><code>/Users/Alice/Library/Application Support</code></td>
</tr>
<tr>
<td>Windows</td>
<td><code>%LOCALAPPDATA%</code></td>
<td><code>C:\Users\Alice\AppData\Local</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
</ul>
</li>
<li>
<p dir="auto"><code>_ZO_ECHO</code></p>
<ul dir="auto">
<li>When set to 1, <code>z</code> will print the matched directory before navigating to
it.</li>
</ul>
</li>
<li>
<p dir="auto"><code>_ZO_EXCLUDE_DIRS</code></p>
<ul dir="auto">
<li>
<p dir="auto">Excludes the specified directories from the database.</p>
</li>
<li>
<p dir="auto">This is provided as a list of <a href="https://man7.org/linux/man-pages/man7/glob.7.html" rel="nofollow">globs</a>, separated by OS-specific
characters:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>OS</th>
<th>Separator</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>Linux / macOS / BSD</td>
<td><code>:</code></td>
<td><code>$HOME:$HOME/private/*</code></td>
</tr>
<tr>
<td>Windows</td>
<td><code>;</code></td>
<td><code>$HOME;$HOME/private/*</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</li>
<li>
<p dir="auto">By default, this is set to <code>"$HOME"</code>.</p>
</li>
</ul>
</li>
<li>
<p dir="auto"><code>_ZO_FZF_OPTS</code></p>
<ul dir="auto">
<li>Custom options to pass to <a href="https://github.com/junegunn/fzf">fzf</a> during interactive selection. See
<a href="https://manpages.ubuntu.com/manpages/en/man1/fzf.1.html" rel="nofollow"><code>man fzf</code></a> for the list of options.</li>
</ul>
</li>
<li>
<p dir="auto"><code>_ZO_MAXAGE</code></p>
<ul dir="auto">
<li>Configures the <a href="https://github.com/ajeetdsouza/zoxide/wiki/Algorithm#aging">aging algorithm</a>, which limits the maximum
number of entries in the database.</li>
<li>By default, this is set to 10000.</li>
</ul>
</li>
<li>
<p dir="auto"><code>_ZO_RESOLVE_SYMLINKS</code></p>
<ul dir="auto">
<li>When set to 1, <code>z</code> will resolve symlinks before adding directories to the
database.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Third-party integrations</h2><a id="user-content-third-party-integrations" aria-label="Permalink: Third-party integrations" href="#third-party-integrations"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Application</th>
<th>Description</th>
<th>Plugin</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/rjarry/aerc">aerc</a></td>
<td>Email client</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://www.alfredapp.com/" rel="nofollow">alfred</a></td>
<td>macOS launcher</td>
<td><a href="https://github.com/yihou/alfred-zoxide">alfred-zoxide</a></td>
</tr>
<tr>
<td><a href="https://github.com/mridgers/clink">clink</a></td>
<td>Improved cmd.exe for Windows</td>
<td><a href="https://github.com/shunsambongi/clink-zoxide">clink-zoxide</a></td>
</tr>
<tr>
<td><a href="https://www.gnu.org/software/emacs/" rel="nofollow">emacs</a></td>
<td>Text editor</td>
<td><a href="https://gitlab.com/Vonfry/zoxide.el" rel="nofollow">zoxide.el</a></td>
</tr>
<tr>
<td><a href="https://github.com/kyoheiu/felix">felix</a></td>
<td>File manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/kamiyaa/joshuto">joshuto</a></td>
<td>File manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/gokcehan/lf">lf</a></td>
<td>File manager</td>
<td>See the <a href="https://github.com/gokcehan/lf/wiki/Integrations#zoxide">wiki</a></td>
</tr>
<tr>
<td><a href="https://github.com/jarun/nnn">nnn</a></td>
<td>File manager</td>
<td><a href="https://github.com/jarun/nnn/blob/master/plugins/autojump">nnn-autojump</a></td>
</tr>
<tr>
<td><a href="https://github.com/ranger/ranger">ranger</a></td>
<td>File manager</td>
<td><a href="https://github.com/jchook/ranger-zoxide">ranger-zoxide</a></td>
</tr>
<tr>
<td><a href="https://www.raycast.com/" rel="nofollow">raycast</a></td>
<td>macOS launcher</td>
<td><a href="https://www.raycast.com/mrpunkin/raycast-zoxide" rel="nofollow">raycast-zoxide</a></td>
</tr>
<tr>
<td><a href="https://github.com/dsxmachina/rfm">rfm</a></td>
<td>File manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/joshmedeski/sesh">sesh</a></td>
<td><code>tmux</code> session manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/nvim-telescope/telescope.nvim">telescope.nvim</a></td>
<td>Fuzzy finder for Neovim</td>
<td><a href="https://github.com/jvgrootveld/telescope-zoxide">telescope-zoxide</a></td>
</tr>
<tr>
<td><a href="https://github.com/27medkamal/tmux-session-wizard">tmux-session-wizard</a></td>
<td><code>tmux</code> session manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/omerxx/tmux-sessionx">tmux-sessionx</a></td>
<td><code>tmux</code> session manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/vim/vim">vim</a> / <a href="https://github.com/neovim/neovim">neovim</a></td>
<td>Text editor</td>
<td><a href="https://github.com/nanotee/zoxide.vim">zoxide.vim</a></td>
</tr>
<tr>
<td><a href="https://github.com/sayanarijit/xplr">xplr</a></td>
<td>File manager</td>
<td><a href="https://github.com/sayanarijit/zoxide.xplr">zoxide.xplr</a></td>
</tr>
<tr>
<td><a href="https://github.com/xxh/xxh">xxh</a></td>
<td>Transports shell configuration over SSH</td>
<td><a href="https://github.com/xxh/xxh-plugin-prerun-zoxide">xxh-plugin-prerun-zoxide</a></td>
</tr>
<tr>
<td><a href="https://github.com/sxyazi/yazi">yazi</a></td>
<td>File manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/Mellbourn/zabb">zabb</a></td>
<td>Finds the shortest possible query for a path</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/roberte777/zesh">zesh</a></td>
<td><code>zellij</code> session manager</td>
<td>Natively supported</td>
</tr>
<tr>
<td><a href="https://github.com/marlonrichert/zsh-autocomplete">zsh-autocomplete</a></td>
<td>Realtime completions for zsh</td>
<td>Natively supported</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-1-fad79386de4d55dbdbd472811d9bcdf2">
<p dir="auto">Debian and its derivatives update their packages very slowly. If you're
using one of these distributions, consider using the install script instead. <a href="#user-content-fnref-1-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-backref="" aria-label="Back to reference 1">↩</a> <a href="#user-content-fnref-1-2-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-backref="" aria-label="Back to reference 1-2">↩<sup>2</sup></a> <a href="#user-content-fnref-1-3-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-backref="" aria-label="Back to reference 1-3">↩<sup>3</sup></a></p>
</li>
<li id="user-content-fn-2-fad79386de4d55dbdbd472811d9bcdf2">
<p dir="auto">If you're not sure how to set an environment variable on your shell, check
out the <a href="https://github.com/ajeetdsouza/zoxide/wiki/HOWTO:-set-environment-variables" title="HOWTO: set environment variables">wiki</a>. <a href="#user-content-fnref-2-fad79386de4d55dbdbd472811d9bcdf2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nine Things I Learned in Ninety Years (747 pts)]]></title>
            <link>http://edwardpackard.com/wp-content/uploads/2025/09/Nine-Things-I-Learned-in-Ninety-Years.pdf</link>
            <guid>45342364</guid>
            <pubDate>Tue, 23 Sep 2025 03:03:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://edwardpackard.com/wp-content/uploads/2025/09/Nine-Things-I-Learned-in-Ninety-Years.pdf">http://edwardpackard.com/wp-content/uploads/2025/09/Nine-Things-I-Learned-in-Ninety-Years.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45342364">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Pocket Casts, You Altered the Deal, So I Will Alter Your App (114 pts)]]></title>
            <link>https://blog.matthewbrunelle.com/podcasts-you-altered-the-deal-so-i-will-alter-your-app/</link>
            <guid>45342319</guid>
            <pubDate>Tue, 23 Sep 2025 02:56:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.matthewbrunelle.com/podcasts-you-altered-the-deal-so-i-will-alter-your-app/">https://blog.matthewbrunelle.com/podcasts-you-altered-the-deal-so-i-will-alter-your-app/</a>, See on <a href="https://news.ycombinator.com/item?id=45342319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<main>

        <article>

        

    <div>
        
<h3 id="history-so-far">History so far</h3>
<p>Pocket Casts, people are not upset you are trying to find revenue sources. People are upset you are reneging on your promise.</p>
<p>You were a pay-once app. Released in 2011, pay once each for Android, iOS, and Web and keep for life.</p>
<p>In 2018 NPR <a href="https://www.npr.org/about-npr/607823388/pocket-cast-acquired?ref=blog.matthewbrunelle.com">acquired you</a>.  Then in 2019 you moved to a subscription for all users, including the paid ones. People were upset so you backtracked and <a href="https://blog.pocketcasts.com/2019/09/18/major-new-update/?ref=blog.matthewbrunelle.com">grandfathered them into</a> a lifetime plus membership. Sadly, in 2020 NPR lost <a href="https://current.org/2021/01/public-media-owners-agree-to-sell-pocket-casts-podcast-platform/?ref=blog.matthewbrunelle.com">$800k from running you</a> so you were <a href="https://wordpress.com/blog/2021/07/16/popular-podcast-app-pocket-casts-joins-automattic/?ref=blog.matthewbrunelle.com">sold to Automattic</a>.</p>
<p>In 2024, you renamed all "Pocket Casts Lifetime Members" to <a href="https://support.pocketcasts.com/knowledge-base/lifetime-access-to-pocket-casts-plus/?ref=blog.matthewbrunelle.com">"Pocket Casts Champions"</a> and we knew shenanigans were afoot.</p>
<p>This week you flipped the switch to turn on ads in the app:<br>
<img src="https://blog.matthewbrunelle.com/content/images/2025/09/1000002462.png" alt="1000002462.png" loading="lazy"></p>
<p>However, in 2022 you <a href="https://blog.pocketcasts.com/2022/10/19/pocket-casts-mobile-apps-are-now-open-source/?ref=blog.matthewbrunelle.com">made your mobile apps open source</a>, so there is something that can be done: I <a href="https://github.com/ciferkey/pocket-casts-android?ref=blog.matthewbrunelle.com">forked</a> the repo.</p>
<hr>
<h3 id="exorcising-the-ads">Exorcising the ads</h3>
<p>In the app you may be able to see the new nag that says: "Unlock folders, bookmarks, transcripts and more with Pocket Casts Plus" just above the artwork in the player screen. I don't see that exact string in the <a href="https://blog.matthewbrunelle.com/podcasts-you-altered-the-deal-so-i-will-alter-your-app/github.com/Automattic/pocket-casts-android">GitHub repo</a>, I think that's because of internationalization.</p>
<p>However, I found where the <a href="https://github.com/Automattic/pocket-casts-android/blob/f17d2a0408dd299684eb4afa11fb07f4df1fc59e/modules/features/player/src/main/java/au/com/shiftyjelly/pocketcasts/player/view/PlayerHeaderFragment.kt?ref=blog.matthewbrunelle.com#L99">artwork view fragment is</a> and that it contains <code>AdAndArtworkHorizontal</code>. Looking at the changelog I can see that this was added in <a href="https://github.com/Automattic/pocket-casts-android/pull/4086?ref=blog.matthewbrunelle.com">Display ads in the player #4086</a> which created the flag <code>Feature.BANNER_ADS</code>.</p>
<p>In the project, a feature flag has the following details:</p>
<pre><code>enum class Feature(  
    val key: String,  
    val title: String,  
    val defaultValue: Boolean,  
    val tier: FeatureTier,  
    val hasFirebaseRemoteFlag: Boolean,  
    val hasDevToggle: Boolean,  
)
</code></pre>
<p>With some further updates to the project, the flag is now <a href="https://github.com/Automattic/pocket-casts-android/blob/f17d2a0408dd299684eb4afa11fb07f4df1fc59e/modules/services/utils/src/main/java/au/com/shiftyjelly/pocketcasts/utils/featureflag/Feature.kt?ref=blog.matthewbrunelle.com#L125-L140">broken in two</a>:</p>
<pre><code>BANNER_ADS_PLAYER(  
    key = "banner_ad_player",  
    title = "Banner Ads Player",  
    defaultValue = true,  
    tier = FeatureTier.Free,  
    hasFirebaseRemoteFlag = true,  
    hasDevToggle = true,  
),  
BANNER_ADS_PODCASTS(  
    key = "banner_ad_podcasts",  
    title = "Banner Ads Podcasts",  
    defaultValue = true,  
    tier = FeatureTier.Free,  
    hasFirebaseRemoteFlag = true,  
    hasDevToggle = true,  
),
</code></pre>
<p>The flags are ultimately used by <a href="https://github.com/Automattic/pocket-casts-android/blob/f17d2a0408dd299684eb4afa11fb07f4df1fc59e/modules/services/model/src/main/java/au/com/shiftyjelly/pocketcasts/models/type/BlazeAdLocation.kt?ref=blog.matthewbrunelle.com#L11">BlazeAdLocation</a>.</p>
<p>There are a couple of different ways we could slice out the ads. For testing, I went with the simplest approach to start:</p>
<ul>
<li>Flip <code>defaultValue</code> to false.</li>
<li>Flip <code>hasFirebaseRemoteFlag</code> to false so the flag will not be remotely overridden.</li>
</ul>
<p>Anyway, based on the readme I just needed to<code>./gradlew :app:assembleDebugProd</code> and <code>./gradlew :app:installDebugProd</code>. This will install a different debug version of the app:<br>
<img src="https://blog.matthewbrunelle.com/content/images/2025/09/1000002460.png" alt="1000002460.png" loading="lazy"></p>
<p>Voila, ads gone. Though in the future this process may be tougher because of Google's <a href="https://android-developers.googleblog.com/2025/08/elevating-android-security.html?ref=blog.matthewbrunelle.com">impending crackdown on loading APKs</a>.</p>
<p>Now, after doing all that work, guess what I realized? <code>hasDevToggle</code> field in the Features class? Well the debug build has a feature toggles section:<br>
<img src="https://blog.matthewbrunelle.com/content/images/2025/09/1000002458.png" alt="1000002458.png" loading="lazy"></p>
<p>So for now you do not need to modify the project's code. You can get by with just using the debug build and toggling the feature off. Feature flags only exist for testing features though. Eventually the flag will go away and I'll have to disable the ads more directly.</p>
<hr>
<h3 id="why-did-we-end-up-here">Why did we end up here?</h3>
<p>Pocket Casts, your current approach to monetization seems extreme. Are you in a similar situation to 2020? Back then the NPR <a href="https://media.npr.org/documents/about/statements/fy2020/National%20Public%20Radio%20-%20Consolidated%20Financial%20Statements%202020.pdf?ref=blog.matthewbrunelle.com">financial report</a> only had a single line item of $812,129 for "Minus: Share of Podcast Media’s net loss". Why does a podcast service cost so much to run? If you give us more transparency, maybe we will better understand why you need to make changes.</p>
<p>Maybe more of the work can be moved on-device. You open-sourced your app. Maybe the community can help you out and contribute those changes? We're not too scary. You extended an olive branch by open-sourcing the project, so let's work together. Hopefully Automattic doesn't pull back on contributions like they <a href="https://automattic.com/2025/01/09/aligning-automattics-sponsored-contributions-to-wordpress/?ref=blog.matthewbrunelle.com">did with WordPress this year</a>.</p>
<hr>
<h3 id="an-entirely-different-option">An entirely different option</h3>
<p>As I mentioned in my post about <a href="https://blog.matthewbrunelle.com/the-apps-that-i-kept-on-grapheneos-2/#the-media-apps">the apps I kept when switching to GrapheneOS</a>,  self-hosting PinePods and using AntennaPod on your phone is a great option! That way you can still have web and desktop sync. I also said in that post:</p>
<blockquote>
<p>If I wasn't grandfathered into the free premium tier I would be more tempted to jump ship.</p>
</blockquote>
<p>The time to jump ship seems to be getting closer. I think Pocket Casts will join a future version of my <a href="https://blog.matthewbrunelle.com/the-apps-that-i-got-rid-of-when-trying-out-grapheneos/">apps that I got rid of when switching to GrapheneOS</a> post.</p>
<p>Oh, and if anyone is looking for new podcasts to listen to, <a href="https://blog.matthewbrunelle.com/what-podcasts-am-i-listening-to-2025/">I have recommendations</a>.</p>

    </div>
</article>
                
                

</main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fall Foliage Map 2025 (234 pts)]]></title>
            <link>https://www.explorefall.com/fall-foliage-map</link>
            <guid>45341324</guid>
            <pubDate>Tue, 23 Sep 2025 00:14:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.explorefall.com/fall-foliage-map">https://www.explorefall.com/fall-foliage-map</a>, See on <a href="https://news.ycombinator.com/item?id=45341324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="more-info-4">
          <p>If you've ever traveled in search of fall foliage before, you likely know how tricky it can be to be in the right place at the right time. The timing of peak color varies signficantly season-to-season, meaning what worked one year might not work the next! The best fall trips take careful planning, a lot of patience, and a reliable fall foliage map.</p>
          <p>It's helpful to establish a baseline for when leaves <i>normally</i> change. Maps, like the one in the above section, can help you identify roughly when in the season you should be planning your trip. From there, you should consult a real-time fall foliage map like ours to see if fall foliage is on-time or running early/late due to ongoing weather conditions.</p>
          <p>If at all possible, don't solidify your plans until you're two weeks out from peak fall foliage. This allows you to be flexible should extreme weather rear its head and disrupt the normal progression of fall foliage. Should that not be an option for you, do your planning in early September when fall foliage experts can give you an idea of whether or not fall color is on-time this year.</p>
          <p>You'll want to make the most of your time in fall's splendor, so be sure to pick out a few beautiful hikes or drives on which you can truly be emersed in autumnal glory. If you're looking to beat the crowds, consider going to popular locations very early in the morning, before the majority of people arrive. Sunrise bathes fall foliage in golden hues, making early morning one of the best times to venture out!</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Designating Antifa as a domestic terrorist organization (130 pts)]]></title>
            <link>https://www.whitehouse.gov/presidential-actions/2025/09/designating-antifa-as-a-domestic-terrorist-organization/</link>
            <guid>45340814</guid>
            <pubDate>Mon, 22 Sep 2025 23:16:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whitehouse.gov/presidential-actions/2025/09/designating-antifa-as-a-domestic-terrorist-organization/">https://www.whitehouse.gov/presidential-actions/2025/09/designating-antifa-as-a-domestic-terrorist-organization/</a>, See on <a href="https://news.ycombinator.com/item?id=45340814">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>




<p><span>Section</span> <span>1</span>. &nbsp;<span>Antifa as a Terrorist Threat</span>.&nbsp; Antifa is a militarist, anarchist enterprise that explicitly calls for the overthrow of the United States Government, law enforcement authorities, and our system of law.&nbsp; It uses illegal means to organize and execute a campaign of violence and terrorism nationwide to accomplish these goals.&nbsp; This campaign involves coordinated efforts to obstruct enforcement of Federal laws through armed standoffs with law enforcement, organized riots, violent assaults on Immigration and Customs Enforcement and other law enforcement officers, and routine doxing of and other threats against political figures and activists. &nbsp;Antifa recruits, trains, and radicalizes young Americans to engage in this violence and suppression of political activity, then employs elaborate means and mechanisms to shield the identities of its operatives, conceal its funding sources and operations in an effort to frustrate law enforcement, and recruit additional members.&nbsp; Individuals associated with and acting on behalf of Antifa further coordinate with other organizations and entities for the purpose of spreading, fomenting, and advancing political violence and suppressing lawful political speech.&nbsp; This organized effort designed to achieve policy objectives by coercion and intimidation is domestic terrorism.</p>



<p><span>Sec</span>. <span>2</span>. &nbsp;<span>Designation as a Domestic Terrorist Organization</span>.&nbsp; Because of the aforementioned pattern of political violence designed to suppress lawful political activity and obstruct the rule of law, I hereby designate Antifa as a “domestic terrorist organization.”&nbsp; All relevant executive departments and agencies shall utilize all applicable authorities to investigate, disrupt, and dismantle any and all illegal operations — especially those involving terrorist actions — conducted by Antifa or any person claiming to act on behalf of Antifa, or for which Antifa or any person claiming to act on behalf of Antifa provided material support, including necessary investigatory and prosecutorial actions against those who fund such operations.&nbsp;</p>



<p><span>Sec</span>. <span>3</span>. &nbsp;<span>General Provisions</span>.&nbsp; (a)&nbsp; This order shall be implemented consistent with applicable law.&nbsp; This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person.</p>



<p>(b)&nbsp; This order shall be published in the <em>Federal Register.</em></p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DONALD J. TRUMP</p>



<p>THE WHITE HOUSE,</p>



<p>&nbsp;&nbsp;&nbsp; September 22, 2025.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In Maine, prisoners are thriving in remote jobs, other states are taking notice (240 pts)]]></title>
            <link>https://www.mainepublic.org/2025-08-29/in-maine-prisoners-are-thriving-in-remote-jobs-and-other-states-are-taking-notice</link>
            <guid>45340600</guid>
            <pubDate>Mon, 22 Sep 2025 22:51:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mainepublic.org/2025-08-29/in-maine-prisoners-are-thriving-in-remote-jobs-and-other-states-are-taking-notice">https://www.mainepublic.org/2025-08-29/in-maine-prisoners-are-thriving-in-remote-jobs-and-other-states-are-taking-notice</a>, See on <a href="https://news.ycombinator.com/item?id=45340600">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
        Published&nbsp;August 29, 2025 at 5:12 PM EDT
    </p>
    <meta content="2025-08-29T21:12:00.981Z">


                                        </div><div>
                                        <p>People who are incarcerated are paid notoriously low wages for kitchen, laundry work and maintenance.</p><p>But the expanded use of laptops is creating other opportunities.</p>
<p><i>This is part two in a two-part series about remote work in Maine prisons. </i><a href="https://www.mainepublic.org/maine/2025-08-28/cracking-the-code-how-technology-and-education-are-changing-life-in-prison" target="_blank"><i>To read part one, click here</i></a><i>.</i></p><p>Preston Thorpe is only 32, but he says he's already landed his dream job as a senior software engineer and bought a modest house with his six-figure salary. It was all accomplished by putting in long days from his cell at the Mountain View Correctional Center in Charleston.</p><p>"It's not normal to have 15-17 hours a day to really focus on something and learn something, like deeply," Thorpe says. "And fortunately tech is one of the few areas where they're not concerned with your college degree. They're really only concerned with your ability to write code."</p>
<p>A self-described "computer geek," Thorpe says he built his first computer at age 13. In high school he always expected he'd have a career in tech. But he also had a rebellious side. He got into trouble with drugs, using them and selling them. He says his parents kicked him out of the house and he ended up in prison for the first time at age 20.</p><p>"You know, I was worried and pretty hopeless that I had messed my life up so bad that it was no longer possible to have like a normal life and normal career," he says.</p><p>When you have nothing to lose, Thorpe says it's pretty easy to behave that way. And when you're out of prison with a criminal record, no money and an identity as a convict, he says the likelihood you're going to improve your life in any way is zero.</p><p>His own circumstances changed in 2019 when he got transferred from the New Hampshire prison system to Maine, where he discovered laptops with limited internet access were available for education. That's when he says he had an epiphany that he could change himself by pursuing his passion. And about two years ago, he became one of the first incarcerated people in the country to get hired for a remote job.</p><p>"Now I feel like my life has purpose," Thorpe says.</p><div data-align-center="">
<figure>
    
        
            <picture>
    
    
        
            
    
            <source media="(max-width: 768px)" type="image/webp" width="420" height="280" srcset="https://npr.brightspotcdn.com/dims4/default/b201217/2147483647/strip/true/crop/3600x2400+0+0/resize/840x560!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F2a%2Fac%2F6bc44f5c43899b25843a9d43acad%2Fprestont7horpe-kb.JPG 2x" data-size="fallbackImageSizeMobile">
    

    
        <source media="(max-width: 768px)" width="420" height="280" srcset="https://npr.brightspotcdn.com/dims4/default/c9f7465/2147483647/strip/true/crop/3600x2400+0+0/resize/420x280!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F2a%2Fac%2F6bc44f5c43899b25843a9d43acad%2Fprestont7horpe-kb.JPG" data-size="fallbackImageSizeMobile">
    

        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
    
            <source type="image/webp" width="880" height="587" srcset="https://npr.brightspotcdn.com/dims4/default/9838af1/2147483647/strip/true/crop/3600x2400+0+0/resize/1760x1174!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F2a%2Fac%2F6bc44f5c43899b25843a9d43acad%2Fprestont7horpe-kb.JPG 2x" data-size="fallbackImageSize">
    

    
        <source width="880" height="587" srcset="https://npr.brightspotcdn.com/dims4/default/47baa79/2147483647/strip/true/crop/3600x2400+0+0/resize/880x587!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F2a%2Fac%2F6bc44f5c43899b25843a9d43acad%2Fprestont7horpe-kb.JPG" data-size="fallbackImageSize">
    

        
    

    
    <img alt="Maine inmate Preston Thorpe talks with his team during a group work session from his cell at the Mountain View Correctional Facility in Charleston, Maine, on Aug. 18, 2025." srcset="https://npr.brightspotcdn.com/dims4/default/0d3fa0e/2147483647/strip/true/crop/3600x2400+0+0/resize/1760x1174!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F2a%2Fac%2F6bc44f5c43899b25843a9d43acad%2Fprestont7horpe-kb.JPG 2x" width="880" height="587" loading="lazy" src="https://npr.brightspotcdn.com/dims4/default/47baa79/2147483647/strip/true/crop/3600x2400+0+0/resize/880x587!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F2a%2Fac%2F6bc44f5c43899b25843a9d43acad%2Fprestont7horpe-kb.JPG">


</picture>
        
    
    
    
    
    <div>
    

    <div><p>Kevin Bennett</p>
            
                <p>/</p>
            
        
            <p> For Maine Public</p></div><figcaption>Maine inmate Preston Thorpe talks with his team during a group work session from his cell at the Mountain View Correctional Facility in Charleston, Maine, on Aug. 18, 2025.</figcaption>
    </div>
    
</figure>
</div>
<p>Glauber Costa says he first became aware of Thorpe through his contributions to an online public software project. Costa is the CEO of Turso, an international database company. He was impressed by Thorpe's work and had no idea he was incarcerated.</p><p>Once he found out, he thought it would be impossible to talk to Thorpe, let alone hire him.</p><p>"But then," Costa says, "it turns out that he can take video calls. And then by talking to him, it became very, very clear to me that if this is not a reformed person I don't know what is."</p><p>Costa says he was also surprised to learn that Thorpe was eligible for remote work while he was in prison. He hired him in June. He figured Thorpe might have trouble clearing the company's background check and he says he prepared himself for that. But since it only searches back seven years and since Thorpe has been in prison for more than a decade, "He is actually our cleanest background check," Costa says.</p><p>"He doesn't have a parking ticket."</p><p>Several dozen other prisoners are also working remote jobs. At the Maine Correctional Center in Windham, Darlene George is a certified recovery coach, a scholar and a teaching assistant who's serving a 40-year sentence for the murder of her husband.</p><div data-align-center="">
<figure>
    
        
            <picture>
    
    
        
            
    
            <source media="(max-width: 768px)" type="image/webp" width="420" height="315" srcset="https://npr.brightspotcdn.com/dims4/default/37aabe5/2147483647/strip/true/crop/4000x3000+0+0/resize/840x630!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fe0%2Fbb%2F1107dbaf41da9e8e92ef0e660f23%2F20250709-105418.jpg 2x" data-size="fallbackImageSizeMobile">
    

    
        <source media="(max-width: 768px)" width="420" height="315" srcset="https://npr.brightspotcdn.com/dims4/default/e1c9445/2147483647/strip/true/crop/4000x3000+0+0/resize/420x315!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fe0%2Fbb%2F1107dbaf41da9e8e92ef0e660f23%2F20250709-105418.jpg" data-size="fallbackImageSizeMobile">
    

        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
    
            <source type="image/webp" width="880" height="660" srcset="https://npr.brightspotcdn.com/dims4/default/fa561a2/2147483647/strip/true/crop/4000x3000+0+0/resize/1760x1320!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fe0%2Fbb%2F1107dbaf41da9e8e92ef0e660f23%2F20250709-105418.jpg 2x" data-size="fallbackImageSize">
    

    
        <source width="880" height="660" srcset="https://npr.brightspotcdn.com/dims4/default/5d89c00/2147483647/strip/true/crop/4000x3000+0+0/resize/880x660!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fe0%2Fbb%2F1107dbaf41da9e8e92ef0e660f23%2F20250709-105418.jpg" data-size="fallbackImageSize">
    

        
    

    
    <img alt="Darlene George" srcset="https://npr.brightspotcdn.com/dims4/default/0ae6bfd/2147483647/strip/true/crop/4000x3000+0+0/resize/1760x1320!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fe0%2Fbb%2F1107dbaf41da9e8e92ef0e660f23%2F20250709-105418.jpg 2x" width="880" height="660" loading="lazy" src="https://npr.brightspotcdn.com/dims4/default/5d89c00/2147483647/strip/true/crop/4000x3000+0+0/resize/880x660!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fe0%2Fbb%2F1107dbaf41da9e8e92ef0e660f23%2F20250709-105418.jpg">


</picture>
        
    
    
    
    
    <div>
    

    <div><p>Susan Sharon</p>
            
                <p>/</p>
            
        
            <p>Maine Public </p></div><figcaption> Darlene George</figcaption>
    </div>
    
</figure>
</div>
<p>"I became incarcerated in 2009 and I've been here 16 years," George says.</p><p>Unlike most women in prison, George had a college degree before she was incarcerated. She says she still tries to make the most of every opportunity she can. For the past two years, she's held a full-time remote job, first as a grant writer and now as a program coordinator, for a Maine-based health care company.</p><p>"The work, it just, it really makes you feel good," she says. "When I — when I put my head down at night I can say I'm giving something back."</p><p>George relishes her role as a decision maker and an advocate for clients' health care. She makes a competitive salary. And she says her boss and her co-workers are extremely supportive of her situation, and so are the other women at the Maine Correctional Center.</p><p>"Literally, I work from my room. There's a sign that I put out that lets people know I'm Zooming or in meetings," she says. "They try not to be noisy on the floor ... because they're like, 'Well, we want a job, too.'"</p><div data-align-center="">
<figure>
    
        
            <picture>
    
    
        
            
    
            <source media="(max-width: 768px)" type="image/webp" width="420" height="280" srcset="https://npr.brightspotcdn.com/dims4/default/bc06d52/2147483647/strip/true/crop/3600x2400+0+0/resize/840x560!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ffb%2F19%2F980ba2b14acfafd7699b7785839d%2Fprestont8horpe-kb.JPG 2x" data-size="fallbackImageSizeMobile">
    

    
        <source media="(max-width: 768px)" width="420" height="280" srcset="https://npr.brightspotcdn.com/dims4/default/a89176d/2147483647/strip/true/crop/3600x2400+0+0/resize/420x280!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ffb%2F19%2F980ba2b14acfafd7699b7785839d%2Fprestont8horpe-kb.JPG" data-size="fallbackImageSizeMobile">
    

        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
    
            <source type="image/webp" width="880" height="587" srcset="https://npr.brightspotcdn.com/dims4/default/f00a0d7/2147483647/strip/true/crop/3600x2400+0+0/resize/1760x1174!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ffb%2F19%2F980ba2b14acfafd7699b7785839d%2Fprestont8horpe-kb.JPG 2x" data-size="fallbackImageSize">
    

    
        <source width="880" height="587" srcset="https://npr.brightspotcdn.com/dims4/default/08af25b/2147483647/strip/true/crop/3600x2400+0+0/resize/880x587!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ffb%2F19%2F980ba2b14acfafd7699b7785839d%2Fprestont8horpe-kb.JPG" data-size="fallbackImageSize">
    

        
    

    
    <img alt="Maine prison inmate Preston Thorpe talks with his team during a group work session from his cell at the Mountain View Correctional Facility in Charleston, Maine, on Aug. 18, 2025." srcset="https://npr.brightspotcdn.com/dims4/default/7b68e2d/2147483647/strip/true/crop/3600x2400+0+0/resize/1760x1174!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ffb%2F19%2F980ba2b14acfafd7699b7785839d%2Fprestont8horpe-kb.JPG 2x" width="880" height="587" loading="lazy" src="https://npr.brightspotcdn.com/dims4/default/08af25b/2147483647/strip/true/crop/3600x2400+0+0/resize/880x587!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Ffb%2F19%2F980ba2b14acfafd7699b7785839d%2Fprestont8horpe-kb.JPG">


</picture>
        
    
    
    
    
    <div>
    

    <div><p>Kevin Bennett</p>
            
                <p>/</p>
            
        
            <p> For Maine Public</p></div><figcaption>Maine prison inmate Preston Thorpe talks with his team during a group work session from his cell at the Mountain View Correctional Facility in Charleston, Maine, on Aug. 18, 2025.</figcaption>
    </div>
    
</figure>
</div>
<p>Mara Sanchez, the program director for the Alliance for Higher Education in Prison, says Maine's Department of Corrections was the first to have a remote work policy.</p><p>"Their implementation, willingness to try remote work for incarcerated students has really kind of set the bar for other states and been very inspiring to other states," she says.</p><p>Maine Corrections Commissioner Randall Liberty says remote work is an outgrowth of expanded educational opportunities in prison. There are 800 residents who now have access to the internet.</p><p>"We have technicians that are watching where they're going and what they're doing and we've had very few problems," Liberty says. "If it provides meaningful employment for them ... it also allows for a transition back into the community."</p><p>For example, Liberty says one resident worked as a paralegal for a law firm and continued with the job after he got out. Wages are garnished for child support, victim restitution and other fees. And for those who earn above a certain amount, 10% goes to the Department of Corrections for room and board. But residents can also save money or send it home. And Liberty says between educational programs and remote work, the prison environment is better for everyone.</p><div data-align-center="">
<figure>
    
        
            <picture>
    
    
        
            
    
            <source media="(max-width: 768px)" type="image/webp" width="420" height="280" srcset="https://npr.brightspotcdn.com/dims4/default/c19c10c/2147483647/strip/true/crop/3600x2400+0+0/resize/840x560!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F72%2F65%2F31e5663d4a6d8efd2e6af082c146%2Fprestont6horpe-kb.JPG 2x" data-size="fallbackImageSizeMobile">
    

    
        <source media="(max-width: 768px)" width="420" height="280" srcset="https://npr.brightspotcdn.com/dims4/default/d287b2d/2147483647/strip/true/crop/3600x2400+0+0/resize/420x280!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F72%2F65%2F31e5663d4a6d8efd2e6af082c146%2Fprestont6horpe-kb.JPG" data-size="fallbackImageSizeMobile">
    

        
    

    
    
        
            
        
    

    
    
        
            
        
    

    
    
        
            
    
            <source type="image/webp" width="880" height="587" srcset="https://npr.brightspotcdn.com/dims4/default/e6d2044/2147483647/strip/true/crop/3600x2400+0+0/resize/1760x1174!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F72%2F65%2F31e5663d4a6d8efd2e6af082c146%2Fprestont6horpe-kb.JPG 2x" data-size="fallbackImageSize">
    

    
        <source width="880" height="587" srcset="https://npr.brightspotcdn.com/dims4/default/8f60449/2147483647/strip/true/crop/3600x2400+0+0/resize/880x587!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F72%2F65%2F31e5663d4a6d8efd2e6af082c146%2Fprestont6horpe-kb.JPG" data-size="fallbackImageSize">
    

        
    

    
    <img alt="A list of approved computer items is taped to the door of Maine inmate Preston Thorpe, who works as a senior software engineer from his cell at the Mountain View Correctional Facility in Charleston, Maine." srcset="https://npr.brightspotcdn.com/dims4/default/b5dadba/2147483647/strip/true/crop/3600x2400+0+0/resize/1760x1174!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F72%2F65%2F31e5663d4a6d8efd2e6af082c146%2Fprestont6horpe-kb.JPG 2x" width="880" height="587" loading="lazy" src="https://npr.brightspotcdn.com/dims4/default/8f60449/2147483647/strip/true/crop/3600x2400+0+0/resize/880x587!/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F72%2F65%2F31e5663d4a6d8efd2e6af082c146%2Fprestont6horpe-kb.JPG">


</picture>
        
    
    
    
    
    <div>
    

    <div><p>Kevin Bennett</p>
            
                <p>/</p>
            
        
            <p> For Maine Public</p></div><figcaption>A list of approved computer items is taped to the door of Maine inmate Preston Thorpe, who works as a senior software engineer from his cell at the Mountain View Correctional Facility in Charleston, Maine.</figcaption>
    </div>
    
</figure>
</div>
<p>"It's important that the officers work with residents that have hope and have meaning in their life," he says. "We had 87 assaults on staff in 2017. Last year, we had seven assaults on staff. So all of this work isn't just about the residents. It's about the community ... the officers that go to work everyday and don't feel like their life is at risk."</p><p>Liberty is optimistic that remote work can be expanded to other people in prison as the network of employers who understand their value grows.</p><p>"I think it can become the norm," he says. "This isn't a reckless attempt at finding work for individuals. This is a well-thought out plan with lessons learned and consequences. ... The last thing anybody wants is to lose their laptop."</p><p>Preston Thorpe would agree. He's hoping to be released sometime next year. He never expected to have started a successful career in prison or to have bought a house. But he says what he's most proud of is that after everything he's put his parents through, they are proud of him.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Federal judge lifts administration halt of offshore wind farm in New England (215 pts)]]></title>
            <link>https://apnews.com/article/trump-renewable-energy-offshore-wind-revolution-wind-f1cbe85a829e3d5e5496f834bcb617d1</link>
            <guid>45340550</guid>
            <pubDate>Mon, 22 Sep 2025 22:45:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/trump-renewable-energy-offshore-wind-revolution-wind-f1cbe85a829e3d5e5496f834bcb617d1">https://apnews.com/article/trump-renewable-energy-offshore-wind-revolution-wind-f1cbe85a829e3d5e5496f834bcb617d1</a>, See on <a href="https://news.ycombinator.com/item?id=45340550">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>WASHINGTON (AP) — A federal judge ruled Monday that a nearly complete offshore wind project halted by the administration can resume, dealing President Donald Trump a setback in his ongoing effort to restrict the fledgling industry.</p><p>Work on the nearly completed Revolution Wind project for Rhode Island and Connecticut <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/offshore-revolution-wind-project-stopped-trump-33214b9efb8f3f7a98c58299581bff9f">has been paused since Aug. 22</a></span> when the Bureau of Ocean Energy Management issued a stop-work order for what it said were national security concerns. The Interior Department agency did not specify those concerns at the time. Both the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-renewable-energy-offshore-wind-revolution-wind-356d6be1f0967302cd8414b2fb881308">developer and the two states sued</a></span> in federal courts.</p><p>Danish energy company Orsted and its joint venture partner Skyborn Renewables sought a preliminary injunction in U.S. District Court that would allow them to move forward with the project.</p><p>At a hearing Monday, Judge Royce Lamberth said he considered how Revolution Wind has relied on its federal approval, the delays are costing $2.3 million a day and if the project can’t meet deadlines, the entire enterprise could collapse. After December, the specialized ship needed to complete the project won’t be available until at least 2028, he said. More than 1,000 people have been working on the wind farm, which is 80% complete.</p>
    
<p>“There is no question in my mind of irreparable harm to the plaintiffs,” Lamberth said, as he granted the motion for the preliminary injunction. In his written ruling, he said Revolution Wind had “demonstrated likelihood of success on the merits” of its claim, adding that granting the injunction is in the public interest.</p>



<p>Interior Department spokeswoman Elizabeth Peace said the ruling means Revolution Wind “will be able to resume construction” while the Bureau of Ocean Energy Management “continues its investigation into possible impacts by the project to national security and prevention of other uses on the Outer Continental Shelf.”</p>
    
    
    
<p>The administration said in a court filing this month that while BOEM approved the wind farm, it stipulated that the developer continue to work with the Department of Defense to mitigate national security concerns. It said the Interior Department, to date, has not received any information that these concerns have been addressed.</p>
    
<p>Orsted said Monday that construction will resume as soon as possible, and it will continue to seek to work collaboratively with the administration.</p><p>Nancy Pyne of the Sierra Club said the court ruling “reaffirms that Donald Trump and his administration’s attacks on clean energy are not only reckless and harmful to our communities, but they are also illegal.” Trump is trying to “kneecap” renewable energy “in favor of dirty and expensive fossil fuels,” she said. </p><p>White House spokeswoman Anna Kelly said Trump was elected with a mandate to “restore our country’s energy dominance — which includes prioritizing the most effective and reliable tools to power our country. This will not be the final say on the matter.” </p><p>On the campaign trail, <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-offshore-wind-energy-4e5b18ecd4799cc4cfd8cd7dc7b326ee">Trump vowed to end the offshore wind industry</a></span> as soon as he returned to the White House. He wants to boost production of fossil fuels such as oil, natural gas and coal, which emit greenhouse gases that cause climate change, in order for the U.S. to have the lowest-cost energy and electricity of any nation in the world, he says.</p>
    
<p>His administration has <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/offshore-revolution-wind-project-stopped-trump-33214b9efb8f3f7a98c58299581bff9f">stopped construction on major offshore wind farms</a></span>, revoked wind energy permits and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/wind-energy-offshore-turbines-trump-executive-order-995a744c3c1a2eddb30cacf50b681f13">paused permitting</a></span>, canceled plans to use <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-wind-permitting-offshore-7a05dff77ba92e4a7761604583a6d208">large areas of federal waters</a></span> for new offshore wind development and stopped <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-offshore-wind-renewable-energy-transportation-8578da8b985b6d4eef20ec4d85c21b5d">$679 million in federal funding</a></span> for a dozen offshore wind projects. </p><p>Last week, the administration moved to block a <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-offshore-wind-southcoast-massachusetts-125266070fcc8c784c92ca83d6f14300">separate Massachusetts offshore wind farm</a></span>. That was just days after the Interior Department asked a federal judge in Baltimore to cancel previous approval to build an offshore wind project in Maryland. </p><p>Revolution Wind is supposed to be Rhode Island’s and Connecticut’s first large offshore wind farm, capable of supplying power to more than 350,000 homes, about 2.5% of the region’s electricity needs.</p><p>Connecticut Attorney General William Tong and Rhode Island Attorney General Peter Neronha, who are both Democrats, called the judge’s ruling a major win for workers and families, who need the project to stay on track so it can start to drive down unaffordable energy bills. </p>
    
<p>Connecticut Rep. Joe Courtney, a Democrat, said a multibillion-dollar project that is 80% complete and was fully permitted with input by the Pentagon is not a national security problem. The Interior Department “should take the hint and let the thousands of construction workers finish the job,” he said.</p><p>Orsted began construction in 2024 about 15 miles (24 kilometers) south of the Rhode Island coast. It says in its complaint that about $5 billion has been spent or committed, and it expects more than $1 billion in costs if the project is canceled. Rhode Island is already home to one offshore wind farm, the five-turbine Block Island Wind Farm.</p>
    
<p>___</p><p>McDermott reported from Providence, Rhode Island. AP Writer Susan Haigh in Hartford, Connecticut, contributed to this report.</p><p>___</p><p>The Associated Press’ climate and environmental coverage receives financial support from multiple private foundations. AP is solely responsible for all content. Find AP’s <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.ap.org/about/standards-for-working-with-outside-groups/" target="_blank" rel="noopener">standards</a></span> for working with philanthropies, a list of supporters and funded coverage areas at <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://www.ap.org/discover/Supporting-AP" target="_blank" rel="noopener">AP.org</a></span>.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kevo app shutdown (128 pts)]]></title>
            <link>https://www.kwikset.com/support/answers/what-does-the-kevo-app-shutdown-mean-to-my-kevo-door-lock</link>
            <guid>45340192</guid>
            <pubDate>Mon, 22 Sep 2025 22:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kwikset.com/support/answers/what-does-the-kevo-app-shutdown-mean-to-my-kevo-door-lock">https://www.kwikset.com/support/answers/what-does-the-kevo-app-shutdown-mean-to-my-kevo-door-lock</a>, See on <a href="https://news.ycombinator.com/item?id=45340192">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                    
                    <span>
                        <div><p>After more than a decade of service, as of November 14, 2025 the Kevo app and web portal will no longer be available.</p><p>

ASSA ABLOY Americas Residential Inc. (“ASSA ABLOY”, “we” and “us”), which is the successor to the company that previously marketed Kwikset Kevo, Weiser Kevo and Baldwin Evolved smart door locks, will cease supporting your Kevo lock’s remote functionality.</p></div>
<p><strong><em>Locks Affected (All Generations): </em></strong><em>Kevo, Kevo Convert, Kevo Plus, Baldwin Evolved</em></p>
<p><strong><em>Brands Affected: </em></strong><em>Kwikset, Weiser, Baldwin</em></p>
<p><strong>Impact</strong></p>
<ul>
    <li>Users can no longer open/close or manage their door lock via the mobile app or web portal.</li>
</ul>

<p><strong>Not Impacted</strong></p>
<ul>
    <li>Physical Key, users will be able to unlock or lock the deadbolt with the physical key</li>
    <li>Key FOB, users will be able to unlock or lock the deadbolt with the Key FOB</li>
</ul>

<p><strong>Required User Action</strong></p>
<p>Prepare in advance for the Kevo app shutdown.&nbsp; Ensure that you have the physical key or key fob to unlock and lock the door moving forward or you can redeem the unique promotional offer that existing Kevo users received via e-mail and replace the Kevo deadbolt entirely.</p>
<p><strong>Replacement Door Lock Discount</strong></p>
<p>To help make this transition easier, we’re offering our steepest discounts ever on trusted smart lock replacements, available exclusively to Kevo users.</p>
<p><strong><em>&nbsp;(United States Only)</em></strong></p>
<p>Offers will be fulfilled by our partners at Level, a fellow ASSA ABLOY brand.&nbsp; Your orders will be securely processed and shipped through Level’s website.</p>
<p>Available options include:</p>
<ul>
    <li>$80 off Kwikset Halo Keypad Wi-Fi Smart Lock</li>
    <li>$130 off Level Lock+&nbsp;</li>
</ul>
<img src="https://images.kwikset.com/is/image/Kwikset/Kwikset%5FPromo?scl=1" alt="How to Redeem">
<p>

<img src="https://images.kwikset.com/is/image/Kwikset/Level%5FPromo?scl=1" alt="How to Redeem">
<br>
How to Redeem</p><ol>
    <li>Use the following link to visit <a href="http://www.level.co/kevo">
    </a>
    <p><a href="http://www.level.co/kevo"></a><a href="http://www.level.co/kevo"></a><a href="http://www.level.co/kevo"></a><a href="http://www.level.co/kevo">www.level.co/kevo</a>
    </p>
    </li>
    <li>Choose the replacement deadbolt that is right for you</li>
    <li>Enter your unique promotional code at checkout</li>
</ol>
<ul>
    <li>Your unique promotional code was sent to your registered Kevo e-mail address, notifying you of the Kevo app shutdown</li>
</ul>
<div><p>The above offer is final, and no other offers will ensue with respect to the loss of remote functionality of your Kevo door lock.&nbsp; This offer will expire December 14, 2025.</p><p>


<strong>(Canada Only)</strong><br>
Orders will be securely processed and shipped through Weiser’s customer service team.<br>
Available options include:<br>
- $89 (CDN) off Weiser Halo Keypad Wi-Fi Smart Lock</p><p>
&nbsp;
<img src="https://images.kwikset.com/is/image/Kwikset/Weiser%5FPromo?scl=1" alt="How to Redeem"></p><p>

How to Redeem<br>
1. Call our Weiser customer service team: 1-800-501-9471<br>
2. Ask the service team member about claiming your Kevo replacement offer<br>
3. Provide your unique promo code<br>
o Your unique promotional code was sent to your registered Kevo e-mail address, notifying you of the Kevo app shutdown<br>
These offers are made in connection with the Kevo app shutdown; and available through December 14, 2025—without further extension.</p></div>

                    </span>
                </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paper2Agent: Stanford Reimagining Research Papers as Interactive AI Agents (142 pts)]]></title>
            <link>https://arxiv.org/abs/2509.06917</link>
            <guid>45340133</guid>
            <pubDate>Mon, 22 Sep 2025 22:02:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2509.06917">https://arxiv.org/abs/2509.06917</a>, See on <a href="https://news.ycombinator.com/item?id=45340133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2509.06917">View PDF</a>
    <a href="https://arxiv.org/html/2509.06917v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We introduce Paper2Agent, an automated framework that converts research papers into AI agents. Paper2Agent transforms research output from passive artifacts into active systems that can accelerate downstream use, adoption, and discovery. Conventional research papers require readers to invest substantial effort to understand and adapt a paper's code, data, and methods to their own work, creating barriers to dissemination and reuse. Paper2Agent addresses this challenge by automatically converting a paper into an AI agent that acts as a knowledgeable research assistant. It systematically analyzes the paper and the associated codebase using multiple agents to construct a Model Context Protocol (MCP) server, then iteratively generates and runs tests to refine and robustify the resulting MCP. These paper MCPs can then be flexibly connected to a chat agent (e.g. Claude Code) to carry out complex scientific queries through natural language while invoking tools and workflows from the original paper. We demonstrate Paper2Agent's effectiveness in creating reliable and capable paper agents through in-depth case studies. Paper2Agent created an agent that leverages AlphaGenome to interpret genomic variants and agents based on ScanPy and TISSUE to carry out single-cell and spatial transcriptomics analyses. We validate that these paper agents can reproduce the original paper's results and can correctly carry out novel user queries. By turning static papers into dynamic, interactive AI agents, Paper2Agent introduces a new paradigm for knowledge dissemination and a foundation for the collaborative ecosystem of AI co-scientists.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Jiacheng Miao [<a href="https://arxiv.org/show-email/844f854d/2509.06917" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 8 Sep 2025 17:28:42 UTC (6,422 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Germicidal UV could make airborne diseases as rare as those carried by water (103 pts)]]></title>
            <link>https://www.worksinprogress.news/p/how-to-clean-the-air</link>
            <guid>45339923</guid>
            <pubDate>Mon, 22 Sep 2025 21:44:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.worksinprogress.news/p/how-to-clean-the-air">https://www.worksinprogress.news/p/how-to-clean-the-air</a>, See on <a href="https://news.ycombinator.com/item?id=45339923">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>Works in Progress is becoming a print magazine. Our first print issue, Issue 21, will land in November. If you live in the United States and the United Kingdom, you can subscribe </span><a href="https://worksinprogress.co/print/" rel="">here</a><span>. If you live outside the US or UK and want to be notified as soon as subscriptions are live in your country, </span><a href="https://airtable.com/appYLHseqbAs4aOV9/paglNkIcTXDSx6Bz5/form" rel="">leave your details here</a><span>.</span></em></p><p>Between the 1860s and 1920, successive outbreaks of typhoid fever killed over 300,000 Americans. As population growth surged and people moved to urban areas en masse, American cities began to dump sewage in the same rivers that provided their drinking water. After epidemiologists linked typhoid outbreaks to water cleanliness, cities began building large-scale sand filtration systems in the 1890s, and in 1908, Jersey City pioneered the first continuous chlorination of a public water supply. By the 1920s, typhoid deaths had fallen by two-thirds, and waterborne diseases were in retreat across the country.</p><p>While typhoid and other waterborne diseases triggered vast engineering and regulatory responses, the equivalent airborne threats have not. Tuberculosis alone kills more than a million people every year around the world, yet the air in schools, clinics, and public buildings remains largely unfiltered and unmonitored. Covid-19, which killed over seven million people, demonstrated how rapidly airborne pathogens can spread in poorly ventilated spaces.</p><p>Just as filtration and chlorination made drinking water safe at scale, we now have the tools to do the same for indoor air: ventilation, high-quality filters, and germicidal light. A century ago, germicidal light at 254 nanometers seemed to be a promising way of controlling pathogens by killing them in the air, but it turned out to cause irritation and cancer in the skin, and it was largely dropped when antibiotics became widespread.</p><p>But today there is an update that has none of these drawbacks. We now know that wavelengths under 230 nanometers, especially 222 nanometer light, are harmless to humans, but can still disable microscopic pathogens. We know how to filter out all wavelengths except the ones we want, and how to direct them away from humans, cycling the air through them to clean it without exposing people to it, just in case it carries unknown risks. This far-UVC light, as it is called, may be how we can make the air we breathe as safe as the water we drink.</p><p><span>Until the mid-nineteenth century, most physicians believed that disease spread through </span><a href="https://www.sciencedirect.com/topics/medicine-and-dentistry/miasma-theory" rel="">miasmas</a><span>, poisonous vapors rising from filth and decay. Contemporaries were obsessed with air: moving to the countryside for the air, taking the air at the seaside. Bad air was blamed for sickness. Herbs were burned to purify the air to fight the plague. But because they didn’t understand what made the air dirty, they were not very good at cleaning it. This began to change only when Louis Pasteur and Robert Koch provided the first definitive proof that microscopic organisms were responsible for infectious disease.</span></p><p>Cleaning air relies on the same fundamental techniques as cleaning water: replacement, filtration, and disinfection. Pathogens replicate inside people, who then expel them into the air by breathing, talking, or coughing, where they can remain suspended and infect new individuals. The relative contributions of aerosol transmission, droplet transmission, and fomite (surface) transmission vary between diseases. Certain diseases, such as Covid-19, are driven by a small number of highly infectious individuals (‘superspreaders’) that account for a disproportionate number of cases.</p><p><a href="https://www.globalhealthdelivery.org/files/ghd_dubai/files/history_of_uvg_radiation_reed.pdf" rel="">In 1877</a><span>, British researchers Arthur Downes and Thomas Blunt stumbled upon a discovery that would lay the groundwork for modern disinfection. In </span><a href="https://royalsocietypublishing.org/doi/epdf/10.1098/rspl.1877.0068" rel="">a paper</a><span> submitted to the Royal Society of London, they described how over the course of six months they had used sunlight to prevent bacteria from growing in a tube.</span></p><p><span>Follow-up research by Robert Koch demonstrated that sunlight could kill </span><em>Mycobacterium tuberculosis</em><span>, but the early experiments lacked precision. Scientists knew light worked, but not which parts of the spectrum were responsible. The turning point came in 1930, when Frederick L Gates </span><a href="https://pubmed.ncbi.nlm.nih.gov/19872573/" rel="">published</a><span> the first quantitative analysis of how ultraviolet light affected bacteria, pinpointing peak germicidal effectiveness at 265 nanometers, the same point that nucleic acids – DNA and RNA – absorb light.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!rWCA!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!rWCA!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 424w, https://substackcdn.com/image/fetch/$s_!rWCA!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 848w, https://substackcdn.com/image/fetch/$s_!rWCA!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 1272w, https://substackcdn.com/image/fetch/$s_!rWCA!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!rWCA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png" width="1024" height="564" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:564,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!rWCA!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 424w, https://substackcdn.com/image/fetch/$s_!rWCA!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 848w, https://substackcdn.com/image/fetch/$s_!rWCA!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 1272w, https://substackcdn.com/image/fetch/$s_!rWCA!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b4452e-9dc2-4cd1-83df-8ac0ad7f6388_1024x564.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Understanding the spectrum wasn’t necessary for harnessing it. In 1901, American electrical engineer Peter Cooper Hewitt </span><a href="https://patents.google.com/patent/US682692" rel="">patented</a><span> the first mercury-vapor lamp to achieve widespread commercial success. Hewitt created a voltage difference across electrodes in a glass tube, with mercury vapor causing electrons to separate from mercury atoms and collide with other atoms, exciting them to higher energy states. When these excited atoms return to their ground state, they release energy as photons, primarily at a wavelength of 254 nanometers.</span></p><p><span>Nucleic acids absorb this 254-nanometer light and produce new bonds between bases, preventing DNA/RNA replication. For human skin and eyes, this means sunburn-like irritation. But for viruses, amoeba, and bacteria in the air, as engineers at an American manufacturing company put it, these </span><a href="https://archive.warplane.com/omeka/s/archive/item/20985#:~:text=Its%20rays%20spell%20doom%20for%20germs" rel="">rays spell doom</a><span>.</span></p><p><span>An array of different factors influences how sensitive pathogens are to ultraviolet-C (UVC), ultraviolet light with a wavelength of 100–280 nanometers. Viruses with larger genomes – such as herpesviruses (which have about 150,000 base pairs) or coronaviruses (30,000 base pairs) – offer </span><a href="https://journals.asm.org/doi/pdf/10.1128/jvi.79.22.14244-14252.2005" rel="">many nucleotide bonds for photons to break,</a><span> so they can be more quickly disabled than small-genome viruses such as parvoviruses (5,000 base pairs).</span></p><p><span>In 1936, Dr. Deryl Hart, a surgeon at Duke University Hospital, became the first person to use ultraviolet radiation to curb airborne infections in surgical operating rooms. High-intensity germicidal ultraviolet light fixtures, designed to irradiate the entire room, cut postoperative wound infection rates </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC2789813/" rel="">from 11.6 percent to just 0.2 percent,</a><span> and not one patient out of 2,463 cases died from postoperative infections.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MfiD!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MfiD!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 424w, https://substackcdn.com/image/fetch/$s_!MfiD!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 848w, https://substackcdn.com/image/fetch/$s_!MfiD!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 1272w, https://substackcdn.com/image/fetch/$s_!MfiD!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MfiD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png" width="1024" height="722" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:722,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!MfiD!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 424w, https://substackcdn.com/image/fetch/$s_!MfiD!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 848w, https://substackcdn.com/image/fetch/$s_!MfiD!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 1272w, https://substackcdn.com/image/fetch/$s_!MfiD!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F206f1243-c4f2-44a9-891c-9a7f27c23eae_1024x722.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span> Ultraviolet sterilization (Using the Sterilamp; developed by Westinghouse Engineers) in effect in an operating room. Image credit: </span><a href="https://surgery.duke.edu/about-department/history" rel="">Duke Medical Center Archives</a><span>.</span></figcaption></figure></div><p><span>Shortly after the installation at Duke, UV from mercury vapor lamps was used to create invisible ‘curtains’ between cubicles in hospital wards and cribs in nurseries in </span><a href="https://www.sciencedirect.com/science/article/abs/pii/S0022347642800451" rel="">Philadelphia</a><span>, </span><a href="https://jamanetwork.com/journals/jamapediatrics/article-abstract/1719444" rel="">Boston</a><span>, </span><a href="https://jamanetwork.com/journals/jama/article-abstract/260580" rel="">Toronto</a><span>, and </span><a href="https://jamanetwork.com/journals/jamapediatrics/article-abstract/1180579" rel="">Evanston</a><span>. In Boston, this attempt to prevent respiratory pathogens from crossing cubicles and infecting infant patients led to infection rates that were </span><a href="https://jamanetwork.com/journals/jamapediatrics/article-abstract/1719444#" rel="">a quarter</a><span> of those in the other cubicles. In the other cases, cross-infections fell by between 40 percent and 96 percent.</span></p><p><span>In 1937, </span><a href="https://web.archive.org/web/20220217071849/https://ghdcenter.hms.harvard.edu/files/ghd_dubai/files/wells_1942.pdf" rel="">researchers installed upper-room germicidal UV</a><span> lights in the Germantown Friends School in Philadelphia and studied its impact over the next few school years. During the fourth year of the study, Philadelphia saw its largest recorded epidemic of measles, the </span><a href="https://www.thelancet.com/journals/laninf/article/PIIS1473-3099(17)30307-9/abstract" rel="">most transmissible known pathogen</a><span>. In the irradiated classrooms, only 14.5 percent of susceptible children fell ill, while in the unprotected ones, infection rates soared to 55 percent.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!74LI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!74LI!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 424w, https://substackcdn.com/image/fetch/$s_!74LI!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 848w, https://substackcdn.com/image/fetch/$s_!74LI!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 1272w, https://substackcdn.com/image/fetch/$s_!74LI!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!74LI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png" width="718" height="556" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:556,&quot;width&quot;:718,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!74LI!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 424w, https://substackcdn.com/image/fetch/$s_!74LI!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 848w, https://substackcdn.com/image/fetch/$s_!74LI!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 1272w, https://substackcdn.com/image/fetch/$s_!74LI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F06e7f0ed-5ea0-4ee3-bd57-5959254ff1ed_718x556.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Classroom at Germantown Friends School with central UV lighting. Image credit: The Global Health Delivery Project, Harvard.</figcaption></figure></div><p><span>At the height of World War II, US defence manufacturer Westinghouse </span><a href="https://archive.warplane.com/omeka/s/archive/item/20985#:~:text=THE%20DEATH%20RAY%20THAT%20GUARDS%20LIFE" rel="">wrote</a><span> that it was ‘fighting two wars at once’: one against the Germans and Japanese and the other against germs. Once a major producer of UV lamps and fixtures, the company had developed the Sterilamp in the 1930s. The Sterilamp system is described in a </span><a href="https://archive.warplane.com/omeka/s/archive/item/20985#:~:text=TITLE-,Westinghouse%20Employee%20Newsletter%20(September%201943),-DESCRIPTION" rel="">1943 newsletter</a><span> as a ‘DEATH RAY THAT GUARDS LIFE’.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!AMZK!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!AMZK!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 424w, https://substackcdn.com/image/fetch/$s_!AMZK!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 848w, https://substackcdn.com/image/fetch/$s_!AMZK!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 1272w, https://substackcdn.com/image/fetch/$s_!AMZK!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!AMZK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png" width="600" height="450" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/9b607c2c-5dba-4100-bc72-169545d28246_600x450.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:450,&quot;width&quot;:600,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!AMZK!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 424w, https://substackcdn.com/image/fetch/$s_!AMZK!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 848w, https://substackcdn.com/image/fetch/$s_!AMZK!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 1272w, https://substackcdn.com/image/fetch/$s_!AMZK!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9b607c2c-5dba-4100-bc72-169545d28246_600x450.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>A Westinghouse Sterilamp early GUV light bulb carrying the cautionary warning ‘DANGER PROTECT EYES FROM RAYS’. First introduced in the 1930s. Image credit: The National Museum of American History.</figcaption></figure></div><p><span>But the deployment of germicidal UV light stalled after the war. In 1945–46, the New York Department of Health tried to </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC1623610/pdf/amjphnation01116-0034.pdf" rel="">replicate the Philadelphia findings in large public rural schools</a><span> and failed. In one of the schools with an internal control group in Port Byron, 90.4 percent of susceptible students in UV-treated classrooms still contracted measles, compared to 83 percent in unirradiated classrooms.</span></p><p><span>Once they took bus ridership into account, the researchers found that UV had appeared to reduce the measles incidence rate by roughly 8.2 percentage points (from 77.4 percent to 69.2 percent) in non-bus riders. Germicidal UV could disrupt measles transmission in specific spaces such as classrooms, but it proved insufficient if face-to-face exposure continued in buses, hallways, and other shared spaces. Mercury lamps were also costly and could irritate the skin and eyes of people exposed to them. No long-term effects had been observed in humans at the doses used in schools, but higher doses had been shown to </span><a href="https://www.ncbi.nlm.nih.gov/books/NBK401582/" rel="">raise long-term cancer risk in mice</a><span>. At the same time, the large-scale emergence of antibiotics was transforming the fight against infectious diseases. By 1945, </span><a href="https://www.amazon.co.uk/Origins-Efficiency-Brian-Potter/dp/1953953522" rel="">mass production made penicillin widely available</a><span>, ushering in the antibiotic era and shifting the medical focus toward drug-based infection control. </span><a href="http://forum.effectivealtruism.org/posts/z8ZWwm4xeHBAiLZ6d/thoughts-on-far-uvc-after-working-in-the-field-for-8-months#Efficacy" rel="">Together with the failures of the UV studies, interest in</a><span> germicidal UV receded.</span></p><p><span>Decades later, </span><a href="https://worksinprogress.co/issue/age-of-the-bacteriophage/" rel="">over 700,000 people a year</a><span> die from antibiotic resistance as people use more and </span><a href="https://www.macroscience.org/p/how-scientific-incentives-stalled" rel="">more antibiotics while their discovery rates stagnate</a><span>. </span><a href="https://www.wired.com/story/the-teeny-tiny-scientific-screwup-that-helped-covid-kill/" rel="">Airborne viral pandemics</a><span>, which antibiotics cannot treat, have caused enormous economic damage and inflicted </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC7149761/" rel="">tens of millions</a><span> of deaths. There is </span><a href="https://www.nature.com/articles/s41598-020-67211-2" rel="">once again a case for the use of germicidal ultraviolet light</a><span>.</span></p><p><span>Skin and eye irritation and </span><a href="https://health.ec.europa.eu/system/files/2018-03/scheer_o_002_0.pdf" rel="">cancer risks</a><span> limited direct exposure to 254-nanometer germicidal UV to surgical cases. But new technologies – circulation, light filtering, and lower wavelengths – have together fixed these problems.</span></p><p>If we can circulate air, we can move it, clean it, and put it back. Today’s systems do this by projecting beams across the upper level of a room, above the heads of occupants. Natural circulation patterns move air to the ceiling, where it is cleaned, before it falls back down. But even reflected beams can cause irritation, meaning that each installation has to be calibrated carefully for the specifics of the room. Even repainting or shifting furniture can change the reflection of the beams, meaning that the UV beams would need to be recalibrated.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!1OsI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!1OsI!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 424w, https://substackcdn.com/image/fetch/$s_!1OsI!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 848w, https://substackcdn.com/image/fetch/$s_!1OsI!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 1272w, https://substackcdn.com/image/fetch/$s_!1OsI!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!1OsI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png" width="1024" height="716" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:716,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!1OsI!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 424w, https://substackcdn.com/image/fetch/$s_!1OsI!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 848w, https://substackcdn.com/image/fetch/$s_!1OsI!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 1272w, https://substackcdn.com/image/fetch/$s_!1OsI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff40eb0ab-e5ea-4b00-8235-5a6016ba1097_1024x716.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Shorter-wavelength light </span><a href="https://pubmed.ncbi.nlm.nih.gov/39828932/" rel="">works</a><span> just as </span><a href="https://www.nature.com/articles/s41598-024-57441-z" rel="">effectively, without many of the downsides. </a><span>Light with a wavelength of 230 nanometers or lower, known as ‘far-UVC’, disables pathogens without hurting humans, but mercury lamps cannot produce it.</span></p><p><span>Unlike longer wavelengths, far-UVC penetrates weakly, meaning it is only absorbed by the uppermost layers of the skin and eye, tissues which slough off frequently and do not divide. When shone directly into the eyes, </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11913762/" rel="">germicidal doses of far-UVC</a><span> do not appear to have any effect beyond temporary discomfort (the same as if a torch was shone into your eyes). When installed overhead, the lamp’s positioning and human facial structure mean only five percent of the light reaches the eye, creating an even larger safety margin.</span></p><p><span>Long-term exposure does not harm mice at all, </span><a href="https://pubmed.ncbi.nlm.nih.gov/32222977/#:~:text=phenotype%20mice%20that%20lack%20xeroderma,perspective%20of%20skin%20cancer%20development" rel="">even those with a severely limited ability to repair DNA defects</a><span>. In humans, a 36-month-long trial installation of </span><a href="https://onlinelibrary.wiley.com/doi/epdf/10.1111/php.14052" rel="">far-UVC in a hospital</a><span>, with ongoing exposure to germicidal doses, caused no adverse effects on those working on the ward. There is no evidence from any other study that far-UVC raises cancer rates, though more work should be done to prove this beyond any doubt.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!-kQl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!-kQl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 424w, https://substackcdn.com/image/fetch/$s_!-kQl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 848w, https://substackcdn.com/image/fetch/$s_!-kQl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 1272w, https://substackcdn.com/image/fetch/$s_!-kQl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!-kQl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png" width="1024" height="820" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:820,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!-kQl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 424w, https://substackcdn.com/image/fetch/$s_!-kQl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 848w, https://substackcdn.com/image/fetch/$s_!-kQl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 1272w, https://substackcdn.com/image/fetch/$s_!-kQl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4abbdbf8-fe13-4b94-8fdd-da8c3b2874c2_1024x820.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In order to prevent disease transmission, far-UVC lamps must disable pathogens in respiratory aerosols quickly enough that, by the time they are inhaled, not enough for an infectious dose remain.</p><p><span>A </span><a href="https://www.nature.com/articles/s41598-024-57441-z#:~:text=the%20inactivation%20estimates,in%20an%20occupied%20indoor%20location" rel="">2024 study</a><span> presented some of the best data on far-UVC in an occupied room. Four lamps were installed in a lab mouse cage-cleaning room, where the constant activity and movement continuously aerosolized murine norovirus present in the bedding. When switched on, the lamps reduced the amount of virus in the air by 98 percent, equivalent to at least 36 air changes per hour. This happened despite murine norovirus being more resistant to far-UVC than many common human respiratory viruses, </span><a href="https://www.sciencedirect.com/science/article/pii/S0195670120301298" rel="">likely due to its tough protein outer ‘shell’</a><span>.</span></p><p>There are other ways to clean the air, like ventilation and filtration. There’s an important role for both of these approaches, but they come with critical limitations that only far-UVC can plausibly overcome.</p><p><span>Ventilation is the easiest method of removing things from indoor air, diluting pathogens and pollutants into the 5.5 quadrillion tonnes of atmosphere outside. But it is not always convenient. It can be awkward or noisy to install and run. In highly polluted areas, bringing in outdoor air reduces disease transmission at the expense of worse air quality. In 2024, </span><a href="https://www.reuters.com/business/healthcare-pharmaceuticals/only-seven-countries-met-who-air-quality-standards-2024-data-shows-2025-03-11/#:~:text=Only%20Australia%2C%20New%20Zealand%2C%20the,made%20the%20grade%2C%20IQAir%20said." rel="">only seven countries</a><span> met World Health Organization air quality standards. In very hot or cold places, outdoor air must be heated or cooled, which can be energy-intensive and costly, especially in older or heritage buildings where air conditioning needs to be retrofitted.</span></p><p><span>Another technique is filtration. Mechanical filters work by forcing air through a dense, pleated mesh of fine fibers that trap hazardous particles. </span><a href="https://www.britannica.com/technology/high-efficiency-particulate-air-system?utm_source=chatgpt.com" rel="">Originally developed as part of the Manhattan Project</a><span> to prevent the spread of radioactive particles, mechanical filters have become </span><a href="https://www.britannica.com/technology/high-efficiency-particulate-air-system?utm_source=chatgpt.com" rel="">standard</a><span> in hospitals, cleanrooms, and aircraft cabins.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!nD5H!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!nD5H!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 424w, https://substackcdn.com/image/fetch/$s_!nD5H!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 848w, https://substackcdn.com/image/fetch/$s_!nD5H!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 1272w, https://substackcdn.com/image/fetch/$s_!nD5H!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!nD5H!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png" width="1024" height="918" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:918,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!nD5H!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 424w, https://substackcdn.com/image/fetch/$s_!nD5H!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 848w, https://substackcdn.com/image/fetch/$s_!nD5H!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 1272w, https://substackcdn.com/image/fetch/$s_!nD5H!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca50b6d1-09f2-4ad3-b84e-fa2ec50aa48b_1024x918.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Mechanical filters are ‘plug and play’: there are dozens of verified and recommended models that anyone can buy off the shelf, install in their house by plugging them in, and expect to deliver reduced pollutants, allergens, and cleaner air for between $80 and $300. Consumer far-UVC systems are often considerably more expensive – a </span><a href="https://www.amazon.com/Technologies-Krypton-36-222nm-Ceiling-Cleaner/dp/B0CPNJBNNL" rel="">typical example</a><span> costs $2,500 for a lamp covering 1,000 square feet, although a </span><a href="https://aerolamp.net/" rel="">newer model</a><span> has recently come to market at $600, and </span><a href="https://cybernightmarket.com/" rel="">less expensive lamps</a><span> with lower output can be added together to cover a similar floorspace.</span></p><p>The drawbacks of ventilation-based air filtration methods are similar to the drawbacks of ventilation itself. Moving air from place to place and forcing it through a fine filter requires energy, and fresh air from outdoors is often at the wrong temperature, requiring extra heating or cooling. Meanwhile, the constant air movement can also chill the air to the point of discomfort, requiring indoor heating. This has obvious impacts on the costs and environmental footprint of buildings.</p><p><span>Doubling the ventilation rate from the US standard minimum in offices could add </span><a href="https://www.mdpi.com/1660-4601/12/11/14709#B10-ijerph-12-14709" rel="">up to $40 per person per year</a><span> to building running costs. This is lower than typically </span><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/ina.12192?casa_token=P1Zttgo1oAQAAAAA%3AntfvAyxBEL0J1BluyedDMYnPDbhR3D19PPGXydkRqnd2M1sR5DrW3lHohZY4KB9FwvWuDKSKVTF6eVY" rel="">predicted</a><span>, but still more than double what many building officials were prepared (before the pandemic) to pay. Energy recovery units help equalize the temperatures between intake and exhaust air, and can </span><a href="https://www.mdpi.com/1660-4601/12/11/14709" rel="">lower these figures by about 60 percent</a><span> (or even more), depending on local climate and system type. However, in Europe, the hurdle is even higher: most buildings have no mechanical ventilation at all, so adapting existing ventilation systems is out of the question. For example, in the UK, </span><a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1019896/cooling-in-uk.pdf" rel="">an engineering review</a><span> found that only five percent of residential buildings were likely to have air conditioning (a proxy for mechanical ventilation) by 2019. By contrast, in the US, </span><a href="https://www.iea.org/news/air-conditioning-use-emerges-as-one-of-the-key-drivers-of-global-electricity-demand-growth" rel="">about 90 percent</a><span> of residences have air conditioning.</span></p><p>Ventilation comes with another tradeoff: noise. The more air you filter, the harder your fan has to work, the faster it spins, and the louder it gets. Free-standing filtration units can be powerful, quiet, or affordable – but rarely all three at once. Purpose-built ventilation can be made quieter, but quiet movement of a large volume of air requires wide, leak-free ducting, which can increase installation complexity. Real world studies have shown that the noise and discomfort created by even relatively modest free-standing units mean that they are frequently turned down or switched off.</p><p><span>These drawbacks mean that ventilation-based methods lack the power to effectively block transmission of highly infectious pathogens or prevent pandemics. Without UV light, public buildings will require air handling systems akin to those in hospital isolation rooms to comply with current </span><a href="https://www.ashrae.org/technical-resources/bookstore/ashrae-standard-241-control-of-infectious-aerosols" rel="">infection control </a><span>guidelines. While circumstances vary from place to place, ventilation-based air quality measures quickly become impractical beyond around five air changes per hour, while upper-room UV light can achieve the equivalent of 35 air changes per hour, and far-UVC has the potential to reach well over 100.</span></p><p><span>Despite this, both ventilation and filtration need to be kept in mind as new buildings replace the old. If nothing else, ventilation design is an important </span><a href="https://www.sciencedirect.com/science/article/abs/pii/S0021850202001179" rel="">factor</a><span> in determining the effectiveness of UV systems; how well air is mixed and how quickly it moves </span><a href="https://www.sciencedirect.com/science/article/pii/S2210670722003663?casa_token=I1CkXXNQmOMAAAAA:ZM2DxrbHI07-zr9Ssqg2LwdcKWFNxncDpbtKiNw8LNx6I4BSlAbSncOlrGnEc7rxEnwEWlDxAQ" rel="">affects the degree</a><span> to which pathogens are exposed to UV light. These interactions have a </span><a href="https://www.sciencedirect.com/science/article/pii/S0360132324009508?casa_token=k-801HeYWfsAAAAA:2rhPctBjo0IcwqPYJSDiAdBfH_lMZrQCWib4Y6mdoaE7gkv4Je3CQWILrkubjA08bbPbEccHpw#sec3" rel="">positive or negative</a><span> effect on pathogen removal. We flush and filter water, but we also disinfect it to eliminate remaining microbes. Air should be treated no differently.</span></p><p>Far-UVC is like an aerial disinfectant or bleach, except that it is harmless to humans at practical germicidal doses, and thus should not provoke resistance to its uptake. It does not alter pathogens in a way that allows resistance to emerge, a serious problem for antibiotics. Instead, it thoroughly damages microbial genomes at random, destroying bacteria and viruses alike, whether they are drug-resistant, vaccine-evasive, or indeed newly emerged.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!IQbl!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!IQbl!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 424w, https://substackcdn.com/image/fetch/$s_!IQbl!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 848w, https://substackcdn.com/image/fetch/$s_!IQbl!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 1272w, https://substackcdn.com/image/fetch/$s_!IQbl!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!IQbl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png" width="1024" height="654" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:654,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!IQbl!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 424w, https://substackcdn.com/image/fetch/$s_!IQbl!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 848w, https://substackcdn.com/image/fetch/$s_!IQbl!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 1272w, https://substackcdn.com/image/fetch/$s_!IQbl!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb69e24cc-4ea8-49a7-a4b5-dd8f75969d10_1024x654.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The most widely used commercial far-UVC source is a krypton-chloride excimer lamp. ‘Excimer’ is a contraction of ‘excited dimer’,</span><strong> </strong><span>a short-lived, high-energy molecule formed when the krypton and chlorine temporarily bond in an excited state as an electric current is passed through the gas mixture.</span></p><p>Krypton chloride lamps emit mostly 222-nanometer light, produced by the excited dimer decaying to its ground state and releasing the excess energy as a photon. Light at this wavelength is safe for human eyes and skin at doses that efficiently kill germs, but about 10–20 percent of the output consists of longer wavelengths with much lower maximum exposures. To use the lamps in occupied spaces, a filter with multiple layers of quartz and hafnium oxide is used to reflect unwanted wavelengths while allowing 222-nanometer light through.</p><p>Despite its potential, far-UVC has yet to achieve widespread use.</p><p>The very best krypton chloride emitters on the market are reliable, long-lasting, powerful, use little energy, and come with effective optical filters. But the state of the art is not representative. The krypton-chloride lamp industry is plagued by low-quality products with short lifespans that may not even produce any far-UVC light, and could even emit dangerous longer wavelengths. There is no product standard certification for UV lamps.</p><p><span>Top-tier excimer lamps, from reputable manufacturers, are expensive. This is partly due to their inherent complexity but largely from sluggish demand. The key reason is that, notwithstanding their successes in the 1930s, a </span><a href="https://www.worksinprogress.news/p/flipping-the-switch-on-far-uvc" rel="">certification vacuum denies buyers an authoritative seal of efficacy</a><span>.</span></p><p><span>In part, this is because some of the studies establishing far-UVC’s efficacy aren’t as definitive as they need to be to really move the dial. </span><a href="https://www.youtube.com/watch?v=MefmQL0fY3o" rel="">One study</a><span> on the impact of germicidal UV installations on tuberculosis transmission in homeless shelters was unsuccessful when the national rate of tuberculosis declined, which meant that the study ended up being too small to detect an effect even in principle.</span></p><p><a href="https://www.youtube.com/watch?v=MefmQL0fY3o" rel="">In another study</a><span>, germicidal UV was installed in hospitals to assess the impact of germicidal UV on flu transmission, but during the course of that study, the hospitals stopped routine flu testing. In a </span><a href="https://www.youtube.com/watch?v=uadVLEAfjt8" rel="">classroom study</a><span>, not all classrooms had enough electrical sockets to plug in the portable air cleaners required for the study, some teachers turned off the air filters because they were too loud, and some schools didn’t install the germicidal UV devices they were supposed to because there were no legal protections for them for doing so.</span></p><p><span>But there are many other factors as well. Measuring infection control is challenging and seldom undertaken, particularly in public spaces. Epidemiological data is expensive and difficult to gather, and there is currently no way to measure the amount of viable, infectious pathogens in the air in real time. Office attendance can be tracked, but controlling for how users mix outside the office space is immensely difficult, and measuring the real-world effect of small-scale deployments in public areas is almost impossible. Studies aiming to cause deliberate disease transmission in controlled environments have </span><a href="https://pubmed.ncbi.nlm.nih.gov/32658939/" rel="">failed to work</a><span> in </span><a href="https://www.medrxiv.org/content/10.1101/2025.04.28.25326458v1.full" rel="">practice</a><span> because they have been too small to generate enough infections.</span></p><p>Pathogen-free air and the research that goes into getting it are both, to some extent, public goods: the beneficiaries will mostly be people who haven’t paid for them. Even if a business reduces pathogens in its offices’ air, the biggest upside goes to other people who share spaces with its employees. This could be commuters on the same train, people in shops, or parents whose children attend the same school.</p><p>Despite the lack of clear economic upside, we are already seeing some early adoption among respected institutions: Mount Sinai Hospital, for example, has far-UVC lamps installed in its Cohen Center for Recovery from Complex Chronic Illnesses. Ideally, others would emulate this example, creating a stronger basis for research.</p><p>If one part of the knot were cut, then one of the most promising disease-fighting technologies of our time could finally be employed en masse.</p><p>In the early 1900s, a public health official in Jersey City, John Leal, lost his father to illness likely caused by contaminated drinking water.</p><p>But Leal had an opportunity to prevent such a loss for others: he quietly directed the addition of chlorine to the drinking water supply in Jersey City, hiring engineer George Fuller to design and build a system for dripping a diluted bleach solution into Boonton Reservoir. He believed that this common household bleach agent could kill pathogens without harming people. He was right.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!JsZN!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!JsZN!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 424w, https://substackcdn.com/image/fetch/$s_!JsZN!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 848w, https://substackcdn.com/image/fetch/$s_!JsZN!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 1272w, https://substackcdn.com/image/fetch/$s_!JsZN!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!JsZN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png" width="1024" height="654" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:654,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!JsZN!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 424w, https://substackcdn.com/image/fetch/$s_!JsZN!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 848w, https://substackcdn.com/image/fetch/$s_!JsZN!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 1272w, https://substackcdn.com/image/fetch/$s_!JsZN!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F62d245ee-227e-4b5f-a851-75552dafe198_1024x654.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Beyond being a triumph of science, water sanitation led to a fundamental shift in public expectations. Once people saw that clean water was possible, they demanded it.</p><p>Twentieth-century water treatment programs transformed public health by virtually eliminating waterborne diseases. Ventilation, filtration and disinfection provide us with the opportunity to dramatically reduce the burden of airborne illnesses. Tuberculosis and coronaviruses would join typhoid and cholera as tragedies of the past, and seasonal flu and common colds would become rare rather than routine if clean air were as universal and expected as clean water.</p><p><em>Gavriel Kleinwaks is program director for indoor air quality at 1Day Sooner.</em></p><p><em>Karam Elabd is a researcher and writer.</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disney reinstates Jimmy Kimmel after backlash over capitulation to FCC (197 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2025/09/disney-abc-reinstate-jimmy-kimmel-amid-uproar-over-government-censorship/</link>
            <guid>45339428</guid>
            <pubDate>Mon, 22 Sep 2025 21:05:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2025/09/disney-abc-reinstate-jimmy-kimmel-amid-uproar-over-government-censorship/">https://arstechnica.com/tech-policy/2025/09/disney-abc-reinstate-jimmy-kimmel-amid-uproar-over-government-censorship/</a>, See on <a href="https://news.ycombinator.com/item?id=45339428">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Station owners can still block Kimmel show</h2>
<p>Apparently buoyed by Disney caving to his demand to "take action" against Kimmel, Carr went on to <a href="https://arstechnica.com/tech-policy/2025/09/after-getting-jimmy-kimmel-suspended-fcc-chair-threatens-abcs-the-view/">make threats</a> regarding ABC's <em>The View</em> and NBC late-night hosts Seth Meyers and Jimmy Fallon. Carr's threats were criticized by Democratic lawmakers en masse, and a couple of prominent Republicans <a href="https://arstechnica.com/tech-policy/2025/09/rand-paul-fcc-chair-had-no-business-intervening-in-abc-kimmel-controversy/">sided against him</a>. Sen. Rand Paul (R-Ky.) said that "Brendan Carr has got no business weighing in on this," while Sen. Ted Cruz (R-Texas) said that Carr's threat to ABC was "right outta <em>Goodfellas</em>."</p>
<p>Disney reinstating Kimmel doesn't necessarily mean his show will immediately appear on all ABC-affiliated networks. Conservative broadcaster Sinclair <a href="https://sbgi.net/sinclair-says-kimmel-suspension-is-not-enough-calls-on-fcc-and-abc-to-take-additional-action/">said last week</a> that "regardless of ABC's plans for the future of the program, Sinclair intends not to return <em>Jimmy Kimmel Live!</em> to our air until we are confident that appropriate steps have been taken to uphold the standards expected of a national broadcast platform."</p>
<p>Station owner Nexstar helped pressure Disney into suspending Kimmel's show last week when it <a href="https://www.nexstar.tv/nexstar-abc-affiliates-to-preempt-jimmy-kimmel-live-indefinitely-beginning-tonight/">announced</a> its ABC-affiliated stations would not air the show "for the foreseeable future."</p>
<p>Part of Carr's strategy was to urge station owners to demand that Kimmel be taken off the air. "The individual licensed stations that are taking their content, it's time for them to step up and say this garbage isn't something that we think serves the needs of our local communities," Carr said.</p>
<p>The pressure from broadcasters came at a time when both <a href="https://variety.com/2025/tv/news/broadcaster-fcc-abolish-national-tv-ownership-rule-1236496159/">Nexstar</a> and <a href="https://www.bloomberg.com/news/articles/2025-04-23/doj-probes-disney-fubo-deal-over-competition-concerns">Disney</a> are seeking Trump administration approval for mergers. Anna Gomez, the one Democrat on the Republican-majority FCC, said that companies seeking merger approvals are "vulnerable to pressure to bend to the government's ideological demands."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Umberto Eco: Ur-Fascism (106 pts)]]></title>
            <link>https://bobmschwartz.com/2017/12/28/umberto-eco-ur-fascism/</link>
            <guid>45338990</guid>
            <pubDate>Mon, 22 Sep 2025 20:25:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bobmschwartz.com/2017/12/28/umberto-eco-ur-fascism/">https://bobmschwartz.com/2017/12/28/umberto-eco-ur-fascism/</a>, See on <a href="https://news.ycombinator.com/item?id=45338990">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p>Celebrated Italian author and scholar <a href="http://amzn.to/2loibAd">Umberto Eco</a> (1932-2016)&nbsp; published an article in 1995 entitled <a href="http://www.nybooks.com/articles/1995/06/22/ur-fascism/">Ur-Fascism</a> .</p>
<p>Eco grew up during the time of Mussolini. In the article, he jumps from memories of that experience to describe some varieties of fascism and other types of totalitarianism. Not all are well-defined fascism, he says, but he does identify the core characteristics of what he calls Ur-Fascism.</p>
<p>I think it is possible to outline a list of features that are typical of what I would like to call Ur-Fascism, or Eternal Fascism. These features cannot be organized into a system; many of them contradict each other, and are also typical of other kinds of despotism or fanaticism. But it is enough that one of them be present to allow fascism to coagulate around it.</p>
<p>Eco goes on to list 14 features of Ur-Fascism. This is the excerpted list; please read the article for an expanded explanation. And as you read it, please consider which of those features you might be seeing now.</p>
<p>1. The first feature of Ur-Fascism is the cult of tradition….As a consequence, there can be no advancement of learning.</p>
<p>2. Traditionalism implies the rejection of modernism….In this sense Ur-Fascism can be defined as irrationalism.</p>
<p>3. Irrationalism also depends on the cult of action for action’s sake. Action being beautiful in itself, it must be taken before, or without, any previous reflection.</p>
<p>4. No syncretistic faith can withstand analytical criticism. The critical spirit makes distinctions, and to distinguish is a sign of modernism.</p>
<p>5. Besides, disagreement is a sign of diversity. Ur-Fascism grows up and seeks for consensus by exploiting and exacerbating the natural fear of difference.</p>
<p>6. Ur-Fascism derives from individual or social frustration. That is why one of the most typical features of the historical fascism was the appeal to a frustrated middle class, a class suffering from an economic crisis or feelings of political humiliation, and frightened by the pressure of lower social groups.</p>
<p>7. To people who feel deprived of a clear social identity, Ur-Fascism says that their only privilege is the most common one, to be born in the same country. This is the origin of nationalism.</p>
<p>8. The followers must feel humiliated by the ostentatious wealth and force of their enemies….Thus, by a continuous shifting of rhetorical focus, the enemies are at the same time too strong and too weak.</p>
<p>9. For Ur-Fascism there is no struggle for life but, rather, life is lived for struggle.</p>
<p>10. Elitism is a typical aspect of any reactionary ideology, insofar as it is fundamentally aristocratic, and aristocratic and militaristic elitism cruelly implies contempt for the weak. Ur-Fascism can only advocate a popular elitism.</p>
<p>11. In such a perspective everybody is educated to become a hero. In every mythology the hero is an exceptional being, but in Ur-Fascist ideology, heroism is the norm.</p>
<p>12. Since both permanent war and heroism are difficult games to play, the Ur-Fascist transfers his will to power to sexual matters. This is the origin of machismo (which implies both disdain for women and intolerance and condemnation of nonstandard sexual habits, from chastity to homosexuality). Since even sex is a difficult game to play, the Ur-Fascist hero tends to play with weapons—doing so becomes an ersatz phallic exercise.</p>
<p>13. Ur-Fascism is based upon a selective populism, a qualitative populism, one might say. In a democracy, the citizens have individual rights, but the citizens in their entirety have a political impact only from a quantitative point of view—one follows the decisions of the majority. For Ur-Fascism, however, individuals as individuals have no rights, and the People is conceived as a quality, a monolithic entity expressing the Common Will. Since no large quantity of human beings can have a common will, the Leader pretends to be their interpreter….Because of its qualitative populism Ur-Fascism must be against “rotten” parliamentary governments.</p>
<p>14. Ur-Fascism speaks Newspeak.</p>
<p>Eco closes with this:</p>
<p>Ur-Fascism is still around us, sometimes in plainclothes. It would be so much easier, for us, if there appeared on the world scene somebody saying, “I want to reopen Auschwitz, I want the Black Shirts to parade again in the Italian squares.” Life is not that simple. Ur-Fascism can come back under the most innocent of disguises. Our duty is to uncover it and to point our finger at any of its new instances—every day, in every part of the world.</p>
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Rand Paul: FCC chair had "no business" intervening in ABC/Kimmel controversy (121 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2025/09/rand-paul-fcc-chair-had-no-business-intervening-in-abc-kimmel-controversy/</link>
            <guid>45338798</guid>
            <pubDate>Mon, 22 Sep 2025 20:09:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2025/09/rand-paul-fcc-chair-had-no-business-intervening-in-abc-kimmel-controversy/">https://arstechnica.com/tech-policy/2025/09/rand-paul-fcc-chair-had-no-business-intervening-in-abc-kimmel-controversy/</a>, See on <a href="https://news.ycombinator.com/item?id=45338798">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Democratic lawmakers have criticized Carr en masse, saying he abused his power in order to censor speech. Not many Republican lawmakers have done so, but Carr did take heat from Sen. Ted Cruz (R-Texas), who chairs the Senate Commerce Committee that has oversight over the FCC.</p>
<p>On <a href="https://www.youtube.com/watch?v=l6KYixCBTJc">his podcast</a> Friday, Cruz discussed the Carr comment in which the FCC chair said of ABC, "We can do this the easy way or the hard way. These companies can find ways to change conduct, to take action, frankly on Kimmel, or there's going to be additional work for the FCC ahead."</p>
<p>"[Carr] says, 'We can do this the easy way or we can do this the hard way.' And I gotta say, that's right outta <em>Goodfellas</em>, that's right out of a mafioso coming into a bar going, 'Nice bar you have here, it'd be a shame if something happened to it,'" Cruz said.</p>

<h2>Cruz: Resist urge to censor opponents</h2>
<p>Cruz said he is "thrilled" that Kimmel was suspended, noting that "Jimmy Kimmel has mocked me so many times I cannot count." But Cruz said that using the government to dictate what the media can say "will end up bad for conservatives," and that what Carr said is "dangerous as hell." In a J.R.R. Tolkien reference, Cruz compared the power of government to the power and allure of Sauron's One Ring.</p>
<p>"It reminds me of like the Ring of Power," Cruz said. "It is so attractive, it is sort of like conservatives saying, 'Wait, if we have government, we have power. We can ban the media.' Let me tell you what will happen. Going down this road, there will come a time when a Democrat wins again, wins the White House. They will silence us, they will use this power, and they will use it ruthlessly."</p>
<p>The Kimmel controversy is over a monologue in which he said, "We hit some new lows over the weekend with the MAGA gang desperately trying to characterize this kid who murdered Charlie Kirk as anything other than one of them and with everything they can to score political points from it."</p>

          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Choose Your Own Adventure (148 pts)]]></title>
            <link>https://www.filfre.net/2025/09/choose-your-own-adventure/</link>
            <guid>45337450</guid>
            <pubDate>Mon, 22 Sep 2025 18:22:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.filfre.net/2025/09/choose-your-own-adventure/">https://www.filfre.net/2025/09/choose-your-own-adventure/</a>, See on <a href="https://news.ycombinator.com/item?id=45337450">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><em>In 1999, after twenty years and many tens of millions of books sold,<span><a role="button" tabindex="0" onclick="footnote_moveToReference_6462_1('footnote_plugin_reference_6462_1_1');" onkeypress="footnote_moveToReference_6462_1('footnote_plugin_reference_6462_1_1');"><sup id="footnote_plugin_tooltip_6462_1_1">[1]</sup></a><span id="footnote_plugin_tooltip_text_6462_1_1">A truly incredible figure of 250 million copies sold is frequently cited for the original <em>Choose Your Own Adventure</em> series today, apparently on the basis of a statement released in January of 2007 by Choosco, a company which has repeatedly attempted to reboot the series in the post-millennial era. Based upon the running tally of sales which appeared in <em>Publishers Weekly</em> during the books’ 1980s heyday, I struggle to see how this figure can be correct. That journal of record reported 34 million <em>Choose Your Own Adventure</em> books sold in North America as of December 1, 1989. By that time, the series’s best years as a commercial proposition were already behind it. Even when factoring in international sales, which were definitely considerable, it is difficult to see how the total figure could have exceeded 100 million books sold at the outside. Having said that, however, the fact remains that the series sold an awful lot of books by any standard.</span></span></em><em> Bantam Books announced that it would no longer be publishing its Choose Your Own Adventure line of children’s paperbacks. So, since these histories currently find themselves in 1999, this seems like a good time to look back on one of the formative influences upon the computer games I’ve been covering for so many years now, as well as upon the people who played them — not least, yours truly. Or maybe that’s just an excuse for me to finally write an article I should have written a long time ago. Either way, I hope you don’t mind if I step out of the chronology today and <a href="https://www.youtube.com/watch?v=gQMYiTYGpXk">take you way, way back</a>, to steal a phrase from Van Morrison.</em></p><div>
<hr>


<blockquote><p>These books were the gateway drugs of interactive entertainment.</p>
<p>— Choose Your Own Adventure historian Christian Swineheart</p>
</blockquote>
<p>My first experience with interactive media wasn’t mediated by any sort of digital technology. Instead it came courtesy of a “technology” that was already more than half a millennium old at the time: the printed book.</p>
<p>In the fall of 1980, I was eight years old, and doing my childish best to adjust to life in a suburb of Dallas, Texas, where my family had moved the previous summer from the vicinity of Youngstown, Ohio. I was a skinny, frail kid who wasn’t very good at throwing balls or throwing punches, which did nothing to ease the transition. Even when I wasn’t being actively picked on, I was bewildered at my new classmates’ turns of phrase (“I reckon,” “y’all,” “I’m fixin’ to”) that I had previously heard only in the John Wayne movies I watched on my dad’s knee. In their eyes, my birthplace north of the Mason Dixon Line meant that I could be dismissed as just another clueless, borderline useless “Yankee,” a heathen in the eyes of those who adhered to my new state’s twin religions of Baptist Christianity and Friday-night football.</p>
<p>I found my refuge in my imagination. I was interested in just about everything — a trait I’ve never lost, both to my benefit and my detriment in life — and I could sit for long periods of time in my room, spinning out fantasies in my head about school lessons, about books I’d read, about television shows I’d seen, even about songs I’d heard on the radio. I actually framed this as a distinct activity in my mind: “I’m going to go imagine now.” If nothing else, it was good training for becoming a writer. As they say, the child is the father of the man.</p>
<p>One Friday afternoon, I discovered a slim, well-thumbed volume in my elementary school’s scanty library. Above the title <a href="https://gamebooks.org/Item/518/Show"><em>The Cave of Time</em></a> was the now-iconic&nbsp;<em>Choose Your Own Adventure</em> masthead, proclaiming it to be the first book in a series. Curious as always, I opened it to the first page. I was precocious enough to know what was meant by a first-person and third-person narrator of written fiction, but this was something else: this book was written in the <em>second</em> person.</p>
<blockquote><p>You’ve hiked through Snake Canyon once before while visiting your Uncle Howard at Red Creek Ranch, but you never noticed any cave entrance. It looks as though a recent rock slide has uncovered it.</p>
<p>Though the late afternoon sun is striking the surface of the cave, the interior remains in total darkness. You step inside a few feet, trying to get an idea of how big it is. As your eyes become used to the dark, you see what looks like a tunnel ahead, dimly lit by some kind of phosphorescent material on its walls. The tunnel walls are smooth, as if they were shaped by running water. After twenty feet or so, the tunnel curves. You wonder where it leads. You venture in a bit further, but you feel nervous being alone in such a strange place. You turn and hurry out.</p>
<p>A thunderstorm may be coming, judging by how dark it looks outside. Suddenly you realize the sun has long since set, and the landscape is lit only by the pale light of the full moon. You must have fallen asleep and woken up hours later. But then you remember something even more strange. Just last evening, the moon was only a slim crescent in the sky.</p>
<p>You wonder how long you’ve been in the cave. You are not hungry. You don’t feel you have been sleeping. You wonder whether to try to walk back home by moonlight or whether to wait for dawn, rather than risk your footing on the steep and rocky trail.</p></blockquote>
<p>All of this was intriguing enough already for a kid like me, but now came the kicker. The book asked me — asked <em>me</em>!! — whether I wanted to “start back home” (“turn to page 4”) or to “wait” (“turn to page 5”). This was the book I had never known I needed, a vehicle for the imagination like no other.</p>
<p>I took&nbsp;<em>The Cave of Time</em> home and devoured it that weekend. Through the simple expedient of flipping through its pages, I time-traveled to the age of dinosaurs, to the Battle of Gettysburg, to London during the Blitz, to the building of <a href="https://analog-antiquarian.net/2021/12/17/introduction-walls-walls-and-yet-again-walls/">the Great Wall of China</a>, to <a href="https://www.filfre.net/2022/09/titanic-visions-part-1-sifting-through-the-wreckage">the <em>Titanic</em></a> and the Ice Age and <a href="https://analog-antiquarian.net/2023/03/30/chapter-1-a-dawning-age-of-faith/">the Middle Ages</a>. Much of this history was entirely new to me, igniting whole new avenues of interest. Today, it’s all too easy to see all of the limitations and infelicities of <em>The Cave of Time</em> and its successors: a book of 115 pages that had, as it proudly trumpeted on the cover, 40 possible endings meant that the sum total of any given adventure wasn’t likely to span more than about three choices if you were lucky. But to a lonely, hyper-imaginative eight-year-old, none of that mattered. I was well and truly smitten, not so much by what the book was as by what I wished it to be, by what I was able to turn it into in my mind by the sheer intensity of that wish.</p>
<p>I remained a devoted&nbsp;<em>Choose Your Own Adventure</em> reader for the next couple of years. Back in those days, each book could be had for just $1.25, well within reach of a young boy’s allowance even at a time when a dollar was worth a lot more than it is today. Each volume had some archetypal-feeling adventurous theme that made it catnip for a kid who was also discovering Jules Verne and beginning to flirt with golden-age science fiction (the golden age being, of course, age twelve): <a href="https://gamebooks.org/Item/163/Show">deep-sea diving</a>, <a href="https://gamebooks.org/Item/563/Show">a journey by hot-air balloon</a>, <a href="https://gamebooks.org/Item/333/Show">the Wild West</a>, <a href="https://gamebooks.org/Item/552/Show">a cross-country auto race</a>, <a href="https://gamebooks.org/Item/551/Show">the Egyptian pyramids</a>, <a href="https://gamebooks.org/Item/553/Show">a hunt for the Abominable Snowman</a>. What they evoked in me was as important as what was actually printed on the page; each was a springboard for another weekend of fantasizing about exotic undertakings where nobody mocked you because you had two left feet in gym class and spoke with a stubbornly persistent Northern accent. And each was a springboard for learning as well; this process usually started with pestering my parents, and then, if I didn’t get everything I needed from that source, ended with me turning to the family set of <em>Encyclopedia Britannica</em> in the study. (I remember how when reading <em>Journey Under the Sea</em> I was confused by frequent references to “the bends.” I asked my mom what that meant, and, bless her heart, she said she thought the bends were diarrhea. Needless to say, this put a whole new spin on my underwater exploits until I finally did a bit of my own research about diving.)</p>
<p>Inevitably, I did begin to see the limitations of the format in time — right about the time that some of my nerdier classmates, whom I had by now managed to connect with, started to show me a tabletop game called <a href="https://www.filfre.net/2011/07/dungeons-and-dragons"><em>Dungeons &amp; Dragons</em></a>.&nbsp;<em>Choose Your Own Adventure</em> had primed me to understand and respond to it right away; it would be no exaggeration to say that I saw this game that would remake so much of the entertainment landscape in its image as simply a <em>better</em>, less constrained take on the same core concept. Ditto the computer games that I began to notice in a corner of the bookstore I haunted circa 1984. When <a href="https://www.filfre.net/tag/infocom/?order=asc">Infocom</a> promised me that playing one of their games meant “waking up inside a story,” I knew exactly what they must mean: <em>Choose Your Own Adventure</em> done&nbsp;<em>right</em>. For the Christmas of 1984, I convinced my parents to buy me a disk drive for the <a href="https://www.filfre.net/2012/12/the-commodore-64">Commodore 64</a> they had bought me the year before. And so the die was cast. If <em>Choose Your Own Adventure</em> hadn’t come along, I don’t think that I would be the Digital Antiquarian today.</p>
<p>But since I am the Digital Antiquarian, I have my usual array of questions to ask. Where did <em>Choose Your Own Adventure</em>, that gateway drug for the first generation to be raised on interactive media, come from? Who was responsible for it? The most obvious answer is the authors Edward Packard and R.A. Montgomery, one or the other of whose name could be seen on most of the early books in the series. But two authors alone do not a cultural phenomenon make.</p>
<hr>

<blockquote><p>“Will you read me a story?”</p>
<p>“Read you a story? What fun would that be? I’ve got a better idea: let’s tell a story together.”</p>
<p>— Adam Cadre, <a href="https://www.filfre.net/2024/11/retro-no-more-interactive-fiction-of-the-early-comp-era">Photopia</a></p>
</blockquote>
<p>During the twentieth century, when print still ruled the roost, the hidden hands behind the American cultural zeitgeist were the agents, editors, and marketers in and around the big Manhattan publishing houses, who decided which books were worth publishing and promoting, who decided what they would look like and even to a large extent how they would read. No one outside of the insular world of print publishing knew these people’s names, but the power they had to shape hearts and minds was enormous — arguably more so than that of any of the writers they served. After all, even the most prolific author of fiction or non-fiction usually couldn’t turn out more than one book per year, whereas an agent or editor could quietly, anonymously leave her fingerprints on dozens. Amy Berkower, a name I’m pretty sure you’ve never heard of, is a fine case in point.</p>
<p>Berkower joined Writers House, one of the most prestigious of the New York literary agencies, during the mid-1970s as a “secretarial girl.” Having shown herself to be an enthusiastic go-getter by working long hours and sitting in on countless meetings, she was promoted to the role of agent in 1977, but assigned to “juvenile publishing,” largely because nobody else in the organization wanted to work with such non-prestigious books. Yet the assignment suited Berkower just fine. “As a kid, I read and loved Nancy Drew before I went on to Camus,” she says. “I was in the right place at the right time. I didn’t have the bias that juvenile series wouldn’t lead to Camus.”</p>
<p>Thus when a fellow named Ray Montgomery came to her with a unique concept he called&nbsp;<em>Adventures of You</em>, he found a receptive audience. Montgomery was the co-owner of a small press called Vermont Crossroads, far removed from the glitz and glamor of Manhattan. Crossroads’s typical fare was esoteric volumes like <em>Hemingway in Michigan</em> and&nbsp;<em>The Male Nude in Photography</em> that generally weren’t expected to break four digits in total unit sales. A few years earlier, however, Montgomery had himself been approached by Edward Packard, a lawyer by trade who had already pitched a multiple-choice children’s book called <em>Sugarcane Island</em> to what felt like every other publisher in the country without success.</p>
<p>As he would find himself relating again and again to curious journalists in the decades to come, Packard had come up with his idea for an interactive book by making a virtue of necessity. During the 1960s, he was an up-and-coming attorney who worked long days in Manhattan, to which he commuted by train from his and his wife’s home in Greenwich, Connecticut. He often arrived home in the evening just in time to put his two daughters to bed. They liked to be told a bedtime story, but Packard was usually so exhausted that he had trouble coming up with one. So, he slyly enlisted his daughters’ help with the creative process. He would feed them a little bit of a story in which <em>they</em> were the stars, then ask them what they wanted to do next. Their answers would jog his tired imagination, and he would be off and running once again.</p>
<p>Sometimes, though, the girls would each want to do something different. “What would happen if you wrote both endings?” Packard mused to himself. A long-time frustrated writer as well as a self-described “lawyer who was never comfortable with the law,” Packard began to wonder whether he could turn his interactive bedtime stories into a new kind of book. By as early as 1969, he had invented the classic <em>Choose Your Own Adventure</em> format — turn to this page to do this, turn to that page to do that — and produced his first finished work in the style: the aforementioned <em>Sugarcane Island</em>, about a youngster who gets swept off the deck of a scientific research vessel by a sudden tidal wave and washed ashore on a mysterious Pacific island that has monsters, pirates, sharks, headhunters, and many another staple of more traditional children’s adventure fiction to contend with.</p>
<p>He was sure that it was “such a wonderful idea, I’d immediately find a big publisher.” He signed on with an agent, who “said he would be surprised if there were no takers,” recalls Packard. “Then he proceeded to be surprised.” One rejection letter stated that “it’s hard enough to get children to read, and you’re just making it harder with all these choices.” Letters like that came over and over again, over a period of years.</p>
<p>By 1975, Edward Packard was divorced from both his agent and his wife. With his daughters no longer of an age to beg for bedtime stories, he had just about resigned himself to being a lawyer forever. Then, whilst flipping through an issue of <em>Vermont Life</em> during a stay at a ski lodge, he happened upon a small advertisement from Crossroads Press. “Authors Wanted,” it read. Crossroads wasn’t the bright-lights, big-city publisher Packard had once dreamed of, but on a lark he sent a copy of <em>Sugarcane Island</em> to the address in the magazine.</p>
<p>It arrived on the desk of Ray Montgomery, who was instantly intrigued. “I Xeroxed 50 copies of Ed’s manuscript and took it to a reading teacher in Stowe,” Montgomery told <em>The New York Times</em> in 1981. “His kids — third grade through junior high — couldn’t get enough of it.” Satisfied by that proof of concept, Montgomery agreed to publish the book. Crossroads Press sold 8000 copies of&nbsp;<em>Sugarcane Island</em> over the next couple of years, a figure that was “unbelievable” by their modest standards. Montgomery was inspired to pen a book of his own in the same style, which he called&nbsp;<em>Journey Under the Sea</em>. The budding series was given the name&nbsp;<em>Adventures of You</em> — a proof that, whatever else they may have had going for them, branding was not really Crossroads Press’s strength.</p>
<p><a href="https://www.filfre.net/2025/09/choose-your-own-adventure/sugarcane/" rel="attachment wp-att-6468"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2025/08/sugarcane-203x300.jpg" alt="" width="304" height="450" srcset="https://www.filfre.net/wp-content/uploads/2025/08/sugarcane-203x300.jpg 203w, https://www.filfre.net/wp-content/uploads/2025/08/sugarcane.jpg 540w" sizes="(max-width: 304px) 100vw, 304px"></a></p>
<p>Indeed, Montgomery himself was well able to see that he had stumbled over a concept that was too big for his little press. He sent the two extant books to Amy Berkower at Writers House and asked her what she thought. Having grown up on Nancy Drew, she was inclined to judge them less on their individual merits than on their prospects as a franchise in the making. A concept this new, she judged, had to have a strong brand of its own in order for children to get used to it. It would take her some time to find a publisher who agreed with her.</p>
<p>In the meantime, Edward Packard, heartened by the relative success of <em>Sugarcane Island</em>, was writing more interactive books. Although their names were destined to be indelibly linked in the annals of pop-culture history, Packard and Montgomery would never really be friends; they would always have a somewhat prickly, contentious relationship with one another. In an early signal of this, Packard chose not to publish more books through Crossroads. Instead he convinced the mid-list Philadelphia-based publisher J.B. Lippincott to take on <em>Deadwood City</em>, a Western, and&nbsp;<a href="https://gamebooks.org/Item/332/Show"><em>Third Planet from Altair</em></a>, a sci-fi tale. These served ironically to confirm Amy Berkower’s belief that there needed to be a concerted push behind the concept as a branded series; released with no fanfare whatsoever, neither sold all that well. Yet Lippincott did do Packard one brilliant service. Above the titles on the covers of the books, it placed the words “Choose your own adventures in the Wild West!” and “Choose your own adventures in outer space!” There was a brand in the offing in those phrases, even if Lippincott didn’t realize it.</p>
<p><a href="https://www.filfre.net/2025/09/choose-your-own-adventure/deadwoodpb/" rel="attachment wp-att-6469"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2025/08/deadwoodpb-195x300.jpg" alt="" width="293" height="450" srcset="https://www.filfre.net/wp-content/uploads/2025/08/deadwoodpb-195x300.jpg 195w, https://www.filfre.net/wp-content/uploads/2025/08/deadwoodpb-667x1024.jpg 667w, https://www.filfre.net/wp-content/uploads/2025/08/deadwoodpb-768x1180.jpg 768w, https://www.filfre.net/wp-content/uploads/2025/08/deadwoodpb.jpg 778w" sizes="(max-width: 293px) 100vw, 293px"></a></p>
<p>For her part, Berkower was now more convinced than ever that this book-by-book approach was the wrong one. There needed to be <em>a lot</em> of these books, quickly, in order for them to take off properly. She made the rounds of the big publishing houses one more time. She finally found the ally she was looking for in Joëlle Delbourgo at Bantam Books. Delbourgo recalls getting “really excited” by the concept: “I said, ‘Amy, this is revolutionary.’ This is pre-computer, remember. The idea of interactive fiction, choosing an ending, was fresh and novel. It tapped into something very fundamental. I remember how I felt when I read the books, and how excited I got, the clarity I had about them.”</p>
<p>Seeing eye to eye on what needed to be done to cement the concept in the minds of the nation’s children, the two women drew up a contract under whose terms Bantam would publish an initial order of no fewer than six books in two slates of three. They would appear under a distinctive series trade dress, with each volume numbered to feed young readers’ collecting instinct. Barbara Marcus, Bantam’s marketing director for children’s books, needed only slightly modify the phrases deployed by J.B. Lippincott to create the perfect, pithy, and as-yet un-trademarked name for the series: <em>Choose Your Own Adventure</em>.</p>
<p>Berkower was acting as the agent of Montgomery alone up to this point. There are conflicting reports as to how and why Packard was brought into the fold. The widow of Ray Montgomery, who died in 2014, told <em>The New Yorker</em> in 2022 that her husband’s innate sense of fair play, plus the need to provide a lot of books quickly, prompted him to voluntarily bring Packard on as an equal partner. Edward Packard told the same magazine that it was Bantam who insisted that he be included, possibly in order to head off potential legal problems in the future.</p>
<p>At any rate, the first three <em>Choose Your Own Adventure</em> paperbacks arrived in bookstores in July of 1979. They were <em>The Cave of Time</em>, a new effort by Packard, written with some assistance from his daughter Andrea, she for whom he had first begun to tell his interactive stories; Montgomery’s journeyman <em>Journey Under the Sea</em>; and&nbsp;<em>By Balloon to the Sahara</em>, which Packard and Montgomery had subcontracted out to Douglas Terman, normally an author of adult military thrillers. Faced with an advertising budget that was almost nonexistent, Barbara Marcus devised an unusual grass-roots marketing strategy: “We did absolutely nothing except give the books away. We gave thousands of books to our salesmen and told them to give five to each bookseller and tell him to give them to the first five kids into his shop.”</p>
<p>The series sold itself, just as Marcus had believed it would. As <em>The New York Times</em> would soon write with a mixture of bemusement and condescension, it proved “contagious as chickenpox.” By September of 1980, around the time that I first discovered <em>The Cave of Time</em>,&nbsp;<em>Publishers Weekly</em> could report that <em>Choose Your Own Adventure</em> had become a “bonanza” for Bantam, which had sold more than 1 million copies of the first six volumes, with Packard and Montgomery now contracted to provide many more. A year later, eleven books in all had come out and the total sold was 4 million, with the series accounting for eight of the 25 bestselling children’s books at B. Dalton’s, the nation’s largest bookstore chain. A year after that, 10 million copies had been sold. By decade’s end, the total domestic sales of <em>Choose Your Own Adventure</em> would reach 34 million copies, with possibly that many or more again having been sold internationally after being translated into dozens of languages. The series was approaching its hundredth numbered volume by that point. It was a few years past its commercial peak already, but would continue on for another decade, until 184 volumes in all had come out.</p>
<p>Edward Packard, who turned 50 in 1981, could finally call himself an author rather than a lawyer by trade — and an astonishingly successful author at that, if not one who was likely to be given any awards by the literary elite. He and Ray Montgomery alone wrote about half of the 184 <em>Choose Your Own Adventure</em> installments. Packard’s prose was consistently solid and evocative without ever feeling like he was writing down to his audience, as the extract from <em>The Cave of Time</em> near the beginning of this article will attest; not all authors of children’s books, then or now, would dare to use a word like “phosphorescent.” If Montgomery was generally a less skilled wordsmith than Packard, and one who displayed less interest in producing internally consistent story spaces — weaknesses that I could see even as a young boy — he does deserve a full measure of credit for the pains he took to get the series off the ground in the first place. Looking back on the long struggle to get his brainstorm into print, Packard liked to quote the philosopher Arthur Schopenhauer: “Every original idea is first ridiculed, then vigorously attacked, and finally taken for granted.”</p>
<p>Although Packard at least was always careful to make his protagonists androgynous, it was no secret that <em>Choose Your Own Adventure</em> appealed primarily to boys — which was no bad thing on the whole, given that it was also no secret that reading in general was a harder sell with little boys than it was with little girls. Some educators and child psychologists kvetched about the violence that was undoubtedly one of the sources of the series’s appeal for boys — in just about all of the books, it was disarmingly easy to get yourself flamboyantly and creatively killed&nbsp; — but Packard was quick to counter that the mayhem was all very stylized, “exaggerated and melodramatic” rather than “harsh or nasty.” “Stupid” choices were presented to you all the time, he noted, but never “cruel” ones: “You as [the] reader never hurt anyone.”</p>
<div id="attachment_6472"><p><a href="https://www.filfre.net/2025/09/choose-your-own-adventure/kingdom/" rel="attachment wp-att-6472"><img decoding="async" aria-describedby="caption-attachment-6472" src="https://www.filfre.net/wp-content/uploads/2025/08/kingdom-182x300.jpg" alt="" width="273" height="450" srcset="https://www.filfre.net/wp-content/uploads/2025/08/kingdom-182x300.jpg 182w, https://www.filfre.net/wp-content/uploads/2025/08/kingdom-622x1024.jpg 622w, https://www.filfre.net/wp-content/uploads/2025/08/kingdom.jpg 624w" sizes="(max-width: 273px) 100vw, 273px"></a></p><p id="caption-attachment-6472">Although Packard always strained to present an <a href="https://www.filfre.net/2024/06/the-last-days-of-zork">“AFGNCAAP”</a> protagonist (“Ageless, Faceless, Gender-Neutral, Culturally Ambiguous Adventure Person”), when the stars of the books were depicted on the covers they were almost always boys. Bantam explained to a disgruntled Packard that it had many years of market research showing that, while little girls were willing to buy books that showed a hero of the opposite gender on the cover, little boys were not similarly open-minded.</p></div>
<p>One had to be a publishing insider to know that this “boys series” owed its enormous success as much to the packaging and promotional skills of three women — Amy Berkower, Joëlle Delbourgo, and Barbara Marcus — as it did to the literary talents of Packard and Montgomery. Berkower in particular became a superstar within the publishing world in the wake of <em>Choose Your Own Adventure</em>. Incredibly, the latter became only her second most successful children’s franchise, after the girl-focused&nbsp;<em>Sweet Valley High</em>, which could boast of 54 million copies sold domestically by the end of the 1980s; meanwhile <em>The Baby-Sitters Club</em> was coming up fast behind <em>Choose Your Own Adventure</em>, with 27 million copies sold. In short, her books were reaching millions upon millions of children every single month. Small wonder that she was made a full partner at Writers House in 1988; she was moving far more books each month than anyone else there.</p>
<p>Of course, any hit on the scale of&nbsp;<em>Choose Your Own Adventure</em> is bound to be copied. And this hit most certainly was, prolifically and unashamedly. During the middle years of the 1980s, when the format was at its peak, interactive books had whole aisles dedicated to them in bookstores. <a href="https://gamebooks.org/Series/29/Show"><em>Which Way?</em></a>, <a href="https://gamebooks.org/Series/104/Show"><em>Decide Your Own Adventure</em></a>,&nbsp;<a href="https://gamebooks.org/Series/304/Show"><em>Pick-a-Path</em></a>,&nbsp;<a href="https://gamebooks.org/Series/1571/Show"><em>Twisted Tales</em></a>… branders did what they could when the best brand was already taken. While&nbsp;<em>Choose Your Own Adventure</em> remained archetypal in its themes and settings, other lines were unabashedly idiosyncratic: anyone up for a&nbsp;<a href="https://gamebooks.org/Series/115/Show"><em>Do-It-Yourself Jewish Adventure</em></a>?&nbsp;Publishers were quick to leverage other properties for which they owned the rights, from <a href="https://gamebooks.org/Series/116/Show"><em>Doctor Who</em></a> to&nbsp;<em><a href="https://gamebooks.org/Series/270/Show">The Lord of the Rings</a></em>. TSR, the maker of that other school-cafeteria sensation&nbsp;<em>Dungeons &amp; Dragons</em>, introduced <a href="https://gamebooks.org/Series/79/Show">an interactive-book line drawn from the game</a>; even this website’s old friend Infocom came out with <a href="https://gamebooks.org/Series/311/Show"><em>Zork</em> books</a>, written by the star computer-game implementor <a href="https://www.filfre.net/tag/meretzky/?order=asc">Steve Meretzky</a>. Many of these books were content with the <em>Choose Your Own Adventure</em> approach of nothing but chunks of text tied to arbitrarily branching choices, but others grafted rules systems onto the format to effectively become solo role-playing games packaged as paperback books, with character creation and advancement, a dice-driven combat system, etc. The most successful of these lines was <a href="https://gamebooks.org/Series/11/Show"><em>Fighting Fantasy</em></a>, a name that is today almost as well-remembered as <em>Choose Your Own Adventure</em> itself in some quarters.</p>
<p><a href="https://www.filfre.net/2025/09/choose-your-own-adventure/warlock/" rel="attachment wp-att-6473"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2025/08/warlock-188x300.jpg" alt="" width="282" height="450" srcset="https://www.filfre.net/wp-content/uploads/2025/08/warlock-188x300.jpg 188w, https://www.filfre.net/wp-content/uploads/2025/08/warlock.jpg 631w" sizes="(max-width: 282px) 100vw, 282px"></a></p>
<p>The gamebook boom was big and real, but relatively short-lived. By 1987, the decline had begun, for both <em>Choose Your Own Adventure</em> and all of the copycats and expansions upon its formula that it had spawned. Although a few of the most lucrative series, like <em>Fighting Fantasy</em>, would join the ur-property of the genre in surviving well into the 1990s, the majority were already starting to shrivel and fall away like apples in November. Demian Katz, the Internet’s foremost archivist of gamebooks, notes that this pattern has tended to hold true “in every country” where they make an appearance: “A few come out, they become explosively popular, a flood of knock-offs are released, they reach critical mass and then drop off into nothing.” It isn’t hard to spot the reason why in the context of 1980s North America. Computers were becoming steadily more commonplace — computers that were capable of bringing vastly more flexible forms of interactive storytelling to American children, via games that didn’t require one to read the same passages of text over and over again or to toss dice and keep track of a list of statistics on paper. The same pattern would be repeated elsewhere, such as in the former Soviet countries, most of which experienced their own gamebook boom and bust during the 1990s. It seems that the arrival of the commercial mass-market publishing infrastructure that makes gamebooks go is generally followed in short order by the arrival of affordable digital technology for the home, which stops them cold.</p>
<p>In the United States, Bantam Books tried throughout the 1990s to make <em>Choose Your Own Adventure</em> feel relevant to the children of that decade, introducing a more photo-realistic art style to accompany edgier, more traditionally novelistic plots. None of it worked. In 1999, after a good twelve years of slowly but steadily declining sales, Bantam finally pulled the plug on the series. <em>Choose Your Own Adventure</em> became just another nostalgic relic of the day-glo decade, to be placed on the shelf next to Michael Jackson’s <em>Thriller</em>, a Jane Fonda workout video, and that old&nbsp;<em>Dungeons &amp; Dragons</em> Basic Set.</p>
<div id="attachment_6474"><p><a href="https://www.filfre.net/2025/09/choose-your-own-adventure/cyoa184/" rel="attachment wp-att-6474"><img decoding="async" aria-describedby="caption-attachment-6474" src="https://www.filfre.net/wp-content/uploads/2025/08/cyoa184-208x300.jpg" alt="" width="312" height="450" srcset="https://www.filfre.net/wp-content/uploads/2025/08/cyoa184-208x300.jpg 208w, https://www.filfre.net/wp-content/uploads/2025/08/cyoa184-710x1024.jpg 710w, https://www.filfre.net/wp-content/uploads/2025/08/cyoa184-768x1107.jpg 768w, https://www.filfre.net/wp-content/uploads/2025/08/cyoa184.jpg 788w" sizes="(max-width: 312px) 100vw, 312px"></a></p><p id="caption-attachment-6474">Appropriately enough, the very last <em>Choose Your Own Adventure</em> book was written by Edward&nbsp; and Andrea Packard, the latter being the grown-up version of one of the little girls to whom he had once told interactive bedtime stories.</p></div>
<p>As of this writing, <em>Choose Your Own Adventure</em> is still around in a way, but the only real <em>raison d’être</em> it has left is nostalgia. In 2003, Ray Montgomery saw that Bantam Books had let the trademark for the series lapse, and formed his own company called Chooseco to try to revive it, mostly by republishing the old books that he had written himself. He met with mixed results at best. Since Montgomery’s death in 2014, Chooseco has continued to be operated by his family, who have used it increasingly as an instrument of litigation. In 2020, for example, Netflix agreed to settle for an undisclosed sum a lawsuit over <a href="https://www.imdb.com/title/tt9495224">“Bandersnatch,”</a> a bold interactive episode of the critically lauded streaming series <em>Black Mirror</em> whose script unwisely mentioned the book series from which it drew inspiration.</p>
<p>A worthier successor on the whole is <a href="https://www.choiceofgames.com/">Choice Of Games</a>, a name whose similarity to <em>Choose Your Own Adventure</em> can hardly be coincidental. Born out of a revival of the old menu-driven computer game <a href="https://www.filfre.net/2014/11/alter-ego"><em>Alter Ego</em></a>, Choice Of has released dozens of digital branching stories over the past fifteen years. In being more adventurous than literary and basing themselves around broad, archetypal ideas — <a href="https://ifdb.org/viewgame?id=y6act0sdadab6l1n"><em>Choice of the Dragon</em></a>, <a href="https://ifdb.org/viewgame?id=zl55orcu76ngwf6t"><em>Choice of Broadsides</em></a>, <a href="https://ifdb.org/viewgame?id=66z6d3qdh378cti8"><em>Choice of the Vampire</em></a> — these games, which can run on just about any digital device capable of putting words on a screen, have done a fine job of carrying the spirit of <em>Choose Your Own Adventure</em> forward into this century. That said, there is one noteworthy difference: they are aimed at post-pubescent teens and adults — perhaps ones with fond memories of <em>Choose Your Own Adventure</em> — instead of children. “Play as male, female, or nonbinary; cis or trans; gay, straight, or bisexual; asexual and/or aromantic; allosexual and/or alloromantic; monogamous or polyamorous!” (Boring middle-aged married guy that I am, I must confess that I have no idea what three of those words even mean.)</p>
<p>Edward Packard, the father of it all, is still with us at age 94, still <a href="https://edwardpackard.com/personal-blog/">blogging</a> from time to time, still a little bemused at how he became one of the most successful working authors in the United States during the 1980s. In a plot twist almost as improbable as some of his stranger <em>Choose Your Own Adventure</em> endings, his grandson is David Corenswet, the latest actor to play Superman on the silver screen. Never a computer gamer, Packard would doubtless be baffled by most of what is featured on this website. And yet I owe him an immense debt of gratitude, for giving me my first glimpse of the potential of interactive storytelling, thus igniting a lifelong obsession. I suspect that more than one of you out there might be able to say the same.</p>
<hr>
<p><code> </code><br>
<strong>Did you enjoy this article? If so, please think about pitching in to help me make many more like it. You can pledge any amount you like.</strong></p>
<p><a href="https://www.patreon.com/DigitalAntiquarian" rel="attachment wp-att-5598"><img decoding="async" src="https://www.filfre.net/wp-content/uploads/2023/04/Patreon-300x133-1.png" alt="" width="300" height="133"></a></p>
<hr>

<p><strong>Sources</strong><strong>: </strong><em>Publishers Weekly</em> of February 29 1980, September 26 1980, October 8 1982, July 25 1986, August 12 1988, December 1 1989, July 6 1990, February 23 1998; <em>New York Times</em> of August 25 1981;&nbsp;<em>Beaver County Times</em> of March 30 1986; <em>New Yorker</em> of September 19 2022;&nbsp;<em>Journal of American Studies</em> of May 2021.</p>
<p>Online sources include <a href="https://www.mentalfloss.com/article/56160/brief-history-choose-your-own-adventure">“A Brief History of&nbsp;<em>Choose Your Own Adventure</em>“</a> by Jake Rossen at&nbsp;<em>Mental Floss</em>, <a href="https://slate.com/culture/2011/02/choose-your-own-adventure-books-how-the-cave-of-time-taught-us-to-love-interactive-entertainment.html">“<em>Choose Your Own Adventure</em>: How&nbsp;<em>The Cave of Time</em> Taught Us to Love Interactive Entertainment”</a> by Grady Hendrix at&nbsp;<em>Slate</em>, <a href="https://web.archive.org/web/20220504140422/https://www.smithsonianmag.com/innovation/surprisingly-long-history-of-choose-your-own-adventure-stories-180980014/">“The Surprising Long History of&nbsp;<em>Choose Your Own Adventure</em> Stories”</a> by Jackie Mansky at the Smithsonian’s website, and <a href="https://www.hollywoodreporter.com/tv/tv-features/choose-your-own-adventure-edward-packard-bandersnatch-knives-out-1235261356/">“Meet the 91-Year-Old Mastermind Behind&nbsp;<em>Choose Your Own Adventure</em>“</a> by Seth Abramovitch at <em>The Hollywood Reporter</em>. Plus <a href="https://edwardpackard.com/">Edward Packard’s personal site</a>. And <a href="https://gamebooks.org/">Damian Katz’s exhaustive gamebook site</a> is essential to anyone interested in these subjects; all of the book covers shown in this article were taken from his site.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI-generated “workslop” is destroying productivity? (214 pts)]]></title>
            <link>https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity</link>
            <guid>45337253</guid>
            <pubDate>Mon, 22 Sep 2025 18:07:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity">https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity</a>, See on <a href="https://news.ycombinator.com/item?id=45337253">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="main"><svg x="0" y="0" viewBox="0 0 130 148" aria-labelledby="logo:Ram6:" role="img"><title id="logo:Ram6:">Harvard Business Review Logo</title><path d="M21.3729 54.332V50.78C21.3729 49.2013 20.5031 47.9022 19.0534 47.3102L18.8546 47.228L19.0534 47.154C20.4037 46.6689 21.2072 45.3862 21.2072 43.7171V40.6667C21.2072 37.3531 19.3434 35.6758 15.6736 35.6758H9.05469V59.3229H15.8392C19.509 59.3229 21.3729 57.6456 21.3729 54.332ZM13.9671 39.7869H15.1682C15.8807 39.7869 16.2866 40.2884 16.2866 41.16V43.75C16.2866 44.6216 15.8807 45.1231 15.1682 45.1231H13.9671V39.7869ZM13.9671 55.2036V49.1684H15.1351C15.9884 49.1684 16.4191 49.6618 16.4191 50.6402V53.8222C16.4191 54.7102 16.0132 55.1953 15.2676 55.1953H13.9671V55.2036Z"></path><path d="M34.8668 35.6758H29.8882V54.036C29.8882 54.9487 29.4823 55.4749 28.7698 55.4749C28.0574 55.4749 27.6184 54.9322 27.6184 54.036V35.6758H22.6729V54.1676C22.6729 57.4647 25.0669 59.5942 28.7698 59.5942C32.4728 59.5942 34.8668 57.4647 34.8668 54.1676V35.6758Z"></path><path d="M41.908 59.5859C45.6109 59.5859 48.005 57.4563 48.005 54.1592V51.0759C48.005 49.0779 47.392 47.9267 45.7352 46.8332L41.8252 44.0787C41.2287 43.6347 41.0216 43.199 41.0216 42.385V40.9625C41.0216 39.7703 41.6098 39.5236 42.1068 39.5236C42.7861 39.5236 43.1589 40.0334 43.1589 40.9625V43.7827H47.9719V40.831C47.9719 37.4352 45.7766 35.4043 42.1068 35.4043C38.437 35.4043 36.043 37.5339 36.043 40.831V43.3881C36.043 45.3861 36.656 46.5372 38.3128 47.6307L42.2228 50.4181C42.753 50.8127 43.0263 51.1827 43.0263 52.1119V54.0359C43.0263 54.965 42.6536 55.4747 41.9743 55.4747C41.4772 55.4747 40.8891 55.2281 40.8891 54.0359V50.7881H36.043V54.1674C36.043 57.5632 38.2382 59.5941 41.908 59.5941V59.5859Z"></path><path d="M54.334 35.6758H49.3223V59.3229H54.334V35.6758Z"></path><path d="M64.3746 59.3229H68.7568V35.6758H64.2752V41.8589L64.3497 47.0142H63.9024L61.2681 35.6758H56.2811V59.3229H60.7628V51.446L60.6965 46.488H61.1355L64.3746 59.3229Z"></path><path d="M80.1721 40.05V35.6758H70.7118V59.3229H80.1721V54.9404H75.591V49.3082H79.6005V44.9258H75.591V40.05H80.1721Z"></path><path d="M92.9786 51.0846C92.9786 49.0866 92.3656 47.9355 90.7088 46.842L86.7988 44.0875C86.2024 43.6435 85.9952 43.2078 85.9952 42.3938V40.9713C85.9952 39.7791 86.5834 39.5324 87.0805 39.5324C87.7597 39.5324 88.1325 40.0422 88.1325 40.9713V43.7915H92.9455V40.8398C92.9455 37.444 90.7502 35.4131 87.0805 35.4131C83.4107 35.4131 81.0166 37.5426 81.0166 40.8398V43.3969C81.0166 45.3949 81.6296 46.546 83.2864 47.6395L87.1964 50.4269C87.7266 50.8215 88 51.1915 88 52.1206V54.0446C88 54.9738 87.6272 55.4835 86.9479 55.4835C86.4509 55.4835 85.8627 55.2369 85.8627 54.0446V50.7969H81.0166V54.1762C81.0166 57.572 83.2118 59.6029 86.8816 59.6029C90.5514 59.6029 92.9786 57.4733 92.9786 54.1762V51.0846Z"></path><path d="M106.076 51.0846C106.076 49.0866 105.463 47.9355 103.806 46.842L99.8965 44.0875C99.3 43.6435 99.0929 43.2078 99.0929 42.3938V40.9713C99.0929 39.7791 99.6811 39.5324 100.178 39.5324C100.857 39.5324 101.23 40.0422 101.23 40.9713V43.7915H106.043V40.8398C106.043 37.444 103.848 35.4131 100.178 35.4131C96.5083 35.4131 94.1143 37.5426 94.1143 40.8398V43.3969C94.1143 45.3949 94.7273 46.546 96.3841 47.6395L100.294 50.4269C100.824 50.8215 101.098 51.1915 101.098 52.1206V54.0446C101.098 54.9738 100.725 55.4835 100.046 55.4835C99.5485 55.4835 98.9604 55.2369 98.9604 54.0446V50.7969H94.1143V54.1762C94.1143 57.572 96.3095 59.6029 99.9793 59.6029C103.649 59.6029 106.076 57.4733 106.076 54.1762V51.0846Z"></path><path d="M21.696 32.6417V8.98633H16.7091V18.2446H14.0748V8.98633H9.05469V32.6417H14.0748V22.6188H16.7091V32.6417H21.696Z"></path><path d="M30.8663 27.8651L31.3634 32.6422H36.2095L32.987 8.99512H25.7137L22.5244 32.6422H27.2048L27.6687 27.8651H30.8663ZM28.3977 19.8813L28.8782 15.3345H29.6238L30.1456 19.8813L30.6344 23.9513H27.909L28.3977 19.8813Z"></path><path d="M49.7285 32.6418C49.4386 31.7785 49.3972 30.5945 49.3972 29.542V24.4032C49.3972 22.6847 48.6599 21.4514 47.3096 20.9334L47.1025 20.8512L47.3096 20.7772C48.6599 20.292 49.4635 19.0094 49.4635 17.3403V13.9938C49.4635 10.6803 47.5996 9.00293 43.9298 9.00293H37.1121V32.65H42.0576V23.03H43.1925C43.7641 23.03 44.4434 23.2849 44.4434 24.5018V29.7065C44.4434 30.652 44.4848 31.8278 44.783 32.6418H49.7285ZM43.3665 18.812H42.0659V13.2127H43.3665C44.0706 13.2127 44.4848 13.7307 44.4848 14.5858V17.4389C44.4848 18.3105 44.0789 18.812 43.3665 18.812Z"></path><path d="M58.5261 8.9873L57.4989 19.7913L57.0598 25.0782H56.538L56.0989 19.7913L55.0303 8.9873H49.9688L53.5143 32.6426H59.8101L63.3971 8.9873H58.5261Z"></path><path d="M84.5049 32.6428H89.4422C89.1522 31.7795 89.1108 30.5955 89.1108 29.543V24.4041C89.1108 22.6857 88.3735 21.4524 87.0232 20.9343L86.8244 20.8521L87.0315 20.7781C88.3818 20.293 89.1854 19.0104 89.1854 17.3412V13.9948C89.1854 10.6812 87.3215 9.00391 83.6517 9.00391H76.834V32.651H81.7795V23.031H82.9144C83.486 23.031 84.1653 23.2859 84.1653 24.5028V29.7075C84.1653 30.653 84.2067 31.8288 84.5049 32.6428ZM83.0801 18.813H81.7795V13.2137H83.0801C83.7842 13.2137 84.1984 13.7317 84.1984 14.5868V17.4399C84.1984 18.3115 83.7925 18.813 83.0801 18.813Z"></path><path d="M103.276 14.414C103.276 11.0675 100.973 8.9873 97.2784 8.9873H90.9246V32.6344H97.2784C100.981 32.6344 103.276 30.5542 103.276 27.2077V14.4057V14.414ZM98.2973 27.0515C98.2973 27.9149 97.8831 28.4246 97.179 28.4246H95.8784V13.2053H97.179C97.8831 13.2053 98.2973 13.7233 98.2973 14.5784V27.0515Z"></path><path d="M70.6041 27.8651L71.1094 32.6422H75.9555L72.7331 8.99511H65.4598L62.2704 32.6422H66.9509L67.4148 27.8651H70.6041ZM68.1355 19.8813L68.616 15.3344H69.3615L69.8834 19.8813L70.3721 23.9513H67.6467L68.1355 19.8813Z"></path><path d="M16.7336 86.0129H21.6708C21.3809 85.1496 21.3394 83.9656 21.3394 82.9131V77.7742C21.3394 76.0558 20.6022 74.8225 19.2519 74.3045L19.0531 74.2222L19.2602 74.1482C20.6105 73.6631 21.414 72.3805 21.414 70.7114V67.3649C21.414 64.0514 19.5501 62.374 15.8803 62.374H9.06264V86.0211H14.0082V76.4011H15.1431C15.7146 76.4011 16.3939 76.656 16.3939 77.8729V83.0776C16.3939 84.0231 16.4354 85.1989 16.7336 86.0129ZM15.3087 72.1831H14.0082V66.5838H15.3087C16.0129 66.5838 16.4271 67.1018 16.4271 67.9569V70.81C16.4271 71.6816 16.0212 72.1831 15.3087 72.1831Z"></path><path d="M32.5472 66.7399V62.3574H23.0869V86.0128H32.5472V81.6303H27.9662V75.9899H31.9756V71.6156H27.9662V66.7399H32.5472Z"></path><path d="M52.3956 62.3574H47.3838V86.0045H52.3956V62.3574Z"></path><path d="M63.7367 66.7398V62.3573H54.2764V86.0127H63.7367V81.6302H59.1557V75.9898H63.1651V71.6156H59.1557V66.7398H63.7367Z"></path><path d="M78.9626 62.3573L77.9851 76.0227H77.2395L77.2313 75.9487L76.3035 62.3573H72.2609L71.3911 76.0227H70.6372L70.2562 71.1058L69.6266 62.3573H64.4491L67.1497 86.0127H72.8408L73.7768 73.3093H74.4478L75.3508 86.0127H81.0419L83.7424 62.3573H78.9626Z"></path><path d="M41.7842 62.3573L40.757 73.1613L40.3097 78.4482H39.7961L39.3488 73.1613L38.2884 62.3573H33.2186L36.7724 86.0127H43.0682L46.6469 62.3573H41.7842Z"></path><path d="M64.9959 148L64.0929 147.556C39.1499 135.387 22.9548 124.509 13.1218 113.319C4.05085 103 0 92.1464 0 78.1276V0H130V78.1276C130 92.1464 125.957 103 116.878 113.319C107.045 124.509 90.8418 135.387 65.9071 147.556L65.0042 148H64.9959ZM4.10884 4.07822V78.1276C4.10884 91.0858 7.8449 101.117 16.2117 110.638C25.5643 121.27 41.0801 131.712 64.9959 143.453C88.9116 131.712 104.436 121.27 113.78 110.638C122.155 101.117 125.883 91.094 125.883 78.1276V4.07822H4.10055H4.10884Z"></path></svg><div><div><p><span>September 22, 2025<!-- -->, Updated September 22, 2025</span></p></div><div><p><img src="https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid.jpg" sizes="(min-width: 64em) 84vw, 100vw" srcset="https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid.jpg 1200w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-300x169.jpg 300w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-1024x576.jpg 1024w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-768x432.jpg 768w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-500x281.jpg 500w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-383x215.jpg 383w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-700x394.jpg 700w, https://hbr.org/resources/images/article_assets/2025/09/Sep25_22_AIslopmid-850x478.jpg 850w" alt=""></p><p><span>HBR Staff/AI</span></p></div><p data-first-paragraph="true">A confusing contradiction is unfolding in companies embracing generative AI tools: while workers are largely following mandates to embrace the technology, few are seeing it create real value. Consider, for instance, that the number of companies with fully AI-led processes <a href="https://www.accenture.com/content/dam/accenture/final/accenture-com/document-3/Accenture-Reinventing-Enterprise-Operations-FA-9-25-24.pdf">nearly doubled</a> last year, while AI use has likewise <a href="https://www.gallup.com/workplace/691643/work-nearly-doubled-two-years.aspx">doubled</a> at work since 2023. Yet a <a href="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf">recent report</a> from the MIT Media Lab found that 95% of organizations see no measurable return on their investment in these technologies. So much activity, so much enthusiasm, so little return. Why?</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen3-Omni: Native Omni AI model for text, image and video (522 pts)]]></title>
            <link>https://github.com/QwenLM/Qwen3-Omni</link>
            <guid>45336989</guid>
            <pubDate>Mon, 22 Sep 2025 17:50:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/QwenLM/Qwen3-Omni">https://github.com/QwenLM/Qwen3-Omni</a>, See on <a href="https://news.ycombinator.com/item?id=45336989">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Qwen3-Omni</h2><a id="user-content-qwen3-omni" aria-label="Permalink: Qwen3-Omni" href="#qwen3-omni"></a></p>

<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/1df0c9499512c1ce1c446481874a712de3eacdb6a5b674c1cd3bf0fafd4280cd/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f2f5177656e332d4f6d6e692f7177656e335f6f6d6e695f6c6f676f2e706e67"><img src="https://camo.githubusercontent.com/1df0c9499512c1ce1c446481874a712de3eacdb6a5b674c1cd3bf0fafd4280cd/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f2f5177656e332d4f6d6e692f7177656e335f6f6d6e695f6c6f676f2e706e67" width="400" data-canonical-src="https://qianwen-res.oss-cn-beijing.aliyuncs.com//Qwen3-Omni/qwen3_omni_logo.png"></a>
</p><p dir="auto">
        💜 <a href="https://chat.qwen.ai/" rel="nofollow"><b>Qwen Chat</b></a>&nbsp;&nbsp; | &nbsp;&nbsp;🤗 <a href="https://huggingface.co/collections/Qwen/qwen3-omni-68d100a86cd0906843ceccbe" rel="nofollow">Hugging Face</a>&nbsp;&nbsp; | &nbsp;&nbsp;🤖 <a href="https://modelscope.cn/collections/Qwen3-Omni-867aef131e7d4f" rel="nofollow">ModelScope</a>&nbsp;&nbsp; | &nbsp;&nbsp;📑 <a href="https://qwen.ai/blog?id=65f766fc2dcba7905c1cb69cc4cab90e94126bf4&amp;from=research.latest-advancements-list" rel="nofollow">Blog</a>&nbsp;&nbsp; | &nbsp;&nbsp;📚 <a href="https://github.com/QwenLM/Qwen3-Omni/tree/main/cookbooks">Cookbooks</a>&nbsp;&nbsp; | &nbsp;&nbsp;📑 <a href="https://github.com/QwenLM/Qwen3-Omni/tree/main/assets/Qwen3_Omni.pdf">Paper</a>&nbsp;&nbsp;
<br>
🖥️ <a href="https://huggingface.co/spaces/Qwen/Qwen3-Omni-Demo" rel="nofollow">Hugging Face Demo</a>&nbsp;&nbsp; | &nbsp;&nbsp; 🖥️ <a href="https://modelscope.cn/studios/Qwen/Qwen3-Omni-Demo" rel="nofollow">ModelScope Demo</a>&nbsp;&nbsp; | &nbsp;&nbsp;💬 <a href="https://github.com/QwenLM/Qwen/blob/main/assets/wechat.png">WeChat (微信)</a>&nbsp;&nbsp; | &nbsp;&nbsp;🫨 <a href="https://discord.gg/CV4E9rpNSD" rel="nofollow">Discord</a>&nbsp;&nbsp; | &nbsp;&nbsp;📑 <a href="https://help.aliyun.com/zh/model-studio/user-guide/qwen-omni" rel="nofollow">API</a>
</p>
<p dir="auto">We release <strong>Qwen3-Omni</strong>, the natively end-to-end multilingual omni-modal foundation models. It is designed to process diverse inputs including text, images, audio, and video, while delivering real-time streaming responses in both text and natural speech. Click the video below for more information 😃</p>
<details open="">
<summary>English Version</summary>
<a href="https://youtu.be/_zdOrPju4_g" rel="nofollow">
  <img src="https://camo.githubusercontent.com/c71f457935383f018f713df40205bb87a7bb92a1f46e3456e14e6f81b438541c/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f5177656e332d4f6d6e692f766964656f636f7665722e706e67" alt="Open English Video" data-canonical-src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/videocover.png">
</a>
</details>
<details>
<summary>Chinese Version</summary>
<a href="https://youtu.be/Wtjsw5deXfQ" rel="nofollow">
  <img src="https://camo.githubusercontent.com/c71f457935383f018f713df40205bb87a7bb92a1f46e3456e14e6f81b438541c/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f5177656e332d4f6d6e692f766964656f636f7665722e706e67" alt="打开中文视频" data-canonical-src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/videocover.png">
</a>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">News</h2><a id="user-content-news" aria-label="Permalink: News" href="#news"></a></p>
<ul dir="auto">
<li>2025.09.22: 🎉🎉🎉 We have released <a href="https://huggingface.co/collections/Qwen/qwen3-omni-68d100a86cd0906843ceccbe" rel="nofollow">Qwen3-Omni</a>. For more details, please check our <a href="https://qwen.ai/blog?id=65f766fc2dcba7905c1cb69cc4cab90e94126bf4&amp;from=research.latest-advancements-list" rel="nofollow">blog</a>!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents </h2><a id="user-content-contents-" aria-label="Permalink: Contents " href="#contents-"></a></p>
<ul dir="auto">
<li><a href="#overview">Overview</a>
<ul dir="auto">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#model-architecture">Model Architecture</a></li>
<li><a href="#cookbooks-for-usage-cases">Cookbooks for Usage Cases</a></li>
</ul>
</li>
<li><a href="#quickstart">QuickStart</a>
<ul dir="auto">
<li><a href="#model-description-and-download">Model Description and Download</a></li>
<li><a href="#transformers-usage">Transformers Usage</a></li>
<li><a href="#vllm-usage">vLLM Usage</a></li>
<li><a href="#dashscope-api-usage">DashScope API Usage</a></li>
<li><a href="#usage-tips-recommended-reading">Usage Tips (Recommended Reading)</a></li>
</ul>
</li>
<li><a href="#interaction-with-qwen3-omni">Interaction with Qwen3-Omni</a>
<ul dir="auto">
<li><a href="#online-demo">Online Demo</a></li>
<li><a href="#real-time-interaction">Real-Time Interaction</a></li>
<li><a href="#launch-local-web-ui-demo">Launch Local Web UI Demo</a></li>
</ul>
</li>
<li><a href="#-docker">Docker</a></li>
<li><a href="#evaluation">Evaluation</a>
<ul dir="auto">
<li><a href="#performance-of-qwen3-omni">Performance of Qwen3-Omni</a></li>
<li><a href="#setting-for-evaluation">Setting for Evaluation</a></li>
</ul>
</li>
<li><a href="#citation">Citation</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Introduction</h3><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7d96c10768d1a12d6718515935a0da75295e66b53a76407358205764576cb1e7/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f5177656e332d4f6d6e692f71336f5f696e74726f64756374696f6e2e706e67"><img src="https://camo.githubusercontent.com/7d96c10768d1a12d6718515935a0da75295e66b53a76407358205764576cb1e7/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f5177656e332d4f6d6e692f71336f5f696e74726f64756374696f6e2e706e67" width="90%" data-canonical-src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/q3o_introduction.png"></a>
</p><p dir="auto">Qwen3-Omni is the natively end-to-end multilingual omni-modal foundation models. It processes text, images, audio, and video, and delivers real-time streaming responses in both text and natural speech. We introduce several architectural upgrades to improve performance and efficiency. Key features:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>State-of-the-art across modalities</strong>: Early text-first pretraining and mixed multimodal training provide native multimodal support. While achieving strong audio and audio-video results, unimodal text and image performance does not regress. Reaches SOTA on 22 of 36 audio/video benchmarks and open-source SOTA on 32 of 36; ASR, audio understanding, and voice conversation performance is comparable to Gemini 2.5 Pro.</p>
</li>
<li>
<p dir="auto"><strong>Multilingual</strong>: Supports 119 text languages, 19 speech input languages, and 10 speech output languages.</p>
<ul dir="auto">
<li><strong>Speech Input</strong>: English, Chinese, Korean, Japanese, German, Russian, Italian, French, Spanish, Portuguese, Malay, Dutch, Indonesian, Turkish, Vietnamese, Cantonese, Arabic, Urdu.</li>
<li><strong>Speech Output</strong>: English, Chinese, French, German, Russian, Italian, Spanish, Portuguese, Japanese, Korean.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Novel Architecture</strong>: MoE-based Thinker–Talker design with AuT pretraining for strong general representations, plus a multi-codebook design that drives latency to a minimum.</p>
</li>
<li>
<p dir="auto"><strong>Real-time Audio/Video Interaction</strong>: Low-latency streaming with natural turn-taking and immediate text or speech responses.</p>
</li>
<li>
<p dir="auto"><strong>Flexible Control</strong>: Customize behavior via system prompts for fine-grained control and easy adaptation.</p>
</li>
<li>
<p dir="auto"><strong>Detailed Audio Captioner</strong>: Qwen3-Omni-30B-A3B-Captioner is now open source: a general-purpose, highly detailed, low-hallucination audio captioning model that fills a critical gap in the open-source community.</p>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Model Architecture</h3><a id="user-content-model-architecture" aria-label="Permalink: Model Architecture" href="#model-architecture"></a></p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/c4e0a9eeee86b979ea2d52f01ec3ec13f133324ef14e01c2c0d42ba8044da756/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f5177656e332d4f6d6e692f6f766572766965772e706e67"><img src="https://camo.githubusercontent.com/c4e0a9eeee86b979ea2d52f01ec3ec13f133324ef14e01c2c0d42ba8044da756/68747470733a2f2f7169616e77656e2d7265732e6f73732d636e2d6265696a696e672e616c6979756e63732e636f6d2f5177656e332d4f6d6e692f6f766572766965772e706e67" width="80%" data-canonical-src="https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/overview.png"></a>
</p><p dir="auto"><h3 tabindex="-1" dir="auto">Cookbooks for Usage Cases</h3><a id="user-content-cookbooks-for-usage-cases" aria-label="Permalink: Cookbooks for Usage Cases" href="#cookbooks-for-usage-cases"></a></p>
<p dir="auto">Qwen3-Omni supports a wide range of multimodal application scenarios, covering various domain tasks involving audio, image, video, and audio-visual modalities. Below are several cookbooks demonstrating the usage cases of Qwen3-Omni and these cookbooks include our actual execution logs. You can first follow the <a href="#quickstart">QuickStart</a> guide to download the model and install the necessary inference environment dependencies, then run and experiment locally—try modifying prompts or switching model types, and enjoy exploring the capabilities of Qwen3-Omni!</p>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Cookbook</th>
      <th>Description</th>
      <th>Open</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="6">Audio</td>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/speech_recognition.ipynb">Speech Recognition</a></td>
      <td>Speech recognition, supporting multiple languages and long audio.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/speech_recognition.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/speech_translation.ipynb">Speech Translation</a></td>
      <td>Speech-to-Text / Speech-to-Speech translation.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/speech_translation.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/music_analysis.ipynb">Music Analysis</a></td>
      <td>Detailed analysis and appreciation of any music, including style, genre, rhythm, etc.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/music_analysis.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/sound_analysis.ipynb">Sound Analysis</a></td>
      <td>Description and analysis of various sound effects and audio signals.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/sound_analysis.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_caption.ipynb">Audio Caption</a></td>
      <td>Audio captioning, detailed description of any audio input.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_caption.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/mixed_audio_analysis.ipynb">Mixed Audio Analysis</a></td>
      <td>Analysis of mixed audio content, such as speech, music, and environmental sounds.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/mixed_audio_analysis.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td rowspan="7">Visual</td>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/ocr.ipynb">OCR</a></td>
      <td>OCR for complex images.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/ocr.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/object_grounding.ipynb">Object Grounding</a></td>
      <td>Target detection and grounding.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/object_grounding.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/image_question.ipynb">Image Question</a></td>
      <td>Answering arbitrary questions about any image.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/image_question.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/image_math.ipynb">Image Math</a></td>
      <td>Solving complex mathematical problems in images, highlighting the capabilities of the Thinking model.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/image_math.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/video_description.ipynb">Video Description</a></td>
      <td>Detailed description of video content.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/video_description.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/video_navigation.ipynb">Video Navigation</a></td>
      <td>Generating navigation commands from first-person motion videos.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/video_navigation.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/video_scene_transition.ipynb">Video Scene Transition</a></td>
      <td>Analysis of scene transitions in videos.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/video_scene_transition.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td rowspan="3">Audio-Visual</td>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_visual_question.ipynb">Audio Visual Question</a></td>
      <td>Answering arbitrary questions in audio-visual scenarios, demonstrating the model's ability to model temporal alignment between audio and video.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_visual_question.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_visual_interaction.ipynb">Audio Visual Interaction</a></td>
      <td>Interactive communication with the model using audio-visual inputs, including task specification via audio.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_visual_interaction.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_visual_dialogue.ipynb">Audio Visual Dialogue</a></td>
      <td>Conversational interaction with the model using audio-visual inputs, showcasing its capabilities in casual chat and assistant-like behavior.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_visual_dialogue.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td>Agent</td>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_function_call.ipynb">Audio Function Call</a></td>
      <td>Using audio input to perform function calls, enabling agent-like behaviors.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/audio_function_call.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
    <tr>
      <td>Downstream Task Fine-tuning</td>
      <td><a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/omni_captioner.ipynb">Omni Captioner</a></td>
      <td>Introduction and capability demonstration of <strong>Qwen3-Omni-30B-A3B-Captioner</strong>, a downstream fine-tuned model based on Qwen3-Omni-30B-A3B-Instruct, illustrating the strong generalization ability of the Qwen3-Omni foundation model.</td>
      <td><a href="https://colab.research.google.com/github/QwenLM/Qwen3-Omni/blob/main/cookbooks/omni_captioner.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/96889048f8a9014fdeba2a891f97150c6aac6e723f5190236b10215a97ed41f3/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"></a></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">QuickStart</h2><a id="user-content-quickstart" aria-label="Permalink: QuickStart" href="#quickstart"></a></p>
<p dir="auto">Here, we provide several methods to quickly get started with Qwen3-Omni. If you want complete experience of Qwen3-Omni, you can use <a href="#transformers-usage">Hugging Face Transformers</a>. However, since Qwen3-Omni employs an MoE architecture, inference speed with Hugging Face Transformers on MoE models can be very slow. For large-scale invocation or low-latency requirements, we highly recommend using <a href="#vllm-usage">vLLM</a> or performing inference via the <a href="#dashscope-api-usage">DashScope API</a>. We also strongly suggest using our provided <a href="#-docker">Docker</a> image, which includes a complete runtime environment for both Hugging Face Transformers and vLLM. In addition, our <a href="https://github.com/QwenLM/Qwen3-Omni/tree/main/cookbooks">cookbooks</a> offer some use cases to show Qwen3-Omni's capabilities. Welcome to learn more!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Model Description and Download</h3><a id="user-content-model-description-and-download" aria-label="Permalink: Model Description and Download" href="#model-description-and-download"></a></p>
<p dir="auto">Below is the description of all Qwen3-Omni models. Please select and download the model that fits your needs.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Qwen3-Omni-30B-A3B-Instruct</td>
<td>The Instruct model of Qwen3-Omni-30B-A3B, containing both thinker and talker, supporting audio, video, and text input, with audio and text output. For more information, please read the <a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/assets/Qwen3_Omni.pdf">Qwen3-Omni Technical Report</a>.</td>
</tr>
<tr>
<td>Qwen3-Omni-30B-A3B-Thinking</td>
<td>The Thinking model of Qwen3-Omni-30B-A3B, containing the thinker component, equipped with chain-of-thought reasoning, supporting audio, video, and text input, with text output. For more information, please read the <a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/assets/Qwen3_Omni.pdf">Qwen3-Omni Technical Report</a>.</td>
</tr>
<tr>
<td>Qwen3-Omni-30B-A3B-Captioner</td>
<td>A downstream audio fine-grained caption model fine-tuned from Qwen3-Omni-30B-A3B-Instruct, which produces detailed, low-hallucination captions for arbitrary audio inputs. It contains the thinker, supporting audio input and text output. For more information, you can refer to the model's <a href="https://github.com/QwenLM/Qwen3-Omni/blob/main/cookbooks/omni_captioner.ipynb">cookbook</a> or <a href="https://huggingface.co/spaces/Qwen/Qwen3-Omni-Captioner-Demo" rel="nofollow">Hugging Face Demo</a> and <a href="https://modelscope.cn/studios/Qwen/Qwen3-Omni-Captioner-Demo" rel="nofollow">ModelScope Demo</a>.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">During loading in Hugging Face Transformers or vLLM, model weights will be automatically downloaded based on the model name. However, if your runtime environment is not conducive to downloading weights during execution, you can refer to the following commands to manually download the model weights to a local directory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Download through ModelScope (recommended for users in Mainland China)
pip install -U modelscope
modelscope download --model Qwen/Qwen3-Omni-30B-A3B-Instruct --local_dir ./Qwen3-Omni-30B-A3B-Instruct
modelscope download --model Qwen/Qwen3-Omni-30B-A3B-Thinking --local_dir ./Qwen3-Omni-30B-A3B-Thinking
modelscope download --model Qwen/Qwen3-Omni-30B-A3B-Captioner --local_dir ./Qwen3-Omni-30B-A3B-Captioner

# Download through Hugging Face
pip install -U &quot;huggingface_hub[cli]&quot;
huggingface-cli download Qwen/Qwen3-Omni-30B-A3B-Instruct --local-dir ./Qwen3-Omni-30B-A3B-Instruct
huggingface-cli download Qwen/Qwen3-Omni-30B-A3B-Thinking --local-dir ./Qwen3-Omni-30B-A3B-Thinking
huggingface-cli download Qwen/Qwen3-Omni-30B-A3B-Captioner --local-dir ./Qwen3-Omni-30B-A3B-Captioner"><pre><span><span>#</span> Download through ModelScope (recommended for users in Mainland China)</span>
pip install -U modelscope
modelscope download --model Qwen/Qwen3-Omni-30B-A3B-Instruct --local_dir ./Qwen3-Omni-30B-A3B-Instruct
modelscope download --model Qwen/Qwen3-Omni-30B-A3B-Thinking --local_dir ./Qwen3-Omni-30B-A3B-Thinking
modelscope download --model Qwen/Qwen3-Omni-30B-A3B-Captioner --local_dir ./Qwen3-Omni-30B-A3B-Captioner

<span><span>#</span> Download through Hugging Face</span>
pip install -U <span><span>"</span>huggingface_hub[cli]<span>"</span></span>
huggingface-cli download Qwen/Qwen3-Omni-30B-A3B-Instruct --local-dir ./Qwen3-Omni-30B-A3B-Instruct
huggingface-cli download Qwen/Qwen3-Omni-30B-A3B-Thinking --local-dir ./Qwen3-Omni-30B-A3B-Thinking
huggingface-cli download Qwen/Qwen3-Omni-30B-A3B-Captioner --local-dir ./Qwen3-Omni-30B-A3B-Captioner</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Transformers Usage</h3><a id="user-content-transformers-usage" aria-label="Permalink: Transformers Usage" href="#transformers-usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">The Hugging Face Transformers code for Qwen3-Omni has been successfully merged, but the PyPI package has not yet been released. Therefore, you need to install it from source using the following command. We strongly recommend that you <strong>create a new Python environment</strong> or use our <a href="#-docker">Docker</a> to avoid environment runtime issues.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# If you already have transformers installed, please uninstall it first, or create a new Python environment
# pip uninstall transformers
pip install git+https://github.com/huggingface/transformers
pip install accelerate"><pre><span><span>#</span> If you already have transformers installed, please uninstall it first, or create a new Python environment</span>
<span><span>#</span> pip uninstall transformers</span>
pip install git+https://github.com/huggingface/transformers
pip install accelerate</pre></div>
<p dir="auto">We offer a toolkit to help you handle various types of audio and visual input more conveniently, providing an API-like experience. This includes support for base64, URLs, and interleaved audio, images, and videos. You can install it using the following command and make sure your system has <code>ffmpeg</code> installed:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install qwen-omni-utils -U"><pre>pip install qwen-omni-utils -U</pre></div>
<p dir="auto">Additionally, we recommend using FlashAttention 2 when running with Hugging Face Transformers to reduce GPU memory usage. However, if you are primarily using <a href="#vllm-usage">vLLM</a> for inference, this installation is not necessary, as vLLM includes FlashAttention 2 by default.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -U flash-attn --no-build-isolation"><pre>pip install -U flash-attn --no-build-isolation</pre></div>
<p dir="auto">Also, you should have hardware that is compatible with FlashAttention 2. Read more about it in the official documentation of the <a href="https://github.com/Dao-AILab/flash-attention">FlashAttention repository</a>. FlashAttention 2 can only be used when a model is loaded in <code>torch.float16</code> or <code>torch.bfloat16</code>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Code Snippet</h4><a id="user-content-code-snippet" aria-label="Permalink: Code Snippet" href="#code-snippet"></a></p>
<p dir="auto">Here is a code snippet to show you how to use Qwen3-Omni with <code>transformers</code> and <code>qwen_omni_utils</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import soundfile as sf

from transformers import Qwen3OmniMoeForConditionalGeneration, Qwen3OmniMoeProcessor
from qwen_omni_utils import process_mm_info

MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;
# MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Thinking&quot;

model = Qwen3OmniMoeForConditionalGeneration.from_pretrained(
    MODEL_PATH,
    dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;,
    attn_implementation=&quot;flash_attention_2&quot;,
)

processor = Qwen3OmniMoeProcessor.from_pretrained(MODEL_PATH)

conversation = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg&quot;},
            {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you see and hear? Answer in one short sentence.&quot;}
        ],
    },
]

# Set whether to use audio in video
USE_AUDIO_IN_VIDEO = True

# Preparation for inference
text = processor.apply_chat_template(conversation, add_generation_prompt=True, tokenize=False)
audios, images, videos = process_mm_info(conversation, use_audio_in_video=USE_AUDIO_IN_VIDEO)
inputs = processor(text=text, 
                   audio=audios, 
                   images=images, 
                   videos=videos, 
                   return_tensors=&quot;pt&quot;, 
                   padding=True, 
                   use_audio_in_video=USE_AUDIO_IN_VIDEO)
inputs = inputs.to(model.device).to(model.dtype)

# Inference: Generation of the output text and audio
text_ids, audio = model.generate(**inputs, 
                                 speaker=&quot;Ethan&quot;, 
                                 thinker_return_dict_in_generate=True,
                                 use_audio_in_video=USE_AUDIO_IN_VIDEO)

text = processor.batch_decode(text_ids.sequences[:, inputs[&quot;input_ids&quot;].shape[1] :],
                              skip_special_tokens=True,
                              clean_up_tokenization_spaces=False)
print(text)
if audio is not None:
    sf.write(
        &quot;output.wav&quot;,
        audio.reshape(-1).detach().cpu().numpy(),
        samplerate=24000,
    )"><pre><span>import</span> <span>soundfile</span> <span>as</span> <span>sf</span>

<span>from</span> <span>transformers</span> <span>import</span> <span>Qwen3OmniMoeForConditionalGeneration</span>, <span>Qwen3OmniMoeProcessor</span>
<span>from</span> <span>qwen_omni_utils</span> <span>import</span> <span>process_mm_info</span>

<span>MODEL_PATH</span> <span>=</span> <span>"Qwen/Qwen3-Omni-30B-A3B-Instruct"</span>
<span># MODEL_PATH = "Qwen/Qwen3-Omni-30B-A3B-Thinking"</span>

<span>model</span> <span>=</span> <span>Qwen3OmniMoeForConditionalGeneration</span>.<span>from_pretrained</span>(
    <span>MODEL_PATH</span>,
    <span>dtype</span><span>=</span><span>"auto"</span>,
    <span>device_map</span><span>=</span><span>"auto"</span>,
    <span>attn_implementation</span><span>=</span><span>"flash_attention_2"</span>,
)

<span>processor</span> <span>=</span> <span>Qwen3OmniMoeProcessor</span>.<span>from_pretrained</span>(<span>MODEL_PATH</span>)

<span>conversation</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg"</span>},
            {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you see and hear? Answer in one short sentence."</span>}
        ],
    },
]

<span># Set whether to use audio in video</span>
<span>USE_AUDIO_IN_VIDEO</span> <span>=</span> <span>True</span>

<span># Preparation for inference</span>
<span>text</span> <span>=</span> <span>processor</span>.<span>apply_chat_template</span>(<span>conversation</span>, <span>add_generation_prompt</span><span>=</span><span>True</span>, <span>tokenize</span><span>=</span><span>False</span>)
<span>audios</span>, <span>images</span>, <span>videos</span> <span>=</span> <span>process_mm_info</span>(<span>conversation</span>, <span>use_audio_in_video</span><span>=</span><span>USE_AUDIO_IN_VIDEO</span>)
<span>inputs</span> <span>=</span> <span>processor</span>(<span>text</span><span>=</span><span>text</span>, 
                   <span>audio</span><span>=</span><span>audios</span>, 
                   <span>images</span><span>=</span><span>images</span>, 
                   <span>videos</span><span>=</span><span>videos</span>, 
                   <span>return_tensors</span><span>=</span><span>"pt"</span>, 
                   <span>padding</span><span>=</span><span>True</span>, 
                   <span>use_audio_in_video</span><span>=</span><span>USE_AUDIO_IN_VIDEO</span>)
<span>inputs</span> <span>=</span> <span>inputs</span>.<span>to</span>(<span>model</span>.<span>device</span>).<span>to</span>(<span>model</span>.<span>dtype</span>)

<span># Inference: Generation of the output text and audio</span>
<span>text_ids</span>, <span>audio</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>**</span><span>inputs</span>, 
                                 <span>speaker</span><span>=</span><span>"Ethan"</span>, 
                                 <span>thinker_return_dict_in_generate</span><span>=</span><span>True</span>,
                                 <span>use_audio_in_video</span><span>=</span><span>USE_AUDIO_IN_VIDEO</span>)

<span>text</span> <span>=</span> <span>processor</span>.<span>batch_decode</span>(<span>text_ids</span>.<span>sequences</span>[:, <span>inputs</span>[<span>"input_ids"</span>].<span>shape</span>[<span>1</span>] :],
                              <span>skip_special_tokens</span><span>=</span><span>True</span>,
                              <span>clean_up_tokenization_spaces</span><span>=</span><span>False</span>)
<span>print</span>(<span>text</span>)
<span>if</span> <span>audio</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
    <span>sf</span>.<span>write</span>(
        <span>"output.wav"</span>,
        <span>audio</span>.<span>reshape</span>(<span>-</span><span>1</span>).<span>detach</span>().<span>cpu</span>().<span>numpy</span>(),
        <span>samplerate</span><span>=</span><span>24000</span>,
    )</pre></div>
<p dir="auto">Here are some more advanced usage examples. You can expand the sections below to learn more.</p>
<details>
<summary>Batch inference</summary>
<p dir="auto">The model can batch inputs composed of mixed samples of various types such as text, images, audio, and videos as input when <code>return_audio=False</code> is set. Here is an example.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from transformers import Qwen3OmniMoeForConditionalGeneration, Qwen3OmniMoeProcessor
from qwen_omni_utils import process_mm_info

MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;
# MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Thinking&quot;

model = Qwen3OmniMoeForConditionalGeneration.from_pretrained(
    MODEL_PATH,
    dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;,
    attn_implementation=&quot;flash_attention_2&quot;,
)
model.disable_talker()

processor = Qwen3OmniMoeProcessor.from_pretrained(MODEL_PATH)

# Conversation with image only
conversation1 = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you see in this image? Answer in one sentence.&quot;},
        ]
    }
]

# Conversation with audio only
conversation2 = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you hear in this audio?&quot;},
        ]
    }
]

# Conversation with pure text and system prompt
conversation3 = [
    {
        &quot;role&quot;: &quot;system&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;You are Qwen-Omni.&quot;}
        ],
    },
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Who are you?&quot;
    }
]

# Conversation with mixed media
conversation4 = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg&quot;},
            {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you see and hear? Answer in one sentence.&quot;}
        ],
    }
]

# Combine messages for batch processing
conversations = [conversation1, conversation2, conversation3, conversation4]

# Set whether to use audio in video
USE_AUDIO_IN_VIDEO = True

# Preparation for batch inference
text = processor.apply_chat_template(conversations, add_generation_prompt=True, tokenize=False)
audios, images, videos = process_mm_info(conversations, use_audio_in_video=USE_AUDIO_IN_VIDEO)

inputs = processor(text=text, 
                   audio=audios, 
                   images=images, 
                   videos=videos, 
                   return_tensors=&quot;pt&quot;, 
                   padding=True, 
                   use_audio_in_video=USE_AUDIO_IN_VIDEO)
inputs = inputs.to(model.device).to(model.dtype)

# Batch inference does not support returning audio
text_ids, audio = model.generate(**inputs,
                                 return_audio=False,
                                 thinker_return_dict_in_generate=True,
                                 use_audio_in_video=USE_AUDIO_IN_VIDEO)

text = processor.batch_decode(text_ids.sequences[:, inputs[&quot;input_ids&quot;].shape[1] :],
                              skip_special_tokens=True,
                              clean_up_tokenization_spaces=False)
print(text)"><pre><span>from</span> <span>transformers</span> <span>import</span> <span>Qwen3OmniMoeForConditionalGeneration</span>, <span>Qwen3OmniMoeProcessor</span>
<span>from</span> <span>qwen_omni_utils</span> <span>import</span> <span>process_mm_info</span>

<span>MODEL_PATH</span> <span>=</span> <span>"Qwen/Qwen3-Omni-30B-A3B-Instruct"</span>
<span># MODEL_PATH = "Qwen/Qwen3-Omni-30B-A3B-Thinking"</span>

<span>model</span> <span>=</span> <span>Qwen3OmniMoeForConditionalGeneration</span>.<span>from_pretrained</span>(
    <span>MODEL_PATH</span>,
    <span>dtype</span><span>=</span><span>"auto"</span>,
    <span>device_map</span><span>=</span><span>"auto"</span>,
    <span>attn_implementation</span><span>=</span><span>"flash_attention_2"</span>,
)
<span>model</span>.<span>disable_talker</span>()

<span>processor</span> <span>=</span> <span>Qwen3OmniMoeProcessor</span>.<span>from_pretrained</span>(<span>MODEL_PATH</span>)

<span># Conversation with image only</span>
<span>conversation1</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you see in this image? Answer in one sentence."</span>},
        ]
    }
]

<span># Conversation with audio only</span>
<span>conversation2</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you hear in this audio?"</span>},
        ]
    }
]

<span># Conversation with pure text and system prompt</span>
<span>conversation3</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"system"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"You are Qwen-Omni."</span>}
        ],
    },
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: <span>"Who are you?"</span>
    }
]

<span># Conversation with mixed media</span>
<span>conversation4</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg"</span>},
            {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you see and hear? Answer in one sentence."</span>}
        ],
    }
]

<span># Combine messages for batch processing</span>
<span>conversations</span> <span>=</span> [<span>conversation1</span>, <span>conversation2</span>, <span>conversation3</span>, <span>conversation4</span>]

<span># Set whether to use audio in video</span>
<span>USE_AUDIO_IN_VIDEO</span> <span>=</span> <span>True</span>

<span># Preparation for batch inference</span>
<span>text</span> <span>=</span> <span>processor</span>.<span>apply_chat_template</span>(<span>conversations</span>, <span>add_generation_prompt</span><span>=</span><span>True</span>, <span>tokenize</span><span>=</span><span>False</span>)
<span>audios</span>, <span>images</span>, <span>videos</span> <span>=</span> <span>process_mm_info</span>(<span>conversations</span>, <span>use_audio_in_video</span><span>=</span><span>USE_AUDIO_IN_VIDEO</span>)

<span>inputs</span> <span>=</span> <span>processor</span>(<span>text</span><span>=</span><span>text</span>, 
                   <span>audio</span><span>=</span><span>audios</span>, 
                   <span>images</span><span>=</span><span>images</span>, 
                   <span>videos</span><span>=</span><span>videos</span>, 
                   <span>return_tensors</span><span>=</span><span>"pt"</span>, 
                   <span>padding</span><span>=</span><span>True</span>, 
                   <span>use_audio_in_video</span><span>=</span><span>USE_AUDIO_IN_VIDEO</span>)
<span>inputs</span> <span>=</span> <span>inputs</span>.<span>to</span>(<span>model</span>.<span>device</span>).<span>to</span>(<span>model</span>.<span>dtype</span>)

<span># Batch inference does not support returning audio</span>
<span>text_ids</span>, <span>audio</span> <span>=</span> <span>model</span>.<span>generate</span>(<span>**</span><span>inputs</span>,
                                 <span>return_audio</span><span>=</span><span>False</span>,
                                 <span>thinker_return_dict_in_generate</span><span>=</span><span>True</span>,
                                 <span>use_audio_in_video</span><span>=</span><span>USE_AUDIO_IN_VIDEO</span>)

<span>text</span> <span>=</span> <span>processor</span>.<span>batch_decode</span>(<span>text_ids</span>.<span>sequences</span>[:, <span>inputs</span>[<span>"input_ids"</span>].<span>shape</span>[<span>1</span>] :],
                              <span>skip_special_tokens</span><span>=</span><span>True</span>,
                              <span>clean_up_tokenization_spaces</span><span>=</span><span>False</span>)
<span>print</span>(<span>text</span>)</pre></div>
</details>
<details>
<summary>Use audio output or not</summary>
<p dir="auto">The model supports both text and audio outputs. If users do not need audio outputs, they can call <code>model.disable_talker()</code> after initializing the model. This option will save about <code>10GB</code> of GPU memory, but the <code>return_audio</code> option for the <code>generate</code> function will only allow <code>False</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="model = Qwen3OmniMoeForConditionalGeneration.from_pretrained(
    &quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;,
    dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;,
    attn_implementation=&quot;flash_attention_2&quot;,
)
model.disable_talker()"><pre><span>model</span> <span>=</span> <span>Qwen3OmniMoeForConditionalGeneration</span>.<span>from_pretrained</span>(
    <span>"Qwen/Qwen3-Omni-30B-A3B-Instruct"</span>,
    <span>dtype</span><span>=</span><span>"auto"</span>,
    <span>device_map</span><span>=</span><span>"auto"</span>,
    <span>attn_implementation</span><span>=</span><span>"flash_attention_2"</span>,
)
<span>model</span>.<span>disable_talker</span>()</pre></div>
<p dir="auto">For a more flexible experience, we recommend that users decide whether to return audio when the <code>generate</code> function is called. If <code>return_audio</code> is set to <code>False</code>, the model will only return text outputs, resulting in faster text responses.</p>
<div dir="auto" data-snippet-clipboard-copy-content="model = Qwen3OmniMoeForConditionalGeneration.from_pretrained(
    &quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;,
    dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;,
    attn_implementation=&quot;flash_attention_2&quot;,
)
...
text_ids, _ = model.generate(..., return_audio=False)```

</details>

<details>
<summary>Change voice type of output audio</summary>

Qwen3-Omni supports changing the voice of the output audio. The `&quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;` checkpoint supports three voice types as follows:

| Voice Type | Gender | Description |
|------------|--------|-------------|
| Ethan      | Male   | A bright, upbeat voice with infectious energy and a warm, approachable vibe. |
| Chelsie    | Female | A honeyed, velvety voice that carries a gentle warmth and luminous clarity. |
| Aiden      | Male   | A warm, laid-back American voice with a gentle, boyish charm. |

Users can use the `speaker` parameter of the `generate` function to specify the voice type. By default, if `speaker` is not specified, the voice type is `Ethan`.

```python
text_ids, audio = model.generate(..., speaker=&quot;Ethan&quot;)"><pre><span>model</span> <span>=</span> <span>Qwen3OmniMoeForConditionalGeneration</span>.<span>from_pretrained</span>(
    <span>"Qwen/Qwen3-Omni-30B-A3B-Instruct"</span>,
    <span>dtype</span><span>=</span><span>"auto"</span>,
    <span>device_map</span><span>=</span><span>"auto"</span>,
    <span>attn_implementation</span><span>=</span><span>"flash_attention_2"</span>,
)
...
<span>text_ids</span>, <span>_</span> <span>=</span> <span>model</span>.<span>generate</span>(..., <span>return_audio</span><span>=</span><span>False</span>)<span>``</span>`

<span>&lt;</span><span>/</span><span>details</span><span>&gt;</span>

<span>&lt;</span><span>details</span><span>&gt;</span>
<span>&lt;</span><span>summary</span><span>&gt;</span><span>Change</span> <span>voice</span> type <span>of</span> <span>output</span> <span>audio</span><span>&lt;</span><span>/</span><span>summary</span><span>&gt;</span>

<span>Qwen3</span><span>-</span><span>Omni</span> <span>supports</span> <span>changing</span> <span>the</span> <span>voice</span> <span>of</span> <span>the</span> <span>output</span> <span>audio</span>. <span>The</span> <span>`"Qwen/Qwen3-Omni-30B-A3B-Instruct"`</span> <span>checkpoint</span> <span>supports</span> <span>three</span> <span>voice</span> <span>types</span> <span>as</span> <span>follows</span>:

<span>|</span> <span>Voice</span> <span>Type</span> <span>|</span> <span>Gender</span> <span>|</span> <span>Description</span> <span>|</span>
<span>|</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>|</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>|</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>-</span><span>|</span>
<span>|</span> <span>Ethan</span>      <span>|</span> <span>Male</span>   <span>|</span> <span>A</span> <span>bright</span>, <span>upbeat</span> <span>voice</span> <span>with</span> <span>infectious</span> <span>energy</span> <span>and</span> <span>a</span> <span>warm</span>, <span>approachable</span> <span>vibe</span>. <span>|</span>
<span>|</span> <span>Chelsie</span>    <span>|</span> <span>Female</span> <span>|</span> <span>A</span> <span>honeyed</span>, <span>velvety</span> <span>voice</span> <span>that</span> <span>carries</span> <span>a</span> <span>gentle</span> <span>warmth</span> <span>and</span> <span>luminous</span> <span>clarity</span>. <span>|</span>
<span>|</span> <span>Aiden</span>      <span>|</span> <span>Male</span>   <span>|</span> <span>A</span> <span>warm</span>, <span>laid</span><span>-</span><span>back</span> <span>American</span> <span>voice</span> <span>with</span> <span>a</span> <span>gentle</span>, <span>boyish</span> <span>charm</span>. <span>|</span>

<span>Users</span> <span>can</span> <span>use</span> <span>the</span> <span>`speaker`</span> <span>parameter</span> <span>of</span> <span>the</span> <span>`generate`</span> <span>function</span> <span>to</span> <span>specify</span> <span>the</span> <span>voice</span> <span>type</span>. <span>By</span> <span>default</span>, <span>if</span> <span>`speaker`</span> <span><span>is</span> <span>not</span></span> <span>specified</span>, <span>the</span> <span>voice</span> <span>type</span> <span>is</span> <span>`Ethan`</span>.

<span>``</span>`<span>python</span>
<span>text_ids</span>, <span>audio</span> <span>=</span> <span>model</span>.<span>generate</span>(..., <span>speaker</span><span>=</span><span>"Ethan"</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="text_ids, audio = model.generate(..., speaker=&quot;Chelsie&quot;)"><pre><span>text_ids</span>, <span>audio</span> <span>=</span> <span>model</span>.<span>generate</span>(..., <span>speaker</span><span>=</span><span>"Chelsie"</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="text_ids, audio = model.generate(..., speaker=&quot;Aiden&quot;)"><pre><span>text_ids</span>, <span>audio</span> <span>=</span> <span>model</span>.<span>generate</span>(..., <span>speaker</span><span>=</span><span>"Aiden"</span>)</pre></div>
</details>
<p dir="auto">Additionally, for more usage details such as prompt settings, task-specific usage methods, and resource requirements, please refer to <a href="#usage-tips-recommended-reading">Usage Tips</a> and <a href="#cookbooks-for-usage-cases">Cookbooks for Usage Cases</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">vLLM Usage</h3><a id="user-content-vllm-usage" aria-label="Permalink: vLLM Usage" href="#vllm-usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation-1" aria-label="Permalink: Installation" href="#installation-1"></a></p>
<p dir="auto">We strongly recommend using vLLM for inference and deployment of the Qwen3-Omni series models. Since our code is currently in the pull request stage, and <strong>audio output inference support for the Instruct model will be released in the near future</strong>, you can follow the commands below to install vLLM from source. Please note that we recommend you <strong>create a new Python environment</strong> or use our provided <a href="#-docker">Docker</a> to avoid runtime environment conflicts and incompatibilities. For more details on compiling vLLM from source, please refer to the <a href="https://docs.vllm.ai/en/latest/getting_started/installation/gpu.html#set-up-using-python-only-build-without-compilation" rel="nofollow">vLLM official documentation</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone -b qwen3_omni https://github.com/wangxiongts/vllm.git
cd vllm
pip install -r requirements/build.txt
pip install -r requirements/cuda.txt
export VLLM_PRECOMPILED_WHEEL_LOCATION=https://wheels.vllm.ai/a5dd03c1ebc5e4f56f3c9d3dc0436e9c582c978f/vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl
VLLM_USE_PRECOMPILED=1 pip install -e . -v --no-build-isolation
# If you meet an &quot;Undefined symbol&quot; error while using VLLM_USE_PRECOMPILED=1, please use &quot;pip install -e . -v&quot; to build from source.
# Install the Transformers
pip install git+https://github.com/huggingface/transformers
pip install accelerate
pip install qwen-omni-utils -U
pip install -U flash-attn --no-build-isolation"><pre>git clone -b qwen3_omni https://github.com/wangxiongts/vllm.git
<span>cd</span> vllm
pip install -r requirements/build.txt
pip install -r requirements/cuda.txt
<span>export</span> VLLM_PRECOMPILED_WHEEL_LOCATION=https://wheels.vllm.ai/a5dd03c1ebc5e4f56f3c9d3dc0436e9c582c978f/vllm-0.9.2-cp38-abi3-manylinux1_x86_64.whl
VLLM_USE_PRECOMPILED=1 pip install -e <span>.</span> -v --no-build-isolation
<span><span>#</span> If you meet an "Undefined symbol" error while using VLLM_USE_PRECOMPILED=1, please use "pip install -e . -v" to build from source.</span>
<span><span>#</span> Install the Transformers</span>
pip install git+https://github.com/huggingface/transformers
pip install accelerate
pip install qwen-omni-utils -U
pip install -U flash-attn --no-build-isolation</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Inference</h4><a id="user-content-inference" aria-label="Permalink: Inference" href="#inference"></a></p>
<p dir="auto">You can use the following code for vLLM inference. The <code>limit_mm_per_prompt</code> parameter specifies the maximum number of each modality's data allowed per message. Since vLLM needs to pre-allocate GPU memory, larger values will require more GPU memory; if OOM issues occur, try reducing this value. Setting <code>tensor_parallel_size</code> greater than one enables multi-GPU parallel inference, improving concurrency and throughput. In addition, <code>max_num_seqs</code> indicates the number of sequences that vLLM processes in parallel during each inference step. A larger value requires more GPU memory but enables higher batch inference speed. For more details, please refer to the <a href="https://docs.vllm.ai/en/latest/api/vllm/index.html#vllm.LLM" rel="nofollow">vLLM official documentation</a>. Below is a simple example of how to run Qwen3-Omni with vLLM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import os
import torch

from vllm import LLM, SamplingParams
from transformers import Qwen3OmniMoeProcessor
from qwen_omni_utils import process_mm_info

if __name__ == '__main__':
    # vLLM engine v1 not supported yet
    os.environ['VLLM_USE_V1'] = '0'

    MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;
    # MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Thinking&quot;

    llm = LLM(
            model=MODEL_PATH, trust_remote_code=True, gpu_memory_utilization=0.95,
            tensor_parallel_size=torch.cuda.device_count(),
            limit_mm_per_prompt={'image': 3, 'video': 3, 'audio': 3},
            max_num_seqs=8,
            max_model_len=32768,
            seed=1234,
    )

    sampling_params = SamplingParams(
        temperature=0.6,
        top_p=0.95,
        top_k=20,
        max_tokens=16384,
    )

    processor = Qwen3OmniMoeProcessor.from_pretrained(MODEL_PATH)

    messages = [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {&quot;type&quot;: &quot;video&quot;, &quot;video&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/draw.mp4&quot;}
            ], 
        }
    ]

    text = processor.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
    )
    audios, images, videos = process_mm_info(messages, use_audio_in_video=True)

    inputs = {
        'prompt': text,
        'multi_modal_data': {},
        &quot;mm_processor_kwargs&quot;: {
            &quot;use_audio_in_video&quot;: True,
        },
    }

    if images is not None:
        inputs['multi_modal_data']['image'] = images
    if videos is not None:
        inputs['multi_modal_data']['video'] = videos
    if audios is not None:
        inputs['multi_modal_data']['audio'] = audios

    outputs = llm.generate([inputs], sampling_params=sampling_params)

    print(outputs[0].outputs[0].text)"><pre><span>import</span> <span>os</span>
<span>import</span> <span>torch</span>

<span>from</span> <span>vllm</span> <span>import</span> <span>LLM</span>, <span>SamplingParams</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>Qwen3OmniMoeProcessor</span>
<span>from</span> <span>qwen_omni_utils</span> <span>import</span> <span>process_mm_info</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span>:
    <span># vLLM engine v1 not supported yet</span>
    <span>os</span>.<span>environ</span>[<span>'VLLM_USE_V1'</span>] <span>=</span> <span>'0'</span>

    <span>MODEL_PATH</span> <span>=</span> <span>"Qwen/Qwen3-Omni-30B-A3B-Instruct"</span>
    <span># MODEL_PATH = "Qwen/Qwen3-Omni-30B-A3B-Thinking"</span>

    <span>llm</span> <span>=</span> <span>LLM</span>(
            <span>model</span><span>=</span><span>MODEL_PATH</span>, <span>trust_remote_code</span><span>=</span><span>True</span>, <span>gpu_memory_utilization</span><span>=</span><span>0.95</span>,
            <span>tensor_parallel_size</span><span>=</span><span>torch</span>.<span>cuda</span>.<span>device_count</span>(),
            <span>limit_mm_per_prompt</span><span>=</span>{<span>'image'</span>: <span>3</span>, <span>'video'</span>: <span>3</span>, <span>'audio'</span>: <span>3</span>},
            <span>max_num_seqs</span><span>=</span><span>8</span>,
            <span>max_model_len</span><span>=</span><span>32768</span>,
            <span>seed</span><span>=</span><span>1234</span>,
    )

    <span>sampling_params</span> <span>=</span> <span>SamplingParams</span>(
        <span>temperature</span><span>=</span><span>0.6</span>,
        <span>top_p</span><span>=</span><span>0.95</span>,
        <span>top_k</span><span>=</span><span>20</span>,
        <span>max_tokens</span><span>=</span><span>16384</span>,
    )

    <span>processor</span> <span>=</span> <span>Qwen3OmniMoeProcessor</span>.<span>from_pretrained</span>(<span>MODEL_PATH</span>)

    <span>messages</span> <span>=</span> [
        {
            <span>"role"</span>: <span>"user"</span>,
            <span>"content"</span>: [
                {<span>"type"</span>: <span>"video"</span>, <span>"video"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/draw.mp4"</span>}
            ], 
        }
    ]

    <span>text</span> <span>=</span> <span>processor</span>.<span>apply_chat_template</span>(
        <span>messages</span>,
        <span>tokenize</span><span>=</span><span>False</span>,
        <span>add_generation_prompt</span><span>=</span><span>True</span>,
    )
    <span>audios</span>, <span>images</span>, <span>videos</span> <span>=</span> <span>process_mm_info</span>(<span>messages</span>, <span>use_audio_in_video</span><span>=</span><span>True</span>)

    <span>inputs</span> <span>=</span> {
        <span>'prompt'</span>: <span>text</span>,
        <span>'multi_modal_data'</span>: {},
        <span>"mm_processor_kwargs"</span>: {
            <span>"use_audio_in_video"</span>: <span>True</span>,
        },
    }

    <span>if</span> <span>images</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
        <span>inputs</span>[<span>'multi_modal_data'</span>][<span>'image'</span>] <span>=</span> <span>images</span>
    <span>if</span> <span>videos</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
        <span>inputs</span>[<span>'multi_modal_data'</span>][<span>'video'</span>] <span>=</span> <span>videos</span>
    <span>if</span> <span>audios</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
        <span>inputs</span>[<span>'multi_modal_data'</span>][<span>'audio'</span>] <span>=</span> <span>audios</span>

    <span>outputs</span> <span>=</span> <span>llm</span>.<span>generate</span>([<span>inputs</span>], <span>sampling_params</span><span>=</span><span>sampling_params</span>)

    <span>print</span>(<span>outputs</span>[<span>0</span>].<span>outputs</span>[<span>0</span>].<span>text</span>)</pre></div>
<p dir="auto">Here are some more advanced usage examples. You can expand the sections below to learn more.</p>
<details>
<summary>Batch inference</summary>
<p dir="auto">Using vLLM enables fast batch inference, which can help you efficiently process large volumes of data or conduct benchmarking. Refer to the following code example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import os
import torch

from vllm import LLM, SamplingParams
from transformers import Qwen3OmniMoeProcessor
from qwen_omni_utils import process_mm_info

def build_input(processor, messages, use_audio_in_video):
    text = processor.apply_chat_template(
        messages,
        tokenize=False,
        add_generation_prompt=True,
    )
    audios, images, videos = process_mm_info(messages, use_audio_in_video=use_audio_in_video)

    inputs = {
        'prompt': text,
        'multi_modal_data': {},
        &quot;mm_processor_kwargs&quot;: {
            &quot;use_audio_in_video&quot;: use_audio_in_video,
        },
    }

    if images is not None:
        inputs['multi_modal_data']['image'] = images
    if videos is not None:
        inputs['multi_modal_data']['video'] = videos
    if audios is not None:
        inputs['multi_modal_data']['audio'] = audios
    
    return inputs

if __name__ == '__main__':
    # vLLM engine v1 not supported yet
    os.environ['VLLM_USE_V1'] = '0'

    MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Instruct&quot;
    # MODEL_PATH = &quot;Qwen/Qwen3-Omni-30B-A3B-Thinking&quot;

    llm = LLM(
            model=MODEL_PATH, trust_remote_code=True, gpu_memory_utilization=0.95,
            tensor_parallel_size=torch.cuda.device_count(),
            limit_mm_per_prompt={'image': 3, 'video': 3, 'audio': 3},
            max_num_seqs=8,
            max_model_len=32768,
            seed=1234,
    )

    sampling_params = SamplingParams(
        temperature=0.6,
        top_p=0.95,
        top_k=20,
        max_tokens=16384,
    )

    processor = Qwen3OmniMoeProcessor.from_pretrained(MODEL_PATH)

    # Conversation with image only
    conversation1 = [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg&quot;},
                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you see in this image? Answer in one sentence.&quot;},
            ]
        }
    ]

    # Conversation with audio only
    conversation2 = [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav&quot;},
                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you hear in this audio?&quot;},
            ]
        }
    ]

    # Conversation with pure text and system prompt
    conversation3 = [
        {
            &quot;role&quot;: &quot;system&quot;,
            &quot;content&quot;: [
                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;You are Qwen-Omni.&quot;}
            ],
        },
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;Who are you? Answer in one sentence.&quot;
        }
    ]

    # Conversation with mixed media
    conversation4 = [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: [
                {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg&quot;},
                {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/cookbook/asr_fr.wav&quot;},
                {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you see and hear? Answer in one sentence.&quot;}
            ],
        }
    ]
    
    USE_AUDIO_IN_VIDEO = True

    # Combine messages for batch processing
    conversations = [conversation1, conversation2, conversation3, conversation4]
    inputs = [build_input(processor, messages, USE_AUDIO_IN_VIDEO) for messages in conversations]

    outputs = llm.generate(inputs, sampling_params=sampling_params)

    result = [outputs[i].outputs[0].text for i in range(len(outputs))]
    print(result)"><pre><span>import</span> <span>os</span>
<span>import</span> <span>torch</span>

<span>from</span> <span>vllm</span> <span>import</span> <span>LLM</span>, <span>SamplingParams</span>
<span>from</span> <span>transformers</span> <span>import</span> <span>Qwen3OmniMoeProcessor</span>
<span>from</span> <span>qwen_omni_utils</span> <span>import</span> <span>process_mm_info</span>

<span>def</span> <span>build_input</span>(<span>processor</span>, <span>messages</span>, <span>use_audio_in_video</span>):
    <span>text</span> <span>=</span> <span>processor</span>.<span>apply_chat_template</span>(
        <span>messages</span>,
        <span>tokenize</span><span>=</span><span>False</span>,
        <span>add_generation_prompt</span><span>=</span><span>True</span>,
    )
    <span>audios</span>, <span>images</span>, <span>videos</span> <span>=</span> <span>process_mm_info</span>(<span>messages</span>, <span>use_audio_in_video</span><span>=</span><span>use_audio_in_video</span>)

    <span>inputs</span> <span>=</span> {
        <span>'prompt'</span>: <span>text</span>,
        <span>'multi_modal_data'</span>: {},
        <span>"mm_processor_kwargs"</span>: {
            <span>"use_audio_in_video"</span>: <span>use_audio_in_video</span>,
        },
    }

    <span>if</span> <span>images</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
        <span>inputs</span>[<span>'multi_modal_data'</span>][<span>'image'</span>] <span>=</span> <span>images</span>
    <span>if</span> <span>videos</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
        <span>inputs</span>[<span>'multi_modal_data'</span>][<span>'video'</span>] <span>=</span> <span>videos</span>
    <span>if</span> <span>audios</span> <span><span>is</span> <span>not</span></span> <span>None</span>:
        <span>inputs</span>[<span>'multi_modal_data'</span>][<span>'audio'</span>] <span>=</span> <span>audios</span>
    
    <span>return</span> <span>inputs</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>'__main__'</span>:
    <span># vLLM engine v1 not supported yet</span>
    <span>os</span>.<span>environ</span>[<span>'VLLM_USE_V1'</span>] <span>=</span> <span>'0'</span>

    <span>MODEL_PATH</span> <span>=</span> <span>"Qwen/Qwen3-Omni-30B-A3B-Instruct"</span>
    <span># MODEL_PATH = "Qwen/Qwen3-Omni-30B-A3B-Thinking"</span>

    <span>llm</span> <span>=</span> <span>LLM</span>(
            <span>model</span><span>=</span><span>MODEL_PATH</span>, <span>trust_remote_code</span><span>=</span><span>True</span>, <span>gpu_memory_utilization</span><span>=</span><span>0.95</span>,
            <span>tensor_parallel_size</span><span>=</span><span>torch</span>.<span>cuda</span>.<span>device_count</span>(),
            <span>limit_mm_per_prompt</span><span>=</span>{<span>'image'</span>: <span>3</span>, <span>'video'</span>: <span>3</span>, <span>'audio'</span>: <span>3</span>},
            <span>max_num_seqs</span><span>=</span><span>8</span>,
            <span>max_model_len</span><span>=</span><span>32768</span>,
            <span>seed</span><span>=</span><span>1234</span>,
    )

    <span>sampling_params</span> <span>=</span> <span>SamplingParams</span>(
        <span>temperature</span><span>=</span><span>0.6</span>,
        <span>top_p</span><span>=</span><span>0.95</span>,
        <span>top_k</span><span>=</span><span>20</span>,
        <span>max_tokens</span><span>=</span><span>16384</span>,
    )

    <span>processor</span> <span>=</span> <span>Qwen3OmniMoeProcessor</span>.<span>from_pretrained</span>(<span>MODEL_PATH</span>)

    <span># Conversation with image only</span>
    <span>conversation1</span> <span>=</span> [
        {
            <span>"role"</span>: <span>"user"</span>,
            <span>"content"</span>: [
                {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg"</span>},
                {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you see in this image? Answer in one sentence."</span>},
            ]
        }
    ]

    <span># Conversation with audio only</span>
    <span>conversation2</span> <span>=</span> [
        {
            <span>"role"</span>: <span>"user"</span>,
            <span>"content"</span>: [
                {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav"</span>},
                {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you hear in this audio?"</span>},
            ]
        }
    ]

    <span># Conversation with pure text and system prompt</span>
    <span>conversation3</span> <span>=</span> [
        {
            <span>"role"</span>: <span>"system"</span>,
            <span>"content"</span>: [
                {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"You are Qwen-Omni."</span>}
            ],
        },
        {
            <span>"role"</span>: <span>"user"</span>,
            <span>"content"</span>: <span>"Who are you? Answer in one sentence."</span>
        }
    ]

    <span># Conversation with mixed media</span>
    <span>conversation4</span> <span>=</span> [
        {
            <span>"role"</span>: <span>"user"</span>,
            <span>"content"</span>: [
                {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg"</span>},
                {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/cookbook/asr_fr.wav"</span>},
                {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"What can you see and hear? Answer in one sentence."</span>}
            ],
        }
    ]
    
    <span>USE_AUDIO_IN_VIDEO</span> <span>=</span> <span>True</span>

    <span># Combine messages for batch processing</span>
    <span>conversations</span> <span>=</span> [<span>conversation1</span>, <span>conversation2</span>, <span>conversation3</span>, <span>conversation4</span>]
    <span>inputs</span> <span>=</span> [<span>build_input</span>(<span>processor</span>, <span>messages</span>, <span>USE_AUDIO_IN_VIDEO</span>) <span>for</span> <span>messages</span> <span>in</span> <span>conversations</span>]

    <span>outputs</span> <span>=</span> <span>llm</span>.<span>generate</span>(<span>inputs</span>, <span>sampling_params</span><span>=</span><span>sampling_params</span>)

    <span>result</span> <span>=</span> [<span>outputs</span>[<span>i</span>].<span>outputs</span>[<span>0</span>].<span>text</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>len</span>(<span>outputs</span>))]
    <span>print</span>(<span>result</span>)</pre></div>
</details>
<details>
<summary>vLLM Serve Usage</summary>
<p dir="auto">vLLM serve for Qwen3-Omni currently only supports the thinker model. The <code>use_audio_in_video</code> parameter is not available in vLLM serve; you can handle this by separately passing video and audio inputs for processing. You can start vLLM serve through the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Qwen3-Omni-30B-A3B-Instruct for single GPU
vllm serve Qwen/Qwen3-Omni-30B-A3B-Instruct --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 32768 --allowed-local-media-path / -tp 1
# Qwen3-Omni-30B-A3B-Instruct for multi-GPU (example on 4 GPUs)
vllm serve Qwen/Qwen3-Omni-30B-A3B-Instruct --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 65536 --allowed-local-media-path / -tp 4
# Qwen/Qwen3-Omni-30B-A3B-Thinking for single GPU
vllm serve Qwen/Qwen3-Omni-30B-A3B-Thinking --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 32768 --allowed-local-media-path / -tp 1
# Qwen/Qwen3-Omni-30B-A3B-Thinking for multi-GPU (example on 4 GPUs)
vllm serve Qwen/Qwen3-Omni-30B-A3B-Thinking --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 65536 --allowed-local-media-path / -tp 4"><pre><span><span>#</span> Qwen3-Omni-30B-A3B-Instruct for single GPU</span>
vllm serve Qwen/Qwen3-Omni-30B-A3B-Instruct --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 32768 --allowed-local-media-path / -tp 1
<span><span>#</span> Qwen3-Omni-30B-A3B-Instruct for multi-GPU (example on 4 GPUs)</span>
vllm serve Qwen/Qwen3-Omni-30B-A3B-Instruct --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 65536 --allowed-local-media-path / -tp 4
<span><span>#</span> Qwen/Qwen3-Omni-30B-A3B-Thinking for single GPU</span>
vllm serve Qwen/Qwen3-Omni-30B-A3B-Thinking --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 32768 --allowed-local-media-path / -tp 1
<span><span>#</span> Qwen/Qwen3-Omni-30B-A3B-Thinking for multi-GPU (example on 4 GPUs)</span>
vllm serve Qwen/Qwen3-Omni-30B-A3B-Thinking --port 8901 --host 127.0.0.1 --dtype bfloat16 --max-model-len 65536 --allowed-local-media-path / -tp 4</pre></div>
<p dir="auto">Then you can use the chat API as below (via curl, for example):</p>
<div dir="auto" data-snippet-clipboard-copy-content="curl http://localhost:8901/v1/chat/completions \
    -H &quot;Content-Type: application/json&quot; \
    -d '{
    &quot;messages&quot;: [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [
        {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg&quot;}},
        {&quot;type&quot;: &quot;audio_url&quot;, &quot;audio_url&quot;: {&quot;url&quot;: &quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav&quot;}},
        {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;What can you see and hear? Answer in one sentence.&quot;}
    ]}
    ]
    }'"><pre>curl http://localhost:8901/v1/chat/completions \
    -H <span><span>"</span>Content-Type: application/json<span>"</span></span> \
    -d <span><span>'</span>{</span>
<span>    "messages": [</span>
<span>    {"role": "system", "content": "You are a helpful assistant."},</span>
<span>    {"role": "user", "content": [</span>
<span>        {"type": "image_url", "image_url": {"url": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cars.jpg"}},</span>
<span>        {"type": "audio_url", "audio_url": {"url": "https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Omni/demo/cough.wav"}},</span>
<span>        {"type": "text", "text": "What can you see and hear? Answer in one sentence."}</span>
<span>    ]}</span>
<span>    ]</span>
<span>    }<span>'</span></span></pre></div>
</details>
<p dir="auto">Additionally, for more usage details such as prompt settings, task-specific usage methods, and resource requirements, please refer to <a href="#usage-tips-recommended-reading">Usage Tips</a> and <a href="#cookbooks-for-usage-cases">Cookbooks for Usage Cases</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DashScope API Usage</h3><a id="user-content-dashscope-api-usage" aria-label="Permalink: DashScope API Usage" href="#dashscope-api-usage"></a></p>
<p dir="auto">To further explore Qwen3-Omni, we encourage you to try our DashScope API for a faster and more efficient experience. For detailed API information and documentation, please refer to the following:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>API Description</th>
<th>API Documentation (Mainland China)</th>
<th>API Documentation (International)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Offline API for Qwen3-Omni-Flash, including Instruct and Thinking models</td>
<td><a href="https://help.aliyun.com/zh/model-studio/qwen-omni" rel="nofollow">https://help.aliyun.com/zh/model-studio/qwen-omni</a></td>
<td><a href="https://www.alibabacloud.com/help/en/model-studio/qwen-omni" rel="nofollow">https://www.alibabacloud.com/help/en/model-studio/qwen-omni</a></td>
</tr>
<tr>
<td>Real-time API for Qwen3-Omni-Flash, supporting end-to-end real-time interaction</td>
<td><a href="https://help.aliyun.com/zh/model-studio/realtime" rel="nofollow">https://help.aliyun.com/zh/model-studio/realtime</a></td>
<td><a href="https://www.alibabacloud.com/help/en/model-studio/realtime" rel="nofollow">https://www.alibabacloud.com/help/en/model-studio/realtime</a></td>
</tr>
<tr>
<td>API for Qwen3-Omni-30B-A3B-Captioner model</td>
<td><a href="https://help.aliyun.com/zh/model-studio/qwen3-omni-captioner" rel="nofollow">https://help.aliyun.com/zh/model-studio/qwen3-omni-captioner</a></td>
<td><a href="https://www.alibabacloud.com/help/zh/model-studio/qwen3-omni-captioner" rel="nofollow">https://www.alibabacloud.com/help/zh/model-studio/qwen3-omni-captioner</a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage Tips (Recommended Reading)</h3><a id="user-content-usage-tips-recommended-reading" aria-label="Permalink: Usage Tips (Recommended Reading)" href="#usage-tips-recommended-reading"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Minimum GPU memory requirements</h4><a id="user-content-minimum-gpu-memory-requirements" aria-label="Permalink: Minimum GPU memory requirements" href="#minimum-gpu-memory-requirements"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>Precision</th>
<th>15s Video</th>
<th>30s Video</th>
<th>60s Video</th>
<th>120s Video</th>
</tr>
</thead>
<tbody>
<tr>
<td>Qwen3-Omni-30B-A3B-Instruct</td>
<td>BF16</td>
<td>78.85 GB</td>
<td>88.52 GB</td>
<td>107.74 GB</td>
<td>144.81 GB</td>
</tr>
<tr>
<td>Qwen3-Omni-30B-A3B-Thinking</td>
<td>BF16</td>
<td>68.74 GB</td>
<td>77.79 GB</td>
<td>95.76 GB</td>
<td>131.65 GB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Note</strong>: The table above presents the theoretical minimum memory requirements for inference with <code>transformers</code> and <code>BF16</code> precision, tested with <code>attn_implementation="flash_attention_2"</code>. The Instruct model includes both the <strong>thinker</strong> and <strong>talker</strong> components, whereas the Thinking model includes only the <strong>thinker</strong> part.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prompt for Audio-Visual Interaction</h4><a id="user-content-prompt-for-audio-visual-interaction" aria-label="Permalink: Prompt for Audio-Visual Interaction" href="#prompt-for-audio-visual-interaction"></a></p>
<p dir="auto">When using Qwen3-Omni for audio-visual multimodal interaction, where the input consists of a video and its corresponding audio (with the audio serving as a query), we recommend using the <strong>following system prompt</strong>. This setup helps the model maintain high reasoning capability while better assuming interactive roles such as a smart assistant. Additionally, the text generated by the thinker will be more readable, with a natural, conversational tone and without complex formatting that is difficult to vocalize, leading to more stable and fluent audio output from the talker. You can customize the <code>user_system_prompt</code> field in the system prompt to include character settings or other role-specific descriptions as needed.</p>
<div data-snippet-clipboard-copy-content="user_system_prompt = &quot;You are Qwen-Omni, a smart voice assistant created by Alibaba Qwen.&quot;
message = {
    &quot;role&quot;: &quot;system&quot;,
    &quot;content&quot;: [
          {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: f&quot;{user_system_prompt} You are a virtual voice assistant with no gender or age.\nYou are communicating with the user.\nIn user messages, “I/me/my/we/our” refer to the user and “you/your” refer to the assistant. In your replies, address the user as “you/your” and yourself as “I/me/my”; never mirror the user’s pronouns—always shift perspective. Keep original pronouns only in direct quotes; if a reference is unclear, ask a brief clarifying question.\nInteract with users using short(no more than 50 words), brief, straightforward language, maintaining a natural tone.\nNever use formal phrasing, mechanical expressions, bullet points, overly structured language. \nYour output must consist only of the spoken content you want the user to hear. \nDo not include any descriptions of actions, emotions, sounds, or voice changes. \nDo not use asterisks, brackets, parentheses, or any other symbols to indicate tone or actions. \nYou must answer users' audio or text questions, do not directly describe the video content. \nYou should communicate in the same language strictly as the user unless they request otherwise.\nWhen you are uncertain (e.g., you can't see/hear clearly, don't understand, or the user makes a comment rather than asking a question), use appropriate questions to guide the user to continue the conversation.\nKeep replies concise and conversational, as if talking face-to-face.&quot;}
    ]
}"><pre><code>user_system_prompt = "You are Qwen-Omni, a smart voice assistant created by Alibaba Qwen."
message = {
    "role": "system",
    "content": [
          {"type": "text", "text": f"{user_system_prompt} You are a virtual voice assistant with no gender or age.\nYou are communicating with the user.\nIn user messages, “I/me/my/we/our” refer to the user and “you/your” refer to the assistant. In your replies, address the user as “you/your” and yourself as “I/me/my”; never mirror the user’s pronouns—always shift perspective. Keep original pronouns only in direct quotes; if a reference is unclear, ask a brief clarifying question.\nInteract with users using short(no more than 50 words), brief, straightforward language, maintaining a natural tone.\nNever use formal phrasing, mechanical expressions, bullet points, overly structured language. \nYour output must consist only of the spoken content you want the user to hear. \nDo not include any descriptions of actions, emotions, sounds, or voice changes. \nDo not use asterisks, brackets, parentheses, or any other symbols to indicate tone or actions. \nYou must answer users' audio or text questions, do not directly describe the video content. \nYou should communicate in the same language strictly as the user unless they request otherwise.\nWhen you are uncertain (e.g., you can't see/hear clearly, don't understand, or the user makes a comment rather than asking a question), use appropriate questions to guide the user to continue the conversation.\nKeep replies concise and conversational, as if talking face-to-face."}
    ]
}
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Best Practices for the Thinking Model</h4><a id="user-content-best-practices-for-the-thinking-model" aria-label="Permalink: Best Practices for the Thinking Model" href="#best-practices-for-the-thinking-model"></a></p>
<p dir="auto">The <code>Qwen3-Omni-30B-A3B-Thinking</code> model is primarily designed for understanding and interacting with multimodal inputs, including text, audio, image, and video. To achieve optimal performance, we recommend that users include an explicit textual instruction or task description in each round of dialogue alongside the multimodal input. This helps clarify the intent and significantly enhances the model's ability to leverage its reasoning capabilities. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;/path/to/audio.wav&quot;},
            {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;/path/to/image.png&quot;},
            {&quot;type&quot;: &quot;video&quot;, &quot;video&quot;: &quot;/path/to/video.mp4&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Analyze this audio, image, and video together.&quot;},
        ], 
    }
]"><pre><span>messages</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"/path/to/audio.wav"</span>},
            {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"/path/to/image.png"</span>},
            {<span>"type"</span>: <span>"video"</span>, <span>"video"</span>: <span>"/path/to/video.mp4"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"Analyze this audio, image, and video together."</span>},
        ], 
    }
]</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Use audio in video</h4><a id="user-content-use-audio-in-video" aria-label="Permalink: Use audio in video" href="#use-audio-in-video"></a></p>
<p dir="auto">In multimodal interaction, user-provided videos are often accompanied by audio (such as spoken questions or sounds from events in the video). This information helps the model provide a better interactive experience. We provide the following options for users to decide whether to use the audio from a video.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# In data preprocessing
audios, images, videos = process_mm_info(messages, use_audio_in_video=True)"><pre><span># In data preprocessing</span>
<span>audios</span>, <span>images</span>, <span>videos</span> <span>=</span> <span>process_mm_info</span>(<span>messages</span>, <span>use_audio_in_video</span><span>=</span><span>True</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# For Transformers
text = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)
inputs = processor(text=text, audio=audios, images=images, videos=videos, return_tensors=&quot;pt&quot;, 
                   padding=True, use_audio_in_video=True)
text_ids, audio = model.generate(..., use_audio_in_video=True)

# For vLLM
text = processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)
inputs = {
    'prompt': text,
    'multi_modal_data': {},
    &quot;mm_processor_kwargs&quot;: {
        &quot;use_audio_in_video&quot;: True,
    },
}"><pre><span># For Transformers</span>
<span>text</span> <span>=</span> <span>processor</span>.<span>apply_chat_template</span>(<span>messages</span>, <span>add_generation_prompt</span><span>=</span><span>True</span>, <span>tokenize</span><span>=</span><span>False</span>)
<span>inputs</span> <span>=</span> <span>processor</span>(<span>text</span><span>=</span><span>text</span>, <span>audio</span><span>=</span><span>audios</span>, <span>images</span><span>=</span><span>images</span>, <span>videos</span><span>=</span><span>videos</span>, <span>return_tensors</span><span>=</span><span>"pt"</span>, 
                   <span>padding</span><span>=</span><span>True</span>, <span>use_audio_in_video</span><span>=</span><span>True</span>)
<span>text_ids</span>, <span>audio</span> <span>=</span> <span>model</span>.<span>generate</span>(..., <span>use_audio_in_video</span><span>=</span><span>True</span>)

<span># For vLLM</span>
<span>text</span> <span>=</span> <span>processor</span>.<span>apply_chat_template</span>(<span>messages</span>, <span>add_generation_prompt</span><span>=</span><span>True</span>, <span>tokenize</span><span>=</span><span>False</span>)
<span>inputs</span> <span>=</span> {
    <span>'prompt'</span>: <span>text</span>,
    <span>'multi_modal_data'</span>: {},
    <span>"mm_processor_kwargs"</span>: {
        <span>"use_audio_in_video"</span>: <span>True</span>,
    },
}</pre></div>
<p dir="auto">It is worth noting that during a multi-round conversation, the <code>use_audio_in_video</code> parameter must be set consistently across these steps; otherwise, unexpected results may occur.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interaction with Qwen3-Omni</h2><a id="user-content-interaction-with-qwen3-omni" aria-label="Permalink: Interaction with Qwen3-Omni" href="#interaction-with-qwen3-omni"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Online Demo</h3><a id="user-content-online-demo" aria-label="Permalink: Online Demo" href="#online-demo"></a></p>
<p dir="auto">Without local deployment, you can experience an online web demo directly by visiting our <a href="https://huggingface.co/spaces/Qwen/Qwen3-Omni-Demo" rel="nofollow">Hugging Face Spaces</a> and <a href="https://modelscope.cn/studios/Qwen/Qwen3-Omni-Demo" rel="nofollow">ModelScope Studio</a>. This includes quick hands-on experiences for Qwen3-Omni-Realtime, Qwen3-Omni (Instruct and Thinking), and Qwen3-Omni-30B-A3B-Captioner.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Real-Time Interaction</h3><a id="user-content-real-time-interaction" aria-label="Permalink: Real-Time Interaction" href="#real-time-interaction"></a></p>
<p dir="auto">Real-time streaming interaction with Qwen3-Omni is available now. Please visit <a href="https://chat.qwen.ai/" rel="nofollow">Qwen Chat</a> and select the voice/video call option in the chat box to experience it.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Launch Local Web UI Demo</h3><a id="user-content-launch-local-web-ui-demo" aria-label="Permalink: Launch Local Web UI Demo" href="#launch-local-web-ui-demo"></a></p>
<p dir="auto">In this section, we provide instructions for users to build a web-based user interface (UI) demo. This UI demo allows users to interact with the model through a web browser. Follow the steps below to get start :)</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installation</h4><a id="user-content-installation-2" aria-label="Permalink: Installation" href="#installation-2"></a></p>
<p dir="auto">Before you begin, we strongly recommend that you refer to the <strong>Installation</strong> section in <a href="#vllm-usage">vLLM Usage</a> to set up your environment, which will allow you to seamlessly use both the vLLM and Transformers backends. However, if you only intend to use the Transformers backend (<strong>note that this will result in significantly slower inference</strong>), please follow the installation instructions in <a href="#transformers-usage">Transformers Usage</a>. That said, we still highly recommend using our <a href="#-docker">Docker</a> image to avoid potential environment-related issues. Additionally, if you are running locally, make sure your system has <code>ffmpeg</code> installed and you install the following dependencies:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install gradio==5.44.1 gradio_client==1.12.1 soundfile==0.13.1"><pre>pip install gradio==5.44.1 gradio_client==1.12.1 soundfile==0.13.1</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Running the Demo</h4><a id="user-content-running-the-demo" aria-label="Permalink: Running the Demo" href="#running-the-demo"></a></p>
<p dir="auto">Once the required packages are installed, you can launch the web demo using the following commands. These commands will start a web server and provide you with a link to access the UI in your web browser. You can run <code>python web_demo.py --help</code> and <code>python web_demo_captioner.py --help</code> to learn about more options.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# For Qwen3-Omni-30B-A3B-Instruct with vLLM backend
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct
# For Qwen3-Omni-30B-A3B-Instruct with Transformers backend
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct --use-transformers --generate-audio
# For Qwen3-Omni-30B-A3B-Instruct with Transformers backend and FlashAttention support
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct --use-transformers --generate-audio --flash-attn2"><pre><span><span>#</span> For Qwen3-Omni-30B-A3B-Instruct with vLLM backend</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct
<span><span>#</span> For Qwen3-Omni-30B-A3B-Instruct with Transformers backend</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct --use-transformers --generate-audio
<span><span>#</span> For Qwen3-Omni-30B-A3B-Instruct with Transformers backend and FlashAttention support</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct --use-transformers --generate-audio --flash-attn2</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# For Qwen3-Omni-30B-A3B-Thinking with vLLM backend
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Thinking
# For Qwen3-Omni-30B-A3B-Thinking with Transformers backend
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Thinking --use-transformers
# For Qwen3-Omni-30B-A3B-Thinking with Transformers backend and FlashAttention support
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Thinking --use-transformers --flash-attn2"><pre><span><span>#</span> For Qwen3-Omni-30B-A3B-Thinking with vLLM backend</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Thinking
<span><span>#</span> For Qwen3-Omni-30B-A3B-Thinking with Transformers backend</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Thinking --use-transformers
<span><span>#</span> For Qwen3-Omni-30B-A3B-Thinking with Transformers backend and FlashAttention support</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Thinking --use-transformers --flash-attn2</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# For Qwen3-Omni-30B-A3B-Captioner with vLLM backend
python web_demo_captioner.py -c Qwen/Qwen3-Omni-30B-A3B-Captioner
# For Qwen3-Omni-30B-A3B-Captioner with Transformers backend
python web_demo_captioner.py -c Qwen/Qwen3-Omni-30B-A3B-Captioner --use-transformers
# For Qwen3-Omni-30B-A3B-Captioner with Transformers backend and FlashAttention support
python web_demo_captioner.py -c Qwen/Qwen3-Omni-30B-A3B-Captioner --use-transformers --flash-attn2"><pre><span><span>#</span> For Qwen3-Omni-30B-A3B-Captioner with vLLM backend</span>
python web_demo_captioner.py -c Qwen/Qwen3-Omni-30B-A3B-Captioner
<span><span>#</span> For Qwen3-Omni-30B-A3B-Captioner with Transformers backend</span>
python web_demo_captioner.py -c Qwen/Qwen3-Omni-30B-A3B-Captioner --use-transformers
<span><span>#</span> For Qwen3-Omni-30B-A3B-Captioner with Transformers backend and FlashAttention support</span>
python web_demo_captioner.py -c Qwen/Qwen3-Omni-30B-A3B-Captioner --use-transformers --flash-attn2</pre></div>
<p dir="auto">After running the command, you’ll see a link generated in the terminal similar to this:</p>
<div data-snippet-clipboard-copy-content="Running on local: http://127.0.0.1:8901/"><pre><code>Running on local: http://127.0.0.1:8901/
</code></pre></div>
<p dir="auto">If you are running locally, copy this link and paste it into your browser to access the web UI. If you are running on a server or in a <code>docker</code> container, please configure the address according to the server's actual IP, or set up port forwarding where necessary. For instructions on how to configure port forwarding from the official <code>docker</code> container to the host machine, please refer to <a href="#-docker">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🐳 Docker</h2><a id="user-content--docker" aria-label="Permalink: 🐳 Docker" href="#-docker"></a></p>
<p dir="auto">To simplify the deployment process, we provide Docker images with pre-built environments: <a href="https://hub.docker.com/r/qwenllm/qwen3-omni" rel="nofollow">qwenllm/qwen3-omni</a>. You only need to install the driver and download model files to launch the demos. Please refer to the <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html" rel="nofollow">guide</a> to install the NVIDIA Container Toolkit, ensuring that your Docker can access the GPU. For users in mainland China who may have difficulty accessing Docker Hub, you can use mirror acceleration services to pull the images. First, run the following command to pull and initialize the container:</p>
<div dir="auto" data-snippet-clipboard-copy-content="LOCAL_WORKDIR=/path/to/your/workspace
HOST_PORT=8901
CONTAINER_PORT=80
docker run --gpus all --name qwen3-omni \
    -v /var/run/docker.sock:/var/run/docker.sock -p $HOST_PORT:$CONTAINER_PORT \
    --mount type=bind,source=$LOCAL_WORKDIR,target=/data/shared/Qwen3-Omni \
    --shm-size=4gb \
    -it qwenllm/qwen3-omni:3-cu124"><pre>LOCAL_WORKDIR=/path/to/your/workspace
HOST_PORT=8901
CONTAINER_PORT=80
docker run --gpus all --name qwen3-omni \
    -v /var/run/docker.sock:/var/run/docker.sock -p <span>$HOST_PORT</span>:<span>$CONTAINER_PORT</span> \
    --mount type=bind,source=<span>$LOCAL_WORKDIR</span>,target=/data/shared/Qwen3-Omni \
    --shm-size=4gb \
    -it qwenllm/qwen3-omni:3-cu124</pre></div>
<p dir="auto">After executing the command, you will enter the bash shell of the container. Your local model and data directory (<strong>please replace</strong> <code>/path/to/your/workspace</code> <strong>with the actual path</strong>) will be mounted to the container's internal path <code>/data/shared/Qwen3-Omni</code>. The host's port <code>8901</code> is mapped to port <code>80</code> in the container, meaning you can access the service inside the container by visiting port <code>8901</code> on the host machine.</p>
<p dir="auto">Please note that services inside the container must be started with the IP <code>0.0.0.0</code> to ensure proper port forwarding. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run this command inside the Docker container
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct --server-port 80 --server-name 0.0.0.0"><pre><span><span>#</span> Run this command inside the Docker container</span>
python web_demo.py -c Qwen/Qwen3-Omni-30B-A3B-Instruct --server-port 80 --server-name 0.0.0.0</pre></div>
<p dir="auto">For more ways to launch the web demo, please refer to <a href="#launch-local-web-ui-demo">Launch Local Web UI Demo</a>. If you exit the container, you can re-enter it using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker start qwen3-omni
docker exec -it qwen3-omni bash"><pre>docker start qwen3-omni
docker <span>exec</span> -it qwen3-omni bash</pre></div>
<p dir="auto">Or if you want to completely remove the container, please run:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Evaluation</h2><a id="user-content-evaluation" aria-label="Permalink: Evaluation" href="#evaluation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Performance of Qwen3-Omni</h3><a id="user-content-performance-of-qwen3-omni" aria-label="Permalink: Performance of Qwen3-Omni" href="#performance-of-qwen3-omni"></a></p>
<p dir="auto">Qwen3-Omni maintains state-of-the-art performance on text and visual modalities without degradation relative to same-size single-model Qwen counterparts. Across 36 audio and audio-visual benchmarks, it achieves open-source SOTA on 32 and sets the SOTA on 22, outperforming strong closed-source systems such as Gemini 2.5 Pro and GPT-4o.</p>
<details>
<summary>Text -&gt; Text</summary>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th colspan="2"></th>
      <th>GPT-4o-0327</th>
      <th>Qwen3-235B-A22B<br>Non Thinking</th>
      <th>Qwen3-30B-A3B-Instruct-2507</th>
      <th>Qwen3-Omni-30B-A3B-Instruct</th>
      <th>Qwen3-Omni-Flash-Instruct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="2">General<br>Tasks</td>
      <td>MMLU-Redux</td>
      <td><strong>91.3</strong></td>
      <td>89.2</td>
      <td>89.3</td>
      <td>86.6</td>
      <td>86.8</td>
    </tr>
    <tr>
      <td>GPQA</td>
      <td>66.9</td>
      <td>62.9</td>
      <td><strong>70.4</strong></td>
      <td>69.6</td>
      <td>69.7</td>
    </tr>
    <tr>
      <td rowspan="2">Reasoning</td>
      <td>AIME25</td>
      <td>26.7</td>
      <td>24.7</td>
      <td>61.3</td>
      <td>65.0</td>
      <td><strong>65.9</strong></td>
    </tr>
    <tr>
      <td>ZebraLogic</td>
      <td>52.6</td>
      <td>37.7</td>
      <td><strong>90.0</strong></td>
      <td>76.0</td>
      <td>76.1</td>
    </tr>
    <tr>
      <td>Code</td>
      <td>MultiPL-E</td>
      <td>82.7</td>
      <td>79.3</td>
      <td><strong>83.8</strong></td>
      <td>81.4</td>
      <td>81.5</td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td rowspan="3">Alignment<br>Tasks</td>
      <td>IFEval</td>
      <td>83.9</td>
      <td>83.2</td>
      <td><strong>84.7</strong></td>
      <td>81.0</td>
      <td>81.7</td>
    </tr>
    <tr>
      <td>Creative Writing v3</td>
      <td>84.9</td>
      <td>80.4</td>
      <td><strong>86.0</strong></td>
      <td>80.6</td>
      <td>81.8</td>
    </tr>
    <tr>
      <td>WritingBench</td>
      <td>75.5</td>
      <td>77.0</td>
      <td><strong>85.5</strong></td>
      <td>82.6</td>
      <td>83.0</td>
    </tr>
    <tr>
      <td>Agent</td>
      <td>BFCL-v3</td>
      <td>66.5</td>
      <td><strong>68.0</strong></td>
      <td>65.1</td>
      <td>64.4</td>
      <td>65.0</td>
    </tr>
    <tr>
      <td rowspan="2">Multilingual<br>Tasks</td>
      <td>MultiIF</td>
      <td><strong>70.4</strong></td>
      <td>70.2</td>
      <td>67.9</td>
      <td>64.0</td>
      <td>64.7</td>
    </tr>
    <tr>
      <td>PolyMATH</td>
      <td>25.5</td>
      <td>27.0</td>
      <td><strong>43.1</strong></td>
      <td>37.9</td>
      <td>39.3</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th></th>
      <th></th>
      <th>Gemini-2.5-Flash<br>Thinking</th>
      <th>Qwen3-235B-A22B<br>Thinking</th>
      <th>Qwen3-30B-A3B-Thinking-2507</th>
      <th>Qwen3-Omni-30B-A3B-Thinking</th>
      <th>Qwen3-Omni-Flash-Thinking</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td rowspan="2"><em>General<br>Tasks</em></td>
      <td>MMLU-Redux</td>
      <td>92.1</td>
      <td><b>92.7</b></td>
      <td>91.4</td>
      <td>88.8</td>
      <td>89.7</td>
    </tr>
    <tr>
      <td>GPQA</td>
      <td><b>82.8</b></td>
      <td>71.1</td>
      <td>73.4</td>
      <td>73.1</td>
      <td>73.1</td>
    </tr>
    <tr>
      <td rowspan="2"><em>Reasoning</em></td>
      <td>AIME25</td>
      <td>72.0</td>
      <td>81.5</td>
      <td><b>85.0</b></td>
      <td>73.7</td>
      <td>74.0</td>
    </tr>
    <tr>
      <td>LiveBench 20241125</td>
      <td>74.3</td>
      <td><b>77.1</b></td>
      <td>76.8</td>
      <td>71.8</td>
      <td>70.3</td>
    </tr>
    <tr>
      <td><em>Code</em></td>
      <td>MultiPL-E</td>
      <td><b>84.5</b></td>
      <td>79.9</td>
      <td>81.3</td>
      <td>80.6</td>
      <td>81.0</td>
    </tr>
    <tr>
      <td rowspan="4"><em>Alignment<br>Tasks</em></td>
      <td>IFEval</td>
      <td><b>89.8</b></td>
      <td>83.4</td>
      <td>88.9</td>
      <td>85.1</td>
      <td>85.2</td>
    </tr>
    <tr>
      <td>Arena-Hard v2</td>
      <td>56.7</td>
      <td><b>61.5</b></td>
      <td>56.0</td>
      <td>55.1</td>
      <td>57.8</td>
    </tr>
    <tr>
      <td>Creative Writing v3</td>
      <td><b>85.0</b></td>
      <td>84.6</td>
      <td>84.4</td>
      <td>82.5</td>
      <td>83.6</td>
    </tr>
    <tr>
      <td>WritingBench</td>
      <td>83.9</td>
      <td>80.3</td>
      <td>85.0</td>
      <td>85.5</td>
      <td><b>85.9</b></td>
    </tr>
    <tr>
      <td><em>Agent</em></td>
      <td>BFCL-v3</td>
      <td>68.6</td>
      <td>70.8</td>
      <td><b>72.4</b></td>
      <td>63.2</td>
      <td>64.5</td>
    </tr>
    <tr>
      <td rowspan="2"><em>Multilingual<br>Tasks</em></td>
      <td>MultiIF</td>
      <td>74.4</td>
      <td>71.9</td>
      <td><b>76.4</b></td>
      <td>72.9</td>
      <td>73.2</td>
    </tr>
    <tr>
      <td>PolyMATH</td>
      <td>49.8</td>
      <td><b>54.7</b></td>
      <td>52.6</td>
      <td>47.1</td>
      <td>48.7</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<details>
<summary>Audio -&gt; Text</summary>
<markdown-accessiblity-table><table>
<thead>
  <tr>
    <th></th>
    <th>Seed-ASR</th>
    <th>Voxtral-Mini</th>
    <th>Voxtral-Small</th>
    <th>GPT-4o-Transcribe</th>
    <th>Gemini-2.5-Pro</th>
    <th>Qwen2.5-Omni</th>
    <th>Qwen3-Omni-30B-A3B-Instruct</th>
    <th>Qwen3-Omni-Flash-Instruct</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td colspan="9"><em>EN &amp; ZH ASR (wer)</em></td>
  </tr>
  <tr>
    <td>Wenetspeech<br><em>net</em> | <em>meeting</em></td>
    <td>4.66 | <strong>5.69</strong></td>
    <td>24.30 | 31.53</td>
    <td>20.33 | 26.08</td>
    <td>15.30 | 32.27</td>
    <td>14.43 | 13.47</td>
    <td>5.91 | 7.65</td>
    <td>4.69 | 5.89</td>
    <td><strong>4.62</strong> | 5.75</td>
  </tr>
  <tr>
    <td>Librispeech<br><em>clean</em> | <em>other</em></td>
    <td>1.58 | 2.84</td>
    <td>1.88 | 4.12</td>
    <td>1.56 | 3.30</td>
    <td>1.39 | 3.75</td>
    <td>2.89 | 3.56</td>
    <td>1.74 | 3.45</td>
    <td><strong>1.22</strong> | 2.48</td>
    <td>1.27 | <strong>2.44</strong></td>
  </tr>
  <tr>
    <td>CV15-en</td>
    <td>-</td>
    <td>9.47</td>
    <td>7.79</td>
    <td>10.01</td>
    <td>9.89</td>
    <td>7.61</td>
    <td>6.05</td>
    <td><strong>5.94</strong></td>
  </tr>
  <tr>
    <td>CV15-zh</td>
    <td>-</td>
    <td>24.67</td>
    <td>19.30</td>
    <td>9.84</td>
    <td>8.00</td>
    <td>5.13</td>
    <td>4.31</td>
    <td><strong>4.28</strong></td>
  </tr>
  <tr>
    <td>Fleurs-en</td>
    <td>3.40</td>
    <td>3.96</td>
    <td>3.77</td>
    <td>3.32</td>
    <td>2.94</td>
    <td>3.77</td>
    <td><strong>2.72</strong></td>
    <td>2.74</td>
  </tr>
  <tr>
    <td>Fleurs-zh</td>
    <td>2.69</td>
    <td>12.22</td>
    <td>7.98</td>
    <td>2.44</td>
    <td>2.71</td>
    <td>2.54</td>
    <td>2.20</td>
    <td><strong>2.19</strong></td>
  </tr>
  <tr>
    <td colspan="9"><em>Multilingual ASR (wer)</em></td>
  </tr>
  <tr>
    <td>Fleurs-avg<br>(19 lang)</td>
    <td>-</td>
    <td>15.67</td>
    <td>8.09</td>
    <td>4.48</td>
    <td>5.55</td>
    <td>14.04</td>
    <td>5.33</td>
    <td><strong>5.31</strong></td>
  </tr>
  <tr>
    <td colspan="9"><em>Lyric ASR (wer)</em></td>
  </tr>
  <tr>
    <td>MIR-1K (vocal-only)</td>
    <td>6.45</td>
    <td>23.33</td>
    <td>18.73</td>
    <td>11.87</td>
    <td>9.85</td>
    <td>8.15</td>
    <td>5.90</td>
    <td><strong>5.85</strong></td>
  </tr>
  <tr>
    <td>Opencpop-test</td>
    <td>2.98</td>
    <td>31.01</td>
    <td>16.06</td>
    <td>7.93</td>
    <td>6.49</td>
    <td>2.84</td>
    <td><strong>1.54</strong></td>
    <td>2.02</td>
  </tr>
  <tr>
    <td colspan="9"><em>S2TT (BLEU)</em></td>
  </tr>
  <tr>
    <td>Fleurs-en2xx</td>
    <td>-</td>
    <td>30.35</td>
    <td>37.85</td>
    <td>-</td>
    <td><strong>39.25</strong></td>
    <td>29.22</td>
    <td>37.50</td>
    <td>36.22</td>
  </tr>
  <tr>
    <td>Fleurs-xx2en</td>
    <td>-</td>
    <td>27.54</td>
    <td>32.81</td>
    <td>-</td>
    <td><strong>35.41</strong></td>
    <td>28.61</td>
    <td>31.08</td>
    <td>30.71</td>
  </tr>
  <tr>
    <td>Fleurs-zh2xx</td>
    <td>-</td>
    <td>17.03</td>
    <td>22.05</td>
    <td>-</td>
    <td><strong>26.63</strong></td>
    <td>17.97</td>
    <td>25.17</td>
    <td>25.10</td>
  </tr>
  <tr>
    <td>Fleurs-xx2zh</td>
    <td>-</td>
    <td>28.75</td>
    <td>34.82</td>
    <td>-</td>
    <td><strong>37.50</strong></td>
    <td>27.68</td>
    <td>33.13</td>
    <td>31.19</td>
  </tr>
</tbody>
</table></markdown-accessiblity-table>

      <markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th></th>
      <th>GPT-4o-Audio</th>
      <th>Gemini-2.5-Flash</th>
      <th>Gemini-2.5-Pro</th>
      <th>Qwen2.5-Omni</th>
      <th>Qwen3-Omni-30B-A3B-Instruct</th>
      <th>Qwen3-Omni-30B-A3B-Thinking</th>
      <th>Qwen3-Omni-Flash-Instruct</th>
      <th>Qwen3-Omni-Flash-Thinking</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="9"><strong>VoiceBench</strong></td>
    </tr>
    <tr>
      <td>AlpacaEval</td>
      <td>95.6</td>
      <td>96.1</td>
      <td>94.3</td>
      <td>89.9</td>
      <td>94.8</td>
      <td>96.4</td>
      <td>95.4</td>
      <td><strong>96.8</strong></td>
    </tr>
    <tr>
      <td>CommonEval</td>
      <td>89.8</td>
      <td>88.3</td>
      <td>88.4</td>
      <td>76.7</td>
      <td>90.8</td>
      <td>90.5</td>
      <td><strong>91.0</strong></td>
      <td>90.9</td>
    </tr>
    <tr>
      <td>WildVoice</td>
      <td>91.6</td>
      <td>92.1</td>
      <td>93.4</td>
      <td>77.7</td>
      <td>91.6</td>
      <td>90.5</td>
      <td><strong>92.3</strong></td>
      <td>90.9</td>
    </tr>
    <tr>
      <td>SD-QA</td>
      <td>75.5</td>
      <td>84.5</td>
      <td><strong>90.1</strong></td>
      <td>56.4</td>
      <td>76.9</td>
      <td>78.1</td>
      <td>76.8</td>
      <td>78.5</td>
    </tr>
    <tr>
      <td>MMSU</td>
      <td>80.3</td>
      <td>66.1</td>
      <td>71.1</td>
      <td>61.7</td>
      <td>68.1</td>
      <td>83.0</td>
      <td>68.4</td>
      <td><strong>84.3</strong></td>
    </tr>
    <tr>
      <td>OpenBookQA</td>
      <td>89.2</td>
      <td>56.9</td>
      <td>92.3</td>
      <td>80.9</td>
      <td>89.7</td>
      <td>94.3</td>
      <td>91.4</td>
      <td><strong>95.0</strong></td>
    </tr>
    <tr>
      <td>BBH</td>
      <td>84.1</td>
      <td>83.9</td>
      <td><strong>92.6</strong></td>
      <td>66.7</td>
      <td>80.4</td>
      <td>88.9</td>
      <td>80.6</td>
      <td>89.6</td>
    </tr>
    <tr>
      <td>IFEval</td>
      <td>76.0</td>
      <td>83.8</td>
      <td><strong>85.7</strong></td>
      <td>53.5</td>
      <td>77.8</td>
      <td>80.6</td>
      <td>75.2</td>
      <td>80.8</td>
    </tr>
    <tr>
      <td>AdvBench</td>
      <td>98.7</td>
      <td>98.9</td>
      <td>98.1</td>
      <td>99.2</td>
      <td><strong>99.3</strong></td>
      <td>97.2</td>
      <td><strong>99.4</strong></td>
      <td>98.9</td>
    </tr>
    <tr>
      <td>Overall</td>
      <td>86.8</td>
      <td>83.4</td>
      <td><strong>89.6</strong></td>
      <td>73.6</td>
      <td>85.5</td>
      <td>88.8</td>
      <td>85.6</td>
      <td>89.5</td>
    </tr>
    <tr>
      <td colspan="9"><strong>Audio Reasoning</strong></td>
    </tr>
    <tr>
      <td>MMAU-v05.15.25</td>
      <td>62.5</td>
      <td>71.8</td>
      <td>77.4</td>
      <td>65.5</td>
      <td>77.5</td>
      <td>75.4</td>
      <td><strong>77.6</strong></td>
      <td>76.5</td>
    </tr>
    <tr><td>MMSU</td>
      <td>56.4</td>
      <td>70.2</td>
      <td><strong>77.7</strong></td>
      <td>62.6</td>
      <td>69.0</td>
      <td>70.2</td>
      <td>69.1</td>
      <td>71.3</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th></th>
      <th>Best Specialist<br>Models</th>
      <th>GPT-4o-Audio</th>
      <th>Gemini-2.5-Pro</th>
      <th>Qwen2.5-Omni</th>
      <th>Qwen3-Omni-30B-A3B-Instruct</th>
      <th>Qwen3-Omni-Flash-Instruct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>RUL-MuchoMusic</td>
      <td>47.6 (Audio Flamingo 3)</td>
      <td>36.1</td>
      <td>49.4</td>
      <td>47.3</td>
      <td>52.0</td>
      <td><strong>52.1</strong></td>
    </tr>
    <tr>
      <td>GTZAN<br><em>Acc.</em></td>
      <td>87.9 (CLaMP 3)</td>
      <td>76.5</td>
      <td>81.0</td>
      <td>81.7</td>
      <td>93.0</td>
      <td><strong>93.1</strong></td>
    </tr>
    <tr>
      <td>MTG Genre<br><em>Micro F1</em></td>
      <td>35.8 (MuQ-MuLan)</td>
      <td>25.3</td>
      <td>32.6</td>
      <td>32.5</td>
      <td>39.0</td>
      <td><strong>39.5</strong></td>
    </tr>
    <tr>
      <td>MTG Mood/Theme<br><em>Micro F1</em></td>
      <td>10.9 (MuQ-MuLan)</td>
      <td>11.3</td>
      <td>14.1</td>
      <td>8.9</td>
      <td>21.0</td>
      <td><strong>21.7</strong></td>
    </tr>
    <tr>
      <td>MTG Instrument<br><em>Micro F1</em></td>
      <td>39.8 (MuQ-MuLan)</td>
      <td>34.2</td>
      <td>33.0</td>
      <td>22.6</td>
      <td>40.5</td>
      <td><strong>40.7</strong></td>
    </tr>
    <tr>
      <td>MTG Top50<br><em>Micro F1</em></td>
      <td>33.2 (MuQ-MuLan)</td>
      <td>25.0</td>
      <td>26.1</td>
      <td>21.6</td>
      <td>36.7</td>
      <td><strong>36.9</strong></td>
    </tr>
    <tr>
      <td>MagnaTagATune<br><em>Micro F1</em></td>
      <td>41.6 (MuQ)</td>
      <td>29.2</td>
      <td>28.1</td>
      <td>30.1</td>
      <td>44.3</td>
      <td><strong>46.8</strong></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<details>
<summary>Vision -&gt; Text</summary>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Datasets</th>
      <th>GPT4-o</th>
      <th>Gemini-2.0-Flash</th>
      <th>Qwen2.5-VL<br>72B</th>
      <th>Qwen3-Omni-30B-A3B<br>-Instruct</th>
      <th>Qwen3-Omni-Flash<br>-Instruct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="6">General Visual Question Answering</td>
    </tr>
    <tr>
      <td>MMStar</td>
      <td>64.7</td>
      <td><strong>71.4</strong></td>
      <td>70.8</td>
      <td>68.5</td>
      <td>69.3</td>
    </tr>
    <tr>
      <td>HallusionBench</td>
      <td>55.0</td>
      <td>56.3</td>
      <td>55.2</td>
      <td><strong>59.7</strong></td>
      <td>58.5</td>
    </tr>
    <tr>
      <td>MM-MT-Bench</td>
      <td><strong>7.7</strong></td>
      <td>6.7</td>
      <td>7.6</td>
      <td>7.4</td>
      <td>7.6</td>
    </tr>
    <tr>
      <td colspan="6">Math &amp; STEM</td>
    </tr>
    <tr>
      <td>MMMU_val</td>
      <td>69.1</td>
      <td><strong>71.3</strong></td>
      <td>70.2</td>
      <td>69.1</td>
      <td>69.8</td>
    </tr>
    <tr>
      <td>MMMU_pro</td>
      <td>51.9</td>
      <td>56.1</td>
      <td>51.1</td>
      <td>57.0</td>
      <td><strong>57.6</strong></td>
    </tr>
    <tr>
      <td>MathVista_mini</td>
      <td>63.8</td>
      <td>71.4</td>
      <td>74.8</td>
      <td>75.9</td>
      <td><strong>77.4</strong></td>
    </tr>
    <tr>
      <td>MathVision_full</td>
      <td>30.4</td>
      <td>48.6</td>
      <td>38.1</td>
      <td>56.3</td>
      <td><strong>58.3</strong></td>
    </tr>
    <tr>
      <td colspan="6">Documentation Understanding</td>
    </tr>
    <tr>
      <td>AI2D</td>
      <td>84.6</td>
      <td>86.7</td>
      <td><strong>88.7</strong></td>
      <td>85.2</td>
      <td>86.4</td>
    </tr>
    <tr>
      <td>ChartQA_test</td>
      <td>86.7</td>
      <td>64.6</td>
      <td><strong>89.5</strong></td>
      <td>86.8</td>
      <td>87.1</td>
    </tr>
    <tr>
      <td colspan="6">Counting</td>
    </tr>
    <tr>
      <td>CountBench</td>
      <td>87.9</td>
      <td>91.2</td>
      <td><strong>93.6</strong></td>
      <td>90.0</td>
      <td>90.0</td>
    </tr>
    <tr>
      <td colspan="6">Video Understanding</td>
    </tr>
    <tr>
      <td>Video-MME</td>
      <td>71.9</td>
      <td>72.4</td>
      <td><strong>73.3</strong></td>
      <td>70.5</td>
      <td>71.4</td>
    </tr>
    <tr>
      <td>LVBench</td>
      <td>30.8</td>
      <td><strong>57.9</strong></td>
      <td>47.3</td>
      <td>50.2</td>
      <td>51.1</td>
    </tr>
    <tr>
      <td>MLVU</td>
      <td>64.6</td>
      <td>71.0</td>
      <td>74.6</td>
      <td>75.2</td>
      <td><strong>75.5</strong></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Datasets</th>
      <th>Gemini-2.5-flash-thinking</th>
      <th>InternVL-3.5-241B-A28B</th>
      <th>Qwen3-Omni-30B-A3B-Thinking</th>
      <th>Qwen3-Omni-Flash-Thinking</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td colspan="5">General Visual Question Answering</td>
    </tr>
    <tr>
      <td>MMStar</td>
      <td>75.5</td>
      <td><b>77.9</b></td>
      <td>74.9</td>
      <td>75.5</td>
    </tr>
    <tr>
      <td>HallusionBench</td>
      <td>61.1</td>
      <td>57.3</td>
      <td>62.8</td>
      <td><b>63.4</b></td>
    </tr>
    <tr>
      <td>MM-MT-Bench</td>
      <td>7.8</td>
      <td>–</td>
      <td><b>8.0</b></td>
      <td><b>8.0</b></td>
    </tr>
    <tr>
      <td colspan="5">Math &amp; STEM</td>
    </tr>
    <tr>
      <td>MMMU_val</td>
      <td>76.9</td>
      <td><b>77.7</b></td>
      <td>75.6</td>
      <td>75.0</td>
    </tr>
    <tr>
      <td>MMMU_pro</td>
      <td><b>65.8</b></td>
      <td>–</td>
      <td>60.5</td>
      <td>60.8</td>
    </tr>
    <tr>
      <td>MathVista_mini</td>
      <td>77.6</td>
      <td><b>82.7</b></td>
      <td>80.0</td>
      <td>81.2</td>
    </tr>
    <tr>
      <td>MathVision_full</td>
      <td>62.3</td>
      <td><b>63.9</b></td>
      <td>62.9</td>
      <td>63.8</td>
    </tr>
    <tr>
      <td colspan="5">Documentation Understanding</td>
    </tr>
    <tr>
      <td>AI2D_test</td>
      <td><b>88.6</b></td>
      <td>87.3</td>
      <td>86.1</td>
      <td>86.8</td>
    </tr>
    <tr>
      <td>ChartQA_test</td>
      <td>–</td>
      <td>88.0</td>
      <td><b>89.5</b></td>
      <td>89.3</td>
    </tr>
    <tr>
      <td colspan="5">Counting</td>
    </tr>
    <tr>
      <td>CountBench</td>
      <td>88.6</td>
      <td>–</td>
      <td>88.6</td>
      <td><b>92.5</b></td>
    </tr>
    <tr>
      <td colspan="5">Video Understanding</td>
    </tr>
    <tr>
      <td>Video-MME</td>
      <td><b>79.6</b></td>
      <td>72.9</td>
      <td>69.7</td>
      <td>69.8</td>
    </tr>
    <tr>
      <td>LVBench</td>
      <td><b>64.5</b></td>
      <td>–</td>
      <td>49.0</td>
      <td>49.5</td>
    </tr>
    <tr>
      <td>MLVU</td>
      <td><b>82.1</b></td>
      <td>78.2</td>
      <td>72.9</td>
      <td>73.9</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<details>
<summary>AudioVisual -&gt; Text</summary>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Datasets</th>
      <th>Previous Open-source SoTA</th>
      <th>Gemini-2.5-Flash</th>
      <th>Qwen2.5-Omni</th>
      <th>Qwen3-Omni-30B-A3B-Instruct</th>
      <th>Qwen3-Omni-Flash-Instruct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>WorldSense</td>
      <td>47.1</td>
      <td>50.9</td>
      <td>45.4</td>
      <td>54.0</td>
      <td><strong>54.1</strong></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Datasets</th>
      <th>Previous Open-source SoTA</th>
      <th>Gemini-2.5-Flash-Thinking</th>
      <th>Qwen3-Omni-30B-A3B-Thinking</th>
      <th>Qwen3-Omni-Flash-Thinking</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>DailyOmni</td>
      <td>69.8</td>
      <td>72.7</td>
      <td>75.8</td>
      <td><b>76.2</b></td>
    </tr>
    <tr>
      <td>VideoHolmes</td>
      <td>55.6</td>
      <td>49.5</td>
      <td><b>57.3</b></td>
      <td><b>57.3</b></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<details>
<summary>Zero-shot Speech Generation</summary>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Datasets</th>
      <th>Model</th>
      <th>Performance</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&nbsp;</td>
      <td colspan="2"><em>Content Consistency</em></td>
    </tr>
  </tbody>
  <tbody>
    <tr>
      <td rowspan="10"><strong>SEED</strong><br><em>test-zh</em> | <em>test-en</em></td>
      <td>Seed-TTS<sub>ICL</sub></td>
      <td>1.11 | 2.24</td>
    </tr>
    <tr>
      <td>Seed-TTS<sub>RL</sub></td>
      <td>1.00 | 1.94</td>
    </tr>
    <tr>
      <td>MaskGCT</td>
      <td>2.27 | 2.62</td>
    </tr>
    <tr>
      <td>E2 TTS</td>
      <td>1.97 | 2.19</td>
    </tr>
    <tr>
      <td>F5-TTS</td>
      <td>1.56 | 1.83</td>
    </tr>
    <tr>
      <td>Spark TTS</td>
      <td>1.20 | 1.98</td>
    </tr>
    <tr>
      <td>CosyVoice 2</td>
      <td>1.45 | 2.57</td>
    </tr>
    <tr>
      <td>CosyVoice 3</td>
      <td><strong>0.71</strong> | 1.45</td>
    </tr>
    <tr>
      <td>Qwen2.5-Omni-7B</td>
      <td>1.42 | 2.33</td>
    </tr>
    <tr>
      <td>Qwen3-Omni-30B-A3B</td>
      <td>1.07 | <strong>1.39</strong></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<details>
<summary>Multilingual Speech Generation </summary>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th rowspan="2">Language</th>
      <th colspan="3">Content Consistency</th>
      <th colspan="3">Speaker Similarity</th>
    </tr>
    <tr>
      <th>Qwen3-Omni-30B-A3B</th>
      <th>MiniMax</th>
      <th>ElevenLabs</th>
      <th>Qwen3-Omni-30B-A3B</th>
      <th>MiniMax</th>
      <th>ElevenLabs</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Chinese</td>
      <td><strong>0.716</strong></td>
      <td>2.252</td>
      <td>16.026</td>
      <td>0.772</td>
      <td><strong>0.780</strong></td>
      <td>0.677</td>
    </tr>
    <tr>
      <td>English</td>
      <td><strong>1.069</strong></td>
      <td>2.164</td>
      <td>2.339</td>
      <td><strong>0.773</strong></td>
      <td>0.756</td>
      <td>0.613</td>
    </tr>
    <tr>
      <td>German</td>
      <td>0.777</td>
      <td>1.906</td>
      <td><strong>0.572</strong></td>
      <td><strong>0.738</strong></td>
      <td>0.733</td>
      <td>0.614</td>
    </tr>
    <tr>
      <td>Italian</td>
      <td><strong>1.067</strong></td>
      <td>1.543</td>
      <td>1.743</td>
      <td><strong>0.742</strong></td>
      <td>0.699</td>
      <td>0.579</td>
    </tr>
    <tr>
      <td>Portuguese</td>
      <td>1.872</td>
      <td>1.877</td>
      <td><strong>1.331</strong></td>
      <td>0.770</td>
      <td><strong>0.805</strong></td>
      <td>0.711</td>
    </tr>
    <tr>
      <td>Spanish</td>
      <td>1.765</td>
      <td><strong>1.029</strong></td>
      <td>1.084</td>
      <td>0.744</td>
      <td><strong>0.762</strong></td>
      <td>0.615</td>
    </tr>
    <tr>
      <td>Japanese</td>
      <td>3.631</td>
      <td><strong>3.519</strong></td>
      <td>10.646</td>
      <td>0.763</td>
      <td><strong>0.776</strong></td>
      <td>0.738</td>
    </tr>
    <tr>
      <td>Korean</td>
      <td><strong>1.670</strong></td>
      <td>1.747</td>
      <td>1.865</td>
      <td><strong>0.778</strong></td>
      <td>0.776</td>
      <td>0.700</td>
    </tr>
    <tr>
      <td>French</td>
      <td><strong>2.505</strong></td>
      <td>4.099</td>
      <td>5.216</td>
      <td><strong>0.689</strong></td>
      <td>0.628</td>
      <td>0.535</td>
    </tr>
    <tr>
      <td>Russian</td>
      <td>3.986</td>
      <td>4.281</td>
      <td><strong>3.878</strong></td>
      <td>0.759</td>
      <td><strong>0.761</strong></td>
      <td>0.676</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<details>
<summary>Cross-Lingual Speech Generation </summary>
<markdown-accessiblity-table><table>
  <thead>
    <tr>
      <th>Language</th>
      <th>Qwen3-Omni-30B-A3B</th>
      <th>CosyVoice3</th>
      <th>CosyVoice2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>en-to-zh</td>
      <td>5.37</td>
      <td><strong>5.09</strong></td>
      <td>13.5</td>
    </tr>
    <tr>
      <td>ja-to-zh</td>
      <td>3.32</td>
      <td><strong>3.05</strong></td>
      <td>48.1</td>
    </tr>
    <tr>
      <td>ko-to-zh</td>
      <td><strong>0.99</strong></td>
      <td>1.06</td>
      <td>7.70</td>
    </tr>
    <tr>
      <td>zh-to-en</td>
      <td><strong>2.76</strong></td>
      <td>2.98</td>
      <td>6.47</td>
    </tr>
    <tr>
      <td>ja-to-en</td>
      <td><strong>3.31</strong></td>
      <td>4.20</td>
      <td>17.1</td>
    </tr>
    <tr>
      <td>ko-to-en</td>
      <td><strong>3.34</strong></td>
      <td>4.19</td>
      <td>11.2</td>
    </tr>
    <tr>
      <td>zh-to-ja</td>
      <td>8.29</td>
      <td><strong>7.08</strong></td>
      <td>13.1</td>
    </tr>
    <tr>
      <td>en-to-ja</td>
      <td>7.53</td>
      <td><strong>6.80</strong></td>
      <td>14.9</td>
    </tr>
    <tr>
      <td>ko-to-ja</td>
      <td>4.24</td>
      <td><strong>3.93</strong></td>
      <td>5.86</td>
    </tr>
    <tr>
      <td>zh-to-ko</td>
      <td><strong>5.13</strong></td>
      <td>14.4</td>
      <td>24.8</td>
    </tr>
    <tr>
      <td>en-to-ko</td>
      <td><strong>4.96</strong></td>
      <td>5.87</td>
      <td>21.9</td>
    </tr>
    <tr>
      <td>ja-to-ko</td>
      <td><strong>6.23</strong></td>
      <td>7.92</td>
      <td>21.5</td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setting for Evaluation</h3><a id="user-content-setting-for-evaluation" aria-label="Permalink: Setting for Evaluation" href="#setting-for-evaluation"></a></p>
<ul dir="auto">
<li><strong>Decoding Strategy</strong>: For the Qwen3-Omni series across all evaluation benchmarks, <code>Instruct</code> models use greedy decoding during generation without sampling. For <code>Thinking</code> models, the decoding parameters should be taken from the <code>generation_config.json</code> file in the checkpoint.</li>
<li><strong>Benchmark-Specific Formatting</strong>: For the majority of evaluation benchmarks, they come with their own ChatML formatting to embed the question or prompt. It should be noted that all video data are set to <code>fps=2</code> during evaluation.</li>
<li><strong>Default Prompts</strong>: For tasks in certain benchmarks that do not include a prompt, we use the following prompt settings:</li>
</ul>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Task Type</th>
<th>Prompt</th>
</tr>
</thead>
<tbody>
<tr>
<td>Auto Speech Recognition (ASR) for Chinese</td>
<td>请将这段中文语音转换为纯文本。</td>
</tr>
<tr>
<td>Auto Speech Recognition (ASR) for Other languages</td>
<td>Transcribe the  audio into text.</td>
</tr>
<tr>
<td>Speech-to-Text Translation (S2TT)</td>
<td>Listen to the provided &lt;source_language&gt; speech and produce a translation in &lt;target_language&gt; text.</td>
</tr>
<tr>
<td>Song Lyrics Recognition</td>
<td>Transcribe the song lyrics into text without any punctuation, separate lines with line breaks, and output only the lyrics without additional explanations.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li><strong>System Prompt</strong>: No <code>system prompt</code> should be set for any evaluation benchmark.</li>
<li><strong>Input Sequence</strong>: The question or prompt should be input as user text. Unless otherwise specified by the benchmark, the text should come <strong>after</strong> multimodal data in the sequence. For example:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="messages = [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;audio&quot;, &quot;audio&quot;: &quot;/path/to/audio.wav&quot;},
            {&quot;type&quot;: &quot;image&quot;, &quot;image&quot;: &quot;/path/to/image.png&quot;},
            {&quot;type&quot;: &quot;video&quot;, &quot;video&quot;: &quot;/path/to/video.mp4&quot;},
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Describe the audio, image and video.&quot;},
        ],
    },
]"><pre><span>messages</span> <span>=</span> [
    {
        <span>"role"</span>: <span>"user"</span>,
        <span>"content"</span>: [
            {<span>"type"</span>: <span>"audio"</span>, <span>"audio"</span>: <span>"/path/to/audio.wav"</span>},
            {<span>"type"</span>: <span>"image"</span>, <span>"image"</span>: <span>"/path/to/image.png"</span>},
            {<span>"type"</span>: <span>"video"</span>, <span>"video"</span>: <span>"/path/to/video.mp4"</span>},
            {<span>"type"</span>: <span>"text"</span>, <span>"text"</span>: <span>"Describe the audio, image and video."</span>},
        ],
    },
]</pre></div>

<br>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>