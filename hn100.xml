<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 10 Jul 2024 04:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[New insights into transcription factors and chromatin remodeling (112 pts)]]></title>
            <link>https://longevity.technology/news/master-controller-of-aging-and-development-uncovered/</link>
            <guid>40919707</guid>
            <pubDate>Tue, 09 Jul 2024 19:09:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://longevity.technology/news/master-controller-of-aging-and-development-uncovered/">https://longevity.technology/news/master-controller-of-aging-and-development-uncovered/</a>, See on <a href="https://news.ycombinator.com/item?id=40919707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img src="https://longevity.technology/wp-content/uploads/2024/07/Master-controller-of-aging-and-development-uncovered-1024x683.jpg" width="811" height="541"></p><h2><strong>New insights into transcription factors and chromatin remodeling reveal potential for improving age-related health outcomes.</strong></h2><p>Researchers from the <a href="https://www.uq.edu.au/" target="_blank" rel="noreferrer noopener">University of Queensland</a> have made significant strides in understanding the molecular mechanisms underpinning aging and development, highlighting the crucial role of gene regulatory elements and their interaction with transcription factors. The study, published in <em><a href="https://www.sciencedirect.com/science/article/pii/S1550413124002316?via%3Dihub" target="_blank" rel="noreferrer noopener">Cell Metabolism</a></em>, offers a comprehensive analysis of chromatin changes across various cell types in both mice and humans, revealing common pathways that govern the transition from youth to old age.</p><p><strong><em>Longevity.Technology: Research into the molecular processes of aging holds significant promise for advancing longevity and improving health outcomes; by dissecting the ways in which gene activity shifts over time, scientists can develop targeted interventions aimed at mitigating age-related diseases and enhancing healthspan. Understanding these underlying mechanisms not only propels geroscientific research, but fosters the development of therapies that can potentially delay or reverse detrimental aging processes.</em></strong></p><h4>Overture and beginners</h4><p>Led by Dr Christian Nefzger, Group Leader, Cellular reprogramming and ageing at UQ, the study employed multi-omic analyses to explore chromatin and transcriptional changes across 22 types of mouse cells, further augmented by existing datasets on human and mouse maturation. The researchers identified a distinct transcription factor binding site (TFBS) signature that is shared between developmental and aging processes, and which is characterized by early-life candidate cis-regulatory elements (cCREs) losing accessibility as organisms mature, while other cCREs gain accessibility through life due to increased levels of Activator Protein 1 (AP-1) [<a href="https://www.sciencedirect.com/science/article/pii/S1550413124002316?via%3Dihub" target="_blank" rel="noreferrer noopener">1</a>].</p><p>Nefzger noted that the mechanisms by which gene activity shifts from birth through adulthood and into old age have remained largely unknown until now.</p><p>“By analyzing molecular datasets from both people and mice and then comparing different age groups over time, we investigated the activity of genes involved in both developmental and ageing processes,” he explained. “Master controller genes regulate which genes are turned on or off in each of our cells, making sure that each cell does its specific job, just as a conductor directs musicians to produce different sounds [<a href="https://www.uq.edu.au/news/article/2024/06/revealing-master-controller-of-development-and-ageing" target="_blank" rel="noreferrer noopener">2</a>].”</p><h4><strong>AP-1: The Master Regulator</strong></h4><p>AP-1 emerged as a pivotal factor in this research, demonstrating its role in progressively activating adult genes while ‘dialing down’ the activity of early-life genes.</p><p>This activity, shared across various cell types, illustrates a fundamental mechanism of aging, and Dr Marina Naval-Sanchez, a Postdoctoral Research Fellow in UQ’s Institute for Molecular Bioscience, added that the study showed this cellular process to be predictable across various life stages as individuals mature.</p><p>“It was ongoing in adulthood, likely because AP-1 is also activated by a number of stress and inflammatory processes as well as by a protein in our blood that increases with age,” she explained. “This further dampens genes most active early in life, which may drive many of the predictable changes of aging [<a href="https://www.uq.edu.au/news/article/2024/06/revealing-master-controller-of-development-and-ageing" target="_blank" rel="noreferrer noopener">2</a>].”</p><p>The study posits that the redistribution of transcription factors such as AP-1, alongside mild downregulation of cell identity transcription factors, prompts chromatin remodeling that alters developmental and metabolic gene expression [<a href="https://www.sciencedirect.com/science/article/pii/S1550413124002316?via%3Dihub" target="_blank" rel="noreferrer noopener">1</a>]. This mechanism can be triggered by elevated AP-1 activity or depletion of repressive H3K27me3, &nbsp;an epigenetic modification to a DNA packaging protein histone, something that highlights the nuanced interplay of genetic and epigenetic factors in aging.</p><h4>Implications for Age-Related Diseases</h4><p>The research holds potential for addressing age-related diseases such as Alzheimer’s, metabolic disorders, and stroke. Dr Ralph Patrick, also a PDRF in the Institute for Molecular Bioscience, explained that to these diseases, it is essential for researchers to first comprehend the underlying processes that cause bodies to age.</p><p>“By pinpointing AP-1 as a master controller linked to aging across cell types, we can now study the effects of drugs that reduce its activity to extend quality of life,” he said [<a href="https://www.uq.edu.au/news/article/2024/06/revealing-master-controller-of-development-and-ageing" target="_blank" rel="noreferrer noopener">2</a>]. Targeting AP-1 and its associated pathways could lead to interventions that slow down or even prevent the onset of these diseases, marking a significant advancement in geriatric medicine.</p><p>Nefzger added that the aim is to prevent age-related diseases from escalating or – even better – occurring in the first place by addressing the underlying aging process, thereby enabling people to age in better health.</p><p>By focusing on the fundamental processes that drive aging, researchers aim to develop strategies that enhance healthspan, the period of life spent in good health, rather than merely extending lifespan. As the understanding of aging at the molecular level continues to evolve, future research will likely explore additional transcription factors and regulatory elements involved in this process, hopefully paving the way for innovative therapeutic approaches that address the challenges of aging.</p><p>[1] <a href="https://www.sciencedirect.com/science/article/pii/S1550413124002316?via%3Dihub" target="_blank" rel="noreferrer noopener">https://www.sciencedirect.com/science/article/pii/S1550413124002316?via%3Dihub</a><br>[2] <a href="https://www.uq.edu.au/news/article/2024/06/revealing-master-controller-of-development-and-ageing" target="_blank" rel="noreferrer noopener">https://www.uq.edu.au/news/article/2024/06/revealing-master-controller-of-development-and-ageing</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Newpipe/yt-dlp stops working (108 pts)]]></title>
            <link>https://github.com/TeamNewPipe/NewPipe/issues/11254</link>
            <guid>40919571</guid>
            <pubDate>Tue, 09 Jul 2024 18:57:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/TeamNewPipe/NewPipe/issues/11254">https://github.com/TeamNewPipe/NewPipe/issues/11254</a>, See on <a href="https://news.ycombinator.com/item?id=40919571">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      


    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>

      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p><react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false">
  
  
  
</react-partial>




      

        

            


<header role="banner" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Actions&quot;,&quot;label&quot;:&quot;ref_cta:Actions;&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Packages&quot;,&quot;label&quot;:&quot;ref_cta:Packages;&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Security&quot;,&quot;label&quot;:&quot;ref_cta:Security;&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Codespaces&quot;,&quot;label&quot;:&quot;ref_cta:Codespaces;&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to GitHub Copilot&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Copilot;&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Code review&quot;,&quot;label&quot;:&quot;ref_cta:Code review;&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Issues&quot;,&quot;label&quot;:&quot;ref_cta:Issues;&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Product&quot;,&quot;action&quot;:&quot;click to go to Discussions&quot;,&quot;label&quot;:&quot;ref_cta:Discussions;&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to GitHub Sponsors&quot;,&quot;label&quot;:&quot;ref_cta:GitHub Sponsors;&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Open Source&quot;,&quot;action&quot;:&quot;click to go to The ReadME Project&quot;,&quot;label&quot;:&quot;ref_cta:The ReadME Project;&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;category&quot;:&quot;Header dropdown (logged out), Enterprise&quot;,&quot;action&quot;:&quot;click to go to Enterprise platform&quot;,&quot;label&quot;:&quot;ref_cta:Enterprise platform;&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
    <a data-analytics-event="{&quot;category&quot;:&quot;Header menu top item (logged out)&quot;,&quot;action&quot;:&quot;click to go to Pricing&quot;,&quot;label&quot;:&quot;ref_cta:Pricing;&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:TeamNewPipe/NewPipe" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="g_THo4CoxceQ-X1uG_GgsS-O4oCI0krJXHaF41jO_9BiXN9AAGnk_3puYHC9dFlxA2V4X14dporxbXbF_6_mVA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="TeamNewPipe/NewPipe" data-current-org="TeamNewPipe" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-blackbird-indexed-repo-csrf="<esi:include src=&quot;/_esi/rails_csrf_token_form_hidden?r=kAMMq7MCwWl2eIlSZ8pgKESi9lwtQ%2FZ5266dEu6mS5XQ6MGJXCjEH50i53RWYPSJegcA1IJl%2FlJ2vR3WXG%2BXpiftDj6UXU1%2F0YsOCOp1LW901v2vl0536A33hnJkFFSgUigJj2jv67USYMqkXFwuI9w%2Fs198uc3e35GjUUOUFhPH0UwMwTqnqdrnI9k2QyysHZ4mM56Teb6Wmg2i4aC0D4nGM%2F1gXrW4UZRjE3%2B%2Bt1oh3Fw3eTWlkGMXOHLw6W1Fey92kuHCBCtcahU%2BzB60bK52dFiUTawYkP0N7IvhZEk%2Bl7Pb%2B8hkuVHTggO1RIDFtSeuI367jIHRgRl3nODKDVvgnSAGKhiixg%2BY7quGpjfmmcDJeqh1%2BWU2VLQAgOMOxhYQSgetWPiQsbzl5Jx%2FaI9s5NhLHG7VPoFaV%2FeGNBHEY2wCXdAspgQHLXBoy4NxWsrxb7zeWCRxig2nJxMmVndo6UMPm8oRXEEQnHG1m4x5J2iaFHxGOzeqsmVp6I9UaKQwvjEZhfH69UDiJm4ioZ0qb7xViQH4FCW2qPO%2F22FH1A%3D%3D--GChvq9%2BPf1cyoFQG--idrKUXEtuyMQOMJPrNXx7w%3D%3D&quot; />" data-nl-search-enabled="false">
  
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&amp;source=header-repo&amp;source_repo=TeamNewPipe%2FNewPipe" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/TeamNewPipe/NewPipe/issues/11254&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="552edf3edb8b655b0ede4b27a40f81c2edae5047efc2e899a02bfcf84b335a7e" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/voltron/issues_fragments/issue_layout;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
        </p></div>
      </div>
</header>

      
    </div>

  








    


    
    <include-fragment data-base-src="https://github.com/notifications/beta/shelf"></include-fragment>





  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  


  
      
    

    






  
  <div id="repository-container-header" data-turbo-replace="">

      <div id="repository-details-container" data-turbo-replace="">
            <ul>
    
        <li>
          <include-fragment src="/TeamNewPipe/NewPipe/sponsor_button"></include-fragment>
        </li>

      

  <li>
            <a href="https://github.com/login?return_to=%2FTeamNewPipe%2FNewPipe" rel="nofollow" id="repository-details-watch-button" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;notification subscription menu watch&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/TeamNewPipe/NewPipe/issues/11254&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="d2de96004db01e4a338be4209845720b89e81f22062a9121c9a727d71efb393b" aria-label="You must be signed in to change notification settings" data-view-component="true">    Notifications
</a>    <tool-tip id="tooltip-ae06272a-6353-42d0-855a-48ddbfb615f4" for="repository-details-watch-button" popover="manual" data-direction="s" data-type="description" data-view-component="true">You must be signed in to change notification settings</tool-tip>

    </li>

  <li>
          <a icon="repo-forked" id="fork-button" href="https://github.com/login?return_to=%2FTeamNewPipe%2FNewPipe" rel="nofollow" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;repo details fork button&quot;,&quot;repository_id&quot;:41889031,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/TeamNewPipe/NewPipe/issues/11254&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="b062d057c376b8f9fce89c5a1c388cb637b23c7c0c92661f89a9e57c8b873cbb" data-view-component="true">    Fork
    <span id="repo-network-counter" data-pjax-replace="true" data-turbo-replace="true" title="2,952" data-view-component="true">3k</span>
</a>
  </li>

  <li>
        
  </li>

</ul>

        </div>

        


          <nav data-pjax="#js-repo-pjax-container" aria-label="Repository" data-view-component="true">

  
    <div data-view-component="true">      <action-menu data-select-variant="none" data-view-component="true">
  <focus-group direction="vertical" mnemonics="" retain="">
    <tool-tip id="tooltip-b1b1acc9-6407-4eff-a0d6-1a6d34ab3849" for="action-menu-94e008b4-26b2-409a-a3c5-18acb94ab9cc-button" popover="manual" data-direction="s" data-type="label" data-view-component="true">Additional navigation options</tool-tip>


<anchored-position id="action-menu-94e008b4-26b2-409a-a3c5-18acb94ab9cc-overlay" anchor="action-menu-94e008b4-26b2-409a-a3c5-18acb94ab9cc-button" side="outside-bottom" anchor-offset="normal" popover="auto" data-view-component="true">
  </anchored-position>  </focus-group>
</action-menu></div>
</nav>

  </div>

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div id="repo-content-pjax-container" data-morpheus-enabled="false" data-channel="eyJjIjoiaXNzdWU6MjM5ODU4MjI1MDp0aW1lbGluZSIsInQiOjE3MjA1NjA2MDN9--3c0fd2ec2de3c55600cafee9adbecd7726fbf774395d55a4ef86055216e79cf2" data-pjax="" data-turbo-frame="">

            
  <div id="partial-discussion-header" data-channel="eyJjIjoiaXNzdWU6MjM5ODU4MjI1MCIsInQiOjE3MjA1NjA2MDN9--0d028370320eb38dd3fd8a0c1a3b2a684c4ffa9f5537bb1127cb733b20e0d9d4" data-url="/TeamNewPipe/NewPipe/issues/11254/show_partial?partial=issues%2Ftitle&amp;sticky=true" data-gid="I_kwDOAn8tB86O93Xq">

          
<details>
  <summary>
    
    New issue
  </summary>
  <details-dialog aria-label="Sign up for GitHub">
            <div>
  <p>
    <strong>Have a question about this project?</strong> Sign up for a free GitHub account to open an issue and contact its maintainers and the community.
  </p>

  

  <p>By clicking “Sign up for GitHub”, you agree to our <a href="https://docs.github.com/terms" target="_blank">terms of service</a> and
  <a href="https://docs.github.com/privacy" target="_blank">privacy statement</a>. We’ll occasionally send you account related emails.</p>

  <p>
    Already on GitHub?
    <a data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;new issue modal&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;LOG_IN&quot;,&quot;originating_url&quot;:&quot;https://github.com/TeamNewPipe/NewPipe/issues/11254&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="b347db2c01b733c78bd83fcb4fd3bb2ab3d674d37a3fd999030338a75c4ca7ca" href="https://github.com/login?return_to=%2FTeamNewPipe%2FNewPipe%2Fissues%2Fnew%2Fchoose">Sign in</a>
    to your account
  </p>
</div>
  </details-dialog>
</details>
        
      </div>


              <div>
        <p><span>Labels</span></p><div>
            
<p><a id="label-02585f" href="https://github.com/TeamNewPipe/NewPipe/labels/template%20ignored" data-name="template ignored" data-view-component="true">
              <span>template ignored</span>
</a></p><tool-tip id="tooltip-d4e26d93-2f6e-4833-857f-340549eaa88a" for="label-02585f" popover="manual" data-direction="s" data-type="description" data-view-component="true">The user didn't follow the template/instructions (or removed them)</tool-tip>
        </div>
      </div>


          
        </div>

</turbo-frame>


    </main>
  </div>

          




    <ghcc-consent id="ghcc" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>


  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tokyo's oldest train line – in pictures (112 pts)]]></title>
            <link>https://www.theguardian.com/artanddesign/gallery/2024/jul/08/tokyos-oldest-train-line-jr-yamanote-in-pictures</link>
            <guid>40919505</guid>
            <pubDate>Tue, 09 Jul 2024 18:51:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/artanddesign/gallery/2024/jul/08/tokyos-oldest-train-line-jr-yamanote-in-pictures">https://www.theguardian.com/artanddesign/gallery/2024/jul/08/tokyos-oldest-train-line-jr-yamanote-in-pictures</a>, See on <a href="https://news.ycombinator.com/item?id=40919505">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-link-name="standfirst" data-component="standfirst">
    

        
            <meta itemprop="description" content="A reportage of the stations along the circular JR Yamanote line in Tokyo, capturing the hustle and bustle at the heart of the world’s biggest urban area. In service since 1885, the line is the city’s oldest, most important and most famous, with millions cramming on to the 35km (22-mile) route’s distinctive green cars every day">
        
    
    
        
            <p>A reportage of stations along the circular JR Yamanote line in Tokyo, capturing the hustle and bustle at the heart of the world’s biggest urban area. In service since 1885, the line is the city’s oldest, most important and most famous, with millions cramming on to the 35km (22-mile) route’s distinctive green cars every day</p>
        
    
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Judge dismisses DMCA copyright claim in GitHub Copilot suit (178 pts)]]></title>
            <link>https://www.theregister.com/2024/07/08/github_copilot_dmca/</link>
            <guid>40919253</guid>
            <pubDate>Tue, 09 Jul 2024 18:25:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/07/08/github_copilot_dmca/">https://www.theregister.com/2024/07/08/github_copilot_dmca/</a>, See on <a href="https://news.ycombinator.com/item?id=40919253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Claims by developers that GitHub Copilot was unlawfully copying their code have largely been dismissed, leaving the engineers for now with just two allegations remaining in their lawsuit against the code warehouse.</p>
<p>The <a target="_blank" href="https://www.theregister.com/2024/01/12/github_copilot_copyright_case_narrowed/">class-action suit</a> against GitHub, Microsoft, and OpenAI was filed in America in November 2022, with the plaintiffs claiming the Copilot coding assistant was trained on open source software hosted on GitHub and as such would suggest snippets from those public projects to other programmers without care for licenses – such as providing appropriate credit for the source – thus violating the original creators' intellectual property rights.</p>
<p>Microsoft owns GitHub and uses OpenAI's generative machine-learning technology to power Copilot, which auto-completes source code for engineers as they type out comments, function definitions, and other prompts.</p>

    

<p>Ergo, the plaintiffs are unhappy that, in their view, portions of their copyrighted open source code might be provided – copied, rather – by Copilot to other programmers to use, without due credit given and other requirements of the original licenses honored.</p>

        


        

<p>The case started with 22 claims in all, and over time this has been whittled down as the defending corporations motioned to have the accusations thrown out of court, requests that Judge Jon Tigar has <a target="_blank" href="https://www.theregister.com/2023/05/12/github_microsoft_openai_copilot/">mostly</a> sustained.</p>
<p>In an <a target="_blank" href="https://regmedia.co.uk/2024/07/08/github_copilot_dismiss.pdf" rel="nofollow">order</a> [PDF] unsealed on Friday, July 5, Judge Tigar ruled on yet another batch of the plaintiffs' claims, and overall it was a win for GitHub, Microsoft, and OpenAI. Three claims were dismissed as requested and just one allowed to continue. According to a count by Microsoft and GitHub's lawyers, that leaves just two allegations standing in total.</p>

        

<p>The most recently dismissed claims were fairly important, with one pertaining to infringement under the Digital Millennium Copyright Act (DMCA), <a target="_blank" rel="nofollow" href="https://www.law.cornell.edu/uscode/text/17/1202">section 1202(b)</a>, which basically says you shouldn't remove without permission crucial "copyright management" information, such as in this context who wrote the code and the terms of use, as licenses tend to dictate.</p>
<p>It was argued in the class-action suit that Copilot was stripping that info out when offering code snippets from people's projects, which in their view would break 1202(b).</p>
<p>The judge disagreed, however, on the grounds that the code suggested by Copilot was not identical enough to the developers' own copyright-protected work, and thus section 1202(b) did not apply. Indeed, last year GitHub <a target="_blank" href="https://www.theregister.com/2023/06/09/github_copilot_lawsuit/">was said</a> to have tuned its programming assistant to generate slight variations of ingested training code to prevent its output from being accused of being an exact copy of licensed software.</p>

        

<p>The plaintiffs won't be able to offer a new section 1202(b) DMCA copyright claim as Judge Tigar dismissed the allegation with prejudice.</p>
<p>The anonymous programmers have repeatedly insisted Copilot could, and would, generate code identical to what they had written themselves, which is a key pillar of their lawsuit since there is an identicality requirement for their DMCA claim. However, Judge Tigar earlier ruled the plaintiffs hadn't actually demonstrated instances of this happening, which prompted a dismissal of the claim with a chance to amend it.</p>
<p>The amended complaint argued that unlawful code copying was an inevitability if users flipped Copilot's anti-duplication safety switch to off, and also cited <a target="_blank" rel="nofollow" href="https://arxiv.org/abs/2202.07646">a study</a> into AI-generated code in attempt to back up their position that Copilot would plagiarize source, but once again the judge was not convinced that Microsoft's system was ripping off people's work in a meaningful way.</p>
<p>Specifically, the judge cited the study's observation that Copilot reportedly "rarely emits memorized code in benign situations, and most memorization occurs only when the model has been prompted with long code excerpts that are very similar to the training data."</p>
<p>"Accordingly, plaintiffs’ reliance on a study that, at most, holds that Copilot may theoretically be prompted by a user to generate a match to someone else’s code is unpersuasive," he concluded.</p>
<p>The DMCA argument was, as we said, one of three claims just now tossed out. The other two were claims for unjust enrichment and punitive damages, though not with prejudice, meaning it's possible these claims could be amended and resubmitted. Until then, however, that leaves the standing claims at just two: an open source license violation allegation, and a breach of contract complaint that was previously reintroduced after being dismissed initially.</p>
<p>"We firmly believe AI will transform the way the world builds software, leading to increased productivity and most importantly, happier developers," GitHub said in a statement to <em>The Register</em>.</p>
<p>"We are confident that Copilot adheres to applicable laws and we’ve been committed to innovating responsibly with Copilot from the start. We will continue to invest in and advocate for the AI-powered developer experience of the future."</p>
<p>We also approached all parties in the lawsuit and their legal teams.</p>
<h3>Both sides squabble during discovery</h3>
<p>Also filed for the case on Friday was a joint case management <a target="_blank" href="https://regmedia.co.uk/2024/07/08/github_copilot_joint_management.pdf" rel="nofollow">statement</a> [PDF] chock full of various grievances and complaints each side made against the other over the discovery process, with both saying the other hasn't given up all the documents they were supposed to.</p>
<p>The plaintiffs accuse the defendants of deliberately dragging their feet, saying the documents that have been produced so far were already publicly available or should have been disclosed a long time ago. Much of the focus is on Microsoft and its single submitted document so far, something that the plaintiffs say makes no sense.</p>
<p>"That Microsoft employees were involved in many of these GitHub-sourced conversations demonstrates that Microsoft's production of one document thus far has been a function of delay and obfuscation, and nothing else," the anonymous developers said. "Microsoft has known but failed to disclose that its employees were directly involved in the creation, operation, and management of Copilot and its underlying models."</p>
<ul>

<li><a href="https://www.theregister.com/2024/06/24/udio_suno_riaa/">Record labels gang up to sue AI music generator duo into utter oblivion</a></li>

<li><a href="https://www.theregister.com/2024/04/30/newspapers_microsoft_openai/">More big city newspapers drag Microsoft, OpenAI hard in copyright lawsuit</a></li>

<li><a href="https://www.theregister.com/2024/03/11/authors_file_lawsuit_to_torpedo/">Filing NeMo: Nvidia's AI framework hit with copyright lawsuit</a></li>

<li><a href="https://www.theregister.com/2024/04/22/ghaderi_v_amazon/">Ex-Amazon exec claims she was asked to ignore copyright law in race to AI</a></li>
</ul>
<p>The lack of documents from the Windows maker is apparently down to "technical difficulties" in collecting Slack messages, something the plaintiffs aren't convinced by. Similarly, the programmers say that OpenAI should have also submitted lots more information by now, pointing out that it had submitted tens of thousands as a <a target="_blank" href="https://www.theregister.com/2023/09/21/authors_guild_openai_lawsuit/">defendant</a> in the Authors Guild lawsuit.</p>
<p>Microsoft and GitHub, however, counter that the plaintiffs have been asking for way too much info, accusing them of having "failed to pursue relevant discovery of these topics efficiently and in good faith." One of these topics includes Microsoft's 2018 acquisition of GitHub.</p>
<p>Meanwhile, OpenAI says the plaintiffs haven't been following proper procedure in respect to asking for emails, saying it can't (or won't) produce any until it receives a correct request.</p>
<p>The corporate trio also say that the dismissal of the above DMCA copyright claim has fundamentally changed the case and argue that the scope of discovery should now be narrowed. This is something the plaintiffs dispute on the grounds that the open source license violation claim pertains to pretty much the same documents as the DMCA issue should bring up.</p>
<p>GitHub, Microsoft, and OpenAI say the plaintiffs haven't properly responded to their discovery requests, arguing that their documents include "JSON files, a blank HTML file, emails without any metadata, and improperly redacted PNG files of Slack and other messages."</p>
<p>The plaintiffs have asked for more time for discovery, and although the defendants argue this isn't necessary, the three tech titans say they're open to a "reasonable extension." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't use 7-segment displays (2011) [pdf] (114 pts)]]></title>
            <link>https://harold.thimbleby.net/cv/files/seven-segment.pdf</link>
            <guid>40918829</guid>
            <pubDate>Tue, 09 Jul 2024 17:42:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://harold.thimbleby.net/cv/files/seven-segment.pdf">https://harold.thimbleby.net/cv/files/seven-segment.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=40918829">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: How do browsers isolate internal audio from microphone input? (155 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=40918152</link>
            <guid>40918152</guid>
            <pubDate>Tue, 09 Jul 2024 16:45:01 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=40918152">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="40918539"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918539" href="https://news.ycombinator.com/vote?id=40918539&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>The way this works (and I'm obviously taking a high level view here) is by comparing what is being played to what is being captured. There is an inherent latency in between what is called the capture stream (the mic) and the reverse stream (what is being output to the speakers, be it people taking or music or whatever), and by finding this latency and comparing, one can cancel the music from the speech captured.</p><p>Within a single process, or tree of processes that can cooperate, this is straightforward (modulo the actual audio signal processing which isn't) to do: keep what you're playing for a few hundreds milliseconds around, compare to what you're getting in the microphone, find correlations, cancel.</p><p>If the process aren't related there are multiple ways to do this. Either the OS provides a capture API that does the cancellation, this is what happens e.g. on macOS for Firefox and Safari, you can use this. The OS knows what is being output. This is often available on mobile as well.</p><p>Sometimes (Linux desktop, Windows) the OS provides a loopback stream: a way to capture the audio that is being played back, and that can similarly be used for cancellation.</p><p>If none of this is available, you mix the audio output and perform cancellation yourself, and the behaviour your observe happens.</p><p>Source: I do that, but at Mozilla and we unsurprisingly have the same problems and solutions.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40919287"><td></td></tr>
            <tr id="40918748"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40918748" href="https://news.ycombinator.com/vote?id=40918748&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>It just seems more logical for the OS to do that, rather than the application. Basically every application that uses microphone input will want to do this, and will want to compensate for all audio output of the device, not just its own. Why does the OS not provide a way to do this?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40920538"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40920538" href="https://news.ycombinator.com/vote?id=40920538&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>&gt; Why does the OS not provide a way to do this?</p><p>Some do.</p><p>But you need to have a strong-handed OS team that's willing to push everybody towards their most modern and highly integrated interfaces and sunset their older interfaces.</p><p>Not everybody wants that in their OS. Some want operating systems that can be pieced together from myriad components maintained by radically different teams, some want to see their API's/interfaces preserved for decades of backwards compatibility, some want minimal features from their OS and maximum raw flexibility in user space, etc</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40920688"><td></td></tr>
                <tr id="40921324"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40921324" href="https://news.ycombinator.com/vote?id=40921324&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>As others have noted, this is trivial for most macOS and iOS apps to opt in to.</p><p>Frankly, I imagine its also available at the system level on Windows (and maybe Android and Linux) but probably only among applications that happen to be using certain audio frameworks/engines.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40918955"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40918955" href="https://news.ycombinator.com/vote?id=40918955&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>&gt; Basically every application that uses microphone input will want to do this</p><p>The OS doesn't have more information about this than applications and it's not that obvious whether an application wants the OS to fuck around with the audio input it sees. Even in the applications where this might be the obvious default behavior, you're wrong - since most listeners don't use loudspeakers at all, and this is not a problem when they wear headphones. And detecting that (also, is the input a microphone at all?) is not straightforward.</p><p>Not all audio applications are phone calls.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40919806"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40919806" href="https://news.ycombinator.com/vote?id=40919806&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>&gt;<i>The OS doesn't have more information about this than applications</i></p><p>the OP pointed out that this only works if he uses a browser monoculture</p><p>the OS does have more information than that, it can know what is being played by any/all apps, and what is being picked up by the mic</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40920152"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40920152" href="https://news.ycombinator.com/vote?id=40920152&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>The "OS" isn't special here, apps can listen to system audio.</p><p>fwiw, you only need to know anything about outputs if you are doing AEC. Blind source separation doesn't have that problem and can just process the input stream.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40921222"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40921222" href="https://news.ycombinator.com/vote?id=40921222&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>&gt; The "OS" isn't special here, apps can listen to system audio.</p><p>Even if this is true, it's easy to imagine such functionality being exploited by malicious apps as a security and/or privacy concern, particularly if the user needs a screen reader.</p><p>It definitely makes sense for the operating system to provide this functionality.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40920103"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40920103" href="https://news.ycombinator.com/vote?id=40920103&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>Assuming this isn't parody, the OS doesn't have to do it automatically. Having an application grab a microphone stream and say to the OS "take this and cancel any audio out streams" might be pretty useful.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40920206"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40920206" href="https://news.ycombinator.com/vote?id=40920206&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>I agree with that, but the point I'm trying to make is that audio i/o handling is pretty complicated and application specific. The idea I'm challenging is that "any app that wants microphone input wants this" is dubious. I'd say it's only a small number of audio applications that care about mic input want background noise reduced - and it makes sense for this to be configured per-input stream.</p><p><i>Really</i> what would be nice is if every audio i/o backend supported multiplex i/o streams and you could configure whether or not to cancel audio based on that set of streams but not all output (because multi output-device audio gets tricky).</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40921013"><td><table>  <tbody><tr>    <td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td>
      <center><a id="up_40921013" href="https://news.ycombinator.com/vote?id=40921013&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>I'm honestly having trouble thinking of a case where you wouldn't want this.</p><p>I'm sure there <i>are</i> some very niche cases, but in those cases, the application can specifically request that the OS turn off audio isolation.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40921366"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_40921366" href="https://news.ycombinator.com/vote?id=40921366&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>Live video or audio chat is basically the only time you do want this. Granted, that’s a big chunk of microphone usage in practice, but any time you are doing higher fidelity audio recording and you have set up the inputs accordingly you absolutely do not want the artefacts introduced by this cancellation. DAWs, audio calibration, and even live audio when you’ve ensured the output cannot impact the recording all would want it switched off.</p><p>Default on vs default off is really just an implementation detail of the API though, as you say.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40921259"><td><table>  <tbody><tr>    <td indent="6"><img src="https://news.ycombinator.com/s.gif" height="1" width="240"></td><td>
      <center><a id="up_40921259" href="https://news.ycombinator.com/vote?id=40921259&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>The technique introduces latency and distortion because it's subtracting an estimate of  sound that's traveling/reflecting in the listening environment, which is imperfect and involves the speed of sound.</p><p>That latency is within the tolerance that users are comfortable with for voice chat, and much less than video processing/transfer is introducing for video calls anyway, so it's a very obvious win there. Especially since those users are most interested in just picking out clear words using whatever random mic/speaker configuration happens to be most convenient.</p><p>But musicians, for instance, are much more interested in minimizing the delay between their voice or instrument being captured and returned through a monitor, and they generally choose a hardware arrangement that avoids the problem in the first place. And that's not really a niche use case.</p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="40919570"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40919570" href="https://news.ycombinator.com/vote?id=40919570&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>The OS can have multiple sound input devices for the application to choose from, "raw" and "fuckarounded with"</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40920078"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_40920078" href="https://news.ycombinator.com/vote?id=40920078&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>That doesn't make sense in the context of default devices. MacOS's AVKit (or is it CoreAudio?) APIs that configure the streams created on the device makes way more sense, since it's a property of the audio i/o stream and not the devices.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40919211"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40919211" href="https://news.ycombinator.com/vote?id=40919211&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>On mac/iOS, you get this using the AVAudioEngine API if you set voiceProcessingEnabled to true on the input node. It corrects for audio being played from all applications on the device.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40921264"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40921264" href="https://news.ycombinator.com/vote?id=40921264&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>This has certainly made conference calls significantly more usable. I feel like it must have come around during 2020, because I feel like pre-covid I would go around BEGGING everyone I did calls with to get a headset, because otherwise everyone else's voice would echo back through their microphone 0.75s later. Today I recently realized I could just literally do calls out loud on my laptop mic and speaker and somehow it works. Nice to know why!</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40919343"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40919343" href="https://news.ycombinator.com/vote?id=40919343&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>My first thought in reading the question was “if your <i>browser</i> is doing that, your platform architecture has… some room for improvement”.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40921274"><td></td></tr>
                        <tr id="40920866"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40920866" href="https://news.ycombinator.com/vote?id=40920866&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>This assumes there is an OS-managed software mixer sitting in the middle of all audio streams between programs and devices. Historically, that wasn't the case, because it would introduce a lot of latency and jitter in the audio. I believe it is still possible for a program to get exclusive access to an audio output device on Windows (WASAPI) and Linux (ALSA).</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40920328"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40920328" href="https://news.ycombinator.com/vote?id=40920328&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>The OS doesn't know that the application doesn't want feedback from the speaker, and not 100% of applications will want such filtering.  I think a best practice from the OS side would be to provide it as an optional flag.  (Default could be on or off, with reasonable possibility for debate in either direction, but an app that really knows what it wants should be able to ask for it.)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40919007"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40919007" href="https://news.ycombinator.com/vote?id=40919007&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>I suppose the OS probably makes something like this available, when using Voiceover on Mac and presenting in teams by default only the mic comes into teams, you need to do something to share the other processes audio.</p><p>That's mac of course but in my experience Windows is much more trusting of what it gives applications access to so I suppose the same thing is available there.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40918789"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40918789" href="https://news.ycombinator.com/vote?id=40918789&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>How sure are you that Basically every application wants this? So should there be a flag at the os level for enabling the cancellation? How do you control that flag?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40919511"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_40919511" href="https://news.ycombinator.com/vote?id=40919511&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>It would be trivial to pass that flag in whatever API the application calls to request access to the microphone stream.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40919272"><td></td></tr>
                  <tr id="40918963"><td></td></tr>
                <tr id="40919047"><td></td></tr>
                <tr id="40919698"><td></td></tr>
                              <tr id="40918786"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918786" href="https://news.ycombinator.com/vote?id=40918786&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>It's called Acoustic Echo Cancellation. An implementation is included in WebRTC included in Chrome. A FIR filter (1D convolution) is applied to what the browser knows is coming out of the speakers; and this filter is continually optimized to to cancel out as much as possible of what's coming into the microphone (this is a first approximation, the actual algorithm is more involved).</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="40919444"><td></td></tr>
                  <tr id="40918941"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918941" href="https://news.ycombinator.com/vote?id=40918941&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>Search for the compilation flag "CHROME_WIDE_ECHO_CANCELLATION" in the Chromium sources, and you will find your answer.</p><p>Can't tell you anything else due to NDAs.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40919018"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40919018" href="https://news.ycombinator.com/vote?id=40919018&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>It's kind of nuts that (I'm assuming) the source code is publicly available but the developers who wrote it can't talk about it.</p><p>(I realize this situation isn't up to you and I appreciate that you chimed in as you could!)</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40920472"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_40920472" href="https://news.ycombinator.com/vote?id=40920472&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>This is super common.</p><p>When I worked at Mozilla, most stuff was open, but I still couldn't talk about stuff publicly because I wasn't a spokesperson for Mozilla.  Same at OpenDNS/Cisco, or at Fastly, and now at Amazon.  Lots of stuff I can talk about, but I generally avoid threads and comments about Amazon, or if I do, it's strictly to reference public documentation, public releases, or that sort of thing.</p><p>It's easier to simply not participate, link a document, or say no comment than it is to cross reference what I might say against what's public, and what's not.</p></div></td></tr>
        </tbody></table></td></tr>
                        <tr id="40918753"><td></td></tr>
                <tr id="40921252"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40921252" href="https://news.ycombinator.com/vote?id=40921252&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>I seem to remember analog telephone lines used a very simple but magic-looking transformer-based circuit of some sort for this purpose. Presumably that worked because they didn’t need to worry about a processing delay?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40918731"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918731" href="https://news.ycombinator.com/vote?id=40918731&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>A side effect of echo cancellation. Browser knows what audio it is playing, can correlate that to whatever comes in through the mic, maybe even by outputing inaudible test signals, or by picking wide supported defaults.</p><p>This is needed because many people don't use headphones and if you have more than one endpoint with mic and speakers open you will get feedback gallore if you don't do something to suppress it.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40918624"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918624" href="https://news.ycombinator.com/vote?id=40918624&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>Google Meet uses source separation technology to denoise the audio. It's a neural net that's been trained to separate speech from non-speech and ensure that only speech is being piped through. It can even separate different speakers from one another. This technology got really good around 2021 when semi-supervised ways of training the models were developed, and is still improving :)</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40918993"><td></td></tr>
            <tr id="40918497"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918497" href="https://news.ycombinator.com/vote?id=40918497&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>I think this would be part of echo cancellation: in a meeting you don't want the data from the meeting to be fed back to it. I suppose it uses the all the streams from the browser then, though I think in general it would be even better to cancel out everything that comes from the speakers. Maybe it can work this way on some other platforms?</p><p>E.g. PulseAudio and Pipewire have a module for echo cancellation.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="40918446"><td></td></tr>
            <tr id="40919073"><td></td></tr>
            <tr id="40918770"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918770" href="https://news.ycombinator.com/vote?id=40918770&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>Since chrome has the data from both sources: the microphone, and the audio stream from YouTube, I imagine you can construct a filter from the impulse response of the YouTube source and then run the microphone through it</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40918464"><td></td></tr>
            <tr id="40918476"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918476" href="https://news.ycombinator.com/vote?id=40918476&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>This is something that is usually taken care of by the App that's receiving the input from the microphone (Google Meet, Teams, etc). The App breaks the audio into frequencies, and the ones that correspond to human voice ranges are accepted, and anything else is rejected. This is referred to as, for example, voice isolation, and has been turned on by default in all major meeting Apps for a little while now.</p><p>Surprised to hear that it doesn't seem to work for you when the audio is generated by a different browser, this shouldn't make a difference.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="40918663"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_40918663" href="https://news.ycombinator.com/vote?id=40918663&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div><p>Assuming OP is correct, your last sentence implies this isn't the solution being used.</p><p>Additionally, many (<i>citation needed</i>) Youtube videos have people talking in them; this method wouldn't help with that.</p><p>Isolating vocals in general is significantly more difficult than just relying on frequency range. Any instrument I can think of can generate notes that are squarely in the common range of a human (see: <a href="https://www.dbamfordmusic.com/frequency-range-of-instruments.html" rel="nofollow">https://www.dbamfordmusic.com/frequency-range-of-instruments...</a>)</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="40919167"><td></td></tr>
            <tr id="40918468"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_40918468" href="https://news.ycombinator.com/vote?id=40918468&amp;how=up&amp;goto=item%3Fid%3D40918152"></a></center>    </td><td><br><div>
                  <p>Guessing it's a feature of the WebRTC stack if it's to be found anywhere, there's always a requirement for cancelling feedback from other meeting participants</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="40919057"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Chrome has a special hidden API accesible only from *.google.com (727 pts)]]></title>
            <link>https://twitter.com/lcasdev/status/1810696257137959018</link>
            <guid>40918052</guid>
            <pubDate>Tue, 09 Jul 2024 16:35:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/lcasdev/status/1810696257137959018">https://twitter.com/lcasdev/status/1810696257137959018</a>, See on <a href="https://news.ycombinator.com/item?id=40918052">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Linksys Velop routers send Wi-Fi passwords in plaintext to US servers (418 pts)]]></title>
            <link>https://stackdiary.com/linksys-velop-routers-send-wi-fi-passwords-in-plaintext-to-us-servers/</link>
            <guid>40917312</guid>
            <pubDate>Tue, 09 Jul 2024 15:33:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stackdiary.com/linksys-velop-routers-send-wi-fi-passwords-in-plaintext-to-us-servers/">https://stackdiary.com/linksys-velop-routers-send-wi-fi-passwords-in-plaintext-to-us-servers/</a>, See on <a href="https://news.ycombinator.com/item?id=40917312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page"><main id="main" tabindex="-1"><article><header data-canvas-grid="container" data-post-type="post" data-section="first" data-style="stack" data-has-featured-image="true"><div><div data-has-excerpt="true"><p>
It’s as if the routers themselves forgot the first rule of cybersecurity: don’t write your secrets on a postcard.</p></div><div><p>
<span>
<span>
<span>Published</span>
<time datetime="2024-07-09T15:32:29+00:00">
July 9, 2024		</time>
</span>
</span>
<span>
<span>
2 min read	</span>
</span></p></div></div><figure>
<img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjY3NSIgdmlld0JveD0iMCAwIDEyMDAgNjc1Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" width="1200" height="675" data-src="https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server.jpg" alt="Linksys Velop routers send Wi-Fi password in plaintext to US server" loading="eager" data-sizes="(min-width: 82.75em) 1284px, calc(100vw - 16px)" onload="this.setAttribute(&quot;data-loaded&quot;, true)" decoding="async" fetchpriority="high" data-srcset="https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server.jpg 1200w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-300x169.jpg 300w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-701x394.jpg 701w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-768x432.jpg 768w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-500x281.jpg 500w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-640x360.jpg 640w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-855x481.jpg 855w, https://stackdiary.com/wp-content/uploads/2024/07/Linksys-Velop-routers-send-Wi-Fi-password-in-plaintext-to-US-server-1120x630.jpg 1120w"></figure></header><div><div><p>According to Testaankoop, the Belgian equivalent of the Consumers’ Association, two types of Linksys routers are <a href="https://www.test-aankoop.be/hightech/wifi-versterkers/nieuws/router-linksys-onveilig" target="_blank" rel="noreferrer noopener nofollow">sending Wi-Fi login details in plaintext</a> to American Amazon servers. This discovery involves the Linksys Velop Pro 6E and Velop Pro 7 mesh routers.</p><p>During routine installation checks, Testaankoop detected several data packets being transmitted to an Amazon server in the US. These packets included the configured SSID name and password in clear text, identification tokens for the network within a broader database, and an access token for a user session, potentially paving the way for a man-in-the-middle (MITM) attack.</p><blockquote><p>During installation, the router sent several data packets to an Amazon server in the US. These packets contained the configured SSID name and password in clear text, as well as some identification tokens for this network within a broader database and an access token for a user session that could potentially enable a MITM attack.</p>
<cite>Testaankoop</cite></blockquote><p>A MITM attack is a security breach in which an attacker intercepts communication between two parties without either party’s knowledge, allowing the attacker to read or alter the exchanged messages.</p><p>The consumer organization conducted these tests using the latest firmware available at the time. Despite warning Linksys in November, no effective measures have been taken. A firmware update appeared months later, but the problem persists. “We regret the lack of response from Linksys and expected more from such a renowned brand,” Testaankoop expressed.</p><p>Testaankoop suspects the security issue might stem from third-party software used in the Linksys firmware. However, they emphasize that this does not excuse the vulnerability. For those who already own the affected routers, they have recommended changing the Wi-Fi network name and password via the web interface instead of the app. This precaution prevents the SSID name and password from being transmitted in readable text.</p><p>Mesh routers like <a href="https://store.linksys.com/shop/shop-home/whole-home-mesh-wifi/" target="_blank" rel="noreferrer noopener nofollow">the Velop series</a> are designed to improve Wi-Fi distribution in large or multi-story homes by creating a wireless network through multiple connected nodes. These nodes communicate either wirelessly or through cables to ensure better Wi-Fi coverage. However, the Velop Pro WiFi 6E and Pro 7’s data transmission practices undermine the security benefits they should provide.</p><p>Testaankoop contacted Linksys again just days before today’s publication in response to the ongoing issue, giving them a brief window to respond. However, they have not received any acknowledgment or solution from the manufacturer.</p><p>The vulnerability persists even in the latest Linksys 7 Pro, highlighting a critical security lapse. “After our long and intensive tests, we strongly advise against buying the Linksys Velop Pro WiFi 6E and Pro 7 because there is a serious risk of network intrusion and data loss,” the researchers concluded.</p><p><em>Stack Diary has also contacted Linksys to see if they plan on responding.</em></p></div><div data-author-bio="true"><h2>
<span>Posted by</span>
<a href="https://stackdiary.com/author/alex/">Alex Ivanovs</a></h2><p>Alex is the lead editor at <em>Stack Diary</em> and covers stories on tech, artificial intelligence, security, privacy and web development. He previously worked as a lead contributor for Huffington Post for their <em>Code</em> column.</p></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Another AI company wrote us and here’s our response (146 pts)]]></title>
            <link>https://warandpeas.com/2024/07/09/another-ai-company-wrote-us-and-heres-our-response/</link>
            <guid>40917299</guid>
            <pubDate>Tue, 09 Jul 2024 15:32:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://warandpeas.com/2024/07/09/another-ai-company-wrote-us-and-heres-our-response/">https://warandpeas.com/2024/07/09/another-ai-company-wrote-us-and-heres-our-response/</a>, See on <a href="https://news.ycombinator.com/item?id=40917299">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

					
<main id="primary" role="main">

	
		
<article id="post-26587" itemscope="" itemtype="http://schema.org/BlogPosting" itemprop="blogPost">
	

	<div itemprop="articleBody">
		
		<h2>Why the current hype around AI is a slap in the face for creatives</h2>
<div>
<p>Almost every day we receive emails from AI companies who want to work with us. In these emails, someone cheerfully suggests a ‘collaboration’ in which they propose that we promote their product.</p>
<p>It is an understatement to say that these emails are in poor-taste. While we are usually interested in technology and try to remain optimistic about this field, we feel it’s necessary to speak out about the unbearable hype-cycle that generative AI has brought with it. A hype-cycle that has originated by stealing creative work, and now wishes to further damage creative energy by funnelling it into an automated content-creation nightmare.</p>
<p><em>Today we’d like to show you one of these emails and our response.</em></p>
<p><img decoding="async" data-attachment-id="26588" data-permalink="https://warandpeas.com/2024/07/09/another-ai-company-wrote-us-and-heres-our-response/response-to-muse-1/" data-orig-file="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?fit=2300%2C726&amp;ssl=1" data-orig-size="2300,726" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="response-to-muse-1" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?fit=300%2C95&amp;ssl=1" data-large-file="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?fit=1024%2C323&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=768%2C242&amp;ssl=1" alt="A screenshot of an email from Muse to War and Peas. The email is written by a collaboration manager at Muse and discusses the platform's capabilities in creating AI-generated series. The email highlights several benefits of using Muse, such as making your own series with a script, bringing book characters to life, promoting new projects by creating mini-series, helping create content by building other worlds, and making stories come alive for the audience. The sender invites War and Peas to discuss potential collaboration and be among the first creators to gain an early advantage in content creation. The email is signed off by the collaboration manager." width="768" height="242" srcset="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=768%2C242&amp;ssl=1 768w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=1024%2C323&amp;ssl=1 1024w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=1536%2C485&amp;ssl=1 1536w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=2048%2C646&amp;ssl=1 2048w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=1200%2C379&amp;ssl=1 1200w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=700%2C221&amp;ssl=1 700w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20242'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=768%2C242&amp;ssl=1 768w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=300%2C95&amp;ssl=1 300w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=1024%2C323&amp;ssl=1 1024w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=1536%2C485&amp;ssl=1 1536w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=2048%2C646&amp;ssl=1 2048w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=1200%2C379&amp;ssl=1 1200w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=700%2C221&amp;ssl=1 700w" data-lazy-src="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-1.jpg?resize=768%2C242&amp;ssl=1"></p>
<blockquote><p>Hi war.and.peas,</p>
<p>It’s XXX and I’m writing to you on behalf of Muse. Muse is a new creative platform that can create your own AI-generated series so you can dive into a new world of storytelling without the need for personal content creation.</p>
<p>For example, with Muse you can:</p>
<p>make your own series with your script/storyline<br>
bring your book characters to life<br>
promote your new project/book by creating a mini-series<br>
help create content by creating other worlds<br>
make your story come alive for your audience by creating a series about it.</p>
<p>Please let me know if you would like to discuss collaborating and becoming one of the first creators to gain an early advantage in the realm of content creation.</p>
<p>Best regards,<br>
<strong>XXX<br>
</strong>Collaboration Manager</p></blockquote>
<p>Here’s our response:</p>
<p><img loading="lazy" decoding="async" data-attachment-id="26589" data-permalink="https://warandpeas.com/2024/07/09/another-ai-company-wrote-us-and-heres-our-response/response-to-muse-2/" data-orig-file="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?fit=2306%2C988&amp;ssl=1" data-orig-size="2306,988" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="response-to-muse-2" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?fit=300%2C129&amp;ssl=1" data-large-file="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?fit=1024%2C439&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=768%2C329&amp;ssl=1" alt="A screenshot of an email response from War and Peas to Muse. The email is from Elizabeth Pich and Jonathan Kunz, a webcomic duo who have been creating original comics since 2011. They express their appreciation for being contacted but politely decline the offer to collaborate with Muse. They provide several reasons for their decision:

The rise of AI has been built on the work of creative individuals like themselves, without proper compensation or acknowledgment.
Social media platforms thrive on engaging, original content created by people, but creators have not been fairly rewarded.
Most artists love their work and prefer to be properly compensated rather than outsource their creativity to AI. They emphasize the personal nature of storytelling.
Artists would benefit more from AI tools that assist with administrative tasks rather than creative ones.
The email concludes by stating that the Muse platform does not align with their values, as it devalues creative work and promotes derivative content. They hope for a shift towards more inclusive, artist-focused approaches in the industry. The email is signed by Elizabeth Pich and Jonathan Kunz." width="768" height="329" srcset="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=768%2C329&amp;ssl=1 768w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=300%2C129&amp;ssl=1 300w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=1024%2C439&amp;ssl=1 1024w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=1536%2C658&amp;ssl=1 1536w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=2048%2C877&amp;ssl=1 2048w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=1200%2C514&amp;ssl=1 1200w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=700%2C300&amp;ssl=1 700w" sizes="(max-width: 768px) 100vw, 768px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20768%20329'%3E%3C/svg%3E" data-lazy-srcset="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=768%2C329&amp;ssl=1 768w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=300%2C129&amp;ssl=1 300w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=1024%2C439&amp;ssl=1 1024w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=1536%2C658&amp;ssl=1 1536w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=2048%2C877&amp;ssl=1 2048w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=1200%2C514&amp;ssl=1 1200w, https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=700%2C300&amp;ssl=1 700w" data-lazy-src="https://i0.wp.com/warandpeas.com/wp-content/uploads/2024/07/response-to-muse-2.jpg?resize=768%2C329&amp;ssl=1"></p>
<blockquote><p>Dear XXX,</p>
<p>thank you for contacting us. We are a webcomic duo that has been creating original comics since 2011 and sharing them on various platforms on the web.</p>
<p>Usually we are very keen on connecting with potential partners that value our art and wish to help us in making a living. However, in this case we must politely decline. Here are some reasons why:</p>
<ul>
<li>The surge in AI has been built on the backs of creative people like us. Artists’ work has been harvested in order to train large language models and they have not been informed or compensated.</li>
<li>Social Media platforms cannot grow without engaging and original content, made by people. This is the basis for any user to join. Creators have – in large part – not been privy to the rewards that these platforms have generated over the years even though they are the reason for platform growth. Any business model that does not acknowledge this and does not seek proper compensation for artists is not of interest to us.</li>
<li>While being creative is surely not always fun, most artists love their work and do not want to outsource their passion to a machine that does this for them. They would much rather be properly compensated for their work in order to continue to be able to do said work. Frankly, storytelling “without the need for personal content creation” sounds horrible. Storytelling is personal. It is a connection between the writer and the reader. Without this personal connection, storytelling loses its purpose.</li>
<li>Artists would much rather have an AI that actually helps with grunt chores, such as writing invoices, or helping with taxes in order to focus more on fulfilling creative tasks. Such an AI-tool would be of much more value to the artist community.For these reasons, we hope it has become self-evident that your platform does not do anything for us. On the contrary, it works against a world in which creative work is valued and elevated. It turns creative work into an assembly-line meant to churn out derivative and soulless ‘content’ to supply the attention-factory that has become social media.We hope that these efforts will soon be seen as what they are and be quickly abandoned in favor of a more inclusive artist-focused approach.
<p>Best regards,<br>
Elizabeth Pich &amp; Jonathan Kunz</p></li>
</ul>
</blockquote>
</div>
<div><p>Join our Patreon to get secret comics, behind the scenes, and more...</p><p><a rel="nofollow" target="_blank" href="https://patreon.com/warandpeas?utm_content=post_button&amp;utm_medium=patron_button_and_widgets_plugin&amp;utm_campaign=333887&amp;utm_term=&amp;utm_source=https://warandpeas.com/2024/07/09/another-ai-company-wrote-us-and-heres-our-response/" aria-label="Click to become a patron at Patreon!"><img decoding="async" src="https://i0.wp.com/warandpeas.com/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?w=1500&amp;ssl=1" alt="Become a patron at Patreon!" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://i0.wp.com/warandpeas.com/wp-content/plugins/patron-button-and-widgets-by-codebard/images/become_a_patron_button.png?w=1500&amp;ssl=1"></a></p></div>
		
			</div>

	
</article>

		
	
</main>



	



					
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CVE-2024-6409: OpenSSH: Possible remote code execution in privsep child (132 pts)]]></title>
            <link>https://www.openwall.com/lists/oss-security/2024/07/08/2</link>
            <guid>40916820</guid>
            <pubDate>Tue, 09 Jul 2024 14:51:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openwall.com/lists/oss-security/2024/07/08/2">https://www.openwall.com/lists/oss-security/2024/07/08/2</a>, See on <a href="https://news.ycombinator.com/item?id=40916820">Hacker News</a></p>
<div id="readability-page-1" class="page">


<table>
<tbody><tr>

<td>
<a href="https://www.openwall.com/"><img src="https://www.openwall.com/logo.png" width="182" height="80" alt="Openwall"></a>
</td><td>
<div>
<ul>
<li><a href="https://www.openwall.com/">Products</a>
<ul>
<li><a href="https://www.openwall.com/Owl/">Openwall GNU/*/Linux &nbsp; <i>server OS</i></a>
</li><li><a href="https://www.openwall.com/lkrg/">Linux Kernel Runtime Guard</a>
</li><li><a href="https://www.openwall.com/john/">John the Ripper &nbsp; <i>password cracker</i></a>
<ul>
<li><a href="https://www.openwall.com/john/">Free &amp; Open Source for any platform</a>
</li><li><a href="https://www.openwall.com/john/cloud/">in the cloud</a>
</li><li><a href="https://www.openwall.com/john/pro/linux/">Pro for Linux</a>
</li><li><a href="https://www.openwall.com/john/pro/macosx/">Pro for macOS</a>
</li></ul>
</li><li><a href="https://www.openwall.com/wordlists/">Wordlists &nbsp; <i>for password cracking</i></a>
</li><li><a href="https://www.openwall.com/passwdqc/">passwdqc &nbsp; <i>policy enforcement</i></a>
<ul>
<li><a href="https://www.openwall.com/passwdqc/">Free &amp; Open Source for Unix</a>
</li><li><a href="https://www.openwall.com/passwdqc/windows/">Pro for Windows (Active Directory)</a>
</li></ul>
</li><li><a href="https://www.openwall.com/yescrypt/">yescrypt &nbsp; <i>KDF &amp; password hashing</i></a>
</li><li><a href="https://www.openwall.com/yespower/">yespower &nbsp; <i>Proof-of-Work (PoW)</i></a>
</li><li><a href="https://www.openwall.com/crypt/">crypt_blowfish &nbsp; <i>password hashing</i></a>
</li><li><a href="https://www.openwall.com/phpass/">phpass &nbsp; <i>ditto in PHP</i></a>
</li><li><a href="https://www.openwall.com/tcb/">tcb &nbsp; <i>better password shadowing</i></a>
</li><li><a href="https://www.openwall.com/pam/">Pluggable Authentication Modules</a>
</li><li><a href="https://www.openwall.com/scanlogd/">scanlogd &nbsp; <i>port scan detector</i></a>
</li><li><a href="https://www.openwall.com/popa3d/">popa3d &nbsp; <i>tiny POP3 daemon</i></a>
</li><li><a href="https://www.openwall.com/blists/">blists &nbsp; <i>web interface to mailing lists</i></a>
</li><li><a href="https://www.openwall.com/msulogin/">msulogin &nbsp; <i>single user mode login</i></a>
</li><li><a href="https://www.openwall.com/php_mt_seed/">php_mt_seed &nbsp; <i>mt_rand() cracker</i></a>
</li></ul>
</li><li><a href="https://www.openwall.com/services/">Services</a>
</li><li id="narrow-li-1"><a>Publications</a>
<ul>
<li><a href="https://www.openwall.com/articles/">Articles</a>
</li><li><a href="https://www.openwall.com/presentations/">Presentations</a>
</li></ul>
</li><li><a>Resources</a>
<ul>
<li><a href="https://www.openwall.com/lists/">Mailing lists</a>
</li><li><a href="https://openwall.info/wiki/">Community wiki</a>
</li><li><a href="https://github.com/openwall">Source code repositories (GitHub)</a>
</li><li><a href="https://cvsweb.openwall.com/">Source code repositories (CVSweb)</a>
</li><li><a href="https://www.openwall.com/mirrors/">File archive &amp; mirrors</a>
</li><li><a href="https://www.openwall.com/signatures/">How to verify digital signatures</a>
</li><li><a href="https://www.openwall.com/ove/">OVE IDs</a>
</li></ul>
</li><li id="last-li"><a href="https://www.openwall.com/news">What's new</a>
</li></ul>
</div>


</td></tr></tbody></table>




<a href="https://www.openwall.com/lists/oss-security/2024/07/08/1">[&lt;prev]</a> <a href="https://www.openwall.com/lists/oss-security/2024/07/08/3">[next&gt;]</a> <a href="https://www.openwall.com/lists/oss-security/2024/07/04/2">[&lt;thread-prev]</a> <a href="https://www.openwall.com/lists/oss-security/2024/07/09/2">[thread-next&gt;]</a> <a href="https://www.openwall.com/lists/oss-security/2024/07/08/">[day]</a> <a href="https://www.openwall.com/lists/oss-security/2024/07/">[month]</a> <a href="https://www.openwall.com/lists/oss-security/2024/">[year]</a> <a href="https://www.openwall.com/lists/oss-security/">[list]</a>
<pre>Date: Mon, 8 Jul 2024 18:21:06 +0200
From: Solar Designer &lt;solar@...nwall.com&gt;
To: oss-security@...ts.openwall.com
Cc: Qualys Security Advisory &lt;qsa@...lys.com&gt;
Subject: Re: CVE-2024-6387: RCE in OpenSSH's server, on glibc-based Linux systems

Hi,

Today is the coordinated release date to publicly disclose a related
issue I found during review of Qualys' findings, with further analysis
by Qualys.  My summary is:

CVE-2024-6409: OpenSSH: Possible remote code execution in privsep child
due to a race condition in signal handling

OpenSSH versions 8.7 and 8.8 and the corresponding portable releases
call cleanup_exit() from grace_alarm_handler() when running in the
privsep child process.  cleanup_exit() was not meant to be called from a
signal handler and may call other async-signal-unsafe functions.  The
current understanding is that in those upstream versions cleanup_exit()
would not actually call async-signal-unsafe functions under those
conditions, but with downstream distribution patches it sometimes does.
Specifically, openssh-7.6p1-audit.patch found in Red Hat's package of
OpenSSH adds code to cleanup_exit() that exposes the issue.  Relevantly,
this patch is found in RHEL 9 (and its rebuild/downstream
distributions), where the package is based on OpenSSH 8.7p1.

The audit patch is also found in Fedora, so the package versions that
were based on 8.7p1 and 8.8p1 are affected.  Per change log, it appears
that out of Fedora releases only 36 and 37 were affected, as well as
some updates maybe starting with those for 35 and until those for 37.
These versions are now end-of-life, and Fedora 38+ has moved to newer
upstream OpenSSH that doesn't make the problematic cleanup_exit() call.

The main difference from CVE-2024-6387 is that the race condition and
RCE potential are triggered in the privsep child process, which runs
with reduced privileges compared to the parent server process.  So
immediate impact is lower.  However, there may be differences in
exploitability of these vulnerabilities in a particular scenario, which
could make either one of these a more attractive choice for an attacker,
and if only one of these is fixed or mitigated then the other becomes
more relevant.  In particular, the "LoginGraceTime 0" mitigation works
against both issues, whereas the "-e" mitigation only works against
CVE-2024-6387 and not (fully) against CVE-2024-6409.  It may also be
possible to construct an exploit that would work against either
vulnerability probabilistically, which could decrease attack duration or
increase success rate.  That said, actual exploitation of CVE-2024-6409
has not yet been attempted and thus has not been proven.

I brought this extra issue to distros on June 26 and Qualys confirmed
and completed most of the analysis later same day.  Qualys later found
another issue with the audit patch, which is currently believed to be
mostly non-security.  I include it closer to the end of this message.

I'm sorry for not disclosing CVE-2024-6409 on the same day as
CVE-2024-6387, which would have saved many of us time (me included).
I agreed for the separate coordinated release date because apparently
Red Hat already had CVE-2024-6387 in the pipeline and wasn't ready to
add a fix for CVE-2024-6409 at the same time.

I quote relevant excerpts from the distros list discussion below:

On Wed, Jun 26, 2024 at 04:32:49AM +0200, Solar Designer wrote:
&gt; On Thu, Jun 20, 2024 at 01:26:52PM +0000, Qualys Security Advisory wrote:
&gt; &gt; A few days after we started our work on amd64, we noticed the following
&gt; &gt; bug report (in OpenSSH's public Bugzilla), about a deadlock in sshd's
&gt; &gt; SIGALRM handler:
&gt; &gt; 
&gt; &gt;   <a href="https://bugzilla.mindrot.org/show_bug.cgi?id=3690" rel="nofollow">https://bugzilla.mindrot.org/show_bug.cgi?id=3690</a>
&gt; 
&gt; Here's another curious one:
&gt; 
&gt; <a href="https://bugzilla.mindrot.org/show_bug.cgi?id=3286#c7" rel="nofollow">https://bugzilla.mindrot.org/show_bug.cgi?id=3286#c7</a>
&gt; 
&gt; In 2021, djm@ was wondering "why this is triggering when it wasn't
&gt; before" and "I still don't understand why this condition did not exist
&gt; previously."  I guess the reason was this same regression in the signal
&gt; handler.
&gt; 
&gt; The patch for the above issue conditionally replaced the call to
&gt; sigdie() with cleanup_exit(255), but I think that other call was also
&gt; async-signal-unsafe!
&gt; 
&gt; commit e3c032333be5fdbbaf2751f6f478e044922b4ec4
&gt; Author: djm@...nbsd.org &lt;djm@...nbsd.org&gt;
&gt; Date:   Fri May 7 03:09:38 2021 +0000
&gt; 
&gt;     upstream: don't sigdie() in signal handler in privsep child process;
&gt;     
&gt;     this can end up causing sandbox violations per bz3286; ok dtucker@
&gt;     
&gt;     OpenBSD-Commit-ID: a7f40b2141dca4287920da68ede812bff7ccfdda

&gt; -/* $OpenBSD: sshd.c,v 1.572 2021/04/03 06:18:41 djm Exp $ */
&gt; +/* $OpenBSD: sshd.c,v 1.573 2021/05/07 03:09:38 djm Exp $ */
&gt; 
&gt; So in OpenSSH 8.7p1 as used e.g. in RHEL 9, we have this:
&gt; 
&gt;         /* Log error and exit. */
&gt;         if (use_privsep &amp;&amp; pmonitor != NULL &amp;&amp; pmonitor-&gt;m_pid &lt;= 0)
&gt;                 cleanup_exit(255); /* don't log in privsep child */
&gt;         else {
&gt;                 sigdie("Timeout before authentication for %s port %d",
&gt;                     ssh_remote_ipaddr(the_active_state),
&gt;                     ssh_remote_port(the_active_state));
&gt;         }
&gt; 
&gt; So if patching that version, I think not only the body of sshsigdie()
&gt; should be #if 0'ed out, but also the above call to cleanup_exit(255);
&gt; replaced with _exit(1).
&gt; 
&gt; Indeed, that's also the difference between sshlogdie(), which uses
&gt; cleanup_exit(255), and sshsigdie(), which uses _exit(1).
&gt; 
&gt; This extra problematic logic only existed in upstream OpenSSH(-portable)
&gt; for ~9 months, having been removed with:
&gt; 
&gt; commit 4e62c13ab419b4b224c8bc6a761e91fcf048012d
&gt; Author: dtucker@...nbsd.org &lt;dtucker@...nbsd.org&gt;
&gt; Date:   Tue Feb 1 07:57:32 2022 +0000
&gt; 
&gt;     upstream: Remove explicit kill of privsep preauth child's PID in
&gt;     
&gt;     SIGALRM handler. It's no longer needed since the child will get terminated by
&gt;     the SIGTERM to the process group that cleans up any auth helpers, it
&gt;     simplifies the signal handler and removes the risk of a race when updating
&gt;     the PID. Based on analysis by HerrSpace in github PR#289, ok djm@
&gt;     
&gt;     OpenBSD-Commit-ID: 2be1ffa28b4051ad9e33bb4371e2ec8a31d6d663

&gt; -/* $OpenBSD: sshd.c,v 1.582 2021/11/18 03:07:59 djm Exp $ */
&gt; +/* $OpenBSD: sshd.c,v 1.583 2022/02/01 07:57:32 dtucker Exp $ */
&gt; 
&gt; which obviously left the (even worse) sshdie() intact.
&gt; 
&gt; In other words, depending on what exact cleanups are done, it may (or
&gt; may not, I haven't checked) have briefly been possible to exploit a race
&gt; condition of this sort not only in the parent (worse), but also in the
&gt; privsep child (relatively mild).  An extra vulnerability nevertheless,
&gt; maybe with different exploitability conditions - maybe exploitable even
&gt; on *BSD where sshdie() is not?

As a side note, I wrote *BSD above because I had found that syslog_r()
is also available on NetBSD, as well as on AIX and even Tru64, so
_maybe_ some builds of OpenSSH for some of those systems were not
affected by CVE-2024-6387.  We did not research this further.

&gt; Now, cleanup_exit() _might_ have actually be safe if called from this
&gt; place.  Upstream 8.7p1's is:
&gt; 
&gt; /* server specific fatal cleanup */
&gt; void
&gt; cleanup_exit(int i)
&gt; {
&gt;         if (the_active_state != NULL &amp;&amp; the_authctxt != NULL) {
&gt;                 do_cleanup(the_active_state, the_authctxt);
&gt;                 if (use_privsep &amp;&amp; privsep_is_preauth &amp;&amp;
&gt;                     pmonitor != NULL &amp;&amp; pmonitor-&gt;m_pid &gt; 1) {
&gt;                         debug("Killing privsep child %d", pmonitor-&gt;m_pid);
&gt;                         if (kill(pmonitor-&gt;m_pid, SIGKILL) != 0 &amp;&amp;
&gt;                             errno != ESRCH) {
&gt;                                 error_f("kill(%d): %s", pmonitor-&gt;m_pid,
&gt;                                     strerror(errno));
&gt;                         }
&gt;                 }
&gt;         }
&gt; #ifdef SSH_AUDIT_EVENTS
&gt;         /* done after do_cleanup so it can cancel the PAM auth 'thread' */
&gt;         if (the_active_state != NULL &amp;&amp; (!use_privsep || mm_is_monitor()))
&gt;                 audit_event(the_active_state, SSH_CONNECTION_ABANDON);
&gt; #endif
&gt;         _exit(i);
&gt; }

&gt; Further, RHEL 9 patched this to:
&gt; 
&gt; /* server specific fatal cleanup */
&gt; void
&gt; cleanup_exit(int i)
&gt; {
&gt;         static int in_cleanup = 0;
&gt;         int is_privsep_child;
&gt; 
&gt;         /* cleanup_exit can be called at the very least from the privsep
&gt;            wrappers used for auditing.  Make sure we don't recurse
&gt;            indefinitely. */
&gt;         if (in_cleanup)
&gt;                 _exit(i);
&gt;         in_cleanup = 1;
&gt;         if (the_active_state != NULL &amp;&amp; the_authctxt != NULL) {
&gt;                 do_cleanup(the_active_state, the_authctxt);
&gt;                 if (use_privsep &amp;&amp; privsep_is_preauth &amp;&amp;
&gt;                     pmonitor != NULL &amp;&amp; pmonitor-&gt;m_pid &gt; 1) {
&gt;                         debug("Killing privsep child %d", pmonitor-&gt;m_pid);
&gt;                         if (kill(pmonitor-&gt;m_pid, SIGKILL) != 0 &amp;&amp;
&gt;                             errno != ESRCH) {
&gt;                                 error_f("kill(%d): %s", pmonitor-&gt;m_pid,
&gt;                                     strerror(errno));
&gt;                         }
&gt;                 }
&gt;         }
&gt;         is_privsep_child = use_privsep &amp;&amp; pmonitor != NULL &amp;&amp; pmonitor-&gt;m_pid == 0;
&gt;         if (sensitive_data.host_keys != NULL &amp;&amp; the_active_state != NULL)
&gt;                 destroy_sensitive_data(the_active_state, is_privsep_child);
&gt;         if (the_active_state != NULL)
&gt;                 packet_destroy_all(the_active_state, 1, is_privsep_child);
&gt; #ifdef SSH_AUDIT_EVENTS
&gt;         /* done after do_cleanup so it can cancel the PAM auth 'thread' */
&gt;         if (the_active_state != NULL &amp;&amp;
&gt;             (the_authctxt == NULL || !the_authctxt-&gt;authenticated) &amp;&amp;
&gt;             (!use_privsep || mm_is_monitor()))
&gt;                 audit_event(the_active_state, SSH_CONNECTION_ABANDON);
&gt; #endif
&gt;         _exit(i);
&gt; }
&gt; 
&gt; from where it looks like other cleanup calls can be made even when
&gt; called from privsep child prior to authentication

&gt; In summary:
&gt; 
&gt; 1. I think the call to
&gt;                 cleanup_exit(255); /* don't log in privsep child */
&gt; should also be patched to _exit(1) in distro packages that have that
&gt; (perhaps those based on 8.7p1 and 8.8p1).
&gt; 
&gt; 2. The logic of upstream cleanup_exit() (but not necessarily distros')
&gt; is such that the call _may_ have been safe (unless the other race?)
&gt; 
&gt; 3. My analysis is incomplete.  I welcome further analysis by others -
&gt; Qualys, distros, and we could want to contact upstream (via Qualys?)
&gt; for comment even though the issue is already inadvertently fixed.
&gt; 
&gt; 4. If this is in fact an extra vulnerability (even if only exposed in a
&gt; distro?), should it perhaps get its own CVE?  It's different affected
&gt; versions range, which I think qualifies it for a different CVE.  (If
&gt; confirmed that this is in fact a vulnerability.)

On Wed, Jun 26, 2024 at 11:06:43AM +0000, Qualys Security Advisory wrote:
&gt; On Wed, Jun 26, 2024 at 04:32:49AM +0200, Solar Designer wrote:
&gt; &gt; Here's another curious one:
&gt; 
&gt; Well spotted! Yes, the version matches (8.5p1), this is definitely the
&gt; same root cause (sshsigdie() was called and it is doing something,
&gt; instead of just calling _exit(1)).
&gt; 
&gt; &gt; Now, cleanup_exit() _might_ have actually be safe if called from this
&gt; &gt; place.  Upstream 8.7p1's is:
&gt; 
&gt; Interesting, thanks! We have spent some time on this:
&gt; 
&gt; ------------------------------------------------------------------------
&gt; 2429 cleanup_exit(int i)
&gt; 2430 {
&gt; 2431         if (the_active_state != NULL &amp;&amp; the_authctxt != NULL) {
&gt; 2432                 do_cleanup(the_active_state, the_authctxt);
&gt; 2433                 if (use_privsep &amp;&amp; privsep_is_preauth &amp;&amp;
&gt; 2434                     pmonitor != NULL &amp;&amp; pmonitor-&gt;m_pid &gt; 1) {
&gt; 2435                         debug("Killing privsep child %d", pmonitor-&gt;m_pid);
&gt; 2436                         if (kill(pmonitor-&gt;m_pid, SIGKILL) != 0 &amp;&amp;
&gt; 2437                             errno != ESRCH) {
&gt; 2438                                 error_f("kill(%d): %s", pmonitor-&gt;m_pid,
&gt; 2439                                     strerror(errno));
&gt; 2440                         }
&gt; 2441                 }
&gt; 2442         }
&gt; 2443 #ifdef SSH_AUDIT_EVENTS
&gt; 2444         /* done after do_cleanup so it can cancel the PAM auth 'thread' */
&gt; 2445         if (the_active_state != NULL &amp;&amp; (!use_privsep || mm_is_monitor()))
&gt; 2446                 audit_event(the_active_state, SSH_CONNECTION_ABANDON);
&gt; 2447 #endif
&gt; 2448         _exit(i);
&gt; 2449 }
&gt; ------------------------------------------------------------------------
&gt; 
&gt; - The block at lines 2431-2442 is actually entered in the unpriv child,
&gt;   pre-auth, because both the_active_state and the_authctxt are set. The
&gt;   block at lines 2433-2441 is not entered in the unpriv child, so we can
&gt;   forget about this one.
&gt; 
&gt; - The lines 2445-2446 is not executed in the unpriv child, so we can
&gt;   forget about this one too.
&gt; 
&gt; - This leaves us with the call to do_cleanup() at line 2432:
&gt; 
&gt; ------------------------------------------------------------------------
&gt; 2643 do_cleanup(struct ssh *ssh, Authctxt *authctxt)
&gt; 2644 {
&gt; ....
&gt; 2647         debug("do_cleanup");
&gt; ....
&gt; 2662         if (options.use_pam) {
&gt; 2663                 sshpam_cleanup();
&gt; 2664                 sshpam_thread_cleanup();
&gt; 2665         }
&gt; ....
&gt; 2668         if (!authctxt-&gt;authenticated)
&gt; 2669                 return;
&gt; ------------------------------------------------------------------------
&gt; 
&gt; - The debug() call at line 2647 is not ideal, because it calls
&gt;   snprintf(), but we do not consider this to be a practical problem,
&gt;   because we do not know of an snprintf() implementation that calls
&gt;   malloc() (unless the format string uses positional arguments or
&gt;   floating points, which is not the case here).
&gt; 
&gt; - The calls to PAM functions at lines 2662-2665 are no-ops in the unpriv
&gt;   child, so not a problem either.
&gt; 
&gt; - And then do_cleanup() returns at lines 2668-2669, so OK.
&gt; 
&gt; Summary: we consider this upstream version to be safe (from a practical
&gt; point of view, i.e. despite the few calls to snprintf()).
&gt; 
&gt; &gt; Further, RHEL 9 patched this to:
&gt; 
&gt; Ouch, we had not seen this one; it is definitely a problem:
&gt; 
&gt; ------------------------------------------------------------------------
&gt; 2657 cleanup_exit(int i)
&gt; 2658 {
&gt; ....
&gt; 2681         if (sensitive_data.host_keys != NULL &amp;&amp; the_active_state != NULL)
&gt; 2682                 destroy_sensitive_data(the_active_state, is_privsep_child);
&gt; 2683         if (the_active_state != NULL)
&gt; 2684                 packet_destroy_all(the_active_state, 1, is_privsep_child);
&gt; ------------------------------------------------------------------------
&gt; 
&gt; - The call to destroy_sensitive_data() may or may not be a problem,
&gt;   because the "sensitive data" (private keys) were already destroyed in
&gt;   the unpriv child at that point.
&gt; 
&gt; - But the call to packet_destroy_all() is definitely a problem, because
&gt;   it calls packet_destroy_state(), which calls free() everywhere.
&gt; 
&gt; Summary: this patched version of cleanup_exit() makes the unpriv child
&gt; vulnerable too.
&gt; 
&gt; &gt; 1. I think the call to
&gt; &gt;                 cleanup_exit(255); /* don't log in privsep child */
&gt; &gt; should also be patched to _exit(1) in distro packages that have that
&gt; &gt; (perhaps those based on 8.7p1 and 8.8p1).
&gt; 
&gt; Agreed (by "patched" you mean "replace the call to cleanup_exit(255)
&gt; with a call to _exit(1)", right?).
&gt; 
&gt; &gt; 2. The logic of upstream cleanup_exit() (but not necessarily distros')
&gt; &gt; is such that the call _may_ have been safe
&gt; 
&gt; Agreed as well.

The below excepts are about an extra issue (beyond CVE-2024-6409) - the
audit patch's logging of SSH host key fingerprints apparently being
broken at least on RHEL 9.  This issue is only indirectly related to
CVE-2024-6409 because it explains why more async-signal-unsafe calls are
made than would have been otherwise.

On Thu, Jul 04, 2024 at 01:40:34AM +0000, Qualys Security Advisory wrote:
&gt; we found more information on the following:
&gt; 
&gt; On Wed, Jun 26, 2024 at 11:06:43AM +0000, Qualys Security Advisory wrote:
&gt; &gt; - The call to destroy_sensitive_data() may or may not be a problem,
&gt; &gt;   because the "sensitive data" (private keys) were already destroyed in
&gt; &gt;   the unpriv child at that point.
&gt; 
&gt; It is a problem: destroy_sensitive_data() calls malloc functions many
&gt; times (especially free()) because even if only the public keys remain in
&gt; sensitive_data.host_keys, they are still passed to sshkey_free().
&gt; 
&gt; In fact, destroy_sensitive_data() even ends up calling syslog() itself:
&gt; PRIVSEP(audit_destroy_sensitive_data()) calls mm_request_send(), which
&gt; can fail if the priv/parent process already _exit()ed, so fatal_f() is
&gt; called, which calls mm_log_handler(), which also fails because the priv/
&gt; parent process _exit()ed, so fatal_f() is called again, but this time it
&gt; calls syslog().
&gt; 
&gt; If you are wondering why destroy_sensitive_data() calls
&gt; PRIVSEP(audit_destroy_sensitive_data()) in the first place, we were
&gt; wondering too, because this should happen only if one of the keys is
&gt; private, and no private key should remain in the unpriv/child process!
&gt; This is actually a bug in sshkey_is_private(): for ed25519 keys, this
&gt; function checks ed25519_pk, which is the public key! It should check
&gt; ed25519_sk instead, which is the secret/private key.

On Sun, Jul 07, 2024 at 11:21:37PM +0200, Solar Designer wrote:
&gt; Thank you for reporting this to distros.  I don't see this function in
&gt; any upstream version at all - do you?  I see it being added via
&gt; openssh-7.6p1-audit.patch in Red Hat's package.  I don't know if an
&gt; equivalent patch is maybe also added in some other distros?
&gt; 
&gt; As to security consequences, at first my concern was this could leave
&gt; secret host keys around in privsep child.  However, upon a closer look
&gt; the only thing audit_destroy_sensitive_data() does is log a message, so
&gt; the only impact is erroneous audit logging.

&gt; Actual processing of keys is untouched by this patch, so probably
&gt; remains correct.

On Mon, Jul 08, 2024 at 05:23:22PM +0200, Solar Designer wrote:
&gt; On Mon, Jul 08, 2024 at 03:00:37PM +0000, Qualys Security Advisory wrote:
&gt; &gt; On Mon, Jul 08, 2024 at 03:35:29PM +0200, Solar Designer wrote:
&gt; &gt; &gt; [...] with RH's original code
&gt; &gt; &gt; I saw the same key's destruction logged 3 times.  I think some of those
&gt; &gt; &gt; were not from the unprivileged child, and actually made sense.  So I was
&gt; &gt; &gt; hoping that fixing the check from pk to sk would suppress only the
&gt; &gt; &gt; erroneous logging from the unprivileged child, but in my testing it
&gt; &gt; &gt; suppressed all of it.
&gt; &gt; 
&gt; &gt; [...] I think that I have
&gt; &gt; found the solution to this mystery, but I have not yet investigated the
&gt; &gt; consequences (if any): the private host keys are "shielded" as soon as
&gt; &gt; they are loaded (by sshkey_shield_private()), which means that, to the
&gt; &gt; (non-buggy) tests in sshkey_is_private(), they look like public keys,
&gt; &gt; but the private part is actually there, in another part of the key
&gt; &gt; structure, in encrypted form.

&gt; The shielding was added upstream in:
&gt; 
&gt; commit 4f7a56d5e02e3d04ab69eac1213817a7536d0562
&gt; Author: djm@...nbsd.org &lt;djm@...nbsd.org&gt;
&gt; Date:   Fri Jun 21 04:21:04 2019 +0000
&gt; 
&gt;     upstream: Add protection for private keys at rest in RAM against
&gt;     
&gt;     speculation and memory sidechannel attacks like Spectre, Meltdown, Rowhammer
&gt;     and Rambleed. This change encrypts private keys when they are not in use with
&gt;     a symmetic key that is derived from a relatively large "prekey" consisting of
&gt;     random data (currently 16KB).
&gt; 
&gt; which is newer than 7.6p1 that openssh-7.6p1-audit.patch was presumably
&gt; based on.  So it is possible that this audit logging was more functional
&gt; initially (sans this bug for ed25519 you found), but mostly broke when
&gt; it was rebased on newer versions without consideration for the change
&gt; above.  However, that's just a guess, which I did not confirm.  A way to
&gt; confirm it could be to test a Red Hat package that already has the audit
&gt; patch, but does not yet have upstream's shielding.  Since the above
&gt; upstream commit isn't in 8.0 (it's about 1 week newer than V_8_0 tag),
&gt; maybe RHEL 8 is suitable for this test (its package is based on 8.0p1).
&gt; 
&gt; ... and indeed, on a RHEL 8 rebuild system I see "msg='op=destroy
&gt; kind=server fp=SHA256:" /var/log/audit/audit.log lines with 3 different
&gt; fingerprint values, presumably corresponding to the different key types.
&gt; This is different from the RHEL 9 rebuild system I checked before, where
&gt; only one fingerprint value would be seen despite of the system also
&gt; having 3 different host key types.

In the public disclosure of CVE-2024-6387, Qualys wrote:

On Mon, Jul 01, 2024 at 08:40:06AM +0000, Qualys Security Advisory wrote:
&gt; We decided to target Rocky Linux 9 (a Red Hat Enterprise Linux 9
&gt; derivative), from "Rocky-9.4-x86_64-minimal.iso", for two reasons:
&gt; 
&gt; - its OpenSSH version (8.7p1) is vulnerable to this signal handler race
&gt;   condition and its glibc is always mapped at a multiple of 2MB (because
&gt;   of the ASLR weakness discussed in the previous "Theory" subsection),
&gt;   which makes partial pointer overwrites much more powerful;
&gt; 
&gt; - the syslog() function (which is async-signal-unsafe but is called by
&gt;   sshd's SIGALRM handler) of this glibc version (2.34) internally calls
&gt;   __open_memstream(), which malloc()ates a FILE structure in the heap,
&gt;   and also calls calloc(), realloc(), and free() (which gives us some
&gt;   much-needed freedom).
&gt; 
&gt; With a heap corruption as a primitive, two FILE structures malloc()ated
&gt; in the heap, and 21 fixed bits in the glibc's addresses, we believe that
&gt; this signal handler race condition is exploitable on amd64 (probably not
&gt; in ~6-8 hours, but hopefully in less than a week). Only time will tell.

FWIW, we patched CVE-2024-6387 in Rocky Linux SIG/Security and CIQ 9.2
LTS on July 1, and here's the patch we're getting into both today:

$ cat openssh-8.7p1-rocky-CVE-2024-6409.patch
diff -urp openssh-8.7p1-38.el9_4.1-tree.orig/sshd.c openssh-8.7p1-38.el9_4.1-tree/sshd.c
--- openssh-8.7p1-38.el9_4.1-tree.orig/sshd.c	2024-07-08 03:42:51.431994307 +0200
+++ openssh-8.7p1-38.el9_4.1-tree/sshd.c	2024-07-08 03:48:13.860316451 +0200
@@ -384,7 +384,7 @@ grace_alarm_handler(int sig)
 
 	/* Log error and exit. */
 	if (use_privsep &amp;&amp; pmonitor != NULL &amp;&amp; pmonitor-&gt;m_pid &lt;= 0)
-		cleanup_exit(255); /* don't log in privsep child */
+		_exit(1); /* don't log in privsep child */
 	else {
 		sigdie("Timeout before authentication for %s port %d",
 		    ssh_remote_ipaddr(the_active_state),

We'll update the Rocky Linux SIG/Security wiki shortly (didn't do this
in advance in order to push this public disclosure out to all first):

<a href="https://sig-security.rocky.page/packages/openssh/" rel="nofollow">https://sig-security.rocky.page/packages/openssh/</a>

The weakening of ASLR bothers me, but is to be discussed separately.

Alexander
</pre>
<p><a href="http://www.openwall.com/blists/">Powered by blists</a> - <a href="http://lists.openwall.net/">more mailing lists</a>


</p><p>
Please check out the
<a href="https://oss-security.openwall.org/wiki/">
Open Source Software Security Wiki</a>, which is counterpart to this
<a href="https://oss-security.openwall.org/wiki/mailing-lists/oss-security">mailing list</a>.
</p><p>
Confused about <a href="https://www.openwall.com/lists/">mailing lists</a> and their use?
<a href="https://en.wikipedia.org/wiki/Electronic_mailing_list">Read about mailing lists on Wikipedia</a>
and check out these
<a href="https://www.complang.tuwien.ac.at/anton/mail-news-errors.html">guidelines on proper formatting of your messages</a>.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Turbopuffer: Fast search on object storage (182 pts)]]></title>
            <link>https://turbopuffer.com/blog/turbopuffer</link>
            <guid>40916786</guid>
            <pubDate>Tue, 09 Jul 2024 14:48:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://turbopuffer.com/blog/turbopuffer">https://turbopuffer.com/blog/turbopuffer</a>, See on <a href="https://news.ycombinator.com/item?id=40916786">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a title="Go back to blog" href="https://turbopuffer.com/blog"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M18 6 6 18"></path><path d="m6 6 12 12"></path></svg></a><div><p><span>July 08, 2024</span><span>•</span><span>Simon Hørup Eskildsen (Co-founder &amp; CEO)</span></p></div><p>In late 2022 I was helping my friends at Readwise scale their infrastructure
ahead of the launch of <a target="_blank" href="https://readwise.io/read">Readwise Reader</a> (read-it-later app). We wanted
to build a highly requested feature: article recommendations and semantic search
using vector embeddings. Readwise was paying ~$5k/month for their relational
database, but we found that vector search on the same 100m+ documents would've
cost $20k/month+! This wasn't just expensive; it meant we had to shelve a
desired feature until costs came down.</p>
<p>It gnawed at me for months. A promising feature, postponed solely due to
infrastructure costs? Surely these exorbitant prices weren't rooted in some
immutable law of physics. Had we simply failed to create a search engine that
truly harnessed the power of modern hardware and services?</p>
<p>As I went deeper, painful memories of search outages from my early days on
Shopify’s infrastructure team started flashing. The existing solutions aren’t
just expensive, they’re also incredibly difficult to operate at scale. It was
clear to me that a lot had changed since the current generation of search
engines were designed: object storage is now ubiquitous, NVMe SSDs have become
incredibly fast and affordable, and AI &amp; vectors means we’re asking more from
our search systems than before.</p>
<p>In 2022, production-grade vector databases were relying on in-memory storage at
$2+ per GB, not counting the extra cost for durable disk storage. This is the
most expensive way to store data. You can improve this by moving to disk, with
triply replicated SSDs at 50% storage utilization which will run you $0.6 per
GB. But we can do even better by leveraging object storage (like S3 or GCS) at
around $0.02 per GB, with SSD caching at $0.1 per GB for frequently accessed
data. That’s up to 100x cheaper than memory for cold storage, and 6-20x cheaper
for warm storage!</p>
<p>That’s when I decided this is what I wanted to do: build a search engine as you
would build it in 2023 (the year development started). One where cost maps
better to value, so features that aren’t being built today will get built. <a target="_blank" href="https://en.wikipedia.org/wiki/Jevons_paradox">When
you make gas 20% cheaper, people drive 40% more.</a> Coupled with the
tailwinds of retrieval in AI, it seemed like the right time to start building
this was yesterday.</p>
<p>Fast forward to today, and turbopuffer offers a new approach to search,
combining cost efficiency with high performance. By leveraging object storage
and smart caching, we've built a solution that scales effortlessly to billions
of vectors and millions of tenants/namespaces. We’ve heard loud and clear from
our customers they have felt constrained by retrieval costs in their product
ambition. <strong>We want to make it possible for our customers to search every byte
they have.</strong></p>
<pre><code>
                        ╔═turbopuffer══════════════════════════════╗ 
╔════════════╗          ║                                          ║░
║            ║░         ║  ┏━━━━━━━━━━━━━━━┓     ┏━━━━━━━━━━━━━━┓  ║░
║   client   ║░───API──▶║  ┃    Memory/    ┃────▶┃    Object    ┃  ║░
║            ║░         ║  ┃   SSD Cache   ┃     ┃ Storage (S3) ┃  ║░
╚════════════╝░         ║  ┗━━━━━━━━━━━━━━━┛     ┗━━━━━━━━━━━━━━┛  ║░
 ░░░░░░░░░░░░░░         ║                                          ║░
                        ╚══════════════════════════════════════════╝░
                         ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░
</code></pre>
<h2 id="the-five-common-databases">The Five Common Databases</h2>
<p>Let's take a step back to see how search engines fit into the broader
infrastructure stack and how their requirements differ from other types of
databases.</p>
<p>Companies typically start with a relational database (Postgres/MySQL) and
gradually extract parts of their workload to ~5 specialized databases for
performance, cost, and scalability. Searching a few million documents in your
relational database is unlikely to cause issues. Any concerns at that scale are
outweighed by the overhead of operating another database. But, with sufficient
scale you start feeling like a butcher with a Swiss Army Knife. You'll know
you've hit this point when the same workload keeps showing up in the database
query profiles during problems.</p>
<p>The five most common specialized databases in the modern infra stack are:</p>

<p>The storage architecture of the current generation of search engines simply
doesn’t map closely enough to the performance characteristics and cost
constraints of search. We can do better by moving from the old world of
replicated SSDs to object storage with SSD and memory caching.</p>
<h2 id="a-search-engine-on-object-storage">A Search Engine on Object Storage</h2>
<pre><code>First Principle Storage Costs

RAM + 3x SSD        | ████████████████████████████████████████ $3600.00/TB/month (incumbents)
RAM Cache† + 3x SSD | █████████████████ $1600.00/TB/month (incumbents, relational databases)
3x SSD              | ██████ $600.00/TB/month
S3 + SSD Cache†     | █ $70.00/TB/month (turbopuffer)
S3                  |  $20.00/TB/month

*: 50% disk utilization
†: 50% in cache
1TB: 120M documents with 1536 dimensional vectors and 2KB text data
</code></pre>
<p>The current generation of search engines are built using the replicated disk
architecture typical of relational databases. This setup is excellent for low
latency, extremely high concurrency for updates, and transactions. However,
search engines don’t require all this! Their write workload is more akin to a
data warehouse: high write throughput, no transactions, and more relaxed latency
requirements, especially for writes. Consequently, for search engines we end up
paying a serious premium for storage performance characteristics we don’t need!</p>
<p>Unlike data warehouses, search queries do need to finish in &lt;100ms rather than
seconds. Because requests to object storage take more than 100ms, we still need
to reduce latency with an SSD/memory cache for the actively searched data.</p>
<p>Occasionally, you might get a cold query from object storage that takes a few
hundred milliseconds if a node dies or the dataset has been evicted from the
cache. For most search use-cases, the savings are well worth the latency hit of
an occasional cold query</p>
<p>This design allows freely walking the tradeoffs between cheap, cold, slow
storage, and warm, expensive, fast storage. The architecture is just as fast for
warm queries, but cheaper than alternatives that require more copies of the data
for durability. For infrequently accessed data, turbopuffer’s design is more
than an order of magnitude cheaper. The design especially shines when only
subsets of the data (e.g. tenants) are active at once.</p>
<h2 id="object-storage-native-database">Object Storage Native Database</h2>
<p>We set out to build a database that fully leverages this architecture. Not only
is it highly cost-effective, but being backed by object storage offers
unparalleled reliability and virtually unlimited scalability. In addition, if
something is queried enough and makes it all the way to the small memory cache,
there is no reason why hot queries can’t be as fast as in another architecture.</p>
<p>Justin (CTO) and I learned the hard way during our 5+ years on the last-resort
pager at Shopify that the fewer stateful dependencies, the more nines of uptime.
This is why turbopuffer has no  dependencies in the critical path other than
object storage. From day one, turbopuffer has employed multi-tenancy and
sharding, which we know from our days of protecting shops from each other at
Shopify is paramount for reliability. This architecture is a major reason we’ve
been able to maintain 99.99% uptime since launch.</p>
<p>To achieve this, we have built a storage engine native to object storage. This
is not tiering, where cold data is eventually replicated to object storage: it
is an object-storage-first storage engine where object storage is the source of
truth (LSM). Writes are durably committed to object storage. Existing storage
engine/LSM implementations don't apply here because the rules are different on
object storage: any node can compact data, latency is high, throughput is
phenomenal, individual writes are expensive, and storage is cheap. Each search
namespace is simply a prefix on object storage. If a node dies, another will
load into cache after a cold query (~500ms). We don't sell "High Availability"
(HA) at an extra cost, as any node can serve traffic for any namespace (though
we do attempt to route traffic to consistent nodes for cache locality). If you
want our HA number, I’ll just send you the current <code>kubectl get pods | wc -l</code>.
Additionally, because much of our compute runs on spot nodes, we constantly
exercise this failure path.</p>
<p>In order to optimize cold latency, the storage engine carefully handles
roundtrips to object storage. The query planner and storage engine have to work
in concert to strike a delicate balance between downloading more data per
roundtrip, and doing multiple roundtrips (P90 to object storage is around 250ms
for &lt;1MB). For example, for a vector search query, we aim to limit it to a
maximum of three roundtrips for sub-second cold latency.</p>
<p>We are continually working to reduce latency and have many tricks up our sleeve
to improve both cold and warm latency over time. For most production search
applications, the current performance is already excellent:</p>
<pre><code>1M 768 dimensional vectors (3 GB)

Cold Query Latency  | █████████████████████████████████████████ (512ms)
Warm Query Latency  | ██ (37ms P90)
</code></pre>
<p>You can read more about our <a target="_blank" href="https://turbopuffer.com/architecture">architecture</a>, our <a target="_blank" href="https://turbopuffer.com/docs/roadmap">roadmap</a>, and current <a target="_blank" href="https://turbopuffer.com/docs/limits">limitations</a>.</p>
<h2 id="customers">Customers</h2>
<p>Our first large customer was <a target="_blank" href="https://cursor.com/">Cursor</a>, the AI Code Editor. Each codebase is
turned into a vector index to power various features. Cursor manages billions of
vectors in millions of codebases. With their previous provider, they had to
carefully <a target="_blank" href="https://x.com/amanrsanger/status/1730763587944398874">binpack codebases</a> to nodes/indexes to manage cost and
complexity. In addition, the costs were astronomical, as every index was kept in
memory, despite only a subset of code-bases being active at any point in time.
Cursor's use-case was a perfect fit for turbopuffer’s architecture.</p>
<p>Cursor moved everything in a few days in November of last year, and immediately
saw their costs drop 10x with great cold and warm latency. In addition to their
natural growth, it wasn’t long before Cursor started creating more vectors per
user than before, as infrastructure cost and customer value started mapping far
better. Cursor <em>never</em> stores plain text code with turbopoffer, and goes even
further applying a unique vector transformation per code base to make vec2text
attacks extremely difficult.</p>
<p>turbopuffer also powers <a target="_blank" href="https://suno.com/">Suno’s radio feature</a>, <a target="_blank" href="https://new.computer/">Dot’s
memory</a> (by New Computer), the memory of
<a target="_blank" href="https://shapes.inc/home">Shapes</a>, and
<a target="_blank" href="https://fixie.ai/blog/best-vdb-2023">many</a> <a target="_blank" href="https://www.getmerlin.in/">more</a>.</p>
<h2 id="turbopuffer-o">turbopuffer &lt;(°O°)&gt;</h2>
<p>We are <em>very</em> much in production, but currently open by application only, as we
focus on optimizing turbopuffer for our early customers. <a target="_blank" href="https://turbopuffer.com/join">Let us know if you are
a good fit.</a> We hope you’ll trust us with your
queries.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Evolve Bank and Trust confirms LockBit stole 7.6M people's data (133 pts)]]></title>
            <link>https://www.theregister.com/2024/07/09/evolve_lockbit_attack/</link>
            <guid>40916260</guid>
            <pubDate>Tue, 09 Jul 2024 14:01:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/07/09/evolve_lockbit_attack/">https://www.theregister.com/2024/07/09/evolve_lockbit_attack/</a>, See on <a href="https://news.ycombinator.com/item?id=40916260">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Evolve Bank &amp; Trust says the data of more than 7.6 million customers was stolen during the LockBit break-in in late May, per a fresh filing with Maine's attorney general.</p>
<p>The filing <a target="_blank" href="https://www.maine.gov/agviewer/content/ag/985235c7-cb95-4be2-8792-a1252b4f8318/a2e61e38-f78d-403d-9abb-3810771bb5d2.html">lists</a> the total number of persons affected (including residents) at 7,640,112.</p>
<p>It's the first time Evolve has confirmed the scale of the data theft – which affected at least three of its major partners, past and present – and it expects the number to rise as its investigations continue.</p>

    

<p>Both Wise and Affirm, international money transfer and buy-now-pay-later companies respectively, confirmed in SEC filings last week that they were both materially affected by the break-in at Evolve.&nbsp;</p>

        


        

<p>Wise severed ties with Evolve last year but was still impacted by <a target="_blank" href="https://www.theregister.com/2024/07/02/affirm_evolve_ransomware_breach/">the incident</a>. Mercury also suggested it could be affected.</p>
<p>However, none of the company's partners have yet revealed the extent to which the <a target="_blank" href="https://www.theregister.com/2024/05/07/alleged_lockbit_kingpin_charged_sanctioned/">ransomware crew</a> that cops allege is headed by Dmitry Khoroshev managed to pillage their customers' data.</p>

        

<p><em>The Register</em> approached all 15 partners listed on Evolve's website and only received a response from one other company, Melia, and the last we heard it was probing any potential impact rather than confirming anything.</p>
<p>As for Evolve, its <a target="_blank" href="https://www.maine.gov/agviewer/content/ag/985235c7-cb95-4be2-8792-a1252b4f8318/a2e61e38-f78d-403d-9abb-3810771bb5d2.html" rel="nofollow">letter</a> to customers reads: "On May 29, 2024, Evolve identified that some of its systems were not working properly.</p>
<p>"While it initially appeared to be a hardware failure, we subsequently learned it was unauthorized activity.</p>

        

<p>"Evolve promptly initiated its incident response processes and stopped the attack. No new unauthorized activity on Evolve's systems has been identified since May 31, 2024. An investigation with assistance from a cybersecurity firm was initiated to investigate what happened and what data may have been impacted. Evolve also notified law enforcement and worked to add further protections to harden its systems."</p>
<p>The Banking-as-a-Service provider went on to say that although it may have enacted its incident response playbook when it spotted signs of foul play, it took the vendor roughly four months to detect the intrusion.</p>
<p>"There is no evidence that the threat actors accessed any customer funds, but it appears the threat actors did access and download customer information from Evolve's databases and a file share during periods in February and May 2024."</p>
<p>The letters sent to affected individuals are usually attached to filings with state attorneys general, but typically omit details such as the specific data types stolen in each case.</p>
<p>Some customers may have had names and addresses stolen, while others may have had their social security numbers taken as well, for example.</p>
<p>We know from Evolve's <a target="_blank" href="https://www.getevolved.com/about/news/cybersecurity-incident/" rel="nofollow">earlier disclosure</a> that SSNs, bank account numbers, and contact information "for most" of its personal banking customers and partners may be affected, as well as some staff.</p>
<p>That disclosure, last updated on July 8, also stated that this week's notification letters are expected to be a first round with additional, smaller rounds of notifications to come in the following weeks.</p>
<p>Evolve has offered impacted individuals 24 months of credit monitoring, as is often the case in major data leaks. Victims have until October 31 to enroll for these services, and the full instructions on how to do so are included in an email to be sent in the next two weeks.</p>
<ul>

<li><a href="https://www.theregister.com/2024/07/09/eldorado_ransomware_linux_windows/">Eldorado ransomware-as-a-service gang targets Linux, Windows systems</a></li>

<li><a href="https://www.theregister.com/2024/07/08/avast_secretly_gave_donex_ransomware/">Avast secretly gave DoNex ransomware decryptors to victims before crims vanished</a></li>

<li><a href="https://www.theregister.com/2024/07/02/affirm_evolve_ransomware_breach/">Affirm fears customer info pilfered during ransomware raid at Evolve Bank</a></li>

<li><a href="https://www.theregister.com/2024/06/24/indonesia_datacenter_ransomware/">Indonesian government datacenter locked down in $8M ransomware rumble</a></li>
</ul>
<p>Rounding off the letter, Evolve went on to say that it "had a significant number of cybersecurity measures in place," which have now been strengthened even further.</p>
<p>The incident, however, came against the backdrop of a stern <a target="_blank" href="https://www.federalreserve.gov/newsevents/pressreleases/enforcement20240614a.htm" rel="nofollow">telling off</a> from the US Federal Reserve Board on June 14, less than a fortnight before it announced the data had been stolen.</p>
<p>Following a review of Evolve in 2023, the board wasn't happy at all with the Arkansas-headquartered company for a number of reasons including "deficiencies" in anti-money laundering, risk management, and consumer compliance programs.&nbsp;</p>
<p>It was assessed to have engaged in "unsafe and unsound banking practices," particularly in relation to the absence of an effective risk management framework for its array of partners, among other issues, which resulted in an enforcement action being issued.</p>
<p>This, of course, came just a few weeks after Evolve became aware that LockBit was rummaging through its systems for the best part of four months – a hardly ideal 2024 for the finance firm.</p>
<h3>Misery loves company</h3>
<p>At least Evolve is not alone in the pits of the "data breach" filings this week. Financial Business and Consumer Solutions (FBCS) also <a target="_blank" href="https://www.maine.gov/agviewer/content/ag/985235c7-cb95-4be2-8792-a1252b4f8318/186129d3-f965-48f0-a48d-fbdfc6b74b02.html" rel="nofollow">updated</a> Maine's attorney general on the state of its investigation regarding its own data exposure for the second time in as many weeks.</p>
<p>At the end of June, we reported how the debt collector's situation was going <a target="_blank" href="https://www.theregister.com/2024/06/24/security_breaches_of_the_week/">from bad to worse</a>, and now it's worse still with the update indicating the number of affected individuals has now surpassed 4 million.</p>
<p>The February attack on FBCS was originally slated to have affected around 2 million people, according to its first filing in April. By the end of June, that number had risen to just north of 3.4 million, and now it stands at 4,050,711, to be precise.</p>
<p>The data stolen includes names, SSNs, dates of birth, account information, and identity documents, but no recognized cybercrime operation has taken credit for what the FBCS called a "cyber incident." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scoped Propagators (106 pts)]]></title>
            <link>https://www.orionreed.com/posts/scoped-propagators</link>
            <guid>40916193</guid>
            <pubDate>Tue, 09 Jul 2024 13:54:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.orionreed.com/posts/scoped-propagators">https://www.orionreed.com/posts/scoped-propagators</a>, See on <a href="https://news.ycombinator.com/item?id=40916193">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[You Want to Fix Boeing? Prosecute Its Executives (152 pts)]]></title>
            <link>https://www.thefp.com/p/fix-boeing-prosecute-executives-joe-nocera</link>
            <guid>40915381</guid>
            <pubDate>Tue, 09 Jul 2024 12:37:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thefp.com/p/fix-boeing-prosecute-executives-joe-nocera">https://www.thefp.com/p/fix-boeing-prosecute-executives-joe-nocera</a>, See on <a href="https://news.ycombinator.com/item?id=40915381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

      <p data-substack-content="">Let’s face it: Boeing has the government by the balls.</p><p data-substack-content="">It is, after all, America’s only commercial aircraft manufacturer, with <a href="https://www.statista.com/statistics/268992/change-in-employment-figures-from-boeing/">over 170,000 employees</a> in Washington State, South Carolina, and Virginia, most of whom make middle-class to upper-middle-class wages. In dollar volume, it is the country’s <a href="https://money.cnn.com/2018/03/07/news/economy/top-us-exports/index.html">largest exporter</a>. And to top it off, Boeing is a critical <a href="https://www.boeing.com/company/about-bds#anchor1">defense contractor</a>, with a space division that recently sent two astronauts to the International Space Station (though thanks to problems with Boeing’s spacecraft, it’s a little unclear when, exactly, those astronauts <a href="https://phys.org/news/2024-07-nasa-astronauts-unexpected-july-international.html">will return</a> to earth).&nbsp;</p><p data-substack-content="">Late Sunday night, faced with the possibility of a trial, <a href="https://www.nytimes.com/2024/07/08/business/boeing-justice-department-plea-deal.html">Boeing agreed</a> to a settlement offered by the Department of Justice, pleading guilty to a felony for the two 737 Max crashes in 2018 and 2019 that caused the death of 346 passengers and crew. The felony charge comes with a probationary period of three years and a fine of nearly $500 million. Boeing has also agreed to invest $455 million to bolster its safety and compliance programs and accept the oversight of an independent compliance monitor who will submit annual reports to the government. And board members will be required to meet with families of the victims.</p><p data-substack-content="">The Justice Department will no doubt characterize the settlement as just punishment for a recidivist company. Don’t believe it. This is a company that murdered those 346 people as surely as if it had lined them up against a wall and shot them. There was no pilot error involved in those crashes, nor was it the result of some unlucky accident. Those planes crashed because Boeing had cut so many corners in rushing this new 737 model to the marketplace that a disaster was inevitable. As one engineer memorably <a href="https://www.bloomberg.com/news/articles/2020-01-10/-incredibly-damning-boeing-messages-show-employee-unease-on-max">put it in an email</a> to a colleague: “This airplane was designed by clowns, who in turn are supervised by monkeys.”</p><p data-substack-content="">What’s more, to a company the size of Boeing, with <a href="https://www.statista.com/statistics/264374/boeings-worldwide-revenue/">$78 billion</a> in annual revenue, a half billion-dollar fine is pocket change. Back in 2021, Boeing accepted a <a href="https://www.justice.gov/opa/pr/boeing-charged-737-max-fraud-conspiracy-and-agrees-pay-over-25-billion">deferred prosecution agreement</a> with the Justice Department that called for it to pay $2.5 billion, including a criminal fine, money for the victims’ families, and compensation to its airline customers. Even that amount wasn’t enough to cause Boeing to change its ways: in January 2024, a <a href="https://www.axios.com/2024/03/14/boeing-737-max-problems-timeline">door blew out of a 737 Max</a> in flight, proving that safety was still not a top priority on the factory floor. Thus began the latest round of investigations, recriminations, and Boeing’s promise, with this settlement, to do better.</p><p data-substack-content="">The families of the victims are furious, with one of their lawyers calling it “a sweetheart deal.” Can you blame them? Some executives have lost their jobs, but no one has ever been held responsible for the wrongdoing that led to the crashes and to a culture that ignored safety concerns if it got in the way of a higher stock price. The top executives will still make millions. Boeing will still be able to conduct its defense business, even though convicted felons are not supposed to be eligible for government contracts. The settlement makes it obvious that the government is afraid of what would happen—not just to Boeing but to the Defense Department and even the larger economy—if it hit the company as hard as the company deserves to be hit.</p><p data-substack-content="">“I’m ashamed to see that this is our justice system at work,” <a href="https://www.foundationforaviationsafety.org/board/ed-pierson">Ed Pierson</a>, a Boeing whistleblower who has since founded the Foundation for Aviation Safety, told me yesterday afternoon. “It provides zero accountability. The executives who pressured employees to take shortcuts—they’re culpable. This settlement is allowing individuals who have acted criminally to walk away.”</p><p data-substack-content="">And that’s the larger point. The Justice Department seems to believe it’s meaningful to charge a company with a felony. But it’s not. Companies don’t commit felonies—people do. And if people aren’t held responsible—and sent to prison when necessary—then they’ll never have the incentive they need to change.&nbsp;</p><p data-substack-content="">You want to fix Boeing? Then prosecute its executives. There is nothing like the prospect of prison to focus the mind.</p><div data-substack-content=""><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png" data-component-name="Image2ToDOM"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png" width="1336" height="24" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:24,&quot;width&quot;:1336,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:820,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thefp.com/i/146416356?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png&quot;}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7f5dfa68-519d-48c8-8fa5-cc1215b8e110_1336x24.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p data-substack-content=""><em><strong>Joe Nocera is a columnist for The Free Press and the co-author of <a href="https://bookshop.org/p/books/the-big-fail-what-the-pandemic-revealed-about-who-america-protects-and-who-it-leaves-behind-joe-nocera/19667924?ean=9780593331026">The Big Fail</a>. Follow him on X <a href="https://twitter.com/opinion_joe">@opinion_joe</a>, and read his piece, “<a href="https://www.thefp.com/p/boeings-dead-whistleblower-spoke-the-truth">Boeing’s Dead Whistleblower Spoke the Truth</a>.”</strong></em></p><p data-substack-content=""><em><strong>Become a Free Press subscriber today:</strong></em></p><p data-attrs="{&quot;url&quot;:&quot;%%checkout_url%%&quot;,&quot;text&quot;:&quot;Subscribe now&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton" data-substack-content=""><a href="https://www.thefp.com/p/%%checkout_url%%"><span>Subscribe now</span></a></p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PySkyWiFi: Free stupid wi-fi on long-haul flights (637 pts)]]></title>
            <link>https://robertheaton.com/pyskywifi/</link>
            <guid>40915082</guid>
            <pubDate>Tue, 09 Jul 2024 12:01:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://robertheaton.com/pyskywifi/">https://robertheaton.com/pyskywifi/</a>, See on <a href="https://news.ycombinator.com/item?id=40915082">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The plane reached 10,000ft. I took out my laptop, planning to peruse the internet and maybe do a little work if I got really desperate.</p>

<p>I connected to the in-flight wi-fi and opened my browser. The network login page demanded credit card details. I fumbled for my card, which I eventually discovered had hidden itself inside my passport. As I searched I noticed that the login page was encouraging me to sign in to my airmiles account, free of charge, even though I hadn’t paid for anything yet. A hole in the firewall, I thought. It’s a long way from London to San Francisco so I decided to peer through it.</p>

<p>I logged in to my JetStreamers Diamond Altitude account and started clicking. I went to my profile page, where I saw an edit button. It looked like a normal button: drop shadow, rounded corners, nothing special. I was supposed to use it to update my name, address, and so on.</p>

<p>But suddenly I realised that this was no ordinary button. This clickable rascal would allow me to access the entire internet through my airmiles account. This would be slow. It would be unbelievably stupid. But it would work.</p>

<p>Several co-workers were asking me to review their PRs because my feedback was “two weeks late” and “blocking a critical deployment.” But my ideas are important too so I put on my headphones and smashed on some focus tunes. I’d forgotten to charge my headphones so Limp Bizkit started playing out of my laptop speakers. Fortunately no one else on the plane seemed to mind so we all rocked out together.</p>

<p>Before I could access the entire internet through my airmiles account I’d need to write a few prototypes. At first I thought that I’d write them using Go, but then I realised that if I used Python then I could call the final tool <a href="https://github.com/robert/PySkyWiFi"><code>PySkyWiFi</code></a>. Obviously I did that instead.</p>

<h4 id="prototype-1-instant-messaging">Prototype 1: Instant Messaging</h4>

<p>Here’s the basic idea: suppose that I logged into my airmiles account and updated my name. If you were also logged in to my account then you could read my new name, from the ground. You could update it again, and I could read your new value. If we kept doing this then the name field of my airmiles account could serve as a tunnel through the airplane’s wi-fi firewall to the real world.</p>

<p>This tunnel could support a simple instant messaging protocol. I could update my name to “<code>Hello how are you</code>.”  You could read my message and then send me a reply by updating my name again to “<code>Im fine how are you</code>.” I could read that, and we could have a stilted conversation. This might not sound like much, but it would be the first step on the road to full internet access. <a id="nl"></a></p>

<p>I paid for the internet on my old laptop. I hadn’t finished migrating my data off this computer, so it still had to come everywhere with me. I messaged my wife to ask her to help me with my experiments. <code>no, what are you talking about, i'm busy</code> she replied, lovingly.</p>

<p>So instead I took out my new laptop, which still had no internet access. I created a test airmiles account and logged into it on both computers. I found that I could indeed chat with myself by updating the name field in the UI.</p>

<pre><code>sequenceDiagram
    participant Computer1
    participant AirmilesAccount as Airmiles Account&lt;br&gt;Name Field
    participant Computer2
    
    Computer1-&gt;&gt;AirmilesAccount: TYPE: Hello how are you
    AirmilesAccount-&gt;&gt;Computer2: READ: Hello how are you
    Computer2-&gt;&gt;AirmilesAccount: TYPE: Im fine how are you
    AirmilesAccount-&gt;&gt;Computer1: READ: Im fine how are you
</code></pre>

<p>This was a lousy user experience though. So I wrote a command line tool to automate it. My tool asked the user for a message, and then behind the scenes it logged into my airmiles account via the website, using my credentials. The tool updated the name field of my test account with the user’s message. It then polled the name field every few seconds to see if my account’s name had changed again, which would indicate that the other person had sent a message back. Once the tool detected a new value it printed that value and asked the user for their next reply, and so on.</p>

<pre><code>sequenceDiagram
    actor Me
    participant AirmilesAccount as Airmiles Account&lt;br&gt;Name Field
    actor You
    
    You-&gt;&gt;AirmilesAccount: (poll for new data)
    AirmilesAccount--&gt;&gt;You: (no new data)
    Me-&gt;&gt;AirmilesAccount: WRITE: Hello how are you
    You-&gt;&gt;AirmilesAccount: (poll for new data)
    AirmilesAccount-&gt;&gt;You: READ: Hello how are you
    Me-&gt;&gt;AirmilesAccount: (poll for new data)
    AirmilesAccount--&gt;&gt;Me: (no new data)
    You-&gt;&gt;AirmilesAccount: WRITE: Im fine how are you
    Me-&gt;&gt;AirmilesAccount: (poll for new data)
    AirmilesAccount-&gt;&gt;Me: READ: Im fine how are you
</code></pre>

<p>Using this tool I could chat with someone on the ground, via my terminal. I wouldn’t have to pay for wifi, and neither of us would have to know or care that the messages were being sent via my SkyVenture Premium Gold Rewards account.</p>

<p>I still needed to find someone who would chat with me. But this was a good start!</p>

<blockquote>
  <p>NB: at this point I didn’t want to send any more automated data through my airmiles account in case that got me in trouble somehow. Nothing I was doing could possibly cause any damage, but some companies get jumpy about this kind of thing.</p>

  <p>I therefore proved to myself that PySkyWiFi would work on my airmiles accounts too by updating my name ten or so times in quick succession. They all succeeded, which suggested to me that my airmiles account probably wasn’t rate-limiting the speed or number of requests I could send to it.</p>

  <p>I then wrote the rest of my code by sending my data through friendly services like GitHub Gists and local files on my computer, using the same principles as if I were sending it through an airmiles account. If PySkyWiFi worked through GitHub then it would work through my Star Power UltimateBlastOff account too. This had the secondary advantage of being much faster and easier for iteration too.</p>

  <p>I’m going to keep talking about sending data through an airmiles account, because that’s the point I’m trying to make.</p>
</blockquote>

<h4 id="prototype-2-live-headlines-stock-prices-and-football-scores">Prototype 2: Live headlines, stock prices, and football scores</h4>

<p>The tunnel I’d constructed through my airmiles account would be useful for more than IMing. For my next prototype I wrote a program that would run on a computer back at my house or in the cloud, and would automatically send information from the real world up to me on the plane, through my airmiles account. I could deploy it before I left for my next flight and have it send me the latest stock prices or football scores while I was in the sky.</p>

<p>To do this I wrote a daemon that would run on a computer that was on the ground and connected to the internet. The daemon constantly polled the name field in my airmiles account, looking for structured messages that I sent to it from the plane (such as <code>STOCKPRICE: APPL</code> or <code>SCORE: MANUNITED</code>). When the daemon saw a new request it parsed it, retrieved the requested information using the relevant API, and sent it back to me via my airmiles account. It worked perfectly.</p>

<p>Now I could use my first prototype to send IMs through my airmiles account, and I could use my second prototype tio follow the markets and the sports.</p>

<p>It was time to squeeze the entire internet through my airmiles account.</p>

<h4 id="the-real-thing-pyskywifi">The real thing: PySkyWiFi</h4>

<p>During the rest of the flight I wrote PySkyWiFi. PySkyWiFi is a highly simplified version of the TCP/IP protocol that squeezes whole HTTP requests through an airmiles account, out of the plane, and down to a computer connected to the internet on the ground. A daemon running on this ground computer makes the HTTP requests for me, and then finally squeezes the completed HTTP responses back through my airmiles account, up to me on my plane.</p>

<p>This meant that on my next flight I could technically have full access to the internet, via my airmiles account. Depending on network conditions on the plane I might be able to hit speeds of several bytes per second.</p>

<blockquote>
  <p>DISCLAIMER: you obviously shouldn’t actually do any of this</p>
</blockquote>

<p>Here’s how it works (and <a href="https://github.com/robert/PySkyWiFi">here’s the source code</a>).</p>

<hr>

<h3 id="how-pyskywifi-works">How PySkyWiFi works</h3>

<p>PySkyWiFi has two components:</p>

<ul>
  <li><strong>The sky proxy</strong> - a proxy that runs on your laptop, on a plane</li>
  <li><strong>The ground daemon</strong> - a daemon that runs on a computer connected to the internet, at your home on the ground or in the cloud</li>
</ul>

<p>Here’s a simplified diagram:</p>

<pre><code>sequenceDiagram
    actor Me
    participant SkyProxy as Sky Proxy
    participant AirmilesAccount1 as Airmiles Account
    participant GroundDaemon as Ground Daemon
    participant Website as example.com

    Me-&gt;&gt;SkyProxy: HTTP request
    SkyProxy-&gt;&gt;AirmilesAccount1: HTTP request
    AirmilesAccount1-&gt;&gt;GroundDaemon: HTTP request
    GroundDaemon-&gt;&gt;Website: HTTP request
    Website-&gt;&gt;GroundDaemon: HTTP response
    GroundDaemon-&gt;&gt;AirmilesAccount1: HTTP response
    AirmilesAccount1-&gt;&gt;SkyProxy: HTTP response
    SkyProxy-&gt;&gt;Me: HTTP response
</code></pre>

<p>Setup starts before you leave your house. First you start up the ground daemon. Then you get a taxi to the airport, get on the plane, and connect to the plane’s wi-fi network. You boot up the sky proxy on your laptop. Your PySkyWiFi relay is now ready to go.</p>

<p>You use a tool like <code>curl</code> to make an HTTP request to the sky proxy that you’ve started on your laptop. You address your request to the proxy (eg. <code>localhost:1234/</code>) and you put the actual URL that you want to query inside a custom HTTP header called <code>X-PySkyWiFi</code>. For example:</p>

<div><pre><code>curl localhost:1234 -H "X-PySkyWiFi: example.com"`
</code></pre></div>

<p>The <code>X-PySkyWiFi</code> header will be stripped by the ground daemon and used to route your request to your target website. Everything else about the request (including the body and other headers) will be forwarded exactly as-is.</p>

<p>Once you make your request it will hang for several minutes. If by some miracle nothing breaks then you’ll eventually get back an HTTP response, exactly as if you’d sent the request over the normal internet like a normal person. The only difference is that it didn’t cost you anything. You will now almost certainly pay for wi-fi, because your curiosity has been satisfied and your time on this earth is very short.</p>

<h3 id="step-by-step">Step-by-step</h3>

<p>Here’s what happens behind the scenes:</p>


<pre><code>sequenceDiagram
    actor Me
    participant SkyProxy as Sky Proxy
    participant AirmilesAccount1 as Airmiles Account 1&lt;br&gt;Name Field
    participant AirmilesAccount2 as Airmiles Account 2&lt;br&gt;Name Field
    participant GroundDaemon as Ground Daemon
    participant Website as example.com

    Me-&gt;&gt;SkyProxy: curl localhost:1234 \n -H "X-PySkYWiFi: example.com"
    SkyProxy-&gt;&gt;AirmilesAccount1: Write request chunk 1
    GroundDaemon--&gt;&gt;AirmilesAccount1: (poll for new data)
    AirmilesAccount1-&gt;&gt;GroundDaemon: Read request chunk 1
    GroundDaemon-&gt;&gt;AirmilesAccount2: Ack request chunk 1
    SkyProxy--&gt;&gt;AirmilesAccount2: (poll for new data)
    AirmilesAccount2-&gt;&gt;SkyProxy: Read ack for request chunk 1
    SkyProxy-&gt;&gt;AirmilesAccount1: Write request chunk 2
    GroundDaemon--&gt;&gt;AirmilesAccount1: (poll for new data)
    AirmilesAccount1-&gt;&gt;GroundDaemon: Read request chunk 2
    Note over SkyProxy,GroundDaemon: Repeat until the whole HTTP request has been transferred
    GroundDaemon-&gt;&gt;Website: GET / HTTP/1.1&lt;br&gt;Host: example.com&lt;br&gt;&lt;etc&gt;
    Website-&gt;&gt;GroundDaemon: HTTP/1.1 200 OK&lt;br&gt;Content-Type: text/html&lt;br&gt;&lt;etc&gt;
    GroundDaemon-&gt;&gt;AirmilesAccount2: Write response chunk 1
    SkyProxy--&gt;&gt;AirmilesAccount2: (poll for new data)
    AirmilesAccount2-&gt;&gt;SkyProxy: Read response chunk 1
    SkyProxy-&gt;&gt;AirmilesAccount1: Ack request chunk 1
    GroundDaemon--&gt;&gt;AirmilesAccount1: (poll for new data)
    AirmilesAccount1-&gt;&gt;GroundDaemon: Read ack for request chunk 1
    GroundDaemon-&gt;&gt;AirmilesAccount2: Write response chunk 2
    SkyProxy--&gt;&gt;AirmilesAccount2: (poll for new data)
    AirmilesAccount2-&gt;&gt;SkyProxy: Read response chunk 2
    Note over GroundDaemon,SkyProxy: Repeat until the whole HTTP response has been transferred
    SkyProxy-&gt;&gt;Me: HTTP/1.1 200 OK&lt;br&gt;Content-Type: text/html&lt;br&gt;&lt;etc&gt;
</code></pre>

<p>In order:</p>

<ol>
  <li>The sky proxy receives the HTTP request from your <code>curl</code> call. It splits the request into chunks, because the entire request is too large to fit into you airmiles account in one go</li>
  <li>The sky proxy writes each chunk one-by-one to the name field in your airmiles account.</li>
  <li>The ground daemon polls your airmiles account. When it detects that the name field has changed to a new chunk, it reads that chunk and sends an acknowledgement to the sender so that the sender knows it’s safe to send the next chunk. The receiver sticks the chunks back together and rebuilds the original HTTP request</li>
  <li>Once the ground daemon has received and rebuilt the full HTTP request, it sends the request out over the internet.</li>
  <li>The ground daemon receives an HTTP response.</li>
  <li>The ground daemon sends the HTTP response up to the sky proxy using the same process as before, in reverse. This time the ground daemon splits the HTTP response up into chunks and writes each chunk one-by-one to the name field in your airmiles account (it actually writes these response chunks using a second airmiles account to make the protocol simpler)</li>
  <li>The sky proxy polls the second airmiles account. It reads each chunk and sticks them back together to rebuild the HTTP response</li>
  <li>The sky proxy returns the HTTP response to the original call to <code>curl</code>. As far as <code>curl</code> is concerned this is a perfectly normal HTTP response, just a little slow. <code>curl</code> has no idea about the silliness that just transpired</li>
</ol>

<p>The sky proxy and the ground daemon are relatively simple: they send HTTP requests and parse HTTP responses. The magic is in how they squeeze these requests and responses through an airmiles account. Let’s look closer.</p>

<h3 id="squeezing-http-requests-through-an-airmiles-account">Squeezing HTTP requests through an airmiles account</h3>

<p>PySkyWiFi’s communication logic is split into two layers: a <strong>transport layer</strong>, and a <strong>network layer</strong>. The transport layer’s job is to decide what data clients should send to each other. It dictates how senders should split up long messages into manageable chunks, as well as how senders and receivers should signal information like “I am ready to receive another chunk.” The PySkyWiFi transport layer is somewhat similar to the TCP protocol that powers much of the internet, if you squint very hard and don’t know much about TCP.</p>

<p>By contrast, the network layer’s job is to actually send data between clients, once the transport protocol has decided what that data should be. It’s vaguely similar to the IP protocol, if you squint even harder and know even less what you’re talking about.</p>

<p>This division of responsibility between layers is useful because the transport layer doesn’t have to care about how the network layer sends its data, and the network layer doesn’t care what the data it sends means or where it came from. The transport layer just hands the network layer some data, and the network layer sends it however it likes.</p>

<p>This separation makes it easy to add support for new airmiles platforms, because all we have to do is implement a new network layer that reads and writes to the new type of airmiles account. This separation also allows us to write test versions of the network protocol that write and read from local files instead of airmiles accounts. In each case the network layer changes, but the transport layer stays exactly the same. Here’s how they work.</p>

<h4 id="the-transport-layer">The transport layer</h4>

<p>A PySkyWiFi transport connection between two clients consists of two “pipes” (or “airmiles accounts”). Each client has a “SEND” pipe that it can write data to, and a “RECV” pipe that it can read from. Clients write to their SEND pipe by writing data to it, and they read from their RECV pipe by constantly polling it and seeing if anything has changed.</p>

<pre><code>flowchart LR
    Client1 --&gt; Client2
    Client2 --&gt; Client1
</code></pre>

<p>From the transport layer’s point of view, a pipe is just something that it can write and read data from. Beyond that the transport layer doesn’t care how its pipes work.</p>

<p>At any given moment a PSWF (PySkYWiFi) client can only either send or receive data, but not both. A client in <em>send mode</em> will not see data sent by the other client, and a client in <em>receive mode</em> should never send data because the other client won’t see it. This is unlike TCP, where clients can send or receive data at ay time.</p>

<p>When squeezing HTTP requests and responses through an airmiles account, the sky proxy sends the first message and the ground daemon receives it. Once the sky proxy has finished sending its HTTP request it switches to receive mode and the ground daemon switches to send. The ground daemon makes the HTTP request and sends back the response, at which point the two switch roles again so that the sky proxy can send another HTTP request.</p>

<h4 id="how-are-long-messages-sent-through-such-a-small-pipe">How are long messages sent through such a small pipe?</h4>

<p>PSWF uses small pipes (such as an airmiles name field) that can’t fit much data in them at once. This means that it takes some work and care to squeeze long messages (like HTTP requests) through them.</p>

<p>To send a long message, the sender first splits up their message into chunks that will fit into their SEND pipe. They then send each chunk down the pipe one at a time.</p>

<p>To begin a message, a sender starts by sending its first chunk of message data inside a <code>DATA</code> segment:</p>

<blockquote>
  <p>A <code>DATA</code> segment consists of:</p>

  <ul>
    <li>The letter <code>D</code></li>
    <li>The <em>sequence number</em> of the chunk (a number that uniquely identifies the chunk, padded to 6 digits)</li>
    <li>The actual chunk of data.</li>
  </ul>

  <p>For example, a data segment in the middle of a message might read: <code>D000451adline": "Mudslide in Wigan causes m</code></p>
</blockquote>

<p>Once the sender has sent a <code>DATA</code> segment, it pauses. It wants to send its next <code>DATA</code> segment, but it can’t overwrite the airmiles account name field until it knows that the receiver has received and processed the previous one.</p>

<p>The receiver tells the sender that it’s safe for to send a new <code>DATA</code> segment by acknowledging every segment that it reads. The receiver does this by writing an <code>ACK</code> segment to its own SEND pipe:</p>

<blockquote>
  <p>An <code>ACK</code> segment consists of:</p>

  <ul>
    <li>The letter <code>A</code></li>
    <li>The sequence number of the segment that is being acknowledged (padded to 6 digits)</li>
  </ul>

  <p>For example: <code>A000451</code></p>
</blockquote>

<p>The sender is constantly polling its own RCV pipe to check for changes, and so it reads this new <code>ACK</code> segment promptly. Once the sender reads the <code>ACK</code>, it knows that the receiver has received the segment corresponding to the <code>ACK</code>’s sequence number. For example, if a sender receives an <code>ACK</code> segment with sequence number <code>000451</code>, the sender knows that it’s safe to send the next <code>DATA</code> segment with sequence number <code>000452</code>. The sender therefore pulls the next chunk from its message and constructs a new <code>DATA</code> segment using this chunk and sequence number. The sender writes the new segment to its SEND pipe, and then pauses waits for another <code>ACK</code>.</p>

<p>This loop continues until the sender has sent all the data in its message. To tell the recipient that it’s finished, the sender sends an <code>END</code> segment.</p>

<blockquote>
  <p>An <code>END</code> segment is just the letter <code>E</code>.</p>
</blockquote>

<p>When a receiver sees an <code>END</code> segment it knows that the sender’s message is over. The sender and the receiver swap roles. The old sender starts polling its RECV pipe for <code>DATA</code> segments, and the old receiver starts chunking up its response message and sending it through its pipe, exactly as before.</p>

<p>None of this transport logic cares about the details of the network layer through which the segments are sent. The transport layer just needs the network layer to provide two pipes that it can read and write to. The network layer can pipe this data around via local files, a Discord profile, or an airmiles account. This genericness is what allows PySkyWiFi to work with any airline’s airmiles account, so long as the airline allows you to login to it from the plane without paying.</p>

<p>Here’s how PSWF uses transport protocol segments to exchange long messages:</p>


<pre><code>sequenceDiagram
    actor Me
    participant SkyProxy as Sky Proxy
    participant AirmilesAccount1 as Airmiles Account 1&lt;br&gt;Name Field
    participant AirmilesAccount2 as Airmiles Account 2&lt;br&gt;Name Field
    participant GroundDaemon as Ground Daemon
    participant Website as robertheaton.com

    Me-&gt;&gt;SkyProxy: curl localhost:1234 \n -H "X-PySkYWiFi: robertheaton.com"
    SkyProxy-&gt;&gt;AirmilesAccount1: Write DATA segment&lt;br&gt;sequence number=000000:&lt;br&gt;contents=`GET / HTTP/1.1 X-PySkyW`
    GroundDaemon--&gt;&gt;AirmilesAccount1: (poll for new data)
    AirmilesAccount1-&gt;&gt;GroundDaemon: Read DATA segment&lt;br&gt;sequence number=000000:&lt;br&gt;contents=`GET / HTTP/1.1 X-PySkyW`
    GroundDaemon-&gt;&gt;AirmilesAccount2: Write ACK segment&lt;br&gt;sequence number=000000
    SkyProxy--&gt;&gt;AirmilesAccount2: (poll for new data)
    AirmilesAccount2-&gt;&gt;SkyProxy: Read ACK segment&lt;br&gt;sequence number=000000
    SkyProxy-&gt;&gt;AirmilesAccount1: Write DATA segment&lt;br&gt;sequence number=000001&lt;br&gt;contents=`iFi: www.robertheaton.co`
    GroundDaemon--&gt;&gt;AirmilesAccount1: (poll for new data)
    AirmilesAccount1-&gt;&gt;GroundDaemon: Read DATA segment&lt;br&gt;sequence number=000001&lt;br&gt;contents=`iFi: www.robertheaton.co`
    Note over SkyProxy,GroundDaemon: Repeat until the whole HTTP request has been transferred
    GroundDaemon-&gt;&gt;Website: GET / HTTP/1.1&lt;br&gt;Host: robertheaton.com&lt;br&gt;&lt;etc&gt;
    Website-&gt;&gt;GroundDaemon: HTTP/1.1 200 OK&lt;br&gt;Content-Type: text/html, charset=UTF-8&lt;br&gt;&lt;etc&gt;
    GroundDaemon-&gt;&gt;AirmilesAccount2: Write DATA segment&lt;br&gt;sequence number=000000&lt;br&gt;contents=HTTP/1.1 200 OK\nCont
    SkyProxy--&gt;&gt;AirmilesAccount2: (poll for new data)
    AirmilesAccount2-&gt;&gt;SkyProxy: Read DATA segment&lt;br&gt;sequence number=000000&lt;br&gt;contents=HTTP/1.1 200 OK\nCont
    SkyProxy-&gt;&gt;AirmilesAccount1: Write ACK segment&lt;br&gt;sequence number=000000
    GroundDaemon--&gt;&gt;AirmilesAccount1: (poll for new data)
    AirmilesAccount1-&gt;&gt;GroundDaemon: Read ACK segment&lt;br&gt;sequence number=000000
    Note over GroundDaemon,SkyProxy: Repeat until the whole HTTP response has been transferred
    SkyProxy-&gt;&gt;Me: HTTP/1.1 200 OK&lt;br&gt;Content-Type: text/html, charset=UTF-8&lt;br&gt;&lt;etc&gt;
</code></pre>

<p>The transport layer decides what data the clients should send each other, but it doesn’t say anything about how they should send it. That’s where the network protocol comes in.</p>

<h3 id="the-network-layer">The network layer</h3>

<p>The network layer’s job is to send data between clients. It doesn’t care about where the data came from or what it means; it just receives some data from the transport layer and sends it to the other client (typically via an airmiles account).</p>

<p>This means that the network layer is quite simple. It also means that adding a new network layer for a new airmiles platform is straightforward. You use the new platform to implement a few operations and a few properties (see below), and then the transport layer can automatically to use your new airmiles platform with no extra work.</p>

<p>A network layer consists of two operations:</p>

<ul>
  <li><code>send(msg: str)</code> - write <code>msg</code> to storage. For an airmiles-based implementation, this writes the value of <code>msg</code> to the name field in the user’s airmiles account</li>
  <li><code>recv() -&gt; str</code> - read the message from storage. For an airmiles-based implementation, this reads the value of the name field from the user’s airmiles account.</li>
</ul>

<p>A network layer implementation must also define two properties:</p>

<ul>
  <li><code>sleep_for</code> - the number of seconds that the transport layer should sleep for in between polling for new segments from a RECV pipe. <code>sleep_for</code> can be very low for test implementations like files, but it should be at least several seconds for an implementation like an airmiles account. This is in order to avoid hammering remote server with too many requests.</li>
  <li><code>segment_data_size</code> - the number of characters that the transport layer should send in a single segment. Should be equal to the maximum size of the airmiles account field being used to transfer segments (often around 20 characters).</li>
</ul>

<p>A network layer implementation can also optionally provide two more operations:</p>

<ul>
  <li><code>connect_send()</code> - a hook called by the sender when a SEND pipe is initialised. In an airmiles-based implementation this allows the client to login to the platform using a username and password. This gives the client a cookie that it can use to authenticate future <code>send</code> and <code>recv</code> calls.</li>
  <li><code>connect_recv()</code> - a hook called by the receiver when a RECV pipe is initialised</li>
</ul>

<p>If you fill in all these methods, you’ll be able to use PySkyWiFi on a new airline. But again, don’t.</p>

<h3 id="tips-and-tricks">Tips and tricks</h3>

<p>When writing a network layer that uses a new airmiles provider, there are a couple of tricks that can make your implementation faster and more reliable.</p>

<h4 id="1-encode-messages-to-make-sure-the-airmiles-account-accepts-them">1. Encode messages to make sure the airmiles account accepts them</h4>

<p>Airmiles HTML forms usually don’t let users include non-alphabetic characters in their name. <code>Stephen</code> will probably be allowed, but <code>GET /data?id=5</code> will probably be rejected.</p>

<p>To work around this, the network layer should encode segments using base26 before writing them to an airmiles account. base26 is a way of representing a string using only the letters <code>A</code> to <code>Z</code> . In order to convert a byte string to base26, you convert the bytes to a single large number, then you represent that number using a counting system with base 26 (hence the name) where the digits are the letters <code>A</code> to <code>Z</code>.</p>

<div><pre><code><span>def</span> <span>b26_encode</span><span>(</span><span>input_string</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span># Convert input string to a base-256 integer
</span>    <span>base256_int</span> <span>=</span> <span>0</span>
    <span>for</span> <span>char</span> <span>in</span> <span>input_string</span><span>:</span>
        <span>base256_int</span> <span>=</span> <span>base256_int</span> <span>*</span> <span>256</span> <span>+</span> <span>ord</span><span>(</span><span>char</span><span>)</span>
    
    <span># Convert base-256 integer to base26 string
</span>    <span>if</span> <span>base256_int</span> <span>==</span> <span>0</span><span>:</span>
        <span>return</span> <span>'A'</span>  <span># Special case for empty input or input that equals zero
</span>    
    <span>base26_str</span> <span>=</span> <span>""</span>
    <span>while</span> <span>base256_int</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>base26_str</span> <span>=</span> <span>chr</span><span>(</span><span>base256_int</span> <span>%</span> <span>26</span> <span>+</span> <span>65</span><span>)</span> <span>+</span> <span>base26_str</span>
        <span>base256_int</span> <span>//=</span> <span>26</span>
    
    <span>return</span> <span>base26_str</span>

<span>b26_encode</span><span>(</span><span>"Hello world"</span><span>)</span>
<span># =&gt; 'CZEZINADXFFTZEIDPKM'
</span></code></pre></div>

<p>The transport layer never needs to know about this encoding. The network layer receives some bytes, encodes them using base26, and writes this encoded string of <code>A</code> to <code>Z</code> to the airmiles account. When the network layer reads the base26 value back out of the airmiles account, it decodes the encoded string back into a number and then back into bytes, and then returns those bytes to the transport layer.</p>

<p>Encoding a string using base 26 makes it significantly longer, just like how it takes many more digits to represent a number using binary than decimal. This reduces the bandwidth of our protocol. We could increase our bandwidth by using base52 (using both upper- and lower-case letters) instead of base26, which would shorten it somewhat. This is left as an enhancement for version 2.</p>

<h4 id="2-increase-bandwidth-by-using-more-account-fields">2. Increase bandwidth by using more account fields</h4>

<p>Another way to increase our PSWF bandwidth is to increase the segment size that a network layer can handle. If we double the size of our segments, we double the bandwidth of our protocol.</p>

<p>Fields in airmiles accounts usually have length limits. For example, you might not be allowed to set a name longer than 20 characters. However, we can maximise our bandwidth by:</p>

<ol>
  <li>Using the full length of the field</li>
  <li>Spreading out a segment across multiple fields</li>
</ol>

<p>Suppose we have control over 5 fields that can each store 20 characters. Instead of using one field to transmit segments of 20 characters, we can split a 100 character segment into 5 chunks of 20 and update them all at once in a single request. The receiver can then read all 5 fields, again in a single request, and stitch them back together to reconstruct the full segment.</p>

<h3 id="further-enhancements">Further enhancements</h3>

<h3 id="http-connect">HTTP <code>CONNECT</code></h3>

<p>It would be better if PySkyWiFi used <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/CONNECT">HTTP <code>CONNECT</code> requests</a> to set up the tunnel from the sky proxy to the target site, instead of manually tossing around HTTP requests. <code>CONNECT</code> requests are how most HTTP proxies work, and using them would allow PySkyWiFi to act as the system-level proxy and so handle requests from a web browser. It would also mean that PySkyWiFi would negotiate TLS connections with the target website directly, so its traffic would be encrypted as it passed through the airmiles account.</p>

<p>On the other hand, using <code>CONNECT</code> would also be a lot more work and I’ve already taken this joke way too far.</p>

<h2 id="in-conclusion">In conclusion</h2>

<p>When I was done with all of this I used PySkyWiFi to load the homepage of my blog using <code>curl</code>, tunneling the data via a GitHub Gist. Several minutes later I got a response back. I scrolled around the HTML and reflected that this had been both the most and least productive flight of my life.</p>

<p><em>(<a href="https://github.com/robert/PySkyWiFi">PySkyWiFi source code here</a>)</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MobileLLM: Optimizing Sub-Billion Parameter Language Models for On-Device Use (201 pts)]]></title>
            <link>https://github.com/facebookresearch/MobileLLM</link>
            <guid>40915005</guid>
            <pubDate>Tue, 09 Jul 2024 11:48:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/facebookresearch/MobileLLM">https://github.com/facebookresearch/MobileLLM</a>, See on <a href="https://news.ycombinator.com/item?id=40915005">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">MobileLLM</h2><a id="user-content-mobilellm" aria-label="Permalink: MobileLLM" href="#mobilellm"></a></p>
<p dir="auto">This repository contains the training code of MobileLLM introduced in our work: "<a href="https://arxiv.org/abs/2402.14905" rel="nofollow">MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases</a>", published in ICML 2024.</p>
<p dir="auto">In this work, we comprehensively consider multiple design factors to obtain high-quality LLMs with fewer than a billion parameters. We integrated (1) SwiGLU activation function, (2) deep and thin architectures, (3) embedding sharing, (4) grouped-query attention to build MobileLLM. MobileLLM-125M/350M attains a remarkable 2.7%/4.3% accuracy boost over preceding 125M/350M SoTA models on zero-shot commonsense reasoning tasks. In our updated version, we further demonstrate that our design philosophy scales effectively to larger models, with SoTA results for MobileLLM-600M/1B/1.5B.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/facebookresearch/MobileLLM/blob/main/mobilellm.png"><img width="50%" src="https://github.com/facebookresearch/MobileLLM/raw/main/mobilellm.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you find our code useful for your research, please consider citing:</p>
<div data-snippet-clipboard-copy-content="@article{liu2024mobilellm,
    title={MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases},
    author={Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and others},
    journal={arXiv preprint arXiv:2402.14905},
    year={2024}
}"><pre><code>@article{liu2024mobilellm,
    title={MobileLLM: Optimizing Sub-billion Parameter Language Models for On-Device Use Cases},
    author={Liu, Zechun and Zhao, Changsheng and Iandola, Forrest and Lai, Chen and Tian, Yuandong and Fedorov, Igor and Xiong, Yunyang and Chang, Ernie and Shi, Yangyang and Krishnamoorthi, Raghuraman and others},
    journal={arXiv preprint arXiv:2402.14905},
    year={2024}
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run</h2><a id="user-content-run" aria-label="Permalink: Run" href="#run"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 1. Requirements:</h3><a id="user-content-step-1-requirements" aria-label="Permalink: Step 1. Requirements:" href="#step-1-requirements"></a></p>
<ul dir="auto">
<li>python 3.9, pytorch &gt;= 2.0</li>
<li>pip install -r requirement.txt</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 2. Data preprocessing</h3><a id="user-content-step-2-data-preprocessing" aria-label="Permalink: Step 2. Data preprocessing" href="#step-2-data-preprocessing"></a></p>
<p dir="auto">Dividing a tokenized dataset or tokenize your own dataset, and even distribute it across the total number of training nodes, where each node comprises 1x8 GPUs. Next, organize the data into the following structure:</p>
<ul dir="auto">
<li>basepath
<ul dir="auto">
<li>1
<ul dir="auto">
<li>xxx.jsonl</li>
</ul>
</li>
<li>2
<ul dir="auto">
<li>xxx.jsonl</li>
</ul>
</li>
<li>...</li>
<li>#nodes
<ul dir="auto">
<li>xxx.jsonl</li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto">Each line of a jsonl file is a key-value pair of tokenized data {"token_ids": [1,2,3,4,...]}.</p>
<p dir="auto">Our training code is compatible with the data pre-processing method in <a href="https://github.com/LLM360/amber-data-prep">https://github.com/LLM360/amber-data-prep</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Step 3. Training script</h3><a id="user-content-step-3-training-script" aria-label="Permalink: Step 3. Training script" href="#step-3-training-script"></a></p>
<p dir="auto">The script <code>pretrain.sh</code> is provided to initiate training on a 1x8 node setup using torchrun. This script can be modified to adjust the <code>--nnodes</code> parameter and other settings to suit different multi-node configurations, such as those using slurm or torchx. The learning rate in the script is for 1x8 node with a batch size of 32. If you increase the number of nodes or the batch size, you need to increase the learning rate linearly.</p>
<p dir="auto">Steps to run:</p>
<ul dir="auto">
<li>In <code>pretrain.sh</code> file, specify the  <code>--train_data_local_path</code> to the pre-processed data in Step 2 and <code>--input_model_filename</code> to <code>./configs/{model_size}/</code>.</li>
<li>Run <code>bash pretrain.sh </code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Others</h3><a id="user-content-others" aria-label="Permalink: Others" href="#others"></a></p>
<p dir="auto">The model weights is still under legal review. If you have any questions, feel free to email (zechunliu at meta dot com) and (cszhao at meta dot com)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Results on Zero-shot Common Sense Reasoning tasks</h2><a id="user-content-results-on-zero-shot-common-sense-reasoning-tasks" aria-label="Permalink: Results on Zero-shot Common Sense Reasoning tasks" href="#results-on-zero-shot-common-sense-reasoning-tasks"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">MobileLLM-125M</h3><a id="user-content-mobilellm-125m" aria-label="Permalink: MobileLLM-125M" href="#mobilellm-125m"></a></p>
<table>
<thead>
<tr>
<th>model</th>
<th>boolq</th>
<th>piqa</th>
<th>siqa</th>
<th>hellaswag</th>
<th>winogrande</th>
<th>arc_easy</th>
<th>arc_challenge</th>
<th>obqa</th>
<th>avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td>OPT-125M</td>
<td>41.3</td>
<td>25.2</td>
<td>57.5</td>
<td>62.0</td>
<td>41.9</td>
<td>31.1</td>
<td>31.2</td>
<td>50.8</td>
<td>42.6</td>
</tr>
<tr>
<td>GPT-neo-125M</td>
<td>40.7</td>
<td>24.8</td>
<td>61.3</td>
<td>62.5</td>
<td>41.9</td>
<td>29.7</td>
<td>31.6</td>
<td>50.7</td>
<td>42.9</td>
</tr>
<tr>
<td>Pythia-160M</td>
<td>40.0</td>
<td>25.3</td>
<td>59.5</td>
<td>62.0</td>
<td>41.5</td>
<td>29.9</td>
<td>31.2</td>
<td>50.9</td>
<td>42.5</td>
</tr>
<tr>
<td><strong>MobileLLM-125M</strong></td>
<td>43.9</td>
<td>27.1</td>
<td>60.2</td>
<td>65.3</td>
<td>42.4</td>
<td>38.9</td>
<td>39.5</td>
<td>53.1</td>
<td><strong>46.3</strong></td>
</tr>
<tr>
<td><strong>MobileLLM-LS-125M</strong></td>
<td>45.8</td>
<td>28.7</td>
<td>60.4</td>
<td>65.7</td>
<td>42.9</td>
<td>39.5</td>
<td>41.1</td>
<td>52.1</td>
<td><strong>47.0</strong></td>
</tr>
</tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">MobileLLM-350M</h3><a id="user-content-mobilellm-350m" aria-label="Permalink: MobileLLM-350M" href="#mobilellm-350m"></a></p>
<table>
<thead>
<tr>
<th>model</th>
<th>boolq</th>
<th>piqa</th>
<th>siqa</th>
<th>hellaswag</th>
<th>winogrande</th>
<th>arc_easy</th>
<th>arc_challenge</th>
<th>obqa</th>
<th>avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td>OPT-350M</td>
<td>41.9</td>
<td>25.7</td>
<td>54.0</td>
<td>64.8</td>
<td>42.6</td>
<td>36.2</td>
<td>33.3</td>
<td>52.4</td>
<td>43.9</td>
</tr>
<tr>
<td>Pythia-410M</td>
<td>47.1</td>
<td>30.3</td>
<td>55.3</td>
<td>67.2</td>
<td>43.1</td>
<td>40.1</td>
<td>36.2</td>
<td>53.4</td>
<td>46.6</td>
</tr>
<tr>
<td><strong>MobileLLM-350M</strong></td>
<td>53.8</td>
<td>33.5</td>
<td>62.4</td>
<td>68.6</td>
<td>44.7</td>
<td>49.6</td>
<td>40.0</td>
<td>57.6</td>
<td><strong>51.3</strong></td>
</tr>
<tr>
<td><strong>MobileLLM-LS-350M</strong></td>
<td>54.4</td>
<td>32.5</td>
<td>62.8</td>
<td>69.8</td>
<td>44.1</td>
<td>50.6</td>
<td>45.8</td>
<td>57.2</td>
<td><strong>52.1</strong></td>
</tr>
</tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">MobileLLM-600M</h3><a id="user-content-mobilellm-600m" aria-label="Permalink: MobileLLM-600M" href="#mobilellm-600m"></a></p>
<table>
<thead>
<tr>
<th>model</th>
<th>boolq</th>
<th>piqa</th>
<th>siqa</th>
<th>hellaswag</th>
<th>winogrande</th>
<th>arc_easy</th>
<th>arc_challenge</th>
<th>obqa</th>
<th>avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td>Qwen1.5-500M</td>
<td>54.7</td>
<td>32.1</td>
<td>46.9</td>
<td>68.9</td>
<td>46.0</td>
<td>48.8</td>
<td>37.7</td>
<td>55.0</td>
<td>48.8</td>
</tr>
<tr>
<td>BLOOM-560M</td>
<td>43.7</td>
<td>27.5</td>
<td>53.7</td>
<td>65.1</td>
<td>42.5</td>
<td>36.5</td>
<td>32.6</td>
<td>52.2</td>
<td>44.2</td>
</tr>
<tr>
<td>MobiLlama-800M</td>
<td>52.0</td>
<td>31.7</td>
<td>54.6</td>
<td>73.0</td>
<td>43.3</td>
<td>52.3</td>
<td>42.5</td>
<td>56.3</td>
<td>50.7</td>
</tr>
<tr>
<td><strong>MobileLLM-600M</strong></td>
<td>58.1</td>
<td>35.8</td>
<td>61.0</td>
<td>72.3</td>
<td>44.9</td>
<td>55.9</td>
<td>47.9</td>
<td>58.6</td>
<td><strong>54.3</strong></td>
</tr>
</tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">MobileLLM-1B</h3><a id="user-content-mobilellm-1b" aria-label="Permalink: MobileLLM-1B" href="#mobilellm-1b"></a></p>
<table>
<thead>
<tr>
<th>model</th>
<th>boolq</th>
<th>piqa</th>
<th>siqa</th>
<th>hellaswag</th>
<th>winogrande</th>
<th>arc_easy</th>
<th>arc_challenge</th>
<th>obqa</th>
<th>avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td>Pythia-1B</td>
<td>49.9</td>
<td>30.4</td>
<td>58.7</td>
<td>69.2</td>
<td>43.3</td>
<td>47.4</td>
<td>38.6</td>
<td>52.2</td>
<td>48.7</td>
</tr>
<tr>
<td>MobiLlama-1B</td>
<td>59.7</td>
<td>38.4</td>
<td>59.2</td>
<td>74.5</td>
<td>44.9</td>
<td>62.0</td>
<td>43.7</td>
<td>59.0</td>
<td>55.2</td>
</tr>
<tr>
<td>Falcon-1B</td>
<td>59.5</td>
<td>38.4</td>
<td>63.9</td>
<td>74.6</td>
<td>44.6</td>
<td>62.9</td>
<td>45.6</td>
<td>60.9</td>
<td>56.3</td>
</tr>
<tr>
<td>BLOOM-1.1B</td>
<td>47.6</td>
<td>27.3</td>
<td>58.6</td>
<td>67.0</td>
<td>42.4</td>
<td>42.2</td>
<td>36.6</td>
<td>53.8</td>
<td>46.9</td>
</tr>
<tr>
<td>TinyLlama-1.1B</td>
<td>59.2</td>
<td>37.1</td>
<td>58.1</td>
<td>72.9</td>
<td>43.9</td>
<td>59.1</td>
<td>44.7</td>
<td>58.8</td>
<td>54.2</td>
</tr>
<tr>
<td><strong>MobileLLM-1B</strong></td>
<td>63.0</td>
<td>39.0</td>
<td>66.7</td>
<td>74.4</td>
<td>45.0</td>
<td>61.4</td>
<td>46.8</td>
<td>62.3</td>
<td><strong>57.3</strong></td>
</tr>
</tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">MobileLLM-1.5B</h3><a id="user-content-mobilellm-15b" aria-label="Permalink: MobileLLM-1.5B" href="#mobilellm-15b"></a></p>
<table>
<thead>
<tr>
<th>model</th>
<th>boolq</th>
<th>piqa</th>
<th>siqa</th>
<th>hellaswag</th>
<th>winogrande</th>
<th>arc_easy</th>
<th>arc_challenge</th>
<th>obqa</th>
<th>avg.</th>
</tr>
</thead>
<tbody>
<tr>
<td>GPT-neo-1.3B</td>
<td>51.3</td>
<td>33.0</td>
<td>61.8</td>
<td>70.9</td>
<td>43.7</td>
<td>48.6</td>
<td>41.2</td>
<td>54.5</td>
<td>50.6</td>
</tr>
<tr>
<td>OPT-1.3B</td>
<td>54.4</td>
<td>31.7</td>
<td>58.4</td>
<td>71.5</td>
<td>44.7</td>
<td>53.7</td>
<td>44.6</td>
<td>59.1</td>
<td>52.3</td>
</tr>
<tr>
<td>BLOOM-1.7B</td>
<td>50.9</td>
<td>31.2</td>
<td>61.7</td>
<td>70.0</td>
<td>43.2</td>
<td>47.2</td>
<td>36.2</td>
<td>56.1</td>
<td>49.6</td>
</tr>
<tr>
<td>Qwen1.5-1.8B</td>
<td>61.1</td>
<td>36.5</td>
<td>68.3</td>
<td>74.1</td>
<td>47.2</td>
<td>60.4</td>
<td>42.9</td>
<td>61.2</td>
<td>56.5</td>
</tr>
<tr>
<td>GPT-neo-2.7B</td>
<td>55.8</td>
<td>34.3</td>
<td>62.4</td>
<td>72.9</td>
<td>43.6</td>
<td>55.6</td>
<td>40.0</td>
<td>57.9</td>
<td>52.8</td>
</tr>
<tr>
<td>OPT-2.7B</td>
<td>56.6</td>
<td>34.6</td>
<td>61.8</td>
<td>74.5</td>
<td>45.6</td>
<td>60.2</td>
<td>48.2</td>
<td>59.6</td>
<td>55.1</td>
</tr>
<tr>
<td>Pythia-2.8B</td>
<td>59.4</td>
<td>38.9</td>
<td>66.1</td>
<td>73.8</td>
<td>44.5</td>
<td>59.6</td>
<td>45.0</td>
<td>59.4</td>
<td>55.8</td>
</tr>
<tr>
<td>BLOOM-3B</td>
<td>55.1</td>
<td>33.6</td>
<td>62.1</td>
<td>70.5</td>
<td>43.2</td>
<td>53.9</td>
<td>41.6</td>
<td>58.2</td>
<td>52.3</td>
</tr>
<tr>
<td><strong>MobileLLM-1.5B</strong></td>
<td>67.5</td>
<td>40.9</td>
<td>65.7</td>
<td>74.8</td>
<td>46.4</td>
<td>64.5</td>
<td>50.5</td>
<td>64.7</td>
<td><strong>59.4</strong></td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgement</h2><a id="user-content-acknowledgement" aria-label="Permalink: Acknowledgement" href="#acknowledgement"></a></p>
<p dir="auto">This code is partially based on HuggingFace transformer repo.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">Zechun Liu, Meta Inc (zechunliu at meta dot com)</p>
<p dir="auto">Changsheng Zhao, Meta Inc (cszhao at meta dot com)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">BiT is CC-BY-NC 4.0 licensed as of now.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamic translation of Smalltalk to WebAssembly (122 pts)]]></title>
            <link>https://thiscontext.com/2023/07/26/dynamic-translation-of-smalltalk-to-webassembly/</link>
            <guid>40914475</guid>
            <pubDate>Tue, 09 Jul 2024 10:34:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thiscontext.com/2023/07/26/dynamic-translation-of-smalltalk-to-webassembly/">https://thiscontext.com/2023/07/26/dynamic-translation-of-smalltalk-to-webassembly/</a>, See on <a href="https://news.ycombinator.com/item?id=40914475">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<div>
<figure><a href="https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg"><img data-attachment-id="2438" data-permalink="https://thiscontext.com/2023/07/26/dynamic-translation-of-smalltalk-to-webassembly/r647yxe-scientific-dna-wallpapers-2015/" data-orig-file="https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="r647yxe-scientific-dna-wallpapers-2015" data-image-description="" data-image-caption="" data-medium-file="https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=300" data-large-file="https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=450" tabindex="0" role="button" src="https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=1024" alt="" width="669" height="376" srcset="https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=1024 1024w, https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=669 669w, https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=1338 1338w, https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=150 150w, https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=300 300w, https://thiscontext.com/wp-content/uploads/2023/07/r647yxe-scientific-dna-wallpapers-2015.jpg?w=768 768w" sizes="(max-width: 669px) 100vw, 669px"></a><figcaption><em>continuing with the DNA theme…</em></figcaption></figure></div>


<p>In <a href="https://thiscontext.com/2023/05/08/catalyst-a-webassembly-enabled-version-of-squeakjs/">Catalyst</a>, a <a href="https://www.wikiwand.com/en/Webassembly">WebAssembly</a> implementation of the <a href="https://github.com/OpenSmalltalk/opensmalltalk-vm">OpenSmalltalk</a> virtual machine, there are three linguistic levels in play: <a href="https://www.wikiwand.com/en/Smalltalk">Smalltalk</a>, <a href="https://www.wikiwand.com/en/JavaScript">JavaScript</a> (JS), and WebAssembly (WASM). Smalltalk is our primary language, JS is the coordinating language of the hosting environment (a web browser), and WASM is a high-performance runtime instruction set to which we can compile any other language. In a previous article, I wrote about <a href="https://thiscontext.com/2023/07/06/automated-translation-of-javascript-to-webassembly-for-squeakjs/">automatic translation of JS to WASM</a>, as a temporary way of translating the <a href="https://squeak.js.org/">SqueakJS</a> virtual machine to WASM. That benefits from a proven JS starting point for the relatively large codebase of the virtual machine. When translating individual Smalltalk compiled methods for “just-in-time” optimization, however, it makes more sense to translate from Smalltalk to WASM directly.</p>



<h2>compiled method transcription</h2>



<p>We already have infrastructure for transcribing Smalltalk compiled methods, via class InstructionStream. We use it to print human-readable descriptions of method instructions, and to simulate their execution in the Smalltalk debugger. We can also use it to translate a method to human-readable <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/Understanding_the_text_format">WebAssembly Text</a> (WAT) source code, suitable for translation to binary WASM code which the web browser can execute. Since the Smalltalk and WASM instruction sets are both stack-oriented, the task is straightforward.</p>



<p>I’ve created a subclass of InstructionStream, called WATCompiledMethodTranslator, which uses the classic scanner pattern to drive translation from Smalltalk instructions to WASM instructions. With accompanying WASM type information for Smalltalk virtual machine structures, we can make WASM modules that execute the instructions for individual Smalltalk methods.</p>



<h2>the “hello world” of Smalltalk: 3 + 4</h2>



<p>As an example, let’s take a look at translating the traditional first Smalltalk expression, 3 + 4. We’ll create a Smalltalk method in class HelloWASM from this source:</p>


<div><pre title="">HelloWASM&gt;&gt;add
	"Add two numbers."

	^3 + 4
</pre></div>


<p>This gives us a compiled method with the following Smalltalk instructions. On each line below, we list the program counter value, the instruction, and a description of the instruction.</p>


<div><pre title="">0: 0x20: push the literal constant at index 0 (3) onto the method's stack
1: 0x21: push the literal constant at index 1 (4) onto the method's stack
2: 0xB0: send the arithmetic message at index 0 (+)
3: 0x7C: return the top of the method's stack
</pre></div>


<p>A WATCompiledMethodTranslator uses an instance of InstructionStream as a scanner of the method, interpreting each Smalltalk instruction in turn. When interpreting an instruction, the scanner sends a corresponding message to the translator, which in turn writes a transcription of that instruction as WASM instructions, onto a stream of WAT source.</p>



<p>The first instruction in the method is “push the literal constant at index 0”. The scanner finds the indicated literal in the literal frame of the method (i.e., 3), and sends <strong>pushConstant: 3</strong> to the translator. Here are the methods that the translator runs in response:</p>


<div><pre title="">WATCompiledMethodTranslator&gt;&gt;pushConstant: value
	"Push value, a constant, onto the method's stack."

	self
		comment: 'push constant ', value printString;
		pushFrom: [value printWATFor: self]
</pre></div>

<div><pre title="">WATCompiledMethodTranslator&gt;&gt;pushFrom: closure
     "Evaluate closure, which emits WASM instructions that push a value onto the WASM stack. Emit further WASM instructions that push that value onto the Smalltalk stack."

	self
		setElementAtIndexFrom: [
			self
				incrementField: #sp
				ofStructType: #vm
				named: #vm;
				getField: #sp
				ofStructType: #vm
				named: #vm]
		ofArrayType: #pointers
		named: #stack
		from: closure
</pre></div>

<div><pre title="">WATCompiledMethodTranslator&gt;&gt;setElementAtIndexFrom: elementIndexClosure ofArrayType: arrayTypeName named: arrayName from: elementValueClosure
	"Evaluate elementIndexClosure to emit WASM instructions that leave an array index on the WASM stack. Evaluate elementValueClosure to emit WASM instructions that leave an array element value on the WASM stack. Emit further WASM instructions, setting the element with that index in an array of the given type and variable name to the value."

	self get: arrayName.
	{elementIndexClosure. elementValueClosure} do: [:each | each value].

	self
		indent;
		nextPutAll: 'array.set $';
		nextPutAll: arrayTypeName
</pre></div>


<p>In the final method above, we finally see a WASM instruction, <strong>array.set</strong>. The translator implements stream protocol for actually writing WAT text to a stream. The <strong>comment:</strong>, <strong>get:</strong>, and <strong>getField:ofStructType:named:</strong> methods are similar, using “;;” and the <strong>array.get</strong> and <strong>struct.get</strong> WASM instructions. The array and struct instructions are part of the <a href="https://github.com/WebAssembly/gc/blob/master/proposals/gc/MVP.md">WASM garbage collection extension</a>, which introduces types.</p>



<h2>WASM types for virtual machine structures</h2>



<p>To actually use WASM instructions that make use of types, we need to define the types in our method’s WASM module. In <strong>pushFrom:</strong> above, we use a struct variable of type <strong>vm</strong> named <strong>vm</strong>, and an array variable of type <strong>pointers</strong> named <strong>stack</strong>. The <strong>vm</strong> variable holds global virtual machine state (for example, the currently executing method’s stack pointer), similar to the <strong>SqueakJS.vm</strong> variable in SqueakJS. The <strong>stack</strong> variable holds an array of Smalltalk object pointers, constituting the current method’s stack. In general, the WASM code for a Smalltalk method will also need fast variable access to the active Smalltalk context, the active context’s stack, the current method’s literals, and the current method’s temporary variables.</p>



<p>Our WASM module for <strong>HelloWASM&gt;&gt;add</strong> might begin like this:</p>


<div><pre title="">(module
	(type $bytes (array (mut i8)))
 	(type $words (array (mut i32)))
 	(type $pointers (array (ref $object)))

 	(type $object (struct
		(field $metabits (mut i32))
		(field $class (ref $object))
		(field $format (mut i32))
		(field $hash (mut i32))
		(field $pointers (ref $pointers))
		(field $words (ref $words))
		(field $bytes (ref $bytes))
		(field $float (mut f32))
		(field $integer (mut i32))
		(field $address (mut i32))
		(field $nextObject (ref $object))))

	(global $vm (struct
		(field $sp (mut i32))
		(field $pc (mut i32)))

	(global $stack (array (ref $pointers)))

	(function $HelloWASM_add
		;; pc 0
		;; push constant 3
		global.get $stack
		global.get $vm
		global.get $vm
		struct.get $vm $sp
		i32.const 1
		i32.add
		struct.set $vm $sp ;; increment the stack pointer
		global.get $vm
		struct.get $vm $sp
		i32.const 3
		array.set $pointers
		
		;; pc 1
		...
</pre></div>


<p>As is typical with assembly-level code, there’s a lot of setup involved which seems quite verbose, but it enables fast paths for the execution machinery. We’re also effectively taking on the task of writing the firmware for our idealized Smalltalk processor, by setting up interfaces to contexts and methods, and by implementing the logic for each Smalltalk instruction. In a future article, I’ll discuss the mechanisms by which we actually run the WASM code for a Smalltalk method. I’ll also compare the performance of dynamic WASM translations of Smalltalk methods versus the dynamic JS translations that SqueakJS makes. I don’t expect the WASM translations to be much (or any) faster at the moment, but I do expect them to get faster over time, as the WASM engines in web browsers improve (just as JS engines have).</p>

				
				<p>
					<small>
						This entry was posted on 26 July 2023 at 9:52 am and is filed under <a href="https://thiscontext.com/tag/caffeine/" rel="category tag">Caffeine</a>, <a href="https://thiscontext.com/tag/consulting/" rel="category tag">consulting</a>, <a href="https://thiscontext.com/category/context/" rel="category tag">Context</a>, <a href="https://thiscontext.com/tag/livecoding/" rel="category tag">livecoding</a>, <a href="https://thiscontext.com/category/smalltalk-2/" rel="category tag">Smalltalk</a>, <a href="https://thiscontext.com/category/spoon/" rel="category tag">Spoon</a>, <a href="https://thiscontext.com/tag/squeakjs/" rel="category tag">SqueakJS</a> with tags <a href="https://thiscontext.com/tag/caffeine/" rel="tag">Caffeine</a>, <a href="https://thiscontext.com/tag/context-2/" rel="tag">context</a>, <a href="https://thiscontext.com/tag/javascript/" rel="tag">JavaScript</a>, <a href="https://thiscontext.com/tag/livecoding/" rel="tag">livecoding</a>, <a href="https://thiscontext.com/tag/smalltalk/" rel="tag">smalltalk</a>, <a href="https://thiscontext.com/tag/squeak/" rel="tag">squeak</a>, <a href="https://thiscontext.com/tag/squeakjs/" rel="tag">SqueakJS</a>, <a href="https://thiscontext.com/tag/webassembly/" rel="tag">WebAssembly</a>.						You can follow any responses to this entry through the <a href="https://thiscontext.com/2023/07/26/dynamic-translation-of-smalltalk-to-webassembly/feed/">RSS 2.0</a> feed.
													You can <a href="#respond">leave a response</a>, or <a href="https://thiscontext.com/2023/07/26/dynamic-translation-of-smalltalk-to-webassembly/trackback/">trackback</a> from your own site.
						
					</small>
				</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HP discontinues online-only LaserJet printers in response to backlash (136 pts)]]></title>
            <link>https://www.tomshardware.com/peripherals/printers/hp-discontinues-online-only-laserjet-printers-in-response-to-backlash</link>
            <guid>40914029</guid>
            <pubDate>Tue, 09 Jul 2024 09:20:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/peripherals/printers/hp-discontinues-online-only-laserjet-printers-in-response-to-backlash">https://www.tomshardware.com/peripherals/printers/hp-discontinues-online-only-laserjet-printers-in-response-to-backlash</a>, See on <a href="https://news.ycombinator.com/item?id=40914029">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-320-80.png.webp 320w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-970-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-1024-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-1200-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-1920-80.png.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-320-80.png" alt="Official render of the HP LaserJet Pro 3002dwe, one of the printers being discontinued." srcset="https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-320-80.png 320w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-970-80.png 970w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-1024-80.png 1024w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-1200-80.png 1200w, https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm-1920-80.png 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm.png"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/R4qKkoKQk2238TimxMg5Cm.png">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span>Official render of the HP LaserJet Pro 3002dwe, one of the printers being discontinued.</span>
<span itemprop="copyrightHolder">(Image credit: HP)</span>
</figcaption>
</div>

<div id="article-body">
<p>Per a report from <a data-analytics-id="inline-link" href="https://www.druckerchannel.de/artikel.php?ID=5023&amp;t=hp_laserjet_drucker" target="_blank" data-url="https://www.druckerchannel.de/artikel.php?ID=5023&amp;t=hp_laserjet_drucker" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">DruckerChannel</a>, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/hewlett-packard" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/hewlett-packard">HP</a> has finally been forced to discontinue its cheaper e-series LaserJet printers due to customers experiencing problems with their online-only and always tied to HP+ subscription requirements. Among other things, HP+ requires a permanent Internet connection, and customers only use HP-original ink and toners, not allowing for third-party alternatives to be used at all. There are benefits to HP+, including cloud printing and an extra year's warranty, but the forced online requirement for a cheaper printer left a bad taste in the mouths of many consumers.</p><p>In any case, it's important to clarify that this discontinuation of HP printers will only impact HP LaserJet printers that have an "e" added to the end of their model name to denote the alternative business model. So, the HP Laserjet M110w is unaffected by this, but the HP LaserJet M110we and M209dwe, two cheaper always-online alternatives, will no longer be produced or sold by HP.</p><p>Another critical point of clarification is that the existing HP e-series LaserJet printer models in the wild will still function exactly as they did when they were purchased. No software updates are forthcoming to unlock the true potential of the hardware, so existing customers will have to deal with it and HP+ until they can replace their printers entirely. At least they'll still get HP+ benefits, but after such backlash, it'd be nice if HP acknowledged its mistake enough to remove some of the restrictions on e-series printer users.</p><p>Speaking to DruckerChannel, an HP representative had the following to say (translated from German) on the discontinuation of these printers.&nbsp;</p><p>"Since the introduction of HP+, our smart, connected printing system has been embraced by customers who appreciate the convenience, extended warranty, and solutions," said the HP representative, "We know that some customers in IT-managed office environments are unable to meet the cloud connection requirements for HP+. To provide our customers with an exceptional printing experience in all office environments, we will no longer offer LaserJet series products with HP+. We plan to extend proven solutions such as Print from Anywhere and Smart <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/security" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/security">Security</a> to select new HP LaserJet devices. HP+ customers who are satisfied [...] do not need to make any adjustments."</p><p>The HP representative also disclosed that "HP will stop marketing the Instant Ink toner subscription service later this year. The service will no longer be available to new customers. This will not affect existing Instant Ink toner subscribers, only those new to the service."</p><p>The reasons for Instant Ink's discontinuation are less clear, as it was an optional subscription. DruckerChannel speculates it may have been getting confused or conflated with HP+ and that some customers may even think it required HP+, so HP opted to discontinue the service to simplify things for end users. That step, at least, feels like a slight overcorrection.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-PWXp4w6JeR4nwWqNo3Zjv"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>
<div id="slice-container-authorBio-PWXp4w6JeR4nwWqNo3Zjv"><p>Christopher Harper has been a successful freelance tech writer specializing in PC hardware and gaming since 2015, and ghostwrote&nbsp;for various B2B clients in High School before that. Outside of work, Christopher is best known to friends and rivals as an active competitive player in various eSports (particularly fighting games and arena shooters) and a purveyor of music ranging from Jimi Hendrix to Killer Mike to the&nbsp;<em>Sonic Adventure 2</em>&nbsp;soundtrack.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's Xandr grants GDPR rights at a rate of 0% (189 pts)]]></title>
            <link>https://noyb.eu/en/microsofts-xandr-grants-gdpr-rights-rate-0</link>
            <guid>40913915</guid>
            <pubDate>Tue, 09 Jul 2024 09:00:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noyb.eu/en/microsofts-xandr-grants-gdpr-rights-rate-0">https://noyb.eu/en/microsofts-xandr-grants-gdpr-rights-rate-0</a>, See on <a href="https://news.ycombinator.com/item?id=40913915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><ul><li><a href="https://noyb.eu/sites/default/files/2024-07/Xandr%20Complaint-EN_redacted.pdf">Complaint against Xandr (EN)</a></li><li><a href="https://noyb.eu/sites/default/files/2024-07/Xandr%20Reclamo-IT_redacted.pdf">Complaint against Xandr (IT)</a></li></ul><p><strong>Background: targeted advertising.</strong> If companies want to use targeted advertising to promote their products or services online, they have to go through so-called Real Time Bidding (RTB) platforms. One such platform is run by Microsoft subsidiary Xandr, which allows advertisers to buy ad space on websites or in mobile apps in a fully automated way. When a user visits a website, an algorithmic auction takes place in order to decide which company can display an advertisement. Because a users’ interests and characteristics ultimately determine an advertiser’s willingness to place an ad, Xandr collects and shares a massive amount of personal data in order to profile the users and to allow for targeting. Much of that data is bought by external parties like <a href="https://www.emetriq.com/">emetriq, a subsidiary of the German Telecom</a>.</p><p><strong>Disability? Pregnant? LGBT?</strong> <a href="https://netzpolitik.org/2023/microsofts-datenmarktplatz-xandr-das-sind-650-000-kategorien-in-die-uns-die-online-werbeindustrie-einsortiert/">Previous research has shown</a> that <a href="https://themarkup.org/privacy/2023/06/08/from-heavy-purchasers-of-pregnancy-tests-to-the-depression-prone-we-found-650000-ways-advertisers-label-you">Xandr collects hundreds of sensitive profiles</a> of Europeans containing information about their health, sex life or sexual orientation, political or philosophical opinions, religious beliefs or financial status. Specific segments include things like ‘french_disability’, ‘pregnant’, ‘lgbt’, ‘gender_equality’ and ‘jewishfrench’.</p><p><strong>0% compliance with GDPR requests. </strong>According to the GDPR, everyone has the right to get access to their information. However, despite collecting vast amounts of detailed information about people, Xandr reports an astonishing 0% response rate to access and erasure requests in 2022. <a href="https://monetize.xandr.com/privacy-center/metric-calculations">Xandr even publishes these internal statistics</a> on a hidden website for everyone to see. The complainant has experienced this approach first hand: When he requested access to his data, Xandr claimed that it couldn’t identify him - and denied his request for access and erasure. In reality, the company has all the necessary information to single out specific data subjects. Identifying and targeting individuals is after all their core business.</p><p>Massimiliano Gelmi, data protection lawyer at <em>noyb</em>: <em>“Xandr’s business is obviously based on keeping data on millions of Europeans and targeting them. Still, the company admits that it has a 0% response rate to access and erasure requests. It is astonishing that Xandr even publicly illustrates how it breaches the GDPR.”</em></p></div><div><p><strong>(Un)targeted advertising.</strong> In addition, the GDPR requires data about individuals to be 'accurate'. However, the available information suggests that Xandr’s system uses tonnes of false information about users. Even from a business perspective, Xandr seems to make a mockery of the idea of targeted advertising. Thanks to an access request with the data broker – and Xandr supplier – emetriq, we know that at least part of Xandr’s database consists of wildly inaccurate and contradictory personal data about people: According to emetriq, the complainant is both male and female, has an estimated age between 16-19, 20-29, 30-39, 40-49, 50-59 and 60+. The complainant also has an income between €500 - €1,500, €1,500 - €2,500 and €2,500 - €4,000. Furthermore, the same person is looking for a job, is employed, a student, a pupil and works in a company. That company, in turn, employs 1-10, 1,000+ and 1,100-5,000 people at the same time. It is hard to imagine how these data categories can be used for accurate ad targeting. Although emetriq isn’t the only data broker supplying data to Xandr, it has to be assumed that this information is used for ad targeting.&nbsp;</p><p>Massimiliano Gelmi, data protection lawyer at <em>noyb</em>: <em>“It seems that parts of the advertising industry don’t really care about providing advertisers with accurate information. Instead, the data set contains a chaotic variety of conflicting information. This can potentially benefit companies like Xandr as they can sell the same user as young and old to different business partners.”</em></p><p><strong>Complaint filed in Italy. </strong><em>noyb</em> has now filed a GDPR complaint with the Italian data protection authority (Garante) regarding transparency issues, the right of access and the use of inaccurate information about users. Overall, Xandr appears to be in breach of Article 5(1)(c) and (d), Article 12(2), Article 15 and Article 17 of the GDPR. We therefore ask the authority to investigate Xandr’s processing operations and to order the company to comply with the complainant’s request for access and erasure. With respect to all affected data subjects, we also suggest that the Garante orders Xandr to bring its processing operations in line with the principles of data minimisation and accuracy. Finally, we suggest that the competent authority impose an effective, proportionate and dissuasive administrative fine of up to 4% of Xandr’s annual turnover.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[End-to-end congestion control cannot avoid latency spikes (2022) (112 pts)]]></title>
            <link>https://blog.apnic.net/2022/01/26/beyond-bufferbloat-end-to-end-congestion-control-cannot-avoid-latency-spikes/</link>
            <guid>40913793</guid>
            <pubDate>Tue, 09 Jul 2024 08:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.apnic.net/2022/01/26/beyond-bufferbloat-end-to-end-congestion-control-cannot-avoid-latency-spikes/">https://blog.apnic.net/2022/01/26/beyond-bufferbloat-end-to-end-congestion-control-cannot-avoid-latency-spikes/</a>, See on <a href="https://news.ycombinator.com/item?id=40913793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-content">
                            <p><img width="555" height="202" src="https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-555x202.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a" alt="" decoding="async" fetchpriority="high" srcset="https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-555x202.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 555w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-300x109.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 300w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-1024x373.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 1024w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-768x280.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 768w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-624x227.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 624w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-206x75.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 206w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer-256x93.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 256w, https://blog.apnic.net/wp-content/uploads/2021/12/beyond-buffer.jpg?v=282d32e402d01c56dc38869b6aab81ce82b179233d8d3b5370320abf8c65b87a 1110w" sizes="(max-width: 555px) 100vw, 555px"></p><p>End-to-end congestion control methods, such as TCP and QUIC, are the main ways of avoiding congestion on the Internet, and much research has gone into improving the latency performance of TCP. In a <a href="https://arxiv.org/abs/2111.00488" target="_blank" rel="noreferrer noopener">recent paper</a>, we at Domos, describe a fundamental limitation of these methods — they cannot avoid latency spikes.</p>



<p>Our paper addresses an awkward problem that is obvious to a part of the community (hello control theory people), but which many researchers and engineers frequently either ignore or overlook. The initial motivation for the work was a recent workshop at the Internet Architecture Board (IAB). During the workshop, a common misunderstanding (even among experts in the field) became apparent — that end-to-end congestion control can deliver reliable low latency <em>if we just tune it correctly</em>.</p>



<p>That is not true for networks where link capacity can change rapidly, such as Wi-Fi and 5G.</p>



<p>Two recent survey papers (<a href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1514537&amp;dswid=-5289" target="_blank" rel="noreferrer noopener">Survey 1</a> and <a href="https://www.semanticscholar.org/paper/A-Comprehensive-Overview-of-TCP-Congestion-Control-Lorincz-Klarin/e2f731a675afd6a14cfeb1dde1f602b12394d7b1" target="_blank" rel="noreferrer noopener">Survey 2</a>) both state that large variations in capacity are one of the main problems for congestion control in 5G networks. Yet, there are no references to fundamental limitations in either survey.</p>



<h2>TCP, bufferbloat, and the promise of a responsive Internet</h2>



<p>Bufferbloat has been identified as a common source of latency on the Internet. <a href="https://queue.acm.org/detail.cfm?id=2209336" target="_blank" rel="noreferrer noopener">Nichols and Van Jacobson</a> describe Bufferbloat as ‘unnecessary queuing’. Bufferbloat is caused by poor congestion signalling leading to a ‘standing queue’ at bottleneck interfaces.&nbsp;</p>



<p>A standing queue adds latency without improving throughput and is therefore just wasting everyone’s time. Lots of progress has been made on reducing bufferbloat in the Internet, perhaps most notably by Dave Taht, Toke Høiland-Jørgensen, Jim Gettys, and Kathleen Nichols. In the latest iOS release, there is a tool called RPM, which is designed to measure and detect bufferbloat, and <a href="https://www.bufferbloat.net/projects/bloat/wiki/Tests_for_Bufferbloat/" target="_blank" rel="noreferrer noopener">browser tools</a> exist as well.</p>



<p>Removing unnecessary queuing is a win-win. However, to get close to the ideal speed-of-light Internet, removing standing queues is not enough. Transient queues, often called ‘good queues’ because they help improve link utilization, can be large enough to contribute significantly to performance problems.</p>



<figure><img decoding="async" width="640" height="480" src="https://blog.apnic.net/wp-content/uploads/2021/12/Figure-1-%E2%80%94-Perfect-operation-at-saturation.-The-ACKs-%E2%80%98clock-the-sender-to-perfectly-fill-the-bottleneck-link-to-100-capacity..gif" alt="Figure 1 — Perfect operation at saturation. The ACKs ‘clock’ the sender to perfectly fill the bottleneck link to 100% capacity."><figcaption>Figure 1 — Perfect operation at saturation. The ACKs ‘clock’ the sender to perfectly fill the bottleneck link to 100% capacity.</figcaption></figure>



<figure><img decoding="async" width="640" height="480" src="https://blog.apnic.net/wp-content/uploads/2021/12/Figure-2-%E2%80%94-What-happens-when-capacity-drops..gif" alt="Figure 2 — What happens when capacity drops. The green ACKs mark the first congestion signal seen by the sender. Notice that the queue is already formed by the time the sender knows about the congestion."><figcaption>Figure 2 — What happens when capacity drops. The green ACKs mark the first congestion signal seen by the sender. Notice that the queue is already formed by the time the sender knows about the congestion.</figcaption></figure>



<h2>How good is TCP latency under perfect conditions?</h2>



<p>In the paper, we model the best possible case for an end-to-end congestion controller and work out how much latency we’d see on the bottleneck link if its capacity is suddenly reduced. The mathematics is simple, and we can compute the peak latency using the factor of capacity change (1/r) and how much time it takes to send a signal from the point of congestion to the traffic source (d). ‘d’ depends on the speed of light. One trip around the earth at the speed of light takes 133 milliseconds, so the speed of light is significant in these calculations. As we can see in Figure 3, the queuing latency can grow to several hundred milliseconds for values of C and d that are not uncommon on the Internet.</p>



<div><figure><a href="https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss..png"><img loading="lazy" decoding="async" width="1024" height="632" src="https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss.-1024x632.png" alt="" srcset="https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss.-1024x632.png 1024w, https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss.-300x185.png 300w, https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss.-768x474.png 768w, https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss.-624x385.png 624w, https://blog.apnic.net/wp-content/uploads/2022/01/Figure-3-%E2%80%94Minimum-queuing-delay-with-end-to-end-congestion-control-and-no-packet-loss..png 1046w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Figure 3 — Minimum queuing delay with end-to-end congestion control and no packet loss.</figcaption></figure></div>



<p>A key point is that this is the theoretical optimum for any and all end-to-end congestion control algorithms. The results are valid for all versions of TCP, QUIC, adaptive bitrate streaming methods, and all other end-to-end congestion control schemes you can possibly think of. Congestion signalling methods cannot work around this problem either, so our analysis is also valid for Explicit Congestion Notification methods such as Low Latency Low Loss Scalable Throughput (L4S).</p>



<h2>How can latency spikes be avoided?</h2>



<p>We have concluded that end-to-end congestion control alone is not enough to provide the reliable low-latency Internet that 5G marketers have promised us. What are our other options?</p>



<p>We have come up with a list of solutions that can help us out in different scenarios:</p>



<ol type="1"><li>See the future. If a congestion controller can react <strong>before</strong> capacity is reduced, then peak delays are smaller (this is equivalent to reducing d). This might be possible for cases where capacity drops are a result of things moving around.</li><li>Underutilize the link. If we use the link at 10% capacity, then a capacity drop to 1/10th is not noticed. This is a good solution if the bandwidth is cheap enough, but it is expensive to build networks that are 10 times as big as they need to be!</li><li>Treat traffic differently. This is like underutilization, but smarter. The idea is to underutilize the link, but only for traffic that is latency sensitive. Never fill more than 1/10th or 1/20th of the capacity with time-sensitive traffic, and suddenly you can handle large capacity drops. The rest of the link can be filled with traffic that is not as latency sensitive. The caveat is that when the capacity drops, the latency-sensitive traffic must be given priority on the link until capacity bounces back up. If this is handled <strong>at the point of congestion</strong>, then we can have the best of both worlds.</li><li>Link diversification. If the same traffic is sent over more than one link, then the end-to-end connection can be made much more reliable because the chance of both links reducing capacity at the same time is small (assuming they are not correlated!).</li></ol>



<p>I will leave you with a question: Are we trying to make end-to-end congestion control work for cases where it can’t possibly work? If so, then accepting the limitation we describe here is a necessary step towards making the reliable low-latency Internet a reality.</p>



<p><em>Bjørn Ivar Teigen is Head of Research at Domos, and a PhD candidate at the University of Oslo. His research interests are in queuing theory, distributed systems, and Machine Learning with applications in modelling and optimizing real-world networks.</em></p>

                            <!-- DISCUSS ON HN BUTTON: START -->
                            
                                                        <hr>

                            <p id="views-disclaimer">The views expressed by the authors of this blog are their own
                                and do not necessarily reflect the views of APNIC. Please note a <a href="https://blog.apnic.net/?p=395">Code of Conduct</a> applies to this blog.
                            </p>
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Crawlee for Python – a web scraping and browser automation library (207 pts)]]></title>
            <link>https://crawlee.dev/python/</link>
            <guid>40913736</guid>
            <pubDate>Tue, 09 Jul 2024 08:30:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crawlee.dev/python/">https://crawlee.dev/python/</a>, See on <a href="https://news.ycombinator.com/item?id=40913736">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__docusaurus_skipToContent_fallback"><div><h2>Reliable crawling 🏗️</h2><p>Crawlee won't fix broken selectors for you (yet), but it helps you <b>build and maintain your crawlers faster</b>.</p><p>When a website adds <a href="https://crawlee.dev/docs/guides/javascript-rendering">JavaScript rendering</a>, you don't have to rewrite everything, only switch to one of the browser crawlers. When you later find a great API to speed up your crawls, flip the switch back.</p><p>Crawlee is built by people who scrape for a living and use it every day to scrape millions of pages.<a href="https://discord.com/invite/jyEM2PRvMU" target="_blank" rel="noreferrer"><b> Meet our community on Discord</b></a>.</p></div><section><svg xmlns="http://www.w3.org/2000/svg" width="0" height="0" viewBox="0 0 0 0" fill="none"><defs><linearGradient id="gradient-1" x1="26.6667" y1="12" x2="14.2802" y2="34.5208" gradientUnits="userSpaceOnUse"><stop offset="0%" stop-color="#9dceff"></stop><stop offset="70%" stop-color="#4584b6"></stop><stop offset="100%" stop-color="#4584b6"></stop></linearGradient><linearGradient id="gradient-2" x1="29.6667" y1="0" x2="-1.80874" y2="26.2295" gradientUnits="userSpaceOnUse"><stop offset="0%" stop-color="#4584b6"></stop></linearGradient></defs></svg><div><div><h3>Python with type hints</h3><p>Crawlee for Python is written in a modern way using type hints, providing code completion in your IDE and helping you catch bugs early on build time.</p></div><div><h3>Headless browsers</h3><p>Switch your crawlers from HTTP to <a href="https://crawlee.dev/python/api/class/BeautifulSoupCrawler">headless browsers</a> in 3 lines of code. Crawlee builds on top of <b>Playwright</b> and adds its own <b>anti-blocking features and human-like fingerprints</b>. Chrome, Firefox and more.</p></div></div></section><div><h2>Try Crawlee out 👾</h2><p>The fastest way to try Crawlee out is to use the <b>Crawlee CLI</b> and choose one of the provided templates. The CLI will install all the necessary dependencies and add boilerplate code for you to play with.</p><div><pre tabindex="0"><code><span><span>pipx run crawlee create my-crawler</span><br></span></code></pre></div><p>If you prefer adding Crawlee <b>into your own project</b>, try the example below. Because it uses <code>PlaywrightCrawler</code> we also need to install Playwright. It's not bundled with Crawlee to reduce install size.</p><div><pre tabindex="0"><code><span><span>pip </span><span>install</span><span> </span><span>'crawlee[playwright]'</span><br></span></code></pre></div><div><pre tabindex="0"><code><span><span>import</span><span> asyncio</span><br></span><span><span></span><br></span><span><span></span><span>from</span><span> crawlee</span><span>.</span><span>playwright_crawler </span><span>import</span><span> PlaywrightCrawler</span><span>,</span><span> PlaywrightCrawlingContext</span><br></span><span><span></span><br></span><span><span></span><br></span><span><span></span><span>async</span><span> </span><span>def</span><span> </span><span>main</span><span>(</span><span>)</span><span> </span><span>-</span><span>&gt;</span><span> </span><span>None</span><span>:</span><span></span><br></span><span><span>    </span><span># Create a crawler instance and provide a request provider (and other optional arguments)</span><span></span><br></span><span><span>    crawler </span><span>=</span><span> PlaywrightCrawler</span><span>(</span><span></span><br></span><span><span>        max_requests_per_crawl</span><span>=</span><span>50</span><span>,</span><span> </span><span># scrape only first 50 pages</span><span></span><br></span><span><span>        </span><span># headless=False,</span><span></span><br></span><span><span>        </span><span># browser_type='firefox',</span><span></span><br></span><span><span>    </span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span>@crawler</span><span>.</span><span>router</span><span>.</span><span>default_handler</span><span></span><br></span><span><span>    </span><span>async</span><span> </span><span>def</span><span> </span><span>request_handler</span><span>(</span><span>context</span><span>:</span><span> PlaywrightCrawlingContext</span><span>)</span><span> </span><span>-</span><span>&gt;</span><span> </span><span>None</span><span>:</span><span></span><br></span><span><span>        data </span><span>=</span><span> </span><span>{</span><span></span><br></span><span><span>            </span><span>'request_url'</span><span>:</span><span> context</span><span>.</span><span>request</span><span>.</span><span>url</span><span>,</span><span></span><br></span><span><span>            </span><span>'page_url'</span><span>:</span><span> context</span><span>.</span><span>page</span><span>.</span><span>url</span><span>,</span><span></span><br></span><span><span>            </span><span>'page_title'</span><span>:</span><span> </span><span>await</span><span> context</span><span>.</span><span>page</span><span>.</span><span>title</span><span>(</span><span>)</span><span>,</span><span></span><br></span><span><span>            </span><span>'page_content'</span><span>:</span><span> </span><span>(</span><span>await</span><span> context</span><span>.</span><span>page</span><span>.</span><span>content</span><span>(</span><span>)</span><span>)</span><span>[</span><span>:</span><span>10000</span><span>]</span><span>,</span><span></span><br></span><span><span>        </span><span>}</span><span></span><br></span><span><span>        </span><span>await</span><span> context</span><span>.</span><span>push_data</span><span>(</span><span>data</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span>await</span><span> crawler</span><span>.</span><span>run</span><span>(</span><span>[</span><span>'https://crawlee.dev'</span><span>]</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span># Export the whole dataset to a single file in `./result.csv`.</span><span></span><br></span><span><span>    </span><span>await</span><span> crawler</span><span>.</span><span>export_data</span><span>(</span><span>'./result.csv'</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span>    </span><span># Or work with the data directly.</span><span></span><br></span><span><span>    data </span><span>=</span><span> </span><span>await</span><span> crawler</span><span>.</span><span>get_data</span><span>(</span><span>)</span><span></span><br></span><span><span>    </span><span>print</span><span>(</span><span>data</span><span>.</span><span>items</span><span>)</span><span></span><br></span><span><span></span><br></span><span><span></span><br></span><span><span></span><span>if</span><span> __name__ </span><span>==</span><span> </span><span>'__main__'</span><span>:</span><span></span><br></span><span><span>    </span><span># Add first URL to the queue and start the crawl.</span><span></span><br></span><span><span>    asyncio</span><span>.</span><span>run</span><span>(</span><span>main</span><span>(</span><span>)</span><span>)</span><br></span></code></pre></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Tegon: Open-source alternative to Jira, Linear (128 pts)]]></title>
            <link>https://github.com/tegonhq/tegon</link>
            <guid>40912920</guid>
            <pubDate>Tue, 09 Jul 2024 06:01:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tegonhq/tegon">https://github.com/tegonhq/tegon</a>, See on <a href="https://news.ycombinator.com/item?id=40912920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a href="https://tegon.ai/" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/17528887/300198942-07036ee1-774d-4dff-a56b-8050041f36ce.svg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA1NTczMDEsIm5iZiI6MTcyMDU1NzAwMSwicGF0aCI6Ii8xNzUyODg4Ny8zMDAxOTg5NDItMDcwMzZlZTEtNzc0ZC00ZGZmLWE1NmItODA1MDA0MWYzNmNlLnN2Zz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzA5VDIwMzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWEyOWUwZWM3MzJhYmNkNzBkOTllMDk3OGU1NzNkMjljNTc0N2Y1NTU3NzY0YTBjZjM0NzdjNjljZjU4MmVhYjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.wSLzg0Z7B2f8HQpdtLMqWlFKA0nP-5-U3MTSdZJ7oEc" width="200" height="100" secured-asset-link=""></a>
</p>

<p dir="auto">
 <a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/36505468/341765928-888ebcaa-29fb-4f33-833f-9652bdd37711.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA1NTczMDEsIm5iZiI6MTcyMDU1NzAwMSwicGF0aCI6Ii8zNjUwNTQ2OC8zNDE3NjU5MjgtODg4ZWJjYWEtMjlmYi00ZjMzLTgzM2YtOTY1MmJkZDM3NzExLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzA5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcwOVQyMDMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOTEwMjEwYTRlNzJkODg5ZThiMDdlODBhYTk4OGIwZmFkMGFjYWZkNjViYjMxMmM0ZmIzOWZhZDc0N2NmMTY1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.t1sX12dwEDFdzm-5CbelkumakicTZlrpnExpR6LY_C0"><img src="https://private-user-images.githubusercontent.com/36505468/341765928-888ebcaa-29fb-4f33-833f-9652bdd37711.jpeg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjA1NTczMDEsIm5iZiI6MTcyMDU1NzAwMSwicGF0aCI6Ii8zNjUwNTQ2OC8zNDE3NjU5MjgtODg4ZWJjYWEtMjlmYi00ZjMzLTgzM2YtOTY1MmJkZDM3NzExLmpwZWc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzA5JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcwOVQyMDMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0xOTEwMjEwYTRlNzJkODg5ZThiMDdlODBhYTk4OGIwZmFkMGFjYWZkNjViYjMxMmM0ZmIzOWZhZDc0N2NmMTY1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.t1sX12dwEDFdzm-5CbelkumakicTZlrpnExpR6LY_C0"></a>
</p>
<p dir="auto">
    <em> Tegon is AI-First Issue Tracking tool for engineering teams
</em>
</p>
<p dir="auto"><a href="https://tegon.ai/" rel="nofollow">Tegon</a> is an AI-first, open-source issue tracking software that uses AI to smartly automate manual task, workflows or provide more context to engineers for a given task.</p>
<p dir="auto">Issue Tracking is important for fast-paced teams, enabling them to organize list of tasks, collaborate, and track progress effectively. However, existing tools often introduce the following challenges:</p>
<ul dir="auto">
<li>Manual efforts in task management, such as task triaging and backlog maintenance, can be time-consuming.</li>
<li>Engineers often waste time navigating multiple platforms to gather task context, rather than accessing details within the task itself.</li>
<li>Issue tracking tools serve as a task database, directing engineers on what to work on but not aiding in faster task completion.</li>
<li>Existing tools don't effectively assist Engineering Managers in real-time task, feature, or bug prioritisation.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo Video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo Video" href="#demo-video"></a></p>
<p dir="auto"><a href="https://www.loom.com/share/b664b01e9b064a02be5791c12b77a107?sid=d4146365-1597-4ff5-88fd-a07b08ddb9f4" rel="nofollow">https://www.loom.com/share/b664b01e9b064a02be5791c12b77a107?sid=d4146365-1597-4ff5-88fd-a07b08ddb9f4</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto">Go to <a href="https://demo.tegon.ai/" rel="nofollow">demo.tegon.ai</a> and login with the following credentials</p>
<div data-snippet-clipboard-copy-content="email: elon@xyz.com
password: XfFNw6GwVJVQv6PA"><pre><code>email: elon@xyz.com
password: XfFNw6GwVJVQv6PA
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Self Hosted</h2><a id="user-content-self-hosted" aria-label="Permalink: Self Hosted" href="#self-hosted"></a></p>
<p dir="auto">To self-host Tegon on your own machine, you can do so using Docker. However note that you will need to add configurations for email, AI and storage services. Please refer to the documentation <a href="https://docs.tegon.ai/oss/deploy-tegon" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tegon Cloud</h2><a id="user-content-tegon-cloud" aria-label="Permalink: Tegon Cloud" href="#tegon-cloud"></a></p>
<p dir="auto">We offer a managed cloud version of Tegon that allows you to run Tegon without having to manage the infrastructure. It is currently in private beta.
If you're interested in using Tegon Cloud, please book a <a href="https://calendly.com/manik-tegon/30min" rel="nofollow">demo call</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Issues Tracking:</strong>
<ul dir="auto">
<li>Interactive Layout - Choose between List or Kanban views.</li>
<li>Focus on What Matters - Easily update key details and highlight critical dependencies (sub-tasks, blocked/blocking issues).</li>
<li>List View - Perfect for scanning prioritized issues, grouped by status. Collapse sections for focus.</li>
<li>Kanban View - Visualize workflow with Kanban boards, ideal for tracking progress at a glance.</li>
</ul>
</li>
<li><strong>AI-powered Suggestions:</strong> Automatically suggests titles, labels, assignees, and even identifies duplicate issues while you create new ones.</li>
<li><strong>AI Summarization:</strong> Uses AI to generate concise summaries of issue activity, keeping you focused.</li>
<li><strong>Natural Language Filtering:</strong> Filter issues with ease by simply typing in plain text.</li>
<li><strong>Automated Triaging:</strong> AI saves time by automatically categorizing issues coming in triage</li>
<li><strong>Centralised Triage:</strong>
<ul dir="auto">
<li>Unified Inbox - Capture issues from all sources (sales, support, monitoring tools) in a single queue.</li>
<li>Slack Integration - Create issues directly from Slack, empowering non-technical users.</li>
<li>Automatic Routing - Errors detected by tools (e.g., Sentry) automatically flow into triage for prioritization.</li>
</ul>
</li>
<li>Custom Views</li>
<li>Sprints (coming soon)</li>
<li>Task Prioritisation (coming soon)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Integrations</h2><a id="user-content-integrations" aria-label="Permalink: Integrations" href="#integrations"></a></p>
<ul dir="auto">
<li>Github: Automatically update issues status based on commits and pull requests and link mentions of issues back to Tegon</li>
<li>Slack:
<ul dir="auto">
<li>Mention the Tegon bot in a Slack channel to automatically create a bug or feature request.</li>
<li>Link a Slack thread to an issue to provide full context about the discussions happening on a specific task or a feature request.</li>
</ul>
</li>
<li>Sentry: Get information about Sentry errors in Tegon issues</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Whether it's big or small, we love contributions. Not sure where to get started?
You can join our <a href="https://join.slack.com/t/tegoncommunity/shared_invite/zt-2jvar8p1x-9wqFTL9PP5ICImb76qcjEA" rel="nofollow">Slack</a>, and ask us any questions there.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The product is under the <a href="https://github.com/tegonhq/tegon/blob/main/LICENSE.md">MIT License</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The zombie misconception of theoretical computer science (217 pts)]]></title>
            <link>https://scottaaronson.blog/?p=8106</link>
            <guid>40912684</guid>
            <pubDate>Tue, 09 Jul 2024 05:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottaaronson.blog/?p=8106">https://scottaaronson.blog/?p=8106</a>, See on <a href="https://news.ycombinator.com/item?id=40912684">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-8106">
				
<p>In Michael Sipser’s <a href="https://www.amazon.com/Introduction-Theory-Computation-Michael-Sipser/dp/113318779X"><em>Introduction to the Theory of Computation</em> textbook</a>, he has one Platonically perfect homework exercise, so perfect that I can reconstruct it from memory despite not having opened the book for over a decade.  It goes like this:</p>



<ul>
<li>Let f:{0,1}*→{0,1} be the constant 1 function if God exists, or the constant 0 function if God does not exist. Is f computable? (<em>Hint:</em> The answer does not depend on your religious beliefs.)</li>
</ul>



<p>The correct answer is that yes, f is computable.  Why?  Because the constant 1 function is computable, and so is the constant 0 function, so if f is one or the other, then it’s computable.</p>



<p>If you’re still tempted to quibble, then consider the following parallel question:</p>



<ul>
<li>Let n equal 3 if God exists, or 5 if God does not exist.  Is n prime?</li>
</ul>



<p>The answer is again yes: even though n hasn’t been completely mathematically specified, it’s been specified <em>enough</em> for us to say that it’s prime (just like if we’d said, “n is an element of the set {3,5}; is n prime?”).  Similarly, f has been specified enough for us to say that it’s computable.</p>



<p>The deeper lesson Sipser was trying to impart is that the concept of <a href="https://en.wikipedia.org/wiki/Computable_function">computability</a> applies to <em>functions</em> or <em>infinite sequences</em>, not to individual yes-or-no questions or individual integers.  Relatedly, and even more to the point: computability is about whether a computer program <em>exists</em> to map inputs to outputs in a specified way; it says nothing about how hard it might be to <em>choose</em> or <em>find</em> or <em>write</em> that program.  Writing the program could even require settling God’s existence, for all the definition of computability cares.</p>



<hr>



<p>Dozens of times in the past 25 years, I’ve gotten some variant on the following question, always with the air that I’m about to bowled over by its brilliance:</p>



<ul>
<li>Could the P versus NP question <em>itself</em> be NP-hard, and therefore impossible to solve?</li>
</ul>



<p>Every time I get this one, I struggle to unpack the layers of misconceptions.  But for starters: the concept of <a href="https://en.wikipedia.org/wiki/NP-hardness">“NP-hard”</a> applies to <em>functions</em> or <em>languages</em>, like 3SAT or Independent Set or Clique or whatnot, all of which <em>take an input</em> (a Boolean formula, a graph, etc) and produce a corresponding output.  NP-hardness means that, if you had a polynomial-time algorithm to map the inputs to the outputs, then you could convert it via reductions into a polynomial-time algorithm for any language or function in the class NP.</p>



<p><a href="https://www.scottaaronson.com/papers/pnp.pdf">P versus NP</a>, by contrast, is an individual yes-or-no question.  Its answer (for all we know) could be independent of the <a href="https://en.wikipedia.org/wiki/Zermelo%E2%80%93Fraenkel_set_theory">Zermelo-Fraenkel axioms</a> of set theory, but there’s no sense in which the question could be uncomputable or NP-hard.  Indeed, a fast program that correctly answers the P vs. NP question trivially exists:</p>



<ul>
<li>If P=NP, then the program prints “P=NP.”</li>



<li>If P≠NP, then the program prints “P≠NP.”</li>
</ul>



<hr>



<p>In the comments of <a href="https://scottaaronson.blog/?p=8088">last week’s post</a> on the breakthrough determination of Busy Beaver 5, I got several variants on the following question:</p>



<ul>
<li>What’s the smallest n for which the value of BB(n) is uncomputable?  Could BB(6) already be uncomputable?</li>
</ul>



<p>Once again, I explained that the Busy Beaver <em>function</em> is uncomputable, but the concept of computability doesn’t apply to individual integers like BB(6).  Indeed, whichever integer k turns out to equal BB(6), the program “print k” clearly exists, and it clearly outputs that integer!</p>



<p>Again, we can ask for the smallest n such that the value of BB(n) is <em>unprovable in ZF set theory</em> (or some other system of axioms)—precisely the question that Adam Yedidia and I <a href="https://arxiv.org/abs/1605.04343">did ask in 2016</a> (the current record stands at n=745, improving my and Adam’s n=8000).  But <em>every</em> specific integer is “computable”; it’s only the BB function <em>as a whole</em> that’s uncomputable.</p>



<p>Alas, in return for explaining this, I got more pushback, and even ridicule and abuse that I chose to leave in the moderation queue.</p>



<hr>



<p>So, I’ve come to think of this as the Zombie Misconception of Theoretical Computer Science: this constant misapplication of concepts that were designed for infinite sequences and functions, to individual integers and open problems. (Or, relatedly: the constant conflation of the uncomputability of the halting problem with Gödel incompleteness.  While they’re closely related, only Gödel lets you talk about <em>individual</em> statements rather than infinite families of statements, and only Turing-computability is absolute, rather than relative to a system of axioms.)</p>



<p>Anyway, I’m writing this post mostly just so that I have a place to link the <em>next</em> time this pedagogical zombie rises from its grave, muttering “UNCOMPUTABLE INTEGERRRRRRS….”  But also so I can query my readers: what are <em>your</em> ideas for how to keep this zombie down?</p>

		
				
				<p>
					<small>
						This entry was posted
												on Monday, July 8th, 2024 at 3:07 pm						and is filed under <a href="https://scottaaronson.blog/?cat=5" rel="category">Complexity</a>.
						You can follow any responses to this entry through the <a href="https://scottaaronson.blog/?feed=rss2&amp;p=8106">RSS 2.0</a> feed.

													You can <a href="#respond">leave a response</a>, or <a href="https://scottaaronson.blog/wp-trackback.php?p=8106" rel="trackback">trackback</a> from your own site.

						
					</small>
				</p>

			</div><p>You can use rich HTML in comments!  You can also use basic TeX, by enclosing it within <span>$$ $$</span> for displayed equations or <span>\( \)</span> for inline equations.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly 2M metric tons of wild fish used to feed Norwegian farmed salmon (146 pts)]]></title>
            <link>https://www.seafoodsource.com/news/aquaculture/report-nearly-2-million-metric-tons-of-wild-fish-used-to-feed-norwegian-farmed-salmon-annually</link>
            <guid>40912650</guid>
            <pubDate>Tue, 09 Jul 2024 04:56:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seafoodsource.com/news/aquaculture/report-nearly-2-million-metric-tons-of-wild-fish-used-to-feed-norwegian-farmed-salmon-annually">https://www.seafoodsource.com/news/aquaculture/report-nearly-2-million-metric-tons-of-wild-fish-used-to-feed-norwegian-farmed-salmon-annually</a>, See on <a href="https://news.ycombinator.com/item?id=40912650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span lang="EN-GB">Nearly 2 million metric tons of wild fish are harvested from the ocean to feed Norwegian farmed salmon every year, according to a report from U.K.- and Netherlands-based environmental campaign group Feedback, as well as a coalition of West African and Norwegian organizations.<o:p></o:p></span></p><p><span lang="EN-GB">According to </span><a href="http://feedbackglobal.org/blue-empire"><span lang="EN-GB">"Blue Empire: How the Norwegian salmon industry extracts nutrition and undermines livelihoods in West Africa,"</span></a><span lang="EN-GB"> these wild fish are used to produce fish oil for salmon feed, which is contributing to the loss of livelihoods and malnutrition in the West African countries of The Gambia, Senegal, and Mauritania.&nbsp;<o:p></o:p></span></p><p><span lang="EN-GB">“Along the West African coast, small-scale fishing is the only means of subsistence for Indigenous communities,” </span><span lang="FR">Regional Network of Marine Protected Areas in West Africa (</span><span lang="EN-GB">RAMPAO</span><span lang="FR">) Executive Secretary </span><span lang="EN-GB">Marie Suzanna Traore</span><span lang="EN-GB"> </span><span lang="FR">said. </span><span lang="EN-GB">”The big boats that supply the fishmeal and fish oil industry with fish caught in African waters <span>–</span> to the detriment of these communities <span>–</span> undermine their human dignity.”</span><o:p></o:p></p><p><span lang="EN-GB">In the report, Feedback calculated that the Norwegian salmon farming industry’s "feed footprint" is equivalent to 2.5 percent of global marine fisheries catch. The report also estimated that Norway’s annual output of farmed salmon is 27 percent lower than the volume of wild fish required to produce the fish oil used in Norwegian farmed salmon feed. The Norwegian industry’s plan to more than triple farmed salmon production to 5 million metric tons by 2050 would create demand for over three times as much wild-caught fish compared to 2020.<span> <o:p></o:p></span></span></p><p><span><span lang="EN-GB">“While salmon companies claim their ‘blue revolution’ will contribute to global food security by feeding the world, the rapid expansion of industrial aquaculture is fueling a modern-day colonialism <span>–</span> or food imperialism,” Feedback Campaigns Director Natasha Hurley said. “Despite mounting hunger and malnutrition in West African countries, corporate sustainability initiatives are failing to protect West African communities from hunger and malnutrition linked to the voracious appetite of the salmon-farming industry for wild fish.”</span><span><o:p></o:p></span></span></p><p><span lang="EN-GB">Feedback estimated that <span>fish sourced from West African fishing grounds to </span>supply fish oil to the Norwegian salmon farming industry in 2020 could have provided up to 4 million people in the region with a year’s supply of fish.<o:p></o:p></span></p><p><span lang="EN-GB">Four of the industry’s biggest feed producers <span>–</span> Mowi, Skretting, Cargill, and Biomar <span>–</span> supply most of the feed used in Norwegian salmon farming, and each sources fish oil from northwest Africa. </span></p><p><span lang="EN-GB">One-quarter of the total volume of fish oil sourced from West Africa by Norwegian companies was purchased by Mowi in 2020, including 5,100 MT of fish oil from Mauritania in 2020, which Feedback calculates was produced from 28,300 MT of fish. Another 17,000 MT of fish oil were sourced by Skretting, Cargill, and BioMar from&nbsp;</span>the major fishing area located off the west coast of Africa known as FAO 34<span lang="EN-GB">. <o:p></o:p></span></p><p><span lang="EN-GB">In Mauritania, round sardinella catches dropped by 66 percent between 2020 and 2021, while in Senegal, they dropped by 86 percent and in Gambia by 16 percent over the same period, according to Sub-Regional Fisheries Commission Techincal Advisor Mika Samba Diop.<o:p></o:p></span></p><p><span lang="EN-GB">“Unfair competition from fishmeal factories, which offer more money for catches, has resulted in many women who process small pelagic fish losing their jobs,” Diop said. “The overexploitation of fish stocks has led to a drastic reduction in small-scale fishers’ incomes and local fish consumption of fish. For example, in The Gambia, annual per capita consumption of fish has gone from 15 kilograms in 2020 to only 8 kilogarms in 2021.”<o:p></o:p></span></p><p><span lang="EN-GB">As part of the campaign, Feedback and fellow environmental NGO WildFish is calling for British restaurant chain Wagamama to stop serving farmed salmon.The chain, which has nearly 200 U.K. locations, currently features three dishes featuring farmed salmon.</span></p><p><span lang="EN-GB">"The campaign was launched after Wagamama failed to respond to several letters from NGOs asking for clarification on its farmed salmon sourcing standards," Feedback Campaigner Liam Lysaght said in a press release. "</span><span lang="EN-GB">As a restaurant which markets itself as a sustainability leader, Wagamama’s response may set a precedent for the place of farmed salmon on hospitality menus.</span></p><p><i>Photo courtesy of Evannovostro/Shutterstock<o:p></o:p></i></p></div></div>]]></description>
        </item>
    </channel>
</rss>