<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 22 Oct 2023 01:00:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Reddit mods dumped tokens hours before blockchain program termination (213 pts)]]></title>
            <link>https://cointelegraph.com/news/reddit-mods-dumped-tokens-hours-before-blockchain-program-termination</link>
            <guid>37969387</guid>
            <pubDate>Sat, 21 Oct 2023 18:38:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cointelegraph.com/news/reddit-mods-dumped-tokens-hours-before-blockchain-program-termination">https://cointelegraph.com/news/reddit-mods-dumped-tokens-hours-before-blockchain-program-termination</a>, See on <a href="https://news.ycombinator.com/item?id=37969387">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gtm-locator="a1" data-v-3d3be88a=""><article id="article-118556" data-v-3d3be88a=""><p itemprop="description" data-v-3d3be88a=""> Analysis suggests at least three Reddit moderators dumped thousands of dollars worth of Moons just minutes before the actual announcement.  </p><div data-v-1b2c826e="" data-v-3d3be88a=""><p><span data-v-1b2c826e=""></span><span data-v-1b2c826e=""> 8617 </span><span data-v-1b2c826e=""> Total views </span></p><p><span data-v-1b2c826e=""> 648 </span><span data-v-1b2c826e=""> Total shares </span></p></div><div data-v-3d3be88a=""><picture><source media="(min-width: 1200px)" srcset="https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=717/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg, https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=1434/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg"><source media="(min-width: 992px)" srcset="https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=587/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg, https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=1174/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg"><source media="(min-width: 768px)" srcset="https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=638/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg, https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=1276/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg"><source media="(min-width: 480px)" srcset="https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=747/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg, https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=1494/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg"><img srcset="https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=480/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg, https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=960/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg" src="https://images.cointelegraph.com/cdn-cgi/image/format=auto,onerror=redirect,quality=90,width=1434/https://s3.cointelegraph.com/uploads/2023-10/8f74cc48-aa85-47c9-955d-ad9dc3ed33a3.jpg" alt="Reddit mods dumped tokens hours before blockchain program termination"></picture><!----></div><!----><!----><div data-v-3d3be88a=""><!----><div data-v-3d3be88a=""><p>Popular social network platform <a href="https://cointelegraph.com/news/reddit-shutters-blockchain-based-community-points" data-amp="https://cointelegraph-com.cdn.ampproject.org/c/s/cointelegraph.com/news/reddit-shutters-blockchain-based-community-points/amp">Reddit announced the winddown of its blockchain-based community points program</a> on Oct. 17, citing scalability issues. The announcement created controversy in the crypto community, with many calling it a rug-pull, as the price of the native token on different subreddits tanked after the news was revealed.&nbsp;</p><p>Each subreddit had its own native token. For example, the Moons (MOON) token was the native crypto asset of r/CryptoCurrency, while Bricks (BRICK) was for r/FortNiteBR. Users could spend these points on badges and exclusive items for their avatars. </p><p>At the time of the announcement, the moderators of most of the subreddits involved with the community points program claimed to be unaware of the decision. However, this is now being called into question as new on-chain data suggests that at least a couple of moderators holding Moons may have been linked to three wallets that dumped millions of the tokens shortly before the announcement.</p><p><strong><em>Related: </em></strong><a href="https://cointelegraph.com/news/reddit-community-tokens-soar-kraken-listing" data-amp="https://cointelegraph-com.cdn.ampproject.org/c/s/cointelegraph.com/news/reddit-community-tokens-soar-kraken-listing/amp"><strong><em>Reddit community tokens soar on Kraken listing</em></strong></a></p><p>On-chain analysts such as Pledditor were the first to draw attention to the actions of subreddit moderator u/Mcgillby. On-chain data reveals that this moderator transferred more than 100,000 MOON over two different transactions on the Arbitrum Nova blockchain, turning it into more than $23,000 in Ether (<a href="https://cointelegraph.com/ethereum-price">ETH</a>). The user subsequently deleted all earlier Reddit posts.</p><blockquote><div lang="en" dir="ltr"><p>.<a href="https://twitter.com/Reddit?ref_src=twsrc%5Etfw">@Reddit</a> admins told /r/CryptoCurrency moderators beforehand, and 3 moderators sold <a href="https://twitter.com/search?q=%24MOON&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$MOON</a> tokens on insider information<a href="https://twitter.com/search?q=%24MOON&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$MOON</a> price dropped -22% minutes before the announcement was posted</p><p>Here is a list of Reddit moderators acting on inside information BEFORE the announcement: <a href="https://t.co/xAh75hOVEa">pic.twitter.com/xAh75hOVEa</a></p></div>— Pledditor (@Pledditor) <a href="https://twitter.com/Pledditor/status/1714610041699930439?ref_src=twsrc%5Etfw">October 18, 2023</a></blockquote>

<p>In another incident, just 17 minutes before Reddit’s statement, moderator u/Rider_of_the_storm allegedly shifted 345,422 MOON, worth over $69,000 at the time, to an exchange address. The Reddit account in question has since been deactivated. According to Lookonchain, on-chain data showed that at least three of the administrators overseeing the cryptocurrency subreddit liquidated tokens some 20 to 30 minutes before the announcement went public. </p><blockquote><p lang="en" dir="ltr">1/ Three <a href="https://twitter.com/CCMOD_?ref_src=twsrc%5Etfw">@CCMOD_</a> moderators dumped <a href="https://twitter.com/search?q=%24MOON&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$MOON</a> in advance via <a href="https://twitter.com/hashtag/inside?src=hash&amp;ref_src=twsrc%5Etfw">#inside</a> information from <a href="https://twitter.com/Reddit?ref_src=twsrc%5Etfw">@Reddit</a> admins. <a href="https://t.co/ucrPkh6siX">pic.twitter.com/ucrPkh6siX</a></p>— Lookonchain (@lookonchain) <a href="https://twitter.com/lookonchain/status/1714851956995555816?ref_src=twsrc%5Etfw">October 19, 2023</a></blockquote>

<p>A statement from the Reddit moderators <a href="https://www.reddit.com/r/CryptoCurrency/comments/17a33ql/comment/k5ahcpu/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3" target="_blank" rel="noopener nofollow">clarified</a> that they received the notice about the termination of the community points program an hour prior, suggesting that the three moderators could have used the information to dump their token holdings.</p><p><strong><em>Magazine: </em></strong><a href="https://cointelegraph.com/magazine/blockchain-detectives-mt-gox-collapse-birth-chainalysis/"><strong><em>Blockchain detectives — Mt. Gox collapse saw birth of Chainalysis</em></strong></a></p><template data-name="subscription_form" data-type="law_decoded"></template>










</div><!----><!----><!----><!----><p><img alt="" src="https://zoa.cointelegraph.com/pixel?postId=118556&amp;regionId=1" data-v-3d3be88a=""></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Adtech surveillance and government surveillance are often the same (182 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/10/adtech-surveillance-and-government-surveillance-are-often-same-surveillance</link>
            <guid>37969248</guid>
            <pubDate>Sat, 21 Oct 2023 18:22:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/10/adtech-surveillance-and-government-surveillance-are-often-same-surveillance">https://www.eff.org/deeplinks/2023/10/adtech-surveillance-and-government-surveillance-are-often-same-surveillance</a>, See on <a href="https://news.ycombinator.com/item?id=37969248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><p><span>In the absence of comprehensive federal privacy </span><a href="https://www.eff.org/deeplinks/2019/06/effs-recommendations-consumer-data-privacy-laws"><span>legislation</span></a><span> in the United States, the </span><a href="https://www.eff.org/deeplinks/2019/01/guided-tour-data-facebook-uses-target-ads"><span>targeted</span></a> <a href="https://www.eff.org/wp/behind-the-one-way-mirror"><span>advertising</span></a> <a href="https://www.eff.org/deeplinks/2022/03/ban-online-behavioral-advertising"><span>industry</span></a><span>, fueled by personal information harvested from our cell phone applications, has run roughshod over our privacy. Worse, the boundaries between corporate surveillance and government surveillance are eroding. Unless your data is fully encrypted or stored locally by you, the government often can get it from a communications or computing company. <br></span></p>
<p><span>Traditionally, that required a court order. But increasingly, the government just buys it from data brokers who bought it from the adtech industry. <br></span></p>
<p><span>An investigation from the </span><a href="https://www.wsj.com/tech/cybersecurity/how-ads-on-your-phone-can-aid-government-surveillance-943bde04"><span>Wall Street Journal </span></a><span>identified a company called Near Intelligence that purchased data about individuals and their devices from brokers who usually sell to advertisers. The company had contracts with government contractors that passed this data along to federal military and intelligence agencies. The company says it purchased data on over a billion devices. The government, in turn, can buy access to geolocation data on all those devices, when generally they’d have to show probable cause and get a warrant to get that same data. <br></span></p>
<p><span>Many smartphone application developers, to make a quick buck, are all too eager to sell your data to the highest bidder–and that often includes the government. Courts should hold that the Fourth Amendment requires police to get a warrant before tracking a person this way, but unfortunately, this corporate-government surveillance partnership has mostly evaded judicial review. <br></span></p>
<p><span>With the click of a mouse, police can use such surveillance tools to see the devices of people who attended a protest, follow them home to where they sleep, and target them for more surveillance, harassment, and retribution. Police can also track people whose devices have been inside an immigration attorney’s office, a reproductive health clinic, or a mental health facility. Police could easily use this tool to watch a secret rendezvous between a journalist and their whistleblowing source. Not to mention that law enforcement officials have often</span><a href="https://slate.com/technology/2013/09/loveint-how-nsa-spies-snooped-on-girlfriends-lovers-and-first-dates.html"> <span>abused</span></a><span> surveillance technologies for</span><a href="https://www.kentucky.com/news/nation-world/national/article243605777.html"> <span>malicious personal reasons</span></a><span>.</span></p>
<p><span>This type of surveillance also makes people who live and work in heavily-policed areas more vulnerable to falling under police suspicion. If you happened to be next door to a pizza shop that got robbed, or took a coffee break near graffiti, police could easily see your device located near the crime and target you for more surveillance.</span></p>
<p><span>News about Near Intelligence comes just a year after an EFF investigation revealed </span><a href="https://www.eff.org/deeplinks/2022/06/what-fog-data-science-why-surveillance-company-so-dangerous"><span>Fog Data Science</span></a><span>, a previously unknown company that provides state and local law enforcement with easy and often warrantless access to the precise and continuous geolocation of hundreds of millions of unsuspecting Americans, collected through their smartphone apps and then aggregated by shadowy data brokers. <br></span></p>
<p><span>In light of the Journal’s recent expose, Congress must close this databroker loophole once and for all. The </span><a href="https://www.wyden.senate.gov/news/press-releases/wyden-paul-and-bipartisan-senators-reintroduce-the-fourth-amendment-is-not-for-sale-act"><span>Fourth Amendment is Not For Sale Act</span></a><span> is bipartisan, commonsense law that would ban the U.S. government from purchasing data it would otherwise need a warrant to acquire.&nbsp; Moreover, with the invasive surveillance law</span><a href="https://act.eff.org/action/tell-congress-absent-major-changes-702-should-not-be-renewed"><span> Section 702 of the Foreign Intelligence Surveillance Act set to expire in December 2023</span></a><span>, Congress has a chance to include a databroker limits in any bill that seeks to renew it. <br></span></p>
<p><span>Further, Congress and the states must enact </span><a href="https://www.eff.org/deeplinks/2019/06/effs-recommendations-consumer-data-privacy-laws"><span>comprehensive</span></a> <a href="https://www.eff.org/deeplinks/2022/07/federal-preemption-state-privacy-law-hurts-everyone"><span>consumer</span></a> <a href="https://www.eff.org/deeplinks/2019/01/you-should-have-right-sue-companies-violate-your-privacy"><span>data</span></a> <a href="https://www.eff.org/deeplinks/2022/04/stop-forced-arbitration-data-privacy-legislation"><span>privacy</span></a> <a href="https://www.eff.org/deeplinks/2023/03/eff-comments-ntia-privacy-and-civil-rights"><span>legislation</span></a><span>. If companies harvest less of our data, then there will be less data for the government to buy from those companies. <br></span></p>
<p><span>It’s up to us to keep agitating to prevent the government from continuing to buy information about us that it would otherwise need a warrant for.&nbsp;</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Worlds First FPGA N64 (287 pts)]]></title>
            <link>http://www.ultrafp64.com/</link>
            <guid>37967936</guid>
            <pubDate>Sat, 21 Oct 2023 16:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.ultrafp64.com/">http://www.ultrafp64.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37967936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><header id="masthead" role="banner">

	

<div>

	
						
			
			<p>
			The Worlds First FPGA N64		</p>
	</div><!-- .site-branding -->
	
	<!-- #site-navigation -->

</header><!-- #masthead -->

	<div id="content">
			<main id="main" role="main">

<article id="post-5" class="page">

	
	<div>
		
<figure><img width="1024" height="577" src="http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-1024x577.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-1024x577.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-768x433.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-1536x865.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-2048x1154.jpg 2048w, http://www.ultrafp64.com/wp-content/uploads/2022/06/20220615_164630-1568x883.jpg 1568w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h2 id="many-things-done-and-the-core-itself-is-almost-done-4-years-in-the-making-by-probing-everything-in-the-real-hardware-rcp-core-done-now-on-to-the-cpu">Many things are done, and the core itself is almost done – 5 Years in the making by probing everything in the real hardware. </h2>



<h2 id="many-things-done-and-the-core-itself-is-almost-done-4-years-in-the-making-by-probing-everything-in-the-real-hardware-rcp-core-done-now-on-to-the-cpu">Everything is now done!!! Just working on some upgrades!!!!</h2>



<div>
<div>
<h2 id="cpu-design"><strong>CPU design</strong></h2>




</div>



<div>
<h2 id="bus-design"><strong>Bus Design</strong></h2>




</div>



<div>
<h2 id="mips-interface"><strong>MIPS Interface</strong></h2>




</div>
</div>



<div>
<div>
<h2 id="pif-si-interface"><strong>PIF/SI interface</strong></h2>




</div>



<div>
<h2 id="rom-reader"><strong>Rom Reader</strong></h2>




</div>



<div>
<h2 id="ram-controller"><strong>Ram controller</strong></h2>




</div>
</div>



<div>
<div>
<h2 id="rsp-core-completed"><strong>RSP Core</strong>&nbsp;-completed</h2>




</div>



<div>
<h2 id="rdp-core-completed-with-one-masking-issue"><strong>RDP Core</strong> – completed</h2>




</div>



<div>
<h2 id="video-core"><strong>Video Core</strong>&nbsp;</h2>




</div>
</div>



<div>
<h2 id="audio-core">Audio Core</h2>




</div>







<p>This has been Five years in the making and written fully by myself. No leaks were used for the production of this core. Only emulators, reverse engineering and a lot of reading of patents. Coffee was overused as well</p>



<p>Many thanks to the N64Brew team and Decompiler teams as well for testing and source code access to find all the bugs.  </p>



<p><a href="https://www.twitch.tv/ultrafp64">https://www.twitch.tv/ultrafp64</a></p>



<p><a href="https://www.youtube.com/user/mazamars312/videos">https://www.youtube.com/user/mazamars312/videos</a></p>



<figure><img loading="lazy" width="1024" height="576" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_25_33_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_21_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure>
<figure><img loading="lazy" width="1024" height="576" data-id="43" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_48_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="45" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_26_53_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="39" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_23_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="40" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_26_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="42" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_43_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="44" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_27_47_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="41" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_07_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="46" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_28_16_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img loading="lazy" width="1024" height="576" data-id="48" src="https://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro-1024x576.jpg" alt="" srcset="http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro-1024x576.jpg 1024w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro-300x169.jpg 300w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro-768x432.jpg 768w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro-1536x864.jpg 1536w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro-1568x882.jpg 1568w, http://www.ultrafp64.com/wp-content/uploads/2022/03/WIN_20220401_08_30_10_Pro.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</figure>



<p>Where am I up to right now….. Well, let’s just say I’m almost done 🙂 Finally!!!!</p>



<p>I have no issues with buying myself a coffee to help my coffee addiction 🙂</p>








	</div><!-- .entry-content -->

	</article><!-- #post-5 -->
			</main><!-- #main -->
		</div><!-- #content -->

	
	<!-- .widget-area -->


	<!-- #colophon -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Keju, China’s difficult civil service test (102 pts)]]></title>
            <link>https://aeon.co/essays/why-chinese-minds-still-bear-the-long-shadow-of-keju</link>
            <guid>37967751</guid>
            <pubDate>Sat, 21 Oct 2023 15:46:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aeon.co/essays/why-chinese-minds-still-bear-the-long-shadow-of-keju">https://aeon.co/essays/why-chinese-minds-still-bear-the-long-shadow-of-keju</a>, See on <a href="https://news.ycombinator.com/item?id=37967751">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>On 7 and 8 June 2023, close to <span>13 million</span> high-school students in China sat for the world’s most gruelling college entrance exam. ‘Imagine,’ wrote a Singapore journalist, ‘the SAT, ACT, and all of your AP tests rolled into two days. That’s <em>Gao Kao</em>, or “higher education exam”.’ In 2023, almost <span>2.6 million</span> applied to sit China’s civil service exam to compete for only 37,100 slots.</p>
<p><em>Gao Kao</em> and China’s civil service exam trace their origin to, and are modelled on, an ancient Chinese institution, <em>Keju</em>, the imperial civil service exam established by the Sui Dynasty (581-618). It can be translated as ‘subject recommendation’. Toward the end of its reign, the Qing dynasty (1644-1911) abolished it in 1905 as part of its effort to reform and modernise the Chinese system. Until then, <em>Keju</em> had been the principal recruitment route for imperial bureaucracy. <em>Keju</em> reached its apex during the Ming dynasty (1368-1644). All the prime ministers but one came through the <em>Keju</em> route and many of them were ranked at the very top in their exam cohort.</p>
<p><em>Keju</em> was sheer memorisation. Testing was based primarily on the Confucian classics. And there was a lot to memorise. There were some 400,000 characters and phrases in the Confucian classics, according to Benjamin Elman’s <a href="https://www.ucpress.edu/book/9780520215092/a-cultural-history-of-civil-examinations-in-late-imperial-china" target="_blank" rel="noreferrer noopener">book</a> <em>A Cultural History of Civil Examinations in Late Imperial China</em> (2000). Preparation for the <em>Keju</em> began early. Boys aged as young as three to five began to practise their memorisation drills. After the immediate environs of their families, <em>Keju</em> was their first exposure to the world. <em>Keju</em>, which was open only to the male gender, was fiercely competitive. Using figures provided by Elman, during the Ming dynasty, <span>1 million</span> regularly took the qualifying tests and, of these, eventually about 400 would make it to the final <em>Jinshi</em> round. Passing the first tier of <em>Keju</em>, known as the provincial exam, was a lot easier – working out to be <span>4 per</span> cent on average during the Ming. Still, this was more cut-throat than getting into Harvard in most years.</p>
<p><span>T</span>he prestige of <em>Keju</em> was such that even an emperor coveted its bona fides. According to a legend, an emperor in the late Tang dynasty (618-907) hung on the wall of an imperial palace a wooden tablet proudly displaying his <em>Keju</em> degree – only it was fake. The emperor had it made for himself. This credentialism pervades officialdom today. Many Chinese government officials claim PhD degrees – earned or otherwise – on their résumés.</p>
<p>Much of the academic literature focuses on the meritocracy of <em>Keju</em>. The path-breaking book in this genre is Ping-ti Ho’s <em>The</em> <em>Ladder of Success in Imperial China</em> (1962). One of his observations is eye catching: more than half of those who obtained the <em>Juren</em> degree were first generation: ie, none of their ancestors had ever attained a <em>Juren</em> status. (<em>Juren</em> was, at the time, the first degree granted in the three-tiered hierarchy of <em>Keju</em>.) More recent literature demonstrates the political effects of <em>Keju</em>. In 1905, the Qing dynasty <a href="https://www.econometricsociety.org/publications/econometrica/2016/03/01/elite-recruitment-and-political-stability-impact-abolition" target="_blank" rel="noreferrer noopener">abolished</a> <em>Keju</em>, dashing the aspirations of millions and sparking regional rebellions that eventually toppled China’s last imperial regime <span>in 1911.</span></p>
<p><em>Keju</em> cultivated and imposed the values of deference to authority and collectivism</p>
<p>The political dimension of <em>Keju</em> goes far beyond its meritocracy and its connection to the 1911 republican revolution. For an institution that had such deep penetration, both cross-sectionally in society and across time in history, <em>Keju</em> was all encompassing, laying claims to the time, effort and cognitive investment of a significant swathe of the male Chinese population. It was a state institution designed to augment the state’s own power and capabilities. Directly, the state monopolised the very best human capital; indirectly, the state deprived society of access to talent and pre-empted <em>organised</em> religion, commerce and the intelligentsia. <em>Keju</em> anchored Chinese autocracy.</p>
<figure><img alt="Many young Chinese people are pictured in a long line outside an examination centre in a commercial district" loading="lazy" width="2400" height="2400" decoding="async" data-nimg="1" srcset="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2687%2F1-final-GettyImages-1309387268.jpg&amp;w=3840&amp;q=90 1x" src="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2687%2F1-final-GettyImages-1309387268.jpg&amp;w=3840&amp;q=90"><figcaption><p>Candidates queue for the national civil service examination on 27 March 2021 in Taiyuan, Shanxi province, China. Photo by Wu Junjie/China News Service via Getty</p></figcaption></figure>
<p>The impact of <em>Keju</em> is still felt today, not only in the form and practice of <em>Gao Kao</em> and the civil service exam but also because <em>Keju</em> incubated values and work ethics. Today, Chinese minds still bear its imprint. For one, <em>Keju</em> elevated the value of education and we see this effect today. A 2020 <a href="https://academic.oup.com/ej/article/130/631/2030/5819954" target="_blank" rel="noreferrer noopener">study</a> shows that, for every doubling of successful <em>Keju</em> candidates per 10,000 of the population in the Ming-Qing period, there was a <span>6.9 per</span> cent increase in years of schooling in 2010. The <em>Keju</em> exams loom as part of China’s human capital formation today, but they also cultivated and imposed the values of deference to authority and collectivism that the Chinese Communist Party has reaped richly for its rule and legitimacy.</p>
<p>But isn’t it the case that the West – Prussia, then the United Kingdom and the United States – all had their own civil service exams? How is it possible that a strong bureaucracy complemented rather than supplanted political and religious pluralisms in the West?</p>
<p><span>C</span>hina and the West bureaucratised under an entirely different sequential order and under different contextual conditions, and these differences entail substantial implications for the subsequent political development. The civil service in the West was not a single-platform institution in the way that <em>Keju</em> was. There was a military civil service, a civil service for foreign affairs, for forestry, etc, etc. Multiple platforms of bureaucratic recruitment competed with one another and, collectively, they competed with other channels of mobility, such as the political parties and commerce. In <span>the US,</span> the Pendleton Act of 1883 removed the power of Congress and the political parties to control civil service appointments. Before the <span>1883 Act,</span> federal appointees returned a portion of their salaries to the party that had appointed them. Civil service never replaced Congress or political parties <em>in toto</em>, as witnessed by the fact that Congress today wields enormous power over the bureaucracy, including the power of the purse that funds its operation.</p>
<p>Another difference – and this is a big one – is timing. In the 19th century, the US introduced bureaucracy when ‘[t]he two institutions of constraint, the rule of law and accountability, were the most highly developed,’ as Francis Fukuyama <a href="https://us.macmillan.com/books/9780374535629/politicalorderandpoliticaldecay" target="_blank" rel="noreferrer noopener">writes</a> in <em>Political Order and Political Decay</em> (2014). The state in <span>the US</span> and <span>the UK</span> was already ‘a Shackled Leviathan’, to use the words of Daron Acemoglu and James A Robinson in their influential <a href="https://www.penguinrandomhouse.com/books/555400/the-narrow-corridor-by-daron-acemoglu-and-james-a-robinson/" target="_blank" rel="noreferrer noopener">book</a>, <em>The Narrow Corridor</em> (2020). The sequential order ran from politics to bureaucracy, not as in China from bureaucracy to politics. In the West, society was vibrant long before the state ramped up its administrative capacity. The rule of law, the principle of accountability, and the powers of the legislature and the political parties were already firmly entrenched. Yes, the Leviathan was shackled by society, but different parts of the Leviathan shackled each other. Bureaucracy in the US formed and gained power only under a myriad of constraints and contending forces, rather than the socioeconomic <em>tabula rasa</em> that greeted the arrival of Chinese bureaucracy.</p>
<p>Vladimir Putin’s autocracy pales in comparison with that of China’s president Xi Jinping</p>
<p>The civil service in <span>the UK</span> and <span>the US</span> was ensconced in pluralistic societies that enjoyed a degree of religious freedom and a modicum of emergent electoral democracy. A world of competing forces and constraints attended the arrival of bureaucracy, even helped to create it. Government bureaucracy competed in some situations or complemented in others with church, universities, commerce and other social groups for human capital, legitimacy and resources. For political development, birth order really matters.</p>
<p>In his <a href="https://press.princeton.edu/books/paperback/9780691010731/strong-societies-and-weak-states" target="_blank" rel="noreferrer noopener">book</a> <em>Strong Societies and Weak States</em> (1988), Joel S Migdal identifies a common problem in the developing world – the struggle of the state to acquire autonomy and capabilities. China, through history and today, is exactly the opposite. The state dominates society. Vladimir Putin’s Russia is autocratic but his autocracy pales in comparison with that of China’s president Xi Jinping. Harassed and targeted by the state, opposition parties are still legal and tenuously legitimate in Russia and some of Putin’s critics command a sizeable following. Even the power to commit violence – war fighting – was outsourced to a private force, the mercenaries led by Yevgeny Prigozhin, an arrangement not even remotely conceivable in China.</p>
<figure><img alt="An anxious looking young woman and a young man are reading notebooks or textbooks outside an examination hall" loading="lazy" width="2400" height="2400" decoding="async" data-nimg="1" srcset="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2688%2F2-final-GettyImages-107348633.jpg&amp;w=3840&amp;q=90 1x" src="https://aeon.co/_next/image?url=https%3A%2F%2Fd2e1bqvws99ptg.cloudfront.net%2Fuser_image_upload%2F2688%2F2-final-GettyImages-107348633.jpg&amp;w=3840&amp;q=90"><figcaption><p>Last-minute revision before the 2010 civil service examination in Hefei, Anhui province, China. Photo AFP/Getty</p></figcaption></figure>
<p>Since 2013, against the increasingly dictatorial Xi, there have been two prominent critics of the president and both were dispensed with summarily. Unlike Putin who has to rely on extra-legal means to silence his critics, suggesting some formal constraints on him, Xi directed the full apparatus of the Chinese state after his critics. The Chinese court sentenced the businessman Ren Zhiqiang to <span>18 years</span> in prison, and Tsinghua University promptly fired Xu Zhangrun, a law professor who wrote an open letter criticising Xi. Standing forlornly by themselves, neither Ren nor Xu commanded any formal political organisations behind them. In 2022, the Chinese regime put almost <span>400 million</span> people under some sort of <span>COVID-19</span> lockdown, a feat that is unimaginable in any other country.</p>
<p><span>A</span>n ultimate autocracy is one that reigns without society. Society shackles the state in many ways. One is <em>ex ante:</em> it checks and balances the actions of the state. The other is <em>ex post</em>. A strong society provides an outside option to those inside the state. Sometimes, this is derisively described as ‘a revolving door’, but it may also have the positive function of checking the power of the state. State functionaries can object to state actions by voting with their feet, as many US civil servants did during the Donald Trump administration, and thereby drain the state of the valuable human capital it needs to function and operate. A strong society raises the opportunity costs for the state to recruit human capital but such a receptor function of society has never existed at scale in imperial China nor today, thanks – in large part, I would argue – to <em>Keju</em>.</p>
<p><em>Keju</em> was so precocious that it pre-empted and displaced an emergent society. Meritocracy empowered the Chinese state at a time when society was still at an embryonic stage. Massive resources and administrative manpower were poured into <em>Keju</em> such that it completely eclipsed all other channels of upward mobility that could have emerged. In that sense, the celebration by many of <em>Keju</em>’s meritocracy misses the bigger picture of Chinese history. It is a view of a tree rather than of a forest. The crowding-out effect of <em>Keju</em> is captured succinctly in a book from the late <span>19th century:</span></p>
<blockquote>Since the introduction of the examination system … scholars have forsaken their studies, peasants their ploughs, artisans their crafts, and merchants their trades; all have turned their attention to but one thing – government office. This is because the official has all the combined advantages of the four without requiring their necessary toil …</blockquote>
<p>This is the larger impact of <em>Keju</em>. Its impressive bureaucratic mobility demolished all other mobility channels and possibilities. <em>Keju</em> was an anti-mobility mobility channel. It packed all the upward mobility within one channel – that of the state. Society was crowded out, and over time, due to its deficient access to quality human capital, it atrophied. This is the root of the power of Chinese autocracy and, I would argue, it is a historical development that is unique to China and explains the awesome power of Chinese autocracy.</p>
<p>China has legions of intellectuals, but it is bereft of an intelligentsia</p>
<p>Take intellectuals as an example. <em>Keju</em> inculcated literacy and helped create a vibrant book readership. Book ownership was widespread as early as the Ming dynasty. ‘More books were available,’ <a href="https://www.hup.harvard.edu/catalog.php?isbn=9780674072534" target="_blank" rel="noreferrer noopener">writes</a> Timothy Brook in <em>The Troubled Empire</em> (2010), ‘and more people read and owned more books, in the late Ming than at any earlier time in history, anywhere in the world.’ Brook sums up the impressions of Jesuits visiting China: ‘More surprising, perhaps, is that complete illiterates may well have been a minority in the late Ming.’</p>
<p>But a striking fact is that no organised intelligentsia of any significant size and visibility ever emerged in imperial China. There were no Chinese equivalents of the Royal Society in Britain or the many learned societies in France. One that left a mark is the Donglin Academy, a private discussion forum founded in 1111 by intellectuals of the Song dynasty (960-1279). The academy lasted as long as its founders’ lifespan and vanished into obscurity after their expiry. It was revived in 1604 during the reign of the Wanli emperor (1573-1620), but it operated as a political rather than an intellectual force. The scholar-officials formed a Donglin Faction, later brutally put down by the powerful eunuchs of the Ming court. The grand total of the second life of the Donglin Academy is <span>21 years,</span> from 1604 to 1625.</p>
<p>The term ‘scholar official’ is of Chinese coinage and it is evocative of China’s lacuna of intellectuals as an <em>institutionalised establishment</em>. Compare that situation with Tsarist Russia, another autocracy. Russians coined the term ‘intelligentsia’ – intellectuals as a class – and Russian intellectuals have a long tradition of standing apart from and defining their identity as separate to the state. China has legions of intellectuals, but it is bereft of an intelligentsia.</p>
<p>Prior to <em>Keju</em> and even during the early centuries of <em>Keju</em>, China had a plurality of upward mobility. Within bureaucracy, officials were appointed through nepotism, family ties, heredity and recommendations. Commerce, while always curtailed, was a nascent force, promising to burst forward. The Song dynasty experienced a vibrant development of commerce and a market economy. Although Confucianism was always the first among equals, other ideologies, such as Legalism, Daoism and Buddhism, cohabitated with Confucianism and vied with one another for the Chinese population’s attention and adherence.</p>
<p>But these societal forces were too nascent and too embryonic by the time <em>Keju</em> arrived and matured. They had yet to acquire their own unique identity, significant organisation and autonomous agency. In imperial China, there never was a level playing field between state and society, and over nearly <span>1,500 years,</span> <em>Keju</em> further deprived the congenitally deficient society of its oxygen – human capital. Fukuyama is right to assert that the Chinese state was precocious, but it was precocious in a particular fashion: its precocity contrasted sharply with the immaturity of Chinese society.</p>
<p><span>T</span>he most direct way <em>Keju</em> decimated Chinese society is through talent monopoly but there were others. <em>Keju</em> also monopolised the time and mental energy of its candidates. <em>Keju</em> was not a one-shot deal. A candidate could take the test multiple times. In a <a href="https://www.journals.uchicago.edu/doi/10.1086/714934" target="_blank" rel="noreferrer noopener">dataset</a> that has information on the 11,706 <em>Keju</em> candidates during the Ming dynasty, the average age passing the final stage of <em>Keju</em> was 32, approaching middle age at a time when average life expectancy was much lower than today. The oldest in the dataset was was probably Gui Youguang (1506-1571). Before passing the provincial examination in 1540 at the youngish age of 34, Gui had already failed it on six occasions. He then proceeded to toil for more than 24 years of his life and finally attained his <em>Jinshi</em> degree in 1565, although ranking near the bottom of his class and at the ripe age of 59. Unfortunately, he did not bask in his exalted status for long, as he died aged 65. For him, and many others, <em>Keju</em> was a life-long endeavour.</p>
<!-- -->
<p>The <em>Keju</em> curriculum was formidable and required memorising close to 400,000 characters. Is there spare residual energy, capacity and curiosity left to pursue other mentally taxing activities, such as ideation of new thoughts, new politics, and discoveries of natural phenomena? In my <a href="https://yalebooks.co.uk/book/9780300266368/the-rise-and-fall-of-the-east/" target="_blank" rel="noreferrer noopener">book</a> <em>The Rise and Fall of the EAST</em> (2023), I show that Chinese technology began to stagnate as <em>Keju</em> gained dominance. The brain power that ended up in the state did not flow to Chinese society, the economy or human creativity.</p>
<p>Mental energy aside, the values drilled deeply into <em>Keju</em> candidates were pro-autocracy and authoritarian. <em>Keju</em> legitimates statism. Boys as young as three or four began to practise writing characters that were meant to instil admiration of, and devotion to, the ideas and teachings of the master – Confucius – which would eventually be tested on <em>Keju</em>. By the Ming dynasty, the initial plurality of the <em>Keju</em> subjects gave way to one subject only, Confucianism – ‘knowledge of classics, stereotyped theories of administration, and literary attainments’.</p>
<p>Autocracy and <em>Keju</em> became ever more intimately intertwined</p>
<p>Imagine repeated exposures to the statist values at that tender age, producing what psychologists call ‘an imprinting effect’. The autocratic values were incubated in substance but also by the format of <em>Keju</em>; this was standardised testing par excellence. When <em>Keju</em> was first established, candidates were tested on a wide range of subject matters but, after the Song dynasty, the <em>Keju</em> curriculum became progressively stratified and exceedingly narrow. Candidates were required to fill in the blanks with missing words or phrases in excerpted texts from the Confucian classics. The Yuan dynasty (1271-1368) narrowed the <em>Keju</em> curriculum further. Only a streamlined version of annotations of Confucian classics was allowed, the so-called Neo-Confucianism, which was the brainchild of the great Confucian scholar Zhu Xi (1130-1200) of the Song dynasty.</p>
<p>Neo-Confucianism is a pared-down version of classical Confucianism, and it strips away some of the moral veneer of its classical predecessor. Summarising a common view among historians, Peter K Bol <a href="https://www.hup.harvard.edu/catalog.php?isbn=9780674053243" target="_blank" rel="noreferrer noopener">observes</a> in <em>Neo-Confucianism in History</em> (2010) that this version of Confucianism ‘provided a justification for seeking external authority in the ruler’ and stipulated the responsibility for transforming the world as that of the emperor alone. The Neo-Confucianist <em>Keju</em> curriculum was rigid, narrow and absolutist, and was single-minded in its advocacy of a hierarchical order – subordination to the ruler, to the elderly, and to the male gender. No scope for scepticism and ambiguity was allowed. Autocracy and <em>Keju</em> thus became ever more intimately intertwined.</p>
<p>There was, however, a massive operational advantage to the Neo-Confucianist curriculum: it standardised everything. Standardisation abhors nuance and the evaluations became more straightforward as the baseline comparison was more clearly delineated. There was objectivity, even if the objectivity was a manufactured artefact. The Chinese invented the modern state and meritocracy, but above all the Chinese invented specialised standardised testing – the memorisation, cognitive inclination and frame of references of an exceedingly narrow ideology.</p>
<p><span>M</span>ing standardised <em>Keju</em> further: it enforced a highly scripted essay format, known as the ‘eight-legged essay’, or <em>baguwen</em> in Chinese (八股文), to which every <em>Keju</em> candidate had to adhere. A ‘leg’ here refers to each section of an essay, with a <em>Keju</em> essay requiring eight sections: <span>1) breaking</span> open the topic; <span>2) receiving</span> the topic; <span>3) beginning</span> the discussion; <span>4) the</span> initial leg; <span>5) the</span> transition leg; <span>6) the</span> middle leg; <span>7) the</span> later leg; and <span>8) conclusion.</span> The eight-legged essay fixed more than the aggregate structure of exposition. The specifications were granular and detailed. For example, the number of phrases was specified in each of the sections and the entire essay required expressions in paired sentences – a minimum of six paired sentences, up to a maximum of 12. The key contribution of the eight-legged essay is that it packed information into a pre-set presentational format.</p>
<p>Standardisation was designed to scale the <em>Keju</em> system and it succeeded brilliantly in that regard, but it had a devastating effect on expositional freedom and human creativity. All elements of subjectivity and judgment were taken out. In his <a href="https://cup.cuhk.edu.hk/index.php?route=product/product&amp;product_id=461" target="_blank" rel="noreferrer noopener">book</a> <em>Traditional Government in Imperial China</em> (1982), the historian Ch’ien Mu describes the ‘eight-legged essay’ as ‘the greatest destroyer of human talent’.</p>
<p>A bane to human creativity was a boon to autocracy. Standardised testing was conducive to authoritarianism. In his <a href="https://www.wiley.com/en-gb/Who%27s+Afraid+of+the+Big+Bad+Dragon%3F%3A+Why+China+Has+the+Best+%28and+Worst%29+Education+System+in+the+World-p-9781118487136" target="_blank" rel="noreferrer noopener">book</a> <em>Who’s Afraid of the Big Bad Dragon?</em> (2014), Yong Zhao, professor at the School of Education of the University of Kansas, notes a natural compatibility between authoritarianism and standardised testing. Authoritarianism, he writes, ‘sees education as a way to instil in all students the same knowledge and skills deemed valuable by the authority.’ The standardised tests appeal to an authoritative body for correct answers; as Zhao said in an interview for the US National Education Policy Center, the tests ‘force students to comply with the answers or the way of thinking that the authority wants.’ The direction of deference is automatically established: ‘Then you hold the students, the teachers and, to a lesser extent, the parents accountable for being able to get the answers that the authority wants and to show that they have mastered the skills and the knowledge and possibly even the beliefs that the authority wants.’</p>
<p>Confucianism, thus, functioned as an equivalent of the abstruse and arcane vocabulary of the SAT</p>
<p>In his <a href="https://www.penguin.co.uk/books/193790/the-weirdest-people-in-the-world-by-henrich-joseph/9780141976211" target="_blank" rel="noreferrer noopener">book</a> <em>The WEIRDest People in the World</em> (2020), Joseph Henrich posited that the West prospered because of its early lead in literacy. Yet the substantial <em>Keju</em> literacy produced none of the liberalising effects on Chinese ideas, economy or society. The literacy that Henrich had in mind was a particular kind of literacy – Protestant literacy – and the contrast with <em>Keju</em> literacy could not have been sharper. <em>Keju</em> literacy was drilled and practised in classical and highly stratified Chinese, the language of the imperial court rather than the language of the masses, in sharp contrast to Protestant literacy. Protestant literacy empowered personal agency by embracing and spreading vernaculars of the masses. Henrich’s liberalising <a href="https://aeon.co/essays/american-undergrads-are-too-weird-to-stand-for-all-humanity" target="_blank" rel="noopener">‘WEIRD’ effect</a> – Western, educated, industrialised, rich and democratic – was a byproduct of Protestant literacy. It is no accident that <em>Keju</em> literacy produced an opposite effect.</p>
<p>Why was there such a close affinity between <em>Keju</em> and Confucianism? The answer is not obvious. Ancient China boasted other great ideologies and traditions, such as Daoism, Mohism and Legalism, but they were completely absent in the <em>Keju</em> curriculum. This ideological single-mindedness of <em>Keju</em> is puzzling and it is puzzling still considering the following: in my book, I document that several emperors who played an instrumental role in inventing and developing <em>Keju</em> were not Confucianists themselves.</p>
<p>The answer may lie in an operational imperative of <em>Keju</em>. Standardised testing is necessary when you want to scale the evaluation. Subjective evaluations, such as relying on reputation, recommendations and interviews, are feasible when the number of candidates under evaluation is small. For example, the Big Three colleges in the US – Harvard, Yale and Princeton – began to embrace the SAT (the standardised test for college admissions) when they started recruiting beyond their traditional, narrow socioeconomic group – the white Anglo-Saxon Protestants (WASPs) in the elite private schools of the east coast. The Chinese emperors made the same decision when they expanded bureaucratic recruitment beyond the nobility and wealthy elites. Standardising and constricting the <em>Keju</em> curriculum were not an optional luxury; it was a necessity to scale <em>Keju</em>.</p>
<p>Confucianism offered an operational advantage. It is textually rich; the verbiage is massive, and the pontifications are incredibly involved, not unlike the verbal portion of the SAT. As noted before, there are approximately 400,000 characters and phrases in the Confucian classics. Using a <a href="https://ctext.org/" target="_blank" rel="noreferrer noopener">website</a>, Chinese Text Project, ‘an online open-access digital library that makes pre-modern Chinese texts available to readers and researchers all around the world’, I found that among the classical texts created before the Han dynasty (206 BCE-220 CE) Confucianism is paragraphically the richest, with 11,184 paragraphs. No other ideologies come remotely close. Legalism has 1,783 paragraphs; Daoism has 1,161 paragraphs, and Mohism has 915 paragraphs. Confucianism, thus, functioned as an equivalent of the abstruse and arcane vocabulary of the SAT, and it was most suited for screening and selecting the desired human capital from a large pool of candidates.</p>
<p>Is it at all possible that <em>Keju</em> successfully anchored and shaped the nature of the Chinese autocracy because of this accidental feature of Confucianism and on account of an operational technicality? Let’s pause, savour and ponder for a moment the momentous implications of this proposition.</p>
<p><em>This essay is adapted from the book </em><a href="https://yalebooks.co.uk/book/9780300266368/the-rise-and-fall-of-the-east/" target="_blank" rel="noreferrer noopener"><em>The Rise and Fall of the EAST: How Exam, Autocracy, Stability and Technology Brought China Success, and Why They Might Lead to its Decline</em></a> <em>(2023) by Yasheng Huang.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Human microbiome myths and misconceptions (117 pts)]]></title>
            <link>https://www.nature.com/articles/s41564-023-01426-7</link>
            <guid>37967748</guid>
            <pubDate>Sat, 21 Oct 2023 15:46:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/s41564-023-01426-7">https://www.nature.com/articles/s41564-023-01426-7</a>, See on <a href="https://news.ycombinator.com/item?id=37967748">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <div id="Sec1-section" data-title="Main"><h2 id="Sec1">Main</h2><p>Human microbiome research has undergone rapid growth over the past two decades and thousands of research papers on this topic are now published every year. Huge sums of money have been spent investigating the human microbiome as a cause of, or potential therapeutic solution to, a wide range of diseases, including inflammatory bowel disease and cardiometabolic conditions. Although truly exciting, the increasing focus on microbiome research has unfortunately also brought with it hype and entrenched certain misconceptions. As a result, many unsupported, or undersupported, statements have become ‘fact’ by virtue of constant repetition. Some are more widespread than others and some are relatively trivial, but, cumulatively, they highlight that misinformation is pervasive in the human microbiome literature. Given the potential importance of human microbiomes for health, it is crucial that claims are based on evidence. In this Perspective, we shine a light on persistent or emerging microbiome myths and misconceptions, outlining factual inaccuracies. We begin with relatively minor, but illustrative, points and build towards issues with greater potential impacts. We have purposefully tried to avoid unnecessary finger pointing at original sources of erroneous information, and instead hope that our insights and critical assessment are helpful to the field.</p></div><div id="Sec2-section" data-title="“Microbiome research is a new field”"><h2 id="Sec2">“Microbiome research is a new field”</h2><p>The pace of human microbiome research has greatly accelerated over the past 15 years, but the field is not in its infancy. To state so does a disservice to the excellent research that preceded the advent of high-throughput DNA-sequencing approaches. Indeed, there has been a rich history of research into human-associated microorganisms since at least the late nineteenth century. <i>Escherichia coli</i> was first isolated in 1885<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Hacker, J. &amp; Blum-Oehler, G. In appreciation of Theodor Escherich. Nat. Rev. Microbiol. 5, 902 (2007)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR1" id="ref-link-section-d151206423e405">1</a></sup>, bifidobacteria were described in 1899<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Cruickshank, R. Bacillus bifidus: its characters and isolation from the intestine of infants. J. Hyg. 24, 241–254 (1925)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR2" id="ref-link-section-d151206423e409">2</a></sup> and Metchnikoff speculated on the importance of beneficial gut microorganisms in the early 1900s<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Metchnikoff, E. The Prolongation of Life: Optimistic Studies (William Heinemann, G. P. Putnam’s Sons, 1907)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR3" id="ref-link-section-d151206423e413">3</a></sup>. Similarly, concepts such as the gut–brain axis have been researched for centuries<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Miller, I. The gut–brain axis: historical reflections. Microb. Ecol. Health Dis. 29, 1542921 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR4" id="ref-link-section-d151206423e417">4</a></sup> and health impacts of key microbiome-associated metabolites, such as short-chain fatty acids, were first reported more than 40 years ago<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Roediger, W. E. W. The colonic epithelium in ulcerative colitis: an energy-deficiency disease? Lancet 316, 712–715 (1980)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR5" id="ref-link-section-d151206423e422">5</a></sup>.</p></div><div id="Sec3-section" data-title="“Joshua Lederberg coined the term ‘microbiome’”"><h2 id="Sec3">“Joshua Lederberg coined the term ‘microbiome’”</h2><p>Although Nobel laureate Joshua Lederberg had many notable achievements in his career, he did not invent the word ‘microbiome’. This oft-repeated claim has been thoroughly refuted elsewhere, with evidence provided that the word was used in its modern context more than a decade before Joshua Lederberg first used it in 2001<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Prescott, S. L. History of medicine: origin of the term microbiome and why it matters. Hum. Microb. J. 4, 24–25 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR6" id="ref-link-section-d151206423e434">6</a></sup>. Although relatively trivial, this myth serves as an example of how easy it is for falsehoods to become embedded in the human microbiome literature.</p></div><div id="Sec4-section" data-title="“There are 1012 bacterial cells per gram of human faeces”"><h2 id="Sec4">“There are 10<sup>12</sup> bacterial cells per gram of human faeces”</h2><p>This figure is commonly mentioned in the microbiome literature, but its source has been difficult to ascertain. It may, however, have originated from dry-weight rather than wet-weight faecal cell counts. Regardless, it is incorrect. The real figure, as ascertained using various methods such as direct cell counts, fluorescence in situ hybridization, flow cytometry and quantitative polymerase chain reaction (qPCR), is typically between 10<sup>10</sup> and 10<sup>11</sup> microbial cells per wet-weight gram of faeces<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Stephen, A. M. &amp; Cummings, J. H. The microbial contribution to human faecal mass. J. Med. Microbiol. 13, 45–56 (1980)." href="#ref-CR7" id="ref-link-section-d151206423e453">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hoyles, L. &amp; McCartney, A. L. What do we mean when we refer to Bacteroidetes populations in the human gastrointestinal microbiota? FEMS Microbiol. Lett. 299, 175–183 (2009)." href="#ref-CR8" id="ref-link-section-d151206423e453_1">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Vandeputte, D. et al. Quantitative microbiome profiling links gut community variation to microbial load. Nature 551, 507–511 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR9" id="ref-link-section-d151206423e456">9</a></sup>.</p></div><div id="Sec5-section" data-title="“The human microbiota weighs 1 to 2 kg”"><h2 id="Sec5">“The human microbiota weighs 1 to 2 kg”</h2><p>Although this is mentioned many times in the literature, it is often given without citation and we were unable to find an original source for this claim. Nonetheless, it is unlikely to be true in most cases. The majority of the human microbiota resides in the colon, and these microorganisms typically account for less than half of the weight of faecal solids<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Sender, R., Fuchs, S. &amp; Milo, R. Revised estimates for the number of human and bacteria cells in the body. PLoS Biol. 14, e1002533 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR10" id="ref-link-section-d151206423e468">10</a></sup>. The average human stool weighs less than 200 g (wet weight)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Cummings, J. H., Bingham, S. A., Heaton, K. W. &amp; Eastwood, M. A. Fecal weight, colon cancer risk, and dietary intake of nonstarch polysaccharides (dietary fiber). Gastroenterology 103, 1783–1789 (1992)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR11" id="ref-link-section-d151206423e472">11</a></sup>, with total colonic contents ranging from 83 to 421 g in a small study of sudden-death victims<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Cummings, J. H., Pomare, E. W., Branch, W. J., Naylor, C. P. &amp; Macfarlane, G. T. Short chain fatty acids in human large intestine, portal, hepatic and venous blood. Gut 28, 1221–1227 (1987)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR12" id="ref-link-section-d151206423e476">12</a></sup>. Therefore, aside perhaps from rare cases of severely constipated individuals with extremely compacted faecal matter in their colons, the total weight of the human microbiota is much more likely to be less than 500 g, and perhaps even considerably lower than this in some cases.</p></div><div id="Sec6-section" data-title="“The microbiota outnumbers human cells by 10:1”"><h2 id="Sec6">“The microbiota outnumbers human cells by 10:1”</h2><p>This myth is perhaps one of the most pervasive in the human microbiome literature and is one that we have also repeated uncritically in the past (we, sadly, are not immune to mythology). Excellent work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Sender, R., Fuchs, S. &amp; Milo, R. Revised estimates for the number of human and bacteria cells in the body. PLoS Biol. 14, e1002533 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR10" id="ref-link-section-d151206423e489">10</a></sup> has, however, shown that this myth seems to have originated from a ‘back of the envelope’ calculation in the 1970s. More detailed analyses indicate that the true figure, albeit still impressive, is probably closer to a ratio of 1:1. It should be noted that the ratio is likely to vary from person to person and is dependent on factors such as the host’s body size and the amount of faecal material they are carrying in their colon<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Sender, R., Fuchs, S. &amp; Milo, R. Are we really vastly outnumbered? Revisiting the ratio of bacterial to host cells in humans. Cell 164, 337–340 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR13" id="ref-link-section-d151206423e493">13</a></sup>. Current estimates are also largely based on observations from adult individuals living in urbanized high-income country settings. More comprehensive estimates will require study of individuals from lower income or rural settings, and also from across the life course.</p></div><div id="Sec7-section" data-title="“The microbiota is inherited from the mother at birth”"><h2 id="Sec7">“The microbiota is inherited from the mother at birth”</h2><div id="Sec7-content"><p>Although variants of this statement are more often found in popular science articles than the scientific literature, it is an example of how nuance is extremely important when describing the human microbiome. Although some microorganisms are directly transferred from mother to baby during birth<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Ferretti, P. et al. Mother-to-infant microbial transmission from different body sites shapes the developing infant gut microbiome. Cell Host Microbe 24, 133–145.e5 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR14" id="ref-link-section-d151206423e505">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Valles-Colomer, M. et al. The person-to-person transmission landscape of the gut and oral microbiomes. Nature 614, 125–135 (2023)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR15" id="ref-link-section-d151206423e508">15</a></sup>, proportionally few microbiota species are truly ‘heritable’ and persist through from birth to adulthood in the offspring<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Valles-Colomer, M. et al. The person-to-person transmission landscape of the gut and oral microbiomes. Nature 614, 125–135 (2023)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR15" id="ref-link-section-d151206423e512">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Rothschild, D. et al. Environment dominates over host genetics in shaping human gut microbiota. Nature 555, 210–215 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR16" id="ref-link-section-d151206423e515">16</a></sup>. Indeed, most of the expansion in gut microbiota diversity occurs after birth, during the first few years of life, and increases most dramatically after weaning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Yatsunenko, T. et al. Human gut microbiome viewed across age and geography. Nature 486, 222–227 (2012)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR17" id="ref-link-section-d151206423e519">17</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41564-023-01426-7#Fig1">1</a>). Every adult ends up with a unique microbiota configuration, even identical twins that are raised in the same household<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Goodrich, J. K. et al. Human genetics shape the gut microbiome. Cell 159, 789–799 (2014)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR18" id="ref-link-section-d151206423e526">18</a></sup>. Therefore, although microbiota assembly is not yet fully understood, adult microbial communities seem to be predominantly shaped by prior stochastic environmental exposures, as well as multiple other factors such as diet, antibiotic therapy and host genetics, with direct ‘inheritance’ from the mother at birth playing a similarly lesser role.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Diversity of the human gut microbiota dramatically increases in the years after birth."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Diversity of the human gut microbiota dramatically increases in the years after birth.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41564-023-01426-7/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41564-023-01426-7/MediaObjects/41564_2023_1426_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41564-023-01426-7/MediaObjects/41564_2023_1426_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="391"></picture></a></div><p>Diversity (as assessed using number of observed operational taxonomic units) dramatically increases during the first few years of life, particularly after weaning, before beginning to plateau in childhood. This pattern is observed across individuals living in different geographical locations: Malawi (red), Venezuela (green) and the United States (blue). Figure adapted with permission from ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Yatsunenko, T. et al. Human gut microbiome viewed across age and geography. Nature 486, 222–227 (2012)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR17" id="ref-link-section-d151206423e543">17</a></sup>, Springer Nature Ltd.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41564-023-01426-7/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span></a></p></figure></div></div></div><div id="Sec8-section" data-title="“Most diseases are characterized by a pathobiome”"><h2 id="Sec8">“Most diseases are characterized by a pathobiome”</h2><div id="Sec8-content"><p>It has become increasingly common to read claims in the literature that most diseases are caused by a ‘pathobiome’. This is loosely defined as deleterious interactions between microbial communities and their host that lead to disease. This term is unfortunately overly simplistic and inherently flawed. Microorganisms and their metabolites are neither ‘good’ nor ‘bad’, they merely exist. Their impacts on us as hosts are heavily dependent on context. Microorganisms or metabolites that are deleterious in one context may cause no harm in another. As examples, <i>Clostridioides difficile</i> can be carried asymptomatically throughout life, and only cause problems in older age when the host is immunocompromised and treated with antibiotics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Schäffler, H. &amp; Breitrück, A. Clostridium difficile – from colonization to infection. Front. Microbiol. 9, 646 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR19" id="ref-link-section-d151206423e566">19</a></sup>. Similarly, a strain of <i>E.</i> <i>coli</i> may be relatively harmless in the colon, but cause a urinary tract infection if it invades the urethra<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Worby, C. J. et al. Longitudinal multi-omics analyses link gut microbiome dysbiosis with recurrent urinary tract infections in women. Nat. Microbiol. 7, 630–639 (2022)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR20" id="ref-link-section-d151206423e576">20</a></sup>. As a result, the term pathobiome remains vague and lacking in the precision required to be truly useful in clinical practice.</p><p>It is true, however, that numerous human conditions have been shown to correlate with alterations in microbiota composition. This is sometimes referred to as ‘dysbiosis’, which is also a vague term with limited clinical applicability<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Olesen, S. W. &amp; Alm, E. J. Dysbiosis is not an answer. Nat. Microbiol. 1, 16228 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR21" id="ref-link-section-d151206423e583">21</a></sup>. It is very likely that this may contribute to disease progression in some conditions, including inflammatory bowel diseases<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Ni, J., Wu, G. D., Albenberg, L. &amp; Tomov, V. T. Gut microbiota and IBD: causation or correlation? Nat. Rev. Gastroenterol. Hepatol. 14, 573–584 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR22" id="ref-link-section-d151206423e587">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Pammi, M. et al. Intestinal dysbiosis in preterm infants preceding necrotizing enterocolitis: a systematic review and meta-analysis. Microbiome 5, 31 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR23" id="ref-link-section-d151206423e590">23</a></sup>, however, such alterations are rarely consistent and the microbiota is hugely variable between individuals, both in health and disease. This makes it extremely difficult to identify gut microbiota configurations with the required specificity and reproducibility for clinical practice<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Damhorst, G. L., Adelman, M. W., Woodworth, M. H. &amp; Kraft, C. S. Current capabilities of gut microbiome-based diagnostics and the promise of clinical application. J. Infect. Dis. 223, S270–S275 (2021)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR24" id="ref-link-section-d151206423e594">24</a></sup>. In addition, correlating gut microbiome changes with systemic markers or data is fraught with challenges. This often fails to account for confounders such as age, body mass index (BMI), sex and medication, factors such as microbial community interactions or for changes that occur as a result of immunological, metabolic or other functional changes in the host rather than being directly causal (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41564-023-01426-7#Fig2">2</a>). Attempts to define ‘tipping points’ at which changes in microbiome composition definitively influence disease progression have so far largely failed to generate a clear consensus due to a lack of consistency between different studies. It is, therefore, a leap that is not yet evidence based to conclude that a characteristic pathobiome has a role in ‘most’ diseases.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Difficulties of establishing causality from correlation-based microbiota studies."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: Difficulties of establishing causality from correlation-based microbiota studies.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41564-023-01426-7/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41564-023-01426-7/MediaObjects/41564_2023_1426_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41564-023-01426-7/MediaObjects/41564_2023_1426_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="460"></picture></a></div><p>Changes in faecal microbiota have been associated with a range of diseases in humans. Interestingly, despite the diverse nature of these conditions, and the organs they affect, there are some broadly common recurring microbiota features, such as reduced diversity and increases in facultative anaerobes like Enterobacteriaceae. One common theme amongst these conditions is that they often result in increased levels of inflammation, at local and systemic levels. Such inflammation can, in turn, deplete the gut microbiota (and consequently microbial gene diversity), and allow facultative anaerobes such as Enterobacteriaceae to proliferate. This directly impacts the metabolic output of the microbiota, and its interactions with the host. Additionally, there are other host factors that contribute to disease and gut microbiota composition, such as age, BMI and medication, as well as host metabolism and immune response. This makes it very difficult to distinguish cause from effect in correlation-based studies.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41564-023-01426-7/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span></a></p></figure></div></div></div><div id="Sec9-section" data-title="“The Firmicutes:Bacteroidetes ratio is altered in obesity”"><h2 id="Sec9">“The Firmicutes:Bacteroidetes ratio is altered in obesity”</h2><div id="Sec9-content"><p>Related to the previous section, this commonly used but erroneous claim stems primarily from rodent-based research, and from findings in single, or under-powered, human studies. However, as with many other studies that report links between specific microbiota profiles and disease, reproducibility is poor. Indeed, there have now been at least three meta-analyses reporting that this finding is inconsistent between human studies, and that there are, in fact, no reproducible microbial taxonomic signatures of obesity in humans<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Finucane, M. M., Sharpton, T. J., Laurent, T. J. &amp; Pollard, K. S. A taxonomic signature of obesity in the microbiome? Getting to the guts of the matter. PLoS ONE 9, e84689 (2014)." href="#ref-CR25" id="ref-link-section-d151206423e628">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Walters, W. A., Xu, Z. &amp; Knight, R. Meta-analyses of human gut microbes associated with obesity and IBD. FEBS Lett. 588, 4223–4233 (2014)." href="#ref-CR26" id="ref-link-section-d151206423e628_1">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Sze, M. A. &amp; Schloss, P. D. Looking for a signal in the noise: revisiting obesity and the microbiome. mBio 7, e01018-16 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR27" id="ref-link-section-d151206423e631">27</a></sup>.</p><p>This misconception also reflects an unhelpful tendency to examine sequence-based microbiota profiles at very broad taxonomic levels, such as phyla. Although this is appealing from a data simplification point of view, it fails to incorporate the huge and inherent variability within individual phyla. To draw a crude analogy, humans, birds, fish, reptiles and even sea squirts are all members of the phylum Chordata, yet clearly have very different physiologies, lifestyles and impacts on their environments.</p><p>Moreover, this claim was also based on relative-abundance-based DNA sequence data. Compositional data are still useful, and can correlate well with absolute quantifications obtained with techniques such as qPCR<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Tettamanti Boshier, F. A. et al. Complementing 16S rRNA gene amplicon sequencing with total bacterial load to infer absolute species concentrations in the vaginal microbiome. mSystems 5, e00777-19 (2020)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR28" id="ref-link-section-d151206423e641">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Reichardt, N. et al. Specific substrate-driven changes in human faecal microbiota composition contrast with functional redundancy in short-chain fatty acid production. ISME J. 12, 610–622 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR29" id="ref-link-section-d151206423e644">29</a></sup>. However, some studies have suggested that relative-abundance-based correlations can lose significance when absolute microbial abundances are also factored into analyses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Vandeputte, D. et al. Quantitative microbiome profiling links gut community variation to microbial load. Nature 551, 507–511 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR9" id="ref-link-section-d151206423e648">9</a></sup>. Moving forwards, increased incorporation of absolute quantification data may help to make conclusions based on compositional analyses more robust.</p></div></div><div id="Sec10-section" data-title="“The gut microbiome is functionally redundant”"><h2 id="Sec10">“The gut microbiome is functionally redundant”</h2><p>This claim derives from studies showing that, whereas the taxonomic composition of human metagenomes can vary hugely, functional gene prediction profiles remain remarkably consistent. We contend that this is at least partly artefactual, as these functional comparisons are typically carried out after discarding the large proportion of metagenomic data that does not map to reference databases<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Méric, G., Wick, R. R., Watts, S. C., Holt, K. E. &amp; Inouye, M. Correcting index databases improves metagenomic studies. Preprint at bioRxiv 
                  https://doi.org/10.1101/712166
                  
                 (2019)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR30" id="ref-link-section-d151206423e660">30</a></sup>. Much of what does map to those databases is likely to be derived from common housekeeping and/or well-characterized genes, which are found across many different bacteria and are also relatively well represented in reference databases. These comparative analyses therefore fail to accurately capture specialist, or less well-characterized, functions. As such, the truth is more nuanced. Although there are important functionalities that are conserved across many different human microbiota species, such as short-chain fatty acid production<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Reichardt, N. et al. Specific substrate-driven changes in human faecal microbiota composition contrast with functional redundancy in short-chain fatty acid production. ISME J. 12, 610–622 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR29" id="ref-link-section-d151206423e664">29</a></sup>, there are many key functions that are only carried out by a relatively small number of microbiota species. Examples include oxalate<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Daniel, S. L. et al. Forty years of Oxalobacter formigenes, a gutsy oxalate-degrading specialist. Appl. Environ. Microbiol. 87, e0054421 (2021)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR31" id="ref-link-section-d151206423e668">31</a></sup> and resistant-starch<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Ze, X., Duncan, S. H., Louis, P. &amp; Flint, H. J. Ruminococcus bromii is a keystone species for the degradation of resistant starch in the human colon. ISME J. 6, 1535–1543 (2012)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR32" id="ref-link-section-d151206423e672">32</a></sup> degradation. In the absence of key species, functionalities such as these may not necessarily be fully replaced by other members of the microbiota.</p></div><div id="Sec11-section" data-title="“Sequencing is unbiased”"><h2 id="Sec11">“Sequencing is unbiased”</h2><p>Although sequence-based methods have been transformative for microbiome research, they are not perfect. Biases can be introduced at every step of sequence-based studies, from sample collection and storage, through laboratory-based steps such as DNA extraction, to choice of bioinformatic pipelines and reference databases used to analyse the data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Quince, C., Walker, A. W., Simpson, J. T., Loman, N. J. &amp; Segata, N. Shotgun metagenomics, from sampling to analysis. Nat. Biotechnol. 35, 833–844 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR33" id="ref-link-section-d151206423e684">33</a></sup>. Comparisons of sequence-based versus culture-based studies of the microbiota have shown that sequence-based approaches completely failed to detect some species that were only recovered using traditional culturing methods<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Rajilić-Stojanović, M., Smidt, H. &amp; de Vos, W. M. Diversity of the human gastrointestinal tract microbiota revisited. Environ. Microbiol. 9, 2125–2136 (2007)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR34" id="ref-link-section-d151206423e688">34</a></sup>. Modern sequence-based approaches are hugely powerful but, like all techniques, they are not unbiased. For optimal interpretation of results, it is important to be aware of the inherent limitations of any given method.</p></div><div id="Sec12-section" data-title="“We need standardized methodologies”"><h2 id="Sec12">“We need standardized methodologies”</h2><p>This opinion is prevalent in the microbiome field and is sensibly grounded in a desire to make it easier and more robust to compare results from different studies. However, as outlined above, there are no methodologies that are perfect, and all are biased in some way. If everyone in the world is using the same method, then everyone is equally blind to the limitations of that particular approach. There is also the problem of deciding which protocol everyone should use. For example, comparisons of results from the Human Microbiome Project with the MetaHIT project showed stark differences in microbiome profiles and indicated that the Human Microbiome Project protocol was less effective at extracting DNA from eukaryotes and Gram-positive bacterial lineages<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="Wesolowska-Andersen, A. et al. Choice of bacterial DNA extraction method from fecal material influences community structure as evaluated by metagenomic analysis. Microbiome 2, 19 (2014)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR35" id="ref-link-section-d151206423e701">35</a></sup>. The truth is that the ‘best’ method fundamentally depends on the underlying structure of the microbial community in a given sample and this can vary hugely between individuals and between body sites. For these reasons we argue, as others have, that optimization and verification of sequence-based results with additional approaches are preferable to asking everyone to adopt the same method<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Munafò, M. R. &amp; Smith, G. D. Robust research needs many lines of evidence. Nature 553, 399–401 (2018)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR36" id="ref-link-section-d151206423e705">36</a></sup>. An additional advantage of multi-faceted studies using different methods and research platforms is that they can enable more mechanistic understandings of associations between microorganisms and host phenotypes<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hoyles, L. et al. Molecular phenomics and metagenomics of hepatic steatosis in non-diabetic obese women. Nat. Med. 24, 1070–1080 (2018)." href="#ref-CR37" id="ref-link-section-d151206423e709">37</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Koh, A. et al. Microbially produced imidazole propionate impairs insulin signaling through mTORC1. Cell 175, 947–961.e17 (2018)." href="#ref-CR38" id="ref-link-section-d151206423e709_1">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Belda, E. et al. Impairment of gut microbial biotin metabolism and host biotin status in severe obesity: effect of biotin and prebiotic supplementation on improved metabolism. Gut 71, 2463–2480 (2022)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR39" id="ref-link-section-d151206423e712">39</a></sup>. Increased transparency when reporting methodology choices would be helpful for comparing results from different studies. The recently published STORMS (Strengthening the Organization and Reporting of Microbiome Studies) guidelines<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Mirzayi, C. et al. Reporting guidelines for human microbiome research: the STORMS checklist. Nat. Med. 27, 1885–1892 (2021)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR40" id="ref-link-section-d151206423e716">40</a></sup>, for example, could greatly aid this process if adopted widely.</p></div><div id="Sec13-section" data-title="“Most of the human microbiota is ‘unculturable’”"><h2 id="Sec13">“Most of the human microbiota is ‘unculturable’”</h2><p>The adoption of high-throughput sequence-based technologies has also been mirrored by claims from some quarters that these methods must be used because most human-associated microorganisms cannot be cultivated in the laboratory. In fact, a reasonably large proportion of the bacterial and archaeal component of our microbiota has already been cultured<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Lagkouvardos, I., Overmann, J. &amp; Clavel, T. Cultured microbes represent a substantial fraction of the human and mouse gut microbiota. Gut Microbes 8, 493–503 (2017)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR41" id="ref-link-section-d151206423e728">41</a></sup> (viruses and fungi remain under-represented), with pioneering work from as early as the 1970s establishing the cultivability of a broad diversity of species from the human gut microbiota<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Moore, W. E. C. &amp; Holdeman, L. V. Human fecal flora: the normal flora of 20 Japanese-Hawaiians. Appl. Microbiol. 27, 961–979 (1974)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR42" id="ref-link-section-d151206423e732">42</a></sup>. Many more species continue to be cultured as laboratory-based efforts have increased throughput<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Lagier, J. et al. Culture of previously uncultured members of the human gut microbiota by culturomics. Nat. Microbiol. 1, 16203 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR43" id="ref-link-section-d151206423e736">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Browne, H. P. et al. Culturing of ‘unculturable’ human microbiota reveals novel taxa and extensive sporulation. Nature 533, 543–546 (2016)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR44" id="ref-link-section-d151206423e739">44</a></sup>. This implies that current gaps in culture collections are at least in part attributable to a lack of previous effort rather than an inherent ‘unculturability’. Although cultivation is undeniably labour intensive, has its own biases and often requires expensive specialist equipment and media, there are clear advantages to having microorganisms in culture. These include enabling mechanistic experiments, verifying genomic predictions, and developing them as novel therapeutics<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Walker, A. W., Duncan, S. H., Louis, P. &amp; Flint, H. J. Phylogeny, culturing, and metagenomics of the human gut microbiota. Trends Microbiol 22, 267–274 (2014)." href="https://www.nature.com/articles/s41564-023-01426-7#ref-CR45" id="ref-link-section-d151206423e743">45</a></sup>. Given the importance of continued cultivation-based work for the progression of microbiome research, it is gratifying that this myth has become less prevalent in recent years following the publication of the aforementioned high-impact studies that demonstrate it to be false. However, it serves as an excellent example of how previously widely accepted dogma is sometimes simply not true. There are important lessons for many other myths and misconceptions that have yet to become as widely rejected.</p></div><div id="Sec14-section" data-title="Conclusions"><h2 id="Sec14">Conclusions</h2><div id="Sec14-content"><p>The microbiome field is broad, and there are many other controversial topics that might also have been included here. However, knowledge is still evolving on many of these; consequently, we have largely focused on concepts where we believe there is a strong evidence base for rejecting myths and misconceptions. Although some of the points above may seem trivial, we argue that the accuracy of details such as these matters. If we are consistently repeating falsehoods about minor details, can our accuracy be relied upon when covering more important matters? We hope that, by illustrating just a few examples of microbiome myths and misconceptions, we can draw increased attention to the potential problems of over-simplification and insufficient critical assessment in the microbiome literature.</p><p>Given the many potential health impacts, the huge amount of funding and the keen public interest in microbiomes, rejection of unfounded assertions is crucial if we wish to avoid expending finite resources researching unproductive avenues and undermining public confidence in our conclusions.</p></div></div>
                </div><div>
            <div id="MagazineFulltextArticleBodySuffix" aria-labelledby="Bib1" data-title="References"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Hacker, J. &amp; Blum-Oehler, G. In appreciation of Theodor Escherich. <i>Nat. Rev. Microbiol.</i> <b>5</b>, 902 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD2sXhtlajt7fM" aria-label="CAS reference 1">CAS</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=In%20appreciation%20of%20Theodor%20Escherich&amp;journal=Nat.%20Rev.%20Microbiol.&amp;volume=5&amp;publication_year=2007&amp;author=Hacker%2CJ&amp;author=Blum-Oehler%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Cruickshank, R. <i>Bacillus bifidus</i>: its characters and isolation from the intestine of infants. <i>J. Hyg.</i> <b>24</b>, 241–254 (1925).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC3crktVKrsQ%3D%3D" aria-label="CAS reference 2">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20474862" aria-label="PubMed reference 2">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2167664" aria-label="PubMed Central reference 2">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Bacillus%20bifidus%3A%20its%20characters%20and%20isolation%20from%20the%20intestine%20of%20infants&amp;journal=J.%20Hyg.&amp;volume=24&amp;pages=241-254&amp;publication_year=1925&amp;author=Cruickshank%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Metchnikoff, E. <i>The Prolongation of Life: Optimistic Studies</i> (William Heinemann, G. P. Putnam’s Sons, 1907).</p></li><li data-counter="4."><p id="ref-CR4">Miller, I. The gut–brain axis: historical reflections. <i>Microb. Ecol. Health Dis.</i> <b>29</b>, 1542921 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30425612" aria-label="PubMed reference 4">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6225396" aria-label="PubMed Central reference 4">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20gut%E2%80%93brain%20axis%3A%20historical%20reflections&amp;journal=Microb.%20Ecol.%20Health%20Dis.&amp;volume=29&amp;publication_year=2018&amp;author=Miller%2CI">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="5."><p id="ref-CR5">Roediger, W. E. W. The colonic epithelium in ulcerative colitis: an energy-deficiency disease? <i>Lancet</i> <b>316</b>, 712–715 (1980).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20colonic%20epithelium%20in%20ulcerative%20colitis%3A%20an%20energy-deficiency%20disease%3F&amp;journal=Lancet&amp;volume=316&amp;pages=712-715&amp;publication_year=1980&amp;author=Roediger%2CWEW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="6."><p id="ref-CR6">Prescott, S. L. History of medicine: origin of the term microbiome and why it matters. <i>Hum. Microb. J.</i> <b>4</b>, 24–25 (2017).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=History%20of%20medicine%3A%20origin%20of%20the%20term%20microbiome%20and%20why%20it%20matters&amp;journal=Hum.%20Microb.%20J.&amp;volume=4&amp;pages=24-25&amp;publication_year=2017&amp;author=Prescott%2CSL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="7."><p id="ref-CR7">Stephen, A. M. &amp; Cummings, J. H. The microbial contribution to human faecal mass. <i>J. Med. Microbiol.</i> <b>13</b>, 45–56 (1980).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL3c7ktVensQ%3D%3D" aria-label="CAS reference 7">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7359576" aria-label="PubMed reference 7">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20microbial%20contribution%20to%20human%20faecal%20mass&amp;journal=J.%20Med.%20Microbiol.&amp;volume=13&amp;pages=45-56&amp;publication_year=1980&amp;author=Stephen%2CAM&amp;author=Cummings%2CJH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="8."><p id="ref-CR8">Hoyles, L. &amp; McCartney, A. L. What do we mean when we refer to <i>Bacteroidetes</i> populations in the human gastrointestinal microbiota? <i>FEMS Microbiol. Lett.</i> <b>299</b>, 175–183 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1MXht1Oksb3O" aria-label="CAS reference 8">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19694813" aria-label="PubMed reference 8">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20do%20we%20mean%20when%20we%20refer%20to%20Bacteroidetes%20populations%20in%20the%20human%20gastrointestinal%20microbiota%3F&amp;journal=FEMS%20Microbiol.%20Lett.&amp;volume=299&amp;pages=175-183&amp;publication_year=2009&amp;author=Hoyles%2CL&amp;author=McCartney%2CAL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="9."><p id="ref-CR9">Vandeputte, D. et al. Quantitative microbiome profiling links gut community variation to microbial load. <i>Nature</i> <b>551</b>, 507–511 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXhvVKqtb%2FM" aria-label="CAS reference 9">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29143816" aria-label="PubMed reference 9">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantitative%20microbiome%20profiling%20links%20gut%20community%20variation%20to%20microbial%20load&amp;journal=Nature&amp;volume=551&amp;pages=507-511&amp;publication_year=2017&amp;author=Vandeputte%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="10."><p id="ref-CR10">Sender, R., Fuchs, S. &amp; Milo, R. Revised estimates for the number of human and bacteria cells in the body. <i>PLoS Biol.</i> <b>14</b>, e1002533 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27541692" aria-label="PubMed reference 10">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4991899" aria-label="PubMed Central reference 10">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Revised%20estimates%20for%20the%20number%20of%20human%20and%20bacteria%20cells%20in%20the%20body&amp;journal=PLoS%20Biol.&amp;volume=14&amp;publication_year=2016&amp;author=Sender%2CR&amp;author=Fuchs%2CS&amp;author=Milo%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="11."><p id="ref-CR11">Cummings, J. H., Bingham, S. A., Heaton, K. W. &amp; Eastwood, M. A. Fecal weight, colon cancer risk, and dietary intake of nonstarch polysaccharides (dietary fiber). <i>Gastroenterology</i> <b>103</b>, 1783–1789 (1992).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK3s%2Fotlymug%3D%3D" aria-label="CAS reference 11">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1333426" aria-label="PubMed reference 11">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Fecal%20weight%2C%20colon%20cancer%20risk%2C%20and%20dietary%20intake%20of%20nonstarch%20polysaccharides%20%28dietary%20fiber%29&amp;journal=Gastroenterology&amp;volume=103&amp;pages=1783-1789&amp;publication_year=1992&amp;author=Cummings%2CJH&amp;author=Bingham%2CSA&amp;author=Heaton%2CKW&amp;author=Eastwood%2CMA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="12."><p id="ref-CR12">Cummings, J. H., Pomare, E. W., Branch, W. J., Naylor, C. P. &amp; Macfarlane, G. T. Short chain fatty acids in human large intestine, portal, hepatic and venous blood. <i>Gut</i> <b>28</b>, 1221–1227 (1987).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL1c%2Fls1CrsA%3D%3D" aria-label="CAS reference 12">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3678950" aria-label="PubMed reference 12">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1433442" aria-label="PubMed Central reference 12">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Short%20chain%20fatty%20acids%20in%20human%20large%20intestine%2C%20portal%2C%20hepatic%20and%20venous%20blood&amp;journal=Gut&amp;volume=28&amp;pages=1221-1227&amp;publication_year=1987&amp;author=Cummings%2CJH&amp;author=Pomare%2CEW&amp;author=Branch%2CWJ&amp;author=Naylor%2CCP&amp;author=Macfarlane%2CGT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="13."><p id="ref-CR13">Sender, R., Fuchs, S. &amp; Milo, R. Are we really vastly outnumbered? Revisiting the ratio of bacterial to host cells in humans. <i>Cell</i> <b>164</b>, 337–340 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12lsL4%3D" aria-label="CAS reference 13">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26824647" aria-label="PubMed reference 13">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Are%20we%20really%20vastly%20outnumbered%3F%20Revisiting%20the%20ratio%20of%20bacterial%20to%20host%20cells%20in%20humans&amp;journal=Cell&amp;volume=164&amp;pages=337-340&amp;publication_year=2016&amp;author=Sender%2CR&amp;author=Fuchs%2CS&amp;author=Milo%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="14."><p id="ref-CR14">Ferretti, P. et al. Mother-to-infant microbial transmission from different body sites shapes the developing infant gut microbiome. <i>Cell Host Microbe</i> <b>24</b>, 133–145.e5 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhtlSqt7vI" aria-label="CAS reference 14">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30001516" aria-label="PubMed reference 14">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6716579" aria-label="PubMed Central reference 14">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Mother-to-infant%20microbial%20transmission%20from%20different%20body%20sites%20shapes%20the%20developing%20infant%20gut%20microbiome&amp;journal=Cell%20Host%20Microbe&amp;volume=24&amp;pages=133-145.e5&amp;publication_year=2018&amp;author=Ferretti%2CP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="15."><p id="ref-CR15">Valles-Colomer, M. et al. The person-to-person transmission landscape of the gut and oral microbiomes. <i>Nature</i> <b>614</b>, 125–135 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXhslKisbY%3D" aria-label="CAS reference 15">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36653448" aria-label="PubMed reference 15">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9892008" aria-label="PubMed Central reference 15">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20person-to-person%20transmission%20landscape%20of%20the%20gut%20and%20oral%20microbiomes&amp;journal=Nature&amp;volume=614&amp;pages=125-135&amp;publication_year=2023&amp;author=Valles-Colomer%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="16."><p id="ref-CR16">Rothschild, D. et al. Environment dominates over host genetics in shaping human gut microbiota. <i>Nature</i> <b>555</b>, 210–215 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXjsFaitLg%3D" aria-label="CAS reference 16">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29489753" aria-label="PubMed reference 16">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Environment%20dominates%20over%20host%20genetics%20in%20shaping%20human%20gut%20microbiota&amp;journal=Nature&amp;volume=555&amp;pages=210-215&amp;publication_year=2018&amp;author=Rothschild%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="17."><p id="ref-CR17">Yatsunenko, T. et al. Human gut microbiome viewed across age and geography. <i>Nature</i> <b>486</b>, 222–227 (2012).</p></li><li data-counter="18."><p id="ref-CR18">Goodrich, J. K. et al. Human genetics shape the gut microbiome. <i>Cell</i> <b>159</b>, 789–799 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXhvV2msrnJ" aria-label="CAS reference 18">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25417156" aria-label="PubMed reference 18">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4255478" aria-label="PubMed Central reference 18">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20genetics%20shape%20the%20gut%20microbiome&amp;journal=Cell&amp;volume=159&amp;pages=789-799&amp;publication_year=2014&amp;author=Goodrich%2CJK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="19."><p id="ref-CR19">Schäffler, H. &amp; Breitrück, A. <i>Clostridium difficile</i> – from colonization to infection. <i>Front. Microbiol.</i> <b>9</b>, 646 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29692762" aria-label="PubMed reference 19">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5902504" aria-label="PubMed Central reference 19">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Clostridium%20difficile%20%E2%80%93%20from%20colonization%20to%20infection&amp;journal=Front.%20Microbiol.&amp;volume=9&amp;publication_year=2018&amp;author=Sch%C3%A4ffler%2CH&amp;author=Breitr%C3%BCck%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="20."><p id="ref-CR20">Worby, C. J. et al. Longitudinal multi-omics analyses link gut microbiome dysbiosis with recurrent urinary tract infections in women. <i>Nat. Microbiol.</i> <b>7</b>, 630–639 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XhtFyqtrzF" aria-label="CAS reference 20">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35505248" aria-label="PubMed reference 20">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9136705" aria-label="PubMed Central reference 20">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Longitudinal%20multi-omics%20analyses%20link%20gut%20microbiome%20dysbiosis%20with%20recurrent%20urinary%20tract%20infections%20in%20women&amp;journal=Nat.%20Microbiol.&amp;volume=7&amp;pages=630-639&amp;publication_year=2022&amp;author=Worby%2CCJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="21."><p id="ref-CR21">Olesen, S. W. &amp; Alm, E. J. Dysbiosis is not an answer. <i>Nat. Microbiol.</i> <b>1</b>, 16228 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXkvFyqsr0%3D" aria-label="CAS reference 21">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27886190" aria-label="PubMed reference 21">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Dysbiosis%20is%20not%20an%20answer&amp;journal=Nat.%20Microbiol.&amp;volume=1&amp;publication_year=2016&amp;author=Olesen%2CSW&amp;author=Alm%2CEJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="22."><p id="ref-CR22">Ni, J., Wu, G. D., Albenberg, L. &amp; Tomov, V. T. Gut microbiota and IBD: causation or correlation? <i>Nat. Rev. Gastroenterol. Hepatol.</i> <b>14</b>, 573–584 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28743984" aria-label="PubMed reference 22">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5880536" aria-label="PubMed Central reference 22">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Gut%20microbiota%20and%20IBD%3A%20causation%20or%20correlation%3F&amp;journal=Nat.%20Rev.%20Gastroenterol.%20Hepatol.&amp;volume=14&amp;pages=573-584&amp;publication_year=2017&amp;author=Ni%2CJ&amp;author=Wu%2CGD&amp;author=Albenberg%2CL&amp;author=Tomov%2CVT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="23."><p id="ref-CR23">Pammi, M. et al. Intestinal dysbiosis in preterm infants preceding necrotizing enterocolitis: a systematic review and meta-analysis. <i>Microbiome</i> <b>5</b>, 31 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28274256" aria-label="PubMed reference 23">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5343300" aria-label="PubMed Central reference 23">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Intestinal%20dysbiosis%20in%20preterm%20infants%20preceding%20necrotizing%20enterocolitis%3A%20a%20systematic%20review%20and%20meta-analysis&amp;journal=Microbiome&amp;volume=5&amp;publication_year=2017&amp;author=Pammi%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="24."><p id="ref-CR24">Damhorst, G. L., Adelman, M. W., Woodworth, M. H. &amp; Kraft, C. S. Current capabilities of gut microbiome-based diagnostics and the promise of clinical application. <i>J. Infect. Dis.</i> <b>223</b>, S270–S275 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhsVyisrvN" aria-label="CAS reference 24">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33330938" aria-label="PubMed reference 24">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Current%20capabilities%20of%20gut%20microbiome-based%20diagnostics%20and%20the%20promise%20of%20clinical%20application&amp;journal=J.%20Infect.%20Dis.&amp;volume=223&amp;pages=S270-S275&amp;publication_year=2021&amp;author=Damhorst%2CGL&amp;author=Adelman%2CMW&amp;author=Woodworth%2CMH&amp;author=Kraft%2CCS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="25."><p id="ref-CR25">Finucane, M. M., Sharpton, T. J., Laurent, T. J. &amp; Pollard, K. S. A taxonomic signature of obesity in the microbiome? Getting to the guts of the matter. <i>PLoS ONE</i> <b>9</b>, e84689 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24416266" aria-label="PubMed reference 25">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3885756" aria-label="PubMed Central reference 25">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20taxonomic%20signature%20of%20obesity%20in%20the%20microbiome%3F%20Getting%20to%20the%20guts%20of%20the%20matter&amp;journal=PLoS%20ONE&amp;volume=9&amp;publication_year=2014&amp;author=Finucane%2CMM&amp;author=Sharpton%2CTJ&amp;author=Laurent%2CTJ&amp;author=Pollard%2CKS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="26."><p id="ref-CR26">Walters, W. A., Xu, Z. &amp; Knight, R. Meta-analyses of human gut microbes associated with obesity and IBD. <i>FEBS Lett.</i> <b>588</b>, 4223–4233 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXhslCisbjO" aria-label="CAS reference 26">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25307765" aria-label="PubMed reference 26">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5050012" aria-label="PubMed Central reference 26">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Meta-analyses%20of%20human%20gut%20microbes%20associated%20with%20obesity%20and%20IBD&amp;journal=FEBS%20Lett.&amp;volume=588&amp;pages=4223-4233&amp;publication_year=2014&amp;author=Walters%2CWA&amp;author=Xu%2CZ&amp;author=Knight%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="27."><p id="ref-CR27">Sze, M. A. &amp; Schloss, P. D. Looking for a signal in the noise: revisiting obesity and the microbiome. <i>mBio</i> <b>7</b>, e01018-16 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27555308" aria-label="PubMed reference 27">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4999546" aria-label="PubMed Central reference 27">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Looking%20for%20a%20signal%20in%20the%20noise%3A%20revisiting%20obesity%20and%20the%20microbiome&amp;journal=mBio&amp;volume=7&amp;publication_year=2016&amp;author=Sze%2CMA&amp;author=Schloss%2CPD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="28."><p id="ref-CR28">Tettamanti Boshier, F. A. et al. Complementing 16S rRNA gene amplicon sequencing with total bacterial load to infer absolute species concentrations in the vaginal microbiome. <i>mSystems</i> <b>5</b>, e00777-19 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32265316" aria-label="PubMed reference 28">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7141891" aria-label="PubMed Central reference 28">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Complementing%2016S%20rRNA%20gene%20amplicon%20sequencing%20with%20total%20bacterial%20load%20to%20infer%20absolute%20species%20concentrations%20in%20the%20vaginal%20microbiome&amp;journal=mSystems&amp;volume=5&amp;publication_year=2020&amp;author=Tettamanti%20Boshier%2CFA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="29."><p id="ref-CR29">Reichardt, N. et al. Specific substrate-driven changes in human faecal microbiota composition contrast with functional redundancy in short-chain fatty acid production. <i>ISME J.</i> <b>12</b>, 610–622 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhtVOitr8%3D" aria-label="CAS reference 29">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29192904" aria-label="PubMed reference 29">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Specific%20substrate-driven%20changes%20in%20human%20faecal%20microbiota%20composition%20contrast%20with%20functional%20redundancy%20in%20short-chain%20fatty%20acid%20production&amp;journal=ISME%20J.&amp;volume=12&amp;pages=610-622&amp;publication_year=2018&amp;author=Reichardt%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="30."><p id="ref-CR30">Méric, G., Wick, R. R., Watts, S. C., Holt, K. E. &amp; Inouye, M. Correcting index databases improves metagenomic studies. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/712166" data-track="click" data-track-action="external reference" data-track-label="10.1101/712166">https://doi.org/10.1101/712166</a> (2019).</p></li><li data-counter="31."><p id="ref-CR31">Daniel, S. L. et al. Forty years of <i>Oxalobacter formigenes</i>, a gutsy oxalate-degrading specialist. <i>Appl. Environ. Microbiol.</i> <b>87</b>, e0054421 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34190610" aria-label="PubMed reference 31">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Forty%20years%20of%20Oxalobacter%20formigenes%2C%20a%20gutsy%20oxalate-degrading%20specialist&amp;journal=Appl.%20Environ.%20Microbiol.&amp;volume=87&amp;publication_year=2021&amp;author=Daniel%2CSL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="32."><p id="ref-CR32">Ze, X., Duncan, S. H., Louis, P. &amp; Flint, H. J. <i>Ruminococcus bromii</i> is a keystone species for the degradation of resistant starch in the human colon. <i>ISME J.</i> <b>6</b>, 1535–1543 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhtVOjtL3L" aria-label="CAS reference 32">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22343308" aria-label="PubMed reference 32">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3400402" aria-label="PubMed Central reference 32">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Ruminococcus%20bromii%20is%20a%20keystone%20species%20for%20the%20degradation%20of%20resistant%20starch%20in%20the%20human%20colon&amp;journal=ISME%20J.&amp;volume=6&amp;pages=1535-1543&amp;publication_year=2012&amp;author=Ze%2CX&amp;author=Duncan%2CSH&amp;author=Louis%2CP&amp;author=Flint%2CHJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="33."><p id="ref-CR33">Quince, C., Walker, A. W., Simpson, J. T., Loman, N. J. &amp; Segata, N. Shotgun metagenomics, from sampling to analysis. <i>Nat. Biotechnol.</i> <b>35</b>, 833–844 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXhsVOht7vJ" aria-label="CAS reference 33">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28898207" aria-label="PubMed reference 33">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Shotgun%20metagenomics%2C%20from%20sampling%20to%20analysis&amp;journal=Nat.%20Biotechnol.&amp;volume=35&amp;pages=833-844&amp;publication_year=2017&amp;author=Quince%2CC&amp;author=Walker%2CAW&amp;author=Simpson%2CJT&amp;author=Loman%2CNJ&amp;author=Segata%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="34."><p id="ref-CR34">Rajilić-Stojanović, M., Smidt, H. &amp; de Vos, W. M. Diversity of the human gastrointestinal tract microbiota revisited. <i>Environ. Microbiol.</i> <b>9</b>, 2125–2136 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17686012" aria-label="PubMed reference 34">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=Diversity%20of%20the%20human%20gastrointestinal%20tract%20microbiota%20revisited&amp;journal=Environ.%20Microbiol.&amp;volume=9&amp;pages=2125-2136&amp;publication_year=2007&amp;author=Rajili%C4%87-Stojanovi%C4%87%2CM&amp;author=Smidt%2CH&amp;author=Vos%2CWM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="35."><p id="ref-CR35">Wesolowska-Andersen, A. et al. Choice of bacterial DNA extraction method from fecal material influences community structure as evaluated by metagenomic analysis. <i>Microbiome</i> <b>2</b>, 19 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24949196" aria-label="PubMed reference 35">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4063427" aria-label="PubMed Central reference 35">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Choice%20of%20bacterial%20DNA%20extraction%20method%20from%20fecal%20material%20influences%20community%20structure%20as%20evaluated%20by%20metagenomic%20analysis&amp;journal=Microbiome&amp;volume=2&amp;publication_year=2014&amp;author=Wesolowska-Andersen%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="36."><p id="ref-CR36">Munafò, M. R. &amp; Smith, G. D. Robust research needs many lines of evidence. <i>Nature</i> <b>553</b>, 399–401 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29368721" aria-label="PubMed reference 36">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Robust%20research%20needs%20many%20lines%20of%20evidence&amp;journal=Nature&amp;volume=553&amp;pages=399-401&amp;publication_year=2018&amp;author=Munaf%C3%B2%2CMR&amp;author=Smith%2CGD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="37."><p id="ref-CR37">Hoyles, L. et al. Molecular phenomics and metagenomics of hepatic steatosis in non-diabetic obese women. <i>Nat. Med.</i> <b>24</b>, 1070–1080 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXht1WqsLjN" aria-label="CAS reference 37">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29942096" aria-label="PubMed reference 37">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6140997" aria-label="PubMed Central reference 37">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=Molecular%20phenomics%20and%20metagenomics%20of%20hepatic%20steatosis%20in%20non-diabetic%20obese%20women&amp;journal=Nat.%20Med.&amp;volume=24&amp;pages=1070-1080&amp;publication_year=2018&amp;author=Hoyles%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="38."><p id="ref-CR38">Koh, A. et al. Microbially produced imidazole propionate impairs insulin signaling through mTORC1. <i>Cell</i> <b>175</b>, 947–961.e17 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXitVWju7jI" aria-label="CAS reference 38">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30401435" aria-label="PubMed reference 38">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Microbially%20produced%20imidazole%20propionate%20impairs%20insulin%20signaling%20through%20mTORC1&amp;journal=Cell&amp;volume=175&amp;pages=947-961.e17&amp;publication_year=2018&amp;author=Koh%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="39."><p id="ref-CR39">Belda, E. et al. Impairment of gut microbial biotin metabolism and host biotin status in severe obesity: effect of biotin and prebiotic supplementation on improved metabolism. <i>Gut</i> <b>71</b>, 2463–2480 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XivFegtbzE" aria-label="CAS reference 39">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35017197" aria-label="PubMed reference 39">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Impairment%20of%20gut%20microbial%20biotin%20metabolism%20and%20host%20biotin%20status%20in%20severe%20obesity%3A%20effect%20of%20biotin%20and%20prebiotic%20supplementation%20on%20improved%20metabolism&amp;journal=Gut&amp;volume=71&amp;pages=2463-2480&amp;publication_year=2022&amp;author=Belda%2CE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="40."><p id="ref-CR40">Mirzayi, C. et al. Reporting guidelines for human microbiome research: the STORMS checklist. <i>Nat. Med.</i> <b>27</b>, 1885–1892 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXisFWks73O" aria-label="CAS reference 40">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34789871" aria-label="PubMed reference 40">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9105086" aria-label="PubMed Central reference 40">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Reporting%20guidelines%20for%20human%20microbiome%20research%3A%20the%20STORMS%20checklist&amp;journal=Nat.%20Med.&amp;volume=27&amp;pages=1885-1892&amp;publication_year=2021&amp;author=Mirzayi%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="41."><p id="ref-CR41">Lagkouvardos, I., Overmann, J. &amp; Clavel, T. Cultured microbes represent a substantial fraction of the human and mouse gut microbiota. <i>Gut Microbes</i> <b>8</b>, 493–503 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28418756" aria-label="PubMed reference 41">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5628658" aria-label="PubMed Central reference 41">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Cultured%20microbes%20represent%20a%20substantial%20fraction%20of%20the%20human%20and%20mouse%20gut%20microbiota&amp;journal=Gut%20Microbes&amp;volume=8&amp;pages=493-503&amp;publication_year=2017&amp;author=Lagkouvardos%2CI&amp;author=Overmann%2CJ&amp;author=Clavel%2CT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="42."><p id="ref-CR42">Moore, W. E. C. &amp; Holdeman, L. V. Human fecal flora: the normal flora of 20 Japanese-Hawaiians. <i>Appl. Microbiol.</i> <b>27</b>, 961–979 (1974).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaE2c7ntVagsQ%3D%3D" aria-label="CAS reference 42">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4598229" aria-label="PubMed reference 42">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC380185" aria-label="PubMed Central reference 42">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Human%20fecal%20flora%3A%20the%20normal%20flora%20of%2020%20Japanese-Hawaiians&amp;journal=Appl.%20Microbiol.&amp;volume=27&amp;pages=961-979&amp;publication_year=1974&amp;author=Moore%2CWEC&amp;author=Holdeman%2CLV">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="43."><p id="ref-CR43">Lagier, J. et al. Culture of previously uncultured members of the human gut microbiota by culturomics. <i>Nat. Microbiol.</i> <b>1</b>, 16203 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXkvFyruro%3D" aria-label="CAS reference 43">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27819657" aria-label="PubMed reference 43">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Culture%20of%20previously%20uncultured%20members%20of%20the%20human%20gut%20microbiota%20by%20culturomics&amp;journal=Nat.%20Microbiol.&amp;volume=1&amp;publication_year=2016&amp;author=Lagier%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="44."><p id="ref-CR44">Browne, H. P. et al. Culturing of ‘unculturable’ human microbiota reveals novel taxa and extensive sporulation. <i>Nature</i> <b>533</b>, 543–546 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xnt1Ogsrg%3D" aria-label="CAS reference 44">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27144353" aria-label="PubMed reference 44">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4890681" aria-label="PubMed Central reference 44">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Culturing%20of%20%E2%80%98unculturable%E2%80%99%20human%20microbiota%20reveals%20novel%20taxa%20and%20extensive%20sporulation&amp;journal=Nature&amp;volume=533&amp;pages=543-546&amp;publication_year=2016&amp;author=Browne%2CHP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="45."><p id="ref-CR45">Walker, A. W., Duncan, S. H., Louis, P. &amp; Flint, H. J. Phylogeny, culturing, and metagenomics of the human gut microbiota. <i>Trends Microbiol</i> <b>22</b>, 267–274 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXlt1CrsLg%3D" aria-label="CAS reference 45">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24698744" aria-label="PubMed reference 45">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Phylogeny%2C%20culturing%2C%20and%20metagenomics%20of%20the%20human%20gut%20microbiota&amp;journal=Trends%20Microbiol&amp;volume=22&amp;pages=267-274&amp;publication_year=2014&amp;author=Walker%2CAW&amp;author=Duncan%2CSH&amp;author=Louis%2CP&amp;author=Flint%2CHJ">
                    Google Scholar</a>&nbsp;
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41564-023-01426-7?format=refman&amp;flavour=references">Download references</a></p></div></div><div id="Ack1-section" data-title="Acknowledgements"><h2 id="Ack1">Acknowledgements</h2><p>A.W.W. would like to thank S. Patrick for the original invitation to give a talk on this topic, which inspired the subsequent writing of this article. A.W.W. and the Rowett Institute receive core funding support from the Scottish Government’s Rural and Environment Science and Analytical Services division. L.H. is funded by Alzheimer’s Research UK, Healthcare Infection Society, Diabetes UK, Cancer Research UK and the European Union’s Horizon 2020 research and innovation programme under grant agreement 874583. This publication reflects only the authors’ views and the European Commission is not responsible for any use that may be made of the information it contains.</p></div><div id="author-information-section" aria-labelledby="author-information" data-title="Author information"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Microbiome, Food Innovation and Food Security Research Theme, Rowett Institute, University of Aberdeen, Aberdeen, UK</p><p>Alan W. Walker</p></li><li id="Aff2"><p>Department of Biosciences, Nottingham Trent University, Nottingham, UK</p><p>Lesley Hoyles</p></li></ol><div data-test="author-info"><p><span>Authors</span></p><ol><li id="auth-Alan_W_-Walker-Aff1"><span>Alan W. Walker</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Alan%20W.%20Walker" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Alan%20W.%20Walker%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Lesley-Hoyles-Aff2"><span>Lesley Hoyles</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Lesley%20Hoyles" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Lesley%20Hoyles%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li></ol></div><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:alan.walker@abdn.ac.uk">Alan W. Walker</a>.</p></div></div><div id="ethics-section" data-title="Ethics declarations"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar2">Competing interests</h3>
                <p>The authors declare no competing interests.</p>
              
            </div></div><div id="peer-review-section" data-title="Peer review"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar1">Peer review information</h3>
                <p><i>Nature Microbiology</i> thanks Ami Bhatt, Fergus Shanahan and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div><div id="additional-information-section" data-title="Additional information"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div><div id="rightslink-section" data-title="Rights and permissions"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content"><p>Springer Nature or its licensor (e.g. a society or other partner) holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.</p><p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Human%20microbiome%20myths%20and%20misconceptions&amp;author=Alan%20W.%20Walker%20et%20al&amp;contentID=10.1038%2Fs41564-023-01426-7&amp;copyright=Springer%20Nature%20Limited&amp;publication=2058-5276&amp;publicationDate=2023-07-31&amp;publisherName=SpringerNature&amp;orderBeanReset=true">Reprints and Permissions</a></p></div></div><div id="article-info-section" aria-labelledby="article-info" data-title="About this article"><h2 id="article-info">About this article</h2><div id="article-info-content"><p><a data-crossmark="10.1038/s41564-023-01426-7" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41564-023-01426-7" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></p><div><h3 id="citeas">Cite this article</h3><p>Walker, A.W., Hoyles, L. Human microbiome myths and misconceptions.
                    <i>Nat Microbiol</i> <b>8</b>, 1392–1396 (2023). https://doi.org/10.1038/s41564-023-01426-7</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41564-023-01426-7?format=refman&amp;flavour=citation">Download citation</a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2022-08-31">31 August 2022</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2023-06-15">15 June 2023</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2023-07-31">31 July 2023</time></span></p></li><li><p>Issue Date<span>: </span><span><time datetime="2023-08">August 2023</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41564-023-01426-7</span></p></li></ul></div></div></div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fish skin can heal other animals' eye injuries (107 pts)]]></title>
            <link>https://www.scientificamerican.com/article/fish-skin-can-heal-other-animals-eye-injuries/</link>
            <guid>37967493</guid>
            <pubDate>Sat, 21 Oct 2023 15:15:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/fish-skin-can-heal-other-animals-eye-injuries/">https://www.scientificamerican.com/article/fish-skin-can-heal-other-animals-eye-injuries/</a>, See on <a href="https://news.ycombinator.com/item?id=37967493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-behavior="newsletter_promo dfp_article_rendering" data-dfp-adword="Advertisement" data-newsletterpromo_article-text="<p>Sign up for <em>Scientific American</em>&amp;rsquo;s free newsletters.</p>" data-newsletterpromo_article-image="https://static.scientificamerican.com/sciam/cache/file/4641809D-B8F1-41A3-9E5A87C21ADB2FD8_source.png" data-newsletterpromo_article-button-text="Sign Up" data-newsletterpromo_article-button-link="https://www.scientificamerican.com/page/newsletter-sign-up/?origincode=2018_sciam_ArticlePromo_NewsletterSignUp" name="articleBody" itemprop="articleBody"><p>Tilapia skin is rich in <a href="https://www.scientificamerican.com/article/anti-aging-discovery-could-lead-to-restorative-skin-treatments/">collagen</a>, and this structural protein's abundance has made the fish a popular resource in veterinary and human medicine. Researchers have explored its use in applications from bandaging burn victims and correcting abdominal hernias to mending heart valves and reconstructing vaginas.</p>

<p>Inspired by colleagues in a dozen other specialties, Mirza Melo, a veterinary ophthalmologist in northeastern Brazil's Ceará state, tested tilapia skin to treat a pervasive problem in her field: corneal ulcers and perforations, particularly in dogs with short snouts. “These are species with very prominent eyes,” she says. “So they get injured often.“</p>

<p>Such corneal injuries are commonly treated by surgically placing a membrane made of horse placenta (also a collagen source but with a lower concentration than tilapia skin, Melo says) over the affected area to help it regenerate. Melo first swapped that membrane for tilapia skin in 2019, when she successfully operated on a Shih Tzu with a severe corneal perforation.</p>

<p>Brazil's Burn Support Institute and the Federal University of Ceará—home of the Tilapia Skin Project, which pioneered the skin's use to treat burns—approached her about the surgical technique. With their support Melo began testing a membrane she called the acellular dermal matrix (ADM), made of pure collagen extracted from the fish skin.</p>

<p>Collagen is known to stimulate cellular growth and to “guide the generation of various tissues,” Melo says. A tilapia's collagen supply and quality remain high throughout the fish's entire life, whereas horse-placenta collagen varies depending on factors such as the animal's age and weight, she says.</p>

<p>The processed ADM resembles a thick sheet of paper. Veterinarians rehydrate it with saline solution before surgery, then lay it over a dog's corneal lesion and suture it into place, where it acts as scaffolding for regenerating cells.</p>

<p>The 400-plus dogs Melo has treated so far have shown no pain or problems with infection after surgery. They also healed quickly, with minimal scarring that would affect postsurgical care.</p>

<p>Current corneal repair strategies such as using horse placenta, grafting and transplant have good results—but scarring continues to be a concern, says Robson Santos, a veterinary ophthalmologist not involved in the ADM project. “Tilapia skin is an excellent alternative to the well-established techniques we already have,” he says.</p>

<p>Melo is now looking to use the technique on cats, and she says discussions have already begun on how to adapt it for humans. She also hopes to take her research to the eye's retina, which is particularly challenging to treat because of its extremely sensitive specialized neurons.</p>

<p>“It's where we have the most limited resources, in both veterinary and human ophthalmology,” Melo says. “So we hope to get there one day.”</p></div><section><p>This article was originally published with the title "Fish Eye" in Scientific American  329, 3, 17 (October 2023)</p><p>doi:10.1038/scientificamerican1023-17a</p></section><section><h3>ABOUT THE AUTHOR(S)</h3><div><ul></ul><p><strong>Jill Langlois</strong> is a freelance journalist based in São Paulo, Brazil, and writes for publications such as <em>National Geographic, Time</em> and the <em>New York Times</em>. Follow her on Instagram&nbsp;<a href="https://www.instagram.com/journalistjill/?hl=en">@journalistjill</a></p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What every developer should know about GPU computing (362 pts)]]></title>
            <link>https://codeconfessions.substack.com/p/gpu-computing</link>
            <guid>37967126</guid>
            <pubDate>Sat, 21 Oct 2023 14:36:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codeconfessions.substack.com/p/gpu-computing">https://codeconfessions.substack.com/p/gpu-computing</a>, See on <a href="https://news.ycombinator.com/item?id=37967126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Most programmers have an intimate understanding of CPUs and sequential programming because they grow up writing code for the CPU, but many are less familiar with the inner workings of GPUs and what makes them so special. Over the past decade, GPUs have become incredibly important because of their pervasive use in deep learning. Today, it is essential for every software engineer to possess a basic understanding of how they work. My goal with this article is to give you that background.&nbsp;</p><blockquote><p><em><span>Much of this article is based on the book “</span><a href="https://shop.elsevier.com/books/programming-massively-parallel-processors/hwu/978-0-323-91231-0" rel="">Programming Massively Parallel Processors</a><span>”, 4th edition by Hwu et al. As the book covers Nvidia GPUs, I will also be talking about Nvidia GPUs and using Nvidia specific terminology. However, the fundamental concepts and approach to GPU programming apply to other vendors as well.</span></em></p></blockquote><p>We will start by doing a comparison between CPU and GPU which will give us a better vantage point of the GPU landscape. However, this is a topic of its own and we cannot possibly squeeze everything in one section. So, we will stick to a few key points.</p><p><span>The major difference between CPUs and GPUs is in their design goals. CPUs were designed to execute sequential instructions</span></p><p><span>. To improve their sequential execution performance, many features have been introduced in the CPU design over the years. The emphasis has been on reducing the instruction execution latency so that CPUs can execute a sequence of instructions as fast as possible. This includes features like </span><a href="https://en.wikipedia.org/wiki/Instruction_pipelining" rel="">instruction pipelining</a><span>, </span><a href="https://en.wikipedia.org/wiki/Out-of-order_execution" rel="">out of order execution</a><span>, </span><a href="https://en.wikipedia.org/wiki/Speculative_execution" rel="">speculative execution</a><span> and multilevel caches (just to list a few).</span></p><p>GPUs on the other hand have been designed for massive levels of parallelism and high throughput, at the cost of medium to high instruction latency. This design direction has been influenced by their use in video games, graphics, numerical computing, and now deep learning. All of these applications need to perform a ton of linear algebra and numerical computations at a very fast rate, because of which a lot of attention has gone into improving the throughput of these devices.</p><p>Let’s consider a concrete example. A CPU can add two numbers much faster than the GPU because of its low instruction latency. They will be able to do several of such computations in a sequence faster than a GPU. However, when it comes to doing millions or billions of such computations, a GPU will do those computations much much faster than a CPU because of its sheer massive parallelism.</p><p>If you like numbers, let’s talk about numbers. The performance of hardware for numerical computations is measured in terms of how many floating point operations it can do per second (FLOPS). The Nvidia Ampere A100 offers a throughput of 19.5 TFLOPS for 32-bit precision. In comparison, the throughput of an Intel 24-core processor is 0.66 TFLOPS for 32-bit precision (these numbers are from 2021). And, this gap in the throughput performance between GPUs and CPUs has been growing wider with each passing year.</p><p>The following figure compares the architectures of CPUs and GPUs.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png" width="1456" height="719" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:719,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Figure 1: A comparison of the CPU and GPU chip design. Figure from the Nvidia CUDA C++ Programming Guide&quot;,&quot;title&quot;:&quot;A comparison of the CPU and GPU chip design. Figure from the Nvidia CUDA C++ Programming Guide&quot;,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Figure 1: A comparison of the CPU and GPU chip design. Figure from the Nvidia CUDA C++ Programming Guide" title="A comparison of the CPU and GPU chip design. Figure from the Nvidia CUDA C++ Programming Guide" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2e81d6e3-f38b-49d3-995b-a334fb38394f_1456x719.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 1: A comparison of the CPU and GPU chip design. Figure from the Nvidia CUDA C++ Programming Guide</figcaption></figure></div><p>As you may see, CPUs dedicate a significant amount of chip area towards features which will reduce instruction latency, such as large caches, less ALUs and more control units. In contrast, GPUs use a large number of ALUs to maximize their computation power and throughput. They use a very small amount of the chip area for caches and control units, the things which reduce the latency for CPUs.</p><p><span>You might wonder, how do the GPUs tolerate high latencies and yet provide high performance. We can understand this with the help of </span><a href="https://en.wikipedia.org/wiki/Little%27s_law" rel="">Little’s law</a><span> from queuing theory. It states that the average number of requests in the system (Qd for queue depth) is equal to the average arrival rate of requests (throughput T) multiplied by the average amount of time to serve a request (latency L).</span></p><p>In the context of GPUs, this basically means one can tolerate a given level of latency in the system to achieve a target throughput by maintaining a queue of instructions which are either in execution or waiting. The large number of compute units in the GPU and efficient thread scheduling enables the GPUs to maintain this queue over kernel execution time and achieve a high throughput despite these long memory latencies.</p><p>So we understand GPUs favor high throughput but what does their architecture look like which enables them to achieve this, let’s discuss in this section.</p><p>A GPU consists of an array of streaming multiprocessors (SM). Each of these SMs in turn consists of several streaming processors or cores or threads. For instance, the Nvidia H100 GPU has 132 SMs with 64 cores per SM, totalling a whopping 8448 cores.</p><p>Each SM has a limited amount of on-chip memory, often referred to as shared memory or a scratchpad, which is shared among all the cores. Likewise, the control unit resources on the SM are shared by all the cores. Additionally, each SM is equipped with hardware-based thread schedulers for executing threads.</p><p>Apart from these, each SM also has several functional units or other accelerated compute units such as tensor cores, or ray tracing units to serve specific compute demands of the workload that the GPU caters to.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png" width="971" height="593" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:593,&quot;width&quot;:971,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Figure 2: The GPU Compute Architecture&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Figure 2: The GPU Compute Architecture" title="Figure 2: The GPU Compute Architecture" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0f4c3f5e-1d1c-4556-8c7e-2725cc82d2df_971x593.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 2: The GPU Compute Architecture</figcaption></figure></div><p>Next, let’s breakdown the GPU memory and look inside.</p><p>The GPU has several layers of different kinds of memories, with each having their specific use case. The following figure shows the memory hierarchy for one SM in the GPU.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg" width="1456" height="1228" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1228,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Figure 3: The GPU Memory Architecture from the Cornell Virtual Workshop on Understanding GPUs&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Figure 3: The GPU Memory Architecture from the Cornell Virtual Workshop on Understanding GPUs" title="Figure 3: The GPU Memory Architecture from the Cornell Virtual Workshop on Understanding GPUs" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6e9b3eeb-76c2-4a9e-b526-52cea31bfc9a_1456x1228.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 3: The GPU Memory Architecture from the Cornell Virtual Workshop on Understanding GPUs</figcaption></figure></div><p>Let’s break it down.</p><ul><li><p><strong>Registers:</strong><span> We will start with the registers. Each SM in the GPU has a large number of registers. For instance, the Nvidia A100, and H100 models have 65,536 registers per SM. These registers are shared between the cores, and are allocated to them dynamically depending on the requirement of the threads. During execution the registers allocated to a thread are private to it, i.e., other threads cannot read/write those registers.</span></p></li><li><p><strong>Constant Caches:</strong><span> Next, we have constant caches on the chip. These are used to cache constant data used by the code executing on the SM. To utilize these caches, programmers have to explicitly declare objects as constants in the code so that the GPU may cache and keep them in the constant cache.</span></p></li><li><p><strong>Shared Memory:</strong><span> Each SM also has a shared memory or scratchpad which is a small amount of fast and low latency on-chip programmable SRAM memory. It is designed to be shared by a block of threads running on the SM. The idea behind shared memory is that if multiple threads need to work with the same piece of data, only one of them should load it from the global memory, while others will share it. Careful usage of shared memory can cut down redundant load operations from global memory, and improve the kernel execution performance. Another usage of the shared memory is as a synchronization mechanism between threads executing within a block.&nbsp;</span></p></li><li><p><strong>L1 Cache:</strong><span> Each SM also has an L1 cache which can cache frequently accessed data from L2 cache.&nbsp;</span></p></li><li><p><strong>L2 Cache:</strong><span> There is an L2 cache which is shared by all SMs. It caches the frequently accessed data from the global memory to cut down the latency. Note that both L1 and L2 caches are transparent to the SM, i.e., the SM doesn’t know it is getting data from L1 or L2. As far as the SM is concerned, it is getting data from the global memory. This is similar to how L1/L2/L3 caches work in CPUs.</span></p></li><li><p><strong>Global Memory:</strong><span> The GPU also has an off-chip global memory, which is a high capacity and high bandwidth DRAM. For instance, the Nvidia H100 has 80 GB high bandwidth memory (HBM) with bandwidth of 3000 GB/second. Due to being far away from the SMs, the latency of global memory is quite high. However, the several additional layers of on-chip memories, and high number of compute units help hide this latency (see Little's law discussion in the CPU vs GPU section).</span></p></li></ul><p>Now that we know about the key components of the GPU hardware, let’s go one step deeper and understand how these components come into picture when executing code.</p><p>To understand how the GPU executes a kernel, we first need to understand what a kernel is and what its configurations are. Let’s start there.</p><p>CUDA is the programming interface provided by Nvidia for writing programs for their GPUs. In CUDA you express a computation that you want to run on the GPU in the form similar to a&nbsp; C/C++ function and this function is called a kernel. The kernel operates on vectors of numbers in parallel which are provided to it as function parameters. A simple example would be a kernel to perform vector addition, i.e., a kernel that takes two vectors of numbers as inputs, adds them element-wise and writes the result to a third vector.&nbsp;</p><p>To execute a kernel on the GPU, we need to launch a number of threads which is collectively referred to as a grid. But there is more structure to the grid. A grid consists of one or more thread blocks (sometimes simply called as blocks) and each block consists of one or more threads.</p><p>The number of blocks and threads depends on the size of the data and the amount of parallelism we want. For instance, in our vector addition example, if we are adding vectors of dimension 256, then we may decide to configure a single thread block of 256 threads so that each thread operates on one element of the vector. For bigger problems, we may not have enough threads available on the GPU and we might want each thread to handle multiple data points.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png" width="1456" height="692" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/16b44282-f064-478e-84b4-0c44664c1630_1600x760.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:692,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Grid of thread blocks (figure from Nvidia CUDA C++ Programming Guide)&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Grid of thread blocks (figure from Nvidia CUDA C++ Programming Guide)" title="Grid of thread blocks (figure from Nvidia CUDA C++ Programming Guide)" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F16b44282-f064-478e-84b4-0c44664c1630_1600x760.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 4: Grid of thread blocks (figure from Nvidia CUDA C++ Programming Guide)</figcaption></figure></div><p>As far as implementation goes, writing a kernel requires two parts. One is the host code which executes on the CPU. This is where we load the data, allocate memory on the GPU, and launch the kernel with a configured grid of threads. The 2nd part is writing the device (GPU) code which executes on the GPU.</p><p>For our vector addition example, the following figure shows the host code.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png" width="1442" height="739" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:739,&quot;width&quot;:1442,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Host code for the CUDA kernel for adding two vectors&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Host code for the CUDA kernel for adding two vectors" title="Host code for the CUDA kernel for adding two vectors" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F51685688-c07d-4baa-b0c0-7021597e7132_1442x739.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 5: Host code for the CUDA kernel for adding two vectors</figcaption></figure></div><p>And the following is the device code, which defines the actual kernel function.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png" width="1456" height="617" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:617,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Device code containing the definition of the vector addition kernel&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Device code containing the definition of the vector addition kernel" title="Device code containing the definition of the vector addition kernel" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7cb6a3a-d76f-4263-b9b8-0915e6b74c8f_1506x638.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 6: Device code containing the definition of the vector addition kernel</figcaption></figure></div><blockquote><p>As the focus of this article is not teaching CUDA, we will not be going any deeper in this code. Now, let’s look at the exact steps behind the execution of a kernel on the GPU.</p></blockquote><p><span>Before the kernel can be scheduled for execution, all the data that it needs has to be copied from the memory of the host (the CPU) onto the global memory of the GPU (the device). Although, in latest GPU hardware one can also read directly from host memory using unified virtual memory (see section 2.2 of the paper: “</span><a href="https://arxiv.org/pdf/2006.06890.pdf" rel="">EMOGI: Efficient Memory-access for Out-of-memory Graph-traversal in GPUs</a><span>”).&nbsp;</span></p><p>After the GPU has all the necessary data in its memory, it assigns the thread blocks to the SMs. All threads within a block are processed by the same SM at the same time. To make this happen, the GPU must set aside resources on the SM for those threads before it can start executing them. In practice, multiple thread blocks can be assigned to the same SM for simultaneous execution.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png" width="1041" height="331" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0417e64e-77a6-443f-b861-5f2640291187_1041x331.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:331,&quot;width&quot;:1041,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Assignment of a thread block to an SM&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="Assignment of a thread block to an SM" title="Assignment of a thread block to an SM" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0417e64e-77a6-443f-b861-5f2640291187_1041x331.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Figure 7: Assignment of a thread block to an SM</figcaption></figure></div><p>As there are a limited number of SMs and large kernels can have a very large number of blocks, not all the blocks may get assigned for execution immediately. The GPU maintains a list of blocks which are waitlisted for assignment and execution. As and when any block finishes execution, the GPU assigns one of the waitlisted blocks for execution.</p><p><span>We know that all threads of a block are assigned to the same SM. But there’s another level of division of threads after this. These threads are further grouped into sizes of 32, which is called a warp (called a </span><em>warp</em></p><p><span>), and assigned together for execution on a set of cores called a processing block.</span></p><p>The SM executes all the threads within a warp together by fetching and issuing the same instruction to all of them. These threads then execute that instruction simultaneously, but on different parts of the data. In our vector addition example, all the threads in a warp might be executing the add instruction, but they would be operating on different indices of the vectors.</p><p><span>This execution model of the warp is also called </span><em>single instruction multiple threads</em><span> (SIMT) because multiple threads are executing the same instruction. It is similar to the </span><em><a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data" rel="">single instruction multiple data</a></em><span> (SIMD) instructions in CPUs.</span></p><blockquote><p><span>There is an alternative instruction scheduling mechanism available in newer generations of GPUs, starting from Volta and onwards, known as </span><em>independent thread scheduling</em><span>. It allows full concurrency between threads, regardless of warp. It can be used to make better use of the execution resources, or as a synchronization mechanism between threads. We will not cover independent thread scheduling here, but you can read about it in the </span><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#simt-architecture" rel="">CUDA programming guide</a><span>.</span></p></blockquote><p>There are some interesting details about how warps work, that are worth discussing.</p><p>Even if all the processing blocks (groups of cores) within an SM are handling warps, only a few of them are actively executing instructions at any given moment. This happens because there are a limited number of execution units available in the SM.</p><p>But some instructions take longer to complete, causing a warp to wait for the result. In such cases, the SM puts that waiting warp to sleep and starts executing another warp that doesn't need to wait for anything. This enables the GPUs to maximally utilize all the available compute and deliver high throughput (Little’s law again in action here).</p><blockquote><p><strong>Zero-overhead Scheduling: </strong><span>As each thread in each warp has its own set of registers, there is no overhead for the SM to switch from executing one warp to another.&nbsp;</span></p><p>This is in contrast to how context-switching between processes happens on the CPU. If a process is waiting for a long running operation, the CPU schedules another process on that core in the meanwhile. However, context switching in CPU is expensive because the CPU needs to save the registers into main memory, and restore the state of the other process.</p></blockquote><p>Finally, when all the threads of the kernel have finished executing, the final step is to copy the result back to the host memory.</p><p>Although we covered everything about a typical kernel execution but there is one more thing that requires its own section: dynamic resource partitioning.</p><p><span>We measure the utilization of the GPU resources through a metric called “</span><em>occupancy</em><span>”, which represents the ratio of the number of warps assigned to an SM to the maximum number it can support. To achieve maximum throughput, we would want to have 100% occupancy. However, in practice it is not always possible due to various constraints.&nbsp;</span></p><p>So, why can't we always reach 100% occupancy? The SM has a fixed set of execution resources, including registers, shared memory, thread block slots, and thread slots. These resources are dynamically divided among threads based on their requirements and the GPU's limits. For example, on the Nvidia H100, each SM can handle 32 blocks, 64 warps (i.e., 2048 threads), and 1024 threads per block. If we launch a grid with a block size of 1024 threads, the GPU will split the 2048 available thread slots into 2 blocks.</p><blockquote><p><strong>Dynamic vs Fixed partitioning</strong><span>: Dynamic partitioning allows for more effective usage of the computation resources in the GPU. If we compare this with a fixed partitioning scheme where each thread block receives a fixed amount of execution resources it might not always be the most efficient. In some cases the threads might be assigned more resources than they need, leading to wastage of resources and reduced throughput.</span></p></blockquote><p>Now, let's look at an example to see how resource allocation can affect the occupancy of an SM. If we use a block size of 32 threads and need a total of 2048 threads, we'll have 64 of these blocks. However, each SM can only handle 32 blocks at once. So, even though the SM can run 2048 threads, it will only be running 1024 threads at a time, resulting in a 50% occupancy rate.&nbsp;</p><p>Similarly, each SM has 65536 registers. To execute 2048 threads simultaneously, each thread can have a maximum of 32 registers (65536/2048 = 32). If a kernel needs 64 registers per thread, we can only run 1024 threads per SM, again resulting in 50% occupancy.</p><p>The challenge with suboptimal occupancy is that it may not provide the necessary tolerance for latency or the required compute throughput to reach the hardware’s peak performance.</p><p>Efficiently creating GPU kernels is a complex task. We must allocate resources wisely to maintain high occupancy while minimizing latency. For example, having many registers can make code run quickly but might reduce occupancy, so careful code optimization is important.</p><p>I understand that wrapping your head around so many new terms and concepts is daunting. Let’s summarize the key points for a quick review.</p><ul><li><p>A GPU consists of several streaming multiprocessors (SM), where each SM has several processing cores.</p></li><li><p>There is an off chip global memory, which is a HBM or DRAM. It is far from the SMs on the chip and has high latency.</p></li><li><p>There is an off chip L2 cache and an on chip L1 cache. These L1 and L2 caches operate similarly to how L1/L2 caches operate in CPUs.</p></li><li><p>There is a small amount of configurable shared memory on each SM. This is shared between the cores. Typically, threads within a thread block load a piece of data into the shared memory and then reuse it instead of loading it again from global memory.</p></li><li><p>Each SM has a large number of registers, which are partitioned between threads depending on their requirement. The Nvidia H100 has 65,536 registers per SM.</p></li><li><p>To execute a kernel on the GPU, we launch a grid of threads. A grid consists of one or more thread blocks and each thread block consists of one or more threads.</p></li><li><p>The GPU assigns one or more blocks for execution on an SM depending on resource availability. All threads of one block are assigned and executed on the same SM. This is for leveraging data locality and for synchronization between threads.</p></li><li><p>The threads assigned to an SM are further grouped into sizes of 32, which is called a warp. All the threads within a warp execute the same instruction at the same time, but on different parts of the data (SIMT). (Although newer generations of GPUs also support independent thread scheduling.)</p></li><li><p>The GPU performs dynamic resource partitioning between the threads based on each threads requirements and the limits of the SM. The programmer needs to carefully optimize code to ensure the highest level of SM occupancy during execution.</p></li></ul><p><span>GPUs are in pervasive use today, but their architecture and execution model is fundamentally very different from CPUs. In this article we covered various aspects of GPUs, including their architecture and their execution model. If you're curious about what makes GPUs so sought after and how they operate, I hope this article has provided some valuable insights. If you have any questions about what we discussed here, feel free to ask them in the comments, or reach out to me on</span><a href="https://twitter.com/abhi9u" rel=""> Twitter/X</a><span>.</span></p><p>I would also like to give a shout out to our community. This topic was requested by many of you and I had to cover it. You can also request me to write about a topic of your choice by becoming a paid subscriber.</p><p><span>I would like to thank </span><a href="https://msharmavikram.github.io/" rel="">Vikram Sharma Mailthody</a><span>, who is a Senior Research Scientist at Nvidia for reviewing and offering insights on various parts of the article. His feedback helped improve the quality of the article significantly. I am very grateful. Vikram is very interested in increasing awareness about GPU programming, so if you are interested in learning more about this area, reach out to him on </span><a href="https://twitter.com/msharmavikram" rel="">Twitter</a><span> or </span><a href="https://www.linkedin.com/in/vikramsharmam/" rel="">LinkedIn</a><span>.</span></p><p>If you want to dive deeper into GPUs, here are few resources you could refer to:</p><ul><li><p>Programming Massively Parallel Processors: 4th edition is the most up-to-date reference, but earlier editions are fine, too.</p></li><li><p><a href="https://www.youtube.com/channel/UC2Y6MNqiTwTrh-qPQHGIUyg" rel="">Programming Massively Parallel Processors</a><span>: online course by Prof. Hwu</span></p></li><li><p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html" rel="">Nvidia’s CUDA C++ Programming Guide</a></p></li><li><p><a href="https://www.youtube.com/watch?v=3l10o0DYJXg" rel="">How GPU Computing Works (YouTube)</a></p></li><li><p><a href="https://enccs.github.io/gpu-programming/" rel="">GPU Programming: When, Why and How?</a></p></li><li><p><span>For Little’s law refer to section 2.2 of the paper “</span><a href="https://arxiv.org/pdf/2203.04910.pdf" rel="">GPU-Initiated On-Demand High-Throughput Storage Access in the BaM System Architecture</a><span>”</span></p></li></ul><p data-attrs="{&quot;url&quot;:&quot;https://codeconfessions.substack.com/p/gpu-computing?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;,&quot;action&quot;:null,&quot;class&quot;:null}" data-component-name="ButtonCreateButton"><a href="https://codeconfessions.substack.com/p/gpu-computing?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cratering motor fuel sales in Norway show the death spiral that can end oil (119 pts)]]></title>
            <link>https://electrek.co/2023/10/20/cratering-motor-fuel-sales-in-norway-show-the-death-spiral-that-can-end-oil/</link>
            <guid>37966767</guid>
            <pubDate>Sat, 21 Oct 2023 13:48:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2023/10/20/cratering-motor-fuel-sales-in-norway-show-the-death-spiral-that-can-end-oil/">https://electrek.co/2023/10/20/cratering-motor-fuel-sales-in-norway-show-the-death-spiral-that-can-end-oil/</a>, See on <a href="https://news.ycombinator.com/item?id=37966767">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
			<img src="https://electrek.co/wp-content/uploads/sites/3/2019/10/CircleK_pressebilder_23sept2019_2395.jpg?quality=82&amp;strip=all&amp;w=1600" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2019/10/CircleK_pressebilder_23sept2019_2395.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2019/10/CircleK_pressebilder_23sept2019_2395.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2019/10/CircleK_pressebilder_23sept2019_2395.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2019/10/CircleK_pressebilder_23sept2019_2395.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" width="1600" height="796" alt="norway ev charger gas station" fetchpriority="high">
	
	</figure>

<p>It’s common knowledge that Norway is the <a href="https://electrek.co/2023/01/03/norway-electric-car-utopia-sustainable-transportation/">land of electric cars</a> and that the country keeps breaking EV sales records with <a href="https://electrek.co/2023/06/01/tesla-model-y-outsells-2nd-place-id-4-by-4x-in-norway-97-electrified-in-may/">virtually no new fossil vehicle sales</a>. But what’s <em>really</em> important is the effect those EVs are having on oil sales, which are in steep decline in the country as a result –&nbsp;and the same thing could happen elsewhere.</p>



<p>Norwegian statistics agency SSB released its latest numbers on motor fuel sales today, showing a <a href="https://www.ssb.no/en/energi-og-industri/olje-og-gass/statistikk/sal-av-petroleumsprodukt">whopping 9% decline</a> in motor fuel sales year-over-year for the month of September.</p>



<p>This is a result of Norway’s world-leading EV sales, with over 90% of new vehicles in the country having some sort of plug and <a href="https://electrek.co/2023/06/01/tesla-model-y-outsells-2nd-place-id-4-by-4x-in-norway-97-electrified-in-may/">vanishingly few having no electrification at all</a>. The country has exceeded its own high expectations, virtually ending fossil vehicle sales <a href="https://electrek.co/2021/09/23/norway-bans-gas-cars-in-2025-but-trends-point-toward-100-ev-sales-as-early-as-april/">years ahead of schedule</a>.</p>



<p>However, there are still fossil vehicles on the road from previous years that are continuing to pollute and use fossil fuels throughout their lifecycle. But as they age and are replaced almost solely with EVs, the vehicle fleet cycles out from fossil to electric. If it takes 10-15 years for the vehicle fleet to cycle out, then that means Norway would remove ~6-10% of fossil cars from the road every year, replace them with electric cars, and thus reduce motor fuel usage by a similar amount every year.</p>



<p>But this trend is nothing particularly new. While this big 9% drop is just a one-month snapshot, petrol/gasoline sales have been in decline for about two decades in the country, as diesel started to replace petrol in the mid-2000s. But diesel has also been in decline for the better part of a decade, as electricity has replaced it as a motor fuel.</p>



<figure><img decoding="async" fetchpriority="high" width="1852" height="1042" src="https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png 1852w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=150,84 150w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=300,169 300w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=768,432 768w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=1024,576 1024w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=1536,864 1536w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=350,197 350w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=140,79 140w, https://electrek.co/wp-content/uploads/sites/3/2023/10/NORenergy.png?resize=1600,900 1600w" sizes="(max-width: 1852px) 100vw, 1852px"><figcaption>Stats from Robbie Andrew’s excellent Norway EV stats tracker at <a href="https://robbieandrew.github.io/EV/">robbieandrew.github.io/EV/</a></figcaption></figure>



<p>To compare against other rapid declines, US coal usage has gone from a peak of 1,045 million tons in 2007 to 469 million tons in 2022, a decline of about 5% per year (and going from ~50% of the US electricity mix to ~20% now, and dropping). Many observers acknowledged, even <a href="https://www.desmog.com/2011/01/03/future-coal-dims-further-2010-dying-industry-still-killing-and-polluting/">near the beginning of this trend</a>, that coal was a dead industry. Any subsequent <a href="https://electrek.co/2018/07/05/scott-pruitt-resigns-replaced-by-climate-denier-and-coal-lobbyist-andrew-wheeler/">attempts to expand it</a> have been <a href="https://electrek.co/2020/11/23/egeb-trump-administration-coal-childrens-climate-prize-solar-iron/">unserious political stunts</a> that were doomed to fail from the start – everyone (<a href="https://electrek.co/2020/03/31/epa-andrew-wheeler-idiot-liar/">with a brain</a>) knows the industry is dead.</p>



<p>But in that context, Norway’s decline in motor fuel sales seems to be happening <em>almost twice as fast</em> on a percentage basis as the United States’ decline in coal use, at least according to today’s data point. And the long-term trend may accelerate as the country now has virtually no gas vehicle sales.</p>



<p>This is important because when we talk about electrifying the auto industry, the point is not just to get people into better cars with neat new technology. The point is to reduce oil consumption, such that carbon that belongs underground stays there –&nbsp;permanently.</p>



<p>This is vitally important because if we burned even a fraction of all the oil that is already discovered and owned by oil companies, the carbon released would cause catastrophic climate change. This was covered in Bill McKibben’s excellent 2012 article “<a href="https://www.rollingstone.com/politics/politics-news/global-warmings-terrifying-new-math-188550/">Global Warming’s Terrifying New Math</a>.”</p>



<p>The only way we can avoid this fate is through one of the more wonderful phrases in the English language: “stranded assets.” In this context, the phrase refers to&nbsp;oil reserves owned by oil companies which get written off of those companies’ books because they are uneconomical to extract and sell.</p>



<p>In short, oil companies need to lose money, and lots of them need to go bankrupt.</p>



<p>And while Norway is just one relatively small country, news like this shows how that could happen as EV sales (and better yet, <a href="https://electrek.co/2022/05/17/norway-rolls-back-ev-incentives-while-boosting-walking-and-cycling/">even cleaner methods of transportation</a> like e-bikes and public transit) grow rapidly worldwide.</p>



<h2 id="h-oil-demand-oil-prices-oil-supply">Oil demand -&gt; oil prices -&gt; oil supply</h2>



<p>There is an interplay between oil demand, oil prices, and oil supply that could lead to a death spiral for the oil industry.</p>



<p>Lately, oil prices have been quite high around the world, nearing the <a href="https://www.macrotrends.net/1369/crude-oil-price-history-chart">historic highs of the 2010s and late 70s</a>. This spike has largely been driven by pandemic-related supply (and demand) disruptions, the Russian invasion of Ukraine, and, as always, the decisions of Saudi Arabia (in this case, their decision to cut supply to buoy oil prices).</p>



<p>But looking back to the last peak, we can see another interesting thing: a giant drop in oil prices in the mid-2010s, which was driven by a “supply glut.” This supply glut was at least partially related to increased usage of hybrid and electric cars, which led to a relatively small decrease in oil demand. However, that small decrease meant that more oil was being pumped than used, which led prices to drop by about two-thirds in a matter of months.</p>



<p>The effect of oil prices on consumer demand is that as oil prices go up, usage (often) goes down, and interest in electric cars goes up. This stands to reason, as people start thinking about more efficient vehicles when the cost of fueling their vehicle becomes too much.</p>



<p>But the effect on supply is less popularly examined. In this case, low oil prices can actually be environmentally advantageous because it means that oil companies are less incentivized to explore new methods of extraction and that more expensive methods (such as tar sands extraction, which is also much more environmentally costly) become uneconomical.</p>



<p>If it costs more to extract the oil than the oil is worth, then the project won’t get started. And if the project doesn’t get started, then the oil stays in the ground to begin with, right where it belongs.</p>



<p>So, in a way, low oil prices can actually be better for the environment than high oil prices. This means fewer projects get started, and more projects and companies go bankrupt due to high costs and low profits.</p>



<p>And this is the spiral that we want to see. As the primary driver of oil demand (vehicles, specifically consumer vehicles) disappears, oil prices can drop because of this supply-demand imbalance. Then, there will be less reason for companies to extract oil in the first place, leading to the stranded assets we spoke of before.</p>



<p>Some regions with low cost of extraction might even prefer it this way and work to ensure this happens. The Middle East can extract oil for <a href="https://www.energy.ca.gov/sites/default/files/2021-09/2021-09_Petroleum_Watch_ADA.pdf">cheaper than anywhere else</a>, so it could be to their benefit to put high-cost extraction methods out of business. Norway itself is an oil country (primarily for export, at this point) and has middling oil-extraction costs, but it may benefit in the short term from a shakeout of higher-cost countries. But ideally, Norway’s extraction would soon become uneconomical –&nbsp;and hopefully, so will Saudi Arabia’s.</p>




	<p>The one danger of this path is that if oil demand does drop low enough, low oil prices could jeopardize consumer decision-making to move to cleaner options. Oil is subsidized to the tune of <a href="https://www.imf.org/en/Blogs/Articles/2023/08/24/fossil-fuel-subsidies-surged-to-record-7-trillion">trillions of dollars worldwide per year</a> based on unpriced external costs that all of us are paying on the back end –&nbsp;usually in the form of higher hospital bills or other environmental costs.</p>



<p>This could be solved by <a href="https://electrek.co/2017/12/02/hey-gop-you-passed-your-tax-hike-now-pass-your-carbon-price-too/">finally properly pricing oil</a> globally, as <a href="https://bellona.org/news/carbon-accounting/2021-02-norway-proposes-e200-per-ton-co2-tax-by-2030">Norway already rightly does</a>. Norway’s realistic pricing for carbon pollution has helped to ensure that the true price of oil is reflected in consumer pricing, making it more apparent to consumers that fossil vehicles are not an economical option for society or their pocketbooks.</p>



<p>In contrast, the <a href="https://www.bloomberg.com/news/articles/2015-01-05/the-real-reason-u-s-gas-is-so-cheap-is-americans-don-t-pay-the-true-cost-of-driving">artificially low</a> gasoline costs in the US (yes, US gasoline prices are still artificially low, even at today’s high prices) work to buoy consumer oil demand. Removing the <a href="https://www.imf.org/en/Publications/WP/Issues/2019/05/02/Global-Fossil-Fuel-Subsidies-Remain-Large-An-Update-Based-on-Country-Level-Estimates-46509">~$650 billion in implicit subsidies</a> received by the fossil fuel industry in the US alone would help ensure that fair market conditions could prevail, and consumers would have a clear choice about what the better and cleaner option is.</p>



<p>And if we finally let the market work freely, after more than a century of both <a href="https://www.motherjones.com/politics/2014/04/oil-subsidies-energy-timeline/">direct</a> and <a href="https://en.wikipedia.org/wiki/Tragedy_of_the_commons">implicit</a> oil subsidies that have coddled this <a href="https://www.npr.org/2021/07/01/1012138741/exxon-lobbyist-caught-on-video-talks-about-undermining-bidens-climate-push">lying</a>, <a href="https://www.nrdc.org/stories/fossil-fuel-air-pollution-kills-one-five-people">deadly</a> industry, we could finally see it spiral into the oblivion it deserves.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Problem with Jon Stewart cancellation highlights a problem for Apple content (104 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2023/10/report-apple-cancels-the-problem-with-jon-stewart-over-china-ai-topics/</link>
            <guid>37966643</guid>
            <pubDate>Sat, 21 Oct 2023 13:28:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2023/10/report-apple-cancels-the-problem-with-jon-stewart-over-china-ai-topics/">https://arstechnica.com/gadgets/2023/10/report-apple-cancels-the-problem-with-jon-stewart-over-china-ai-topics/</a>, See on <a href="https://news.ycombinator.com/item?id=37966643">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      The Weekly Show    —
</h4>
            
            <h2 itemprop="description">The problem with Jon Stewart seems to be that he could land Apple in hot water.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/10/The-Problem-with-Jon-Stewart-2-800x470.png" alt="Jon Stewart holds up a pen as he makes a point at his dsek">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2023/10/The-Problem-with-Jon-Stewart-2.png" data-height="830" data-width="1414">Enlarge</a> <span>/</span> Jon Stewart on his Apple TV show.</p><p>Apple</p></figcaption>  </figure>

  




<!-- cache hit 1017:single/related:2f1d48c3ca09fba499be7fbde4a53ce0 --><!-- empty -->
<p>Jon Stewart and his weekly talk show <em>The Problem with Jon Stewart</em> are out at Apple, according to reports from <a href="https://www.nytimes.com/2023/10/19/business/media/jon-stewart-the-problem-ends.html">The New York Times</a> and <a href="https://variety.com/2023/tv/news/jon-stewart-the-problem-canceled-season-3-apple-tv-1235762554/">Variety</a>. Apple canceled the show just weeks before its third season began taping. Its cancellation sheds some light on the conflict of priorities Apple faces as it leans more into content rather than just selling tools, platforms, and gadgets.</p>
<p>The New York Times article cites "several people with knowledge of the situation," saying that staffers working on the show were told at the end of the day Thursday that it would not move forward.</p>
<p>The reason for the shift? Stewart and Apple executives "had disagreements over some of the topics and guests," the sources said. Specifically, they claimed Stewart told staffers that Apple execs took issue with planned programming related to both China and artificial intelligence, and noted that with the 2024 US election coming up, there might have been additional opportunities for disagreement then.</p>
<p>Apple does much of its business (both in production and sales) in China and has invested heavily in the country's infrastructure. Regarding China, Apple execs may have been worried that Stewart's planned commentary could alienate customers or partners in the country.</p>                                            
                                                        
<p>As for AI, Apple has increasingly focused on AI for software features on the iPhone. Primarily, it uses machine learning to drive things like search suggestions, photography, and palm detection. There have also been rumors that Apple plans to get into ChatGPT-like <a href="https://arstechnica.com/information-technology/2023/10/ted-ai-2023-a-historic-symposium-on-benefits-risks-and-applications-of-ai/">large language models, which have been more controversial.</a></p>
<p>We're just engaging in informed speculation about the specific reasoning, though; Apple declined to comment on the NYT story.</p>
<p>The show's cancellation is indicative of the kinds of challenges owners of platforms (like Apple, Amazon, Google, and others) face when they are producing content, too. Apple TV+, the iPhone, and other Apple products are used by a wide range of people, and investing in content that may be contentious for key customers or partners could create big problems for the company's overall business.</p>
<p>It's also part of a larger pattern of streaming services struggling with the talk show format. There have been numerous attempts, but most (talk shows like Netflix's <em>Norm Macdonald has a Show</em>) have not been hugely successful—in part because the business model of streaming TV is as much about the long-term value of content as it is about timeliness, and talk shows tend to focus on topics du jour.</p>
<p><em>The Problem with Jon Stewart</em> was Stewart's first return to hosting a TV show since his much-praised and widely watched tenure on <em>The Daily Show</em> ended in 2015. Stewart has not yet announced any future television plans.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Pixel 8 Pro's Tensor G3 off-loads all generative AI tasks to the cloud (199 pts)]]></title>
            <link>https://www.notebookcheck.net/MrWhosetheboss-video-reveals-Google-s-Pixel-8-Pro-Tensor-G3-off-loads-all-generative-AI-tasks-to-the-cloud.760215.0.html</link>
            <guid>37966569</guid>
            <pubDate>Sat, 21 Oct 2023 13:14:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.notebookcheck.net/MrWhosetheboss-video-reveals-Google-s-Pixel-8-Pro-Tensor-G3-off-loads-all-generative-AI-tasks-to-the-cloud.760215.0.html">https://www.notebookcheck.net/MrWhosetheboss-video-reveals-Google-s-Pixel-8-Pro-Tensor-G3-off-loads-all-generative-AI-tasks-to-the-cloud.760215.0.html</a>, See on <a href="https://news.ycombinator.com/item?id=37966569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="c10363088"><figure><a href="https://www.notebookcheck.net/fileadmin/_processed_/3/3/csm_IMG_0003_d19336e9c2.jpg" title="Google and its Pixel 8 Pro are at the center of another controversy. (Source: Notebookcheck)" data-fancybox="news_intro_image" data-caption="Google and its Pixel 8 Pro are at the center of another controversy. (Source: Notebookcheck)" data-title-id="lightbox_title_news_intro_image"><picture><source srcset="https://www.notebookcheck.net/fileadmin/_processed_/webp/Notebooks/News/_nc3/IMG_0003-q82-w240-h.webp 1x, https://www.notebookcheck.net/fileadmin/_processed_/webp/Notebooks/News/_nc3/IMG_0003-q82-w480-h.webp 2x" type="image/webp"><img src="https://www.notebookcheck.net/fileadmin/_processed_/3/3/csm_IMG_0003_82337d91e4.jpg" loading="lazy" width="240" height="309" alt="Google and its Pixel 8 Pro are at the center of another controversy. (Source: Notebookcheck)"></picture></a><figcaption>Google and its Pixel 8 Pro are at the center of another controversy. (Source: Notebookcheck)</figcaption></figure><div><p>Popular YouTuber @Mrwhosetheboss has singled out the Google Tensor G3 as a major failing of the Pixel 8 Pro. According to the YouTuber, all of the new generative AI features found on the Pixel 8 Pro cannot be processed onboard the device, but need to be off-loaded to the cloud for processing, despite Google pitching the device as being “AI-first.”</p></div></div><div id="c10363087">
<p>The Google Pixel 8 Pro has had a rockier launch than has been typical for the flagship series. Last year’s Pixel 7 Pro won a few high-profile YouTuber “Phone of the Year” awards, including from Arun Maini, who is better known by his handle of @Mrwhosetheboss. While Maini awarded the <a href="https://www.notebookcheck.net/Google-Pixel-7-Pro-review-Premium-smartphone-with-stock-Android.669256.0.html" target="_self">Pixel 7 Pro </a>his gong for “Best Smartphone of 2022”, he hasn’t been quite so effusive in his praise for the <a href="https://www.notebookcheck.net/Google-Pixel-8-Pro-starts-at-US-999-with-2-400-nit-display-new-48-MP-ultra-wide-angle-camera-and-free-Pixel-Watch-2-with-pre-orders.757289.0.html" target="_self">Pixel 8 Pro</a>. </p>
<p>There are many aspects of the Pixel 8 series that Maini praises in his latest video, including its design, the frosted glass finish on the rear of the Pixel 8 Pro, and its advanced software. He also praises the still photo capabilities of the devices, as well as new AI-powered features like Best Photo, Magic Editor and Audio Magic Eraser. However, Maini is less than complimentary about the janky way the Pixel 8 Pro handles zoom when transitioning between lenses, and its artificial-looking video stabilization. But his biggest criticism of the Pixel 8 series is reserved for the <a href="https://www.notebookcheck.net/Google-Tensor-G3-Pixel-8-Pro-fails-to-outperform-its-predecessor-in-Genshin-Impact.759422.0.html" target="_self">Tensor G3</a> processor. </p>
<p>Maini highlights how the new generative AI features including AI wallpaper and Magic Editor, for example, need a permanent internet connection as these require more processing power than the Tensor G3 SoC can deliver. As Maini explains:</p><blockquote><p>For all of this generative AI stuff, for anything that actually has to use AI to create things like the AI Wallpaper making, the Magic Editor needs a permanent internet connection. [This is] because every action you take needs to be passed through Google’s servers…It feels so sluggish, that you are constantly reminded that it's not running on-device…It really makes you realize that the Tensor G3 chip inside this phone is not quite flagship level.</p></blockquote><p>Maini’s observations run contrary to Google’s marketing which touts the AI processing capabilities of the Tensor G3 as being “AI-first.” In an official blog, Monika Gupta, Google VP of Product Management makes the following claims about the Tensor G3:</p><blockquote><p>This past year we’ve seen incredible AI breakthroughs and innovations — but a lot of those are built on the kind of compute power only available in a data center. To bring the transformative power of AI to your everyday life, we need to make sure you can access it from the device you use every day. That's why we're so excited that the latest Pixel phone features our latest custom silicon chip: Tensor G3. </p>
<p>Our third-generation Google Tensor G3 chip continues to push the boundaries of on-device machine learning, bringing the latest in Google AI research directly to our newest phones: Pixel 8 and Pixel 8 Pro. </p>
<p>Our work with Tensor has never been about speeds and feeds, or traditional performance metrics. It’s about pushing the mobile computing experience forward. And in our new Tensor G3 chip, every major subsystem has been upgraded, paving the way for on-device generative AI. It includes the latest generation of Arm CPUs, an upgraded GPU, new ISP and Imaging DSP and our next-gen TPU, which was custom-designed to run Google’s AI models.</p></blockquote><p>Not only does Google’s account of the importance of both what the Tensor G3 claims to be able to accomplish apparently clash with the reality of how the Pixel 8 Pro is actually handling generative AI tasks, its claims about the unimportance of performance metrics do not stack up with Arm’s own account of the central its CPUs and GPUs play in processing AI tasks – these are not solely handled by the TPU (Tensor Processing Unit), as Google infers in its blog. </p>
<p>On its website, Arm <a href="https://www.arm.com/markets/artificial-intelligence/machine-learning" target="_blank">explains</a>&nbsp;why its CPUs and GPUs (such as those used in the Tensor G3) are critical in performing AI tasks on device:</p><blockquote><p> As AI compute moves from the cloud to where the data is gathered, Arm CPU and MCU (Micro Controller Unit) technologies are already handling the majority of AI and ML workloads at the edge and endpoints. The CPU is central to all AI systems, whether it’s handling the AI entirely or partnering with a co-processor, such as a GPU or an NPU for certain tasks.</p></blockquote><p>As we covered exclusively earlier this week, in an extraordinary move, Google went out of its way to <a href="https://www.notebookcheck.net/Google-blocked-Pixel-8-Pixel-8-Pro-reviewers-from-using-popular-benchmarks-to-test-the-Tensor-G3-chip-new-owners-too.759260.0.html" target="_self">block reviewers</a> from being able to easily install popular benchmark apps through its Play Store during the review embargo period. This actually also extended into the post-launch period too, however <a href="https://www.notebookcheck.net/Google-Pixel-8-Pixel-8-Pro-benchmark-block-lifted.759613.0.html" target="_self">Google lifted the ban</a> after our article went live. Tests using Primate Labs’ popular cross-platform benchmark <i>Geekbench 6</i> <a href="https://www.notebookcheck.net/Google-Pixel-8-Pro-and-Tensor-G3-appear-on-Geekbench-ahead-of-launch-with-disappointing-CPU-scores.756901.0.html" target="_self">showed</a> that - despite having quite new CPU architecture - Tensor G3 performance is closer to the mid-range Qualcomm <a href="https://www.notebookcheck.net/Qualcomm-Snapdragon-7-Gen-2-Processor-Benchmarks-and-Specs.750396.0.html" target="_blank">Snapdragon 7+ Gen 2</a> than it is to its current flagship chip the <a href="https://www.notebookcheck.net/Qualcomm-Snapdragon-8-Gen-2-Processor-Benchmarks-and-Specs.670032.0.html" target="_self">Snapdragon 8 Gen 2</a>. </p>
<p><b>Update:</b> We've recorded a couple of short clips confirming that a persistent internet connection to enable cloud-based processing is indeed required for the new Pixel 8 Pro AI features including Magic Editor and AI Wallpaper. </p>
<p><a href="https://www.amazon.com/Google-Pixel-Pro-Smartphone-Telephoto/dp/B0CGTJ12Z9?tag=notebookcheck-20" target="_blank">Purchase the Google Pixel 8 Pro 128GB from Amazon starting from $999</a>.</p></div><div itemscope="" itemtype="http://schema.org/Person" rel="author"><div><a href="https://www.notebookcheck.net/Notebookcheck-Team.212978.0.html?&amp;tx_nbc2journalist_pi1%5Bmode%5D=show&amp;tx_nbc2journalist_pi1%5Buid%5D=230"><picture><source srcset="https://www.notebookcheck.net/fileadmin/_processed_/6/e/csm_San_sathiah_9451ededa5.png 1x, https://www.notebookcheck.net/fileadmin/_processed_/6/e/csm_San_sathiah_4165f56c18.png 2x"><img src="https://www.notebookcheck.net/fileadmin/_processed_/6/e/csm_San_sathiah_9451ededa5.png" loading="lazy" width="120" height="120" alt="Sanjiv Sathiah"></picture></a></div><p><a href="https://www.notebookcheck.net/Notebookcheck-Team.212978.0.html?&amp;tx_nbc2journalist_pi1%5Bmode%5D=show&amp;tx_nbc2journalist_pi1%5Buid%5D=230">Sanjiv Sathiah</a> - Senior Tech Writer <span title="1413&nbsp;"> - 1413 articles published on Notebookcheck</span> since 2017</p><p>I have been writing about consumer technology over the past ten years, previously with the former MacNN and Electronista, and now Notebookcheck since 2017. My first computer was an Apple ][c and this sparked a passion for Apple, but also technology in general. In the past decade, I’ve become increasingly platform agnostic and love to get my hands on and explore as much technology as I can get my hand on. Whether it is Windows, Mac, iOS, Android, Linux, Nintendo, Xbox, or PlayStation, each has plenty to offer and has given me great joy exploring them all. I was drawn to writing about tech because I love learning about the latest devices and also sharing whatever insights my experience can bring to the site and its readership.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Refactoring has a price, not refactoring has a cost (145 pts)]]></title>
            <link>https://www.germanvelasco.com/blog/refactoring-is-a-habit</link>
            <guid>37966485</guid>
            <pubDate>Sat, 21 Oct 2023 13:02:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.germanvelasco.com/blog/refactoring-is-a-habit">https://www.germanvelasco.com/blog/refactoring-is-a-habit</a>, See on <a href="https://news.ycombinator.com/item?id=37966485">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p>I recently heard this phrase:</p>

<blockquote>
  <p>Good habits have a price. Bad habits have a cost. Either way, you pay.</p>
</blockquote>

<p>That is a great life lesson. But it’s also a great lesson for our team and
codebase.</p>

<p>Refactoring is a good habit.</p>

<p>I’m talking about refactoring as <a href="https://www.germanvelasco.com/blog/finding-the-time-to-refactor#thinking-differently">test-driven development (TDD) defines it</a> – something you do with every test and feature. I’m not talking about
pausing feature work for a month so we can do refactoring.</p>

<p>In TDD, we refactor as the third step of the red-green-refactor cycle:</p>

<ul>
  <li>Red: write a test that fails</li>
  <li>Green: get the test to pass</li>
  <li>Refactor: clean up the changes. Improve design.</li>
</ul>

<p><img src="https://www.germanvelasco.com/images/red-green-refactor-def-done.png" alt="Red points to green. Work isn't done. Green points to refactor. Now work is done. Refactor points back to red."></p>

<p>Many developers think our work is done when the code “works” (when we get to green).
After all, the tests pass. So, we’re good, right?</p>

<p>I think that misses an amazing opportunity to improve our codebase!</p>

<p>The work is not done when the code works. The work is done when the code works
<em>and</em> when we’ve made sure the changes are designed well. And to do that, we
need to refactor.</p>

<p>Of course, refactoring after every feature has a price – just like good habits.
It takes time and discipline. But people erroneously think that the alternative
is free – that <em>not</em> refactoring has no cost.</p>

<p>Yet, if we don’t refactor continuously, we eventually have to pay the cost.</p>

<p>That cost is likely imperceptible at first. So, we carry on without refactoring.
Our codebase atrophies day by day, feature by feature, every change seemingly
not affecting the whole.</p>

<p>But one day all the cruft calcifies, and the numerous incompatible changes and
features grind our progress to a halt. It is <em>suddenly</em> impossible to add new
features without breaking something else. Bugs come up faster than we can squash
them. And every feature takes longer and longer to ship as we have to verify
that nothing is breaking.</p>

<p>The cost of our bad habit accumulates until we cannot foot the bill. That’s when
we throw in the towel, declare code bankruptcy, and call for the “great
rewrite”.</p>

<p>We either refactor continuously as we build features – paying the price. Or we
slowly accumulate cruft until our codebase is impossible to change – paying the
cost.</p>

<p>Either way, you pay.</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It takes 12 people to use the 18k Sphere camera (126 pts)]]></title>
            <link>https://petapixel.com/2023/10/20/darren-aronofsky-says-it-takes-12-people-to-use-the-18k-sphere-camera/</link>
            <guid>37966367</guid>
            <pubDate>Sat, 21 Oct 2023 12:45:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://petapixel.com/2023/10/20/darren-aronofsky-says-it-takes-12-people-to-use-the-18k-sphere-camera/">https://petapixel.com/2023/10/20/darren-aronofsky-says-it-takes-12-people-to-use-the-18k-sphere-camera/</a>, See on <a href="https://news.ycombinator.com/item?id=37966367">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><img data-perfmatters-preload="" decoding="async" fetchpriority="high" src="https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera.jpg" alt="Sphere Camera Darren Aronofsky" width="1600" height="840" srcset="https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera.jpg 1600w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-320x168.jpg 320w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-800x420.jpg 800w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-1536x806.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-150x79.jpg 150w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-300x157.jpg 300w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-400x209.jpg 400w, https://petapixel.com/assets/uploads/2023/10/aronofsky-big-sky-camera-550x288.jpg 550w" sizes="(max-width: 1600px) 100vw, 1600px"></p> <p>The music and entertainment arena <a href="https://petapixel.com/2023/06/12/sphere-studios-big-sky-cinema-camera-features-an-insane-18k-sensor/" data-wpel-link="internal">Sphere</a> opened in September in Las Vegas and the striking venue is the largest spherical building in the world. It features the world’s biggest and highest-resolution screens and its content is captured using a <a href="https://petapixel.com/2023/06/12/sphere-studios-big-sky-cinema-camera-features-an-insane-18k-sensor/" data-wpel-link="internal">state-of-the-art 18K cinema camera</a>. </p>  <p>Acclaimed filmmaker Darren Aronofsky used the remarkable camera to create his new movie, <em>Postcard From Earth</em>, which is now playing at Sphere. <a href="https://petapixel.com/2023/06/12/sphere-studios-big-sky-cinema-camera-features-an-insane-18k-sensor/" data-wpel-link="internal">As <em>Screen Rant</em> describes</a>, Aronofsky’s new film is a “technical marvel.” </p> <p>In a recent appearance on <em>Late Night With Seth Meyers</em>, Aronofsky discussed <em>Postcard From Earth</em>, including some remarkable behind-the-scenes information. Among the fascinating details Aronofsky discusses is that the 18K camera he used requires about a dozen people to operate, including moving it and keeping it from overheating. </p> <div><p><iframe src="https://www.youtube.com/embed/9WUehJrAekw?si=jFeieB3nsR885-3d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p></div> <p>Aronofsky’s 18K resolution film plays back at Sphere at a blistering-fast 60 frames per second, more than twice the speed of the typical 24p motion picture, and is about half a petabyte in size, or about 500 terabytes. Aronofsky explains that the movie is about 32GB of data per second, or nearly 2,000 GB a minute. </p> <p><img decoding="async" src="https://petapixel.com/assets/uploads/2023/10/BBB4994.jpg" alt="Sphere Camera Darren Aronofsky" width="1600" height="1067" srcset="https://petapixel.com/assets/uploads/2023/10/BBB4994.jpg 1600w, https://petapixel.com/assets/uploads/2023/10/BBB4994-320x213.jpg 320w, https://petapixel.com/assets/uploads/2023/10/BBB4994-800x534.jpg 800w, https://petapixel.com/assets/uploads/2023/10/BBB4994-1536x1024.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/BBB4994-450x300.jpg 450w, https://petapixel.com/assets/uploads/2023/10/BBB4994-300x200.jpg 300w, https://petapixel.com/assets/uploads/2023/10/BBB4994-120x80.jpg 120w" sizes="(max-width: 1600px) 100vw, 1600px"></p>
<p>Beyond the technical challenges, working with never-before-seen technology also presents artistic challenges. Aronofsky worked on a project for a wholly unique venue that he had not even been able to see in person. He didn’t see Sphere until August, the month before it opened. </p> <p>Seeing the 18K creation for the first time on the world’s most gargantuan screen was a spectacular experience. </p> <p>“It was great. It was what we were hoping for. So, no one had ever seen it, so we didn’t really know what they would respond. And then this moment happened. I actually didn’t know that jaw-dropping was a real thing. You hear that word, but it’s fun to look around, and people are just like, their jaws are literally dropped, and they’re all pointing at different places on the screen. So it’s a joy to have audiences go along for that trip,” Aronofsky says to Meyers. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment.jpg" alt="Sphere Camera Darren Aronofsky" width="1600" height="1067" srcset="https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment.jpg 1600w, https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment-320x213.jpg 320w, https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment-800x534.jpg 800w, https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment-1536x1024.jpg 1536w, https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment-450x300.jpg 450w, https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment-300x200.jpg 300w, https://petapixel.com/assets/uploads/2023/10/BigSky_1-Credit-Sphere-Entertainment-120x80.jpg 120w" sizes="(max-width: 1600px) 100vw, 1600px"></p> <p>“The venue will house the world’s highest resolution LED screen: a 160,000 square-foot display plane that will wrap up, over, and behind the audience at a resolution over 80 times that of a high-definition television with approximately 17,500 seats and a scalable capacity up to 20,000 guests. While the facility for viewing these immersive experiences sounds impressive on its own, it leaves one wondering what kind of cameras and equipment are needed to capture the content that gets played there,” <em><a href="https://petapixel.com/2023/06/12/sphere-studios-big-sky-cinema-camera-features-an-insane-18k-sensor/" data-wpel-link="internal">PetaPixel</a></em><a href="https://petapixel.com/2023/06/12/sphere-studios-big-sky-cinema-camera-features-an-insane-18k-sensor/" data-wpel-link="internal"> wrote about Sphere earlier this year</a>. </p> <p><img decoding="async" loading="lazy" src="https://petapixel.com/assets/uploads/2023/06/Sphere-Skyline-2-Credit-Sphere-Entertainment.jpg" alt="" width="1500" height="844" srcset="https://petapixel.com/assets/uploads/2023/06/Sphere-Skyline-2-Credit-Sphere-Entertainment.jpg 1500w, https://petapixel.com/assets/uploads/2023/06/Sphere-Skyline-2-Credit-Sphere-Entertainment-320x180.jpg 320w, https://petapixel.com/assets/uploads/2023/06/Sphere-Skyline-2-Credit-Sphere-Entertainment-800x450.jpg 800w" sizes="(max-width: 1500px) 100vw, 1500px"></p> <p>The 18K camera Aronofsky describes, dubbed Big Sky, features a 316-megapixel HDR image sensor three by three inches in size. That is a 40x resolution increase compared to 4K cameras. For a detailed dive into this remarkable camera, make sure to <a href="https://petapixel.com/2023/06/12/sphere-studios-big-sky-cinema-camera-features-an-insane-18k-sensor/" data-wpel-link="internal">read <em>PetaPixel</em>‘s exclusive coverage</a> from earlier this year.</p>
<p>Aronofsky will not be the only talented filmmaker to get their hands on the camera, and it will be incredible to see how visual artists take advantage of the camera and the one-of-a-kind venue, Sphere. <em>Postcard From Earth</em> will play exclusively at Sphere for two years. </p> <hr> <p><em><strong>Image credits:</strong> Sphere Studios, MSG. Image of Darren Aronofsky licensed via <a href="https://depositphotos.com/" rel="nofollow external noopener" data-wpel-link="external" target="_blank">Depositphotos</a>.</em></p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google cuts dozens of jobs in news division (111 pts)]]></title>
            <link>https://www.cnbc.com/2023/10/18/google-cuts-dozens-of-jobs-in-news-division-.html</link>
            <guid>37965564</guid>
            <pubDate>Sat, 21 Oct 2023 10:21:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/10/18/google-cuts-dozens-of-jobs-in-news-division-.html">https://www.cnbc.com/2023/10/18/google-cuts-dozens-of-jobs-in-news-division-.html</a>, See on <a href="https://news.ycombinator.com/item?id=37965564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-107186646" data-test="InlineImage"><p>Google headquarters in Mountain View, California, on Jan. 30, 2023.</p><p>Marlena Sloss | Bloomberg | Getty Images</p></div><div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/GOOG/">Google</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> cut dozens of jobs in its news division this week, CNBC has learned, downsizing at a particularly sensitive time for online platforms and publishers. </p><p>An estimated 40 to 45 workers in Google News have lost their jobs, according to an Alphabet Workers Union spokesperson, who didn't know the exact number.</p></div><p>A Google spokesperson confirmed the cuts but didn't provide a number, and said there are still hundreds of people working on the news product.</p><p>"We're deeply committed to a vibrant information ecosystem, and news is a part of that long-term investment," the spokesperson said. "We've made some internal changes to streamline our organization. A small number of employees were impacted. We're supporting everyone with a transition period, outplacement services and severance as they look for new opportunities at Google and beyond."</p><p>Google News presents links to articles from thousands of publishers and magazines. It's a popular tab for people who use Google search, allowing them to find top-ranked stories on a particular topic.</p><p>The layoffs come amid a <a href="https://www.cnbc.com/2023/10/19/israel-hamas-war-gaza-live-updates-latest-news.html">war between Israel and Hamas</a> that has claimed thousands of lives in both Israel and Gaza since Oct. 7, and 20 months after Russia invaded Ukraine. Both wars have spawned a surge in the spread of misinformation across the web, heightening the importance of Google and other sites that users count on to find up-to-date news.</p></div><div id="Placeholder-ArticleBody-Video-107185555" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000283302" aria-labelledby="Placeholder-ArticleBody-Video-107185555"><p><img src="https://image.cnbcfm.com/api/v1/image/107185556-GettyImages-1244644880.jpg?v=1682592778&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Is the bubble bursting for tech workers?"><span></span><span></span></p></div><div><p>Sen. Michael Bennet, D-Colo., on Tuesday <a href="https://www.reuters.com/technology/us-lawmaker-seeks-answers-meta-x-google-tiktok-over-israel-hamas-false-content-2023-10-17/" target="_blank">asked</a> for information on how Google; X, formerly known as Twitter; <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-4"><a href="https://www.cnbc.com/quotes/META/">Meta</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>; and TikTok were trying to stop the spread of false and misleading content about the Israel-Hamas conflict on their platforms.</p><p>European Union industry chief Thierry Breton <a href="https://www.cnbc.com/2023/10/11/europe-gives-zuckerberg-24-hours-to-respond-about-israel-hamas-misinfo.html">demanded</a> that companies, including Google, take stricter steps to battle disinformation as the conflict escalates. Breton specifically <a href="https://x.com/ThierryBreton/status/1712866215591379259?s=20" target="_blank">addressed</a> letters to Google CEO <a href="https://www.cnbc.com/sundar-pichai/">Sundar Pichai</a> and YouTube CEO Neal Mohan, reminding them of the content moderation requirements under the EU's Digital Services Act.</p><p>Google's spokesperson said, "These internal changes have no impact on our misinformation and information quality work in News."</p><p>Some tech companies said they've <a href="https://www.axios.com/2023/10/17/social-media-israel-hamas" target="_blank">staffed up</a> on content moderators as they scramble to battle misinformation.</p><p>Meanwhile, Canada and other countries are eyeing laws that would force tech platforms to compensate publishers for their work.</p><p>The cuts in Google News follow widespread layoffs across many parts of the company this year. In January, Google <a href="https://www.cnbc.com/2023/01/20/google-to-lay-off-12000-people-memo-from-ceo-sundar-pichai-says.html">announced</a> it was cutting 12,000 jobs, affecting roughly 6% of the full-time workforce. Last month, the company <a href="https://www.cnbc.com/2023/09/13/google-is-cutting-hundreds-of-jobs-in-its-recruiting-organization.html">eliminated hundreds</a> of positions from its recruiting organization.</p><p>A staff engineer at Google News <a href="https://www.linkedin.com/posts/robruenes_googlelayoffs-activity-7120150535122415617-Fo_g?utm_source=share&amp;amp;utm_medium=member_desktop" target="_blank">wrote</a> a post on LinkedIn on Tuesday regarding the layoffs.</p><p>"These are some of the best and brightest people I've ever worked with," the person wrote. "We're definitely worse off without them."</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2023/10/04/google-is-the-magnificent-seven-stock-that-has-the-best-catalyst-says-deepwaters-doug-clinton.html">Google is the 'Magnificent Seven' stock that has the best catalyst</a></p></div><div id="Placeholder-ArticleBody-Video-107311362" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000317796" aria-labelledby="Placeholder-ArticleBody-Video-107311362"><p><img src="https://image.cnbcfm.com/api/v1/image/107311363-16964279221696427917-31456107030-1080pnbcnews.jpg?v=1696428449&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Google is the 'Magnificent Seven' stock that has the best catalyst, says Deepwater's Doug Clinton"><span></span><span></span></p></div><div><p><em>Don't miss these CNBC PRO stories:</em></p><ul><li><a href="https://www.cnbc.com/2023/10/09/this-bank-just-hiked-its-1-year-cd-rate-to-a-fresh-high.html"><em>This bank just hiked its 1-year CD rate to a fresh high</em></a></li><li><a href="https://www.cnbc.com/2023/10/16/a-low-cost-way-to-protect-against-an-sp-500-drawdown-as-risks-escalate.html"><em>A low-cost way to protect against an S&amp;P 500 drawdown as risks escalate</em></a></li><li><a href="https://www.cnbc.com/2023/10/09/how-to-invest-1-million-for-the-next-decade-according-to-the-pros.html"><em>How to invest $1 million for the next decade, according to private bankers and wealth advisors</em></a></li><li><a href="https://www.cnbc.com/2023/10/15/this-highly-profitable-industry-is-booming-as-the-population-ages.html"><em>This highly profitable industry is booming as the population ages</em></a></li><li><a href="https://www.cnbc.com/2023/10/11/bank-of-america-sees-risks-for-employers-as-insurance-coverage-of-weight-loss-drugs-grows.html"><em>Bank of America sees risks for employers as insurance coverage of weight loss drugs grows</em></a></li></ul></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We Built a Streaming SQL Engine (110 pts)]]></title>
            <link>https://www.epsio.io/blog/how-to-create-a-streaming-sql-engine</link>
            <guid>37965319</guid>
            <pubDate>Sat, 21 Oct 2023 09:26:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.epsio.io/blog/how-to-create-a-streaming-sql-engine">https://www.epsio.io/blog/how-to-create-a-streaming-sql-engine</a>, See on <a href="https://news.ycombinator.com/item?id=37965319">Hacker News</a></p>
<div id="readability-page-1" class="page"><div fs-codehighlight-element="code"><p>So you probably wake up every morning asking yourself three of life’s most pertinent questions- how do I build a streaming SQL engine, what even is a streaming SQL engine, and can our Lord drop tables owned by another user.</p><p>I too found myself asking these questions, sometimes even dreaming about them- often in the form of various SQL operators pointing and laughing at my incompetence as I beg them to answer me.</p><p>And so, a year ago, I (quite bravely if I may say so myself) packed my bags and set off on the long and treacherous journey to find answers to these questions. I went from monk to priest to spaghetti-enthusiast, shocked to find themselves concerned with paltry questions such as the Meaning of Life and how to find peace within oneself. But eventually, desolate in the deepest pits of my mind, I happened by a small temple by the name of “Epsio Labs”- a feeling of tremendous revelation came over me, and I walked in.</p><p>Friends, &nbsp;today I will share with you the secrets I have found there (despite the numerous NDAs).</p><h3>What is a Streaming SQL Engine? </h3><p>A streaming SQL engine keeps queries’ results up to date without ever having to recalculate them, even as the underlying data changes. To explain this, imagine a simple query, such as [.code]SELECT count(*) FROM humans[.code] . A normal SQL engine (such as Postgres’s, MySQL’s) would need to go over all the different [.code]humans[.code] every time you ran that query- which could be quite costly and lengthy given our ever changing population count. With a streaming SQL engine, you would define that query once, and the engine would constantly keep the resulting count up to date as new humans were born and the old / sickly ones died off, without ever performing a recalculation of counting all humans in the world.</p><h3>How to build a Streaming SQL engine</h3><p>For the simple example above, you may have an idea of how a streaming SQL engine could work- first, you would need to do what any normal SQL engine does and calculate the number of humans. Next, every time a human was born you would add one to your result, and every time a human died you would negate one from your result. Easy, right? <br>Let’s try creating a diagram showing a procedural “query plan” and how we would process a new human being born. We’ll have a series of nodes, one for each operation, and a “final” node which will represent a table with our results. Since we’re a streaming engine and dealing with <em>changes</em>, we’ll represent the messages passed between our nodes as:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc235ada9046f67094e_1*5aMhkvO4eM58JPFXTEhWjQ.png" alt=""></p></figure><p>where the key is <em>what</em> we want to change, and the modification is <em>by how much we want to change it</em>. So for example, if we wanted to pass a message to a node telling it “Hey Mr. Node, 1.5 Apples have been added”, it would look like this:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc3c27ee72b296d5546_1*LZFOpfqt3sL7wEGY2w_bRw.png" alt=""></p></figure><p>Each node will be responsible for receiving changes, performing some type of operation, and then outputting changes itself. Another important concept here is that we can add modifications together if they have the same key. So the two changes [.code]apple: 1.5[.code] and [.code]apple: 2[.code] are equivalent to [.code]apple: 3.5[.code] . If the modifications equal zero together, &nbsp;it’s as if nothing at all happened- for example, if we have two changes [.code]apple: 3[.code] and [.code]apple: -3[.code] , it’s equivalent to not having streamed any changed (You can think of it as me giving you three apples, utterly regretting my kindness, then taking away your three apples. For you it would be as if nothing happened at all- aside from your broken pride). To make this make more sense, let’s draw out the nodes for our query ([.code]SELECT count(*) FROM humans[.code]), and add in the first human, Adam.</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc27e01a5c9472508c7_1*zt4KzYosgm0hVwkFGOdPLQ.png" alt=""></p></figure><p>As we can see, a new human named “Adam” was born. The “Counter” node, perhaps called for its ability to count, holds an internal state of the current count of humans in the world. Whenever it receives a <em>change </em> (an addition or deletion of a human), it updates its internal count, and then outputs relevant changes- in this case, only one change was necessary, telling the next node to add the number one (signifying the total number of humans) once. In this instance, the next node was the “Final Results Table”, an actual honest-to-god relational table (perhaps in Postgres). You can imagine every change translating to a [.code]DELETE[.code] or [.code]INSERT[.code] based on the key and modification.</p><p>Next, let’s add in Eve:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc380bf98de49954758_1*Et0FR_DFbqsyO1ZHbYMbig.png" alt=""></p></figure><p>This time, the counter node needed to output two changes- one to cancel out the previous change it outputted, and one two add the new updated value. Essentially, if we were to look at all the changes the Counter node outputted over time, we’d get:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc335ada9046f67096f_1*ILTxWLJS2WXoclOpluRxog.png" alt=""></p></figure><p>Since we’re allowed to combine changes with the same key, the above is equivalent to:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc2f278a961b5dc16bb_1*Vl1lYUw7hUMqKshsfYHv1w.png" alt=""></p></figure><p>A modification of zero means we can simply remove the change. Therefore, we’re left only with [.code]2: +1[.code] in the final result table- exactly what we wanted.</p><p>Are you starting to feel that sweet sweet catharsis? Ya, me too.</p><h3>A slightly more interesting example</h3><p>Let’s imagine we’re the devil and have two tables: <br>1. A “Human Table” that contains two columns, a unique identifier and their name.<br>2. An “Evil Table” that maps human ids to whether or not they are evil.</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe95502170aaeb31aa_1*1LF2yHSqNJErO5QdfQbFhA.png" alt=""></p></figure><p>Now, for obvious reasons, let’s say we wanted a count of evil humans per name:</p><div><pre><code>SELECT humans.name, count(*) FROM humans 
JOIN evil_humans ON humans.id = evil_humans.human_id 
WHERE is_evil IS true 
GROUP BY humans.name
</code></pre></div><p>To be able to create a query plan (a series of nodes) from this query, we’re going to need to introduce a few new types of nodes here.</p><h3>Filter Node</h3><p>A filter node filters a change by its <em>key</em>, regardless of its <em>modification</em>. If a change “passes” the filter, the filter outputs it as is. To really &nbsp;give you the feel of this, let’s diagram a filter node that passes only changes with keys that are equal to the word “cats”.</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebec27ee72b296f122e_1*7J3fvww666tGqp_Qyyeqdw.png" alt=""></p></figure><p>As we can see, we gave the filter node 3.4 cats and, astonishingly enough, it passed them on without changing a thing. Let’s try passing dogs through the filter node:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018f266674e22c868bb316_1*jNZQVsBrZD02qZ4qu-JC7A.png" alt=""></p></figure><p>Whoa! This time the filter did <strong>not </strong>pass anything on. I imagine you get the idea. Moving on.</p><h3>Joins</h3><p>A Join node is responsible for receiving changes from two nodes, and outputting changes whose “join keys” match. It does this by holding an internal state (all in storage) of all the changes that pass through it from both sides, mapped by their respective join keys. So in our example with</p><div><pre><code>JOIN evil_humans ON humans.id = evil_humans.human_id
</code></pre></div><p>we would create one Join node, with two mappings:<br>On the left side, for [.code]id[.code] to [.code]name[.code]<br>On the right side for [.code]human_id[.code] to [.code]is_evil[.code]</p><p>In practice, the mappings would look something like this:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebec4670ee9f714b5be_1*h8nyNBikQdp0qQHSetAaKg.png" alt=""></p></figure><p>Every time the Join node would receive a change from one of its sides, it would look on the other side for a matching key. If it found one, it would output the combined values. Let’s try drawing out a simple example where the Join node receives a new human named Tommy with id 232, and then a change saying id 232 is not evil. </p><p>First- a new human named Tommy enters the world:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe468f11e1755f4e84_1*_IvDajebrqy4gVIehKGFfw.png" alt=""></p></figure><p>Ok, we streamed a change that tells the Join node that Tommy (id 232) has been added. The Join node looks in its right mapping for a corresponding change for key 232, and finds none. It therefore outputs nothing; but<strong> </strong>it does update its <strong>internal mapping </strong>to reflect the fact Tommy has been added- this will help us when we do the following:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe14e8a9b48b1933e8_1*OEn-Ca9zMWbSNmxgK68-ug.png" alt=""></p></figure><p>Here, the Join node received a change from its <strong>right </strong>side telling it “id 232 is not evil”. The Join node then looked at its left mappings, found a corresponding change (232: Tommy- the change we just streamed before) and outputted the &nbsp;combined change.<br>But this is not the end of the Tommy saga- at any moment new changes could come in. Perhaps Tommy could fall down the steps and die. This would result in the Join receiving [.code]Tommy, 232: -1[.code], which would then have the Join node outputting [.code](232, Tommy, false): -1 [.code]— cancelling out the previous change the Join sent. Or perhaps Tommy could change in his evilness- we’ll keep that idea for an example down the line.</p><p> — -</p><p>Side note- you may have noticed we said “join key to change” but don’t actually keep the modification count in the join mapping. In the real world we do, and then multiply the modification counts of both sides to get the outputted modification count</p><p> — -</p><h3>Group Bys</h3><p>Our “Group By” node is very similar to the counter node we had before (in truth, they are one and the same wearing different hats- but that’s a tale for another time). The Group By node outputs aggregates per buckets- always ensuring that if you were to combine all changes it outputted, you would be left with at most one change per bucket (similar to how we took all the changes over time that came out of the Counter node, and saw that we’re left with only one as others cancel out). It does this by holding an internal mapping (in storage) between each bucket and its aggregated value. So in our example</p><div><pre><code>SELECT humans.name, count(*) ... GROUP BY humans.name
</code></pre></div><p>The Group By node would hold a mapping something like this:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe065142e778f10600_1*RvSq9RJxuwcHmkvv-bdP0w.png" alt=""></p></figure><p>Let’s try drawing out a simple example showing what would happen if we entered a new name the Group By node has never seen before:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/6501926e1795cee663813fa3_firstgroupby.png" loading="lazy" alt=""></p></figure><p>Ok, what happened here? The change coming into the Group By node tells the Group By node to add one to Richard. The Group By node looks in its internal mappings, and sees it has no entry for Richard. It adds an entry, and then outputs that the amount of Richards is one (this is the <em>key </em>of the change- [.code](Richard, 1)[.code] ). Let’s go ahead and add another two Richards:</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/650192a2c0b897576f5d779b_secondgroupby.png" loading="lazy" alt=""></p></figure><p>Slightly more interesting- the Group By node receives another change telling it to add two to Richard. The Group By node updates its internal state, and then outputs two changes- one to <strong>remove </strong>the previous change it outputted, and one to add a change with the new updated count of Richards.</p><h3>Putting it all together </h3><p>Back to our original query:</p><div><pre><code>SELECT humans.name, count(*) FROM humans 
JOIN evil_humans ON humans.id = evil_humans.human_id 
WHERE is_evil IS true 
GROUP BY humans.name
</code></pre></div><p>To set the stage for our upcoming example, &nbsp;imagine a young goody-two-shoes coder named Tommy, id 232 (you may remember him long ago from our explanation about the join). Tommy was a super cool dude who regularly downvoted mean people on StackOverflow (evilness=false). </p><p>One day, Tommy got kicked in the head by a horse, and as a direct result force pushed to master while deleting the CI. We’ll represent this occurrence with two changes- one to cancel out the old change saying Tommy wasn’t evil [.code](232, false): -1[.code] , and one to add in the new change saying he is evil [.code](232, true): +1[.code] :</p><figure><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/650192b21795cee663816f43_whoflow.png" loading="lazy" alt=""></p></figure><p>Let’s do a quick breakdown of what we see above- so we outputted the two changes we talked about [.code](232, false): -1[.code] and [.code](232, true): +1[.code] . The Join node receives it, looks on its other side (ids -&gt; names), finds a name (Tommy), and outputs the inputted changes together with the name “Tommy”. Next, the filter node [.code]WHERE is_evil IS true[.code] filters out the change [.code](232, false): -1[.code] , and, since its evil value is false, only outputs [.code](232, true): +1[.code] . The Group By node takes in this change, looks in its mappings, and sees there existed a previous entry for Tommy (while not a very evil name, I have met some mean Tommys in my life). The Group By node therefore sends out one change to remove the old change it sent out with [.code](Tommy, 7): +1[.code] (this happened in a previous addition of an evil Tommy). It then sends out another change introducing the new change to the Tommy count.</p><h3>Wait, but why go to all the trouble?</h3><p>So, now there are 8 Tommy’s in the world that are evil, and we didn’t need to rerun our query to calculate this. You may be thinking- well, Mr. Devil, you really didn’t need a streaming SQL engine to do that. If you had a humans table and evilness table, just create indexes on them. You’d still need to go over all the records each time queried, but at least the lookups would be quick. The Group By would still need to do everything from scratch, but at least…<br>So yes, it is possible to optimize queries so they run fairly quickly on the fly- up to a certain point. As more Joins, Group Bys, and (god forbid) WITH RECURSIVEs are added, it becomes more and more complex to optimize queries. And as more Tommys and Timmies and Edwards and Jennies (not to mention Ricardos and Samuels and Jeffries and Bennies) are added to our system, even those optimizations might begin to not be enough (and don’t even get me started on the evils of in-house caching). Streaming SQL engines are, to paraphrase a non-existent man, <em>totally badass, </em>and straight up solve this<em>.</em></p><h3>In Conclusion</h3><p>Feel ready to build a streaming engine? You definitely have the building blocks- but you’re missing a few major concepts here such as how to be consistent (to <em>never </em>output<em> </em>partial results), how to do this all with high throughput (in everlasting tension with latency), and how to interact well with storage (async-io anyone?). Maybe I’ll write another blog post, maybe not. </p><p>By the way, as for the Lord dropping a table owned by another user: it apparently comes down to if he uses RDS (on a self-hosted DB he’s a superuser, but on RDS nobody is. Yes, not even the Lord).</p><p>Since posting this article, the Elders at Epsio realized there’s no point to keeping their secrets so secret and published their streaming engine for the world to use- check out Epsio’s <em>blazingly fast </em>SQL engine <a href="https://www.epsio.io/" target="_blank">here</a>.</p></div><p>This is some text inside of a div block.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Town Repeatedly Surveilled Man's Yard with Drone Without a Warrant (108 pts)]]></title>
            <link>https://www.404media.co/town-surveilled-mans-yard-without-a-warrant/</link>
            <guid>37965297</guid>
            <pubDate>Sat, 21 Oct 2023 09:19:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.404media.co/town-surveilled-mans-yard-without-a-warrant/">https://www.404media.co/town-surveilled-mans-yard-without-a-warrant/</a>, See on <a href="https://news.ycombinator.com/item?id=37965297">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <article>
          <div>
                <div>
    <h5>Subscribe</h5>
    <div>
      <p>Join the newsletter to get the latest updates.</p>
      <form data-members-form="subscribe">
        
        
        <div>
          
          <p>
            Great! Check your inbox and click the link.
          </p>
        </div>
        <div>
          
          <p>
            Please enter a valid email address.
          </p>
        </div>
      </form>
    </div>
  </div>
<p>The Michigan Supreme Court heard a case Wednesday that will determine if it was legal under the Fourth Amendment for a local town to hire a drone company to repeatedly spy on the home of one of its residents without a warrant.&nbsp;</p><p>In the case, a man named Todd Maxon was storing and fixing up junked cars on his five-acre property in Long Lake Township in Michigan. Maxon and the township signed an agreement in 2008 that Maxon would not face any zoning action if he did not increase the number of cars he had on his property. In 2010, 2016, 2017, and 2018, the township hired a company called Zero Gravity Aerial to do aerial drone surveys of Maxon’s property to ensure he was complying with the settlement. The town filed a complaint against Maxon stating that he and his wife “significantly increased the scope of the junk cars and other junk material being kept on their property,” as determined by “aerial photographs.”</p><p>“The photographs reveal the existence of a number of trailers and trucks with enclosed beds, which, upon information and belief, are being used as storage by the Defendants,” the city wrote in its enforcement action. “These temporary storage structures violate the zoning ordinance because they are impermissible accessory buildings.”</p><figure><img src="https://www.404media.co/content/images/2023/10/Screenshot-2023-10-19-at-8.07.20-AM.png" alt="" loading="lazy" width="1556" height="730" srcset="https://www.404media.co/content/images/size/w600/2023/10/Screenshot-2023-10-19-at-8.07.20-AM.png 600w, https://www.404media.co/content/images/size/w1000/2023/10/Screenshot-2023-10-19-at-8.07.20-AM.png 1000w, https://www.404media.co/content/images/2023/10/Screenshot-2023-10-19-at-8.07.20-AM.png 1556w" sizes="(min-width: 720px) 720px"><figcaption><span>Todd Maxon</span></figcaption></figure><p>Court records reviewed by 404 Media show that the township hired Zero Gravity Aerial to specifically and repeatedly fly over Maxon’s property for the express purpose of proving he had violated the township’s ordinances. It’s particularly notable that the township did not get a warrant to do this and chose to contract with a commercial drone business to do surveillance, rather than work with local law enforcement or get permission from a judge.</p><p>“The approximately 10-acre area surrounding the property of Todd Maxon [address redacted] will be photographed and mapped to provide evidence for the purposes of code enforcement,” a <a href="https://ij.org/case/michigan-drone-surveillance/?ref=404media.co">proposal from Zero Gravity Aerial</a> reviewed by 404 Media reads. “Primary emphasis will be placed upon identification and documentation of vehicles, scrap, and other detritus located on the property. Digital imagery and GPS coordinates of the proposed area and in the surrounding areas will be recorded.”</p><p>Zero Gravity Aerial delivered “aerial photographs of the proposed property, Ground photographs taken from accessible nearby properties, and a finished orthomap of the proposed property,” according to the proposal, which was submitted as evidence. The company also documented each and every “item” on the property that had moved or been added and created an “inventory” of everything on his property, and was paid $1,200 for doing so.&nbsp;&nbsp;&nbsp;</p><figure><img src="https://www.404media.co/content/images/2023/10/Screenshot-2023-10-18-at-11.27.32-AM-1.png" alt="" loading="lazy" width="1636" height="1017" srcset="https://www.404media.co/content/images/size/w600/2023/10/Screenshot-2023-10-18-at-11.27.32-AM-1.png 600w, https://www.404media.co/content/images/size/w1000/2023/10/Screenshot-2023-10-18-at-11.27.32-AM-1.png 1000w, https://www.404media.co/content/images/size/w1600/2023/10/Screenshot-2023-10-18-at-11.27.32-AM-1.png 1600w, https://www.404media.co/content/images/2023/10/Screenshot-2023-10-18-at-11.27.32-AM-1.png 1636w" sizes="(min-width: 720px) 720px"><figcaption><span>A survey of items created by the city</span></figcaption></figure><p>Dennis Wiand, the owner of Zero Gravity Aerial, wrote an affidavit in which he said that while he was flying his “mission” over the Maxon’s property, he “did see Mr. Maxon walk out to his vehicle and look up at the drone.” He also stated that Maxon walked over to where he was piloting the drone and began to ask him what he was doing and that he “was interfering with my work.”&nbsp;</p><p>“Todd appeared to be frustrated and began to walk away and told me to ‘Go fuck yourself,’” Wiand noted.</p><p>Wiand told me in a phone call that this was the first survey of this type he had done. Wiand specializes in environmental monitoring, and in particular has expertise in flying over lakes to determine if invasive plant species have proliferated there.&nbsp;Wiand is not a party to the case and is not accused of any wrongdoing.</p><p>“I tried to help them solve a problem,” Wiand told me. “I was hired to gather data.”</p><div><p>💡</p><p><b><strong>Any drone surveillance stories I should know about? I would love to hear from you. Using a non-work device, you can message me securely on Signal at +1 202 505 1702. Otherwise, send me an email at jason@404media.co.</strong></b></p></div><p>To put this simply, and to put the specific legal questions at play aside for a moment: What the township did was dangerous for both Wiand and Maxon. People, generally, do not like when unknown drones fly over and surveil their property, and it is dumbfounding that a local government would hire a civilian commercial drone photographer to collect evidence for it in a legal proceeding of this nature, rather than having a town official or law enforcement officer do it. I have written about <a href="https://www.vice.com/en/article/xywjd3/the-skys-not-your-lawn-man-wins-lawsuit-after-neighbor-shotgunned-his-drone?ref=404media.co">numerous</a> instances of <a href="https://arstechnica.com/tech-policy/2020/05/minnesota-man-faces-felony-charges-for-shooting-down-drone/?ref=404media.co">homeowners</a> shooting <a href="https://www.airsight.com/en/news/man-arrested-for-shooting-down-drone-in-long-island-new-york?ref=404media.co">drones</a> down, getting into verbal and <a href="https://www.vice.com/en/article/xyww5d/this-kid-got-assaulted-for-flying-his-drone-on-a-beach?ref=404media.co">physical</a> <a href="https://www.vice.com/en/article/ezvwnk/a-national-parks-service-ranger-tased-a-man-flying-a-3-inch-toy-helicopter?ref=404media.co">altercations</a> with drone pilots, and things of this nature. Everyone is very lucky that no one got hurt.</p><figure><img src="https://www.404media.co/content/images/2023/10/Screenshot-2023-10-19-at-8.29.34-AM-1.png" alt="" loading="lazy" width="1428" height="1682" srcset="https://www.404media.co/content/images/size/w600/2023/10/Screenshot-2023-10-19-at-8.29.34-AM-1.png 600w, https://www.404media.co/content/images/size/w1000/2023/10/Screenshot-2023-10-19-at-8.29.34-AM-1.png 1000w, https://www.404media.co/content/images/2023/10/Screenshot-2023-10-19-at-8.29.34-AM-1.png 1428w" sizes="(min-width: 720px) 720px"><figcaption><span>A screenshot of the drone photography proposal.</span></figcaption></figure><p>Groups like the <a href="https://www.aclu.org/report/protecting-privacy-aerial-surveillance-recommendations-government-use-drone-aircraft?ref=404media.co">ACLU</a> and <a href="https://www.eff.org/deeplinks/2022/08/over-horizon-drones-lineup-privacy-not-sight?ref=404media.co">Electronic Frontier Foundation</a> have been warning that what happened to Maxon could happen for more than a decade. We are far past the original drone hype cycle, and there are now many police departments that use drones for surveillance, emergency response, and search-and-rescue. Many cities and states have highly specific rules for who can fly a drone on official government business, when they can fly it, and how that evidence can be used. Civil liberties experts are not always happy with these rules, but many jurisdictions have them nonetheless.&nbsp;</p><figure><img src="https://www.404media.co/content/images/2023/10/Screenshot-2023-10-18-at-11.27.41-AM.png" alt="" loading="lazy" width="1374" height="1232" srcset="https://www.404media.co/content/images/size/w600/2023/10/Screenshot-2023-10-18-at-11.27.41-AM.png 600w, https://www.404media.co/content/images/size/w1000/2023/10/Screenshot-2023-10-18-at-11.27.41-AM.png 1000w, https://www.404media.co/content/images/2023/10/Screenshot-2023-10-18-at-11.27.41-AM.png 1374w" sizes="(min-width: 720px) 720px"><figcaption><span>An accounting of every large item on the Maxon's property.</span></figcaption></figure><p>Michigan’s Supreme Court will now decide whether it was a Fourth Amendment violation for the township to surveil his property without a warrant, meaning it would be an unreasonable search and seizure. “We argue that both what the government did to the Maxon’s was an unconstitutional search, and that deliberate, repeated drone snooping like this can’t be excused, and you have to exclude that evidence if you don’t want an eye in the sky in everybody’s backyard,” Robert Frommer, an attorney with the Institute for Justice, who is representing Maxon in the case, told me.</p><p>The <a href="https://ij.org/wp-content/uploads/2022/10/164948_122_ac_brf-aclu.pdf?ref=404media.co">ACLU</a> and <a href="https://www.eff.org/deeplinks/2023/09/eff-michigan-court-governments-shouldnt-be-allowed-use-drone-spy-you-without?ref=404media.co">EFF</a> both filed supporting motions in which they argue that what happened was wildly inappropriate and illegal: “No one, anywhere, reasonably expects that their local government will deploy investigative cameras in the sky to repeatedly record their behavior on their own private property. Yet that is what happened in this case—and if the Township gets its way, it will not only profit from its privacy violations, but open the door to other local governments deploying cheap, pervasive, flying surveillance devices to surveil private property for the smallest of civil infractions. This Court should ensure that this is not the future in which Michiganders are consigned to live,” the ACLU wrote.&nbsp;</p><p>Long Lake Township did not respond to a request for comment.</p>
          </div>
        </article>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go Package for Building Progressive Web Apps (114 pts)]]></title>
            <link>https://go-app.dev</link>
            <guid>37965217</guid>
            <pubDate>Sat, 21 Oct 2023 08:59:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go-app.dev">https://go-app.dev</a>, See on <a href="https://news.ycombinator.com/item?id=37965217">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="declarative-syntax">Declarative Syntax</h2>

<p>Go-app uses a declarative syntax so you can <strong>write reusable component-based UI elements just by using the Go programming language</strong>.</p>

<pre><code>// A component that displays a Hello world by composing with HTML elements,
// conditions, and binding.
type hello struct {
	app.Compo

	name string
}

func (h *hello) Render() app.UI {
	return app.Div().Body(
		app.H1().Body(
			app.Text("Hello, "),
			app.If(h.name != "",
				app.Text(h.name),
			).Else(
				app.Text("World!"),
			),
		),
		app.P().Body(
			app.Input().
				Type("text").
				Value(h.name).
				Placeholder("What is your name?").
				AutoFocus(true).
				OnChange(h.ValueTo(&amp;h.name)),
		),
	)
}
</code></pre>

<h2 id="standard-http-server">Standard HTTP Server</h2>

<p>Serving an app built with go-app is done by using the <a href="https://golang.org/pkg/net/http">Go standard HTTP model</a>.</p>

<pre><code>func main() {
    // Go-app component routing (client-side):
	app.Route("/", &amp;hello{})
	app.Route("/hello", &amp;hello{})
	app.RunWhenOnBrowser()

    // Standard HTTP routing (server-side):
	http.Handle("/", &amp;app.Handler{
		Name:        "Hello",
		Description: "An Hello World! example",
	})

	if err := http.ListenAndServe(":8000", nil); err != nil {
		log.Fatal(err)
	}
}
</code></pre>

<h2 id="other-features">Other Features</h2>

<ul>
<li>Works as a <a href="https://en.wikipedia.org/wiki/Single-page_application">Single-page application</a></li>
<li>SEO friendly</li>
<li>Installable</li>
<li>Offline mode support</li>
<li>State management</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We have used too many levels of abstractions and now the future looks bleak (731 pts)]]></title>
            <link>https://unixsheikh.com/articles/we-have-used-too-many-levels-of-abstractions-and-now-the-future-looks-bleak.html</link>
            <guid>37965142</guid>
            <pubDate>Sat, 21 Oct 2023 08:42:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unixsheikh.com/articles/we-have-used-too-many-levels-of-abstractions-and-now-the-future-looks-bleak.html">https://unixsheikh.com/articles/we-have-used-too-many-levels-of-abstractions-and-now-the-future-looks-bleak.html</a>, See on <a href="https://news.ycombinator.com/item?id=37965142">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>Published on <span id="pubdate">2023-10-21</span>. Modified on <span id="moddate">2023-10-21</span>.</p>
<p><span id="description">A big percentage of so-called experts today only know how to configure some kind of hype-tool, but they understand nothing about how things work at the deeper level. This is a real challenge and a big problem for the future.</span></p>

<p>A steering wheel is an abstraction that makes it easier for me to drive my car. Power steering is yet another level of abstraction that further improves the driving experience. Abstractions are nice, they generally improve the quality of life. However, in Denmark we have a proverb that says:</p>

<blockquote>Too little and too much spoils everything.</blockquote>

<p>What good does an abstraction do when it breaks and nobody any longer understands how the technology under the hood works?</p>

<p>Everything in the tech industry is driven with a very hardcore eye for profit and very little interest in anything else. So you need to be able to push out new products or new services as fast as possible. This means more abstraction and more automation, less and less people, and less deeper understanding.</p>

<p>Today programmers and system administrators no longer exist, instead we have <a href="https://en.wikipedia.org/wiki/DevOps">DevOps</a> and even <a href="https://en.wiktionary.org/wiki/DevSecOps">DevSecOps</a>, in which the industry is trying very hard to stuff every single task into the job description of a single individual. The tech guys needs to do development (Dev), security (Sec) and operations (Ops), i.e. system administration, but since no single individual can truly master all that, we need to automate as much as possible in order to save money and avoid the complexities of human social interaction between different tech departments. As a result, the modern tech person is only taught about how to use specific tools, he or she then knows very little about the technology under the hood.</p>

<p>It doesn't help that technology has become increasingly difficult to understand, but more and more of modern life depends heavily upon the tech we're using. So what is going to happen when the level of understanding in the tech industry reaches such a low point in which the majority of people don't even know how to fix the tools they are using?</p>

<video controls="">
  <source src="https://unixsheikh.com/includes/video/wall-e-manual-scene.mp4" type="video/mp4">
  <source src="https://unixsheikh.com/includes/video/wall-e-manual-scene.webm" type="video/webm">
  <p>Your browser does not support the video tag. Download the <a href="https://unixsheikh.com/includes/video/wall-e-manual-scene.webm">WEBM</a> or <a href="https://unixsheikh.com/includes/video/wall-e-manual-scene.mp4">MP4</a> video instead.</p>
</video>

<p>"Manual scene" from the WALL-E movie.</p>

<p>People have become accustomed to the state of abstraction and they think it's the correct approach and they happily contribute to the mess by adding even more abstraction.</p>

<blockquote>Yes, let's all go back to coding in assembly!<p>― Sarcastic comment by arrogant developer</p></blockquote>

<p>We need abstractions, no doubt about it, but every level of abstraction comes with a price which, ironically enough, eventually can cause a massive loss in profit.</p>

<p>Already now a majority of "security people" know very little about security and only about how to use some kind of pre-made penetration testing tool. The penetration testing tool shows a bunch of green lights in its web GUI board and all is assumed well. Yet, a real security expert with evil intentions has broken the system long ago and keeps selling valuable data on the <a href="https://en.wikipedia.org/wiki/Darknet">darknet</a>. Nothing is leaked and nothing is discovered. This can go on for years without anyone finding out because, well, the GUI board says that all is <span>OK</span>.</p>

<h2>A simple case example</h2>

<p>One company I helped with security had used a third party developer firm who hired these exact types of people. The developers knew how to put together a website and an API using a "modern framework", but did not understand much of the coding of the framework itself and nothing about security, and as soon as problems began occurring, nobody could figure out what was going on. They had actually been struggling with the situation for months before they finally decided to reach out for help.</p>

<p>It was clear, just by looking at how bad everything was performing, that something was wrong. I copied everything for offline scrutiny and went straight to the code of the system and spend an evening looking through lines of code, file by file, doing some simple <a href="https://en.wikipedia.org/wiki/Diff">diffing</a> between some of the original framework files and the files running on the company host machines. Just looking through code and files.</p>

<p>Of course, it was not my intention to look through everything, but it is often surprising just how much you can learn from a bit of manual inspection. Often the truth lies just beneath the surface and with a little patience you can find it. This requires of course that you have more than just a basic understanding of how the technology works. Some students today apparently <a href="https://news.slashdot.org/story/21/09/27/2032200/students-dont-know-what-files-and-folders-are-professors-say">don't even know what files and folders are</a>?</p>

<p>Long story short, in the specific case, it turned out that they had been hacked and the system was being used as some kind of back-end distribution database for porn and other stuff. The performance problems was not caused by the hacking, but by the framework itself, which was horribly slow (no surprise there). The hacking was rather discrete and would most likely never had be discovered where it not because I decided to "poke around" and actually physically look at files and code.</p>

<h2>Advice to people studying technology</h2>

<ul>
  <li>Never just follow hype or trends.</li>
  <li>Be curious. Don't just learn tools, try to understand how the underlying technology works.</li>
  <li>If possible, try at least once to manually do what e.g. a configuration tool does for you.</li>
  <li>If possible, try to look at the code for the tool. Even a basic understanding of the code can be very valuable.</li>
  <li>Stay curious. Keep learning. Experiment. Dive deeper into the technology that interests you. If possible, set up a homelab and use it as a playground for learning and breaking things.</li>
  <li>Question everything. Especially things that don't make any sense to you. Don't just assume that someone else knows better - that's how you quickly turn into a blind follower. Sometimes someone else truly knows better, but don't just assume that to be the case by default. And be brave! Stand by the truth and your convictions even if that makes you feel like you stand alone.<p><img src="https://unixsheikh.com/includes/images/blind-following.webp" alt="People blindly following eachother"></p></li>
</ul>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[O3DE (275 pts)]]></title>
            <link>https://o3de.org/</link>
            <guid>37964999</guid>
            <pubDate>Sat, 21 Oct 2023 08:09:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://o3de.org/">https://o3de.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37964999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <main>

                

                    
        <!---- create contribute section--->

        <div>
                    <p>
                        <h2>CREATE in the open</h2>
                    </p>
                </div>

        <!---- features section--->

        <div>
                <div>
                    <p>
                        <h2>WHY O3DE?</h2>
                    </p>
                    <p>Discover the continuously evolving benefits of O3DE and our growing, welcoming community around the world.
</p>
                    
                </div>

                <div>
                                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/high-fidelity.svg" alt="">
                                        </p>
                                        <p>
                                            High
Fidelity                                        </p>
                                    </div>

                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/modular.svg" alt="">
                                        </p>
                                        <p>
                                            Modular                                        </p>
                                    </div>

                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/interoperable.svg" alt="">
                                        </p>
                                        <p>
                                            Inter-operable
                                        </p>
                                    </div>

                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/cross-platform.svg" alt="">
                                        </p>
                                        <p>
                                            Cross Platform
                                        </p>
                                    </div>

                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/Community-1.svg" alt="">
                                        </p>
                                        <p>
                                            Community Driven
                                        </p>
                                    </div>

                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/open-source.svg" alt="">
                                        </p>
                                        <p>
                                            Open
Source                                        </p>
                                    </div>

                                                            <div>
                                        <p><img src="https://o3de.org/wp-content/uploads/2023/05/cloud.svg" alt="">
                                        </p>
                                        <p>
                                            Cloud Friendly                                        </p>
                                    </div>

                                                                                        </div>
                

            </div>
        <!------ Industries ---->
        
        <div>
                <div>
                    <p>
                        <h2>OPEN TO ALL<br>
INDUSTRIES</h2>
                    </p>
                    <p>Unleash your creativity across a variety of industries, applications and platforms, using O3DE as the foundation for any 3D project.</p>
                    
                </div>

                <div>
                    <div>
                        <ul>

                                                                                                    <li data-industry="0">
                                            <div>
                                                <p><span>
                                                    <img src="https://o3de.org/wp-content/uploads/2023/05/gaming.svg" alt="">
                                                </span></p><h4>Gaming</h4>
                                            </div>
                                            
                                        </li>

                                                                            <li data-industry="1">
                                            <div>
                                                <p><span>
                                                    <img src="https://o3de.org/wp-content/uploads/2023/05/robotics.svg" alt="">
                                                </span></p><h4>Robotics</h4>
                                            </div>
                                            
                                        </li>

                                                                            <li data-industry="2">
                                            <div>
                                                <p><span>
                                                    <img src="https://o3de.org/wp-content/uploads/2023/05/metaverse-1.svg" alt="">
                                                </span></p><h4>Metaverse</h4>
                                            </div>
                                            
                                        </li>

                                                                            <li data-industry="3">
                                            <div>
                                                <p><span>
                                                    <img src="https://o3de.org/wp-content/uploads/2023/05/education.svg" alt="">
                                                </span></p><h4>Education</h4>
                                            </div>
                                            
                                        </li>

                                                                                                                        </ul>
                    </div>
                    <div>
                                                                        <div>
                                                <h5>Gaming</h5>
                                                <p>Create stunning worlds that support multi-faceted storytelling and game play, with open source, modular tools.</p>
                                            </div>
                                                                            <div>
                                                <h5>Robotics</h5>
                                                <p>Deploy O3DE in robotics applications through integration with the modern Robot Operating System (ROS).
</p>
                                            </div>
                                                                            <div>
                                                <h5>Metaverse</h5>
                                                <p>Deliver immersive experiences and 3D digital assets for the emerging world of the open metaverse.</p>
                                            </div>
                                                                            <div>
                                                <h5>Education</h5>
                                                <p>Apply different modalities of learning to meet the needs of the modern classroom, with 3D technology that enables deeper understanding and faster learning.</p>
                                            </div>
                                                                                                </div>
                </div>

                
            </div>

        <!---- Gallery section --->
        <div>
                    <div>
                                                        <h2>MADE WITH O3DE</h2>
<p>Our O3DE gallery showcases the latest and greatest creations and simulations from our global community of O3DE users and contributors.</p>
<p><a href="https://o3de.org/showcase/">SEE SHOWCASE</a></p>

                        </div>
                    <div>
                                                                                                            <div data-swiper-autoplay="5000">
                                                    <h4>Robotic Warehouse Simulation</h4>
                                                    <p>Robotec.ai</p>
                                                </div>
                                                                            
                                                                            <div data-swiper-autoplay="5000">
                                                    <h4>Robotic Simulation Example</h4>
                                                    <p>Robotec.ai</p>
                                                </div>
                                                                            <div data-swiper-autoplay="5000">
                                                    <h4>Using Material Maker with O3DE</h4>
                                                    <p>Darkinggq</p>
                                                </div>
                                                                            
                                                                            <div data-swiper-autoplay="5000">
                                                    <h4>Chain Arc skill using PopcornFX</h4>
                                                    <p>Olex Lozitskiy</p>
                                                </div>
                                                                            
                                                                            <div data-swiper-autoplay="5000">
                                                    <h4>Planet Survival Game</h4>
                                                    <p>Starr Shaw</p>
                                                </div>
                                                                            <div data-swiper-autoplay="5000">
                                                <p><img src="https://o3de.org/wp-content/uploads/2023/05/FPC-gem.jpeg" alt="First Person Controller Gem">
                                                                                                    </p>
                                                
                                                <div>
                                                    <h4>First Person Controller Gem</h4>
                                                    <p>Porcupine-Factory</p>
                                                </div>
                                            </div>
                                                                            <div data-swiper-autoplay="5000">
                                                <p><img src="https://o3de.org/wp-content/uploads/2023/05/Paper-Kid.jpeg" alt="Paper Kid">
                                                                                                    </p>
                                                
                                                
                                            </div>
                                                                            <div data-swiper-autoplay="5000">
                                                <p><img src="https://o3de.org/wp-content/uploads/2023/05/buon.jpg" alt="Buon(G.I)orno Sample and Gem">
                                                                                                    </p>
                                                
                                                <div>
                                                    <h4>Buon(G.I)orno Sample and Gem</h4>
                                                    <p>Imagination Technologies</p>
                                                </div>
                                            </div>
                                                                                                        
                            </div>
                </div>

        

        <!--- Members section --->
        <!-- <section class="members-section section-gradient">
        
            
            <div class="container">
                <div class="row mb-80 justify-content-center">
                    <div class="col-sm-9 text-center">
                        <h2>MEMBER ORGANIZATIONS</h2>
<p>More than 25 companies across the globe support O3DE as members of the Open 3D Foundation.<br />
Find out why and discover how becoming a member helps you to shape the future of O3DE.</p>
                    </div>

                </div>
                <div class="row">
                    <div class="col-sm-12">
                                                <div class="swiper member-slider member-slider-1">
                            <div class="swiper-wrapper">
                                                                    <div class="logo-col  swiper-slide"><img class="img-fluid" src="" alt=""></div>
                                                            </div>
                        </div>
                        <div class="swiper member-slider member-slider-2">
                            <div class="swiper-wrapper">
                                                                    <div class="logo-col  swiper-slide"><img class="img-fluid" src="" alt=""></div>
                                                            </div>
                        </div>

                    </div>
                </div>
                <div class="row justify-content-center mt-5 mb-80">
                    <div class="col-sm-4 text-center">
                        <a href="https://o3d.foundation/community/become-a-member/" target="_blank" class="center btn-underline">Become a Member</a>
                    </div>
                </div>
            </div>
        </section> -->
        <div>
                        <h2>MEMBER ORGANIZATIONS</h2>
<p>More than 25 companies across the globe support O3DE as members of the Open 3D Foundation.<br>
Find out why and discover how becoming a member helps you to shape the future of O3DE.</p>
                    </div>


        </main>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microwatt: A tiny Open POWER ISA softcore written in VHDL 2008 (126 pts)]]></title>
            <link>https://github.com/antonblanchard/microwatt</link>
            <guid>37964878</guid>
            <pubDate>Sat, 21 Oct 2023 07:40:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/antonblanchard/microwatt">https://github.com/antonblanchard/microwatt</a>, See on <a href="https://news.ycombinator.com/item?id=37964878">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/antonblanchard/microwatt/blob/master/media/microwatt-title.png"><img src="https://github.com/antonblanchard/microwatt/raw/master/media/microwatt-title.png" alt="Microwatt"></a>
</p>
<h2 tabindex="-1" id="user-content-microwatt" dir="auto"><a href="#microwatt">Microwatt</a></h2>
<p dir="auto">A tiny Open POWER ISA softcore written in VHDL 2008. It aims to be simple and easy
to understand.</p>
<h2 tabindex="-1" id="user-content-simulation-using-ghdl" dir="auto"><a href="#simulation-using-ghdl">Simulation using ghdl</a></h2>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/fef790b5fc71f2acb41496a07b7cfac962e67b994bb8a3a9b821fd27be3009ce/687474703a2f2f6e65756c696e672e6f72672f6d6963726f776174742d6d6963726f707974686f6e2e676966"><img src="https://camo.githubusercontent.com/fef790b5fc71f2acb41496a07b7cfac962e67b994bb8a3a9b821fd27be3009ce/687474703a2f2f6e65756c696e672e6f72672f6d6963726f776174742d6d6963726f707974686f6e2e676966" alt="MicroPython running on Microwatt" data-animated-image="" data-canonical-src="http://neuling.org/microwatt-micropython.gif"></a>
</p>
<p dir="auto">You can try out Microwatt/Micropython without hardware by using the ghdl simulator. If you want to build directly for a hardware target board, see below.</p>
<ul dir="auto">
<li>Build micropython. If you aren't building on a ppc64le box you
will need a cross compiler. If it isn't available on your distro
grab the powerpc64le-power8 toolchain from <a href="https://toolchains.bootlin.com/" rel="nofollow">https://toolchains.bootlin.com</a>.
You may need to set the CROSS_COMPILE environment variable
to the prefix used for your cross compilers.  The default is
powerpc64le-linux-gnu-.</li>
</ul>
<div data-snippet-clipboard-copy-content="git clone https://github.com/micropython/micropython.git
cd micropython
cd ports/powerpc
make -j$(nproc)
cd ../../../"><pre><code>git clone https://github.com/micropython/micropython.git
cd micropython
cd ports/powerpc
make -j$(nproc)
cd ../../../
</code></pre></div>
<p dir="auto">A prebuilt micropython image is also available in the micropython/ directory.</p>
<ul dir="auto">
<li>
<p dir="auto">Microwatt uses ghdl for simulation. Either install this from your
distro or build it. Microwatt requires ghdl to be built with the LLVM
or gcc backend, which not all distros do (Fedora does, Debian/Ubuntu
appears not to). ghdl with the LLVM backend is likely easier to build.</p>
<p dir="auto">If building ghdl from scratch is too much for you, the microwatt Makefile
supports using Docker or Podman.</p>
</li>
<li>
<p dir="auto">Next build microwatt:</p>
</li>
</ul>
<div data-snippet-clipboard-copy-content="git clone https://github.com/antonblanchard/microwatt
cd microwatt
make"><pre><code>git clone https://github.com/antonblanchard/microwatt
cd microwatt
make
</code></pre></div>
<p dir="auto">To build using Docker:</p>

<p dir="auto">and to build using Podman:</p>

<ul dir="auto">
<li>Link in the micropython image:</li>
</ul>
<div data-snippet-clipboard-copy-content="ln -s ../micropython/ports/powerpc/build/firmware.bin main_ram.bin"><pre><code>ln -s ../micropython/ports/powerpc/build/firmware.bin main_ram.bin
</code></pre></div>
<p dir="auto">Or if you were using the pre-built image:</p>
<div data-snippet-clipboard-copy-content="ln -s micropython/firmware.bin main_ram.bin"><pre><code>ln -s micropython/firmware.bin main_ram.bin
</code></pre></div>
<ul dir="auto">
<li>Now run microwatt, sending debug output to /dev/null:</li>
</ul>

<h2 tabindex="-1" id="user-content-synthesis-on-xilinx-fpgas-using-vivado" dir="auto"><a href="#synthesis-on-xilinx-fpgas-using-vivado">Synthesis on Xilinx FPGAs using Vivado</a></h2>
<ul dir="auto">
<li>
<p dir="auto">Install Vivado (I'm using the free 2019.1 webpack edition).</p>
</li>
<li>
<p dir="auto">Setup Vivado paths:</p>
</li>
</ul>
<div data-snippet-clipboard-copy-content="source /opt/Xilinx/Vivado/2019.1/settings64.sh"><pre><code>source /opt/Xilinx/Vivado/2019.1/settings64.sh
</code></pre></div>
<ul dir="auto">
<li>Install FuseSoC:</li>
</ul>
<div data-snippet-clipboard-copy-content="pip3 install --user -U fusesoc"><pre><code>pip3 install --user -U fusesoc
</code></pre></div>
<p dir="auto">Fedora users can get FuseSoC package via</p>
<div data-snippet-clipboard-copy-content="sudo dnf copr enable sharkcz/danny
sudo dnf install fusesoc"><pre><code>sudo dnf copr enable sharkcz/danny
sudo dnf install fusesoc
</code></pre></div>
<ul dir="auto">
<li>If this is your first time using fusesoc, initialize fusesoc.
This is needed to be able to pull down fussoc library components referenced
by microwatt. Run</li>
</ul>
<div data-snippet-clipboard-copy-content="fusesoc init
fusesoc fetch uart16550
fusesoc library add microwatt /path/to/microwatt"><pre><code>fusesoc init
fusesoc fetch uart16550
fusesoc library add microwatt /path/to/microwatt
</code></pre></div>
<ul dir="auto">
<li>Build using FuseSoC. For hello world (Replace nexys_video with your FPGA board such as --target=arty_a7-100):
You may wish to ensure you have <a href="https://reference.digilentinc.com/vivado/installing-vivado/start#installing_digilent_board_files" rel="nofollow">installed Digilent Board files</a>
or appropriate files for your board first.</li>
</ul>
<div data-snippet-clipboard-copy-content="fusesoc run --target=nexys_video microwatt --memory_size=16384 --ram_init_file=/path/to/microwatt/fpga/hello_world.hex"><pre><code>fusesoc run --target=nexys_video microwatt --memory_size=16384 --ram_init_file=/path/to/microwatt/fpga/hello_world.hex
</code></pre></div>
<p dir="auto">You should then be able to see output via the serial port of the board (/dev/ttyUSB1, 115200 for example assuming standard clock speeds). There is a know bug where initial output may not be sent - try the reset (not programming button) on your board if you don't see anything.</p>
<ul dir="auto">
<li>To build micropython (currently requires 1MB of BRAM eg an Artix-7 A200):</li>
</ul>
<div data-snippet-clipboard-copy-content="fusesoc run --target=nexys_video microwatt"><pre><code>fusesoc run --target=nexys_video microwatt
</code></pre></div>
<h2 tabindex="-1" id="user-content-linux-on-microwatt" dir="auto"><a href="#linux-on-microwatt">Linux on Microwatt</a></h2>
<p dir="auto">Mainline Linux supports Microwatt as of v5.14. The Arty A7 is the best tested
platform, but it's also been tested on the OrangeCrab and ButterStick.</p>
<ol dir="auto">
<li>
<p dir="auto">Use buildroot to create a userspace</p>
<p dir="auto">A small change is required to glibc in order to support the VMX/AltiVec-less
Microwatt, as float128 support is mandiatory and for this in GCC requires
VSX/AltiVec. This change is included in Joel's buildroot fork, along with a
defconfig:</p>
<div data-snippet-clipboard-copy-content="git clone -b microwatt https://github.com/shenki/buildroot
cd buildroot
make ppc64le_microwatt_defconfig
make"><pre><code>git clone -b microwatt https://github.com/shenki/buildroot
cd buildroot
make ppc64le_microwatt_defconfig
make
</code></pre></div>
<p dir="auto">The output is <code>output/images/rootfs.cpio</code>.</p>
</li>
<li>
<p dir="auto">Build the Linux kernel</p>
<div data-snippet-clipboard-copy-content="git clone https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git
cd linux
make ARCH=powerpc microwatt_defconfig
make ARCH=powerpc CROSS_COMPILE=powerpc64le-linux-gnu- \
  CONFIG_INITRAMFS_SOURCE=/buildroot/output/images/rootfs.cpio -j`nproc`"><pre><code>git clone https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git
cd linux
make ARCH=powerpc microwatt_defconfig
make ARCH=powerpc CROSS_COMPILE=powerpc64le-linux-gnu- \
  CONFIG_INITRAMFS_SOURCE=/buildroot/output/images/rootfs.cpio -j`nproc`
</code></pre></div>
<p dir="auto">The output is <code>arch/powerpc/boot/dtbImage.microwatt.elf</code>.</p>
</li>
<li>
<p dir="auto">Build gateware using FuseSoC</p>
<p dir="auto">First configure FuseSoC as above.</p>
<div data-snippet-clipboard-copy-content="fusesoc run --build --target=arty_a7-100 microwatt --no_bram --memory_size=0"><pre><code>fusesoc run --build --target=arty_a7-100 microwatt --no_bram --memory_size=0
</code></pre></div>
<p dir="auto">The output is <code>build/microwatt_0/arty_a7-100-vivado/microwatt_0.bit</code>.</p>
</li>
<li>
<p dir="auto">Program the flash</p>
<p dir="auto">This operation will overwrite the contents of your flash.</p>
<p dir="auto">For the Arty A7 A100, set <code>FLASH_ADDRESS</code> to <code>0x400000</code> and pass <code>-f a100</code>.</p>
<p dir="auto">For the Arty A7 A35, set <code>FLASH_ADDRESS</code> to <code>0x300000</code> and pass <code>-f a35</code>.</p>
<div data-snippet-clipboard-copy-content="microwatt/openocd/flash-arty -f a100 build/microwatt_0/arty_a7-100-vivado/microwatt_0.bit
microwatt/openocd/flash-arty -f a100 dtbImage.microwatt.elf -t bin -a $FLASH_ADDRESS"><pre><code>microwatt/openocd/flash-arty -f a100 build/microwatt_0/arty_a7-100-vivado/microwatt_0.bit
microwatt/openocd/flash-arty -f a100 dtbImage.microwatt.elf -t bin -a $FLASH_ADDRESS
</code></pre></div>
</li>
<li>
<p dir="auto">Connect to the second USB TTY device exposed by the FPGA</p>

<p dir="auto">The gateware has firmware that will look at <code>FLASH_ADDRESS</code> and attempt to
parse an ELF there, loading it to the address specified in the ELF header
and jumping to it.</p>
</li>
</ol>
<h2 tabindex="-1" id="user-content-testing" dir="auto"><a href="#testing">Testing</a></h2>
<ul dir="auto">
<li>A simple test suite containing random execution test cases and a couple of
micropython test cases can be run with:</li>
</ul>

<h2 tabindex="-1" id="user-content-issues" dir="auto"><a href="#issues">Issues</a></h2>
<ul dir="auto">
<li>There are a few instructions still to be implemented:
<ul dir="auto">
<li>Vector/VMX/VSX</li>
</ul>
</li>
</ul>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[With Firefox on X11, any page can pastejack you anytime (middle button paste) (207 pts)]]></title>
            <link>https://www.openwall.com/lists/oss-security/2023/10/17/1</link>
            <guid>37964835</guid>
            <pubDate>Sat, 21 Oct 2023 07:30:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openwall.com/lists/oss-security/2023/10/17/1">https://www.openwall.com/lists/oss-security/2023/10/17/1</a>, See on <a href="https://news.ycombinator.com/item?id=37964835">Hacker News</a></p>
<div id="readability-page-1" class="page">


<table>
<tbody><tr>

<td>
<a href="https://www.openwall.com/"><img src="https://www.openwall.com/logo.png" width="182" height="80" alt="Openwall"></a>
</td><td>
<div>
<ul>
<li><a href="https://www.openwall.com/">Products</a>
<ul>
<li><a href="https://www.openwall.com/Owl/">Openwall GNU/*/Linux &nbsp; <i>server OS</i></a>
</li><li><a href="https://www.openwall.com/lkrg/">Linux Kernel Runtime Guard</a>
</li><li><a href="https://www.openwall.com/john/">John the Ripper &nbsp; <i>password cracker</i></a>
<ul>
<li><a href="https://www.openwall.com/john/">Free &amp; Open Source for any platform</a>
</li><li><a href="https://www.openwall.com/john/cloud/">in the cloud</a>
</li><li><a href="https://www.openwall.com/john/pro/linux/">Pro for Linux</a>
</li><li><a href="https://www.openwall.com/john/pro/macosx/">Pro for macOS</a>
</li></ul>
</li><li><a href="https://www.openwall.com/wordlists/">Wordlists &nbsp; <i>for password cracking</i></a>
</li><li><a href="https://www.openwall.com/passwdqc/">passwdqc &nbsp; <i>policy enforcement</i></a>
<ul>
<li><a href="https://www.openwall.com/passwdqc/">Free &amp; Open Source for Unix</a>
</li><li><a href="https://www.openwall.com/passwdqc/windows/">Pro for Windows (Active Directory)</a>
</li></ul>
</li><li><a href="https://www.openwall.com/yescrypt/">yescrypt &nbsp; <i>KDF &amp; password hashing</i></a>
</li><li><a href="https://www.openwall.com/yespower/">yespower &nbsp; <i>Proof-of-Work (PoW)</i></a>
</li><li><a href="https://www.openwall.com/crypt/">crypt_blowfish &nbsp; <i>password hashing</i></a>
</li><li><a href="https://www.openwall.com/phpass/">phpass &nbsp; <i>ditto in PHP</i></a>
</li><li><a href="https://www.openwall.com/tcb/">tcb &nbsp; <i>better password shadowing</i></a>
</li><li><a href="https://www.openwall.com/pam/">Pluggable Authentication Modules</a>
</li><li><a href="https://www.openwall.com/scanlogd/">scanlogd &nbsp; <i>port scan detector</i></a>
</li><li><a href="https://www.openwall.com/popa3d/">popa3d &nbsp; <i>tiny POP3 daemon</i></a>
</li><li><a href="https://www.openwall.com/blists/">blists &nbsp; <i>web interface to mailing lists</i></a>
</li><li><a href="https://www.openwall.com/msulogin/">msulogin &nbsp; <i>single user mode login</i></a>
</li><li><a href="https://www.openwall.com/php_mt_seed/">php_mt_seed &nbsp; <i>mt_rand() cracker</i></a>
</li></ul>
</li><li><a href="https://www.openwall.com/services/">Services</a>
</li><li id="narrow-li-1"><a>Publications</a>
<ul>
<li><a href="https://www.openwall.com/articles/">Articles</a>
</li><li><a href="https://www.openwall.com/presentations/">Presentations</a>
</li></ul>
</li><li><a>Resources</a>
<ul>
<li><a href="https://www.openwall.com/lists/">Mailing lists</a>
</li><li><a href="https://openwall.info/wiki/">Community wiki</a>
</li><li><a href="https://github.com/openwall">Source code repositories (GitHub)</a>
</li><li><a href="https://cvsweb.openwall.com/">Source code repositories (CVSweb)</a>
</li><li><a href="https://www.openwall.com/mirrors/">File archive &amp; mirrors</a>
</li><li><a href="https://www.openwall.com/signatures/">How to verify digital signatures</a>
</li><li><a href="https://www.openwall.com/ove/">OVE IDs</a>
</li></ul>
</li><li id="last-li"><a href="https://www.openwall.com/news">What's new</a>
</li></ul>
</div>


</td></tr></tbody></table>




<a href="https://www.openwall.com/lists/oss-security/2023/10/16/23">[&lt;prev]</a> <a href="https://www.openwall.com/lists/oss-security/2023/10/17/2">[next&gt;]</a> <a href="https://www.openwall.com/lists/oss-security/2023/10/18/3">[thread-next&gt;]</a> <a href="https://www.openwall.com/lists/oss-security/2023/10/17/">[day]</a> <a href="https://www.openwall.com/lists/oss-security/2023/10/">[month]</a> <a href="https://www.openwall.com/lists/oss-security/2023/">[year]</a> <a href="https://www.openwall.com/lists/oss-security/">[list]</a>
<pre>Date: Tue, 17 Oct 2023 03:17:36 +0300
From: turistu &lt;turistu@...il.com&gt;
To: oss-security@...ts.openwall.com
Subject: with firefox on X11, any page can pastejack you anytime

Note to the moderator: I have already submitted this to the firefox people
three weeks ago, and according to them, this is not a real security issue,
or at least not worse than those pesky scripts which you cannot kill without
killing firefox itself; if you think the same, just ignore this without
replying.

I would however appreciate if you let this through and so give it some
visibility so that the other 2 or 3 people who may be affected by this
could learn about it.

Thank you very much.

====

In firefox running on X11, any script from any page can freely write to the
primary selection, and that can be easily exploited to run arbitrary code
on the user's machine.

No user interaction is necessary -- any page able to run javascript can do it,
including e.g. a page from a background tab of a minimized window, an iframe
inside such a window, an error page, a sandboxed iframe, a page that has
reloaded itself via `meta http-equiv=refresh`, etc.

This applies to all the versions of mozilla/firefox and their derivatives
(seamonkey, etc) that I was able to test, including the latest nightly.

### Example

The simplest example, which works in the default configurations of systems
like OpenBSD or Alpine Linux (= any Unix/Linux system where Wayland is not
the default and the default *shell* does not implement bracketed-paste),
would go like this:

Load the following snippet in firefox:

	&lt;pre id=pre style=font-size:0&gt;&lt;/pre&gt;
	intentionally left blank
	&lt;script&gt;
	function writeXPrimary(s){
		pre.textContent = s; getSelection().selectAllChildren(pre);
	}
	setInterval(function(){
		writeXPrimary('touch ~/LOL-' + Date.now() / 1000 +'\r')
	}, 500)
	&lt;/script&gt;

Then pretend to forget about it, and go about your work. Sooner or later,
when trying to paste something in the terminal with shift-Insert or middle
click, you will end up running the command `writeXPrimary()` has injected
just between your copy and paste.

live example of that snippet: <a href="https://turistu.github.io/firefox/pastejack.html" rel="nofollow">https://turistu.github.io/firefox/pastejack.html</a>

### Short technical explanation

Browsers like firefox have the concepts of "secure context" (e.g. `https://`)
and "transient user activation"; the javascript from the page gets some
temporary powers as soon as you have interacted *even so little* with the
page, like clicked, touched, etc.

For instance, writing with `Clipboard.writeText()` to the windows-style
Ctrl-C Ctrl-V *clipboard* selection is only possible from secure contexts
and only in the short while after the user has clicked a button, etc on the page.
As this bug demonstrates, those prerequisites are not needed for writing to the
*primary* selection, which on X11 is much more used and much more valuable.

### Workaround

Without patching firefox, the only workaround I can think about is
disabling the `Clipboard.selectAllChildren()` function from an addon's
content script, e.g. like this:

	let block = function(){ throw Error('blocked') };
	exportFunction(block, Selection.prototype, { defineAs: 'selectAllChildren' });

Complete extension here at <a href="https://github.com/turistu/odds-n-ends/raw/main/firefox/no-sel.xpi" rel="nofollow">https://github.com/turistu/odds-n-ends/raw/main/firefox/no-sel.xpi</a>.

I tried to submit it to addons.mozilla.org but they didn't accept it. If
you're running firefox-esr, the development edition or nightly, you can just
`set xpinstall.signatures.required` to true in `about:config` and install
it with `firefox no-sel.xpi`.

### Firefox Patch
```
diff -r 9b362770f30b layout/generic/nsFrameSelection.cpp
--- a/layout/generic/nsFrameSelection.cpp	Fri Oct 06 12:03:17 2023 +0000
+++ b/layout/generic/nsFrameSelection.cpp	Sun Oct 08 11:04:41 2023 +0300
@@ -3345,6 +3345,10 @@
     return;  // Don't care if we are still dragging.
   }
 
+  if (aReason &amp; nsISelectionListener::JS_REASON) {
+    return;
+  }
+
   if (!aDocument || aSelection.IsCollapsed()) {
 #ifdef DEBUG_CLIPBOARD
     fprintf(stderr, "CLIPBOARD: no selection/collapsed selection\n");
```

The idea of this patch was to *always* prevent javascript from indirectly
messing with the primary selection via the Selection API. However, it turned
out that the `JS_REASON` flag was not reliable; if javascript calls some
function like `addRange()` or `selectAllChildren()` while the user has started
dragging but hasn't released the mouse button yet, that code will be called
*without* that flag but with the text set by javascript, not the text
selected by the user. However, I think that this patch is still enough
to fill the glaring hole opened by `selectAllChildren()`.

### About the example and bracketed-paste

The bracketed paste feature of bash/readline and zsh means that you
cannot just append a CR or LF to the payload and be done, it's the
user who has to press ENTER for it to run.

However, workarounds exist.  For instance, some terminals like mlterm
don't filter out the pasted data, and you can terminate the pasting
mode early by inserting a `\e[201~` in the payload.

For bash, you can take advantage of some quirks in the readline library
to turn off the highlighting and make the payload invisible to the user.
E.g.:

	let payload = 'touch ~/LOL-' + Date.now() / 1000;
	writeXPrimary('\n' + payload + '\n'.repeat(100) + ' '.repeat(30)
		+ '\n'.repeat(100))

which will confuse the user with the same screen as when some stray background job
had written something to the terminal:

	user@...t:~$ : previous unrelated command
	user@...t:~$	&lt;-- paste here
	#   &lt;-- cursor here, most users will just hit Enter to get a new prompt

live example of that snippet:	<a href="https://turistu.github.io/firefox/bash-pastejack.html" rel="nofollow">https://turistu.github.io/firefox/bash-pastejack.html</a>

Just to be clear, I don't think that either mlterm, bash, nor the shells that
don't do have that bracketed-paste feature are at fault here in any way
(and I personally always turn off that misfeature as it badly interferes
with my workflow): It's firefox which should get all the blame for letting
random javascript evade its pretended "sandbox" in this way.

### About Wayland

For firefox running in Wayland, `writeXPrimary()` will only succeed
when the firefox window (the main window, not necessarily the tab the code
runs in) has the focus. Otherwise the selection will be cleared. At first I
assumed that this is something specific to the Wayland protocol, but that
turned out to be utterly false; it's just some quirk, bug or "feature"
specific to either firefox itself or GTK.

But I think that's still bad enough, even if the page should take care to
only set the selection when the main window has gained focus.

And of course, all this doesn't affect the situation where you're copying
and pasting in another firefox tab with a different context, origin, etc;
and all the other situations where you don't appreciate having random
javascript you don't even know about messing with your copy &amp; paste.

===

This is a slightly edited version of
<a href="https://github.com/turistu/odds-n-ends/blob/main/firefox/pastejack.md" rel="nofollow">https://github.com/turistu/odds-n-ends/blob/main/firefox/pastejack.md</a>.

I will correct any errors or omissions and also add more info there.
</pre>
<p><a href="http://www.openwall.com/blists/">Powered by blists</a> - <a href="http://lists.openwall.net/">more mailing lists</a>


</p><p>
Please check out the
<a href="https://oss-security.openwall.org/wiki/">
Open Source Software Security Wiki</a>, which is counterpart to this
<a href="https://oss-security.openwall.org/wiki/mailing-lists/oss-security">mailing list</a>.
</p><p>
Confused about <a href="https://www.openwall.com/lists/">mailing lists</a> and their use?
<a href="https://en.wikipedia.org/wiki/Electronic_mailing_list">Read about mailing lists on Wikipedia</a>
and check out these
<a href="https://www.complang.tuwien.ac.at/anton/mail-news-errors.html">guidelines on proper formatting of your messages</a>.
</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Common-knowledge effect: A bias in team decision making (114 pts)]]></title>
            <link>https://www.nngroup.com/articles/common-knowledge-effect/</link>
            <guid>37964682</guid>
            <pubDate>Sat, 21 Oct 2023 06:51:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nngroup.com/articles/common-knowledge-effect/">https://www.nngroup.com/articles/common-knowledge-effect/</a>, See on <a href="https://news.ycombinator.com/item?id=37964682">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="articleBody"><p>"None of us is as smart as all of us" is a well-known quote by management consultant Kenneth Blanchard. It summarizes the intuitive and commonly held sentiment that teams are more intelligent and capable than individuals. Teams have more brainpower, knowledge, and experience. When confronted with a difficult decision, you want a team — not just one individual — to analyze, deliberate, and resolve the situation.</p>
<p>But is the superiority of team decision making a reality or a myth? Behavioral-psychology research suggests that the answer is not as simple as it may seem.</p>
<h3>On This Page:</h3>
<ul>
<li><a href="#The Common-Knowledge Effect">The Common-Knowledge Effect</a></li>
<li><a href="#Scenario">Scenario</a></li>
<li><a href="#Individual Decision Making">Individual Decision Making</a></li>
<li><a href="#Team Decision Making">Team Decision Making</a></li>
<li><a href="#Why Does the Common-Knowledge Effect Happen?">Why Does the Common-Knowledge Effect Happen?</a></li>
<li><a href="#Why the Common-Knowledge Effect Matters to UX">Why the Common-Knowledge Effect Matters to UX</a></li>
<li><a href="#How to Mitigate the Common-Knowledge Effect">How to Mitigate the Common-Knowledge Effect</a></li>
<li><a href="#Conclusion">Conclusion</a></li>
<li><a href="#References">References</a></li>
</ul>
<h2><a id="The Common-Knowledge Effect" name="The Common-Knowledge Effect"></a>The Common-Knowledge Effect</h2>
<p>Psychologists Garold Stasser and William Titus found that teams often do not live up to their decision-making potential. Instead of harnessing the members' collective resources to make robust decisions, teams spend most of their time discussing the information they all already know and not enough time on uniquely held information, consequently engaging in poor decision making. This phenomenon hindering team decision making (just one problem among many, such as <a href="https://www.nngroup.com/articles/groupthink-in-ux/">groupthink</a>) has been consistently confirmed by psychology researchers over four decades.</p>
<p>Definition: The <strong>common-knowledge effect</strong> is a decision-making bias where teams overemphasize the information most team members understand instead of pursuing and incorporating the unique knowledge of team members.</p>
<p>Let's walk through a scenario demonstrating how the common-knowledge effect can hamper your team's decision making.</p>
<h2><a id="Scenario" name="Scenario"></a>Scenario</h2>
<p>Assume you're a UX leader at a software company. You and your colleagues must decide on pursuing one of three possible projects, A, B, and C, next year. Because this is a strategic decision requiring cross-department coordination and sizable investment, each project has been extensively researched. Multiple facts are known about each project.</p>
<p>To construct this scenario, we used ChatGPT to generate plausible factual statements for each software project. The statements focused on engineering, product management, or user-experience topics. All statements could either be positive or negative. Positive statements suggested that a project would be advantageous, profitable, or beneficial to the organization. Negative statements suggested a project would be challenging, costly, or detrimental to the organization. As part of the statement-generating prompt, ChatGPT was instructed to use sentiment analysis to create statements that were roughly equivalent in the magnitude of their positivity or negativity. (For example, we wouldn’t want a statement like <em>This project is expected to generate billions in revenue</em>, as it would make choosing a project too easy.)</p>
<table>
<tbody>
<tr>
<td>
<p>Statements</p>
</td>
<td>
<p>Project A</p>
</td>
<td>
<p>Project B</p>
</td>
<td>
<p>Project C</p>
</td>
</tr>
<tr>
<td>
<p>Positive</p>
</td>
<td>
<p>4</p>
</td>
<td>
<p><strong>7</strong></p>
</td>
<td>
<p>4</p>
</td>
</tr>
<tr>
<td>
<p>Negative</p>
</td>
<td>
<p>6</p>
</td>
<td>
<p><strong>3</strong></p>
</td>
<td>
<p>6</p>
</td>
</tr>
</tbody>
</table>
<p>Based on this distribution of statements, it's easy to determine that project B is the optimal choice: it has the most positive and the fewest negative statements compared to the other projects.</p>
<h2><a id="Individual Decision Making" name="Individual Decision Making"></a>Individual Decision Making</h2>
<p>We then used this scenario in a digital survey with 307 participants in April 2023. A majority of participants were designers or UX researchers.</p>
<figure><img alt="Bar chart depicting designers and UX researchers were the majority of participants in the survey" height="436" loading="lazy" src="https://media.nngroup.com/media/editor/2023/09/28/percentage-of-sp-by-role.png" width="692">
<figcaption><em>The distribution of roles in our individual decision-making survey</em></figcaption>
</figure>
<p>We presented the above scenario and gave participants 10 minutes to review all statements for each project. The survey tool required all participants to view the statements for 10 minutes before submitting their decision on which project to pursue to ensure a standardized time for evaluation. All statements were listed in randomized order under their respective project without indicating a statement's positivity or negativity. We also informed participants that of the three available projects, one was objectively <strong>optimal compared to the others</strong>, and they should focus on determining this ideal solution based on the statements provided.</p>
<p>When presented with all available project statements, <strong>80% of participants selected Project B as the recommended project, which was indeed the optimal choice</strong>. Of course, in the real world, we never have perfect and complete information regarding our decisions, but this feedback assures us that, if all these project statements are analyzed, then project B is generally seen as best.</p>
<figure><img alt="Bar chart depicting which project was selected as best by survey participants, with Project B at 80%" height="450" loading="lazy" src="https://media.nngroup.com/media/editor/2023/09/28/survey-participants-selected-optimal-projects.png" width="692">
<figcaption><em>When individuals analyzed all project statements, they predominately and correctly selected project B as the best project to pursue (Error bars represent 95% confidence intervals.) This percentage is very close to 83%, the number found by the Stasser and Titus study.</em></figcaption>
</figure>
<h2><a id="Team Decision Making" name="Team Decision Making"></a>Team Decision Making</h2>
<p>An interesting phenomenon happens when this scenario is given to teams. If each team member is provided with all project statements, then the team can match the decision-making effectiveness of an individual (which is about 80%). <strong>But what if information is not equally shared among all team members</strong>? Information asymmetry is prevalent in the UX workplace. Departments and their leaders have different domains of expertise, are measured on various metrics and goals, and may have personal agendas influencing what they divulge to others. In addition, the organization may be less proficient in acquiring new data through research, or its corporate culture may promote secrecy and discourage knowledge sharing.</p>
<p>Furthermore, team members often have preformed preferences that influence their high-stakes decision making. People evaluate what they know about a situation, are influenced by their motivations and biases (both conscious and unconscious), and form opinions before deliberating with others.</p>
<p>With this understanding, we presented participants in our <a href="https://www.nngroup.com/courses/design-tradeoffs/">Design Tradeoffs and UX Decision Making course</a> the following adjusted scenario, that simulates a real-world, team-based decision-making process:</p>
<ol>
<li>Each team member was given a portion of the project statements. (All statements remained identical to those used in the individual decision-making survey.)</li>
<li>Project statements were distributed unevenly:
	<ul>
<li>Projects A and C had all their <strong>positive statements shared </strong>with all team members. Their <strong>negative statements were divided</strong> between team members.</li>
<li>Project B had all its <strong>negative statements shared </strong>with all team members. Most of its <strong>positive statements were divided</strong> between team members.</li>
</ul>
</li>
<li>Each team member was given time to review their project statements privately and decide which project is best. Team members could take personal notes and use them in their subsequent team deliberations.</li>
<li>Afterward, team members got together and were given 10 minutes to share, discuss, and determine the best project.</li>
</ol>
<p>If the team facilitates knowledge sharing and learns from each member's unique information — as the ideal team decision-making process should go — it will likely identify and select project B as the optimal choice. However, if the team leans towards premature consensus building and commonly understood facts, it'll probably select suboptimal projects A or C instead.</p>
<figure><img alt="Multi-column bar chart showing the distribution of statements for each project, with Project B having the most positive and fewest negatives." height="450" loading="lazy" src="https://media.nngroup.com/media/editor/2023/09/28/team-decision-making-copy.png" width="692">
<figcaption><em>Project B's flaws were widely understood among all team members, while many of its benefits were known only to some individuals. This distribution made project B appear unappealing to individuals, but it is, in fact, the team's optimal choice.</em></figcaption>
</figure>
<p>When we give this scenario in our <a href="https://www.nngroup.com/courses/design-tradeoffs/">Design Tradeoffs and UX Decision-Making course</a>, the percentages vary from one course installment to the next, but the results are generally the same: most teams are unable to facilitate their decision-making discussion effectively. <strong>Teams select the optimal project at a significantly reduced rate compared to individuals.</strong></p>
<figure><img alt="Bar chart comparison of individual and team performance showing that teams select the optimal project significantly less than individuals" height="451" loading="lazy" src="https://media.nngroup.com/media/editor/2023/09/28/teams-selected-optimal-projects.png" width="692">
<figcaption><em>Results from our Design Tradeoffs course where 29 teams of 3–4 attendees engaged in this scenario. Attendees tended to adhere to preconceived opinions, not divulge unique statements, and focus on statements all team members knew. Consequently, teams selected the optimal project B far less than individual decision makers (Error bars represent 95% confidence intervals). Teams also selected Project C at a greater rate than individuals. Both differences were statistically significant at p &lt; .05.</em></figcaption>
</figure>
<h2><a id="Why Does the Common-Knowledge Effect Happen?" name="Why Does the Common-Knowledge Effect Happen?"></a>Why Does the Common-Knowledge Effect Happen?</h2>
<p>Decision-making is inherently complex, and involving more people makes it even more complicated. The mixture of individual traits, group dynamics, and social hierarchy can all perpetuate the common-knowledge effect when multiple people are involved. Communication expert Gwen Wittenbaum has developed a framework to categorize the many factors affecting the information sharing of groups:</p>
<h3>Information Availability and Memory</h3>
<ul>
<li>We are more likely to recall and discuss recent or memorable information.</li>
<li>Commonly held information has more opportunities to be shared with the team since several team members possess it. Unique information depends on an individual sharing it.</li>
<li>Once information is shared with a team, it tends to be repeated by others, which boosts its perceived credibility.</li>
</ul>
<h3>Preference Bias</h3>
<ul>
<li>We are more likely to discuss information that aligns with our initial preferences or preconceived notions.</li>
<li>Even when all information is shared with the group, we still process that information according to our initial preferences.</li>
</ul>
<h3>Social Comparison</h3>
<ul>
<li>We seek social acceptance and avoid conflict with teammates. We tend to adopt the group's prevailing view when evaluating information in unclear situations.</li>
<li>Information familiar to multiple team members becomes socially validated and more likely to be repeated and affirmed.</li>
</ul>
<h2><a id="Why the Common-Knowledge Effect Matters to UX" name="Why the Common-Knowledge Effect Matters to UX"></a>Why the Common-Knowledge Effect Matters to UX</h2>
<p>The common-knowledge effect has a real-world impact on UX professionals for several reasons:</p>
<ul>
<li><strong>You are often making team decisions</strong>. Even for small-scale tactical decisions, UX needs collaboration with other departments to see their insights or designs implemented. Creating digital experiences demands teamwork.</li>
<li><strong>You are often outnumbered</strong>. UX professionals are usually fewer in number compared to other groups, such as developers. Consequently, unless UX knowledge is regularly distributed and socialized, such information is unique and not commonly understood by other team members.</li>
<li><strong>You are often an outsider. </strong>Especially in organizations with <a href="https://www.nngroup.com/articles/ux-maturity-model/">lower UX maturity</a>, with new UX roles or departments, UX can be a "cognitively peripheral" group, meaning that it may lack knowledge known to other team members. Research by Susanne Abele and colleagues found that members who share more knowledge with other team members were "cognitively central" and seen as more credible and influential in discussions. Team members with mostly unique knowledge struggled to persuade their fellow team members successfully.</li>
</ul>
<h2><a id="How to Mitigate the Common-Knowledge Effect" name="How to Mitigate the Common-Knowledge Effect"></a>How to Mitigate the Common-Knowledge Effect</h2>
<p>Here are some tips on how UX professionals can mitigate the common-knowledge effect in their group decision making:</p>
<ul>
<li><strong>Promote psychological safety</strong>. Despite being a great learning opportunity, UX-research findings may disappoint or upset the organization's status quo. Sharing this type of dissenting information is challenging if the environment feels unwelcoming. Leaders must model and normalize mutual respect and open communication with their teams.</li>
<li><strong>Be aware of role-power imbalance</strong>. Leaders who insert themselves into team decision making will distort information sharing; delegate exploring complex decisions to teams of equals.</li>
<li><strong>Deliberating in person isn't superior to online.</strong> According to research by Simon Lam and John Schaubroeck, virtual teams are more likely to overcome the common-knowledge effect compared to face-to-face teams, perhaps due to easier access to notes and materials.</li>
<li><strong>Disregard past opinions</strong>. Strongly encourage colleagues (<strong>especially yourself</strong>) to put aside preconceived ideas about the best choice. This approach is quite difficult, but research by Torsten Reimer, Andrea Reimer, and Verlin B. Hinsz suggests that <strong>premature judgments ruin our decision-making capabilities</strong>. In their study, teams whose members<strong> avoided making hasty judgments</strong> before deliberating were <strong>likelier to overcome the common-knowledge effect</strong> and make optimal decisions.</li>
<li><strong>Unite around common goals</strong>. Because human nature is prone to factionalism, UX folks can expect cross-departmental rivalries. But a product team doesn't necessarily succeed by reusing the most code, being the first to release a new product, or fully implementing a design with pixel-perfect precision. Remind team members of KPIs and goals relevant to all involved to disrupt siloed thinking and agendas that may inhibit information sharing.</li>
<li><strong>Remind team members of their individual expertise</strong>. Publicly recognize team members with domain expertise to coax the sharing of unique knowledge. For example, a developer is well-suited to knowing facts about potential technical complications.</li>
<li><strong>Warn against overconfidence bias</strong>. Remind team members that, although they possess expertise, our understanding of complex topics is often incomplete and oversimplified.</li>
<li><strong>Don't rush to consensus</strong>. Never start a crucial decision-making meeting by polling, voting, or requesting opinions from participants (even anonymously). These activities reduce information sharing and processing and make it challenging to integrate new knowledge.</li>
<li><strong>Prioritize data gathering</strong>. Instruct team members to brainstorm before a deliberation meeting and come prepared to share their information immediately. Budget more time for this process when the consequences of failure are high.</li>
<li><strong>Visualize the data</strong>. Anyone who's engaged a team with a prototype has experienced the power of getting people out of their heads and onto a common understanding that all can see (a valuable aspect of <a href="https://www.nngroup.com/courses/ux-deliverables/">UX deliverables</a>). Favor <a href="https://www.nngroup.com/articles/recognition-and-recall/">recognition over recall</a>. Use whiteboards and write down all contributed information to ease the cognitive load.</li>
<li><strong>Mitigate social loafing</strong>. When team members withdraw from discussions, they stop contributing their unique knowledge. Direct questions to members exhibiting this behavior to reengage them.</li>
<li><strong>Involve others in UX research activities</strong>. One of the advantages of having colleagues participate in user research is that they gain first-hand knowledge. This tactic transforms UX research results from unique to common knowledge.</li>
<li><strong>Be cautious of using a devil's advocate</strong>. A devil's advocate is a team member assigned to critically review proposals to uncover problems or unrevealed <a href="https://www.nngroup.com/videos/design-tradeoffs-hidden-costs/">opportunity costs</a>. Research by Charles Schwenk and Richard Cosier suggests this tactic has mixed results. A devil's advocate can improve critical thinking but also decrease team members' desire to work together in the future.</li>
</ul>
<h2><a id="Conclusion" name="Conclusion"></a>Conclusion</h2>
<p>As counterintuitive as it seems, increasing the number of people involved in a difficult decision will likely decrease decision-making quality. Whatever unique knowledge individuals could offer to deliberations often goes unshared or disregarded. When decision-making stakes are high, don't let your valuable UX insights fall victim to the common-knowledge effect. Be a vigilant team facilitator to ensure that all of us are at least as smart as each of us.</p>
<h2><a id="References" name="References"></a>References</h2>
<p>Garold Stasser and William Titus. Pooling of unshared information in Group Decision making: Biased information sampling during discussion. <em>Journal of Personality and Social Psychology</em> <em>48</em>, 6 (1985), 1467–1478. DOI:http://dx.doi.org/10.1037/0022-3514.48.6.1467</p>
<p>Susanne Abele, Garold Stasser, and Sandra Vaughan-Parsons. Information Sharing, Cognitive Centrality, and Influence Among Business Executives During Collective Choice. <em>ERIM Report Series</em> <em>Reference No</em>. ERS-2005-037-ORG, (2005).</p>
<p>Torsten Reimer, Andrea Reimer, and Verlin B. Hinsz. 2010. Naïve groups can solve the hidden-profile problem. <em>Human Communication Research</em> 36, 3 (2010), 443–467. DOI:http://dx.doi.org/10.1111/j.1468-2958.2010.01383.x</p>
<p>Gwen M. Wittenbaum, Andrea B. Hollingshead, and Isabel C. Botero. 2004. From cooperative to motivated information sharing in groups: moving beyond the hidden profile paradigm. <em>Communication Monographs 71</em>, 3 (September 2004), 286–310. DOI:https://doi.org/10.1080/0363452042000299894</p>
<p>Charles R. Schwenk and Richard A. Cosier. 1993. Effects of Consensus and Devil's Advocacy On Strategic Decision-Making. <em>Journal of Applied Social Psychology</em> <em>23</em>, 2 (January 1993), 126–139. DOI:https://doi.org/10.1111/j.1559-1816.1993.tb01056.x</p>
<p>Simon S. K. Lam and John Schaubroeck. 2000. Improving group decisions by better pooling information: A comparative advantage of group decision support systems. <em>Journal of Applied Psychology 85</em>, 4 (2000), 565–573. DOI:https://doi.org/10.1037/0021-9010.85.4.565</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The 7th Guest gets VR remake using volumetric video (124 pts)]]></title>
            <link>https://www.the7thguest-vr.com/</link>
            <guid>37964575</guid>
            <pubDate>Sat, 21 Oct 2023 06:28:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.the7thguest-vr.com/">https://www.the7thguest-vr.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37964575">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="7">
									<div data-id="df86461" data-element_type="section" data-settings="{&quot;sticky&quot;:&quot;top&quot;,&quot;transparent&quot;:&quot;yes&quot;,&quot;sticky_on&quot;:[&quot;desktop&quot;,&quot;tablet&quot;,&quot;mobile&quot;],&quot;sticky_offset&quot;:0,&quot;sticky_effects_offset&quot;:0,&quot;transparent_on&quot;:[&quot;desktop&quot;,&quot;tablet&quot;,&quot;mobile&quot;],&quot;scroll_distance&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:60,&quot;sizes&quot;:[]},&quot;scroll_distance_tablet&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:&quot;&quot;,&quot;sizes&quot;:[]},&quot;scroll_distance_mobile&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:&quot;&quot;,&quot;sizes&quot;:[]}}">
					<div data-id="2a91c51" data-element_type="column" data-widget_type="image.default">
				<p><a href="#home">
							<img decoding="async" src="https://www.the7thguest-vr.com/wp-content/uploads/elementor/thumbs/7thGuest_Logo_Small_small-qaeu1nnfkdo41ldviezscxbgdwu2f0cbiplipgn8qo.png" title="7thGuest_Logo_Small_small" alt="7thGuest_Logo_Small_small" loading="lazy">								</a>
															</p>
				</div>
				<div data-id="7c2cc76" data-element_type="column" data-widget_type="image.default">
				<p><a href="#home">
							<img decoding="async" src="https://www.the7thguest-vr.com/wp-content/uploads/elementor/thumbs/7thGuest_btn_BuyNow-qdzp1r7jvym73995gt3z6ouj9s828wy03xlc3zysq4.jpg" title="7thGuest_btn_BuyNow" alt="7thGuest_btn_BuyNow" loading="lazy">								</a>
															</p>
				</div>
							</div>
				<div data-id="1ac276a" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;video&quot;,&quot;background_video_link&quot;:&quot;https:\/\/youtu.be\/-k6ZwSVokY4&quot;,&quot;background_video_start&quot;:0,&quot;background_video_end&quot;:40,&quot;background_play_on_mobile&quot;:&quot;yes&quot;}">
								
				<div data-id="6ea7178" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" src="https://www.the7thguest-vr.com/wp-content/uploads/elementor/thumbs/7thGuest_Logo_Update-qaeu0z7spyln4u219o5kcp17z1x50on9mssvmphtk0.png" title="7thGuest_Logo_Update" alt="7thGuest_Logo_Update" loading="lazy">															</p>
				</div>
				<div data-id="6a034ae" data-element_type="section" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h3>
                out now            </h3>
		
					</p>
				</div>
				
					</div>
				<div data-id="2e729cb" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="a42af5b" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                EXPERIENCE A SPINE-TINGLING MYSTERY 
LIKE NO OTHER            </h4>
		
					</p>
				</div>
				<div data-id="0510e5e" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="792" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png 792w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-300x19.png 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png 768w" sizes="(max-width: 792px) 100vw, 792px">															</p>
				</div>
				<div data-id="caca101" data-element_type="widget" data-widget_type="text-editor.default">
							<p>The iconic mystery game that chilled you to the bone in the 90s, the 7th Guest, has been brought back to life with cutting-edge VR technology that delivers an atmospheric and haunting story.&nbsp;</p>
<p>Explore the foreboding mansion, solve challenging puzzles, and uncover its dark secrets. The 7th Guest VR is the ultimate mystery adventure, and it’s time for you to experience it for yourself.&nbsp;</p>
<p>Six guests have been welcomed to the foreboding mansion. But something sinister is at play…</p>						</div>
					</div>
				<div data-id="156321d" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;background_motion_fx_motion_fx_scrolling&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_effect&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_affectedRange&quot;:{&quot;unit&quot;:&quot;%&quot;,&quot;size&quot;:&quot;&quot;,&quot;sizes&quot;:{&quot;start&quot;:10,&quot;end&quot;:90}},&quot;background_motion_fx_translateY_speed&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:5.7,&quot;sizes&quot;:[]},&quot;background_motion_fx_devices&quot;:[&quot;desktop&quot;,&quot;tablet&quot;,&quot;mobile&quot;]}">
								<div data-id="6824e64" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="948c4b2" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_TopLft-1.png" alt="">															</p>
				</div>
				<div data-id="59f1b68" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                A BELOVED CLASSICAL GAMING BRAND            </h4>
		
					</p>
				</div>
				<div data-id="efb14af" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="622" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png 622w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold-300x25.png 300w" sizes="(max-width: 622px) 100vw, 622px">															</p>
				</div>
				<div data-id="a1ff371" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Experience the classic game by Trilobyte and relive the original story from a whole new perspective. The 7th Guest VR brings back characters like Martine Burden, Brian Dutton, Edward &amp; Elinor Knox and others. Time to discover who is The 7th guest.</p>
				</div>
				<div data-id="1f17840" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_BtmLft-1.png" alt="">															</p>
				</div>
					</div>
				<div data-id="659d430" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="b83dfa0" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_TopRgt-1.png" alt="">															</p>
				</div>
				<div data-id="1974442" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                A TECHNICAL BENCHMARK            </h4>
		
					</p>
				</div>
				<div data-id="60f995b" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="622" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png 622w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold-300x25.png 300w" sizes="(max-width: 622px) 100vw, 622px">															</p>
				</div>
				<div data-id="57e012f" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_BtmRgt-1.png" alt="">															</p>
				</div>
				<div data-id="843c6bf" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Immerse into a visceral &amp; haunting VR story. Told through innovative and cutting-edge ghostly volumetric video capture with 3D live-action graphics and exquisite performances.</p>
				</div>
					</div>
					</div>
				<div data-id="02f3a12" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;background_motion_fx_motion_fx_scrolling&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_effect&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_affectedRange&quot;:{&quot;unit&quot;:&quot;%&quot;,&quot;size&quot;:&quot;&quot;,&quot;sizes&quot;:{&quot;start&quot;:10,&quot;end&quot;:90}},&quot;background_motion_fx_translateY_speed&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:5.7,&quot;sizes&quot;:[]},&quot;background_motion_fx_devices&quot;:[&quot;desktop&quot;,&quot;tablet&quot;,&quot;mobile&quot;]}">
								<div data-id="7326ee0" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" src="https://www.the7thguest-vr.com/wp-content/uploads/elementor/thumbs/7thGuest_IMG_Mansion-q67k83nimx8vnqc7mlbjglz0okd5j95tl5sqyovumm.jpg" title="7thGuest_IMG_Mansion" alt="7thGuest_IMG_Mansion" loading="lazy">															</p>
				</div>
				<div data-id="067258d" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                A BELOVED CLASSICAL GAMING BRAND            </h4>
		
					</p>
				</div>
				<div data-id="2475fe5" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="622" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png 622w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold-300x25.png 300w" sizes="(max-width: 622px) 100vw, 622px">															</p>
				</div>
				<div data-id="fea1a5b" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Experience the classic game by Trilobyte and relive the original story from a whole new perspective. The 7th Guest VR brings back characters like Martine Burden, Brian Dutton, Edward &amp; Elinor Knox and others. Time to discover who is The 7th guest.</p>
				</div>
				<div data-id="fc7b206" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" src="https://www.the7thguest-vr.com/wp-content/uploads/elementor/thumbs/7thGuest_IMG_Volumetric-q67k84lctra5zcauh3q613qh9y8iqy9jxag8fyugge.jpg" title="7thGuest_IMG_Volumetric" alt="7thGuest_IMG_Volumetric" loading="lazy">															</p>
				</div>
				<div data-id="f1bc4a8" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                A TECHNICAL BENCHMARK            </h4>
		
					</p>
				</div>
				<div data-id="ea02f17" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="622" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png 622w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold-300x25.png 300w" sizes="(max-width: 622px) 100vw, 622px">															</p>
				</div>
				<div data-id="8653ec1" data-element_type="widget" data-widget_type="text-editor.default">
				<p>Immerse into a visceral &amp; haunting VR story. Told through innovative and cutting-edge ghostly volumetric video capture with 3D live-action graphics and exquisite performances.</p>
				</div>
					</div>
				<div data-id="61056ef" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="e97e0cc" data-element_type="section">
								<div data-id="328944e" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                IMMERSIVE VR PUZZLE GAMEPLAY            </h4>
		
					</p>
				</div>
				<div data-id="40d261b" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="792" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png 792w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-300x19.png 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png 768w" sizes="(max-width: 792px) 100vw, 792px">															</p>
				</div>
				<div data-id="d0b90b4" data-element_type="widget" data-widget_type="text-editor.default">
				<p>All-new handcrafted puzzles, carefully redesigned for VR. All puzzles are meaningful to the story and rooted in lore with recognizable aesthetic elements paying homage to the original.</p>
				</div>
					</div>
				<div data-id="f846f29" data-element_type="section">
					<div data-id="454313f" data-element_type="column" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="432" height="300" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/06/T7G_Image_Animated_1-1.gif" alt="">															</p>
				</div>
				<div data-id="353e0c4" data-element_type="column" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="432" height="300" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/06/T7G_Image_Animated_2.gif" alt="">															</p>
				</div>
							</div>
				<div data-id="d7c1c28" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="6d34f5a" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Green_TopLft-1.png" alt="">															</p>
				</div>
				<div data-id="bd0312f" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                VR EXPLORATION            </h4>
		
					</p>
				</div>
				<div data-id="124207b" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Green_TopRgt-1.png" alt="">															</p>
				</div>
				<div data-id="24858cb" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="768" height="49" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png 768w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-300x19.png 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png 792w" sizes="(max-width: 768px) 100vw, 768px">															</p>
				</div>
				<div data-id="5c0534d" data-element_type="widget" data-widget_type="text-editor.default">
				<p>The equally beloved and feared haunted mansion comes alive around you through high-end visuals and VR-powered optical illusions, along with an an all new adaptive soundtrack, inspired by the original and positional audio.</p>
				</div>
				<div data-id="5dcf4a4" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Green_BtmLft-1.png" alt="">															</p>
				</div>
				<div data-id="fc1de4d" data-element_type="widget" data-widget_type="wb-before-after-image-slider-elementor.default">
					<p><span>Before</span>
			<span>After</span>
<img loading="lazy" width="1276" height="886" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1.jpg" alt="" decoding="async" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1.jpg 1276w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1-300x208.jpg 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1-1024x711.jpg 1024w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1-768x533.jpg 768w" sizes="(max-width: 1276px) 100vw, 1276px"><img loading="lazy" width="1276" height="886" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1.jpg" alt="" decoding="async" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1.jpg 1276w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1-300x208.jpg 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1-1024x711.jpg 1024w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1-768x533.jpg 768w" sizes="(max-width: 1276px) 100vw, 1276px">		</p>
		
		</div>
				<div data-id="169b1dc" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Green_BtmRgt-1.png" alt="">															</p>
				</div>
					</div>
					</div>
				<div data-id="c714b09" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="7255453" data-element_type="section">
								<div data-id="67301ab" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                IMMERSIVE VR PUZZLE GAMEPLAY            </h4>
		
					</p>
				</div>
				<div data-id="95ff377" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="792" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png 792w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-300x19.png 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png 768w" sizes="(max-width: 792px) 100vw, 792px">															</p>
				</div>
				<div data-id="0e3c29f" data-element_type="widget" data-widget_type="text-editor.default">
				<p>All-new handcrafted puzzles, carefully redesigned for VR. All puzzles are meaningful to the story and rooted in lore with recognizable aesthetic elements paying homage to the original.</p>
				</div>
					</div>
				<div data-id="f6c1a4d" data-element_type="section">
					<div data-id="774bd71" data-element_type="column" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="432" height="300" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/06/T7G_Image_Animated_1-1.gif" alt="">															</p>
				</div>
				<div data-id="fa83c54" data-element_type="column" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="432" height="300" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/06/T7G_Image_Animated_2.gif" alt="">															</p>
				</div>
							</div>
				<div data-id="69f9d1c" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="49240aa" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                VR EXPLORATION            </h4>
		
					</p>
				</div>
				<div data-id="270b05c" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="768" height="49" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-768x49.png 768w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen-300x19.png 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGreen.png 792w" sizes="(max-width: 768px) 100vw, 768px">															</p>
				</div>
				<div data-id="16ce997" data-element_type="widget" data-widget_type="text-editor.default">
				<p>The equally beloved and feared haunted mansion comes alive around you through high-end visuals and VR-powered optical illusions, along with an an all new adaptive soundtrack, inspired by the original and positional audio.</p>
				</div>
				<div data-id="9c7e0ac" data-element_type="widget" data-widget_type="wb-before-after-image-slider-elementor.default">
					<p><span>Before</span>
			<span>After</span>
<img loading="lazy" width="1276" height="886" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1.jpg" alt="" decoding="async" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1.jpg 1276w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1-300x208.jpg 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1-1024x711.jpg 1024w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Limbo-1-768x533.jpg 768w" sizes="(max-width: 1276px) 100vw, 1276px"><img loading="lazy" width="1276" height="886" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1.jpg" alt="" decoding="async" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1.jpg 1276w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1-300x208.jpg 300w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1-1024x711.jpg 1024w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_IMG_Volumetric_Pristine-1-768x533.jpg 768w" sizes="(max-width: 1276px) 100vw, 1276px">		</p>
		
		</div>
					</div>
					</div>
				<div data-id="10145c4" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;background_motion_fx_motion_fx_scrolling&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_effect&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_affectedRange&quot;:{&quot;unit&quot;:&quot;%&quot;,&quot;size&quot;:&quot;&quot;,&quot;sizes&quot;:{&quot;start&quot;:10,&quot;end&quot;:90}},&quot;background_motion_fx_translateY_speed&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:5.7,&quot;sizes&quot;:[]},&quot;background_motion_fx_devices&quot;:[&quot;desktop&quot;,&quot;tablet&quot;,&quot;mobile&quot;]}">
								<div data-id="55fc43e" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="8f15f79" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_TopLft-1.png" alt="">															</p>
				</div>
				<div data-id="b81cf24" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                MORE FROM THE 7TH GUEST VR            </h4>
		
					</p>
				</div>
				<div data-id="7d51409" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_TopRgt-1.png" alt="">															</p>
				</div>
				<div data-id="ca0b321" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="622" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png 622w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold-300x25.png 300w" sizes="(max-width: 622px) 100vw, 622px">															</p>
				</div>
				
				
				<div data-id="b9d1ef1" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_BtmLft-1.png" alt="">															</p>
				</div>
				<div data-id="c867774" data-element_type="widget" data-settings="{&quot;_position&quot;:&quot;absolute&quot;}" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="182" height="152" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_Silo_Corner_Gold_BtmRgt-1.png" alt="">															</p>
				</div>
					</div>
				<div data-id="08da0af" data-element_type="section" data-widget_type="heading.default">
				<p>
			<h2>buy now</h2>		</p>
				</div>
				
					</div>
				<div data-id="0d70d91" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;background_motion_fx_motion_fx_scrolling&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_effect&quot;:&quot;yes&quot;,&quot;background_motion_fx_translateY_affectedRange&quot;:{&quot;unit&quot;:&quot;%&quot;,&quot;size&quot;:&quot;&quot;,&quot;sizes&quot;:{&quot;start&quot;:10,&quot;end&quot;:90}},&quot;background_motion_fx_translateY_speed&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:5.7,&quot;sizes&quot;:[]},&quot;background_motion_fx_devices&quot;:[&quot;desktop&quot;,&quot;tablet&quot;,&quot;mobile&quot;]}">
								<div data-id="0368221" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
								<div data-id="ac1d3ff" data-element_type="widget" data-widget_type="gradient_heading.default">
				<p>
			
		
            <h4>
                MORE FROM THE 7TH GUEST VR            </h4>
		
					</p>
				</div>
				<div data-id="862b4e4" data-element_type="widget" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="622" height="51" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold.png 622w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/7thGuest_DeviderGold-300x25.png 300w" sizes="(max-width: 622px) 100vw, 622px">															</p>
				</div>
				
					</div>
				<div data-id="9789718" data-element_type="section" data-widget_type="heading.default">
				<p>
			<h2>Wishlist now</h2>		</p>
				</div>
				
					</div>
				
				<div data-id="721c791" data-element_type="section">
								<div data-id="7b31796" data-element_type="section" data-widget_type="image.default">
				<p><a href="https://vertigo-games.com/" target="_blank">
							<img decoding="async" src="https://www.the7thguest-vr.com/wp-content/uploads/elementor/thumbs/VG_Horizontel_Light_FullColor-q6jjwk5hckbqvgis09zeac032zystkj9vnkhrb9fy8.png" title="VG_Horizontel_Light_FullColor" alt="VG_Horizontel_Light_FullColor" loading="lazy">								</a>
															</p>
				</div>
				
				<div data-id="317a997" data-element_type="section">
					<div data-id="9b2f58c" data-element_type="column" data-widget_type="text-editor.default">
							<p>The 7th Guest VR® 2023 Vertigo Games, Published by Vertigo Publishing B.V. Developed by Vertigo Studios B.V. ©2023</p><p>©2023 Facebook Technologies, LLC. OCULUS and OCULUS logo are trademarks or registered trademarks of Facebook Technologies, LLC. All rights reserved</p><p>®2023 Sony Interactive Entertainment LLC “PlayStation Family Mark”, “PlayStation”, “PS5 logo”, “PS5”, “PS4 logo”, “PS4”, “PlayStation Shapes Logo”and “Play Has No Limits” are registered trademarks or trademarks of Sony Interactive Entertainment Inc.</p><p><a href="https://drive.google.com/open?id=1gFC7opo9PjP08p5ZibK_wkLn0CFIOzNW&amp;usp=drive_fs" target="_blank" rel="noopener">Press Pack</a></p>						</div>
				<div data-id="a15d02f" data-element_type="column" data-widget_type="image.default">
				<p><img decoding="async" loading="lazy" width="631" height="300" src="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/T7G_ESRB_descriptors.png" alt="" srcset="https://www.the7thguest-vr.com/wp-content/uploads/2023/05/T7G_ESRB_descriptors.png 631w, https://www.the7thguest-vr.com/wp-content/uploads/2023/05/T7G_ESRB_descriptors-300x143.png 300w" sizes="(max-width: 631px) 100vw, 631px">															</p>
				</div>
							</div>
					</div>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twitch will now let streamers simultaneously stream on any service they want (176 pts)]]></title>
            <link>https://www.theverge.com/2023/10/20/23926013/twitch-simultaneously-stream-any-service-platform-twitchcon</link>
            <guid>37964204</guid>
            <pubDate>Sat, 21 Oct 2023 04:55:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2023/10/20/23926013/twitch-simultaneously-stream-any-service-platform-twitchcon">https://www.theverge.com/2023/10/20/23926013/twitch-simultaneously-stream-any-service-platform-twitchcon</a>, See on <a href="https://news.ycombinator.com/item?id=37964204">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Twitch will now let its creators simultaneously stream across any live streaming service, the company announced on Friday as part of <a href="https://blog.twitch.tv/en/2023/10/20/everything-we-announced-at-twitchcon-las-vegas/">a big batch of news from TwitchCon</a>. Previously, streamers could simulcast <a href="https://www.theverge.com/2022/8/23/23317939/twitch-ends-partner-exclusivity-youtube-tiktok-facebook-gaming">on mobile platforms</a> like TikTok and Instagram, but as of Friday, Twitch is significantly broadening where streamers can simultaneously go live. (Well, assuming the streamers don’t have a Twitch exclusivity agreement in place.)</p><p>As of late, some Twitch streamers have been exploring options on other platforms. Big names like <a href="https://www.theverge.com/2023/6/17/23764530/twitch-star-felix-xqc-lengyel-has-signed-a-100-million-deal-with-rival-platform-kick">xQc</a>, <a href="https://www.pcgamer.com/amouranth-gives-twitch-the-boot-as-kick-steals-second-streaming-star-in-under-2-days/">Amouranth</a>, and <a href="https://www.forbes.com/sites/mattcraig/2023/10/19/kick-signs-nickmercs-nick-kolcheff--to-10-million-deal/?sh=6fe7cc994c66">Nickmercs</a> have signed major deals with Twitch competitor Kick this year; xQc’s and Nickmercs’ deals are non-exclusive, and given that Amouranth has a video on her Twitch account from a couple months ago, it seems hers is non-exclusive, too. Ninja dropped his exclusive contract with Twitch <a href="https://www.pcgamer.com/ninja-drops-twitch-exclusivity-and-starts-streaming-on-youtube-facebook-and-more/">in September 2022</a> so he could simulcast on multiple platforms. (He dined with Twitch CEO Dan Clancy <a href="https://twitter.com/djclancy999/status/1709393663975960825">earlier this month</a> and <a href="https://twitter.com/Ninja/status/1715442576793465285">seems pleased with Friday’s news</a>.) </p><p>There are a few guidelines for Twitch’s new simulcasting policy, <a href="https://help.twitch.tv/s/article/simulcasting-guidelines?language=en_US">according to a support document</a>. Streamers will have to make sure the quality of their stream on Twitch is “no less than the experience on other platforms or services.” Streamers “should not” share links to their Twitch community to their simulcasts on other platforms. (Streamers can still share links to third-party websites on their About pages on their channels, they just can’t link out to their other simulcasts while they’re also live on Twitch.) And streamers can’t use third-party services to do things like merge chat across platforms.</p><p>At some point in the future, Twitch says it will add a tool so that streamers can indicate that they are simulcasting.</p><p>Twitch also announced a big update to its off-service conduct policy. “To further protect our streamers, we’re&nbsp;<strong>adding doxxing and swatting to the list of Off-Service Conduct</strong>&nbsp;behaviors we will enforce against,” the company says (emphasis Twitch’s), and the changes are in effect as of Friday. The addition of doxxing to the policy follows a recent controversy involving <a href="https://www.nbcnews.com/tech/jacksfilms-sssniperwolf-doxxing-allegations-youtube-response-rcna121297">YouTuber Jacksfilms accusing SSSniperWolf of doxxing him</a> in an Instagram story; on Friday, YouTube announced it would be temporarily <a href="https://twitter.com/TeamYouTube/status/1715406957736038476?s=20">demonetizing SSSniperWolf’s channel</a> and SSSniperWolf posted <a href="https://twitter.com/sssniperwolf/status/1715417126113362219?s=20">an apology on X (formerly Twitter)</a>.</p><p>Twitch revealed some product changes, too. <a href="https://www.theverge.com/2023/3/21/23644633/twitch-monetization-ad-incentive-program-guest-star">Guest Star</a>, which lets streamers host co-streams with others, will now be named Stream Together and will be getting features like the ability to merge chats. Twitch says a version of <a href="https://www.theverge.com/2023/8/22/23842075/twitch-tiktok-style-discovery-feed">its TikTok-style Discovery Feed</a> that surfaces live channels is in testing. And Twitch’s own alerts system for notifications like subscribers and <a href="https://www.theverge.com/2016/6/27/12041426/twitch-streaming-real-money-bits-emotes-cheer-feature">Bits donations</a> will “soon” support a streamer’s custom animated emotes.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Recent adventures in performance optimization with Rust (144 pts)]]></title>
            <link>https://willcrichton.net/notes/k-corrset/</link>
            <guid>37964161</guid>
            <pubDate>Sat, 21 Oct 2023 04:44:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://willcrichton.net/notes/k-corrset/">https://willcrichton.net/notes/k-corrset/</a>, See on <a href="https://news.ycombinator.com/item?id=37964161">Hacker News</a></p>
<div id="readability-page-1" class="page">

<p>This note documents one of my recent adventures in performance
optimization with Rust. By following along, hopefully you’ll learn
something about how to write fast Rust.</p>
<p>Here’s the context: imagine you have data from an online exam where a
set of users answered a set of questions. The raw data looks like
this:</p>
<div id="cb1"><pre><code><span id="cb1-1">[</span>
<span id="cb1-2">  {</span>
<span id="cb1-3">    <span>"user"</span><span>:</span> <span>"5ea2c2e3-4dc8-4a5a-93ec-18d3d9197374"</span><span>,</span></span>
<span id="cb1-4">    <span>"question"</span><span>:</span> <span>"7d42b17d-77ff-4e0a-9a4d-354ddd7bbc57"</span><span>,</span></span>
<span id="cb1-5">    <span>"score"</span><span>:</span> <span>1</span></span>
<span id="cb1-6">  }<span>,</span></span>
<span id="cb1-7">  {</span>
<span id="cb1-8">    <span>"user"</span><span>:</span> <span>"b7746016-fdbf-4f8a-9f84-05fde7b9c07a"</span><span>,</span></span>
<span id="cb1-9">    <span>"question"</span><span>:</span> <span>"7d42b17d-77ff-4e0a-9a4d-354ddd7bbc57"</span><span>,</span></span>
<span id="cb1-10">    <span>"score"</span><span>:</span> <span>0</span></span>
<span id="cb1-11">  }<span>,</span>  </span>
<span id="cb1-12">  <span>/* ... more data ... */</span></span>
<span id="cb1-13">]</span></code></pre></div>
<p>Note that each user only answered a subset of all possible questions,
and all scores are either 0 or 1.</p>
<p>Here’s the problem: given a size
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>,
which set of
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span></span>
questions has the highest correlation with overall performance? We’ll
call this the <strong>k-CorrSet problem</strong>. A simple brute-force
algorithm for solving the k-CorrSet problem looks like this
pseudocode:</p>
<pre><code>func k_corrset($data, $k):
  $all_qs = all questions in $data
  for all $k-sized subsets $qs within $all_qs:
    $us = all users that answered every question in $qs
    $qs_totals = the total score on $qs of each user in $us
    $grand_totals = the grand score on $all_qs of each user in $us
    $r = correlation($qs_totals, $grand_totals)
  return $qs with maximum $r    </code></pre>
<p>We are going to implement several variations on this algorithm to see
how fast we can make it.</p>
<h2 id="python-baseline">Python Baseline</h2>
<p>When I do data analysis, I usually start with Python and then
transition to Rust when I need better speed or memory consumption. So as
a baseline, let’s look at a straightforward <a href="https://pandas.pydata.org/">Pandas</a> program for solving
k-CorrSet:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>from</span> itertools <span>import</span> combinations</span>
<span id="cb3-2"><span>import</span> pandas <span>as</span> pd</span>
<span id="cb3-3"><span>from</span> pandas <span>import</span> IndexSlice <span>as</span> islice</span>
<span id="cb3-4"></span>
<span id="cb3-5"><span>def</span> k_corrset(data, K):</span>
<span id="cb3-6">    all_qs <span>=</span> data.question.unique()</span>
<span id="cb3-7">    q_to_score <span>=</span> data.set_index([<span>'question'</span>, <span>'user'</span>])</span>
<span id="cb3-8">    all_grand_totals <span>=</span> data.groupby(<span>'user'</span>).score.<span>sum</span>().rename(<span>'grand_total'</span>)</span>
<span id="cb3-9"></span>
<span id="cb3-10">    corrs <span>=</span> []</span>
<span id="cb3-11">    <span>for</span> qs <span>in</span> combinations(all_qs, K):</span>
<span id="cb3-12">        qs_data <span>=</span> q_to_score.loc[islice[qs,:],:].swaplevel()</span>
<span id="cb3-13">        answered_all <span>=</span> qs_data.groupby(level<span>=</span>[<span>0</span>]).size() <span>==</span> K</span>
<span id="cb3-14">        answered_all <span>=</span> answered_all[answered_all].index</span>
<span id="cb3-15">        qs_totals <span>=</span> qs_data.loc[islice[answered_all,:]] <span>\</span></span>
<span id="cb3-16">            .groupby(level<span>=</span>[<span>0</span>]).<span>sum</span>().rename(columns<span>=</span>{<span>'score'</span>: <span>'qs'</span>})</span>
<span id="cb3-17">        r <span>=</span> qs_totals.join(all_grand_totals).corr().qs.grand_total</span>
<span id="cb3-18">        corrs.append({<span>'qs'</span>: qs, <span>'r'</span>: r})</span>
<span id="cb3-19">    corrs <span>=</span> pd.DataFrame(corrs)</span>
<span id="cb3-20"></span>
<span id="cb3-21">    <span>return</span> corrs.sort_values(<span>'r'</span>, ascending<span>=</span><span>False</span>).iloc[<span>0</span>].qs</span>
<span id="cb3-22"></span>
<span id="cb3-23">data <span>=</span> pd.read_json(<span>'scores.json'</span>)</span>
<span id="cb3-24"><span>print</span>(k_corrset(data, K<span>=</span><span>5</span>))</span></code></pre></div>
<p>This uses a bit of <a href="https://pandas.pydata.org/docs/user_guide/advanced.html">MultiIndex</a>
magic, but don’t sweat the details. Let’s start benchmarking. First, we
need data. To make the benchmark realistic, I generated synthetic data
that roughly matches the properties of my actual data. The properties of
the synthetic data are:</p>
<ul>
<li>60,000 users</li>
<li>200 questions</li>
<li>20% sparsity (i.e., 12,000 users answered each question)</li>
<li>Each score is equally likely 1 or 0</li>
</ul>
<p>Our goal will be to compute k-CorrSet on this dataset for k = 5 in a
reasonable amount of time on my 2021 M1 Macbook Pro. Note that there are
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mn>200</mn><mn>5</mn></mfrac><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\binom{200}{5}</annotation></semantics></math></span></span>
= 2.5 billion combinations of questions, so we need the inner loop of
the brute-force algorithm to be quite fast.</p>
<p>Using Python’s <a href="https://docs.python.org/3/library/time.html#time.time"><code>time.time()</code></a>
function, I computed the speed of the inner loop for 1,000 iterations
running with CPython 3.9.17. The average execution time was <strong>36
milliseconds</strong>. Not too bad, but at this rate, the full
computation would complete in <strong>2.9 years</strong>. Let’s make
that faster!</p>
<blockquote>
<p>Note: there are lots of ways we could make the Python code faster,
but the point of this post isn’t to compare highly-optimized Python to
highly-optimized Rust. The point is to compare
“standard-Jupyter-notebook” Python to highly-optimized Rust.</p>
</blockquote>
<h2 id="rust-reimplementation">Rust Reimplementation</h2>
<p>We can start optimizing by reimplementing the Python code into a
roughly equivalent Rust program, expecting some free speedups from
Rust’s compiler optimizations. For readability, all the code below is a
simplification of the actual benchmark. For instance, I will omit
<code>#[derive]</code>s on types, and I will coalesce disparate blocks
of code into straight-line functions. You can see the full benchmark
here: <a href="https://github.com/willcrichton/corrset-benchmark">https://github.com/willcrichton/corrset-benchmark</a></p>
<p>First, we translate the data types:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>pub</span> <span>struct</span> User(<span>pub</span> <span>String</span>)<span>;</span></span>
<span id="cb4-2"></span>
<span id="cb4-3"><span>pub</span> <span>struct</span> Question(<span>pub</span> <span>String</span>)<span>;</span></span>
<span id="cb4-4"></span>
<span id="cb4-5"><span>pub</span> <span>struct</span> Row <span>{</span></span>
<span id="cb4-6">  <span>pub</span> user<span>:</span> User<span>,</span></span>
<span id="cb4-7">  <span>pub</span> question<span>:</span> Question<span>,</span></span>
<span id="cb4-8">  <span>pub</span> score<span>:</span> <span>u32</span><span>,</span></span>
<span id="cb4-9"><span>}</span></span></code></pre></div>
<p>We make <code>User</code> and <code>Question</code> into newtypes
both for clarity and so we can implement traits on them. Then, the basic
k-CorrSet algorithm is implemented as follows:</p>
<div id="cb5"><pre><code><span id="cb5-1"><span>fn</span> k_corrset(data<span>:</span> <span>&amp;</span>[Row]<span>,</span> k<span>:</span> <span>usize</span>) <span>-&gt;</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;</span> <span>{</span></span>
<span id="cb5-2">  <span>// utils::group_by(impl Iterator&lt;Item = (K1, K2, V)&gt;) </span></span>
<span id="cb5-3">  <span>//   -&gt; HashMap&lt;K1, HashMap&lt;K2, V&gt;&gt;;</span></span>
<span id="cb5-4">  <span>let</span> q_to_score<span>:</span> HashMap<span>&lt;&amp;</span>Question<span>,</span> HashMap<span>&lt;&amp;</span>User<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb5-5">    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (<span>&amp;</span>r<span>.</span>question<span>,</span> <span>&amp;</span>r<span>.</span>user<span>,</span> r<span>.</span>score)))<span>;</span></span>
<span id="cb5-6">  <span>let</span> u_to_score<span>:</span> HashMap<span>&lt;&amp;</span>User<span>,</span> HashMap<span>&lt;&amp;</span>Question<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb5-7">    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (<span>&amp;</span>r<span>.</span>user<span>,</span> <span>&amp;</span>r<span>.</span>question<span>,</span> r<span>.</span>score)))<span>;</span></span>
<span id="cb5-8">  <span>let</span> all_grand_totals<span>:</span> HashMap<span>&lt;&amp;</span>User<span>,</span> <span>u32</span><span>&gt;</span> <span>=</span> </span>
<span id="cb5-9">    u_to_score<span>.</span>iter()<span>.</span>map(<span>|</span>(user<span>,</span> scores)<span>|</span> <span>{</span></span>
<span id="cb5-10">      <span>let</span> total <span>=</span> scores<span>.</span>values()<span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()<span>;</span></span>
<span id="cb5-11">      (<span>*</span>user<span>,</span> total)</span>
<span id="cb5-12">    <span>}</span>)</span>
<span id="cb5-13">    <span>.</span>collect()<span>;</span></span>
<span id="cb5-14"></span>
<span id="cb5-15">  <span>let</span> all_qs <span>=</span> q_to_score<span>.</span>keys()<span>.</span>copied()<span>;</span></span>
<span id="cb5-16">  all_qs<span>.</span>combinations(k)</span>
<span id="cb5-17">    <span>.</span>filter_map(<span>|</span>qs<span>:</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;|</span> <span>{</span></span>
<span id="cb5-18">      <span>let</span> (qs_totals<span>,</span> grand_totals)<span>:</span> (<span>Vec</span><span>&lt;</span>_<span>&gt;,</span> <span>Vec</span><span>&lt;</span>_<span>&gt;</span>) <span>=</span> all_grand_totals<span>.</span>iter()</span>
<span id="cb5-19">        <span>.</span>filter_map(<span>|</span>(u<span>,</span> grand_total)<span>|</span> <span>{</span></span>
<span id="cb5-20">          <span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb5-21">            <span>.</span>map(<span>|</span>q<span>|</span> q_to_score[<span>*</span>q]<span>.</span>get(u)<span>.</span>copied())</span>
<span id="cb5-22">            <span>.</span><span>sum::</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;</span>()<span>?;</span></span>
<span id="cb5-23">          <span>Some</span>((q_total <span>as</span> <span>f64</span><span>,</span> <span>*</span>grand_total <span>as</span> <span>f64</span>))</span>
<span id="cb5-24">        <span>}</span>)</span>
<span id="cb5-25">        <span>.</span>unzip()<span>;</span></span>
<span id="cb5-26">      <span>// utils::correlation(&amp;[f64], &amp;[f64]) -&gt; f64;</span></span>
<span id="cb5-27">      <span>let</span> r <span>=</span> <span>utils::</span>correlation(<span>&amp;</span>qs_totals<span>,</span> <span>&amp;</span>grand_totals)<span>;</span></span>
<span id="cb5-28">      (<span>!</span>r<span>.</span>is_nan())<span>.</span>then_some((qs<span>,</span> r))</span>
<span id="cb5-29">    <span>}</span>)</span>
<span id="cb5-30">    <span>.</span>max_by_key(<span>|</span>(_<span>,</span> r)<span>|</span> FloatOrd(<span>*</span>r))</span>
<span id="cb5-31">    <span>.</span>unwrap()<span>.</span><span>0</span></span>
<span id="cb5-32"><span>}</span></span></code></pre></div>
<p>The key elements to understand:</p>
<ul>
<li>Like with Python, we convert the flat data into hierarchical data
with a hashmap and the <code>utils::group_by</code> helper. (Note that
everywhere we refer to <code>HashMap</code> is actually an alias for <a href="https://docs.rs/fxhash/0.2.1/fxhash/type.FxHashMap.html"><code>fxhash::FxHashMap</code></a>,
which is just <a href="https://doc.rust-lang.org/stable/std/collections/struct.HashMap.html"><code>std::collections::HashMap</code></a>
with a more efficient hashing algorithm.)</li>
<li>Then we iterate over all combinations of questions using the <a href="https://docs.rs/itertools/0.11.0/itertools/trait.Itertools.html#method.combinations"><code>Itertools::combinations</code></a>
method.</li>
<li>In the inner loop, we iterate over all users via
<code>all_grand_totals.iter()</code>.</li>
<li>The expression <code>q_to_score[*q].get(u).copied()</code> has type
<code>Option&lt;u32&gt;</code>, which is <code>Some(n)</code> if the
user has a score for <code>q</code>, and <code>None</code>
otherwise.</li>
<li>The iterator method <code>.sum::&lt;Option&lt;u32&gt;&gt;()</code>
returns <code>Some(total)</code> if the user answered every question in
<code>qs</code>, and <code>None</code> otherwise.</li>
<li>We call a helper method <code>utils::correlation</code> that
implements a standard calculation for <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson’s
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span></span></a>.</li>
<li>We use <code>max_by_key</code> to get the questions with the highest
correlation. We use <a href="https://docs.rs/float-ord/0.3.2/float_ord/struct.FloatOrd.html"><code>FloatOrd</code></a>
so we can compare floats.</li>
</ul>
<p>So how’s the performance? I used <a href="https://bheisler.github.io/criterion.rs/book/index.html">Criterion</a>
to benchmark the performance of the inner loop (the
<code>filter_map</code>) with Criterion’s default settings, using the
same dataset as before. The new inner loop runs in <strong>4.2
milliseconds</strong>, which is about 8 times faster than the Python
baseline! But our full computation is still 124 days, which is too long.
Now let’s start really optimizing.</p>
<h2 id="indexed-data">Indexed Data</h2>
<p>Rather than guess how to optimize the code, let’s run a profiler to
see where the bottleneck is. On my Mac, I usually use <a href="https://en.wikipedia.org/wiki/Instruments_(software)">Instruments.app</a>,
but recently I tried <a href="https://github.com/mstange/samply/">samply</a> and wow! It’s much
nicer to use. Samply seems to work better with Rust both in terms of
symbol demangling and in terms of reconstructing the call stack. Here’s
a screenshot of the relevant part of the samply trace for the Rust
implementation so far:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-naive.png"></p>
<p>We’re spending 75% of our time in <code>HashMap::get</code>! This is
the offending line of code:</p>
<div id="cb6"><pre><code><span id="cb6-1">q_to_score[<span>*</span>q]<span>.</span>get(u)<span>.</span>copied()</span></code></pre></div>
<p>The problem is that we’re hashing and comparing 36-byte UUID strings,
which is expensive. We need a smaller type that can stand-in for the
question/user strings.</p>
<p>The solution is that we will collect all the questions and users into
a <code>Vec</code>, and represent each question/user by their index in
that <code>Vec</code>. We could just use <code>usize</code> indices with
the <code>Vec</code> type, but a better practice is to use newtypes to
represent each kind of index. In fact, this problem comes up so often in
my work that I’ve already made a crate for it, <a href="https://docs.rs/indexical/0.6.0/indexical/index.html">Indexical</a>
(which builds on the <a href="https://docs.rs/index_vec/0.1.3/index_vec/index.html">index_vec</a>
crate). We define those index types like this:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>pub</span> <span>struct</span> QuestionRef<span>&lt;</span><span>'a</span><span>&gt;</span>(<span>pub</span> <span>&amp;</span><span>'a</span> Question)<span>;</span></span>
<span id="cb7-2"><span>pub</span> <span>struct</span> UserRef<span>&lt;</span><span>'a</span><span>&gt;</span>(<span>pub</span> <span>&amp;</span><span>'a</span> User)<span>;</span></span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>define_index_type!</span> <span>{</span></span>
<span id="cb7-5">  <span>pub</span> <span>struct</span> QuestionIdx <span>for</span> QuestionRef<span>&lt;</span><span>'a</span><span>&gt;</span> <span>=</span> <span>u16</span><span>;</span></span>
<span id="cb7-6"><span>}</span></span>
<span id="cb7-7"></span>
<span id="cb7-8"><span>define_index_type!</span> <span>{</span></span>
<span id="cb7-9">  <span>pub</span> <span>struct</span> UserIdx <span>for</span> UserRef<span>&lt;</span><span>'a</span><span>&gt;</span> <span>=</span> <span>u32</span><span>;</span></span>
<span id="cb7-10"><span>}</span></span></code></pre></div>
<p>The <code>QuestionRef</code> and <code>UserRef</code> types are
newtypes that enable us to implement traits on
<code>&amp;Question</code> and <code>&amp;User</code>. The
<code>define_index_type</code> macro creates new index types
<code>QuestionIdx</code> and <code>UserIdx</code> which are associated
with <code>QuestionRef</code> and <code>UserRef</code>. Those indices
are represented as <code>u16</code> and a <code>u32</code>,
respectively.</p>
<p>Finally we update <code>k_corrset</code> to generate an <a href="https://docs.rs/indexical/0.6.0/indexical/struct.IndexedDomain.html"><code>IndexedDomain</code></a>
for questions and users, and then use the <code>QuestionIdx</code> and
<code>UserIdx</code> types throughout the rest of the code:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>fn</span> k_corrset(data<span>:</span> <span>&amp;</span>[Row]<span>,</span> k<span>:</span> <span>usize</span>) <span>-&gt;</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;</span> <span>{</span></span>
<span id="cb8-2">  <span>// first, we create an `IndexedDomain` for questions and users</span></span>
<span id="cb8-3">  <span>let</span> (questions_set<span>,</span> users_set)<span>:</span> (HashSet<span>&lt;</span>_<span>&gt;,</span> HashSet<span>&lt;</span>_<span>&gt;</span>) <span>=</span> data<span>.</span>iter()</span>
<span id="cb8-4">    <span>.</span>map(<span>|</span>row<span>|</span> (QuestionRef(<span>&amp;</span>row<span>.</span>question)<span>,</span> UserRef(<span>&amp;</span>row<span>.</span>user)))</span>
<span id="cb8-5">    <span>.</span>unzip()<span>;</span></span>
<span id="cb8-6">  <span>let</span> questions <span>=</span> <span>IndexedDomain::</span>from_iter(questions_set)<span>;</span></span>
<span id="cb8-7">  <span>let</span> users <span>=</span> <span>IndexedDomain::</span>from_iter(users_set)<span>;</span></span>
<span id="cb8-8"></span>
<span id="cb8-9">  <span>// then we create the same data structures as before, </span></span>
<span id="cb8-10">  <span>// except using `IndexedDomain::index` to lookup indices.</span></span>
<span id="cb8-11">  <span>// note the change in the HashMap key types</span></span>
<span id="cb8-12">  <span>let</span> q_to_score<span>:</span> HashMap<span>&lt;</span>QuestionIdx<span>,</span> HashMap<span>&lt;</span>UserIdx<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb8-13">    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (</span>
<span id="cb8-14">      questions<span>.</span>index(<span>&amp;</span>(QuestionRef(<span>&amp;</span>r<span>.</span>question)))<span>,</span></span>
<span id="cb8-15">      users<span>.</span>index(<span>&amp;</span>(UserRef(<span>&amp;</span>r<span>.</span>user)))<span>,</span></span>
<span id="cb8-16">      r<span>.</span>score<span>,</span></span>
<span id="cb8-17">    )))<span>;</span></span>
<span id="cb8-18">  <span>let</span> u_to_score<span>:</span> HashMap<span>&lt;</span>UserIdx<span>,</span> HashMap<span>&lt;</span>QuestionIdx<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb8-19">    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (</span>
<span id="cb8-20">      users<span>.</span>index(<span>&amp;</span>(UserRef(<span>&amp;</span>r<span>.</span>user)))<span>,</span></span>
<span id="cb8-21">      questions<span>.</span>index(<span>&amp;</span>(QuestionRef(<span>&amp;</span>r<span>.</span>question)))<span>,</span></span>
<span id="cb8-22">      r<span>.</span>score<span>,</span></span>
<span id="cb8-23">    )))<span>;</span>  </span>
<span id="cb8-24">  <span>let</span> all_grand_totals <span>=</span> <span>// same code</span></span>
<span id="cb8-25"></span>
<span id="cb8-26">  <span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb8-27">  all_qs<span>.</span>combinations(k)</span>
<span id="cb8-28">    <span>.</span>filter_map(<span>|</span>qs<span>:</span> <span>Vec</span><span>&lt;</span>QuestionIdx<span>&gt;|</span> <span>{</span></span>
<span id="cb8-29">      <span>// same code</span></span>
<span id="cb8-30">    <span>}</span>)</span>
<span id="cb8-31">    <span>.</span>max_by_key(<span>|</span>(_<span>,</span> r)<span>|</span> FloatOrd(<span>*</span>r))</span>
<span id="cb8-32">    <span>.</span>unwrap()<span>.</span><span>0</span></span>
<span id="cb8-33">    <span>// we have to post-process the indices back to values</span></span>
<span id="cb8-34">    <span>.</span>into_iter()<span>.</span>map(<span>|</span>idx<span>|</span> questions<span>.</span>value(idx)<span>.</span><span>0</span>)<span>.</span>collect()</span>
<span id="cb8-35"><span>}</span></span></code></pre></div>
<p>Again, check out the <a href="https://github.com/willcrichton/corrset-benchmark/blob/main/src/inner/indexed.rs">GitHub</a>
for the complete implementation, and check out the <a href="https://docs.rs/indexical/0.6.0/indexical/index.html">indexical
docs</a> for details on its API.</p>
<p>Once again we run our benchmark on the inner loop of the computation.
The new inner loop runs in <strong>1.0 milliseconds</strong>, which is 4
times faster than our last iteration, and 35 times faster than our
Python baseline. We’re down to 30 days for the total computation — let’s
keep going!</p>
<h2 id="indexed-collections">Indexed Collections</h2>
<p>Let’s profile again:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-indexed.png"></p>
<p>Blast, still spending most our time in <code>HashMap::get</code>.
Well, what if we got rid of hash maps altogether? A
<code>HashMap&lt;&amp;User, u32&gt;</code> is conceptually the same
thing as a <code>Vec&lt;Option&lt;u32&gt;&gt;</code> where each
<code>&amp;User</code> has a unique index. For example, in a domain of
users <code>["a", "b", "c"]</code>, then the hash map
<code>{"b" =&gt; 1}</code> is equivalent to the vector
<code>[None, Some(1), None]</code>. This vector costs more memory
(paying for the <code>None</code> spaces), but it improves the
performance of key/value lookups (avoids hashing).</p>
<p>We’re trying to fully optimize for performance, and given the scale
of our dataset, we can afford to make the compute/memory trade-off. We
will use Indexical which provides a <a href="https://docs.rs/indexical/0.6.0/indexical/map/struct.DenseIndexMap.html"><code>DenseIndexMap&lt;K, V&gt;</code></a>
type that is internally implemented as a <code>Vec&lt;V&gt;</code> type
indexed by <code>K::Index</code>.</p>
<p>The main change to the <code>k_corrset</code> function is that we
convert all our auxiliary data structures to dense index maps:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>pub</span> <span>type</span> QuestionMap<span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span> <span>=</span> DenseIndexMap<span>&lt;</span><span>'a</span><span>,</span> QuestionRef<span>&lt;</span><span>'a</span><span>&gt;,</span> T<span>&gt;;</span></span>
<span id="cb9-2"><span>pub</span> <span>type</span> UserMap<span>&lt;</span><span>'a</span><span>,</span> T<span>&gt;</span> <span>=</span> DenseIndexMap<span>&lt;</span><span>'a</span><span>,</span> UserRef<span>&lt;</span><span>'a</span><span>&gt;,</span> T<span>&gt;;</span></span>
<span id="cb9-3"></span>
<span id="cb9-4"><span>fn</span> k_corrset(data<span>:</span> <span>&amp;</span>[Row]<span>,</span> k<span>:</span> <span>usize</span>) <span>-&gt;</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;</span> <span>{</span></span>
<span id="cb9-5">  <span>// build the `users` and `questions` domains same as before</span></span>
<span id="cb9-6"></span>
<span id="cb9-7">  <span>// Initialize q_to_score to an empty dense map</span></span>
<span id="cb9-8">  <span>let</span> <span>mut</span> q_to_score<span>:</span> QuestionMap<span>&lt;</span><span>'_</span><span>,</span> UserMap<span>&lt;</span><span>'_</span><span>,</span> <span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;&gt;</span> <span>=</span> </span>
<span id="cb9-9">    <span>QuestionMap::</span>new(<span>&amp;</span>questions<span>,</span> <span>|</span>_<span>|</span> <span>UserMap::</span>new(<span>&amp;</span>users<span>,</span> <span>|</span>_<span>|</span> <span>None</span>))<span>;</span>  </span>
<span id="cb9-10"></span>
<span id="cb9-11">  <span>// Fill in q_to_score with the dataset</span></span>
<span id="cb9-12">  <span>for</span> r <span>in</span> data <span>{</span></span>
<span id="cb9-13">    q_to_score</span>
<span id="cb9-14">      <span>.</span>get_mut(<span>&amp;</span>QuestionRef(<span>&amp;</span>r<span>.</span>question))</span>
<span id="cb9-15">      <span>.</span>unwrap()</span>
<span id="cb9-16">      <span>.</span>insert(UserRef(<span>&amp;</span>r<span>.</span>user)<span>,</span> <span>Some</span>(r<span>.</span>score))<span>;</span></span>
<span id="cb9-17">  <span>}</span></span>
<span id="cb9-18"></span>
<span id="cb9-19">  <span>let</span> grand_totals <span>=</span> <span>UserMap::</span>new(<span>&amp;</span>users<span>,</span> <span>|</span>u<span>|</span> <span>{</span></span>
<span id="cb9-20">    q_to_score<span>.</span>values()<span>.</span>filter_map(<span>|</span>v<span>|</span> v[u])<span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()</span>
<span id="cb9-21">  <span>}</span>)<span>;</span></span>
<span id="cb9-22"></span>
<span id="cb9-23">  <span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb9-24">  all_qs<span>.</span>combinations(k)</span>
<span id="cb9-25">    <span>// almost the same code, see below</span></span>
<span id="cb9-26"><span>}</span></span></code></pre></div>
<p>The only change to the inner loop is that our code which used to say
this:</p>
<div id="cb10"><pre><code><span id="cb10-1">q_to_score[<span>*</span>q]<span>.</span>get(u)<span>.</span>copied()</span></code></pre></div>
<p>Is now this:</p>

<p>Running the benchmark again, the new inner loop runs in <strong>181
microseconds</strong>, which is 6 times faster than our last iteration,
and 199 times faster than our Python baseline. We’re down to 5.3 days
for the total computation.</p>
<h2 id="bounds-checks">Bounds Checks</h2>
<p>Another small performance hit comes every time we use the brackets
<code>[]</code> to index into an <code>DenseIndexMap</code>. The vector
beneath will run a bounds-check for safety, but our code is guaranteed
to never exceed vector bounds as written. I couldn’t actually find the
bounds check in the samply profile, but it does make a noticeable
difference in the benchmark, so it’s worth implementing.</p>
<p>Before our inner loop looked like this:</p>
<div id="cb12"><pre><code><span id="cb12-1"><span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb12-2">  <span>.</span>map(<span>|</span>q<span>|</span> q_to_score[<span>*</span>q][u])</span>
<span id="cb12-3">  <span>.</span><span>sum::</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;</span>()<span>?;</span></span>
<span id="cb12-4"><span>let</span> grand_total <span>=</span> all_grand_totals[u]<span>;</span></span></code></pre></div>
<p>Removing bounds checks with <code>get_unchecked</code>, our new inner
loop looks like this:</p>
<div id="cb13"><pre><code><span id="cb13-1"><span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb13-2">  <span>.</span>map(<span>|</span>q<span>|</span> <span>unsafe</span> <span>{</span></span>
<span id="cb13-3">    <span>let</span> u_scores <span>=</span> q_to_score<span>.</span>get_unchecked(q)<span>;</span></span>
<span id="cb13-4">    <span>*</span>u_scores<span>.</span>get_unchecked(u)</span>
<span id="cb13-5">  <span>}</span>)</span>
<span id="cb13-6">  <span>.</span><span>sum::</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;</span>()<span>?;</span></span>
<span id="cb13-7"><span>let</span> grand_total <span>=</span> <span>unsafe</span> <span>{</span> <span>*</span>all_grand_totals<span>.</span>get_unchecked(u) <span>};</span></span></code></pre></div>
<p>It is unsafe without bounds-checks, so we have to mark these blocks
as <code>unsafe</code>.</p>
<p>Running the benchmark again, the new inner loop runs in <strong>156
microseconds</strong>, which is 1.16x faster than our last iteration,
and 229 times faster than our Python baseline. We’re down to 4.6 days
for the total computation.</p>
<h2 id="bit-sets">Bit-sets</h2>
<p>We’re currently at a 225x speedup, which means we still have three
orders of magnitude left to go. To get there, we need to rethink the
computational structure of the inner loop. Right now, our loop
effectively looks like:</p>
<pre><code>for each subset of questions $qs:
  for each user $u:
    for each question $q in $qs:
      if $u answered $q: add $u's score on $q to a running total
      else: skip to the next user
    $r = correlation($u's totals on $qs, $u's grand total)</code></pre>
<p>An important aspect of our data is that it forms a <em>sparse</em>
matrix. For a given question, only 20% of users have answered that
question. For a set of 5 questions, a much smaller fraction have
answered all 5 questions. So if we can efficiently determine first which
users have answered all 5 questions, then our subsequent loop will run
for fewer iterations (and be free of branches). Something like this:</p>
<pre><code>for each subset of questions $qs:
  $qs_u = all users who have answered every question in $qs
  for each user $u in $qs_u:
    for each question $q in $qs:
      add $u's score on $q to a running total
    $r = correlation($u's scores on $qs, $u's grand total)</code></pre>
<p>So how do we represent the set of users who have answered a given
question? We could use a <a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html"><code>HashSet</code></a>,
but we saw earlier that hashing is computationally expensive. Because
our data is indexed, we can use a more efficient data structure: the <a href="https://en.wikipedia.org/wiki/Bit_array">bit-set</a>, which uses
the individual bits of memory to represent whether an object is present
or absent in a set. Indexical provides another abstraction for
integratings bit-sets with our newtype indices: the <a href="https://docs.rs/indexical/0.6.0/indexical/struct.IndexSet.html"><code>IndexSet</code></a>.</p>
<p>Previously, our <code>q_to_score</code> data structure mapped from
questions to a user-indexed vector of optional scores (that is,
<code>UserMap&lt;'_, Option&lt;u32&gt;&gt;</code>). Now we will change
<code>Option&lt;u32&gt;</code> to <code>u32</code> and add a bit-set
describing the set of users who answered a given question. The first
half of the updated code looks like this:</p>
<div id="cb16"><pre><code><span id="cb16-1"><span>type</span> UserSet<span>&lt;</span><span>'a</span><span>&gt;</span> <span>=</span> IndexSet<span>&lt;</span><span>'a</span><span>,</span> UserRef<span>&lt;</span><span>'a</span><span>&gt;&gt;;</span></span>
<span id="cb16-2"></span>
<span id="cb16-3"><span>let</span> <span>mut</span> q_to_score<span>:</span> QuestionMap<span>&lt;</span><span>'_</span><span>,</span> (UserSet<span>&lt;</span><span>'_</span><span>&gt;,</span> UserMap<span>&lt;</span><span>'_</span><span>,</span> <span>u32</span><span>&gt;</span>)<span>&gt;</span> <span>=</span> </span>
<span id="cb16-4">  <span>QuestionMap::</span>new(<span>&amp;</span>questions<span>,</span> <span>|</span>_<span>|</span> (</span>
<span id="cb16-5">    <span>UserMap::</span><span>&lt;</span><span>'_</span><span>,</span> <span>u32</span><span>&gt;</span><span>::</span>new(<span>&amp;</span>users<span>,</span> <span>|</span>_<span>|</span> <span>0</span>)<span>,</span></span>
<span id="cb16-6">    <span>UserSet::</span>new(<span>&amp;</span>users)<span>,</span></span>
<span id="cb16-7">  ))<span>;</span></span>
<span id="cb16-8"><span>for</span> r <span>in</span> data <span>{</span></span>
<span id="cb16-9">  <span>let</span> (scores<span>,</span> set) <span>=</span> <span>&amp;</span><span>mut</span> q_to_score<span>.</span>get_mut(<span>&amp;</span>QuestionRef(<span>&amp;</span>r<span>.</span>question))<span>.</span>unwrap()<span>;</span></span>
<span id="cb16-10">  scores<span>.</span>insert(UserRef(<span>&amp;</span>r<span>.</span>user)<span>,</span> r<span>.</span>score)<span>;</span></span>
<span id="cb16-11">  set<span>.</span>insert(UserRef(<span>&amp;</span>r<span>.</span>user))<span>;</span></span>
<span id="cb16-12"><span>}</span></span></code></pre></div>
<p>Note that <code>q_to_score</code> now effectively has invalid values,
since we provide a default value of 0 for users who did not answer a
question. We have to be careful not to use these invalid values in the
computation.</p>
<p>Then we update our inner loop to match the new pseudocode:</p>
<div id="cb17"><pre><code><span id="cb17-1"><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb17-2">all_qs<span>.</span>combinations(k)</span>
<span id="cb17-3">  <span>.</span>filter_map(<span>|</span>qs<span>:</span> <span>Vec</span><span>&lt;</span>QuestionIdx<span>&gt;|</span> <span>{</span></span>
<span id="cb17-4">    <span>// Compute the intersection of the user-sets for each question</span></span>
<span id="cb17-5">    <span>let</span> <span>mut</span> users <span>=</span> q_to_score[qs[<span>0</span>]]<span>.</span><span>1</span><span>.</span>clone()<span>;</span></span>
<span id="cb17-6">    <span>for</span> q <span>in</span> <span>&amp;</span>qs[<span>1</span><span>..</span>] <span>{</span></span>
<span id="cb17-7">      users<span>.</span>intersect(<span>&amp;</span>q_to_score[<span>*</span>q]<span>.</span><span>1</span>)<span>;</span></span>
<span id="cb17-8">    <span>}</span></span>
<span id="cb17-9"></span>
<span id="cb17-10">    <span>let</span> (qs_totals<span>,</span> grand_totals)<span>:</span> (<span>Vec</span><span>&lt;</span>_<span>&gt;,</span> <span>Vec</span><span>&lt;</span>_<span>&gt;</span>) <span>=</span> users<span>.</span>indices()</span>
<span id="cb17-11">      <span>// only .map, not .filter_map as before</span></span>
<span id="cb17-12">      <span>.</span>map(<span>|</span>u<span>|</span> <span>{</span></span>
<span id="cb17-13">        <span>let</span> q_total <span>=</span> qs<span>.</span>iter()          </span>
<span id="cb17-14">          <span>.</span>map(<span>|</span>q<span>|</span> <span>unsafe</span> <span>{</span></span>
<span id="cb17-15">            <span>let</span> (u_scores<span>,</span> _) <span>=</span> q_to_score<span>.</span>get_unchecked(q)<span>;</span></span>
<span id="cb17-16">            <span>*</span>u_scores<span>.</span>get_unchecked(u)</span>
<span id="cb17-17">          <span>}</span>)</span>
<span id="cb17-18">          <span>// only u32, not Option&lt;u32&gt; as before</span></span>
<span id="cb17-19">          <span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()<span>;</span></span>
<span id="cb17-20">        <span>let</span> grand_total <span>=</span> <span>unsafe</span> <span>{</span> <span>*</span>all_grand_totals<span>.</span>get_unchecked(u) <span>};</span></span>
<span id="cb17-21">        (q_total <span>as</span> <span>f64</span><span>,</span> grand_total <span>as</span> <span>f64</span>)</span>
<span id="cb17-22">      <span>}</span>)</span>
<span id="cb17-23">      <span>.</span>unzip()<span>;</span></span>
<span id="cb17-24">    <span>let</span> r <span>=</span> <span>utils::</span>correlation(<span>&amp;</span>qs_totals<span>,</span> <span>&amp;</span>grand_totals)<span>;</span></span>
<span id="cb17-25">    (<span>!</span>r<span>.</span>is_nan())<span>.</span>then_some((qs<span>,</span> r))</span>
<span id="cb17-26">  <span>}</span>)</span>
<span id="cb17-27">  <span>// rest of the code is the same</span></span></code></pre></div>
<p>Running the benchmark again, the new inner loop runs in <strong>47
microseconds</strong>, which is 3.4 times faster than our last
iteration, and 769 times faster than our Python baseline. We’re down to
1.4 days for the total computation.</p>
<h2 id="simd">SIMD</h2>
<p>Our new computational structure is definitely helping, but it’s still
not fast enough. Let’s check back in with samply:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-bitset.png"></p>
<p>Now we’re spending all our time in the bit-set intersection! That
means we need to dig in to how the bit-set is implemented. The default
bit-set library used by Indexical is <a href="https://docs.rs/bitvec/1.0.1/bitvec/index.html">bitvec</a>. As of
2023, the implementation of intersection within bitvec’s bit-set is
roughly this code:</p>
<div id="cb18"><pre><code><span id="cb18-1"><span>fn</span> intersect(dst<span>:</span> <span>&amp;</span><span>mut</span> BitSet<span>,</span> src<span>:</span> <span>&amp;</span>BitSet) <span>{</span></span>
<span id="cb18-2">  <span>for</span> (n1<span>,</span> n2)<span>:</span> (<span>&amp;</span><span>mut</span> <span>u64</span><span>,</span> <span>&amp;</span><span>u64</span>) <span>in</span> dst<span>.</span>iter_mut()<span>.</span>zip(<span>&amp;</span>src) <span>{</span></span>
<span id="cb18-3">    <span>*</span>n1 <span>&amp;=</span> <span>*</span>n2<span>;</span></span>
<span id="cb18-4">  <span>}</span></span>
<span id="cb18-5"><span>}</span></span></code></pre></div>
<p>So bitvec is AND-ing a <code>u64</code> at a time. But it turns out
most processors have instructions specifically for doing
bit-manipulation on multiple <code>u64</code>s at a time, called <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a>
(single instruction, multiple data). Thankfully, Rust provides an
experimental SIMD API <a href="https://doc.rust-lang.org/std/simd/index.html"><code>std::simd</code></a>
that we can use. Roughly speaking, the SIMD version of bit-set
intersection looks like this:</p>
<div id="cb19"><pre><code><span id="cb19-1"><span>fn</span> intersect(dst<span>:</span> <span>&amp;</span><span>mut</span> SimdBitSet<span>,</span> src<span>:</span> <span>&amp;</span>SimdBitSet) <span>{</span></span>
<span id="cb19-2">  <span>for</span> (n1<span>,</span> n2)<span>:</span> (<span>&amp;</span><span>mut</span> u64x4<span>,</span> <span>&amp;</span>u64x4) <span>in</span> dst<span>.</span>iter_mut()<span>.</span>zip(<span>&amp;</span>src) <span>{</span></span>
<span id="cb19-3">    <span>*</span>n1 <span>&amp;=</span> <span>*</span>n2<span>;</span></span>
<span id="cb19-4">  <span>}</span></span>
<span id="cb19-5"><span>}</span></span></code></pre></div>
<p>The only difference is that we’ve replaced our primitive
<code>u64</code> type with a SIMD type <a href="https://doc.rust-lang.org/std/simd/type.u64x4.html"><code>u64x4</code></a>,
and under the hood, Rust emits a single SIMD instruction to perform the
<code>&amp;=</code> operation that ANDs four <code>u64</code>s at a
time.</p>
<p>Where can we find a SIMD-accelerated bitset? <a href="https://docs.rs/bitvec/1.0.1/bitvec/index.html">bitvec</a> doesn’t
support SIMD. There are a few on <a href="https://crates.io/">crates.io</a>, and I tried out one called <a href="https://github.com/psiace/bitsvec">bitsvec</a>. It works well for
fast intersection, but I found that its iterator which finds the indices
of the 1-bits is actually quite slow. So I copied large portions of the
bitsvec implementation and wrote a more efficient iterator, which you
can check out in the <a href="https://github.com/willcrichton/indexical/blob/913fbf5830f4d5acedd23e04841e453ed2659165/src/bitset/simd.rs">Indexical
source</a> if you’re curious.</p>
<p>Thanks to Indexical’s abstractions, swapping in the SIMD bitset only
requires changing a type alias and no other modifications to the
<code>k_corrset</code> function. I experimented with different lane
sizes and found <code>u64x16</code> is the most efficient on my machine
for this dataset.</p>
<p>Once more we run the benchmark, and the new inner loop runs in
<strong>1.35 microseconds</strong>, which is 34 times faster than our
last iteration, and 26,459 times faster than our Python baseline. We’re
down to 57 minutes for the total computation.</p>
<h2 id="allocation">Allocation</h2>
<p>At this point, we’re pretty close to peak performance. (You may not
like it, but…) Let’s go back to the profile, this time looking at the
inverted view (which shows the most-called functions at the leaves of
the call tree):</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-simd.png"></p>
<p>The biggest bottleneck is our bit-set iterator! I wasn’t joking! But
we see several concerning functions: <code>memmove</code>,
<code>realloc</code>, <code>allocate</code> — that’s right, we’re
allocating memory in the inner loop of this function. Specifically,
there’s the user bit-set that we initially clone, and there’s the two
vectors for <code>qs_totals</code> and <code>grand_totals</code> that we
allocate with <code>unzip</code>.</p>
<p>To avoid allocation, we create these data structures up front with
the maximum possible size needed, and then repeatedly write into
them:</p>
<div id="cb20"><pre><code><span id="cb20-1"><span>// Allocate our data up front</span></span>
<span id="cb20-2"><span>let</span> <span>mut</span> qs_totals <span>=</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]</span>
<span id="cb20-3"><span>let</span> <span>mut</span> grand_totals <span>=</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>;</span></span>
<span id="cb20-4"><span>let</span> <span>mut</span> user_set <span>=</span> <span>IndexSet::</span>new(<span>&amp;</span>users)<span>;</span></span>
<span id="cb20-5"></span>
<span id="cb20-6"><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb20-7">all_qs<span>.</span>combinations(k)</span>
<span id="cb20-8">  <span>.</span>filter_map(<span>|</span>qs<span>|</span> <span>{</span></span>
<span id="cb20-9">    <span>// Use `clone_from` rather than `clone` to copy without allocation</span></span>
<span id="cb20-10">    user_set<span>.</span>clone_from(<span>&amp;</span>q_to_score[qs[<span>0</span>]]<span>.</span><span>1</span>)<span>;</span></span>
<span id="cb20-11">    <span>for</span> q <span>in</span> <span>&amp;</span>qs[<span>1</span><span>..</span>] <span>{</span></span>
<span id="cb20-12">      user_set<span>.</span>intersect(<span>&amp;</span>q_to_score[<span>*</span>q]<span>.</span><span>1</span>)<span>;</span></span>
<span id="cb20-13">    <span>}</span></span>
<span id="cb20-14"></span>
<span id="cb20-15">    <span>let</span> <span>mut</span> n <span>=</span> <span>0</span><span>;</span></span>
<span id="cb20-16">    <span>for</span> (i<span>,</span> u) <span>in</span> user_set<span>.</span>indices()<span>.</span>enumerate() <span>{</span></span>
<span id="cb20-17">      <span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb20-18">        <span>.</span>map(<span>|</span>q<span>|</span> <span>unsafe</span> <span>{</span></span>
<span id="cb20-19">          <span>let</span> (u_scores<span>,</span> _) <span>=</span> q_to_score<span>.</span>get_unchecked(q)<span>;</span></span>
<span id="cb20-20">          <span>*</span>u_scores<span>..</span>get_unchecked(u)</span>
<span id="cb20-21">        <span>}</span>)</span>
<span id="cb20-22">        <span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()<span>;</span></span>
<span id="cb20-23">      <span>let</span> grand_total <span>=</span> <span>unsafe</span> <span>{</span> <span>*</span>all_grand_totals<span>.</span>get_unchecked(u) <span>};</span></span>
<span id="cb20-24"></span>
<span id="cb20-25">      <span>// Update totals/grand_totals in-place rather than pushing into a vector</span></span>
<span id="cb20-26">      <span>unsafe</span> <span>{</span></span>
<span id="cb20-27">        <span>*</span>qs_totals<span>.</span>get_unchecked_mut(i) <span>=</span> q_total <span>as</span> <span>f64</span><span>;</span></span>
<span id="cb20-28">        <span>*</span>grand_totals<span>.</span>get_unchecked_mut(i) <span>=</span> grand_total <span>as</span> <span>f64</span><span>;</span></span>
<span id="cb20-29">      <span>}</span></span>
<span id="cb20-30"></span>
<span id="cb20-31">      n <span>+=</span> <span>1</span><span>;</span></span>
<span id="cb20-32">    <span>}</span></span>
<span id="cb20-33"></span>
<span id="cb20-34">    <span>// Only pass in the first `n` elements!</span></span>
<span id="cb20-35">    <span>let</span> r <span>=</span> <span>utils::</span>correlation(<span>&amp;</span>qs_totals[<span>..</span>n]<span>,</span> <span>&amp;</span>grand_totals[<span>..</span>n])<span>;</span></span>
<span id="cb20-36">    (<span>!</span>r<span>.</span>is_nan())<span>.</span>then_some((qs<span>,</span> r))</span>
<span id="cb20-37">  <span>}</span>)</span></code></pre></div>
<p>We run the benchmark again, and the new inner loop runs in
<strong>1.09 microseconds</strong>, which is 1.24 times faster than our
last iteration, and 32,940 times faster than our Python baseline. We’re
down to 46 minutes for the total computation.</p>
<p>(As an aside, it’s impressive that the heap allocator was fast enough
to have such a small impact on our runtime!)</p>
<p>In summary, Table <a href="#tbl:inner-speedup">1</a> shows the
runtime, relative speedup, absolute speedup, and total estimated
completion time for each level of the benchmark.</p>
<div id="tbl:inner-speedup">
<table>
<caption>Table 1: Performance numbers for the inner loop.</caption>
<colgroup>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Level</th>
<th>Runtime</th>
<th>Speedup over previous level</th>
<th>Speedup over Python</th>
<th>Est. completion time</th>
</tr>
</thead>
<tbody>
<tr>
<td>python</td>
<td>35.85 ms</td>
<td></td>
<td>1.00×</td>
<td>2.88 years</td>
</tr>
<tr>
<td>0_basic</td>
<td>4.24 ms</td>
<td>8.46×</td>
<td>8.46×</td>
<td>124.40 days</td>
</tr>
<tr>
<td>1_indexed</td>
<td>1.03 ms</td>
<td>4.11×</td>
<td>34.78×</td>
<td>30.25 days</td>
</tr>
<tr>
<td>2_imap</td>
<td>180.52 μs</td>
<td>5.71×</td>
<td>198.60×</td>
<td>5.30 days</td>
</tr>
<tr>
<td>3_bchecks</td>
<td>156.23 μs</td>
<td>1.16×</td>
<td>229.47×</td>
<td>4.59 days</td>
</tr>
<tr>
<td>4_bitset</td>
<td>46.60 μs</td>
<td>3.35×</td>
<td>769.26×</td>
<td>1.37 days</td>
</tr>
<tr>
<td>5_simd</td>
<td>1.35 μs</td>
<td>34.40×</td>
<td>26,459.54×</td>
<td>57.26 min</td>
</tr>
<tr>
<td>6_alloc</td>
<td>1.09 μs</td>
<td>1.24×</td>
<td>32,940.02×</td>
<td>45.99 min</td>
</tr>
</tbody>
</table>
</div>
<p>The absolute speedup is summarized in Figure 1. Note that the y-axis
is on a log-scale!</p>
<figure>

<figcaption>
Performance trend of the inner loop.
</figcaption>
</figure>
<h2 id="parallelism">Parallelism</h2>
<p>At this point, we seem to have totally exhausted our avenues for
optimization. I actually can’t think of any other ways to make the inner
loop substantively faster — let me know if you have any ideas. But we’ve
left out one final, obvious trick: parallelism! This problem is
embarassingly parallel, so we can trivially parallelize the inner loop
over multiple cores. <a href="https://docs.rs/rayon/1.8.0/rayon/index.html">Rayon</a> makes this
a breeze:</p>
<div id="cb21"><pre><code><span id="cb21-1"><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb21-2">all_qs<span>.</span>combinations(k)</span>
<span id="cb21-3">  <span>.</span>par_bridge()</span>
<span id="cb21-4">  <span>.</span>map_init(</span>
<span id="cb21-5">    <span>||</span> (<span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>IndexSet::</span>new(<span>&amp;</span>users))<span>,</span></span>
<span id="cb21-6">    <span>|</span>(qs_totals<span>,</span> grand_totals<span>,</span> user_set)<span>,</span> qs<span>|</span> <span>{</span></span>
<span id="cb21-7">      <span>// same code as before</span></span>
<span id="cb21-8">    <span>}</span>)</span>
<span id="cb21-9">    <span>// same code as before</span></span></code></pre></div>
<p>The <code>par_bridge</code> method takes a serial iterator and
converts it into a parallel iterator. The <code>map_init</code> function
is a parallel map with thread-specific state, so we preserve our
allocation-free status.</p>
<p>We need a different benchmark to evaluate the outer loop. I used
Criterion to run the outer loop over 5,000,000 question combinations in
a single run with a given strategy. This is enough executions to reveal
differences in each outer loop without waiting weeks for the benchmark
to complete.</p>
<p>Running this benchmark with the serial strategy over the fastest
inner loop takes <strong>6.8 seconds</strong>. My Macbook Pro has 10
cores, so with Rayon we should expect to see close to a 10x speedup.
After benchmarking the parallel strategy, we get… <strong>4.2
seconds</strong> to complete 5,000,000 combinations. That’s only a 1.6x
speedup! Shameful!</p>
<h2 id="batching">Batching</h2>
<p>Let’s go back to the profile to investigate our lack of scaling:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-parallel.png"></p>
<p>Our threads are spending most of their time locking and unlocking a
mutex! There’s some kind of synchronization bottleneck. Indeed, if we
read the <a href="https://docs.rs/rayon/1.8.0/rayon/iter/trait.ParallelBridge.html"><code>par_bridge</code>
documentation</a> carefully, we’ll find a key sentence:</p>
<blockquote>
<p>Iterator items are pulled by <code>next()</code> one at a time,
synchronized from each thread that is ready for work, so this may become
a bottleneck if the serial iterator can’t keep up with the parallel
demand.</p>
</blockquote>
<p>It seems that the hand-off between the
<code>Itertools::combinations</code> iterator and the Rayon parallel
bridge is too slow. Given that we have a huge number of combinations, a
simple way to avoid this bottleneck is to increase the granularity of
task assignment. That is, we can batch together many question
combinations and pass them off to a thread all at once.</p>
<p>For this task, I defined a quick-and-dirty batching iterator that
uses an <a href="https://docs.rs/arrayvec/0.7.4/arrayvec/struct.ArrayVec.html"><code>ArrayVec</code></a>
to avoid allocation.</p>
<div id="cb22"><pre><code><span id="cb22-1"><span>pub</span> <span>struct</span> Batched<span>&lt;</span><span>const</span> N<span>:</span> <span>usize</span><span>,</span> I<span>:</span> <span>Iterator</span><span>&gt;</span> <span>{</span></span>
<span id="cb22-2">  iter<span>:</span> I<span>,</span></span>
<span id="cb22-3"><span>}</span></span>
<span id="cb22-4"></span>
<span id="cb22-5"><span>impl</span><span>&lt;</span><span>const</span> N<span>:</span> <span>usize</span><span>,</span> I<span>:</span> <span>Iterator</span><span>&gt;</span> <span>Iterator</span> <span>for</span> Batched<span>&lt;</span>N<span>,</span> I<span>&gt;</span> <span>{</span></span>
<span id="cb22-6">  <span>type</span> Item <span>=</span> ArrayVec<span>&lt;</span><span>I::</span>Item<span>,</span> N<span>&gt;;</span></span>
<span id="cb22-7"></span>
<span id="cb22-8">  <span>#[</span>inline<span>]</span></span>
<span id="cb22-9">  <span>fn</span> next(<span>&amp;</span><span>mut</span> <span>self</span>) <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>Self</span><span>::</span>Item<span>&gt;</span> <span>{</span></span>
<span id="cb22-10">    <span>let</span> batch <span>=</span> <span>ArrayVec::</span>from_iter((<span>&amp;</span><span>mut</span> <span>self</span><span>.</span>iter)<span>.</span>take(N))<span>;</span></span>
<span id="cb22-11">    (<span>!</span>batch<span>.</span>is_empty())<span>.</span>then_some(batch)</span>
<span id="cb22-12">  <span>}</span></span>
<span id="cb22-13"><span>}</span></span></code></pre></div>
<p>Then we modify our outer loop by batching the combinations iterator,
and modify the inner loop to flatten each batch:</p>
<div id="cb23"><pre><code><span id="cb23-1"><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb23-2">all_qs<span>.</span>combinations(k)</span>
<span id="cb23-3">  <span>.</span><span>batched::</span><span>&lt;</span><span>1024</span><span>&gt;</span>()</span>
<span id="cb23-4">  <span>.</span>par_bridge()</span>
<span id="cb23-5">  <span>.</span>map_init(</span>
<span id="cb23-6">    <span>||</span> (<span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>IndexSet::</span>new(<span>&amp;</span>users))<span>,</span></span>
<span id="cb23-7">    <span>|</span>(qs_totals<span>,</span> grand_totals<span>,</span> user_set)<span>,</span> qs_batch<span>|</span> <span>{</span></span>
<span id="cb23-8">      qs_batch</span>
<span id="cb23-9">        <span>.</span>into_iter()</span>
<span id="cb23-10">        <span>.</span>filter_map(<span>|</span>qs<span>|</span> <span>{</span></span>
<span id="cb23-11">          <span>// same code as before</span></span>
<span id="cb23-12">        <span>}</span>)</span>
<span id="cb23-13">        <span>.</span>collect_vec()</span>
<span id="cb23-14">    <span>}</span>)</span>
<span id="cb23-15">    <span>.</span>flatten()</span>
<span id="cb23-16">    <span>// same code as before</span></span></code></pre></div>
<p>Running the outer-loop benchmark again, the chunking iterator now
completes 5,000,000 combinations in <strong>982 milliseconds</strong>.
This is a 6.9x speedup over the serial approach, which is much better
for our 10-core machine. Ideally we would get closer to 10x, but I think
this post is long enough. In summary, our outer loop runtime numbers are
in Table <a href="#tbl:outer-loop">2</a>.</p>
<div id="tbl:outer-loop">
<table>
<caption>Table 2: Performance numbers for the outer loop.</caption>
<colgroup>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Level</th>
<th>Runtime</th>
<th>Speedup over previous level</th>
<th>Speedup over Python</th>
<th>Est. completion time</th>
</tr>
</thead>
<tbody>
<tr>
<td>0_serial</td>
<td>6.80 s</td>
<td></td>
<td>26,342.63×</td>
<td>57.51 min</td>
</tr>
<tr>
<td>1_parallel</td>
<td>4.22 s</td>
<td>1.61×</td>
<td>42,439.31×</td>
<td>35.70 min</td>
</tr>
<tr>
<td>2_batched</td>
<td>982.46 ms</td>
<td>4.30×</td>
<td>182,450.94×</td>
<td>8.30 min</td>
</tr>
</tbody>
</table>
</div>
<h2 id="conclusion">Conclusion</h2>
<p>So how far did we come? The original Python program was going to take
2.9 years to complete at k=5. Our final Rust program only takes
<strong>8 minutes</strong> on the same dataset. That is roughly a
<strong>180,000x speedup</strong>. A summary of the key
optimizations:</p>
<ul>
<li>Use Rust’s compiler optimizations.</li>
<li>Hash numbers instead of strings.</li>
<li>Use (indexed) vectors instead of hashmaps.</li>
<li>Use bit-sets for efficient membership tests.</li>
<li>Use SIMD for efficient bit-sets.</li>
<li>Use multi-threading to split the work over many cores.</li>
<li>Use batching to avoid a bottleneck at work distribution.</li>
</ul>
<p>Can we do better? Let’s take one last look at the profile:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-batched.png"></p>
<p>We’re spending 38% of our time in the bit-set iterator, and 36% of
our time in the bit-set intersection. Another 12% in copying the initial
bit-set for a given set of questions. And a long tail of other
operations like computing the correlation.</p>
<p>I tried my best to make the SIMD bit-set implementation fast, so I
don’t know of a way to improve these numbers. We might find another +10%
speedup from careful tweaking of the various constants (lane size, batch
size, etc.), but I don’t think there’s another order of magnitude left
on the table. If you know of a way, I invite you to try it out:<br> <a href="https://github.com/willcrichton/corrset-benchmark">https://github.com/willcrichton/corrset-benchmark</a></p>
<p>Also if you know of an analytic solution to this problem, i.e., a
smarter way to get an optimal answer without brute force, do let me know
as well! Otherwise, I hope you learned a bit about performance
engineering in Rust.</p>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pushing devs for lower estimates is like asking a meteorologist for sunshine (366 pts)]]></title>
            <link>https://smartguess.is/blog/your-estimate-is-less-than-that/</link>
            <guid>37964153</guid>
            <pubDate>Sat, 21 Oct 2023 04:43:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smartguess.is/blog/your-estimate-is-less-than-that/">https://smartguess.is/blog/your-estimate-is-less-than-that/</a>, See on <a href="https://news.ycombinator.com/item?id=37964153">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><ul><li><i></i>2022-01-15</li></ul></div><h2>'No, it's less effort than that!'</h2>
<blockquote>
<p>There is back-and-forth as the estimates are questioned for being too high, almost never for being too low.</p>
</blockquote>
<p>Often stakeholders outside of the development team, with limited technical know-how or insights into the codebase, question team estimates, saying something like <em>'No, it's less effort than that!'</em>. Their purpose is to push the team to give a 'better' estimate. Note that 'better' in this case means a lower estimate. The problem with going down this path and taking part in these discussions is diminished trust and further issues down the line:</p>
<blockquote>
<p>Finally, an agreed-upon estimate is provided with much grumbling. Most of the time, nobody is happy; everybody feels compromised. The most important stakeholder, the business, is especially compromised as a bad expectation was set on when the software will be delivered to the customer.</p>
</blockquote>
<p>Both quotes are from the article <a href="https://iism.org/article/is-tasking-developers-with-creating-detailed-estimates-a-waste-of-company-money-42">Is tasking developers with creating detailed estimates a waste of money?</a></p>
<p>In this post, I will share how it's a mistake for external stakeholders to push for a lower estimate without new facts impacting the effort. In addition, I will share how development teams can move their stakeholder dialogue into a much more productive discussion.</p>
<h2>Does pushing for lower estimates make sense?</h2>
<blockquote>
<p>No, it's less effort than that</p>
</blockquote>
<p>Statements pushing for a lower estimate can be valid, especially when discussing a story with a colleague in your team and when it's backed up with facts.</p>
<p>However, if the stakeholder making this claim is not part of the development team and doesn't know what needs to happen when implementing the story and doesn't bring any new facts, then making this claim is like starting a conversation with a meteorologist saying:</p>
<blockquote>
<p>Hey meteorologist, the weather forecast for tomorrow will not be this bad!</p>
</blockquote>
<p>Let's cover why this is so and how to move the discussion forward!</p>
<h3>Pushing for a lower estimate is like negotiating better weather with the meteorologist!</h3>
<p>The fact is the meteorologist <em>doesn't control the weather</em>. The meteorologist uses his knowledge and observing data to forecast how the weather will be.</p>
<p>In the same way, the development team <em>doesn't control</em> the actual effort - only by a tiny part. The development team is using their knowledge and data to forecast expected effort. They use established team velocity, review data on complete stories, and continuously improve their process every sprint.</p>
<p>What do I mean by saying <em>only by a tiny part?</em> The team can skip parts of their process and deliver lower-quality software. Not a recommended practice, as often teams pay more later when using this strategy. Also, the team has ways to improve the velocity. However, teams need to base estimates on their current throughput and not expected future throughput when giving an estimate. In other words, the team has minimal control over its effort to implement a fixed set of functionality.</p>
<p>Next time, when someone starts a conversation about your team's estimate, pushing for a lower estimate without any new insights that will lower the effort, ask them:</p>
<blockquote>
<p>do you ever tell the meteorologist it isn't going to be this bad weather tomorrow?</p>
</blockquote>
<p>Because negotiating an estimate is like negotiating better weather with the meteorologist. It doesn't make any sense. However, there is a better discussion to have.</p>
<h3>The discussion you need to have instead</h3>
<p>Building software is complicated often takes more time than people think, and therefore, stakeholders often expect lower effort and can't rationalize spending more than a specific amount. What then?</p>
<p>In these cases, discuss with your stakeholders:</p>
<ol>
<li>why the estimated effort is this much?</li>
<li>what part of the story takes the most time?</li>
<li>where are the biggest unknowns?</li>
</ol>
<p>In addition, discuss ways to:</p>
<ol>
<li>slice up the story and deliver it in multiple parts</li>
<li>validate each part early, preferably using prototypes</li>
</ol>
<p>In addition, find ways to leave parts of the story out, especially the features that require lots of effort and have the least value.</p>
<p>This approach makes sense because research shows that a large part of software functionality built is rarely used. Therefore, it's critical to "get out of the building" and talk to the actual users using the software. Because it's often the case, stakeholders base their thoughts on opinions rather than actual data or discussions with users. As Steve Blank often says:</p>
<blockquote>
<p>No facts exist inside the building, only opinions</p>
</blockquote><div><p><img alt="" src="https://res.cloudinary.com/smartguess/image/upload/c_fill,w_856/Steve_Blank_No_Facts_Exist_Inside_The_Building_png_1121356a63?_a=ATAPpFA0"></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pigging (196 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Pigging</link>
            <guid>37964095</guid>
            <pubDate>Sat, 21 Oct 2023 04:31:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Pigging">https://en.wikipedia.org/wiki/Pigging</a>, See on <a href="https://news.ycombinator.com/item?id=37964095">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr">
<p>Not to be confused with <a href="https://en.wikipedia.org/wiki/Pegging_(disambiguation)" title="Pegging (disambiguation)">Pegging</a>.</p>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:NWO-MolchPlastik2.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/NWO-MolchPlastik2.jpg/220px-NWO-MolchPlastik2.jpg" decoding="async" width="220" height="293" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/NWO-MolchPlastik2.jpg/330px-NWO-MolchPlastik2.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/NWO-MolchPlastik2.jpg/440px-NWO-MolchPlastik2.jpg 2x" data-file-width="1200" data-file-height="1600"></a><figcaption>A cleaning pig for a 710-millimetre (28&nbsp;in) oil pipeline. The blue plastic disks seal against the inside of the pipe to propel the device and to remove loose <a href="https://en.wikipedia.org/wiki/Sedimentation" title="Sedimentation">sedimentation</a> or <a href="https://en.wikipedia.org/wiki/Fouling" title="Fouling">scale buildup</a>. The black rectangles at the top and the circular disks in the center are magnets to attract and remove any loose metal objects in the pipe.</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:NWO-MolchRisspruef.JPG"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/NWO-MolchRisspruef.JPG/220px-NWO-MolchRisspruef.JPG" decoding="async" width="220" height="150" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/NWO-MolchRisspruef.JPG/330px-NWO-MolchRisspruef.JPG 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/NWO-MolchRisspruef.JPG/440px-NWO-MolchRisspruef.JPG 2x" data-file-width="1690" data-file-height="1155"></a><figcaption>An <a href="https://en.wikipedia.org/wiki/Ultrasonic_testing" title="Ultrasonic testing">ultrasonic</a> leak-detection pig.</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Six_inch_pipeline_pig.JPG"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Six_inch_pipeline_pig.JPG/220px-Six_inch_pipeline_pig.JPG" decoding="async" width="220" height="317" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Six_inch_pipeline_pig.JPG/330px-Six_inch_pipeline_pig.JPG 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Six_inch_pipeline_pig.JPG/440px-Six_inch_pipeline_pig.JPG 2x" data-file-width="974" data-file-height="1402"></a><figcaption>A cleaning pig for a 150-millimetre (6&nbsp;in) oil pipeline. The wire brush encircles the shaft and scours the interior of the pipeline.</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg/220px-Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg" decoding="async" width="220" height="293" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg/330px-Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg/440px-Trans-Alaska_Pipeline_System_Visitors_Center_Scraper_Pig.jpg 2x" data-file-width="3036" data-file-height="4048"></a><figcaption>A scraper pig shown at the <a href="https://en.wikipedia.org/wiki/Trans-Alaska_Pipeline_System" title="Trans-Alaska Pipeline System">Trans-Alaska Pipeline System</a> Visitors Center</figcaption></figure>
<p>In <a href="https://en.wikipedia.org/wiki/Pipeline_transport" title="Pipeline transport">pipeline transportation</a>, <b>pigging</b> is the practice of using pipeline inspection gauges or gadgets, devices generally referred to as <b>pigs</b> or <b>scrapers</b>, to perform various maintenance operations. This is done without stopping the flow of the product in the pipeline.<sup id="cite_ref-Schlumberger_1-0"><a href="#cite_note-Schlumberger-1">[1]</a></sup><sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup><sup id="cite_ref-Abdel-Hafez_and_Chowdhury_2015_3-0"><a href="#cite_note-Abdel-Hafez_and_Chowdhury_2015-3">[3]</a></sup>
</p><p>These operations include but are not limited to cleaning and inspecting the pipeline. This is accomplished by inserting the pig into a "pig launcher" (or "launching station")—an oversized section in the pipeline, reducing to the normal diameter. The launching station is then closed and the pressure-driven flow of the product in the pipeline is used to push the pig along the pipe until it reaches the receiving trap—the "pig catcher" (or "receiving station").
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Applications">Applications</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=1" title="Edit section: Applications">edit</a><span>]</span></span></h2>
  
<p>Pigging is used to clean large diameter pipelines in the oil industry. Today, however, the use of smaller diameter pigging systems is now increasing in many continuous and batch process plants as plant operators search for increased efficiencies and reduced costs.
</p><p>Pigging can be used for almost any section of the transfer process between, for example, blending, storage or filling systems. Pigging systems are installed in industries handling products as diverse as lubricating oils, paints, chemicals, toiletries, cosmetics and foodstuffs.
</p><p>Pigs are used in lube oil or paint blending to clean the pipes to avoid cross-contamination, and to empty the pipes into the product tanks (or sometimes to send a component back to its tank). Usually pigging is done at the beginning and at the end of each batch, but sometimes it is done in the midst of a batch, such as when producing a premix that will be used as an intermediate component.
</p><p>Pigs are also used in oil and gas industries to clean or clear pipelines. Intelligent or "Smart pigs" used to inspect pipelines to assess their condition and to prevent leaks, which can be hazardous or harmful to the environment. They usually do not interrupt production, though some product can be lost when the pig is removed. They can also be used to separate different products in a multiproduct pipeline and to clear slugs of liquid  from multiphase gas//liquid pipelines.
</p><p>Pigging requires the pipeline to be designed to be pigged from the outset. If the pipeline contains topological variations including changes in diameter, <a href="https://en.wikipedia.org/wiki/Butterfly_valve" title="Butterfly valve">butterfly valves</a>, instrumentation, tight bends, pumps or reduced port ball valves, the pipeline cannot be traditionally pigged. In such instances, alternatives such as <a href="https://en.wikipedia.org/wiki/Ice_Pigging" title="Ice Pigging">Ice Pigging</a> may be employed.  Full port (or full bore) <a href="https://en.wikipedia.org/wiki/Ball_valve" title="Ball valve">ball valves</a> cause no problems because the inside diameter of the ball opening is the same as that of the pipe.
</p>
<h2><span id="Etymology">Etymology</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=2" title="Edit section: Etymology">edit</a><span>]</span></span></h2>
<p>Some early cleaning "pigs" were made from straw bales wrapped in barbed wire<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> while others used leather.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> Both made a squealing noise while traveling through the pipe, sounding to some like a <a href="https://en.wikipedia.org/wiki/Pig" title="Pig">pig</a> squealing,<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> which gave pigs their name.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup><sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>  
</p>
<h2><span id="In_production_environments">In production environments</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=3" title="Edit section: In production environments">edit</a><span>]</span></span></h2>
<h3><span id="Product_and_time_saving">Product and time saving</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=4" title="Edit section: Product and time saving">edit</a><span>]</span></span></h3>
<p>A major advantage  for multi-product pipelines of piggable systems is the potential of product savings. At the end of each product transfer, it is possible to segregate the next products using a pigging sphere. Alternatively it is possible to clear out the entire line contents with the pig, either forwards to the receipt point, or backwards to the source tank. There is no requirement for extensive line flushing.
</p><p>Without the need for line flushing, pigging offers the additional advantage of much more rapid and reliable product changeover. Product sampling at the receipt point is faster with pigs, because the interface between products is very clear; the old method of checking at intervals to determine where the product is on-specification takes considerably longer.
</p><p>Pigging can also be operated totally by a <a href="https://en.wikipedia.org/wiki/Programmable_logic_controller" title="Programmable logic controller">programmable logic controller</a> (PLC).
</p>
<h3><span id="Environmental_benefits">Environmental benefits</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=5" title="Edit section: Environmental benefits">edit</a><span>]</span></span></h3>
<p>Pigging has a significant role to play in reducing the environmental impact of batch operations. Traditionally, the only way that an operator of a batch process could ensure a product was completely cleared from a line was to flush the line with a cleaning agent such as water or a solvent, or even with the next product. The cleaning agent then had to be subjected to effluent treatment or solvent recovery. If a product was used to clear the line, it was necessary to downgrade or dump the contaminated portion of the product. All of these problems can now be eliminated due to the very precise interface produced by modern pigging systems.
</p>
<h3><span id="Safety_considerations">Safety considerations</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=6" title="Edit section: Safety considerations">edit</a><span>]</span></span></h3>
<p>Pigging systems are designed so that the pig is loaded into the launcher, which is pressured to launch the pig into the pipeline through a kicker line. In some cases, the pig is removed from the pipeline via the receiver at the end of each run.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup> All systems must allow for the receipt of pigs at the launcher, as blockages in the pipeline may require the pigs to be pushed back to the launcher. Many systems are designed to pig the pipeline in either direction.
</p><p>The pig is pushed either with a gas or a liquid; if pushed by gas, some systems<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup> can be adapted in the gas inlet in order to ensure pig's constant speed, whatever the flow pressure is. The pigs must be removed, as many pigs are rented, pigs wear and must be replaced, and cleaning (and other) pigs push contaminants from the pipeline such as wax, foreign objects, hydrates, etc., which must be removed from the pipeline. There are inherent risks in opening the barrel to atmospheric pressure so care must be taken to ensure that the barrel is depressurized prior to opening. If the barrel is not completely depressurized, the pig can be ejected from the barrel and operators have been severely injured when standing in front of an open pig door. A pig was once accidentally shot out of the end of a pipeline without a proper pig receiver and went through the side of a house 150 metres (500&nbsp;ft) away.<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> When the product is sour, the barrel should be evacuated to a flare system where the <a href="https://en.wikipedia.org/wiki/Sour_gas" title="Sour gas">sour gas</a> is burnt. Operators should wear a <a href="https://en.wikipedia.org/wiki/Self-contained_breathing_apparatus" title="Self-contained breathing apparatus">self-contained breathing apparatus</a> when working on sour systems.
</p><p>A few pigging systems utilize a "captive pig", and the pipeline is only opened occasionally to check the condition of the pig.<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> At all other times, the pig is shuttled up and down the pipeline at the end of each transfer, and the pipeline is never opened up during process operation. These systems are not common.
</p>
<h3><span id="Pigging_operations">Pigging operations</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=7" title="Edit section: Pigging operations">edit</a><span>]</span></span></h3>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Pig_launcher.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Pig_launcher.jpg/220px-Pig_launcher.jpg" decoding="async" width="220" height="93" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Pig_launcher.jpg/330px-Pig_launcher.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Pig_launcher.jpg/440px-Pig_launcher.jpg 2x" data-file-width="775" data-file-height="327"></a><figcaption>Pig launcher and associated plant</figcaption></figure>
<p>See diagram on the right representing a pig launcher. In normal operation valves V2 and V4 will be open, all other valves and the door are closed and locked.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>
</p><p>To <b>launch</b> a pig
</p>
<ul><li>Ensure pig launcher is drained and vented. Unlock and open, then close and relock the vent and drain valves.</li>
<li>Unlock and open door, load pig into launcher, close and lock door.</li>
<li>Unlock and open valves V1 and V3, to create a flow path through the launcher.</li>
<li>Partly close ‘kicker’ valve V2 to launch the pig.</li>
<li>The launch alarm XA will indicate when the pig has been launched.</li>
<li>Open valve V2 fully.</li>
<li>Close and lock valves V1 and V3.</li>
<li>Unlock and open vent and drain valves. Allow launcher to depressurise and drain.</li>
<li>Close and lock vent and drain valves.</li>
<li>Pig launcher is then ready for the next pig to launch.</li></ul>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Pig_receiver.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Pig_receiver.jpg/220px-Pig_receiver.jpg" decoding="async" width="220" height="91" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Pig_receiver.jpg/330px-Pig_receiver.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Pig_receiver.jpg/440px-Pig_receiver.jpg 2x" data-file-width="685" data-file-height="283"></a><figcaption>Schematic of a pig receiver</figcaption></figure>
<p>See diagram on the right representing a pig receiver.
</p><p>To <b>receive</b> a pig
</p>
<ul><li>Unlock and open valves V1 and V3, to create a flow path through the pig receiver.</li>
<li>Partly close ‘kicker’ valve V2 to induce flow through the receiver.</li>
<li>The receive alarm XA will indicate when the pig has been received.</li>
<li>Open valve V2 fully.</li>
<li>Close and lock valves V1 and V3.</li>
<li>Unlock and open vent and drain valves to empty the receiver.</li>
<li>Close and lock vent and drain valves.</li>
<li>Unlock and open door, remove pig from receiver, close and lock door.</li>
<li>Pig receiver is then ready to receive the next pig.</li></ul>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Pigging_station.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Pigging_station.jpg/220px-Pigging_station.jpg" decoding="async" width="220" height="147" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Pigging_station.jpg/330px-Pigging_station.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Pigging_station.jpg/440px-Pigging_station.jpg 2x" data-file-width="5040" data-file-height="3360"></a><figcaption>Pigging station</figcaption></figure>
<p>The pigging installation shown (right) is known as an Above Ground Installation (AGI). It is part of the UK's <a href="https://en.wikipedia.org/wiki/National_Transmission_System" title="National Transmission System">National Transmission System</a> for natural gas. It shows two pig launcher/ receivers. There are at the end of two 610-millimetre (24&nbsp;in) diameter pipelines that carry gas under the River Thames between East Tilbury Essex and Shorne in Kent. Should one pipeline be damaged, by a ship's anchor for example, that line can be isolated and the second pipeline allows gas to flow across the river.<sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> 
</p>
<h4><span id="Mechanical_interlocks">Mechanical interlocks</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=8" title="Edit section: Mechanical interlocks">edit</a><span>]</span></span></h4>
<p>There are many reports of incidents in which operators have been injured or even killed while performing a pigging operation. Common causes of such events are:
</p>
<ul><li>opening of the closure door while the vessel is still pressurized;</li>
<li>opening of the main process valve while the closure door is not fully closed;</li>
<li>opening of the closure door while a high concentration of H₂S or other toxins remains inside the vessel;</li>
<li>the vent valve remaining open while the vessel is being pressurized with its medium.</li></ul>
<p>All these causes are directly related to improper operation of the process valves and the closure door. A common method of avoiding these kinds of incidents is to add valve interlocks,<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup> which has been adopted by all global oil and gas operating companies.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (May 2018)">citation needed</span></a></i>]</sup>
</p><p>Safety during pigging relies on strict adherence to safety procedures, which give detailed description of a safe valve operating sequence. By physically blocking incorrect operations, valve interlocks enforce such sequences. Valve interlocks are permanently mounted to both manual and motor operated valves and the closure door. The interlocks block operation of a valve or door, unless the appropriate keys are inserted.
</p><p>The principle of valve interlocking is the transfer of keys. Each lock is equipped with two keys: a key for the locked open position and one for the locked closed position. During an operating procedure, only one key at a time is free. This key only fits in the interlock belonging to the valve that is to be operated next in the operating procedure. All keys are uniquely coded to avoid the possibility that valves can be unlocked at an inappropriate time.
</p><p>Nowadays intelligent interlocking solutions enable the integration of field devices like pressure or H<sub>2</sub>S meters in a valve interlocking sequence. This increases safety by integrating operator procedures<sup id="cite_ref-16"><a href="#cite_note-16">[16]</a></sup> with <a href="https://en.wikipedia.org/wiki/Distributed_Control_System" title="Distributed Control System">DCS</a> and <a href="https://en.wikipedia.org/wiki/Safety_Instrumented_System" title="Safety Instrumented System">SIS</a> safety systems.
</p>
<h2><span id="Types_of_pigs">Types of pigs</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=9" title="Edit section: Types of pigs">edit</a><span>]</span></span></h2>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:PipelinePIG.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/PipelinePIG.jpg/220px-PipelinePIG.jpg" decoding="async" width="220" height="147" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/PipelinePIG.jpg/330px-PipelinePIG.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/PipelinePIG.jpg/440px-PipelinePIG.jpg 2x" data-file-width="3872" data-file-height="2592"></a><figcaption>A pig on display in a section of cutaway pipe, from the <a href="https://en.wikipedia.org/wiki/Trans-Alaska_Pipeline_System" title="Trans-Alaska Pipeline System">Alaska Pipeline</a></figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Pipeline_device.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Pipeline_device.jpg/220px-Pipeline_device.jpg" decoding="async" width="220" height="147" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Pipeline_device.jpg/330px-Pipeline_device.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Pipeline_device.jpg/440px-Pipeline_device.jpg 2x" data-file-width="1537" data-file-height="1030"></a><figcaption>A pig launcher/receiver on a natural gas pipeline in Switzerland.</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Smart_pig.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Smart_pig.jpg/220px-Smart_pig.jpg" decoding="async" width="220" height="164" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Smart_pig.jpg/330px-Smart_pig.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Smart_pig.jpg/440px-Smart_pig.jpg 2x" data-file-width="2592" data-file-height="1936"></a><figcaption>An intelligent pig being transported</figcaption></figure>
<figure typeof="mw:File/Thumb"><a href="https://en.wikipedia.org/wiki/File:Smart_pig_install.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Smart_pig_install.jpg/220px-Smart_pig_install.jpg" decoding="async" width="220" height="164" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Smart_pig_install.jpg/330px-Smart_pig_install.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Smart_pig_install.jpg/440px-Smart_pig_install.jpg 2x" data-file-width="2592" data-file-height="1936"></a><figcaption>Installation of an intelligent pig</figcaption></figure>
<h3><span id="Gauging.2C_separation_and_cleaning_pigs"></span><span id="Gauging,_separation_and_cleaning_pigs">Gauging, separation and cleaning pigs</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=10" title="Edit section: Gauging, separation and cleaning pigs">edit</a><span>]</span></span></h3>
<p>A "pig" is a tool that is sent down a pipeline and propelled by the <a href="https://en.wikipedia.org/wiki/Pressure" title="Pressure">pressure</a> of the product flow in the pipeline itself. There are four main uses for pigs:
</p>
<ol><li>Physical separation between different fluids flowing through the pipeline</li>
<li>Internal cleaning of pipelines</li>
<li>Inspection of the condition of pipeline walls (also known as an <i>inline inspection</i> (ILI) tool)</li>
<li>Capturing and recording geometric information relating to pipelines (e.g., size, position).</li></ol>
<p>One of the most common and versatile is the foam pig which is cut or poured out of open cell <a href="https://en.wikipedia.org/wiki/Polyurethane" title="Polyurethane">polyurethane</a> foam into the shape of a bullet and is driven through pipelines for many reasons such as to prove the inner diameter of, clean, de-water, or dry out the line. There are several types of pigs for cleaning in various densities from 32 to 160 kilograms per cubic metre (2 to 10&nbsp;lb/cu&nbsp;ft) foam and in special applications up to 320&nbsp;kg/m<sup>3</sup> (20&nbsp;lb/cu&nbsp;ft). Some have <a href="https://en.wikipedia.org/wiki/Tungsten" title="Tungsten">tungsten</a> <a href="https://en.wikipedia.org/wiki/Screw#Differentiation_between_bolt_and_screw" title="Screw">studs</a> or abrasive wire mesh on the outside to cut <a href="https://en.wikipedia.org/wiki/Rust" title="Rust">rust</a>, <a href="https://en.wikipedia.org/wiki/Fouling" title="Fouling">scale</a>, or <a href="https://en.wikipedia.org/wiki/Paraffin_wax" title="Paraffin wax">paraffin wax</a> deposits off the inside of the pipe. Other types are fully or criss-cross coated in urethane, or there are bare polyurethane foam pigs with a urethane coating just on the rear to seal and assist in driving the pig. There are also fully molded urethane pigs used for liquid removal or batching several different products in one line.
</p><p><a href="https://en.wikipedia.org/w/index.php?title=Inline_inspection&amp;action=edit&amp;redlink=1" title="Inline inspection (page does not exist)">Inline inspection</a> pigs use various methods for inspecting a pipeline. A sizing pig uses one (or more) notched round metal plates as gauges. The notches allow different parts of the plate to bend when a bore restriction is encountered. More complex systems exist for inspecting various aspects of the pipeline.
</p>
<h3><span id="Intelligent_pig">Intelligent pig</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=11" title="Edit section: Intelligent pig">edit</a><span>]</span></span></h3>
<p>Intelligent pigs are used to inspect the pipeline with sensors and record the data for later analysis. These pigs use technologies such as magnetic flux leakage (MFL) and <a href="https://en.wikipedia.org/wiki/Ultrasound" title="Ultrasound">ultrasound</a> to inspect the pipeline. Intelligent pigs may also use <a href="https://en.wikipedia.org/wiki/Caliper" title="Caliper">calipers</a> to measure the inside geometry of the pipeline.
</p><p>In 1961, the first intelligent pig was run by Shell Development. It demonstrated that a self-contained electronic instrument could traverse a pipeline while measuring and recording wall thickness. The instrument used electromagnetic fields to sense wall integrity. In 1964 Tuboscope ran the first commercial instrument. It used MFL technology to inspect the bottom portion of the pipeline. The system used a black box similar to those used on aircraft to record the information; it was basically a highly customized analog tape recorder. Until recently, tape recording (although digital) was still the preferred recording medium. As the capacity and reliability of <a href="https://en.wikipedia.org/wiki/Solid-state_electronics" title="Solid-state electronics">solid-state memory</a> improved, most recording media moved away from tape to solid-state.
</p><p>Capacitive sensor probes are used to detect defects in polyethylene pipe gas pipeline. These probes are attached to the pig before it is sent through the polyethylene pipe to detect any defects in the outside of the pipe wall. This is done by using a triple plate capacitive sensor in which electrostatic waves are propagated outward through the pipe's wall. Any change in dielectric material results in a change in capacitance.<sup id="cite_ref-17"><a href="#cite_note-17">[17]</a></sup> Testing was conducted by NETL DOE research lab at the Battelle West Jefferson's Pipeline Simulation Facility
(PSF) near Columbus, Ohio.<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup>
</p><p>Modern intelligent or "smart" pigs are highly sophisticated instruments that include electronics and sensors that collect various forms of data during their trip through the pipeline. They vary in technology and complexity depending on the intended use and the manufacturer.
</p><p>The electronics are sealed to prevent leakage of the pipeline product into the electronics since products can range from being highly basic to highly acidic and can be of extremely high pressure and temperature. Many pigs use specific materials according to the product in the pipeline. Power for the electronics is typically provided by onboard batteries which are also sealed. Data recording may be by various means ranging from analog tape, digital tape, or solid-state memory in more modern units.
</p><p>The technology used varies by the service required and the design of the pig; each pigging service provider may have unique and proprietary technologies to accomplish the service. Surface pitting and corrosion, as well as cracks and weld defects in steel/ferrous pipelines are often detected using <a href="https://en.wikipedia.org/wiki/Magnetic_flux_leakage" title="Magnetic flux leakage">magnetic flux leakage</a> (MFL) pigs. Other "smart" pigs use <a href="https://en.wikipedia.org/wiki/Electromagnetic_acoustic_transducer" title="Electromagnetic acoustic transducer">electromagnetic acoustic transducers</a> to detect pipe defects.<sup id="cite_ref-19"><a href="#cite_note-19">[19]</a></sup> Caliper pigs can measure the <a href="https://en.wikipedia.org/wiki/Roundness_(object)" title="Roundness (object)">roundness</a> of the pipeline to determine areas of crushing or other deformations. Some smart pigs use a combination of technologies, such as providing MFL and caliper functions in a single tool. Trials of pigs using <a href="https://en.wikipedia.org/wiki/Acoustic_resonance_technology" title="Acoustic resonance technology">acoustic resonance technology</a> have been reported.<sup id="cite_ref-20"><a href="#cite_note-20">[20]</a></sup>
</p><p>During the pigging run the pig is unable to directly communicate with the outside world due to the distance underground or underwater and/or the materials that the pipe is made of. For example, steel pipelines effectively prevent any significant radio communications outside the pipe. It is therefore necessary that the pig use internal means to record its own movement during the trip. This may be done by <a href="https://en.wikipedia.org/wiki/Odometer" title="Odometer">odometers</a>, gyroscope-assisted <a href="https://en.wikipedia.org/wiki/Tilt_sensor" title="Tilt sensor">tilt sensors</a> and other technologies.<sup id="cite_ref-21"><a href="#cite_note-21">[21]</a></sup> The pig records this positional data so that the distance it moves along with any bends can be interpreted later to determine the exact path taken.
</p>
<h4><span id="Location_verification">Location verification</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=12" title="Edit section: Location verification">edit</a><span>]</span></span></h4>
<p>Location verification is often accomplished by surface instruments that record the pig's passage by either audible, magnetic, radio-transmission or other means. The sensors record when they detect the passage of the pig (time-of-arrival); this is then compared to the internal record for verification or adjustment. The external sensors may have <a href="https://en.wikipedia.org/wiki/Global_Positioning_System" title="Global Positioning System">Global Positioning System</a> capability<sup id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup> to assist in their location. A few pig passage indicators transmit the pig's passage, time and location, via satellite uplink.<sup id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup> The pig itself cannot use GPS as the metal pipe blocks satellite signals.
</p><p>After the pigging run has been completed, the positional data from the external sensors is combined with the pipeline evaluation data (corrosion, cracks, etc.) from the pig to provide a location-specific defect map and characterization. In other words, the combined data reveals to the operator the location, type and size of each pipe defect. This information is used to judge the severity of the defect and help repair crews locate and repair the defect quickly without having to dig up excessive amounts of pipeline. By evaluating the rate of change of a particular defect over several years, proactive plans can be made to repair the pipeline before any leakage or environmental damage occurs.
</p><p>The inspection results are typically archived (perhaps in <a href="https://en.wikipedia.org/wiki/Pipeline_Open_Data_Standard" title="Pipeline Open Data Standard">Pipeline Open Data Standard</a> format) for comparison with the results of later pigging runs on the same pipeline.
</p>
<h2><span id="In_popular_culture">In popular culture</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=13" title="Edit section: In popular culture">edit</a><span>]</span></span></h2>

<p>A pig has been used as a plot device in three <a href="https://en.wikipedia.org/wiki/James_Bond" title="James Bond">James Bond</a> films: <i><a href="https://en.wikipedia.org/wiki/Diamonds_Are_Forever_(film)" title="Diamonds Are Forever (film)">Diamonds Are Forever</a></i>, where Bond disabled a pig to escape from a pipeline; <i><a href="https://en.wikipedia.org/wiki/The_Living_Daylights" title="The Living Daylights">The Living Daylights</a></i>, where a pig was modified to secretly transport a person through the <a href="https://en.wikipedia.org/wiki/Iron_Curtain" title="Iron Curtain">Iron Curtain</a>; and <i><a href="https://en.wikipedia.org/wiki/The_World_Is_Not_Enough" title="The World Is Not Enough">The World Is Not Enough</a></i>, where a pig was used to carry and detonate a nuclear weapon in a pipeline.
</p><p>A pig was also used as a plot device in the <a href="https://en.wikipedia.org/wiki/Tony_Hillerman" title="Tony Hillerman">Tony Hillerman</a> book <i><a href="https://en.wikipedia.org/wiki/The_Sinister_Pig" title="The Sinister Pig">The Sinister Pig</a></i> where an abandoned pipeline from Mexico to the United States was used with a pig to transport illegal drugs.
</p><p>A pig launcher was featured in the season 2 episode "Pipeline Fever" of the animated show <i><a href="https://en.wikipedia.org/wiki/Archer_(2009_TV_series)" title="Archer (2009 TV series)">Archer</a></i>, wherein <a href="https://en.wikipedia.org/wiki/Sterling_Archer" title="Sterling Archer">Sterling Archer</a> and <a href="https://en.wikipedia.org/wiki/List_of_Archer_characters#Lana_Kane" title="List of Archer characters">Lana Kane</a> are tasked with going into a swamp and defending a pig launcher from radical environmentalist Joshua Gray.
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=14" title="Edit section: See also">edit</a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/Guided_wave_testing" title="Guided wave testing">Guided wave testing</a>, for <a href="https://en.wikipedia.org/wiki/Nondestructive_testing" title="Nondestructive testing">nondestructive testing</a> of a pipeline</li>
<li><a href="https://en.wikipedia.org/wiki/Hydraulically_activated_pipeline_pigging" title="Hydraulically activated pipeline pigging">Hydraulically activated pipeline pigging</a></li>
<li><a href="https://en.wikipedia.org/wiki/Ice_pigging" title="Ice pigging">Ice pigging</a>, a method of pipe cleaning using ice slurry instead of a solid pig</li>
<li><a href="https://en.wikipedia.org/wiki/Pipeline_transport" title="Pipeline transport">Pipeline transport</a>&nbsp;– Pumping fluids or gas through pipes</li>
<li><a href="https://en.wikipedia.org/wiki/Pipeline_video_inspection" title="Pipeline video inspection">Pipeline video inspection</a></li>
<li><a href="https://en.wikipedia.org/wiki/Robotic_non-destructive_testing" title="Robotic non-destructive testing">Robotic non-destructive testing</a>&nbsp;– Method of inspection using remotely operated tools</li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=15" title="Edit section: References">edit</a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-Schlumberger-1"><span><b><a href="#cite_ref-Schlumberger_1-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.products.slb.com/resource-library/article/valve-academy/how-it-works-pipeline-pigging">"How It Works: Pipeline Pigging"</a>. <i>www.products.slb.com</i>. Schlumberger<span>. Retrieved <span>10 April</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.products.slb.com&amp;rft.atitle=How+It+Works%3A+Pipeline+Pigging&amp;rft_id=https%3A%2F%2Fwww.products.slb.com%2Fresource-library%2Farticle%2Fvalve-academy%2Fhow-it-works-pipeline-pigging&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite><a rel="nofollow" href="https://engineeredpower.com/pig/">"Pipeline Inspection Gauge ( PIG )"</a>. <i>engineeredpower.com</i><span>. Retrieved <span>10 April</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=engineeredpower.com&amp;rft.atitle=Pipeline+Inspection+Gauge+%28+PIG+%29&amp;rft_id=https%3A%2F%2Fengineeredpower.com%2Fpig%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-Abdel-Hafez_and_Chowdhury_2015-3"><span><b><a href="#cite_ref-Abdel-Hafez_and_Chowdhury_2015_3-0">^</a></b></span> <span><cite id="CITEREFAbdel-HafezChowdhury2015">Abdel-Hafez, Mamoun; Chowdhury, Sheruzzaman (2015). <a rel="nofollow" href="https://www.researchgate.net/publication/282510297">"Pipeline Inspection Gauge Position Estimation Using Inertial Measurement Unit, Odometer, and a Set of Reference Stations"</a>. <i>ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems, Part B: Mechanical Engineering</i>. <b>2</b> (2). <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1115%2F1.4030945">10.1115/1.4030945</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ASCE-ASME+Journal+of+Risk+and+Uncertainty+in+Engineering+Systems%2C+Part+B%3A+Mechanical+Engineering&amp;rft.atitle=Pipeline+Inspection+Gauge+Position+Estimation+Using+Inertial+Measurement+Unit%2C+Odometer%2C+and+a+Set+of+Reference+Stations&amp;rft.volume=2&amp;rft.issue=2&amp;rft.date=2015&amp;rft_id=info%3Adoi%2F10.1115%2F1.4030945&amp;rft.aulast=Abdel-Hafez&amp;rft.aufirst=Mamoun&amp;rft.au=Chowdhury%2C+Sheruzzaman&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F282510297&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.engineeringnews.co.za/article/pigs-play-crucial-role-in-pipeline-maintenance-2005-09-09/rep_id:4715/company:fluor-2016-07-04">"<span></span>'Pigs' play crucial role in pipeline maintenance"</a>. <i>Creamer Media Engineering News</i><span>. Retrieved <span>21 November</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Creamer+Media+Engineering+News&amp;rft.atitle=%27Pigs%27+play+crucial+role+in+pipeline+maintenance&amp;rft_id=http%3A%2F%2Fwww.engineeringnews.co.za%2Farticle%2Fpigs-play-crucial-role-in-pipeline-maintenance-2005-09-09%2Frep_id%3A4715%2Fcompany%3Afluor-2016-07-04&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.rigzone.com/training/insight.asp?insight_id=310">"How Does Pipeline Pigging Work?"</a>. <i>rigzone.com</i><span>. Retrieved <span>21 November</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=rigzone.com&amp;rft.atitle=How+Does+Pipeline+Pigging+Work%3F&amp;rft_id=http%3A%2F%2Fwww.rigzone.com%2Ftraining%2Finsight.asp%3Finsight_id%3D310&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.npr.org/templates/story/story.php?storyId=5627707">"That's Some Smart Pig in the Pipeline"</a>. <i>NPR.org</i><span>. Retrieved <span>21 November</span> 2017</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=NPR.org&amp;rft.atitle=That%27s+Some+Smart+Pig+in+the+Pipeline&amp;rft_id=https%3A%2F%2Fwww.npr.org%2Ftemplates%2Fstory%2Fstory.php%3FstoryId%3D5627707&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.rigzone.com/training/insight.asp?insight_id=310&amp;c_id=19">"How Does Pipeline Pigging Work?"</a>. RIGGZONE.com<span>. Retrieved <span>2010-10-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=How+Does+Pipeline+Pigging+Work%3F&amp;rft.pub=RIGGZONE.com&amp;rft_id=http%3A%2F%2Fwww.rigzone.com%2Ftraining%2Finsight.asp%3Finsight_id%3D310%26c_id%3D19&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20201014052030/https://www.pipelinesinternational.com/2020/08/06/reaching-100-years-in-the-pipeline/">"Reaching 100 years in the pipeline"</a>. <i>Pipelines International</i>. August 6, 2020. Archived from <a rel="nofollow" href="https://www.pipelinesinternational.com/2020/08/06/reaching-100-years-in-the-pipeline/">the original</a> on 2020-10-14<span>. Retrieved <span>2020-10-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Pipelines+International&amp;rft.atitle=Reaching+100+years+in+the+pipeline&amp;rft.date=2020-08-06&amp;rft_id=https%3A%2F%2Fwww.pipelinesinternational.com%2F2020%2F08%2F06%2Freaching-100-years-in-the-pipeline%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><a rel="nofollow" href="http://www.pipingtech.com/products/miscellaneous-fabricated-supports.htm">Miscellaneous Fabricated Supports</a> Piping Technology &amp; Products, (retrieved May 2012)</span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite><a rel="nofollow" href="http://servinox.com/wordpress/index.php/systeme-de-raclage/?lang=en">"SERVINOX pig speed regulation unit"</a>. servinox.com<span>. Retrieved <span>2011-01-12</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=SERVINOX+pig+speed+regulation+unit&amp;rft.pub=servinox.com&amp;rft_id=http%3A%2F%2Fservinox.com%2Fwordpress%2Findex.php%2Fsysteme-de-raclage%2F%3Flang%3Den&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFShipp">Shipp, Brett. <a rel="nofollow" href="https://web.archive.org/web/20120829030105/http://www.wfaa.com/news/investigates/Pipeline-Flying-Pig-crashes-through-Grand-Prairie-home-105387413.html">"Pipeline 'pig' crashes through Grand Prairie home"</a>. WFAA. Archived from <a rel="nofollow" href="http://www.wfaa.com/news/investigates/Pipeline-Flying-Pig-crashes-through-Grand-Prairie-home-105387413.html">the original</a> on 2012-08-29.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Pipeline+%27pig%27+crashes+through+Grand+Prairie+home&amp;rft.pub=WFAA&amp;rft.aulast=Shipp&amp;rft.aufirst=Brett&amp;rft_id=http%3A%2F%2Fwww.wfaa.com%2Fnews%2Finvestigates%2FPipeline-Flying-Pig-crashes-through-Grand-Prairie-home-105387413.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20100413114933/http://www.piggingsystems.com/pigs.html">"I.S.T. Molchtechnik GmbH"</a>. Piggingsystems.com. Archived from <a rel="nofollow" href="http://www.piggingsystems.com/pigs.html">the original</a> on 2010-04-13<span>. Retrieved <span>2010-04-14</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=I.S.T.+Molchtechnik+GmbH&amp;rft.pub=Piggingsystems.com&amp;rft_id=http%3A%2F%2Fwww.piggingsystems.com%2Fpigs.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span>Adapted from Amoco  P&amp;ID of pig launcher and Operating Manual 1988</span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.google.com/maps/d/viewer?mid=1H3qFrNgSMKHjl7wIvEMwoWhbD6I&amp;hl=en_US&amp;ll=51.455460914997275%2C0.43466088854493545&amp;z=15">"NTS"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=NTS&amp;rft_id=https%3A%2F%2Fwww.google.com%2Fmaps%2Fd%2Fviewer%3Fmid%3D1H3qFrNgSMKHjl7wIvEMwoWhbD6I%26hl%3Den_US%26ll%3D51.455460914997275%252C0.43466088854493545%26z%3D15&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.netherlocks.com/products/process-interlocking/">"Process interlocking"</a>. <i>Netherlocks</i><span>. Retrieved <span>2020-10-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Netherlocks&amp;rft.atitle=Process+interlocking&amp;rft_id=https%3A%2F%2Fwww.netherlocks.com%2Fproducts%2Fprocess-interlocking%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-16"><span><b><a href="#cite_ref-16">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.netherlocks.com/process-interlocking/the-integration-of-electronic-components-into-mechanical-valve-interlocking-solutions/">"The integration of electronic components into mechanical valve interlocking solutions"</a>. <i>Netherlocks</i>. 2013-11-25<span>. Retrieved <span>2020-10-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Netherlocks&amp;rft.atitle=The+integration+of+electronic+components+into+mechanical+valve+interlocking+solutions&amp;rft.date=2013-11-25&amp;rft_id=https%3A%2F%2Fwww.netherlocks.com%2Fprocess-interlocking%2Fthe-integration-of-electronic-components-into-mechanical-valve-interlocking-solutions%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-17"><span><b><a href="#cite_ref-17">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20110717155911/http://gradworks.umi.com/14/71/1471527.html">"ProQuest Document View - Capacitive sensor technology for polyethylene pipe fault detection"</a>. Archived from <a rel="nofollow" href="http://gradworks.umi.com/14/71/1471527.html">the original</a> on 2011-07-17<span>. Retrieved <span>2010-10-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=ProQuest+Document+View+-+Capacitive+sensor+technology+for+polyethylene+pipe+fault+detection&amp;rft_id=http%3A%2F%2Fgradworks.umi.com%2F14%2F71%2F1471527.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20181031155032/https://www.netl.doe.gov/publications/others/pdf/Oil_Peaking_NETL.pdf">"Oil and Natural Gas Research"</a> <span>(PDF)</span>. <i>netl.doe.gov</i>. Archived from <a rel="nofollow" href="http://www.netl.doe.gov/oil-gas/natural-gas-resources">the original</a> on 2018-10-31<span>. Retrieved <span>2020-10-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=netl.doe.gov&amp;rft.atitle=Oil+and+Natural+Gas+Research&amp;rft_id=http%3A%2F%2Fwww.netl.doe.gov%2Foil-gas%2Fnatural-gas-resources&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-19"><span><b><a href="#cite_ref-19">^</a></b></span> <span>Stéphane Sainson, <i>Inspection en ligne des pipelines. Principes et méthodes</i>. Ed. Lavoisier. 2007. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-2743009724" title="Special:BookSources/978-2743009724">978-2743009724</a>. 332 p.</span>
</li>
<li id="cite_note-20"><span><b><a href="#cite_ref-20">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.gassco.no/en/media/news-archive/New-techonology-revolutionises-gas-pipeline-checks/">"New techonology revolutionises gas pipeline checks"</a>. <i>www.gassco.no</i><span>. Retrieved <span>2020-10-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.gassco.no&amp;rft.atitle=New+techonology+revolutionises+gas+pipeline+checks&amp;rft_id=https%3A%2F%2Fwww.gassco.no%2Fen%2Fmedia%2Fnews-archive%2FNew-techonology-revolutionises-gas-pipeline-checks%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-21"><span><b><a href="#cite_ref-21">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20120207134259/http://www.gdengineering.com/hi_t_pigalert.asp">"PIG Signaller"</a>. Archived from <a rel="nofollow" href="http://www.gdengineering.com/hi_t_pigalert.asp">the original</a> on 2012-02-07<span>. Retrieved <span>2012-02-14</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=PIG+Signaller&amp;rft_id=http%3A%2F%2Fwww.gdengineering.com%2Fhi_t_pigalert.asp&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-22"><span><b><a href="#cite_ref-22">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.enduropls.com/products/tracking">"Enduro Pipeline Services | Engineered to Deliver Superior Results"</a>. <i>www.enduropls.com</i><span>. Retrieved <span>2020-10-08</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=www.enduropls.com&amp;rft.atitle=Enduro+Pipeline+Services+%7C+Engineered+to+Deliver+Superior+Results&amp;rft_id=https%3A%2F%2Fwww.enduropls.com%2Fproducts%2Ftracking&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
<li id="cite_note-23"><span><b><a href="#cite_ref-23">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20140211061649/http://www.tdwilliamson.com/en/Products/PiggingProducts/Indicators/Documents/PIG_SIG%20NI.pdf">"Pig Passage Indicator"</a> <span>(PDF)</span>. Archived from <a rel="nofollow" href="http://www.tdwilliamson.com/en/Products/PiggingProducts/Indicators/Documents/PIG_SIG%20NI.pdf">the original</a> <span>(PDF)</span> on 2014-02-11<span>. Retrieved <span>2012-01-29</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Pig+Passage+Indicator&amp;rft_id=http%3A%2F%2Fwww.tdwilliamson.com%2Fen%2FProducts%2FPiggingProducts%2FIndicators%2FDocuments%2FPIG_SIG%2520NI.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3APigging"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Pigging&amp;action=edit&amp;section=16" title="Edit section: External links">edit</a><span>]</span></span></h2>
<p><a rel="nofollow" href="https://www.vpengineers.in/products/pipe-line-pigs/pipeline-pigging.html">https://www.vpengineers.in/products/pipe-line-pigs/pipeline-pigging.html</a>
<a rel="nofollow" href="https://www.vpengineers.in/products/pipe-line-pigs/cup-pigs.html">https://www.vpengineers.in/products/pipe-line-pigs/cup-pigs.html</a>
<a rel="nofollow" href="https://www.vpengineers.in/products/pipe-line-pigs/foam-pigs.html">https://www.vpengineers.in/products/pipe-line-pigs/foam-pigs.html</a>
</p>
<div>
<p><span typeof="mw:File"><span><img alt="" src="https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png" decoding="async" width="30" height="40" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/45px-Commons-logo.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/59px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376"></span></span></p>
<p>Wikimedia Commons has media related to <span><a href="https://commons.wikimedia.org/wiki/Category:Pigging" title="commons:Category:Pigging">Pigging</a></span>.</p></div>
<ul><li><a rel="nofollow" href="https://web.archive.org/web/20101103185632/http://www.battelle.org/pipetechnology/mfl/MFL98Main.html">Magnetic Flux Leakage information</a></li>
<li><a rel="nofollow" href="http://www.iliassociation.org/">Inline Inspection Association</a></li>
<li><a rel="nofollow" href="http://www.smartpigs.net/">Inline Inspection and Pipeline Pigging Resource</a> <a rel="nofollow" href="https://web.archive.org/web/20140210112019/http://smartpigs.net/">Archived</a> 2014-02-10 at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></li>
<li><a rel="nofollow" href="https://www.wsj.com/articles/SB10001424127887323455104579015140328479048"><i>Oil-Pipeline Cracks Evading Robotic 'Smart Pigs'; Probes used by Exxon and other companies aren't spotting flaws that cause massive spills</i></a> August 16, 2013 WSJ</li></ul>

<!-- 
NewPP limit report
Parsed by mw1489
Cached time: 20231021090903
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.818 seconds
Real time usage: 1.154 seconds
Preprocessor visited node count: 4158/1000000
Post‐expand include size: 534361/2097152 bytes
Template argument size: 2144/2097152 bytes
Highest expansion depth: 15/100
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 69397/5000000 bytes
Lua time usage: 0.447/10.000 seconds
Lua memory usage: 19317828/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  766.017      1 -total
 23.88%  182.906      1 Template:Underwater_diving
 23.33%  178.690      1 Template:Navbox_with_collapsible_groups
 21.36%  163.637      6 Template:Annotated_link
 16.18%  123.955     18 Template:Cite_web
 12.72%   97.412     35 Template:Navbox
  8.27%   63.338      1 Template:Short_description
  7.03%   53.869      2 Template:Unreferenced_section
  6.31%   48.302      2 Template:Unreferenced
  6.30%   48.270      1 Template:Commons_category
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1645192-0!canonical and timestamp 20231021090902 and revision id 1181171470. Rendering was triggered because: api-parse
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MMO Architecture: clients, sockets, threads and connection-oriented servers (140 pts)]]></title>
            <link>https://prdeving.wordpress.com/2023/10/13/mmo-architecture-client-connections-sockets-threads-and-connection-oriented-servers/</link>
            <guid>37963974</guid>
            <pubDate>Sat, 21 Oct 2023 04:03:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prdeving.wordpress.com/2023/10/13/mmo-architecture-client-connections-sockets-threads-and-connection-oriented-servers/">https://prdeving.wordpress.com/2023/10/13/mmo-architecture-client-connections-sockets-threads-and-connection-oriented-servers/</a>, See on <a href="https://news.ycombinator.com/item?id=37963974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<pre>More on MMO Architecture:<br>- <a href="https://prdeving.wordpress.com/2023/09/29/mmo-architecture-source-of-truth-dataflows-i-o-bottlenecks-and-how-to-solve-them/">MMO Architecture: Source of truth, Dataflows, I/O bottlenecks and how to solve&nbsp;them</a></pre>



<hr>



<p>In the MMO-type online gaming landscape, we are often faced with the challenge of managing a <strong>high demand for connections</strong>. Unlike regular applications, these systems must maintain a smooth and enjoyable gaming experience even amidst the digital chaos of having thousands of players interacting in <strong>real time.</strong><br>Layered architectures, dedicated servers per area and countless arcane spells of forbidden magic are employed to achieve this.</p>



<p>The first step in this orgy of fun is the client connecting to the system.<br>Usually, in a system we will encounter a frightening <strong>socket per client at least</strong>.<br>Open connections, like anything else, <strong>consume resources</strong> (CPU and RAM) as well as bandwidth (which could become prohibitively expensive in a rather short time depending on the particular conditions of each project).</p>



<p>Add to this that, no matter how boring and static our game is, those <strong>sockets will tend to be used</strong>, which means more and <strong>more traffic</strong>, and with it more and more load. And of course, we will have to implement some kind of <strong>authentication, authorization</strong> and be able to discern to which world or area the notification we receive from the client should be directed.</p>



<p>it is not complicated to realize that on occasions as extreme as the ridiculous space fights of 10,000 players in Eve online, the saturation of open connections can bring down even the most solid system.</p>



<p>Even more so if the design is not correct.</p>







<p>First of all, how do we manage these connections? You only need to look at an online tutorial on threading of any half-serious language to find the demon itself, <strong>one thread per connection</strong>.<br>Traditional one-to-one management of threads and connections, where each connection is handled in a separate thread, can lead to <strong>inefficient use of resources</strong>, as well as<strong> increased latency </strong>in task execution. The overhead of creating and destroying threads can be prohibitive, and the fixed thread limit can be reached quickly, resulting in lag or <strong>denial of service</strong> to the system clients.</p>



<figure><img data-attachment-id="3113" data-permalink="https://prdeving.wordpress.com/2023/10/13/mmo-architecture-client-connections-sockets-threads-and-connection-oriented-servers/image-3/" data-orig-file="https://prdeving.files.wordpress.com/2023/10/image.png" data-orig-size="771,487" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://prdeving.files.wordpress.com/2023/10/image.png?w=300" data-large-file="https://prdeving.files.wordpress.com/2023/10/image.png?w=771" src="https://prdeving.files.wordpress.com/2023/10/image.png?w=771" alt="" srcset="https://prdeving.files.wordpress.com/2023/10/image.png 771w, https://prdeving.files.wordpress.com/2023/10/image.png?w=150 150w, https://prdeving.files.wordpress.com/2023/10/image.png?w=300 300w, https://prdeving.files.wordpress.com/2023/10/image.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"></figure>



<p>Well, if you want to have to sell your liver to maintain your infrastructure and have your server explode every Friday afternoon, then this is the perfect choice for you.<br>If on the other hand you prefer to be able to sleep peacefully, with all your pieces where they belong, <strong>consider grouping multiple connections in the same thread.</strong><br>How many? it depends, 30-100? it’s a <strong>matter of testing</strong>, but, whatever it is, it will be many more than you can manage with a 1:1 strategy.</p>



<p>In general, we will use these threads to manage the connections, but not the executions derived from the messages that appear in them.<br>Once a message appears in one of the sockets, <strong>we queue</strong> it and let another thread process it. In this way, we <strong>decouple our input layer from our digest layer.</strong></p>



<h2>Thread pooling for message digesting</h2>



<p>The concept of digesting events or messages is quite graphic, in fact.<br>When the time comes, we have a <strong>FIFO queue</strong> that fills up with messages, we take them out, one at a time, and evaluate them.</p>



<figure><img data-attachment-id="3114" data-permalink="https://prdeving.wordpress.com/2023/10/13/mmo-architecture-client-connections-sockets-threads-and-connection-oriented-servers/image-1-2/" data-orig-file="https://prdeving.files.wordpress.com/2023/10/image-1.png" data-orig-size="958,571" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://prdeving.files.wordpress.com/2023/10/image-1.png?w=300" data-large-file="https://prdeving.files.wordpress.com/2023/10/image-1.png?w=840" src="https://prdeving.files.wordpress.com/2023/10/image-1.png?w=958" alt="" srcset="https://prdeving.files.wordpress.com/2023/10/image-1.png 958w, https://prdeving.files.wordpress.com/2023/10/image-1.png?w=150 150w, https://prdeving.files.wordpress.com/2023/10/image-1.png?w=300 300w, https://prdeving.files.wordpress.com/2023/10/image-1.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></figure>



<p>To solve this situation, an ideal tool is a<strong> thread pool</strong>, a simple yet effective mechanism which handles<strong> multiple tasks</strong> without the overhead of initializing and destroying threads for each individual task.<br>A thread pool, as the name suggests, is a <strong>pool of threads that stand ready to execute tasks.</strong></p>



<p>A thread pool is initialized with a specific number of threads, messages are submitted to a shared queue, which, in our case is implemented as a FIFO queue to maintain the order of processing.</p>



<p>The threads in the thread pool continuously <strong>monitor the queue</strong> for new tasks and when a task is available, a thread from the pool will <strong>dequeue the task and execute it.</strong> Upon completion of a task, the <strong>thread returns to the pool</strong> and stands ready to process the next available task in the queue.</p>



<p>These threads are <strong>created in advance</strong>, which alleviates the overhead of creating and destroying threads that would otherwise occur per task, and may even exceed the fixed limits of our machine by producing denials of service to the system’s clients.</p>



<p>This way, threads are <strong>reused across many tasks</strong>, leading to <strong>better performance</strong> and <strong>lower system resource usage</strong> as compared to creating a new thread for each task.</p>



<p>Utilizing a thread pool for digesting messages from a FIFO queue is <strong>highly efficient</strong> especially in scenarios where the rate of message arrival is high and the processing of each message is relatively short-lived, thus perfect for this little MMO situation we have here. The pool can significantly<strong> reduce the latency associated with the processing of these messages</strong>, ensuring that each message is handled in a timely fashion.</p>



<p>By leveraging a thread pool, the system can process <strong>multiple messages concurrently</strong>, maximizing the utilization of system resources and improving the overall throughput of the message processing system.</p>



<p>But threading is just a small slice of the story. </p>



<p>Even if we can afford 40 threads running in parallel and we can easily manage 200 clients per thread, reserving half of them for a pool, we would be talking about <strong>4000 concurrent clients</strong> per server, still far from the 10k nerds and their virtual lasers we were talking about before.<br>Not to mention that we are <strong>ignoring all the additional overhead of the game logic itself, authentication systems</strong>, etc.</p>



<p>How do we scale this?</p>



<h2>Frontend servers to decouple game from connections</h2>



<p>In a way, the question is already answered, but let’s go into a little more detail.</p>



<p>How would the flow look like at the definition point we are at? Simple, a client connects to the server and sends a message “hey server, I jumped!”.<br>The server, in the connection, has assigned the socket to a thread. When the socket receives the message, it puts it in a queue and at some point, another routine extracts the message from the queue, checks that the user is valid, sees what kind of action the user wants to do and executes the game logic for the specific action.</p>



<blockquote>
<p>we have <strong>game servers</strong> […] take care of the game </p>
</blockquote>



<p>This is where the proxy or frontend servers come into play.<br>We take that logic and <strong>split it up</strong>, we have <strong>game servers</strong>, well, they take care of the game and we manage the connections on a <strong>frontend server</strong>.</p>



<blockquote>
<p>The <strong>connection and the message goes to the frontend server</strong></p>
</blockquote>



<p>The <strong>connection and the message goes to the frontend server</strong>, it does its pooling magic, validates the session, sees which game world the character belongs to and sends the action directly to the game server.</p>



<figure><img data-attachment-id="3116" data-permalink="https://prdeving.wordpress.com/2023/10/13/mmo-architecture-client-connections-sockets-threads-and-connection-oriented-servers/image-2-2/" data-orig-file="https://prdeving.files.wordpress.com/2023/10/image-2.png" data-orig-size="1023,553" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://prdeving.files.wordpress.com/2023/10/image-2.png?w=300" data-large-file="https://prdeving.files.wordpress.com/2023/10/image-2.png?w=840" src="https://prdeving.files.wordpress.com/2023/10/image-2.png?w=1023" alt="" srcset="https://prdeving.files.wordpress.com/2023/10/image-2.png 1023w, https://prdeving.files.wordpress.com/2023/10/image-2.png?w=150 150w, https://prdeving.files.wordpress.com/2023/10/image-2.png?w=300 300w, https://prdeving.files.wordpress.com/2023/10/image-2.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"></figure>



<p>Voila, all the load related to sessions, client connections, retries, lags due to lost packets etc is isolated on frontend servers.<br>With the additional advantage that, <strong>being state-less </strong>practically in their entirety, they are infinitely <strong>scalable </strong>horizontally.</p>



<p>Meanwhile, our game worlds are only concerned with, well, <strong>the game.</strong></p>



<hr>



<p>In distributed systems as complex as an MMO, we face unique operational challenges. Real-time interaction among thousands of players, each of them generating a torrent of messages and actions, tests the robustness and efficiency of our designs.<br><strong>Prudent connection management</strong> and<strong> efficient message digestion</strong> are not just an operational necessity, but mission critical to ensure an immersive and rewarding gaming experience.</p>



<p>Efficient<strong> use of resources</strong> through techniques that allow us to control and distribute system load, such as thread pooling, is critical to efficiently digest messages and <strong>avoid overloading at times of high concurrency</strong>, enabling rapid response to player demands. In addition, the layered server architecture, with <strong>frontend servers handling connections</strong> and <strong>game servers focused on game </strong>logic, provides a clear <strong>separation of responsibilities</strong>, facilitating <strong>scalability and system maintenance.</strong></p>

			
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The next Raptor OpenPOWER systems are coming, but they won't be Power10 (133 pts)]]></title>
            <link>https://www.talospace.com/2023/10/the-next-raptor-openpower-systems-are.html</link>
            <guid>37963941</guid>
            <pubDate>Sat, 21 Oct 2023 03:54:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.talospace.com/2023/10/the-next-raptor-openpower-systems-are.html">https://www.talospace.com/2023/10/the-next-raptor-openpower-systems-are.html</a>, See on <a href="https://news.ycombinator.com/item?id=37963941">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-1252817771829370577">
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcTAptM5usH9rX8FpnstN6FiERUTfFy_qK6kwe1_31MQ5mlBPIa0UcAaTfBrx1xb0CBuiDGe2r5o1EA2OUSZjgTmWHOQJgDnn9xxfSt8Ay4zmNBDcQ7TWLcxK0_MWTwHjfws10PSK3BiIFp7z-3ICbTNLgDgHWrXXbff1ItWO56I_mWa_ev3IgN430OWI/s700/4452ea76-7593-41a8-9844-4de06c7bc505.png"><img alt="" data-original-height="700" data-original-width="515" height="320" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgcTAptM5usH9rX8FpnstN6FiERUTfFy_qK6kwe1_31MQ5mlBPIa0UcAaTfBrx1xb0CBuiDGe2r5o1EA2OUSZjgTmWHOQJgDnn9xxfSt8Ay4zmNBDcQ7TWLcxK0_MWTwHjfws10PSK3BiIFp7z-3ICbTNLgDgHWrXXbff1ItWO56I_mWa_ev3IgN430OWI/s320/4452ea76-7593-41a8-9844-4de06c7bc505.png"></a></p><p>

I'd like to first start out by saying I've been aware of new developments but made certain promises to keep my mouth shut until all the parties were ready to announce. (Phoronix is not so constrained.) Many of you <a href="https://www.talospace.com/2023/09/progress-on-firefox-ppc64le-jit.html?showComment=1696260751412#c7354742240276003302">noted</a> an offhand comment in <a href="https://youtu.be/Tj4Q-m_WEh0?feature=shared&amp;t=230">this YouTube video</a> about Raptor announcing a new Power10 system. That got a lot of people excited, because while our POWER9 systems are doing well, in 2023 this dual-8 64-thread POWER9 is no longer cutting edge and we need new silicon in the pipeline to keep the ecosystem viable.
</p><p>
Raptor yesterday <a href="https://www.morningstar.com/news/business-wire/20231019873615/secure-open-source-systems-leader-raptor-computing-systems-partners-with-lattice-showcasing-soft-bmc-for-server-management-and-solid-silicon-for-upcoming-power-isa-31-compliant-server-systems">officially announced</a> that we're <em>not</em> getting Power10 systems. The idea is we're going to be getting something <em>better</em>: the Solid Silicon S1. It's Power ISA 3.1 and fully compatible, but it's also a fully blob-free OpenPOWER successor to the POWER9, avoiding Power10's <a href="https://www.talospace.com/2021/09/its-not-just-omi-thats-trouble-with.html">notorious binary firmware requirement</a> for OMI RAM and I/O.
</p><p>
I asked Timothy Pearson at Raptor about the S1's specs, and he said it's a PCIe 5.0 DDR5 part running from the high 3GHz to low 4GHz clock range, with the exact frequency range to be determined. (OMI-based RAM <em>not</em> required!) The S1 is bi-endian, SMT-4 and will support at least two sockets with an 18-core option confirmed for certain and others to be evaluated. This compares very well with the Power10, which is also PCIe 5.0, also available as SMT-4 (though it has an SMT-8 option), and also clocks somewhere between 3.5GHz and 4GHz.
</p><p>
S1 embeds its own BMC, the X1 (or variant), which is (<a href="https://www.talospace.com/2022/08/whats-arctic-tern-good-for-anyway.html">like Arctic Tern</a>) a Microwatt-based ISA 3.1 core in <a href="https://www.latticesemi.com/Products/FPGAandCPLD/ECP5">Lattice ECP5</a> and <a href="https://www.latticesemi.com/iCE40">iCE40</a> FPGAs with 512MB of DDR3 RAM, similar to the existing ASpeed BMC on current systems. X1 will in turn replace the existing Lattice-based FPGA in Arctic Tern as "Antarctic Tern," being a functional descendant of the same hardware, and should fill the same roles as a BMC upgrade for existing Raptor systems as well as the future BMC for the next generation systems and a platform in its own right. The X1 has "integrated 100% open root of trust" as you would expect for such a system-critical part.
</p><p>
Raptor's newest systems are planned for late 2024. There will be tiering, so most likely (though not confirmed) Blackbird, T2 and T2 server classes of systems will be available under new names. Price? Well, you'll just have to wait and see.
</p><p>
Solid Silicon is definitely a new name in the Power ecosystem and we don't know a lot about them. <a href="https://www.solidsilicon.com/">There's a web page</a>, but the <s>Tw</s>Xitter and LinkedIn links are unpopulated as of this writing, and it's maddeningly minimal on actual content. Tim confirmed they are a new licensee and have been working on the design for at least a couple years. The press release gives a 737 area code, which is Austin, Texas, and the only Solid Silicon business entry I could find for Texas is <a href="https://opencorporates.com/companies/us_tx/0800191006">this one for Solid Silicon Technology LLC</a> in Plano. I'm told this isn't them, so if anyone from Solid Silicon would like to lift the corporate veil a little, drop me a line at ckaiser at floodgap dawt com. <i>[UPDATE: The LinkedIn was updated after this posted, listing <a href="https://www.linkedin.com/in/toddrooke?trk=org-employees">Todd Rooke</a> as CEO. Rooke's listing indicates past experience with FPGAs, as well as his time at HPE and Microsoft. His location is given as Colorado Springs but Colorado lists no company by that name. Hopefully more to come.]</i> 
</p><p>
But besides new systems in the offing, it's also good news that we're getting — we hope — performant OpenPOWER chips that <em>aren't</em> from IBM. I don't have anything against IBM; I've worked with IBM hardware for literally decades, and my home server is a classic POWER6 that just keeps on truckin'. But IBM designs chips to benefit IBM's world, which is server rooms (ask anyone who's got one what it's like to share an office with a POWER8), and IBM doesn't do end-user sales. If Raptor has a good partner here who can design solid OpenPOWER chips for workstations and small servers, not traditionally IBM's present domain but one important for them to maintain if they want OpenPOWER to stay relevant, then in around a year we should be in for a treat — and a very rosy near future.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Reduces the World to Stereotypes (153 pts)]]></title>
            <link>https://restofworld.org/2023/ai-image-stereotypes/</link>
            <guid>37963909</guid>
            <pubDate>Sat, 21 Oct 2023 03:49:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restofworld.org/2023/ai-image-stereotypes/">https://restofworld.org/2023/ai-image-stereotypes/</a>, See on <a href="https://news.ycombinator.com/item?id=37963909">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<!-- Article Start -->
				
<p><span>I</span>n July, BuzzFeed posted a list of 195 images of Barbie dolls produced using Midjourney, the popular artificial intelligence image generator. Each doll was supposed to represent a different country: Afghanistan Barbie, Albania Barbie, Algeria Barbie, and so on. The depictions were clearly flawed: Several of the Asian Barbies were light-skinned; Thailand Barbie, Singapore Barbie, and the Philippines Barbie all had blonde hair. Lebanon Barbie posed standing on rubble; Germany Barbie wore military-style clothing. South Sudan Barbie carried a gun.</p>



<p>The article —&nbsp;to which BuzzFeed added a disclaimer before taking it down entirely — offered an unintentionally striking example of the biases and stereotypes that proliferate in images produced by the recent wave of generative AI text-to-image systems, such as Midjourney, Dall-E, and Stable Diffusion.</p>



<p>Bias occurs in many algorithms and AI systems — from <a href="https://time.com/5209144/google-search-engine-algorithm-bias-racism/">sexist and racist search results</a> to facial recognition systems that <a href="https://www.scientificamerican.com/article/police-facial-recognition-technology-cant-tell-black-people-apart/">perform worse on Black faces</a>. Generative AI systems are no different. In <a href="https://www.bloomberg.com/graphics/2023-generative-ai-bias/">an analysis of more than 5,000 AI images</a>, Bloomberg found that images associated with higher-paying job titles featured people with lighter skin tones, and that results for most professional roles were male-dominated.</p>



<p>A new <em>Rest of World</em> analysis shows that generative AI systems have tendencies toward bias, stereotypes, and reductionism when it comes to national identities, too.&nbsp;</p>



<p>Using Midjourney, we chose five prompts, based on the generic concepts of “a person,” “a woman,” “a house,” “a street,” and “a plate of food.” We then adapted them for different countries: China, India, Indonesia, Mexico, and Nigeria. We also included the U.S. in the survey for comparison, given Midjourney (like most of the biggest generative AI companies) is based in the country.&nbsp;</p>



<p>For each prompt and country combination (e.g., “an Indian person,” “a house in Mexico,” “a plate of Nigerian food”), we generated 100 images, resulting in a data set of 3,000 images.</p>


		<div>
						<div>
				<div>	<figure>
		<div>
		<picture><source media="(orientation: landscape)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-400x224.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-600x336.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-1000x560.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-1600x896.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-2800x1568.jpg 2800w, " sizes="100vw"><source media="(orientation: portrait)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general-mobile-400x711.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general-mobile-600x1067.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general-mobile.jpg 945w, " sizes="100vw">
		<img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-40x22.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-general1-768x432.jpg" sizes="100vw" alt="A photo collage showing a grid of square images with portraits of people, exteriors of buildings, city streets, and plates of food.">
		</picture>
		</div>
				<figcaption itemprop="caption description">
		
		<span itemprop="copyrightHolder">Rest of World</span>
		</figcaption>
	</figure></div>
				<div>
					<p>The results show a hugely stereotypical view of the world.</p>
				</div>
			</div>			<div>
				<div>	<figure>
		<div>
		<picture><source media="(orientation: landscape)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-400x224.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-600x336.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-1000x560.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-1600x896.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-2800x1568.jpg 2800w, " sizes="100vw"><source media="(orientation: portrait)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-mobile-400x711.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-mobile-600x1067.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-mobile.jpg 945w, " sizes="100vw">
		<img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-40x22.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndianPerson-768x432.jpg" sizes="100vw" alt="A photo collage showing a grid of 98 square images of mainly bearded men wearing orange or red head coverings.">
		</picture>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></div>
				<div>
					<p>“An Indian person” is almost always an old man with a beard.</p>
				</div>
			</div>			<div>
				<div>	<figure>
		<div>
		<picture><source media="(orientation: landscape)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-400x224.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-600x336.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-1000x560.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-1600x896.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-2800x1568.jpg 2800w, " sizes="100vw"><source media="(orientation: portrait)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-mobile-400x711.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-mobile-600x1067.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-mobile.jpg 945w, " sizes="100vw">
		<img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-40x22.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-MexicanPerson-768x432.jpg" sizes="100vw" alt="A photo collage showing a grid of 98 square images of mainly men wearing hats.">
		</picture>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></div>
				<div>
					<p>“A Mexican person” is usually a man in a sombrero.</p>
				</div>
			</div>			<div>
				<div>	<figure>
		<div>
		<picture><source media="(orientation: landscape)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-400x224.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-600x336.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-1000x560.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-1600x896.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-2800x1568.jpg 2800w, " sizes="100vw"><source media="(orientation: portrait)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-mobile-400x711.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-mobile-600x1067.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-mobile.jpg 945w, " sizes="100vw">
		<img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-40x22.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-StreetNewDehli-768x432.jpg" sizes="100vw" alt="A photo collage showing a grid of 98 square images of a city street scene.">
		</picture>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></div>
				<div>
					<p>Most of New Delhi’s streets are polluted and littered.</p>
				</div>
			</div>			<div>
				<div>	<figure>
		<div>
		<picture><source media="(orientation: landscape)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-400x224.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-600x336.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-1000x560.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-1600x896.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-2800x1568.jpg 2800w, " sizes="100vw"><source media="(orientation: portrait)" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-mobile-400x711.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-mobile-600x1067.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-mobile.jpg 945w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-mobile.jpg 945w, " sizes="100vw">
		<img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-40x22.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MidjourneyGird-IndonesiaFood-768x432.jpg" sizes="100vw" alt="A photo collage showing a grid of 98 square images of food.">
		</picture>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></div>
				<div>
					<p>In Indonesia, food is served almost exclusively on banana leaves. </p>
				</div>
			</div>
		</div>


<p>“Essentially what this is doing is flattening descriptions of, say, ‘an Indian person’ or ‘a Nigerian house’ into particular stereotypes which could be viewed in a negative light,” Amba Kak, executive director of the AI Now Institute, a U.S.-based policy research organization, told <em>Rest of World</em>. Even stereotypes that are not inherently negative, she said, are still stereotypes: They reflect a particular value judgment, and a winnowing of diversity. Midjourney did not respond to multiple requests for an interview or comment for this story.</p>



<p>“It definitely doesn’t represent the complexity and the heterogeneity, the diversity of these cultures,” Sasha Luccioni, a researcher in ethical and sustainable AI at Hugging Face, told <em>Rest of World</em>.</p>



<figure><blockquote><p>“Now we’re giving a voice to machines.”</p></blockquote></figure>



<p>Researchers told <em>Rest of World</em> this could cause real harm. Image generators are being used for diverse applications, including in the <a href="https://www.reuters.com/technology/mad-men-machines-big-advertisers-shift-ai-2023-08-18/">advertising</a> and <a href="https://restofworld.org/2023/ai-revolution-outsourced-workers/">creative industries</a>, and even in tools designed to make <a href="https://www.vice.com/en/article/qjk745/ai-police-sketches">forensic sketches of crime suspects</a>.</p>



<p>The accessibility and scale of AI tools mean they could have an outsized impact on how almost any community is represented. According to Valeria Piaggio, global head of diversity, equity, and inclusion at marketing consultancy Kantar, the marketing and advertising industries have in recent years made strides in how they represent different groups, though there is still much progress to be made. For instance, they now show greater diversity in terms of race and gender, and better represent people with disabilities, Piaggio told <em>Rest of World</em>. Used carelessly, generative AI could represent a step backwards.&nbsp;</p>



<p>“My personal worry is that for a long time, we sought to diversify the voices — you know, who is telling the stories? And we tried to give agency to people from different parts of the world,“ she said. “Now we’re giving a voice to machines.”</p>



<hr>



<p><strong>Nigeria is home</strong> to more than 300 different ethnic groups, more than 500 different languages, and hundreds of distinct cultures. “There is Yoruba, there is Igbo, there is Hausa, there is Efik, there’s Ibibio, there’s Kanuri, there is Urhobo, there is Tiv,” Doyin Atewologun, founder and CEO of leadership and inclusion consultancy Delta, told <em>Rest of World</em>.</p>



<p>All of these groups have their own traditions, including clothing. Traditional Tiv attire features black-and-white stripes; a red cap has special meaning in the Igbo community; and Yoruba women have a particular way of tying their hair. “From a visual perspective, there are many, many versions of Nigeria,” Atewologun said.</p>



<p>But you wouldn’t know this from a simple search for “a Nigerian person” on Midjourney. Instead, all of the results are strikingly similar. While many images depict clothing that appears to indicate some form of traditional Nigerian attire, Atewologun said they lacked specificity. “It’s all some sort of generalized, ‘give them a head tie, put them in red and yellow and orangey colors<strong>, </strong>let there be big earrings and big necklaces and let the men have short caps,’” she said.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM-40x29.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM-400x285.png 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM-600x428.png 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM-1000x714.png 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM-1600x1142.png 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.31-PM.png 2402w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="A photo collage showing a grid of 98 square images of people under the headline " a="" nigerian="" person.""="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure>


<p>Atewologun added that the images also failed to capture the full variation in skin tones and religious differences among Nigerians. Muslims make up about 50% of the Nigerian population, and religious women often wear hijabs. But very few of the images generated by Midjourney depicted headscarves that resemble a hijab.&nbsp;</p>



<p>Other country-specific searches also appeared to skew toward uniformity. Out of 100 images for “an Indian person,” 99 seemed to depict a man, and almost all appeared to be over 60 years old, with visible wrinkles and gray or white hair.&nbsp;</p>



<p>Ninety-two of the subjects wore a traditional <em>pagri</em> —&nbsp;a type of turban — or similar headwear. The majority wore prayer beads or similar jewelry, and had a <em>tilak</em> mark or similar on their foreheads — both indicators associated with Hinduism. “These are not at all representative of images of Indian men and women,” Sangeeta Kamat, a professor at the University of Massachusetts Amherst who has worked on research related to diversity in higher education in India, told <em>Rest of World</em>. “They are highly stereotypical.”&nbsp;</p>



<p>Kamat said many of the men resembled a sadhu<em> — </em>a type of spiritual guru. “But even then, the garb is excessive and atypical,” she said.<br>Hinduism is the dominant religion in India, with almost <a href="https://www.pewresearch.org/short-reads/2021/09/21/key-findings-about-the-religious-composition-of-india/">80% of the population identifying as Hindu</a>. But there are significant minorities of other religions: Muslims make up the second-largest religious group, representing just over 14% of the population. But on Midjourney, they appeared noticeably absent.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM-40x29.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM-400x286.png 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM-600x429.png 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM-1000x715.png 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM-1600x1144.png 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.16.13-PM.png 2398w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="A photo collage showing a grid of 98 square images of people under the headline " an="" indian="" person.""="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure>


<p>Not all the results for “Indian person” fit the mold. At least two appeared to wear Native American-style feathered headdresses, indicating some ambiguity around the term “Indian.” A couple of the images seemed to merge elements of Indian and Native American culture.</p>



<p>Other country searches also skewed to people wearing traditional or stereotypical dress: 99 out of the 100 images for “a Mexican person,” for instance, featured a sombrero or similar hat.</p>



<p>Depicting solely traditional dress risks perpetuating a reductive image of the world. <strong>“</strong>People don’t just walk around the streets in traditional gear,” Atewologun said. “People wear T-shirts and jeans and dresses<em>.”</em>&nbsp;</p>



<p>Indeed, many of the images produced by Midjourney in our experiment look anachronistic, as if their subjects would fit more comfortably in an historical drama than a snapshot of contemporary society.</p>



<p>“It’s kind of making your whole culture like just a cartoon,” Claudia Del Pozo, a consultant at Mexico-based think tank C Minds, and founder and director of the Eon Institute, told <em>Rest of World</em>.&nbsp;</p>



<p>For the “American person” prompt, national identity appeared to be overwhelmingly portrayed by the presence of U.S. flags. All 100 images created for the prompt featured a flag, whereas none of the queries for the other nationalities came up with any flags at all.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM-40x28.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM-400x285.png 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM-600x427.png 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM-1000x712.png 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM-1600x1139.png 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.55-PM.png 2404w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="A photo collage showing a grid of 98 square images of people under the headline " an="" american="" person.""="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure>


<hr>



<p><strong>Across almost all </strong>countries, there was a clear gender bias in Midjourney’s results, with the majority of images returned for the “person” prompt depicting men.</p>



<p>This type of broad over- and underrepresentation likely stems from bias in the data on which the AI system is trained. Text-to-image generators are trained on data sets of huge numbers of captioned images — <a href="https://laion.ai/blog/laion-5b/">such as LAION-5B</a>, a collection of almost 6 billion image-text pairs (essentially, images with captions) taken from across the web. If these include more images of men than women, for example, it follows that the systems may produce more images of men. Midjourney did not respond to questions about the data it trained its system on.</p>



<p>However, one prompt bucked this male-dominant trend. The results for “an American person” included 94 women, five men, and one rather horrifying masked individual.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76-40x40.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76-400x400.png 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76-600x600.png 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76-1000x1000.png 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76.png 1024w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Person-US-76.png 1024w, " sizes="(max-width: 640px) 100vw, 600px" alt="An AI generated photo portrait of a figure wearing a mask and shirt, with an American Flag pattern.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure>


<p>Kerry McInerney, research associate at the Leverhulme Centre for the Future of Intelligence, suggests that the overrepresentation of women for the “American person” prompt could be caused by an overrepresentation of women in U.S. media, which in turn could be reflected in the AI’s training data. “There’s such a strong contingent of female actresses, models, bloggers — largely light-skinned, white women — who occupy a lot of different media spaces from TikTok through to YouTube,” she told <em>Rest of World.</em></p>



<p>Hoda Heidari, co-lead of the Responsible AI Initiative at Carnegie Mellon University, said it may also be linked to cultural differences around sharing personal images. “For instance, women in certain cultures might not be very willing to take images of themselves or allow their images to go on the internet,” she said.</p>



<p>“Woman”-specific prompts generated the same lack of diversity and reliance on stereotypes as the “person” prompts. Most Indian women appeared with covered heads and in saffron colors often tied to Hinduism; Indonesian women were shown wearing headscarves or floral hair decorations and large earrings. Chinese women wore traditional <em>hanfu-</em>style clothing and stood in front of “oriental”-style floral backdrops.</p>


	<figure>
		<div>
			<ul>
				<li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-NigerianWomen.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of headshots of women wearing colorful and patterned headwraps.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-MexicanWomen.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of headshots of women wearing red and white clothing.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-AmericanWomen.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of headshots of women wearing a variety of types and colors of clothing, all set in front of an American flag.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-ChineseWomen.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of headshots of women wearing red and blue colored clothing.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/MJSquare-IndianWomen.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of headshots of women wearing red sarees against dark backgrounds.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li>
			</ul>
		</div>
		
	</figure>


<p>Comparing the “person” and “woman” prompts revealed a few interesting differences. The women were notably younger: While men in most countries appeared to be over 60 years old, the majority of women appeared to be between 18 and 40.&nbsp;&nbsp;</p>



<p>There was also a difference in skin tone, which <em>Rest of World</em> measured by comparing images against the Fitzpatrick scale, a tool developed for dermatologists which classifies skin color into six types. On average, women’s skin tones were noticeably lighter than those of men. For China, India, Indonesia, and Mexico, the median result for the “woman” prompt featured a skin tone at least two levels lighter on the scale than that for the “person” prompt.</p>



<p>“I’m not surprised that that particular disparity comes up because I think colorism is so profoundly gendered,” McInerney said, pointing out the greater societal pressure on women in many communities to be and appear younger and lighter-skinned. As a result, this is likely reflected in the system’s training data.</p>



<p>She also highlighted Western-centric beauty norms apparent in the images: long, shiny hair; thin, symmetrical faces; and smooth, even skin. The images for “a Chinese woman” mostly depict women with double eyelids. “This is concerning as it means that Midjourney, and other AI image generators, could further entrench impossible or restrictive beauty standards in an already image-saturated world,” McInerney said.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-40x20.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-400x202.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-600x302.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-1000x504.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-1600x806.jpg 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/PersonWomenPrompts-2800x1411.jpg 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="A photo collage showing a grid of square images of people under the headline " an="" american="" person.""="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		<span itemprop="copyrightHolder">Images: Rest of World/Midjourney</span>
		</figcaption>
	</figure>


<hr>



<p><strong>It’s not just </strong>people at risk of stereotyping by AI image generators. A <a href="https://arxiv.org/pdf/2305.11080.pdf">study by researchers at the Indian Institute of Science</a> in Bengaluru found that, when countries weren’t specified in prompts, DALL-E 2 and Stable Diffusion most often depicted U.S. scenes. Just asking Stable Diffusion for “a flag,” for example, would produce an image of the American flag.&nbsp;</p>



<p>“One of my personal pet peeves is that a lot of these models tend to assume a Western context,” Danish Pruthi, an assistant professor who worked on the research, told <em>Rest of World.</em></p>



<p><em>Rest of World </em>ran prompts in the format of “a house in [country],” “a street in [capital city],” and “a plate of [country] food.”</p>



<p>According to Midjourney, Mexicans live in blocky dwellings painted bright yellow, blue, or coral; most Indonesians live in steeply pitched A-frame homes surrounded by palm trees; and Americans live in gothic timber houses that look as if they may be haunted. Some of the houses in India looked more like Hindu temples than people’s homes.</p>



<p>Perhaps the most obviously offensive results were for Nigeria, where most of the houses Midjourney created looked run-down, with peeling paint, broken materials, or other signs of visible disrepair.</p>


	<figure>
		<div>
			<ul>
				<li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndia.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of a blue and pinkish houses in tropical environments.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseAmerica.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of dark houses in foggy, moody environments.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseNigeria.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of a tan and brown houses.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseIndonesia.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of a big houses in jungle environments.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseMexico.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of a colorful houses in bright environments.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li><li>	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina-40x40.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina-400x400.jpg 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina-600x600.jpg 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina-1000x1000.jpg 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina.jpg 1500w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/AIArt-HouseChina.jpg 1500w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="A photo collage showing a grid of 9 square images of dark houses in foggy, moody environments.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure></li>
			</ul>
		</div>
		
	</figure>


<p>Though the majority of results were most remarkable for their similarities, the “house” prompt did produce some creative outliers. Some of the images have a fantastical quality, with several buildings appearing to defy physics to look more inspired by <em>Howl’s Moving Castle </em>than anything with realistic structural integrity.&nbsp;</p>



<p>When comparing the images of streets in capital cities, some differences jump out. Jakarta often featured modern skyscrapers in the background and almost all images for Beijing included red paper lanterns. Images of New Delhi commonly showed visible air pollution and trash in the streets. One New Delhi image appeared to show a riot scene, with lots of men milling around, and fire and smoke in the street.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16-40x40.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16-400x400.png 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16-600x600.png 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16-1000x1000.png 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16.png 1024w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Midjourney-Street-New-Delhi-16.png 1024w, " sizes="(max-width: 640px) 100vw, 600px" alt="An AI generated photo portrait of street scene showing a riot scene, with lots of men milling around and fire and smoke in the street.">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure>


<p>For the “plate of food” prompt, Midjourney favored the Instagram-style overhead view. Here, sameness again prevailed over variety: The Indian meals were arranged thali-style on silver platters, while most Chinese food was accompanied by chopsticks. Out of the 100 images of predominantly beige American food, 84 included a U.S. flag somewhere on the plate.</p>



<p>The images captured a surface-level imitation of any country’s cuisine. Siu Yan Ho, a lecturer at Hong Kong Baptist University who researches Chinese food culture, told <em>Rest of World</em> there was “absolutely no way” the images accurately represented Chinese food. He said the preparation of ingredients and the plating appeared more evocative of Southeast Asia. The deep-fried food, for example, appeared to be cooked using Southeast Asian methods —&nbsp;“most fried Chinese dishes will be seasoned and further processed,” Siu said.&nbsp;</p>



<p>He added that lemons and limes, which garnish many of the images, are rarely used in Chinese cooking, and are not served directly on the plate. But the biggest problem, Siu said, was that chopsticks were often shown in threes rather than pairs —&nbsp;an important symbol in Chinese culture. “It is extremely inauspicious to have a single chopstick or chopsticks to appear in an odd number,” he said.</p>


	<figure>
		<div>
		<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM-40x29.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM-400x285.png 400w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM-600x428.png 600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM-1000x713.png 1000w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM-1600x1141.png 1600w, https://149346090.v2.pressablecdn.com/wp-content/uploads/2023/10/Screen-Shot-2023-10-03-at-2.15.39-PM.png 2398w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="A photo collage showing a grid of 98 square images of food under the headline " a="" plate="" of="" chinese="" food.""="">
		
		</p>
		</div>
				<figcaption itemprop="caption description">
		
		
		</figcaption>
	</figure>


<hr>



<p><strong>Bias in AI </strong>image generators is a tough problem to fix. After all, the uniformity in their output is largely down to the fundamental way in which these tools work. The AI systems look for patterns in the data on which they’re trained, often discarding outliers in favor of producing a result that stays closer to dominant trends. They’re designed to mimic what has come before, not create diversity.&nbsp;</p>



<p>“These models are purely associative machines,” Pruthi said. He gave the example of a football: An AI system may learn to associate footballs with a green field, and so produce images of footballs on grass.&nbsp;</p>



<p>In many cases, this results in a more accurate or relevant image. But if you don’t want an “average” image, you’re out of luck. “It’s kind of the reason why these systems are so good, but also their Achilles’ heel,” Luccioni said.</p>



<p>When these associations are linked to particular demographics, it can result in stereotypes. In a <a href="https://dl.acm.org/doi/10.1145/3593013.3594095">recent paper</a>, researchers found that even when they tried to mitigate stereotypes in their prompts, they persisted. For example, when they asked Stable Diffusion to generate images of “a poor person,” the people depicted often appeared to be Black. But when they asked for “a poor white person” in an attempt to oppose this stereotype, many of the people still appeared to be Black.</p>



<p>Any technical solutions to solve for such bias would likely have to start with the training data, including how these images are initially captioned. Usually, this requires humans to annotate the images. “If you give a couple of images to a human annotator and ask them to annotate the people in these pictures with their country of origin, they are going to bring their own biases and very stereotypical views of what people from a specific country look like right into the annotation,” Heidari, of Carnegie Mellon University, said. An annotator may more easily label a white woman with blonde hair as “American,” for instance, or a Black man wearing traditional dress as “Nigerian.”&nbsp;</p>



<p>There is also a language bias in data sets that may contribute to more stereotypical images. “There tends to be an English-speaking bias when the data sets are created,” Luccioni said. “So, for example, they’ll filter out any websites that are predominantly not in English.&nbsp;</p>



<p>The LAION-5B data set <a href="https://laion.ai/blog/laion-5b/">contains 2.3 billion English-language image-text pairs</a>, with another 2.3 billion image-text pairs in more than 100 other languages. (A further 1.3 billion contain text without a specific language assigned, such as names.)</p>



<p>This language bias may also occur when users enter a prompt. <em>Rest of World</em> ran its experiment using English-language prompts; we may have gotten different results if we typed the prompts in other languages.</p>



<p>Attempts to manipulate the data to give better outcomes can also skew results. For example, many AI image generators filter the training data to weed out pornographic or violent images. But this may have unintended effects. OpenAI found that when it filtered training data for its DALL-E 2 image generator, it exacerbated gender bias. In a blog post, the company explained that more images of women than men <a href="https://openai.com/research/dall-e-2-pre-training-mitigations">had been filtered out of its training data</a>, likely because more images of women were found to be sexualized. As a result, the data set ended up including more men, leading to more men appearing in results. OpenAI attempted to address this by reweighting the filtered data set to restore balance, and has <a href="https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2">made other attempts to improve the diversity</a> of DALL-E’s outputs.</p>



<p>Almost every AI researcher <em>Rest of World </em>spoke to said the first step to improving the issue of bias in AI systems was greater transparency from the companies involved, which are often secretive about the data they use and how they train their systems. “It’s very much been a debate that’s been on their terms, and it’s very much like a ‘trust us’ paradigm,” said Amba Kak of the AI Now Institute.</p>



<p>As generative AI image generators are used for more applications, their bias could have real-world implications. The scale and speed of AI means it could significantly bolster existing prejudices. “Stereotypical views about certain groups can directly translate into negative impact on important life opportunities they get,” said Heidari, citing access to employment, health care, and financial services as examples.</p>



<figure><blockquote><p>“It’s very much like a ‘trust us’ paradigm.”</p></blockquote></figure>



<p>Luccioni cited a project to use <a href="https://www.vice.com/en/article/qjk745/ai-police-sketches">AI image generation to help make forensic sketches</a> as an example of a potential application with a more direct negative impact: Biases in the system could lead to a biased — and inaccurate — sketch. “It’s the derivative tools that really worry me in terms of impacts,” she said.</p>



<p>Experts told <em>Rest of World</em> images can have a profound effect on how we perceive the world and the people in it, especially when it comes to cultures we haven’t experienced ourselves. “We come to our beliefs about what is true, what is real … based on what we see,” said Atewologun.</p>



<p>Kantar’s Piaggio said generative AI could help improve diversity in media by making creative tools more accessible to groups who are currently marginalized or lack the resources to produce messages at scale. But used unwisely, it risks silencing those same groups. “These images, these types of advertising and brand communications have a huge impact in shaping the views of people — around gender, around sexual orientation, about gender identity, about people with disabilities, you name it,” she said. “So we have to move forward and improve, not erase the little progress we have made so far.”</p>



<p>Pruthi said image generators were touted as a tool to enable creativity, automate work, and boost economic activity. But if their outputs fail to represent huge swathes of the global population, those people could miss out on such benefits. It worries him, he said, that companies often based in the U.S. claim to be developing AI for all of humanity, “and they are clearly not a representative sample.”</p>
				<!-- Article End -->
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dropbox handing over 25% of San Francisco HQ back to landlord (101 pts)]]></title>
            <link>https://www.cnbc.com/2023/10/20/dropbox-hands-over-25percent-of-san-francisco-headquarters-back-to-landlord-.html</link>
            <guid>37963854</guid>
            <pubDate>Sat, 21 Oct 2023 03:34:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/10/20/dropbox-hands-over-25percent-of-san-francisco-headquarters-back-to-landlord-.html">https://www.cnbc.com/2023/10/20/dropbox-hands-over-25percent-of-san-francisco-headquarters-back-to-landlord-.html</a>, See on <a href="https://news.ycombinator.com/item?id=37963854">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-106225508" data-test="InlineImage"><p>Drew Houston, Dropbox Co-Founder and CEO.</p><p>Arun Nevader | CNBC</p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/DBX/">Dropbox</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> said Friday that it's agreed to return over one quarter of its San Francisco headquarters to the landlord as the commercial real estate market continues to soften following the Covid pandemic. </p><p><a href="https://www.sec.gov/ix?doc=/Archives/edgar/data/1467623/000146762323000044/dbx-20231017.htm" target="_blank">In a filing</a>, Dropbox said it agreed to surrender to its landlord 165,244 square feet of space and pay $79 million in termination fees. Under the amendment to its lease agreement, Dropbox will offload the space over time through the first quarter of 2025. </p><p>Since going remote during the pandemic three years ago, Dropbox has been trying to figure out what to do with much of the 736,000 square feet of space in Mission Bay it leased in 2017, in what was the largest office lease in the city's history. The company subleased closed to 134,000 square feet of space last year to Vir Biotechnology, leaving it with just over 604,000 square feet.</p><p>In addition, Dropbox took a <a href="https://www.cnbc.com/2023/02/16/dropbox-has-175-million-real-estate-loss-in-2022-for-san-francisco.html#:~:text=Dropbox%20said%20in%20its%20fourth,the%20year%20was%20%24175.2%20million.">$175.2 million impairment</a> on the office last year "as a result of adverse changes" in the market. That came after taking a $400 million hit in 2020.</p><p>San Francisco's office vacancy rate stood at 30% in the third quarter, the highest level since at least 2007, according to <a href="https://sfgov.org/scorecards/economy/commercial-real-estate" target="_blank">city data</a>.</p><p>"As we've noted in the past, we've taken steps to de-cost our real estate portfolio as a result of our transition to Virtual First, our operating model in which remote work is the primary experience for our employees, but where we still come together for planned in-person gatherings," a company spokesperson told CNBC in an emailed statement. </p><p>While the move provides a financial benefit to the cloud software vendor, it signals that demand for office space in the city remains weak and suggests more pain may be ahead for companies that signed big leases before the pandemic, when venture funding and public investors were fueling a tech boom. In addition to the remote work trend, the tech industry has been in downsizing mode since early 2022, with industrywide layoffs. </p><p>Drew Houston, Dropbox's co-founder and CEO, <a href="https://blog.dropbox.com/topics/company/a-message-from-drew" target="_blank">announced</a> in April that the company was cutting its headcount by about 16%.</p><p>Dropbox's 2017 lease for the brand new headquarters was for 15 years. Private-equity firm KKR <a href="https://realassets.ipe.com/news/kkr-reveals-1bn-san-franciscos-the-exchange-office-complex-buy-updated/10051973.article" target="_blank">bought</a> the property in 2021 from its original developer, Kilroy Realty Corp., for over $1 billion. </p><p>"As a result of the amendment the company will avoid future cash payments related to rent and common area maintenance fees of $137 million and approximately $90 million, respectively, over the remaining 10 year lease term," Dropbox said in <a href="https://www.sec.gov/ix?doc=/Archives/edgar/data/1467623/000146762323000044/dbx-20231017.htm" target="_blank">Friday's filing</a>.</p><p>A short walk away from Dropbox, <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-8"><a href="https://www.cnbc.com/quotes/UBER/">Uber</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> has been trying to sublease part of its headquarters. The <a href="https://www.sfchronicle.com/realestate/article/openai-s-f-biggest-office-lease-18422837.php" target="_blank">San Francisco Chronicle</a> reported last week that Microsoft-backed OpenAI is close to taking space there.</p><p>Dropbox had tried working with its landlord to sublease space at the headquarters, but the real estate market deteriorated, finance chief Tim Regan, told analysts on a <a href="https://www.cnbc.com/2023/02/16/dropbox-has-175-million-real-estate-loss-in-2022-for-san-francisco.html">February earnings call</a>.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2023/10/19/sf-giants-ceo-advance-sf-raises-4-million-in-private-donations-as-sf-tries-to-rally-city-pride.html">Advance SF launches 'It All Starts Here' campaign for San Francisco</a></p></div><div id="Placeholder-ArticleBody-Video-107320200" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000319602" aria-labelledby="Placeholder-ArticleBody-Video-107320200"><p><img src="https://image.cnbcfm.com/api/v1/image/107320201-16977323231697732320-31663331025-1080pnbcnews.jpg?v=1697733098&amp;w=750&amp;h=422&amp;vtcrop=y" alt="Advance SF launches 'It All Starts Here' campaign for San Francisco"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to self study pure math – a step-by-step guide [video] (185 pts)]]></title>
            <link>https://www.youtube.com/watch?v=byNaO_zn2fI</link>
            <guid>37963453</guid>
            <pubDate>Sat, 21 Oct 2023 02:05:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=byNaO_zn2fI">https://www.youtube.com/watch?v=byNaO_zn2fI</a>, See on <a href="https://news.ycombinator.com/item?id=37963453">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>