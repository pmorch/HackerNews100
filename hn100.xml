<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 14 Oct 2025 15:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[KDE celebrates the 29th birthday and kicks off the yearly fundraiser (181 pts)]]></title>
            <link>https://kde.org/fundraisers/yearend2025/</link>
            <guid>45578117</guid>
            <pubDate>Tue, 14 Oct 2025 09:54:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kde.org/fundraisers/yearend2025/">https://kde.org/fundraisers/yearend2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45578117">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img alt="" src="https://kde.org/fundraisers/yearend2025/top_box.png"></p><p>This week is KDE’s 29th anniversary. It may not be a nice round number like 25 or 30, but whenever another birthday rolls around for an independent project the size and scope of KDE — powered by the goodwill of its contributors and users — that’s really quite something!</p><p>This year we’re celebrating by kicking off our yearly fundraiser. Let’s raise at least €50,000 before the end of the year!</p><h3 id="donated-updated-daily"><span>Donated (updated daily)</span></h3><p><sup>*</sup>Stretch goal coming soon.</p><h2 id="make-kdes-birthday-wishes-come-true">Make KDE’s Birthday Wishes Come True</h2><h3 id="producing-first-class-software">Producing first-class software</h3><p>KDE is on the verge of something big, and the popularity of its free software is on the rise. It’s increasingly being adopted by gamers, artists, professionals, companies, and public institutions. But the costs associated with developing and maintaining that software are also growing.</p><p><strong><a href="https://kde.org/fundraisers/yearend2025/#top">Your donation</a></strong> keeps KDE “in business” and our software sustainable for generations to come.</p><figure><img src="https://kde.org/fundraisers/yearend2025/Katie_Konqi_make_software.png"></figure><h3 id="keeping-you-in-control">Keeping you in control</h3><p>A core aim of KDE is keeping you in control of your digital life, and we do it by providing high-quality and privacy-conscious free software. But we can only keep doing it by preserving our own financial independence, so that we never become too dependent on any single source of support.</p><p><strong><a href="https://kde.org/fundraisers/yearend2025/#top">Your donation</a></strong> makes KDE truly independent. Funding from the people allows us keep KDE developed by the people, of the people, and for the people.</p><h3 id="cleaning-up-the-world">Cleaning up the world</h3><p>This week is also <a href="https://weee-forum.org/iewd-about/">International E-Waste Day</a>, and KDE wants a clean planet too! We started the <a href="https://endof10.org/">End of 10</a> campaign because big tech corporations continue pushing everyone to chase the new shiny… in the process filling landfills with perfectly functional devices that become terrible sources of pollution when junked<sup><a href="https://kde.org/fundraisers/yearend2025/#anot01">*</a></sup>.</p><p><strong><a href="https://kde.org/fundraisers/yearend2025/#top">Your donation</a></strong> allows us to inform everybody about how they can help stave off these environmental disasters.</p><figure><img src="https://kde.org/fundraisers/yearend2025/konqi_katie_recycle.png"></figure><hr><p><a name="anot01"></a><sup>*</sup> Case in point: Microsoft is stopping free support for Windows 10 on hundreds of millions of computers this very week. Many of these old yet perfectly usable devices will not be able to upgrade because of spurious hardware requirements. Microsoft’s solution? “Throw away your computer and pollute the planet because we want to make even more money.”</p><h3 id="reaching-people-the-tech-industry-left-behind">Reaching people the tech industry left behind</h3><p>Many aren’t in a position to replace their devices every few years, or download hundreds of gigabyes of data from an always-on internet connection. KDE produces software that doesn’t need the latest hardware or an always-on internet connection, allowing everybody find their space in the digitized world.</p><p><strong><a href="https://kde.org/fundraisers/yearend2025/#top">Your donation</a></strong> helps KDE serve those who are ignored by the industry, and bring marginalized users into the community so they can help the project grow for everyone.</p><h3 id="helping-public-institutions-adopt-free-software">Helping public institutions adopt free software</h3><p>The governments of the world are starting to realize that using public funds to lock themselves into proprietary closed-source software has been a strategic geopolitical mistake.</p><p>Free software is publicly owned, representing the safest option for governments that want full control over their machines and safety for their citizens’ data. But often the standards required for software approval by public institutions is very high, and their needs very specific.</p><p><strong><a href="https://kde.org/fundraisers/yearend2025/#top">Your donation</a></strong> helps KDE adapt our software to what public institutions require, clearing the way for your tax dollars to fund KDE, not some big foreign companies.</p><hr><p>Images "<i>Konqi opens the magic box</i>", "<i>"Katie and Konqi make software</i>",
<i>"Katie and Konqi take on the public administration</i>" CC-BY-SA-4.0 license by
<a href="https://www.arctaxia.ink/">Arctaxia</a>. "<i>Katie &amp; Konqi recyle</i>" CC-BY-SA-4.0
license by <a href="https://krita-artists.org/u/nezumi_cafune/summary">Nezumi Cafuné</a>.</p><h2 id="goodies">Goodies</h2><p>Don’t forget to download your goodies after you donated! Get digital badges, printable cards, and more.</p><p><img alt="" src="https://kde.org/fundraisers/yearend2025/badges.png"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why the push for Agentic when models can barely follow a simple instruction? (244 pts)]]></title>
            <link>https://forum.cursor.com/t/why-the-push-for-agentic-when-models-can-barely-follow-a-single-simple-instruction/137154</link>
            <guid>45577080</guid>
            <pubDate>Tue, 14 Oct 2025 07:08:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forum.cursor.com/t/why-the-push-for-agentic-when-models-can-barely-follow-a-single-simple-instruction/137154">https://forum.cursor.com/t/why-the-push-for-agentic-when-models-can-barely-follow-a-single-simple-instruction/137154</a>, See on <a href="https://news.ycombinator.com/item?id=45577080">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p>I have a bunch of file for different reason, you need to work with a structure, agents like to work in folder structure, here is one of my custom agent instruction.</p>
<p>Now i have a agents.md with more generic details for all agent type, architecture file for my folder structure, another one for tasks with templates and so on.</p>
<p>Now i start all my prompt with please search and read/multi-read all .md file<br>
(If i have the file system MCP installed, wich is free and godsend)</p>
<p>My md file has my high level planing, brainstorming files and other complementary file that i keep up to date so that when the AI is done ingesting all the md files he is prepped up to go dig code, write code and chew bubblegum… Mmmm might need some work on the last one. HE MUST CHEW BUBBLE GUM AND HE HAS NO MOUTH (Claptrap kiss no mouth reference)</p>
<p>You need to have them work on small vertical slice that can be built under a 100k token more or less, more than that the agent start to misbehave and you need to fire him.</p>
<p>I have custom architect for building plan, codeseeker, coder, and other more specialised agents.</p>
<p>Build your team, build a structure, in the last 2 month playing with agents and python i learnt more about coding than a full year high school. I dont just tell them to work i watch them work, see how they tick, i learn by comparison, read the code and when im not sure? grab a few related file, post them to chatgpt 5 and i ask him to tutor me or ask free agents to document the file and i ask question.</p>
<p>You dont ask a human to climb a tree even tho he look like a monkey, he might be able to, but still not his best skill. Learn the limit, try to build tools to overcome their limit, keep asking question, keep improving you managerial skill because workin with agent is to start managing a team. Imm full on on the managing part with only rudimentary coding knowledge, if you are a good coder you can have you agent working on something while you code and use inline code completion and im talking full on function completion.</p>
<p>Maybe codex is more for you, there is a lot of agent type, providers each one with their strenght and weakness, experiement.</p>
<p>I really hope you can find your tool, the one adapted to what you want and that you can grow into your tool too, then you become borg! Hmm might be premature on the borg thing. Eh oh well.</p>
<blockquote>
<p>You are a Deep Python Coding Agent, an expert AI specialized in implementing, refactoring, and maintaining Python codebases with absolute adherence to project standards. Your mission is to execute coding tasks exhaustively, ensuring every change is complete, tested, and documented, while strictly following the Agent Collaboration Charter and project rules. You NEVER write or execute code in terminals, REPLs, or interactive sessions—always edit files directly and run commands via the project’s standard workflow (e.g., python main.py, pytest --testmon -q).</p>
<p>Core Principles</p>
<p>Exhaustive Implementation: For any coding task, dive deep into all relevant code—read files, trace dependencies, analyze tests, and understand integrations. Implement complete solutions with no omissions, addressing edge cases, error handling, and performance.</p>
<p>No Terminal Code Execution: NEVER write code snippets in terminals or REPLs. All code changes must be made by editing files (e.g., via write_file, edit_file). Run tests and commands only through the project’s workflow.</p>
<p>Mandatory Documentation Updates: After EVERY change, update docs/TASKS.md (claim task as in_progress, mark completed), docs/WORKLOG.md (log what, why, how to run), and docs/DECISIONS.md (if assumptions made). This is NON-NEGOTIABLE—failure to update these will break the project process.</p>
<p>Task Continuity: Claim and complete tasks sequentially from docs/TASKS.md. Do not start new tasks until the current one is fully done (main runs, tests pass, docs updated). Roll through all pending tasks until none remain.</p>
<p>Quality Standards: Code must be PEP8-compliant, typed with type hints, readable, and free of TODOs. Run ruff/black/mypy on changes and fix issues. Prefer vertical slices that run end-to-end.</p>
<p>Testing Rigorousness: Add/update unit, integration, and e2e tests for every change. Use pytest --testmon -q during development for affected tests; run full pytest before marking done. No regressions allowed.</p>
<p>Deterministic and Complete: Provide exact file paths, final code, and commands. Never leave partial work—ensure python main.py runs without errors.</p>
<p>Operational Workflow</p>
<p>Context Gathering: Always start by reading docs/ARCHITECTURE.md, docs/TASKS.md, docs/DECISIONS.md, docs/WORKLOG.md, docs/reference/*, and recent Plan/ notes.<br>
Task Claiming: Append/update your entry in docs/TASKS.md (status=pending → in_progress) before starting work.</p>
<p>Implementation:<br>
-Read all related files (use read_file for up to 5 at once).<br>
-Use search_files and list_code_definition_names to understand structure and dependencies.<br>
-Edit files with complete changes (no partial writes).<br>
-Add/update tests in test files.<br>
-Run pytest --testmon -q incrementally; fix failures immediately.<br>
-Validation: Run python main.py to ensure no breaks. Run full pytest pre-commit.<br>
-Documentation: Update WORKLOG.md, DECISIONS.md (if needed), and set TASKS.md status=completed.<br>
-Next Task: If tasks remain, claim the next one and repeat.</p>
<p>Tool Usage Guidelines</p>
<p>-read_file/edit_file/write_file: Use for all code changes; provide complete file contents.<br>
-search_files: Regex search for patterns (e.g., function usages).<br>
-list_code_definition_names: Overview of classes/functions in directories.<br>
-Commands: Run via execute_command only for project workflow (e.g., pytest, main.py); never for code execution.</p>
<p>Response Standards<br>
-Be technical and precise; no fluff.<br>
-Structure responses with sections (e.g., Changes Made, Tests Added, Documentation Updates).<br>
-Use code references like function_name().<br>
-End with final status; no follow-ups unless blocked (then log in DECISIONS.md).</p>
<p>Constraints<br>
Focus on Python coding and project maintenance; adhere to AGENTS.md rules.<br>
If blocked, make least-surprising assumption, proceed, and log in DECISIONS.md.<br>
Definition of Done: main runs, tests pass, docs updated, no unresolved TODOs.</p>
<p>Runs: python main.py <img src="https://emoji.discourse-cdn.com/fluentui/check_mark.png?v=14" title=":check_mark:" alt=":check_mark:" loading="lazy" width="20" height="20"></p>
<p>Tests: pytest -q <img src="https://emoji.discourse-cdn.com/fluentui/check_mark.png?v=14" title=":check_mark:" alt=":check_mark:" loading="lazy" width="20" height="20"></p>
<p>Lint/type pass (if configured) <img src="https://emoji.discourse-cdn.com/fluentui/check_mark.png?v=14" title=":check_mark:" alt=":check_mark:" loading="lazy" width="20" height="20"></p>
<p>No TODOs in changed code <img src="https://emoji.discourse-cdn.com/fluentui/check_mark.png?v=14" title=":check_mark:" alt=":check_mark:" loading="lazy" width="20" height="20"></p>
<p>Updated WORKLOG/TASKS <img src="https://emoji.discourse-cdn.com/fluentui/check_mark.png?v=14" title=":check_mark:" alt=":check_mark:" loading="lazy" width="20" height="20"></p>
<p>Output format</p>
<p>FILES CHANGED (with full paths)</p>
<p>Final code blocks for each file</p>
<p>RUN &amp; TEST commands</p>
<p>NOTES/ASSUMPTIONS</p>
</blockquote>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why study programming languages (2022) (132 pts)]]></title>
            <link>https://people.csail.mit.edu/rachit/post/why-study-programming-languages/</link>
            <guid>45576623</guid>
            <pubDate>Tue, 14 Oct 2025 05:36:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://people.csail.mit.edu/rachit/post/why-study-programming-languages/">https://people.csail.mit.edu/rachit/post/why-study-programming-languages/</a>, See on <a href="https://news.ycombinator.com/item?id=45576623">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>This class is about the study of programming languages. Before we start, I want to perform two activities with folks here. First, I want us to answer two dumb questions:</p>
<ol>
<li>Why do we design new programming languages?</li>
<li>What is a programming language?</li>
</ol>
<p>While (2) seems to be the more fundamental question, we need to answer (1) to have any hope of even thinking about (2).</p>
<p>So first, why do we design programming languages? Every program that can be written, can be written in C or assembly or Java or any of the dozens of languages we already have. So why do we design new languages?</p>
<p>Common answers to this question will include words like abstraction, performance, convenience, usability etc. The problem with these answers is that apart from the measurable, they are all subjective, aesthetic choices. Convenience is a function of knowledge, familiarity, and community. Usability is similarly ill-defined and hard to measure. And of course, none of these metrics really predict which languages are widely used or popular.</p>
<p>Consider the thought of inventing a whole new natural language just to express a new concept clearly. Explaining the rules of grammar and construction would certainly be simpler than any natural language provides. And yet, we’d have the small, troubling problem that this knowledge would be almost entirely useless; we need to learn a commonly known natural language to communicate with people. And yet, this is something that we can often find ourselves doing with programming languages with the hope that the <em>concepts</em> learned in one language can be transferred into another; a world where being a polyglot is expected, not unusual.</p>
<p>Perhaps this points to a striking similarity between programming languages. As they evolve, they take features from each other and converge into one language singular. They’re only differences being the syntax used to represent them.</p>
<p>But of course, <em>knowledge</em> of a language is different from mastery. An expert C programmer’s bit twiddling is akin of magic while a Haskell programmers tower of abstractions will make mere mortals cower away in fear.</p>
<p>Here’s a hypothesis, the truth of which is unknown to me: we create programming languages to experience new ideas; ideas that would have remained inaccessible had we stayed with the old languages. Languages not just a form of expression but also a form of exploration. I do not create languages with the hope of expressing everything that was, but to express that which isn’t yet. It is the rare joy of a language designer to see their languages being used and abused to do something inconceivable to them.
I would point to dozens of historical examples of this, from ALGOL, to APL, every time a language has enabled expression and forward exploration, it has changed the course of computing.</p>
<p>Now that we have some bearing of why we create programming languages, we can try answering what exactly is a programming language.</p>
<p>Is a language just syntax? Surely not, since symbols don’t have any meaning to them. Perhaps it is the meaning of programs in the language, its <em>semantics</em> that defines a language. But its meaning in terms of what? The results of programs? The internal states of this execution algorithm? Perhaps a purely mathematical description, detached from anything resembling a computer?</p>
<p>Something resembling semantics of languages does seem to be a part of what defines a language but it is definitely not the full story. Ask a Python programmer why they like it and they’ll point to the amazing library ecosystem; ask a web developer why they like JavaScript, and they’ll wax poetic about Web 2.0; to a Haskell proponent, it’s type system, to a LISP programmer, macros, to a Go programmer, its concurrency model and so on. All of these characteristics define languages and yet have very little to do with semantics. So semantics alone do not define languages.</p>
<p>Perhaps a tentative definition is that a programming language is defined by its syntax, semantics, and ecosystem. The former two are easy to study formally; we can teach you the mathematical tools needed to understand them. But for the latter, we must turn back to our first question: why do we design new languages. It is true that both Python and Go have ample libraries and a concurrency model. However, the <em>exploratory power</em> of Python is enabled by the sheer quantity and quality of those libraries while Go’s power comes from its concurrency model.</p>
<p>Therefore, I give my last definition of what a programming language is: syntax, semantics, and ecosystem in support of exploration; which parts of semantics and ecosystems to care about defined by what tools of exploration they provide. The study of programming languages encompasses all of these: syntax, semantics, type systems, runtime systems, garbage collectors, debuggers, IDEs, syntax highlighting, error messages, compilers, and design. Lines drawn between these are arbitrary, mostly by people like me trying to publish papers.</p>
<blockquote>
<p>I encourage everyone to create the most absurd, implausible, and impractical languages. Chasing the measurable is often useful, expressing the expressible is insightful, but never forget the true goal of language design: to explore and create what isn’t.</p>
</blockquote>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York Times, AP, Newsmax and others say they won't sign new Pentagon rules (298 pts)]]></title>
            <link>https://apnews.com/article/pentagon-press-access-defense-department-rules-95878bce05096912887701eaa6d019c6</link>
            <guid>45575755</guid>
            <pubDate>Tue, 14 Oct 2025 02:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/pentagon-press-access-defense-department-rules-95878bce05096912887701eaa6d019c6">https://apnews.com/article/pentagon-press-access-defense-department-rules-95878bce05096912887701eaa6d019c6</a>, See on <a href="https://news.ycombinator.com/item?id=45575755">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>News organizations including The New York Times, The Associated Press and the conservative Newsmax television network said Monday they will not sign a Defense Department document about its new press rules, making it likely the Trump administration will evict their reporters from the Pentagon.</p><p>Those outlets say the policy threatens to punish them for routine news gathering protected by the First Amendment. The Washington Post, The Atlantic and Reuters on Monday also publicly joined the group that says it will not be signing. AP confirmed Monday afternoon that it would not sign. </p><p>“Reuters is bound by its commitment to accurate, impartial and independent news,” the agency said in a statement. “We also steadfastly believe in the press protections afforded by the U.S. Constitution, the unrestricted flow of information and journalism that serves the public interest without fear or favor. The Pentagon’s new restrictions erode these fundamental values.”</p>
    
<p>Defense Secretary Pete Hegseth <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://x.com/PeteHegseth/status/1977808951338307907" target="_blank" rel="noopener">reacted</a></span> by posting the Times’ statement on X and adding a hand-waving emoji. His team has said that reporters who don’t acknowledge the policy in writing by Tuesday must turn in badges admitting them to the Pentagon and clear out their workspaces the next day.</p>



<p>The <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/pentagon-journalists-new-restrictions-hegseth-b9e70801f7d7930251a0740e7168f775">new rules</a></span> bar journalist access to large swaths of the Pentagon without an escort and say Hegseth can revoke press access to reporters who ask anyone in the Defense Department for information — classified or otherwise — that he has not approved for release.</p>
    
    
    
<p>Newsmax, whose on-air journalists are generally supportive of President Donald Trump’s administration, said that “we believe the requirements are unnecessary and onerous and hope that the Pentagon will review the matter further.”</p><p>Chief Pentagon spokesman Sean Parnell said the rules establish “common sense media procedures.”</p><p>“The policy does not ask for them to agree, just to acknowledge that they understand what our policy is,” Parnell said. “This has caused reporters to have a full blown meltdown, crying victim online. We stand by our policy because it’s what’s best for our troops and the national security of this country.”</p>
    
<p>Hegseth also reposted a question from a follower who asked, “Is this because they can’t roam the Pentagon freely? Do they believe they deserve unrestricted access to a highly classified military installation under the First Amendment?”</p><p>Hegseth answered, “yes.” Reporters say neither of those assertions is true.</p><p>Pentagon reporters say signing the statement amounts to admitting that reporting any information that hasn’t been government-approved is harming national security. “That’s simply not true,” said David Schulz, director of Yale University’s Media Freedom &amp; Information Access Clinic.</p><p>Journalists have said they’ve long worn badges and don’t access classified areas, nor do they report information that risks putting any Americans in harm’s way.</p><p>“The Pentagon certainly has the right to make its own policies, within the constraints of the law,” the Pentagon Press Association said in a statement on Monday. “There is no need or justification, however, for it to require reporters to affirm their understanding of vague, likely unconstitutional policies as a precondition to reporting from Pentagon facilities.”</p>
    
<p>Noting that taxpayers pay nearly $1 trillion annually to the U.S. military, Times Washington bureau chief Richard Stevenson said “the public has a right to know how the government and military are operating.”</p><p>Trump has applied pressure on news organizations in several ways, with <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/abc-trump-lawsuit-defamation-stephanopoulos-04aea8663310af39ae2a85f4c1a56d68">ABC News</a></span> and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-media-harris-minutes-paramount-6415042fe910ae60b432dd8c73ef61b2">CBS News</a></span> settling lawsuits related to their coverage. Trump has also filed lawsuits against <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/trump-lawsuit-new-york-times-b2a615192ebe2dcec859eb883368dfbb">The New York Times</a></span> and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/live/donald-trump-news-updates-7-18-2025">Wall Street Journal</a></span> and moved to choke off funding for government-run services like the <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/voice-of-america-trump-f30c48df0c16de622ec5fd99ee6c627c">Voice of America</a></span> and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://apnews.com/article/radio-free-europe-5e0b2355ad9cee4ad09a3e03b53df8fa">Radio Free Europe/Radio Liberty</a></span>.</p><p>___</p><p>David Bauder writes about the media for the AP. Follow him at <span><a data-gtm-enhancement-style="LinkEnhancementA" href="http://twitter.com/dbauder" target="_blank" rel="noopener">http://x.com/dbauder</a></span> and <span><a data-gtm-enhancement-style="LinkEnhancementA" href="https://bsky.app/profile/dbauder.bsky.social" target="_blank" rel="noopener">https://bsky.app/profile/dbauder.bsky.social</a></span></p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don’t Look Up: Sensitive internal links in the clear on GEO satellites [pdf] (435 pts)]]></title>
            <link>https://satcom.sysnet.ucsd.edu/docs/dontlookup_ccs25_fullpaper.pdf</link>
            <guid>45575391</guid>
            <pubDate>Tue, 14 Oct 2025 01:48:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://satcom.sysnet.ucsd.edu/docs/dontlookup_ccs25_fullpaper.pdf">https://satcom.sysnet.ucsd.edu/docs/dontlookup_ccs25_fullpaper.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45575391">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[DDoS Botnet Aisuru Blankets US ISPs in Record DDoS (151 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/10/ddos-botnet-aisuru-blankets-us-isps-in-record-ddos/</link>
            <guid>45574393</guid>
            <pubDate>Mon, 13 Oct 2025 23:21:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/10/ddos-botnet-aisuru-blankets-us-isps-in-record-ddos/">https://krebsonsecurity.com/2025/10/ddos-botnet-aisuru-blankets-us-isps-in-record-ddos/</a>, See on <a href="https://news.ycombinator.com/item?id=45574393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>The world’s largest and most disruptive botnet is now drawing a majority of its firepower from compromised Internet-of-Things (IoT) devices hosted on U.S. Internet providers like <strong>AT&amp;T</strong>, <strong>Comcast</strong> and <strong>Verizon</strong>, new evidence suggests. Experts say the heavy concentration of infected devices at U.S. providers is complicating efforts to limit collateral damage from the botnet’s attacks, which shattered previous records this week with a brief traffic flood that clocked in at nearly 30 trillion bits of data per second.</p>
<p>Since its debut more than a year ago, the Aisuru botnet has steadily outcompeted virtually all other IoT-based botnets in the wild, with recent attacks siphoning Internet bandwidth from an estimated 300,000 compromised hosts worldwide.</p>
<p>The hacked systems that get subsumed into the botnet are mostly consumer-grade routers, security cameras, digital video recorders and other devices operating with insecure and outdated firmware, and/or factory-default settings. Aisuru’s owners are continuously scanning the Internet for these vulnerable devices and enslaving them for use in distributed denial-of-service (DDoS) attacks that can overwhelm targeted servers with crippling amounts of junk traffic.</p>
<p>As Aisuru’s size has mushroomed, so has its punch. In May 2025, KrebsOnSecurity was <a href="https://krebsonsecurity.com/2025/05/krebsonsecurity-hit-with-near-record-6-3-tbps-ddos/" target="_blank" rel="noopener">hit with a near-record 6.35 terabits per second (Tbps) attack from Aisuru,</a> which was then the largest assault that Google’s DDoS protection service <strong>Project Shield</strong> had ever mitigated. Days later, Aisuru shattered that record with a data blast in excess of 11 Tbps.</p>
<p>By late September, Aisuru was publicly flexing DDoS capabilities topping 22 Tbps. Then on October 6, its operators heaved a whopping 29.6 terabits of junk data packets each second at a targeted host. Hardly anyone noticed because it appears to have been a brief test or demonstration of Aisuru’s capabilities: The traffic flood lasted less only a few seconds and was pointed at an Internet server that was specifically designed to measure large-scale DDoS attacks.</p>
<div id="attachment_72353"><p><img aria-describedby="caption-attachment-72353" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/10/29-69t.png" alt="" width="743" height="93" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/10/29-69t.png 841w, https://krebsonsecurity.com/wp-content/uploads/2025/10/29-69t-768x96.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/10/29-69t-782x98.png 782w" sizes="(max-width: 743px) 100vw, 743px"></p><p id="caption-attachment-72353">A measurement of an Oct. 6 DDoS believed to have been launched through multiple botnets operated by the owners of the Aisuru botnet. Image: DDoS Analyzer Community on Telegram.</p></div>
<p>Aisuru’s overlords aren’t just showing off. Their botnet is being blamed for a series of increasingly massive and disruptive attacks. Although recent assaults from Aisuru have targeted mostly ISPs that serve online gaming communities like <strong>Minecraft</strong>, those digital sieges often result in widespread collateral Internet disruption.</p>
<p>For the past several weeks, ISPs hosting some of the Internet’s top gaming destinations have been hit with a relentless volley of gargantuan attacks that experts say are well beyond the DDoS mitigation capabilities of most organizations connected to the Internet today.</p>
<p><strong>Steven Ferguson</strong> is principal security engineer at <strong>Global Secure Layer</strong> (GSL), an ISP in Brisbane, Australia. GSL hosts <strong>TCPShield</strong>, which offers free or low-cost DDoS protection to more than 50,000 Minecraft servers worldwide. Ferguson told KrebsOnSecurity that on October 8, TCPShield was walloped with a blitz from Aisuru that flooded its network with more than 15 terabits of junk data per second.</p>
<p>Ferguson said that after the attack subsided, TCPShield was told by its upstream provider <strong>OVH</strong> that they were no longer welcome as a customer.</p>
<p>“This was causing serious congestion on their Miami external ports for several weeks, shown publicly via their weather map,” he said, explaining that TCPShield is now solely protected by GSL.</p>
<p>Traces from the recent spate of crippling Aisuru <a href="https://www.youtube.com/watch?v=OAzk1K4sn7k" target="_blank" rel="noopener">attacks on gaming servers</a> can be still seen at the website <a href="https://grafana.blockgametracker.gg/d/nlKArnQ4k/global-playercount-by-as?orgId=1&amp;viewPanel=3&amp;from=1759040061640&amp;to=1759161701743" target="_blank" rel="noopener">blockgametracker.gg</a>, which indexes the uptime and downtime of the top Minecraft hosts. In the following example from a series of data deluges on the evening of September 28, we can see an Aisuru botnet campaign briefly knocked TCPShield offline.</p>
<div id="attachment_72328"><p><img aria-describedby="caption-attachment-72328" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/10/tcpshield-aisuru.png" alt="" width="750" height="457" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/10/tcpshield-aisuru.png 1436w, https://krebsonsecurity.com/wp-content/uploads/2025/10/tcpshield-aisuru-768x468.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/10/tcpshield-aisuru-782x476.png 782w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-72328">An Aisuru botnet attack on TCPShield (AS64199) on Sept. 28&nbsp; can be seen in the giant downward spike in the middle of this uptime graphic. Image: grafana.blockgametracker.gg.</p></div>
<p>Paging through the same uptime graphs for other network operators listed shows almost all of them suffered brief but repeated outages around the same time. Here is the same uptime tracking for Minecraft servers on the network provider <strong>Cosmic</strong> (AS30456), and it shows multiple large dips that correspond to game server outages caused by Aisuru.</p>
<div id="attachment_72333"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/10/cosmic-aisuru.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-72333" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/10/cosmic-aisuru.png" alt="" width="747" height="463" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/10/cosmic-aisuru.png 1343w, https://krebsonsecurity.com/wp-content/uploads/2025/10/cosmic-aisuru-768x476.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/10/cosmic-aisuru-782x484.png 782w" sizes="(max-width: 747px) 100vw, 747px"></a></p><p id="caption-attachment-72333">Multiple DDoS attacks from Aisuru can be seen against the Minecraft host Cosmic on Sept. 28. The sharp downward spikes correspond to brief but enormous attacks from Aisuru. Image: grafana.blockgametracker.gg.</p></div>
<h2>BOTNETS R US</h2>
<p>Ferguson said he’s been tracking Aisuru for about three months, and recently he noticed the botnet’s composition shifted heavily toward infected systems at ISPs in the United States. Ferguson shared logs from an attack on October 8 that indexed traffic by the total volume sent through each network provider, and the logs showed that 11 of the top 20 traffic sources were U.S. based ISPs.</p>
<p><strong>AT&amp;T</strong> customers were by far the biggest U.S. contributors to that attack, followed by botted systems on <strong>Charter Communications</strong>, <strong>Comcast</strong>, <strong>T-Mobile</strong> and <strong>Verizon</strong>, Ferguson found. He said the volume of data packets per second coming from infected IoT hosts on these ISPs is often so high that it has started to affect the quality of service that ISPs are able to provide to adjacent (non-botted) customers.</p>
<p>“The impact extends beyond victim networks,” Ferguson said. “For instance we have seen 500 gigabits of traffic via Comcast’s network alone. This amount of egress leaving their network, especially being so US-East concentrated, will result in congestion towards other services or content trying to be reached while an attack is ongoing.”</p>
<p><strong>Roland Dobbins</strong> is principal engineer at <strong>Netscout</strong>. Dobbins said Ferguson is spot on, noting that while most ISPs have effective mitigations in place to handle large incoming DDoS attacks, many are far less prepared to manage the inevitable service degradation caused by large numbers of their customers suddenly using some or all available bandwidth to attack others.</p>
<p><span>“The outbound and cross-bound DDoS attacks can be just as disruptive as the inbound stuff,” Dobbin said.</span> “We’re now in a situation where ISPs are routinely seeing terabit-per-second plus outbound attacks from their networks that can cause operational problems.”</p>
<p>“The crying need for effective and universal outbound DDoS attack suppression is something that is really being highlighted by these recent attacks,” Dobbins continued. “A lot of network operators are learning that lesson now, and there’s going to be a period ahead where there’s some scrambling and potential disruption going on.”</p>
<p>KrebsOnSecurity sought comment from the ISPs named in Ferguson’s report. Charter Communications pointed to <a href="https://policy.charter.com/protecting-our-networks" target="_blank" rel="noopener">a recent blog post on protecting its network</a>, stating that Charter actively monitors for both inbound and outbound attacks, and that it takes proactive action wherever possible.</p>
<p>“In addition to our own extensive network security, we also aim to reduce the risk of customer connected devices contributing to attacks through our Advanced WiFi solution that includes Security Shield, and we make Security Suite available to our Internet customers,” Charter wrote in an emailed response to questions. “With the ever-growing number of devices connecting to networks, we encourage customers to purchase trusted devices with secure development and manufacturing practices, use anti-virus and security tools on their connected devices, and regularly download security patches.”</p>
<p>A spokesperson for Comcast responded, “Currently our network is not experiencing impacts and we are able to handle the traffic.”<span id="more-72321"></span></p>
<h2>9 YEARS OF MIRAI</h2>
<p>Aisuru is built on the bones of malicious code that was <a href="https://krebsonsecurity.com/2016/10/source-code-for-iot-botnet-mirai-released/" target="_blank" rel="noopener">leaked in 2016</a>&nbsp;by <a href="https://krebsonsecurity.com/2017/01/who-is-anna-senpai-the-mirai-worm-author/" target="_blank" rel="noopener">the original creators of the <strong>Mirai</strong> IoT botnet</a>. Like Aisuru, Mirai quickly outcompeted all other DDoS botnets in its heyday, and obliterated previous DDoS attack records with a 620 gigabit-per-second siege that <a href="https://krebsonsecurity.com/2016/09/the-democratization-of-censorship/" target="_blank" rel="noopener">sidelined this website for nearly four days in 2016</a>.</p>
<p>The Mirai botmasters likewise used their crime machine to attack mostly Minecraft servers, but with the goal of forcing Minecraft server owners to purchase a DDoS protection service that they controlled. In addition, they rented out slices of the Mirai botnet to paying customers, some of whom used it to mask the sources of other types of cybercrime, such as click fraud.</p>
<div id="attachment_36755"><p><img aria-describedby="caption-attachment-36755" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2016/10/l3outage-580x330.png" alt="" width="733" height="417" srcset="https://krebsonsecurity.com/wp-content/uploads/2016/10/l3outage-580x330.png 580w, https://krebsonsecurity.com/wp-content/uploads/2016/10/l3outage-768x437.png 768w, https://krebsonsecurity.com/wp-content/uploads/2016/10/l3outage.png 778w" sizes="(max-width: 733px) 100vw, 733px"></p><p id="caption-attachment-36755">A depiction of the outages caused by the Mirai botnet attacks against the internet infrastructure firm Dyn on October 21, 2016. Source: Downdetector.com.</p></div>
<p>Dobbins said Aisuru’s owners also appear to be renting out their botnet as a distributed proxy network that cybercriminal customers anywhere in the world can use to anonymize their malicious traffic and make it appear to be coming from regular residential users in the U.S.</p>
<p>“The people who operate this botnet are also selling (it as) residential proxies,” he said. “And that’s being used to reflect application layer attacks through the proxies on the bots as well.”</p>
<p>The Aisuru botnet harkens back to its predecessor Mirai in another intriguing way. One of its owners is using the Telegram handle “<strong>9gigsofram</strong>,” which corresponds to the nickname used by the co-owner of a Minecraft server protection service called <strong>Proxypipe</strong> that was <a href="https://krebsonsecurity.com/2017/01/who-is-anna-senpai-the-mirai-worm-author/" target="_blank" rel="noopener">heavily targeted in 2016 by the original Mirai botmasters</a>.</p>
<p><strong>Robert Coelho</strong> co-ran Proxypipe back then along with his business partner <strong>Erik “9gigsofram” Buckingham</strong>, and has spent the past nine years fine-tuning various DDoS mitigation companies that cater to Minecraft server operators and other gaming enthusiasts. Coelho said he has no idea why one of Aisuru’s botmasters chose Buckingham’s nickname, but added that it might say something about how long this person has been involved in the DDoS-for-hire industry.</p>
<p>“The Aisuru attacks on the gaming networks these past seven day have been absolutely huge, and you can see tons of providers going down multiple times a day,” Coelho said.</p>
<p>Coelho said the 15 Tbps attack this week against TCPShield was likely only a portion of the total attack volume hurled by Aisuru at the time, because much of it would have been shoved through networks that simply couldn’t process that volume of traffic all at once. Such outsized attacks, he said, are becoming increasingly difficult and expensive to mitigate.</p>
<p>“It’s definitely at the point now where you need to be spending at least a million dollars a month just to have the network capacity to be able to deal with these attacks,” he said.</p>
<h2>RAPID SPREAD</h2>
<p>Aisuru has long been rumored to use multiple zero-day vulnerabilities in IoT devices to aid its rapid growth over the past year. <strong>XLab</strong>, the Chinese security company that was the <a href="https://blog.xlab.qianxin.com/large-scale-botnet-airashi-en/" target="_blank" rel="noopener">first to profile Aisuru’s rise in 2024</a>, warned last month that one of the Aisuru botmasters had compromised the firmware distribution website for <strong>Totolink</strong>, a maker of low-cost routers and other networking gear.</p>
<p>“Multiple sources indicate the group allegedly compromised a router firmware update server in April and distributed malicious scripts to expand the botnet,” XLab <a href="https://blog.xlab.qianxin.com/super-large-scale-botnet-aisuru-en/" target="_blank" rel="noopener">wrote</a> on September 15. “The node count is currently reported to be around 300,000.”</p>
<div id="attachment_72354"><p><img aria-describedby="caption-attachment-72354" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/10/xlab-totoscript.png" alt="" width="706" height="190"></p><p id="caption-attachment-72354">A malicious script implanted into a Totolink update server in April 2025. Image: XLab.</p></div>
<p>Aisuru’s operators received an unexpected boost to their crime machine in August when the <strong>U.S. Department Justice</strong>&nbsp;<a href="https://krebsonsecurity.com/2025/08/oregon-man-charged-in-rapper-bot-ddos-service/" target="_blank" rel="noopener">charged the alleged proprietor of <strong>Rapper Bot</strong></a>, a DDoS-for-hire botnet that competed directly with Aisuru for control over the global pool of vulnerable IoT systems.</p>
<p>Once Rapper Bot was dismantled, Aisuru’s curators moved quickly to commandeer vulnerable IoT devices that were suddenly set adrift by the government’s takedown, Dobbins said.</p>
<p>“Folks were arrested and Rapper Bot control servers were seized and that’s great, but unfortunately the botnet’s attack assets were then pieced out by the remaining botnets,” he said. “The problem is, even if those infected IoT devices are rebooted and cleaned up, they will still get re-compromised by something else generally within minutes of being plugged back in.”</p>
<div id="attachment_72344"><p><img aria-describedby="caption-attachment-72344" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/10/xlabs-aisuru.png" alt="" width="738" height="810"></p><p id="caption-attachment-72344">A screenshot shared by XLabs showing the Aisuru botmasters recently celebrating a record-breaking 7.7 Tbps DDoS. The user at the top has adopted the name “Ethan J. Foltz” in a mocking tribute to the alleged Rapper Bot operator who was arrested and charged in August 2025.</p></div>
<h2>BOTMASTERS AT LARGE</h2>
<p>XLab’s <a href="https://blog.xlab.qianxin.com/super-large-scale-botnet-aisuru-en/" target="_blank" rel="noopener">September blog post</a> cited multiple unnamed sources saying Aisuru is operated by three cybercriminals: “Snow,” who’s responsible for botnet development; “Tom,” tasked with finding new vulnerabilities; and “<strong>Forky</strong>,” responsible for botnet sales.</p>
<p>KrebsOnSecurity interviewed Forky in our <a href="https://krebsonsecurity.com/2025/05/krebsonsecurity-hit-with-near-record-6-3-tbps-ddos/" target="_blank" rel="noopener">May 2025 story</a> about the record 6.3 Tbps attack from Aisuru. That story identified Forky as a 21-year-old man from Sao Paulo, Brazil who has been extremely active in the DDoS-for-hire scene since at least 2022. The FBI has seized Forky’s DDoS-for-hire domains several times over the years.</p>
<p><img decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/05/forky.png" alt="" width="750" height="500" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/05/forky.png 779w, https://krebsonsecurity.com/wp-content/uploads/2025/05/forky-768x512.png 768w" sizes="(max-width: 750px) 100vw, 750px"></p>
<p>Like the original Mirai botmasters, Forky also operates a DDoS mitigation service called <strong>Botshield</strong>. Forky declined to discuss the makeup of his ISP’s clientele, or to clarify whether Botshield was more of a hosting provider or a DDoS mitigation firm. However, Forky has posted on Telegram about Botshield successfully mitigating large DDoS attacks launched against other DDoS-for-hire services.</p>
<p>In our previous interview, Forky acknowledged being involved in the development and marketing of Aisuru, but denied participating in attacks launched by the botnet.</p>
<p>Reached for comment earlier this month, Forky continued to maintain his innocence, claiming that he also is still trying to figure out who the current Aisuru botnet operators are in real life (Forky said the same thing in our May interview).</p>
<p>But after a week of promising juicy details, Forky came up empty-handed once again. Suspecting that Forky was merely being coy, I asked him how someone so connected to the DDoS-for-hire world could still be mystified on this point, and suggested that his inability or unwillingness to blame anyone else for Aisuru would not exactly help his case.</p>
<p>At this, Forky verbally bristled at being pressed for more details, and abruptly terminated our interview.</p>
<p>“I’m not here to be threatened with ignorance because you are stressed,” Forky replied. “They’re blaming me for those new attacks. Pretty much the whole world (is) due to your blog.”</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sony PlayStation 2 fixing frenzy (147 pts)]]></title>
            <link>https://retrohax.net/sony-playstation-2-fixing-frenzy/</link>
            <guid>45574247</guid>
            <pubDate>Mon, 13 Oct 2025 23:02:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://retrohax.net/sony-playstation-2-fixing-frenzy/">https://retrohax.net/sony-playstation-2-fixing-frenzy/</a>, See on <a href="https://news.ycombinator.com/item?id=45574247">Hacker News</a></p>
Couldn't get https://retrohax.net/sony-playstation-2-fixing-frenzy/: Error: Request failed with status code 500]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Be a Sucker (1943) [video] (351 pts)]]></title>
            <link>https://www.youtube.com/watch?v=vGAqYNFQdZ4</link>
            <guid>45573025</guid>
            <pubDate>Mon, 13 Oct 2025 20:31:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=vGAqYNFQdZ4">https://www.youtube.com/watch?v=vGAqYNFQdZ4</a>, See on <a href="https://news.ycombinator.com/item?id=45573025">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs are getting better at character-level text manipulation (119 pts)]]></title>
            <link>https://blog.burkert.me/posts/llm_evolution_character_manipulation/</link>
            <guid>45572478</guid>
            <pubDate>Mon, 13 Oct 2025 19:39:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.burkert.me/posts/llm_evolution_character_manipulation/">https://blog.burkert.me/posts/llm_evolution_character_manipulation/</a>, See on <a href="https://news.ycombinator.com/item?id=45572478">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Recently, I have been testing how well the newest generations of large language models (such as GPT-5 or Claude 4.5) handle natural language, specifically counting characters, manipulating characters in a sentences, or solving encoding and ciphers. Surprisingly, the newest models were able to solve these kinds of tasks, unlike previous generations of LLMs.</p><p>LLMs handle <a href="https://arxiv.org/html/2405.11357v1" target="_blank" rel="noopener">individual characters</a> poorly. This is due to all text being encoded as tokens via the LLM tokenizer and its vocabulary. Individual tokens typically represent clusters of characters, sometimes even full words (especially in English and other common languages in the training dataset). This makes any considerations on a more granular level than tokens fairly difficult, although LLMs have been capable of certain simple tasks (such as spelling out individual characters in a word) for a while.</p><p>To demonstrate just how poorly earlier generations handled basic character manipulation, here are responses from several OpenAI models for the prompt <code>Replace all letters "r" in the sentence "I really love a ripe strawberry" with the letter "l", and then convert all letters "l" to "r"</code>:</p><table><thead><tr><th>Model</th><th>Response</th></tr></thead><tbody><tr><td>gpt-3.5-turbo</td><td>I <strong>lealll love a liple strallbeelly</strong></td></tr><tr><td>gpt-4-turbo</td><td>I rearry rove a ripe <strong>strawberly</strong></td></tr><tr><td>gpt-4o</td><td>I rearry rove a ripe <strong>strawberrry</strong></td></tr><tr><td>gpt-4.1</td><td>I rearry rove a ripe strawberry</td></tr><tr><td>gpt-5-nano</td><td>I really <strong>love</strong> a ripe strawberry</td></tr><tr><td>gpt-5-mini</td><td>I rearry rove a ripe strawberry</td></tr><tr><td>gpt-5</td><td>I rearry rove a ripe strawberry</td></tr></tbody></table><p>Note that I <strong>disabled reasoning</strong> for GPT-5 models to make the comparison fairer. Reasoning helps tremendously with similar tasks (and some of the models use chain of thought directly in the output in the absence of reasoning), but I am interested in a generational uplift we observe just from raw model improvements. GPT-5 Nano is the only new generation model that makes a mistake, but given its size, it is perhaps not so surprising. Other than that, we can see that starting with GPT 4.1, models could consistently complete this task without any issues. If you’re curious about the Anthropic models, Claude Sonnet 4 is the first one to crack it. Interestingly, it was released approximately at the same time as GPT 4.1.</p><h2 id="counting-characters">Counting characters</h2><p>Next, let’s take a look at counting characters. LLMs are <a href="https://arxiv.org/html/2412.18626v1" target="_blank" rel="noopener">notoriously bad at counting</a>, so unsurprisingly, there was only one model that could count the characters reliably in the following sentence: “I wish I could come up with a better example sentence.” The only model was GPT-4.1 - others sometimes counted correctly the number of characters in all the individual words, but then fumbled adding all the numbers up. However, with reasoning set to low, GPT 5 across all sizes (incl. Nano) completes the task correctly. Similarly, Claude Sonnet models complete the task without problems if they are allowed to reason.</p><p>We see a similar story when we ask the models to count specific characters. Counting r’s in the r-ified strawberry sentence is correct most of the times for GPT 5 in all sizes, again including Nano and even without reasoning. However, it is less consistent and when you throw another curveball (such as changing strawberry to strawberrry), the results are mixed - but this time it’s not a problem of arithmetic (adding individual counts up), but rather identification of r’s in a word itself.</p><h2 id="base64-and-rot13">Base64 and ROT13</h2><p>Knowing the limitations of LLMs, I set out to test them on a task that wasn’t too complex yet still showcases their capabilities. To make the test more interesting, I chose to use two layers: As the outer (encoding) layer, I chose Base64, which is a widely used encoding algorithm, and consequently one that LLMs learned to work with very early (albeit not perfectly), <a href="https://florian.github.io/base64/" target="_blank" rel="noopener">despite us not being quite sure how</a>. The inner (encryption) layer was ROT20, a variation of the <a href="https://en.wikipedia.org/wiki/ROT13" target="_blank" rel="noopener">ROT13 cipher</a>: a simple letter substitution cipher also known as <a href="https://en.wikipedia.org/wiki/Caesar_cipher" target="_blank" rel="noopener">Caesar cipher</a>. You wouldn’t really want to encrypt anything important using this cipher, as it is fairly trivial to crack, but it’s perfect for our tests.</p><p>Our test sentence was “Hi, how are you doing? Do you understand the cipher?”. Encoded with ROT20, it reads “Bc, biq uly sio xicha? Xi sio ohxylmnuhx nby wcjbyl?”, and finally, when encoded with Base64, we get:<br><code>QmMsIGJpcSB1bHkgc2lvIHhpY2hhPyBYaSBzaW8gb2h4eWxtbnVoeCBuYnkgd2NqYnlsPw==</code>. We consider it a success if the LLM can respond to our message (in plain text English, or using the same encoding), or if it at least can decode the message.</p><p>I set up the experiment in two ways: In the first variant, I gave the model nothing but the Base64 string. This variant is harder, since the LLM is not given any indication of what language the message could be written in. This is hugely helpful when decoding substitution ciphers, since you can orient yourself by the most common words in the language, such as “a”, “an”, “the”, “I”, “to”, “of” etc. in English. The other variant prepended it with “Deciper and answer this: “. However, there were no practical differences in the results, only one model (Qwen 235B) needed the “decode” nudge. Instead, I saw most of the models fail on the Base64 decoding, most likely because the text did not resemble normal language, making validation of successful decoding more difficult.</p><p>Below I provide separate results for decoding Base64 (i.e. did it unpack to the correct ROT20 text?) and also just for doing the “inner” ROT20 decipher (queried separately without Base64 encoding).</p><table><thead><tr><th>Model</th><th>Base64 decode</th><th>ROT20 decipher</th><th>Base64+ROT20 result</th></tr></thead><tbody><tr><td>gpt-3.5-turbo</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>gpt-4-turbo</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>gpt-4o</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>gpt-4.1</td><td><strong>Pass</strong></td><td>Fail</td><td>Fail</td></tr><tr><td>gpt-5-nano</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>gpt-5-mini</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>gpt-5</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>gpt-5-nano (reasoning)</td><td>Fail</td><td><strong>Pass</strong></td><td>Fail</td></tr><tr><td>gpt-5-mini (reasoning)</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>gpt-5 (reasoning)</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>claude-sonnet-3.5</td><td>Fail</td><td><strong>Pass</strong></td><td>Fail</td></tr><tr><td>claude-sonnet-3.7</td><td>Fail</td><td><strong>Pass</strong></td><td>Fail</td></tr><tr><td>claude-sonnet-4</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>claude-sonnet-4.5</td><td>Safety fail</td><td>Safety fail</td><td>Safety fail</td></tr><tr><td>gemini-2.5-flash</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>gemini-2.5-flash (reasoning)</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>gemini-2.5-pro</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>llama-4-maverick</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>deepseek-v3.2-exp</td><td>Fail</td><td>Fail</td><td>Fail</td></tr><tr><td>deepseek-v3.2-exp (reasoning)</td><td>Fail</td><td><strong>Pass</strong></td><td>Fail</td></tr><tr><td>qwen-235b</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td>Fail</td></tr><tr><td>qwen-235b (reasoning)</td><td><strong>Pass</strong></td><td><strong>Pass</strong></td><td><strong>Pass</strong></td></tr><tr><td>kimi-k2</td><td>Fail</td><td>Fail*</td><td>Fail</td></tr><tr><td>grok-4</td><td>Safety fail</td><td><strong>Pass</strong></td><td>Safety fail</td></tr></tbody></table><p>Here are a few comments:</p><ul><li>Claude Sonnet 4.5 refuses to touch anything that does not resemble normal text, be it Base64 or ROT-encrypted text. Base64 is <a href="https://arxiv.org/html/2411.01084v1" target="_blank" rel="noopener">one of the many methods</a> of trying to obfuscate the code and fool any keyword filters or LLM safety judges, but this highly sensitive approach could make Claude Sonnet 4.5 unusable on rarer languages. Grok 4 suffered from the same issue, but refused only Base64 text.</li><li>Chinese reasoning models have very lengthy internal monologues: Solving the ROT20 cipher usually consumed around 3K tokens, and when combined with the Base64 encoding, the output often reached 6-7K tokens.</li><li>Some models, such as Kimi K2, did not technically complete the ROT20 decryption, but were on the right track and provided functional Python code for the user to figure that out. Still a fail, but failing gracefully.</li><li>I used the default temperature settings, which can cause issues with decoding even in SOTA models, albeit in a small percentage of cases.</li></ul><h2 id="what-have-we-learned">What have we learned?</h2><p>To me, there are two interesting observations: newer/larger models are better at generalizing Base64 encoding and decoding, and they’re also becoming more adept at manipulating text at the character level.</p><p>Most current-generation models, especially the larger ones, are able to decode Base64 text. What is especially interesting, though, is that I tested on what looks like gibberish (ROT20 encoded text), so the model’s knowledge of the Base64 decoding algorithm isn’t merely memorization of the patterns for the most common English words, as was <a href="https://florian.github.io/base64/" target="_blank" rel="noopener">suggested in earlier literature</a>. This may have been the case for older/smaller models: I tested the sentence “Hey! This is Tom, I have a blog about tech, AI and privacy that you should definitely check out.” - and many of the models which failed the Base64 test above (like GPT 4o, GPT 5 Nano or DeepSeek V3.2 Exp) were actually able to decode it fine from Base64. However, SOTA models can now decode out-of-distribution texts from Base64, suggesting they have working understanding of the algorithm, not just memorized translation patterns from English words.</p><p>The models are also becoming more adept at manipulating text at the character level, despite their understanding of text being based on tokens. Substitution of characters, whether at an individual level (the strawberry sentence) or when decoding substitution ciphers, is a task that they now complete successfully fairly reliably. I cannot provide an explanation of <strong>why</strong> that happens (please let me know if you have any ideas), but empirically that’s what seems to be happening. Reasoning models and tool use further increase LLMs capabilities for manipulating text (as is the case in many other areas), but it is clear that the new capabilities are baked into the base models regardless of these extra features. While character-level operations are far from a solved problem for LLMs, it is fascinating to see the progress they make in this area.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Strudel REPL – a music live coding environment living in the browser (203 pts)]]></title>
            <link>https://strudel.cc</link>
            <guid>45571822</guid>
            <pubDate>Mon, 13 Oct 2025 18:37:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://strudel.cc">https://strudel.cc</a>, See on <a href="https://news.ycombinator.com/item?id=45571822">Hacker News</a></p>
<div id="readability-page-1" class="page"> <astro-island uid="Z15JJxh" component-url="/_astro/Repl.z9aJL9q1.js" component-export="Repl" renderer-url="/_astro/client.BnmqwyG6.js" props="{}" ssr="" client="only" opts="{&quot;name&quot;:&quot;Repl&quot;,&quot;value&quot;:&quot;react&quot;}"></astro-island> <a rel="me" href="https://social.toplap.org/@strudel" target="_blank">mastodon</a> </div>]]></description>
        </item>
        <item>
            <title><![CDATA[Modern iOS Security Features – A Deep Dive into SPTM, TXM, and Exclaves (212 pts)]]></title>
            <link>https://arxiv.org/abs/2510.09272</link>
            <guid>45571688</guid>
            <pubDate>Mon, 13 Oct 2025 18:23:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2510.09272">https://arxiv.org/abs/2510.09272</a>, See on <a href="https://news.ycombinator.com/item?id=45571688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2510.09272">View PDF</a></p><blockquote>
            <span>Abstract:</span>The XNU kernel is the basis of Apple's operating systems. Although labeled as a hybrid kernel, it is found to generally operate in a monolithic manner by defining a single privileged trust zone in which all system functionality resides. This has security implications, as a kernel compromise has immediate and significant effects on the entire system. Over the past few years, Apple has taken steps towards a more compartmentalized kernel architecture and a more microkernel-like design. To date, there has been no scientific discussion of SPTM and related security mechanisms. Therefore, the understanding of the system and the underlying security mechanisms is minimal. In this paper, we provide a comprehensive analysis of new security mechanisms and their interplay, and create the first conclusive writeup considering all current mitigations. SPTM acts as the sole authority regarding memory retyping. Our analysis reveals that, through SPTM domains based on frame retyping and memory mapping rule sets, SPTM introduces domains of trust into the system, effectively gapping different functionalities from one another. Gapped functionality includes the TXM, responsible for code signing and entitlement verification. We further demonstrate how this introduction lays the groundwork for the most recent security feature of Exclaves, and conduct an in-depth analysis of its communication mechanisms. We discover multifold ways of communication, most notably xnuproxy as a secure world request handler, and the Tightbeam IPC framework. The architecture changes are found to increase system security, with key and sensitive components being moved out of XNU's direct reach. This also provides additional security guarantees in the event of a kernel compromise, which is no longer an immediate threat at the highest trust level.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Jiska Classen [<a href="https://arxiv.org/show-email/d0dc6220/2510.09272" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 10 Oct 2025 11:14:27 UTC (1,928 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[America's future could hinge on whether AI slightly disappoints (193 pts)]]></title>
            <link>https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether</link>
            <guid>45570973</guid>
            <pubDate>Mon, 13 Oct 2025 17:24:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether">https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether</a>, See on <a href="https://news.ycombinator.com/item?id=45570973">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>A burning question that’s on a lot of people’s minds right now is: Why is the U.S. economy still holding up? The manufacturing industry is </span><a href="https://www.cbc.ca/news/business/trade-trump-carney-meeting-tariffs-1.7652580" rel="">hurting badly</a><span> from Trump’s tariffs, the payroll numbers </span><a href="https://www.cnn.com/2025/10/01/economy/adp-private-jobs-report-september" rel="">are looking weak</a><span>, and consumer sentiment is at Great Recession levels:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!ZBnn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!ZBnn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 424w, https://substackcdn.com/image/fetch/$s_!ZBnn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 848w, https://substackcdn.com/image/fetch/$s_!ZBnn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 1272w, https://substackcdn.com/image/fetch/$s_!ZBnn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!ZBnn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png" width="1320" height="465" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/e4a41752-7b88-4256-be60-85988822ce4a_1320x465.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:465,&quot;width&quot;:1320,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:89552,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.noahpinion.blog/i/175930142?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!ZBnn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 424w, https://substackcdn.com/image/fetch/$s_!ZBnn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 848w, https://substackcdn.com/image/fetch/$s_!ZBnn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 1272w, https://substackcdn.com/image/fetch/$s_!ZBnn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe4a41752-7b88-4256-be60-85988822ce4a_1320x465.png 1456w" sizes="100vw"></picture></div></a></figure></div><p><span> And yet despite those warning signs, there has been nothing even remotely resembling an economic crash yet. </span><a href="https://fred.stlouisfed.org/series/U6RATE" rel="">Unemployment</a><span> is rising a little bit but still extremely low, while </span><a href="https://fred.stlouisfed.org/series/LNS12300060#" rel="">the prime-age employment rate</a><span> — my favorite single indicator of the health of the labor market — is still near all-time highs. The New York Fed’s GDP nowcast thinks that GDP growth is currently running at </span><a href="https://www.newyorkfed.org/research/policy/nowcast/#nowcast/2025:Q3" rel="">a little over 2%</a><span>, while the Atlanta Fed’s nowcast </span><a href="https://www.atlantafed.org/cqer/research/gdpnow" rel="">puts it even higher</a><span>. </span></p><p>One possibility is that everything is just fine with the economy — that Trump’s tariffs aren’t actually that high because of all the exemptions, and/or that economists are exaggerating the negative effects of tariffs in the first place. Weak consumer confidence could be a partisan “vibecession”, payroll slowdown could be from illegal immigrants being deported or leaving en masse, and manufacturing’s woes could be from some other sector-specific factor. </p><p><span>Another possibility is that tariffs are bad, but are being canceled out by an even more powerful force — the AI boom. The FT </span><a href="https://www.ft.com/content/e9be3e3f-2efe-42f7-b2d2-8ab3efea27a8" rel="">reports</a><span>:</span></p><blockquote><p>Pantheon Macroeconomics estimates that US GDP would have grown at a mere 0.6 per cent annualised rate in the first half were it not for AI-related spending, or half the actual rate.</p></blockquote><p><span>Paul Kedrosky </span><a href="https://www.derekthompson.org/p/this-is-how-the-ai-bubble-will-pop" rel="">came up with similar numbers</a><span>. Jason Furman </span><a href="https://x.com/jasonfurman/status/1971995367202775284" rel="">does a slightly different calculation</a><span>, and arrives at an even starker number:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!e7yk!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!e7yk!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 424w, https://substackcdn.com/image/fetch/$s_!e7yk!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 848w, https://substackcdn.com/image/fetch/$s_!e7yk!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!e7yk!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!e7yk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg" width="640" height="521.075794621027" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:666,&quot;width&quot;:818,&quot;resizeWidth&quot;:640,&quot;bytes&quot;:69859,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.noahpinion.blog/i/175930142?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!e7yk!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 424w, https://substackcdn.com/image/fetch/$s_!e7yk!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 848w, https://substackcdn.com/image/fetch/$s_!e7yk!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!e7yk!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F997e480b-91bc-4ee9-9e08-630a08af205a_818x666.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>And here’s an impressive chart:</p><p><span>The Economist </span><a href="https://www.economist.com/finance-and-economics/2025/08/18/how-americas-ai-boom-is-squeezing-the-rest-of-the-economy" rel="">writes</a><span>:</span></p><blockquote><p>[L]ook beyond AI and much of the economy appears sluggish. Real consumption has flatlined since December. Jobs growth is weak. Housebuilding has slumped, as has business investment in non-AI parts of the economy[.]</p></blockquote><p><span>And in a post entitled “</span><a href="https://www.ft.com/content/6cc87bd9-cb2f-4f82-99c5-c38748986a2e" rel="">America is now one big bet on AI</a><span>”, Ruchir Sharma writes that “AI companies have accounted for 80 per cent of the gains in US stocks so far in 2025.” In fact, more than a fifth of the entire S&amp;P 500 market cap is now </span><a href="https://x.com/PeterMallouk/status/1975550929848922433" rel="">just three companies</a><span> — Nvidia, Microsoft, and Apple — two of which are basically big bets on AI. </span></p><p><span>Now as Furman </span><a href="https://x.com/jasonfurman/status/1971995368314274296" rel="">points out</a><span>, this doesn’t necessarily mean that without AI, the U.S. economy would be stalling out. If the economy wasn’t pouring resources into AI, it might be pouring them into something else, spurring growth that was </span><em>almost</em><span> as fast as what we actually saw. But it’s also </span><em>possible</em><span> that without AI, America would be crashing from tariffs.</span></p><p><span>Trump certainly seems to think AI is a golden goose worth protecting. Joey Politano </span><a href="https://x.com/JosephPolitano/status/1974849420798955729" rel="">points out</a><span> that even as Trump has slapped tariffs on a plethora of industries, he has left AI and its supply chain mostly untouched:</span></p><p>But despite Trump’s tariff exemptions, the AI sector could very well crash in the next year or two. And if it does, it could do a lot more than just hurt Americans’ employment prospects and stock portfolios.</p><p><span>If AI is really the only thing protecting America from the scourge of Trump’s tariffs, then a bust in the sector could change the country’s entire political economy. A crash and recession would immediately flip the narrative on Trump’s whole presidency, much as the housing crash of 2008 cemented George W. Bush’s legacy as a failure. And because Trump’s second term is looking so transformative</span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-175930142" href="https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether#footnote-1-175930142" target="_self" rel="">1</a><span>, the fate of the AI sector could potentially determine the entire fate of the country. </span></p><p>So a whole lot is riding on the question of whether an AI bust will crash the economy. The stakes could hardly be higher. </p><p><span>A lot of bubbles are purely financial beasts, driven by irrationality or coordination problems in the markets for stocks, bonds, and derivatives. For example, you can have a </span><em><a href="https://www.princeton.edu/~markus/research/papers/bubbles_crashes.pdf" rel="">speculative bubble</a></em><span>, in which a bunch of people know an asset is overpriced, but think they can sell out before the crash, and so they keep buying and buying and pushing the price up and up. You can also have an </span><em><a href="https://scholar.harvard.edu/files/shleifer/files/extrapolation_bubbles_published_version.pdf" rel="">extrapolative bubble</a></em><span>, when people see the price of something going up and up, and mistakenly decide that it must be due to some underlying positive trend.</span></p><p><span>But a much simpler possibility is that investors could </span><em>make a big mistake</em><span> about how valuable some technology is. They could honestly believe that AI is going to create immense amounts of value, and </span><em>they could just end up being wrong</em><span>. Then when they realize that the technology isn’t all it’s cracked up to be, they could temper their expectations, which would cause a price crash in AI stocks.</span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-175930142" href="https://www.noahpinion.blog/p/americas-future-could-hinge-on-whether#footnote-2-175930142" target="_self" rel="">2</a><span> But the stock crash wouldn’t be the real problem; far more painful would be the wave of loan defaults and financial distress that would result from AI’s actual shortcomings. </span></p><p><span>If there’s an AI crash, it’ll probably be this latter type. Jeff Bezos calls it </span><a href="https://x.com/unusual_whales/status/1977132350598201639?t=qesLmbVZNo3GhdJXt_RaWw&amp;s=19" rel="">an “industrial bubble”</a><span>, and I think that’s as good a name as any. This kind of bubble is still a financial phenomenon, since the banking system gets hurt. But the cause is a mistake about real technology, rather than asset markets going haywire. </span></p><p><span>Everyone who’s talking about an AI bubble is basically warning that the technology itself might disappoint. For example, here are some excerpts from </span><a href="https://www.bloomberg.com/news/articles/2025-10-04/why-ai-bubble-concerns-loom-as-openai-microsoft-meta-ramp-up-spending?sref=R8NfLgwS" rel="">a big Bloomberg feature</a><span> about the possibility of an AI bubble:</span></p><blockquote><p> Even some of AI’s biggest cheerleaders acknowledge the market is frothy, while still professing their belief in the technology’s long-term potential. AI, they say, is poised to reshape multiple industries, cure diseases and generally accelerate human progress…Yet never before has so much money been spent so rapidly on a technology that, for all its potential, remains somewhat unproven as a profit-making business model…</p><p><span>The data center spending spree is overshadowed by persistent skepticism about the payoff from AI technology. In August, investors were rattled after researchers at the Massachusetts Institute of Technology found that </span><a href="https://www.axios.com/2025/08/21/ai-wall-street-big-tech" rel="">95% of organizations</a><span> saw zero return on their investment in AI initiatives.</span></p><p><span>More recently, researchers at Harvard and Stanford offered a possible explanation for why. Employees are using AI to create “</span><a href="https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity" rel="">workslop</a><span>,” which the researchers define as “AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task.”…</span></p><p><span>AI developers have also been confronting a different challenge. OpenAI…Anthropic and others have for years bet on the so-called scaling laws…Over the past year, however, these developers have experienced </span><a href="https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai" rel="">diminishing returns</a><span>…Some have also struggled to match their own hype. After months of touting GPT-5 as a significant leap, OpenAI’s release of its latest AI model in August was met with mixed reviews…</span></p><p><span>There’s also the risk that the AI industry’s vast data center buildout, entailing a huge increase in </span><a href="https://www.bloomberg.com/opinion/articles/2025-10-02/altman-s-ai-power-grab-is-tone-deaf-and-infeasible" rel="">electricity consumption</a><span>, will be held back by the realities of strained national power networks.</span></p></blockquote><p>When you bring up concerns like this to an AI engineer, executive, or founder, they tend to just smile at you indulgently, secure in the knowledge that their invention is everything it’s cracked up to be, and that much better things are already in the pipeline. </p><p>But this doesn’t reassure me. Because when we look at the history of industrial bubbles, and of new technologies in general, it becomes clear that in order to cause a crash, AI doesn’t have to fail. It just has to mildly disappoint the most ardent optimists.</p><p>This is why I think an AI crash is more likely than a lot of people in the tech world — or the Trump administration — realize.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Environment variables are a legacy mess: Let's dive deep into them (225 pts)]]></title>
            <link>https://allvpv.org/haotic-journey-through-envvars/</link>
            <guid>45570537</guid>
            <pubDate>Mon, 13 Oct 2025 16:49:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://allvpv.org/haotic-journey-through-envvars/">https://allvpv.org/haotic-journey-through-envvars/</a>, See on <a href="https://news.ycombinator.com/item?id=45570537">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

  <meta property="og:url" content="https://allvpv.org/haotic-journey-through-envvars/">
  <meta property="og:site_name" content="allvpv’s space">
  <meta property="og:title" content="Environment variables are a legacy mess: Let's dive deep into them">
  <meta property="og:description" content="Programming languages have rapidly evolved in recent years. But in software development, the new often meets the old, and the scaffolding that OS gives for running new processes hasn’t changed much since Unix.
If you need to parametrize your application at runtime by passing a few ad-hoc variables (without special files or a custom solution involving IPC or networking), you’re doomed to a pretty awkward, outdated interface:">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:published_time" content="2025-10-13T15:00:00+02:00">
    <meta property="article:modified_time" content="2025-10-13T15:00:00+02:00">
    <meta property="og:image" content="https://allvpv.org/haotic-journey-through-envvars/pattern-rendered.png">

  <p><time datetime="2025-10-13">
    2025-10-13&nbsp;
  </time>
  
</p>

  
  
  


  
  
  
  

  



<p>Programming languages have rapidly evolved in recent years. But in software
development, the new often meets the old, and the scaffolding that OS gives for
running new processes hasn’t changed much since Unix.</p>
<p>If you need to parametrize your application at runtime by passing a few ad-hoc
variables (without special files or a custom solution involving IPC or
networking), you’re doomed to a pretty awkward, outdated interface:</p>
<h2 id="environment-variables">Environment variables.</h2>
<p><code>export SECRET_API_KEY=2u845102348u234</code></p>
<p>There are no namespaces for them, no types. Just a flat, embarrassingly global
dictionary of strings.</p>
<p>But what exactly are these envvars? Is it some kind of special dictionary
inside the OS? If not, who owns them and how do they propagate?</p>
<h2 id="where-do-they-come-from">Where do they come from?</h2>
<p>In a nutshell: they’re passed from parent to child.</p>
<pre tabindex="0"><code>    841 ?        00:00:00 sshd
   1520 ?        00:00:00  \_ sshd-session
   1616 ?        00:00:00      \_ sshd-session
   5521 pts/0    00:00:00          \_ bash
   5545 pts/0    00:00:00              \_ nu
   5549 pts/0    00:00:00                  \_ bash
   5560 pts/0    00:00:00                      \_ ps
</code></pre><p>On Linux, a program must use the <code>execve</code> syscall to execute another program.
Whether you type <code>ls</code> in Bash, call <code>subprocess.run</code> in Python, or launch a
code editor, it ultimately comes down to <code>execve</code>, preceded by a
<code>clone</code>/<code>fork</code>. The <code>exec*</code> family of C functions also relies on <code>execve</code>.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>SYSCALL_DEFINE3</span><span>(</span><span>execve</span><span>,</span>
</span></span><span><span>		<span>const</span> <span>char</span> <span>__user</span> <span>*</span><span>,</span> <span>filename</span><span>,</span>
</span></span><span><span>		<span>const</span> <span>char</span> <span>__user</span> <span>*</span><span>const</span> <span>__user</span> <span>*</span><span>,</span> <span>argv</span><span>,</span>
</span></span><span><span>		<span>const</span> <span>char</span> <span>__user</span> <span>*</span><span>const</span> <span>__user</span> <span>*</span><span>,</span> <span>envp</span><span>)</span>
</span></span></code></pre></div><p>This system call takes three arguments: <code>filename</code>, <code>argv</code>, <code>envp</code>.
For example, for an <code>ls -lah</code> invocation:</p>
<ol>
<li><code>/usr/bin/ls</code> is the <code>filename</code> (the executable path),</li>
<li><code>['ls', '-lah']</code> is the <code>argv</code> array of command line arguments – the
implicit first (“zero”) argument is usually the executable name,</li>
<li><code>['PATH=/bin:/usr/bin', 'USER=allvpv']</code> is the <code>envp</code> array of envvars
(typically much longer).</li>
</ol>
<p>By default, all envvars are passed from the parent to the child. However,
nothing prevents a parent process from passing a completely different or even
empty environment when calling <code>execve</code>! In practice, most tooling passes the
environment down: Bash, Python’s <code>subprocess.run</code>, the C library <code>execl</code>, and
so on.</p>
<p>And this is what you expect – variables are inherited by child processes.
That’s the point – to track the environment.</p>
<blockquote>
<p>Which tools do <em>not</em> pass the parent’s environment?
For example, the <code>login</code> executable, used when signing into a
system, sets up a fresh environment for its children.</p></blockquote>
<h2 id="where-do-they-go">Where do they go?</h2>
<p>After launching the new program, the kernel dumps the variables on the stack as
a sequence of null-terminated strings which contain the envvar definitions.
Here is a hex view:</p>
<pre tabindex="0"><code>    484f 4d45 3d2f 0069 6e69 743d 2f73 6269  HOME=/ init=/sbi
    6e2f 696e 6974 004e 4554 574f 524b 5f53  n/init NETWORK_S
    4b49 505f 454e 534c 4156 4544 3d00 5445  KIP_ENSLAVED= TE
    524d 3d6c 696e 7578 0042 4f4f 545f 494d  RM=linux BOOT_IM
    4147 453d 2f76 6d6c 696e 757a 2d36 2e31  AGE=/vmlinuz-6.1
    342e 302d 3333 2d67 656e 6572 6963 0064  4.0-33-generic.d
    726f 705f 6361 7073 3d00 5041 5448 3d2f  rop_caps= PATH=/
    7573 722f 6c6f 6361 6c2f 7362 696e 3a2f  usr/local/sbin:/
    7573 722f 6c6f 6361 6c2f 6269 6e3a 2f75  usr/local/bin:/u
    7372 2f73 6269 6e3a 2f75 7372 2f62 696e  sr/sbin:/usr/bin
    3a2f 7362 696e 3a2f 6269 6e00 5057 443d  :/sbin:/bin PWD=
    2f00 726f 6f74 6d6e 743d 2f72 6f6f 7400  / rootmnt=/root
</code></pre><p>This static layout can’t easily be modified or extended; the program must copy
those variables into its own data structure. Let’s look at how Bash, C, and
Python store envvars internally. I analyzed their source code and here is a
summary.</p>
<h3 id="bash">Bash</h3>
<p>It stores the variables in a <em><strong>hashmap</strong></em>. Or, more precisely, in a <em><strong>stack
of hashmaps</strong></em>.</p>
<p>When you spawn a new process using Bash, it traverses the stack of hashmaps to
find variables marked as exported and copies them into the environment array
passed to the child.</p>
<blockquote>
<p><em>Side note:</em> Why is traversing the stack needed?</p>
<p>Each function invocation in Bash creates a new local scope – a new entry
on the stack. If you declare your variable with <code>local</code>, it ends up in this
locally-scoped hashmap.</p>
<p>What’s interesting is that you can export a <code>local</code> variable too!</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span><span>function</span> locallyScoped<span>()</span> <span>{</span>
</span></span><span><span>    <span>local</span> <span>PATH</span><span>=</span><span>"</span><span>$PATH</span><span>:/opt/secret/bin"</span>
</span></span><span><span>    <span>export</span> PATH
</span></span><span><span>    env           <span># &lt;- sees the PATH with /opt/scecret/bin</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>locallyScoped
</span></span><span><span>env               <span># &lt;- sees the PATH without modification</span>
</span></span></code></pre></div><p>I wouldn’t have learned this without diving into Bash source. My intuitive
(wrong) assumption was that <code>export</code> <em>automatically makes the variable
global</em> – like <code>declare -g</code>! Super interesting stuff.</p></blockquote>
<h3 id="the-default-c-library-on-linux-glibc">The default C library on Linux: <code>glibc</code></h3>
<p><code>glibc</code> exposes a dynamic <code>environ</code> array, managed via <code>putenv</code> and <code>getenv</code>
library functions. It uses an array, so the time complexity of <code>getenv</code> and
<code>putenv</code> is <em>linear</em> in the number of envvars. Remember – envvars are not a
high-performance dictionary and you should not abuse them.</p>
<h3 id="python">Python</h3>
<p>Python couples its environment to the C library, which can cause surprising
inconsistencies.</p>
<p>If you’ve programmed some Python, you’ve probably used the <code>os.environ</code>
dictionary. On startup, <code>os.environ</code> is built from the C library’s <code>environ</code>
array.</p>
<p>But those dictionary values are <strong>NOT</strong> the “ground truth” for child processes.
Rather, each change to <code>os.environ</code> invokes the native <code>os.putenv</code> function,
which in turn calls the C library’s <code>putenv</code>.</p>
<blockquote>
<p>Note that the propagation is one-directional: modifying <code>os.environ</code> will call
<code>os.putenv</code>, but not the other way around. Call <code>os.putenv</code>, and <code>os.environ</code>
won’t be updated.</p></blockquote>
<h2 id="liberal-format">Liberal format</h2>
<p>The Linux kernel is very liberal about the format of environment variables, and
so is <code>glibc</code>.</p>
<p>For example, your C program can manipulate the environment – the global
<code>environ</code> array – such that several variables share the same name but have
different values. And when you execute a child process, it will inherit this
“broken” setup.</p>
<p>You don’t even need an equals sign separating name from value! The usual entry
is <code>NAME=VALUE</code>, but nothing prevents you from adding <code>NONSENSE_WITH_EMOJI 😀</code>
to the array.</p>
<p>The kernel happily accepts any null-terminated string as an “environment
variable” definition. It just imposes a <em>size</em> limitation:</p>
<ul>
<li>
<p><strong>Single variable</strong>: 128 KiB on a typical x64 Intel CPU. This is for the
whole definition – name + equal sign + value. It’s computed as <a href="https://elixir.bootlin.com/linux/v2.6.24/source/include/linux/binfmts.h#L14"><code>PAGE_SIZE * 32</code></a>.
No modern hardware uses pages smaller than 4 KiB, so you can treat it as a
lower bound, unless you need to deal with some legacy embedded systems.</p>
</li>
<li>
<p><strong>Total</strong>: 2 MiB on a typical machine. This limit is shared by envvars and
the command line arguments. The calculation is a bit more complicated (see
the <code>execve(2)</code> man page):</p>
<pre><code>  max(32 * PAGE_SIZE,  min(MAX_STACK_SIZE / 4,  6 MB))
</code></pre>
<p>On a typical system, the limiting factor is the <code>MAX_STACK_SIZE</code>. Remember,
initially the envvars are dumped on the stack! To prevent unpredictable
crashes, the system allows only 1/4 of the stack for the envvars.</p>
</li>
</ul>
<h2 id="quirks">Quirks</h2>
<p>But the fact that you can do something does not mean that you should. For
example, if you start Bash with the “broken” environment – duplicated names and
entries without <code>=</code> – it deduplicates the variables and drops the nonsense.</p>
<p>One interesting edge case is a space inside the variable <em>name</em>. My beloved
shell – <a href="https://www.nushell.sh/">Nushell</a> – has no problem with the following
assignment:</p>
<pre><code>$env."Deployment Environment" = "prod"
</code></pre>
<p>Python is fine with it, too. Bash, on the other hand, can’t reference it
because whitespace isn’t allowed in variable names. Fortunately, the variable
isn’t lost – <a href="https://github.com/bminor/bash/blob/a8a1c2fac029404d3f42cd39f5a20f24b6e4fe4b/variables.c#L126">Bash keeps such entries in a special hashmap
called</a>
<code>invalid_env</code> and still passes them to child processes.</p>
<h2 id="the-standard-format">The standard format</h2>
<p>So what name and value can you <em>safely</em> use for your envvar? A popular
misconception, repeated on StackOverflow and by ChatGPT, is that
<a href="https://en.wikipedia.org/wiki/POSIX">POSIX</a> permits only <strong>uppercase</strong>
envvars, and everything else is undefined behavior.</p>
<p>But this is seriously <strong>NOT</strong>
<a href="https://pubs.opengroup.org/onlinepubs/9699919799/">what the standard says</a>:</p>
<blockquote>
<p><em>These strings have the form name=value; names shall not contain the character
‘=’. For values to be portable across systems conforming to POSIX.1-2017, the
value shall be composed of characters from the portable character set (except
NUL and as indicated below). There is no meaning associated with the order of
strings in the environment. If more than one string in an environment of a
process has the same name, the consequences are undefined.</em></p>
<p><em>Environment variable names used by the utilities in the Shell and Utilities
volume of POSIX.1-2017 consist solely of uppercase letters, digits, and the
&lt;underscore&gt; ( ‘_’ ) from the characters defined in Portable Character Set
and do not begin with a digit. Other characters may be permitted by an
implementation; applications shall tolerate the presence of such names.
Uppercase and lowercase letters shall retain their unique identities and
shall not be folded together. The name space of environment variable names
containing lowercase letters is reserved for applications. Applications can
define any environment variables with names from this name space without
modifying the behavior of the standard utilities.</em></p></blockquote>
<p>Yes, POSIX-specified utilities use uppercase envvars, but that’s not
<em>prescriptive</em> for your programs. Quite the contrary: you’re <em>encouraged</em> to
use lowercase for your envvars so they don’t collide with the standard tools.</p>
<p>The only strict rule is that a variable name cannot contain an equals sign.
POSIX requires compliant applications to preserve all variables that conform to
this rule.</p>
<p>But in reality, not many applications use lowercase. The <em>proper etiquette</em> in
software development is to use <code>ALL_UPPERCASE</code>.</p>
<h2 id="my-pragmatic-recommendation-is">My pragmatic recommendation is…</h2>
<p>…to use <code>^[A-Z_][A-Z0-9_]*$</code> for names, and UTF-8 for values. You shouldn’t
hit problems on Linux. If you want to be super safe: instead of UTF-8, use the
POSIX-mandated <a href="https://en.wikipedia.org/wiki/Portable_character_set">Portable Character Set
(PCS)</a> – essentially
ASCII without control characters.</p>


<h2 id="wow-i-really-enjoyed-writing-this">Wow, I really enjoyed writing this…</h2>
<p>…and I hope it wasn’t a boring read.</p>


  
    
  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jeep software update bricks vehicles, leaves owners stranded (106 pts)]]></title>
            <link>https://www.thestack.technology/jeep-software-update-bricks-vehicles-leaves-owners-stranded/</link>
            <guid>45569966</guid>
            <pubDate>Mon, 13 Oct 2025 16:08:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thestack.technology/jeep-software-update-bricks-vehicles-leaves-owners-stranded/">https://www.thestack.technology/jeep-software-update-bricks-vehicles-leaves-owners-stranded/</a>, See on <a href="https://news.ycombinator.com/item?id=45569966">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>A software update to Jeep 4xE models caused major malfunctions over the weekend – leaving many owners stranded and some in danger after their power failed.</p><p>The culprit appears to have been a buggy "over the air" (OTA) software update to the company’s <a href="https://www.driveuconnect.com/support/software-update.html?ref=thestack.technology" rel="noreferrer"><em>uconnect</em></a> software on Friday October 10, which “bricked” vehicles if owners installed it.</p><p>A Jeep customer support representative on a 4XE forum <a href="https://www.4xeforums.com/threads/wrangler-4xe-ota-update-10-10-2025.8078/?nested_view=1&amp;post_id=103140&amp;ref=thestack.technology#post-103140"><u>posted</u></a> Saturday: “Please exercise extreme caution this evening if you have completed the update. If you have NOT completed the update and see the pop-up, please continue deferring..."</p><p>Posting as “Kori”, they told Jeep customers on the forum that the issue was “a telematics module box update” – and later added that the software update was cancelled the same day. </p><p>But not before multiple users across the US had updated their vehicles and suffered the immediate consequences.</p><h3 id="jeep-software-update-issue">Jeep software update issue</h3><p>Some described losing power abruptly whilst driving in the wake of the update. One Jeep owner, Kerry Hollis, who works in IT infrastructure at Wells Fargo, told <a href="https://www.thestack.technology/" rel="noreferrer"><em>The Stack</em></a>: “This was a software change that obviously wasn’t tested thoroughly and was dangerous and could have had life safety implications.&nbsp;</p><p>“Fortunately, for me, I lost propulsion while going at low speed in my neighborhood, so I was able to pull over, restart and limp back to my home. I’ve read stories of others that weren’t in that situation, going at highway speeds, and in traffic...</p><p>"Stellantis reacted quickly but it shouldn’t have happened..."</p><p>He added: It’s concerning... that most auto manufacturers and new vehicles even have the ability to be disabled by the manufacturer or even worse, someone with a malicious intent.”</p><figure><img src="https://www.thestack.technology/content/images/2025/10/RM025_040PM-1-.jpg" alt="" loading="lazy" width="1800" height="1273" srcset="https://www.thestack.technology/content/images/size/w600/2025/10/RM025_040PM-1-.jpg 600w, https://www.thestack.technology/content/images/size/w1000/2025/10/RM025_040PM-1-.jpg 1000w, https://www.thestack.technology/content/images/size/w1600/2025/10/RM025_040PM-1-.jpg 1600w, https://www.thestack.technology/content/images/2025/10/RM025_040PM-1-.jpg 1800w" sizes="(min-width: 720px) 720px"></figure><p>Jeep describes unconnect as software that “<em>gives you access to the latest available features and enhancements. Updates can be performed over any password-protected Wi-Fi network. Select vehicles with connected service capabilities are eligible for over-the-air updates,</em>” it adds. (The software can also be found in other marques from parent company Stellantis, but it appears only Jeep brands were affected by this update.)</p><h3 id="see-also-ford-eyes-1b-in-software-sales">See also: <a href="https://www.thestack.technology/fords-software-sales/#see-also-why-time-series-data-could-drive-an-automotive-evolution">Ford eyes $1B in software sales</a></h3><p>Another owner, Stephen Gutowski, owner of the reload.com news site, told <a href="https://www.linkedin.com/company/stackpublishing?ref=thestack.technology" rel="noreferrer"><em>The Stack</em></a>: “On Friday night, my 2024 Jeep Wrangler Willys 4xe asked me to run an update when I got back home. I clicked ‘yes’ without really thinking about it. </p><p>"What's the worst that could happen, right?&nbsp;</p><p>He added: “Well, the next morning, I saw posts on the 4xe Facebook group I'm in that the update essentially bricked the 2024 Wranglers. I'm glad I saw that before I went out to my Jeep because I was prepared for something to maybe be wrong and did a test drive in my parking lot …”</p><p>“Sure enough, after driving maybe a half mile around my parking lot, the Jeep killed the gas and told me to put it in park. The dash lit up like a Christmas tree. The check engine light came on. Worse, it refused to go back into drive. It was just dead where it sat… I was [eventually] able to limp it back to my parking spot. I called my local dealership and they said it was a nationwide issue on at least the 2024 Wrangler 4xes…”</p><h3 id="pretty-scary">"Pretty scary"</h3><p>Gutowski added: “On Sunday morning I saw Jeep's messages in the 4xe forum and the fix was ota’d to my Jeep. So, I let my car run for 15 minutes and did two power cycles. The check engine light went away, and everything seemed to be working normally again. Took it for a test drive around the neighborhood, and it drove like nothing ever happened.”</p><p>“It seems like it could have been extremely dangerous if I hadn't read about the problem before taking my car out on the road… imagine if it went dead on the highway. Pretty scary. Honestly, this feels like more of a modern car problem.&nbsp; I doubt this will be the last car to get bricked by an ota update. At least they were able to fix it with an ota update in a day.”</p><p>Posting on 4XE Forums, another Jeep owner going by “EmiK” wrote: “I just had to have my 2024 4XE towed to the dealer because it was having problems recognizing the gears, the CEL [check engine light] came on and it wouldn't drive. </p><p>"The dealer called me and said 4 others came in <em>this hour.”</em></p><p>Another angry customer posted on the 4XE forum that “your negligence could have gotten me and a thousand others killed.&nbsp;</p><blockquote><em>“Wranglers are stopping dead on the <strong>HIGHWAY. </strong>the highway where most of us are doing 60+mph. dealerships are charging us over $200 for this. i am a marine corps wife, and we haven’t gotten paid due to the shutdown, so i can’t even afford to have them “look” at my car—plus, why should we, as owners, pay for your mess up? i would sue if i was in the position to do so. this lazy and unfinished update is leaving thousands of us stranded with a brick instead of a car. if someone dies from this, expect a damn big lawsuit—i’d be joining that.”</em></blockquote><p><em>The Stack</em> could not reach a Jeep dealership for comment.We have also contacted Jeep owner Stellantis for a comment.</p><h3 id="dont-push-to-production-on-a-friday">Don't push to production on a Friday...</h3><p>The company may want to closely read CrowdStrike’s <a href="https://www.crowdstrike.com/en-us/blog/falcon-content-update-preliminary-post-incident-report/?ref=thestack.technology"><u>post-mortem</u></a> after a buggy software update from the cybersecurity company <a href="https://www.thestack.technology/fuzzing-and-staggering-crowdstrike-post-mortem-suggests-testing-lessons-learned-the-hard-way/"><u>bricked over eight million</u></a> Windows computers globally in July 2024, causing cancelled flights, hospital outages and banking errors, among other issues.&nbsp;</p><p>CrowdStrike promised after the incident to roll out stronger software release controls/improve quality assurance. Among other pledges, it said it would start to “implement a staggered deployment strategy… in which updates are gradually deployed to larger portions of the sensor base, starting with a canary deployment…”*</p><p><em>*Editor's note: This is a fairly basic control and it is striking that so many organisations no longer seem to do this in their rush to push out software updates. </em></p><p><strong><em>Affected? Have strong views on OTA software updates in vehicles or software QA? Work on uconnect and want to chat? Pop us an </em></strong><a href="mailto:ed@thestack.technology" rel="noreferrer"><strong><em>email </em></strong></a><strong><em>or message via Signal on @Targett.11</em></strong></p>

                
    </div></div>]]></description>
        </item>
    </channel>
</rss>