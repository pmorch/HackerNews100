<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 31 Dec 2025 03:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Project ideas to appreciate the art of programming (179 pts)]]></title>
            <link>https://codecrafters.io/blog/programming-project-ideas</link>
            <guid>46439027</guid>
            <pubDate>Tue, 30 Dec 2025 22:47:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codecrafters.io/blog/programming-project-ideas">https://codecrafters.io/blog/programming-project-ideas</a>, See on <a href="https://news.ycombinator.com/item?id=46439027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Many developers want to start a side project but aren't sure what to build. The internet is full of ideas that are basic and dull.</p>
<p>Here's our list of 73 project ideas to inspire you. We have chosen projects that teach a lot and are fun to build.</p>
<h2>1. Bittorrent Client</h2>
<p>Build a BitTorrent client that can download files using the BitTorrent protocol. You can start with single-file torrents. This is a great way to learn how P2P networking works.</p>
<p>Read the <a href="https://www.bittorrent.org/beps/bep_0003.html" target="_blank" rel="noopener noreferrer">official BitTorrent specification</a> here.</p>
<h2>2. Wordle Solver</h2>
<p>Build a program that solves Wordle. This can be a great lesson on information theory and entropy. You'll also get hands-on experience at optimizing computations.</p>
<p>This <a href="https://www.youtube.com/watch?v=v68zYyaEmEA" target="_blank" rel="noopener noreferrer">YouTube video</a> will get you started.</p>
<h2>3. Deepfake</h2>
<p>Implement Optimal Transport from scratch to morph one face into another while preserving identity and structure. You'll apply linear programming to a real problem.</p>
<p><img alt="Deepfake" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdeepfake.5b20fd7c.webp&amp;w=1200&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdeepfake.5b20fd7c.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdeepfake.5b20fd7c.webp&amp;w=3840&amp;q=75" width="1200" height="549" decoding="async" data-nimg="1" loading="lazy"></p><p><small>You can try and morph your face on the Mona Lisa. Or maybe not...</small></p>
<p>Here are <a href="https://github.com/kilianFatras/awesome-optimal-transport" target="_blank" rel="noopener noreferrer">some OT resources</a> and a <a href="https://proceedings.neurips.cc/paper_files/paper/2016/file/26f5bd4aa64fdadf96152ca6e6408068-Paper.pdf" target="_blank" rel="noopener noreferrer">paper</a> which proposes a solution.</p>
<h2>4. Spreadsheet</h2>
<p>Create a spreadsheet with support for cell references, simple formulas, and live updates. You'll learn about dependency graphs, parsing, and reactive UI design.</p>
<p>The founder of the GRID spreadsheet engine shares some insights <a href="https://medium.grid.is/we-built-a-spreadsheet-engine-from-scratch-heres-what-we-learned-e4800ab9edf1" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h2>5. Container</h2>
<p>Build a lightweight container runtime from scratch without Docker. You'll learn about kernel namespaces, chroot, process isolation, and more.</p>
<p><a href="https://igupta.in/blog/life-of-a-container/" target="_blank" rel="noopener noreferrer">Read this</a> to understand how containers work.</p>
<h2>6. Geometric Theorem Proving</h2>
<p>Build a system that uses Euclid's postulates to derive geometric proofs and visualize the steps. You'll learn symbolic representation, rule systems, logic engines, and proof theory.</p>
<p><img alt="Mizar" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmizar.0961da34.png&amp;w=640&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmizar.0961da34.png&amp;w=1080&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fmizar.0961da34.png&amp;w=1080&amp;q=75" width="424" height="357" decoding="async" data-nimg="1" loading="lazy"></p><p><small><a href="https://mizar.uwb.edu.pl/" target="_blank" rel="noopener noreferrer">The Mizar project</a> aims to formalize all of mathematics, and has been going on since the 1970s.</small></p>
<p>You can efficiently implement <a href="https://aitopics.org/download/classics:FB935240" target="_blank" rel="noopener noreferrer">Gelernter's visionary 1959 paper</a> today.</p>
<h2>7. Googlebot</h2>
<p>Google uses a crawler to navigate web pages and save their contents. By building one, you'll learn how web search works. It's also great practice for system design.</p>
<p>You can make your own list of sites and create a search engine on a topic of your interest.</p>
<p>This <a href="https://jc1175.medium.com/how-i-would-design-a-web-crawler-9013251fa9f3" target="_blank" rel="noopener noreferrer">article</a> proposes a design approach.</p>
<h2>8. DNS Server</h2>
<p>Build a DNS server that listens for queries, parses packets, resolves domains, and caches results. Learn more about low-level networking, UDP, TCP, and the internet.</p>
<p>Start with <a href="https://www.cloudflare.com/en-gb/learning/dns/what-is-dns/" target="_blank" rel="noopener noreferrer">how DNS works</a> and dive into the <a href="https://mislove.org/teaching/cs4700/spring11/handouts/project1-primer.pdf" target="_blank" rel="noopener noreferrer">DNS packet format</a>.</p>
<h2>9. Six Degrees of Kevin Bacon</h2>
<p>Build a game where players connect two actors through shared credits with other actors, and reveal the optimal path at the end. You'll learn how to deal with massive graphs.</p>
<p><img alt="The Wiki Game" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fwikigame.934b957a.png&amp;w=3840&amp;q=75 1x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fwikigame.934b957a.png&amp;w=3840&amp;q=75" width="2330" height="1288" decoding="async" data-nimg="1" loading="lazy"></p><p><small><a href="https://www.thewikigame.com/group" target="_blank" rel="noopener noreferrer">The Wiki Game</a> is another fun version of the same concept.</small></p>
<p>Explore how to create fast graphs, and then try <a href="https://drops.dagstuhl.de/storage/00lipics/lipics-vol248-isaac2022/LIPIcs.ISAAC.2022.5/LIPIcs.ISAAC.2022.5.pdf" target="_blank" rel="noopener noreferrer">Landmark Labelling</a> for supreme performance.</p>
<h2>10. RAFT</h2>
<p>Implement the RAFT protocol from scratch to support distributed computing. Learn consensus, failure recovery, and how to build fault-tolerant distributed systems.</p>
<p>Visit <a href="https://raft.github.io/" target="_blank" rel="noopener noreferrer">this page</a> for the RAFT paper and other resources.</p>
<h2>11. Procedural Crosswords</h2>
<p>Design a program from scratch that creates satisfying crosswords with adjustable difficulty. You'll learn procedural generation, constraint propagation, and difficulty modeling.</p>
<p><img alt="Procedural Generation" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fprocedural.4ac21de7.jpg&amp;w=1080&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fprocedural.4ac21de7.jpg&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fprocedural.4ac21de7.jpg&amp;w=3840&amp;q=75" width="1040" height="585" decoding="async" data-nimg="1" loading="lazy"></p><p><small><a href="https://www.youtube.com/watch?v=Yio9ypz5cHY" target="_blank" rel="noopener noreferrer">No Man's Sky</a> is the largest deterministic game till date. It features a procedurally generated open world that includes 18,446,744,073,709,551,616 planets.</small></p>
<p>For example, you can implement the Wave Function Collapse algorithm explained <a href="https://robertheaton.com/2018/12/17/wavefunction-collapse-algorithm/" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h2>12. Bitcask</h2>
<p>Bitcask is an efficient embedded key-value store designed to handle production-grade traffic. Building this will improve your understanding of databases and efficient storage.</p>
<p>You can implement this <a href="https://riak.com/assets/bitcask-intro.pdf" target="_blank" rel="noopener noreferrer">short paper</a>.</p>
<h2>13. Audio Fingerprinting</h2>
<p>Apps like Shazam extract unique features from audio. This fingerprint is then used to match and identify sounds. You'll need to learn hash-based lookups and a bit of signal processing.</p>
<p>Here's a <a href="https://uni.johnwhite.it/Appunti/Teoria%20dei%20Segnali/TSG%20-%20Risorse/How%20does%20Shazam%20work%20-%20Coding%20Geek.pdf" target="_blank" rel="noopener noreferrer">detailed post</a> with everything you need to know.</p>
<h2>14. Dangerous Dave</h2>
<p>Recreate the industry-changing game using SDL, and add some story elements, NPC interactions, and levels. It'll be a perfect intro to game development.</p>
<p><img alt="Dangerous Dave" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdave.7464c20c.png&amp;w=640&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdave.7464c20c.png&amp;w=1920&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdave.7464c20c.png&amp;w=1920&amp;q=75" width="640" height="400" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Dangerous Dave was created by the prolific game developer John Romero, who co-founded id Software and designed games like Wolfenstein 3D and Doom.</small></p>
<p><a href="https://www.youtube.com/watch?v=kmECa4Gcckc&amp;list=PLSkJey49cOgTSj465v2KbLZ7LMn10bCF9&amp;index=1" target="_blank" rel="noopener noreferrer">This video</a> will set you up.</p>
<h2>15. Diff Tool</h2>
<p>Implement an algorithm from scratch to compare two text files or programs. This will involve dynamic programming and application of graph traversal.</p>
<p>Here's the <a href="https://publications.mpi-cbg.de/getDocument.html?id=8a8182da40fa742601410c5717da0008" target="_blank" rel="noopener noreferrer">classic paper</a> behind Myers' diff, used in Git for years.</p>
<h2>16. Visualize object-oriented code</h2>
<p>Generate UML class diagrams from source code with support for relationships like inheritance. You'll visualize object-oriented code and learn how to parse with ASTs.</p>
<p><img alt="D &amp; D" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fuml.a6da686b.webp&amp;w=1080&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fuml.a6da686b.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fuml.a6da686b.webp&amp;w=3840&amp;q=75" width="1080" height="1178" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Here's another way to visualize object-oriented code.</small></p>
<p><a href="https://medium.com/basecs/leveling-up-ones-parsing-game-with-asts-d7a6fc2400ff" target="_blank" rel="noopener noreferrer">This article</a> explains parsing with ASTs.</p>
<h2>17. BMP Codec</h2>
<p>Write your own encoder/decoder for the BMP image format and build a tiny viewer for it. You'll learn binary parsing, image encoding, and how to work with pixel buffers and headers.</p>
<p><a href="https://en.wikipedia.org/wiki/BMP_file_format" target="_blank" rel="noopener noreferrer">The Wikipedia article</a> is a good place to start.</p>
<h2>18. Filesystem</h2>
<p>Build a FUSE filesystem for Linux from scratch, with indexing, file metadata, and caching. You'll have to optimize data structures for storage and performance.</p>
<p><a href="https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html" target="_blank" rel="noopener noreferrer">This article</a> talks about the concepts used in filesystems.</p>
<h2>19. Quantum Computer Simulation</h2>
<p>Write the qubit and quantum gates from scratch. Use them to simulate a circuit for a quantum algorithm like Bernstein-Vazirani or Simon's algorithm.</p>
<p><img alt="Quantum" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fquantum.c53b0b96.jpg&amp;w=384&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fquantum.c53b0b96.jpg&amp;w=828&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fquantum.c53b0b96.jpg&amp;w=828&amp;q=75" width="382" height="375" decoding="async" data-nimg="1" loading="lazy"></p><p><small>This is the best way to grasp quantum computing and develop an intuition for it.</small></p>
<p>Read <a href="https://sciendo.com/article/10.1515/aucts-2015-0084" target="_blank" rel="noopener noreferrer">this short paper</a> for the essentials without any fluff.</p>
<h2>20. VLC</h2>
<p>Write a video player that decodes H.264/H.265 using ffmpeg, and supports casting local files to smart devices. Learn packet buffering, discovery protocols, and stream encoding.</p>
<p>Get started with <a href="http://dranger.com/ffmpeg/ffmpeg.html" target="_blank" rel="noopener noreferrer">this article</a>.</p>
<h2>21. Redis</h2>
<p>Build a Redis clone from scratch that supports basic commands, RDB persistence, replica sync, streams, and transactions. You'll get to deep dive into systems programming.</p>
<p>You can use the <a href="https://redis.io/docs/latest/develop/reference/protocol-spec/" target="_blank" rel="noopener noreferrer">official Redis docs</a> as a guide.</p>
<h2>22. Video Editor</h2>
<p>Build a client-side video editor that runs in the browser without uploading files to a server. Learn how to work with WASM, and why people love using it for high performance tasks.</p>
<p><img alt="Video Editor" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fvideoeditor.d7229c0c.png&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fvideoeditor.d7229c0c.png&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fvideoeditor.d7229c0c.png&amp;w=3840&amp;q=75" width="1920" height="1080" decoding="async" data-nimg="1" loading="lazy"></p><p><small>WASM and WebGL made it possible to serve 3D modelling sites on a web browser.</small></p>
<p>Visit the <a href="https://webassembly.org/" target="_blank" rel="noopener noreferrer">official WebAssembly site</a> to get started.</p>
<h2>23. Auth Server with Sessions / JWT</h2>
<p>This is a rite of passage. You'll get hands-on experience with encryption, token expiration, refresh flows, and how to manage user sessions securely.</p>
<p>Implement <a href="https://auth0.com/blog/username-password-authentication/" target="_blank" rel="noopener noreferrer">username and password auth</a>. Then manage sessions with <a href="https://www.youtube.com/watch?v=fyTxwIa-1U0" target="_blank" rel="noopener noreferrer">JWT or session IDs</a>.</p>
<h2>24. Autocomplete System</h2>
<p>You have used it in searches and other places where you write text. Implement a solution that suggests the right words, and then optimize heavily for speed.</p>
<p>This <a href="https://www.youtube.com/watch?v=SG9CPplNGgo" target="_blank" rel="noopener noreferrer">YouTube video</a> gives an idea of the implementation process.</p>
<h2>25. SQLite</h2>
<p>Build a simple SQL engine that reads .db files, uses indexes and executes queries. It's a deep dive into how real-world databases are built and run efficiently.</p>
<p><img alt="SQLite database" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsqlite.b55eaa7c.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsqlite.b55eaa7c.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsqlite.b55eaa7c.webp&amp;w=3840&amp;q=75" width="1600" height="1100" decoding="async" data-nimg="1" loading="lazy"></p><p><small>SQL has been around for 50 years, showing how great abstractions can stand the test of time.</small></p>
<p>You need to understand <a href="https://medium.com/basecs/busying-oneself-with-b-trees-78bbf10522e7" target="_blank" rel="noopener noreferrer">B-trees</a> and <a href="https://www.sqlite.org/fileformat.html#b_tree_pages" target="_blank" rel="noopener noreferrer">how SQLite stores data on disk</a>.</p>
<h2>26. Background Noise Remover</h2>
<p>Remove background sounds from audio files. You'll learn signal processing and denoising techniques used in GPS, mouse input, sensors, object tracking, etc.</p>
<p>You can use a technique like <a href="https://www.kalmanfilter.net/default.aspx" target="_blank" rel="noopener noreferrer">Kalman Filtering</a> to do this.</p>
<h2>27. Dropbox</h2>
<p>Design a file sharing app with sync, cloud storage, and basic p2p features that can scale to some extent. You'll get practice in cloud architecture and backend design.</p>
<p><a href="https://www.pankajtanwar.in/blog/system-design-how-to-design-google-drive-dropbox-a-cloud-file-storage-service" target="_blank" rel="noopener noreferrer">This article</a> dives into the system design.</p>
<h2>28. Google Maps</h2>
<p>Build a map engine to index roads, terrain (rivers, mountains), places (shops, landmarks), and areas (cities, states). Learn spatial indexing, range queries, and zoom-level abstractions.</p>
<p>Start by implementing an R-tree from scratch by following the <a href="https://dl.acm.org/doi/pdf/10.1145/971697.602266" target="_blank" rel="noopener noreferrer">original paper</a>.</p>
<p><img alt="Quadtree" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fquadtree.ba1726ab.png&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fquadtree.ba1726ab.png&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fquadtree.ba1726ab.png&amp;w=3840&amp;q=75" width="1402" height="1178" decoding="async" data-nimg="1" loading="lazy"></p><p><small>You can use Quadtrees instead of R-trees for a simpler implementation.</small></p>
<p>Use <a href="https://www.naturalearthdata.com/" target="_blank" rel="noopener noreferrer">Natural Earth</a> and <a href="https://www.geofabrik.de/" target="_blank" rel="noopener noreferrer">GeoFabrik</a> datasets to populate your map engine.</p>
<h2>29. Road Network</h2>
<p>Recreate a city's road network, simulate traffic using real open data, and design an improved version. Tackle an NP-hard optimization problem with real constraints.</p>
<p>In some cases, nature has long solved what we call hard. Implement <a href="https://en.wikiversity.org/wiki/Slime_Mould_Algorithm" target="_blank" rel="noopener noreferrer">SMA</a> or <a href="https://www.youtube.com/watch?v=u7bQomllcJw" target="_blank" rel="noopener noreferrer">ACO</a> here.</p>
<h2>30. Collaborative Editor</h2>
<p>Develop a decentralized collaborative text editor. Similar to Google Docs, but without any central server. Use CRDTs to manage concurrent edits and ensure eventual consistency.</p>
<p>Use ropes, gap buffers, or piece tables to build a fast text buffer optimized for efficient editing.</p>
<p>Read <a href="https://mattweidner.com/2022/02/10/collaborative-data-design.html" target="_blank" rel="noopener noreferrer">this article</a> on designing data structures for such apps.</p>
<h2>31. Evolutionary Design</h2>
<p>Evolve working models of machinery using only primitive mechanical parts and constraints. You'll learn about genetic algorithms, fitness functions, and physics simulation.</p>
<p><img alt="Evolution" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fevolution.514b562c.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fevolution.514b562c.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fevolution.514b562c.webp&amp;w=3840&amp;q=75" width="1858" height="1290" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Simulating the problem constraints incorrectly can lead to some odd results...</small></p>
<p>You can design <a href="http://www.demo.cs.brandeis.edu/papers/other/cs-97-191.html#resul" target="_blank" rel="noopener noreferrer">bridges</a>, <a href="https://www.whiletrue.it/genetic_3-wheelers/" target="_blank" rel="noopener noreferrer">cars</a>, <a href="https://www.youtube.com/watch?v=mcAq9bmCeR0" target="_blank" rel="noopener noreferrer">clocks</a>, calculators, catapults, and more. <a href="https://ntrs.nasa.gov/api/citations/20030067398/downloads/20030067398.pdf" target="_blank" rel="noopener noreferrer">NASA used GAs to design an antenna for their space mission</a>.</p>
<p>This <a href="https://www.youtube.com/watch?v=mcAq9bmCeR0" target="_blank" rel="noopener noreferrer">YouTube video</a> shows how interesting evolutionary design can get.</p>
<h2>32. Web Server</h2>
<p>Create a server from scratch that supports HTTP requests, static files, routing, and reverse proxying. Learn socket programming and how web servers work.</p>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Overview" target="_blank" rel="noopener noreferrer">This page</a> will get you started.</p>
<h2>33. Depth Estimation</h2>
<p>Estimate a depth (disparity) map from a stereo image pair using Markov Random Fields. You'll learn about computer vision, graphical models, and inference techniques.</p>
<p>Start with the <a href="https://vision.middlebury.edu/stereo/data/" target="_blank" rel="noopener noreferrer">Middlebury Dataset</a> and <a href="https://nghiaho.com/?page_id=1366" target="_blank" rel="noopener noreferrer">this article</a> on belief propagation for stereo matching.</p>
<h2>34. Git</h2>
<p>Build a minimal Git with core features like init, commit, diff, log, and branching. Learn how version control works using content-addressable storage, hashes, and trees.</p>
<p><img alt="Git" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fgit.52598144.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fgit.52598144.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fgit.52598144.webp&amp;w=3840&amp;q=75" width="1280" height="737" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Linus Torvalds built Git in 10 days, and never imagined it would last 20 years.</small></p>
<p>Check out <a href="https://wyag.thb.lt/" target="_blank" rel="noopener noreferrer"><em>Write yourself a Git</em></a> for an overview of git internals.</p>
<h2>35. GDB</h2>
<p>Build a Unix debugger with stepping, breakpoints, and memory inspection. You'll learn low-level systems programming and process control.</p>
<p><a href="https://aosabook.org/en/v2/gdb.html" target="_blank" rel="noopener noreferrer">This article</a> discusses the internal structure of GDB.</p>
<h2>36. Neural Networks</h2>
<p>Build a deep learning framework from scratch with a tensor class, autograd, basic layers, and optimizers. Grasp the internals of backpropagation and gradient descent.</p>
<p>Start by building a simple 3-layer feedforward NN (multilayer perceptron) with your framework.</p>
<p>Andrej Karpathy explains the basic concepts in this <a href="https://www.youtube.com/watch?v=VMj-3S1tku0" target="_blank" rel="noopener noreferrer">YouTube Video</a>.</p>
<h2>37. Chess</h2>
<p>Build a Chess app from scratch, where users can play against each other or your own UCI engine. This project offers a blend of algorithms, UI, game logic, and AI.</p>
<p>You can go one step further and make the engine play itself to improve like AlphaZero and Leela.</p>
<p><img alt="AlphaGo" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falphago.8fdda543.png&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falphago.8fdda543.png&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Falphago.8fdda543.png&amp;w=3840&amp;q=75" width="1476" height="748" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Watch AlphaGo on YouTube if you haven't already.</small></p>
<p>You can start with the <a href="https://www.chesshouse.com/pages/chess-rules" target="_blank" rel="noopener noreferrer">rules</a> and the <a href="https://www.chessprogramming.org/Main_Page" target="_blank" rel="noopener noreferrer">chess programming wiki</a>.</p>
<h2>38. Wikipedia Search</h2>
<p>Build a fast search engine from scratch for the Wikipedia dump with typo tolerance and semantic ranking, and fuzzy queries. You'll learn indexing, tokenization, and ranking algorithms.</p>
<p><a href="https://itnext.io/building-a-search-engine-in-rust-c945b6e638f8" target="_blank" rel="noopener noreferrer">This article</a> offers a good introduction to the basics of information retrieval.</p>
<h2>39. CDN Caching</h2>
<p>Build a caching system to avoid redundant fetches for static assets. You'll learn web caching, log analysis, and how to use probabilistic data structures in a real setting.</p>
<p>You can use <a href="https://ita.ee.lbl.gov/html/contrib/NASA-HTTP.html" target="_blank" rel="noopener noreferrer">this dataset</a> containing two month's worth of HTTP requests to the NASA server.</p>
<p><a href="https://harish-bhattbhatt.medium.com/bloom-filter-application-and-implementation-52c6d4512c21" target="_blank" rel="noopener noreferrer">This article</a> introduces some of the key concepts.</p>
<h2>40. TikTok</h2>
<p>Build a short-video app with infinite scroll, social graphs of friends and subs, and a tailored feed. You'll learn efficient preloading, knowledge graphs, and behavioral signals.</p>
<p><img alt="Doom Scrolling" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdoomscroll.8bc8537e.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdoomscroll.8bc8537e.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdoomscroll.8bc8537e.webp&amp;w=3840&amp;q=75" width="1532" height="856" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Build the next doom-scrolling app that hijacks attention spans and ruins sleep schedules.</small></p>
<p>Read <a href="https://www.aaronabraham.ca/technical-writing/tiktok-monolith-system" target="_blank" rel="noopener noreferrer">this article</a> on Monolith, Bytedance's recommendation system.</p>
<h2>41. Time Sync Daemon</h2>
<p>Implement NTP from scratch to build a background service that syncs system time with time servers. You'll learn daemon design and the internals of network time sync.</p>
<p><a href="https://datatracker.ietf.org/doc/html/rfc5905" target="_blank" rel="noopener noreferrer">RFC 5905</a> is a great place to start.</p>
<h2>42. Twitter Trends</h2>
<p>Implement HyperLogLog from scratch to provide analytics on number of users engaging with hashtags in real time. You'll learn some key concepts around big data systems.</p>
<p>Start with <a href="https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf" target="_blank" rel="noopener noreferrer">Google's paper on HyperLogLog</a>.</p>
<h2>43. SQL Optimizer</h2>
<p>Write a query planner that rewrites SQL queries for better performance. You'll learn cost estimation, join reordering, and index selection.</p>
<p><img alt="Bigquery" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbigquery.085ccc99.png&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbigquery.085ccc99.png&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbigquery.085ccc99.png&amp;w=3840&amp;q=75" width="1354" height="586" decoding="async" data-nimg="1" loading="lazy"></p><p><small>It only takes a few rogue scripts hammering BigQuery to send your burn multiple into a nosedive.</small></p>
<p><a href="https://duckdb.org/2023/09/15/query-optimizer.html" target="_blank" rel="noopener noreferrer">This DuckDB post</a> explains how optimizers work.</p>
<h2>44. Anonymous Voting</h2>
<p>Implement an encrypted voting system for anonymity. Use zero-knowledge proofs to verify results.</p>
<p>Learn cryptographic primitives, smart contracts, and ZKPs.</p>
<p>For example, <a href="https://chinmaysonar.github.io/Projects/bc-zk-report.pdf" target="_blank" rel="noopener noreferrer">this paper</a> attempts to define such a protocol.</p>
<h2>45. VPN</h2>
<p>Build a mesh VPN where nodes relay traffic without central servers. You'll learn NAT traversal, encrypted tunneling, and decentralized routing.</p>
<p><a href="https://tailscale.com/blog/how-nat-traversal-works/" target="_blank" rel="noopener noreferrer">Tailscale's blog</a> introduces some key concepts.</p>
<h2>46. Zip</h2>
<p>Build a file archiver that compresses, bundles, and encrypts your files. Implement compression and encryption algorithms from scratch. Benchmark your performance against zip.</p>
<p><img alt="Zip" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fzip.837110eb.webp&amp;w=640&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fzip.837110eb.webp&amp;w=1920&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fzip.837110eb.webp&amp;w=1920&amp;q=75" width="640" height="267" decoding="async" data-nimg="1" loading="lazy"></p><p><small>'your mama' jokes have clearly gone too far.</small></p>
<p>You can refer to the <a href="https://pkwaredownloads.blob.core.windows.net/pem/APPNOTE.txt" target="_blank" rel="noopener noreferrer">official .zip specification</a>.</p>
<h2>47. Ray Tracer</h2>
<p>Build a basic ray tracer to render 3D scenes with spheres, planes, and lights. This will be great practice in writing clean abstractions and optimizing performance-heavy code.</p>
<p>You can refer to the <a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html#wherenext?/afinalrender" target="_blank" rel="noopener noreferrer"><em>Ray Tracing in One Weekend</em></a> ebook.</p>
<h2>48. Programming Language</h2>
<p>Create your own language. It is best to start with an interpreted language that does not need a complier. Design your own grammar, parser, and an evaluation engine.</p>
<p><a href="https://craftinginterpreters.com/contents.html" target="_blank" rel="noopener noreferrer">Crafting Interpreters</a> is by far the best resource you can refer to.</p>
<h2>49. Messenger</h2>
<p>Recreate WhatsApp with chats, groups, history, encryption, notifications, and receipts. You'll get practice at building a production-grade app with an API, data store, and security.</p>
<p>You can draw inspiration from this <a href="https://interviewnoodle.com/how-i-would-design-facebook-messenger-384fc0d28787" target="_blank" rel="noopener noreferrer">system design approach</a>.</p>
<h2>50. Amazon Delivery</h2>
<p>Build a service to provide routes for a fleet of vehicles with limited capacity to deliver Amazon packages. You'll learn to optimize routing under constraints.</p>
<p><img alt="Amazon Delivery" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Famazondelivery.1dad64d8.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Famazondelivery.1dad64d8.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Famazondelivery.1dad64d8.webp&amp;w=3840&amp;q=75" width="1400" height="875" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Use Google Maps API to visualize customers and routes.</small></p>
<p>Here's a comparison of effective <a href="https://www.dline.info/dspai/fulltext/v2n1/dspaiv2n1_1.pdf" target="_blank" rel="noopener noreferrer">VRP algorithms</a>.</p>
<h2>51. Kafka Broker</h2>
<p>Build a basic broker to handle topic creation, produce and consume requests. You'll implement concurrency, avoid race conditions, and learn how distributed logs work.</p>
<p>Here's a <a href="https://ossrs.io/lts/en-us/assets/files/kafka-160915-0553-82964-c24c2b2f5caacb605a0ccec44e4eb9db.pdf" target="_blank" rel="noopener noreferrer">guide</a> to the Kafka protocol.</p>
<h2>52. Knowledge Graph</h2>
<p>Build an interactive knowledge graph that connects entities across media. Monitor the web for new content to keep it updated. You'll learn graph databases and data handling.</p>
<p>Explore this <a href="https://github.com/BrambleXu/knowledge-graph-learning" target="_blank" rel="noopener noreferrer">GitHub repo</a> to learn about knowledge graphs and find some inspiration.</p>
<h2>53. Malware</h2>
<p>Create a malware and test it against simple firewalls on your VMs. Don't share the code with anyone, though. This project is a solid intro to cybersecurity.</p>
<p>This <a href="https://www.youtube.com/watch?v=zEk3mi4Pt_E" target="_blank" rel="noopener noreferrer">YouTube video</a> discusses the core concepts.</p>
<h2>54. Game Boy Advance Emulator</h2>
<p>Emulate the iconic GBA. You'll learn about CPU architecture, memory, graphics, and input.</p>
<p><img alt="GBA Emulator" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Femu.4e817091.webp&amp;w=640&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Femu.4e817091.webp&amp;w=1080&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Femu.4e817091.webp&amp;w=1080&amp;q=75" width="500" height="363" decoding="async" data-nimg="1" loading="lazy"></p><p><small>It'll be insanely rewarding the moment your first ROM boots up.</small></p>
<p>You can use the <a href="https://problemkaputt.de/gbatek.htm" target="_blank" rel="noopener noreferrer">GBATEK document</a> to get started.</p>
<h2>55. TCP/IP stack</h2>
<p>Implement a minimal userspace TCP/IP stack for Linux based on its core specification. You'll learn network and system programming at a deeper level.</p>
<p>You can get started with IETF's docs on <a href="https://datatracker.ietf.org/doc/html/rfc7414" target="_blank" rel="noopener noreferrer">TCP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc791" target="_blank" rel="noopener noreferrer">IP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc1071" target="_blank" rel="noopener noreferrer">internet checksum</a>, and more.</p>
<h2>56. Lock-Free Data Structures</h2>
<p>Write your own lock-free data structures using atomic primitives. You'll learn a lot about concurrency, memory management, and atomic operations.</p>
<p>Read about the concept <a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm" target="_blank" rel="noopener noreferrer">here</a>, and make sure to run a lot of tests like <a href="https://brilliantsugar.github.io/posts/how-i-learned-to-stop-worrying-and-love-juggling-c++-atomics/" target="_blank" rel="noopener noreferrer">these</a>.</p>
<h2>57. Load Balancer</h2>
<p>Build a program to distribute requests across backend servers, check health, and support sessions. Learn about socket programming, concurrency, and scalable web infrastructure.</p>
<p><img alt="Power of 2 random choices" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fp2.c6335544.png&amp;w=1080&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fp2.c6335544.png&amp;w=1920&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fp2.c6335544.png&amp;w=1920&amp;q=75" width="859" height="425" decoding="async" data-nimg="1" loading="lazy"></p>
<p><a href="https://blog.envoyproxy.io/introduction-to-modern-network-load-balancing-and-proxying-a57f6ff80236" target="_blank" rel="noopener noreferrer">This article</a> is an excellent intro to the topic.</p>
<h2>58. Malloc</h2>
<p>Implement your own version of <code>malloc</code>. Learn how memory allocation works under the hood by working with pointers, heaps, alignment, fragmentation, and system calls.</p>
<p><a href="https://wiki-prog.infoprepa.epita.fr/images/0/04/Malloc_tutorial.pdf" target="_blank" rel="noopener noreferrer">This tutorial</a> by Marwan Burelle is the perfect place to start.</p>
<h2>59. Netflix</h2>
<p>Build an app to host and stream 4k videos by writing a streaming protocol from scratch. You'll learn about file storage, video encoding, adaptive streaming, and scalable content delivery.</p>
<p>This <a href="https://www.youtube.com/watch?v=kCAXpAikMVc" target="_blank" rel="noopener noreferrer">YouTube video</a> provides an overview of how it works.</p>
<h2>60. Smart Home</h2>
<p>Build an app that controls IR appliances and manual switches with device grouping, scheduling, and automation. This project is a mix of embedded systems, app dev, and UI design.</p>
<p><img alt="Smart Home" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsmart.ded8aeb7.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsmart.ded8aeb7.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsmart.ded8aeb7.webp&amp;w=3840&amp;q=75" width="1482" height="1460" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Finally...</small></p>
<p>Watch <a href="https://www.youtube.com/watch?v=y3kPYw9bgBk" target="_blank" rel="noopener noreferrer">this video</a> for some inspiration.</p>
<h2>61. CI System</h2>
<p>Build a Continuous Integration system that watches a Git repo, runs tests in isolated environments, and reports results. You'll learn process orchestration and containerization.</p>
<p>This concise <a href="https://aosabook.org/en/500L/a-continuous-integration-system.html" target="_blank" rel="noopener noreferrer">article</a> will be helpful.</p>
<h2>62. Random Forest</h2>
<p>Implement a decision tree from scratch and use it to solve a binary classification task with random forest. You'll learn information gain, recursive partitioning, and overfitting.</p>
<p>This <a href="https://lethalbrains.com/learn-ml-algorithms-by-coding-decision-trees-439ac503c9a4" target="_blank" rel="noopener noreferrer">blog post</a> covers the basics.</p>
<h2>63. Shell</h2>
<p>Build a shell with command parsing, process execution, piping, redirection, and job control. You'll learn a lot about system programming, memory, and operating systems.</p>
<p><a href="https://aosabook.org/en/v1/bash.html" target="_blank" rel="noopener noreferrer">This article</a> discusses its architecture.</p>
<h2>64. Bitcoin Node</h2>
<p>Build a node that can download and verify blocks from the Bitcoin network. You'll learn about Merkle trees, transactions, Bitcoin's P2P protocol, and more.</p>
<p><img alt="Ape NFT" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fape.3a9b1c8e.webp&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fape.3a9b1c8e.webp&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fape.3a9b1c8e.webp&amp;w=3840&amp;q=75" width="1680" height="1260" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Alternatively, you can use blockchain to sell hyperlinks to png files of apes.</small></p>
<p>You can refer to the Mastering Bitcoin ebook <a href="https://github.com/bitcoinbook/bitcoinbook" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h2>65. Make</h2>
<p>Write a simple <code>make</code> tool that reads a Makefile and builds targets. You'll explore some neat concepts around caching, filesystem, version control, and automation.</p>
<p><a href="https://aegis.sourceforge.net/auug97.pdf" target="_blank" rel="noopener noreferrer">This paper</a> discusses how it works, and also suggests a non-recursive <code>make</code>.</p>
<h2>66. Browser Extension</h2>
<p>Build an extension to store passwords, OTPs, page state, scroll, forms, clipboard history, with auto-fill across sessions. You'll learn DOM inspection, secure storage, and sync protocols.</p>
<p>Start with the official <a href="https://developer.chrome.com/docs/extensions/get-started" target="_blank" rel="noopener noreferrer">Chrome</a> or <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/Your_first_WebExtension" target="_blank" rel="noopener noreferrer">Mozilla</a> docs on extensions.</p>
<h2>67. Stock Trading Bot</h2>
<p>Build a bot that uses trading algorithms to simulate or execute trades. Learn to structure event-driven systems, integrate APIs, and automate decisions under constraints.</p>
<p><img alt="Trump2Cash" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftrump2cash.cc8eb9b6.png&amp;w=1920&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftrump2cash.cc8eb9b6.png&amp;w=3840&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftrump2cash.cc8eb9b6.png&amp;w=3840&amp;q=75" width="1400" height="700" decoding="async" data-nimg="1" loading="lazy"></p><p><small><a href="https://github.com/maxbbraun/trump2cash" target="_blank" rel="noopener noreferrer">Trump2Cash</a> is a bot that monitors Donald Trump's tweets to execute trades on mentioned stocks.</small></p>
<p>For example, <a href="https://ijirt.org/publishedpaper/IJIRT153541_PAPER.pdf" target="_blank" rel="noopener noreferrer">this paper</a> describes one such algorithm you can implement.</p>
<h2>68. Browser Engine</h2>
<p>Build a simple browser that parses HTML/CSS to render text and images. You'll learn tokenization, DOM trees, box models, style cascading, and layout algorithms.</p>
<p><a href="https://limpet.net/mbrubeck/2014/08/08/toy-layout-engine-1.html" target="_blank" rel="noopener noreferrer">This blog series</a> explains the basic concepts.</p>
<h2>69. Automated Journal</h2>
<p>Build a background app that uses your phone's GPS, motion, and mic to identify events and store a journal of your life. You'll learn signal processing, sensor APIs, and background tasks.</p>
<p><a href="https://aosabook.org/en/500L/a-pedometer-in-the-real-world.html" target="_blank" rel="noopener noreferrer">This article</a> offers a glimpse into the experience of working with sensors.</p>
<h2>70. OpenGL</h2>
<p>Build a tiny renderer from scratch. This'll make you a better programmer across the board, and it's a must if you're serious about computer graphics.</p>
<p><img alt="Character Render" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fchar.e11b2b04.webp&amp;w=640&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fchar.e11b2b04.webp&amp;w=1920&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fchar.e11b2b04.webp&amp;w=1920&amp;q=75" width="640" height="671" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Use the renderer to recreate your favorite characters.</small></p>
<p><a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0:-getting-started" target="_blank" rel="noopener noreferrer">Read this wiki</a> to get started.</p>
<h2>71. Laser Tag</h2>
<p>Build a laser tag system with real-time hit detection, wireless comms between guns, and live sync. You'll learn IR encoding, MQTT protocol, and lockstep/event-driven design.</p>
<p><a href="https://hackaday.io/project/160804-lzrtag-flexible-diy-lasertag" target="_blank" rel="noopener noreferrer">This project</a> attempts to do something similar.</p>
<h2>72. Audio Multicast</h2>
<p>Build an audio streaming system from scratch that plays music in sync across multiple devices or speakers. You'll learn low-latency transport, clock sync, buffering, and jitter handling.</p>
<p>Snapcast explains its sync approach <a href="https://github.com/badaix/snapcast?tab=readme-ov-file" target="_blank" rel="noopener noreferrer">here</a>.</p>
<h2>73. Decentralized Internet</h2>
<p>Build a p2p mesh network that routes traffic without ISPs or central servers. You'll learn distributed routing (like BGP for P2P), NAT traversal, and encrypted packet forwarding.</p>
<p><img alt="Decentralized Internet" srcset="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdecentralizedinternet.cac48e04.jpg&amp;w=640&amp;q=75 1x, https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdecentralizedinternet.cac48e04.jpg&amp;w=1920&amp;q=75 2x" src="https://codecrafters.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdecentralizedinternet.cac48e04.jpg&amp;w=1920&amp;q=75" width="613" height="460" decoding="async" data-nimg="1" loading="lazy"></p><p><small>Credit for this idea goes to Richard Hendricks.</small></p>
<p><a href="https://scuttlebot.io/more/protocols/secure-scuttlebutt.html" target="_blank" rel="noopener noreferrer">The Scuttlebutt Protocol</a> and <a href="https://ipfs.tech/" target="_blank" rel="noopener noreferrer">IPFS</a> are great references.</p>
<h2>Final Thoughts</h2>
<p>That's a wrap.</p>
<p>If you do implement anything as a result of this post, or have any feedback on the ideas, <a href="mailto:karan@codecrafters.io" target="_blank" rel="noopener noreferrer">let us know</a>!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NYC Mayoral Inauguration bans Raspberry Pi and Flipper Zero alongside explosives (194 pts)]]></title>
            <link>https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/</link>
            <guid>46438828</guid>
            <pubDate>Tue, 30 Dec 2025 22:28:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/">https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/</a>, See on <a href="https://news.ycombinator.com/item?id=46438828">Hacker News</a></p>
Couldn't get https://blog.adafruit.com/2025/12/30/nyc-mayoral-inauguration-bans-raspberry-pi-and-flipper-zero-alongside-explosives/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Honey's Dieselgate: Detecting and tricking testers (130 pts)]]></title>
            <link>https://vptdigital.com/blog/honey-detecting-testers/</link>
            <guid>46438522</guid>
            <pubDate>Tue, 30 Dec 2025 21:59:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vptdigital.com/blog/honey-detecting-testers/">https://vptdigital.com/blog/honey-detecting-testers/</a>, See on <a href="https://news.ycombinator.com/item?id=46438522">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>MegaLag’s <a href="https://www.youtube.com/watch?v=vc4yL3YTwWk">December 2024 video</a> introduced 18 million viewers to serious questions about Honey, the widely-used browser shopping plug-in—in particular, whether Honey abides by the rules set by affiliate networks and merchants, and whether Honey takes commissions that should flow to other affiliates.&nbsp; I <a href="https://www.benedelman.org/honey-breaches/">wrote</a> in January that I thought Honey was out of line.&nbsp; In particular, I pointed out the contracts that limit when and how Honey may present affiliate links, and I applied those contracts to the behavior MegaLag documented. &nbsp;Honey was plainly breaking the rules.</p><p>As it turns out, Honey’s misconduct is considerably worse than MegaLag, I, or others knew.&nbsp; When Honey is concerned that a user may be a tester—a “network quality” employee, a merchant’s affiliate manager, an affiliate, or an enthusiast—Honey designs its software to honor stand down in full.&nbsp; But when Honey feels confident that it’s being used by an ordinary user, Honey defies stand down rules.&nbsp; Multiple methods support these conclusions: I extracted source code from Honey’s browser plugin and studied it at length, plus I ran Honey through a packet sniffer to collect its config files, and I cross-checked all of this with actual app behavior.&nbsp; Details below.&nbsp; MegaLag tested too, and has a <a href="https://www.youtube.com/watch?v=qCGT_CKGgFE">new video</a> with his updated assessment.</p><p>(A note on our relationship: MegaLag figured out most of this, but asked me to check every bit from first principles, which I did.&nbsp; &nbsp;I added my own findings and methods, and cross-checked with VPT records of prior observations as well as historic Honey config files.&nbsp; More on that below, too.)</p><p>Behaving better when it thinks it’s being tested, Honey follows in Volkswagen’s “<a href="https://en.wikipedia.org/wiki/Volkswagen_emissions_scandal">Dieselgate</a>” footsteps.&nbsp; Like Volkswagen, the cover-up is arguably worse than the underlying conduct.&nbsp; Facing the allegations MegaLag presented last year, Honey could try to defend presenting its affiliate links willy-nilly—argue users want this, claim to be saving users money, suggest that network rules don’t apply or don’t mean what they say.&nbsp; But these new allegations are more difficult to defend.&nbsp; Designing its software to perform differently when under test, Honey reveals knowing what the rules require and knowing they’d be in trouble if caught.&nbsp; Hiding from testers reveals that Honey wanted to present affiliate links as widely as possible, despite the rules, so long as it doesn’t get caught.&nbsp; It’s not a good look.&nbsp; Affiliates, merchants, and networks should be furious.</p><h2>What the rules require</h2><p>The basic bargain of affiliate marketing is that a publisher presents a link to a user, who clicks, browses, and buys.&nbsp; If the user makes a purchase, commission flows to the publisher whose link was last clicked.</p><p>Shopping plugins and other client-side software undermine the basic bargain of affiliate marketing.&nbsp; If a publisher puts software on a user’s computer, that software can monitor where the user browses, present its affiliate link, and always (appear to) be “last”—even if it had minimal role in influencing the customer’s purchase decision.</p><p>Affiliate networks and merchants established rules to restore and preserve the bargain between what we might call “web affiliates” versus software affiliates.&nbsp; One, a user has to actually click a software affiliate’s link; decades ago, auto-clicks were common, but that’s long-since banned (yet nonetheless routine from “adware”-style browser plugins—&nbsp; <a href="https://vptdigital.com/blog/how-adware-manipulates-attribution-to-monetize-a-merchants-own-traffic/">example</a>).&nbsp; Two, software must “stand down”—must not even show its link to users—when some prior web affiliate P has already referred a user to a given merchant.&nbsp; This reflects a balancing of interests: P wants a reasonable opportunity for the user to make a purchase, so P can get paid.&nbsp; If a shopping plugin could always present its offer, the shopping plugin would claim the commission that P had fairly earned.&nbsp; Meanwhile P wouldn’t get sufficient payment for its effort—and might switch to promoting some other merchant with rules P sees as more favorable.&nbsp; Merchants and networks need to maintain a balance in order to attract and retain web affiliates, which are understood to send traffic that’s substantially incremental (customers who wouldn’t have purchased anyway), whereas shopping plugins often take credit for nonincremental purchases.&nbsp; So if a merchant is unsure, it has good reason to err on the side of web affiliates.</p><p>All of this was known and understood literally decades ago.&nbsp; Stand-down rules were <a href="https://www.cumbrowski.com/CodeOfConduct.asp">first established in 2002</a>.&nbsp; Since then, they’ve been increasingly routine, and overall have become clearer and better enforced.&nbsp; Crucially, merchants and networks include stand-down rules in their contracts, making this not just a principle and a norm, but a binding contractual obligation.</p><h2>Detecting testers</h2><p>How can Honey tell when a user may be a tester?&nbsp; Honey’s code and config files show that they’re using four criteria:</p><ul><li>New accounts. If an account is less than 30 days old, Honey concludes the user might be a tester, so it disables its prohibited behavior.</li><li>Low earnings-to-date. In general, under Honey’s current rules, if an account has less than 65,000 points of Honey earning, Honey concludes the user might be a tester, so it disables its prohibited behavior.&nbsp; Since 1,000 points can be redeemed for $10 of gift cards, this threshold requires having earned $650 worth of points.&nbsp; That sounds like a high requirement, and it is.&nbsp; But it’s actually relatively new: As of June 2022, there was no points requirement for most merchants, and for merchants in Rakuten Advertising, the requirement was just 501 points (about $5 of points).&nbsp; (<a href="#changeovertime">Details below</a>.)</li><li>Honey periodically checks a server-side blacklist.&nbsp; The server can condition its decision on any factor known to the server, including the user’s Honey ID and cookie, or IP address inside a geofence or on a ban list. &nbsp;Suppose the user has submitted prior complaints about Honey, as professional testers frequently do.&nbsp; Honey can blacklist the user ID, cookie, and IP or IP range.&nbsp; Then any further requests from that user, cookie, or IP will be treated as high-risk, and Honey disables its prohibited behavior.</li><li>Affiliate industry cookies. Honey checks whether a user has cookies indicating having logged into key affiliate industry tools, including the CJ, Rakuten Advertising, and Awin dashboards.&nbsp; If the user has such a cookie, the user is particularly likely to be a tester, so Honey disables its prohibited behavior.</li></ul><p>If even one of these factors indicates a user is high-risk, Honey honors stand-down.&nbsp; But if all four pass, then Honey ignores stand-down rules and presents its affiliate links regardless of a prior web publisher’s role and regardless of stand-down rules.&nbsp; This isn’t a probabilistic or uncertain dishonoring of stand-down (as plaintiffs <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.441974/gov.uscourts.cand.441974.161.0.pdf#page=34">posited</a> in <a href="https://www.courtlistener.com/docket/69503243/in-re-paypal-honey-browser-extension-litigation/?page=1">litigation against Honey</a>).&nbsp; Rather, Honey’s actions are deterministic: If a high-risk factor hits, Honey will <em>completely</em> and <em>in every instance</em> honor stand-down; and if no such factor hits, then Honey will <em>completely</em> and <em>in every instance</em> dishonor stand-down (meaning, present its link despite networks’ rules).</p><p>These criteria indicate Honey’s attempt to obstruct and frankly frustrate testers.&nbsp; In my experience from two decades of testing affiliate misconduct, it is routine for a tester to install a new shopping plugin on a new PC, create a new account, and check for immediate wrongdoing.&nbsp; By always standing down on new accounts (&lt;30 days), Honey prevents this common test scenario from catching its stand-down violations.&nbsp; Of course diligent testers will check way past 30 days, but a tester on a short-term contract will perceive nothing amiss.&nbsp; Some clients may not pay for testers to stick with the task.&nbsp; And a client for some reason needing an immediate finding—perhaps to dispute Honey’s recent earnings—can’t get it.</p><p>The requirement of achieving sufficiently many points similarly stymies many testers.&nbsp; Over the years, a handful of my clients granted a budget for test purchases.&nbsp; But most did not.&nbsp; If I wanted to perform test purchases, I would have needed to spend my own money.&nbsp; Meanwhile, there’s no proper reason why a shopping app should stand down differently for users with points versus new users, so if testers assumed good faith by Honey, they’d have no reason to build up a points history.&nbsp; This criteria certainly prevented testers from uncovering what Honey was doing.</p><p>The interaction of account age, points history, and blacklist further stymies testing.&nbsp; Once a tester reports a specific observation of misconduct, Honey can blacklist the tester’s account—which will still do most things normally, but will begin to stand down even though unbanned accounts don’t stand down in the same circumstances.&nbsp; A tester who suspected this, would have to create a new account, wait 30 days, and build up a sizable points balance to see what Honey is actually doing for other users. &nbsp;That’s a genuine barrier, impeding even a tester who correctly proposes this hypothesis.</p><p>Honey’s detection of affiliate industry cookies is particularly revealing and, in my view, devastatingly incriminating.&nbsp; Maybe Honey could concoct a story about why it stands down less for established accounts and for high-points-earners.&nbsp; It would be a tall tale, but maybe Honey could convince some people.&nbsp; In contrast, it is inconceivable why a shopping plugin should care whether a user previously logged into an affiliate dashboard.&nbsp; There’s &nbsp;only one reason to check: to hide from testers.&nbsp; But that reveals Honey’s intent and Honey’s knowledge that its conduct is prohibited.</p><h2 id="handson">Evidence from hands-on testing</h2><p>Multiple forms of evidence support my finding of Honey detecting testers.&nbsp; First, consider hands-on testing.&nbsp; With a standard test account with few or no points, Honey honored stand-down.&nbsp; See <a href="https://vptdigital.com/wp-content/uploads/2026/12/v1-affillink-sharperimage-lowpoints-standdown-fiddler-2025-11-14b.mp4" data-fancybox="">video 1</a>.&nbsp; But when I tricked the Honey plugin into thinking I had tens of thousands of points (<a href="#testingmethods">details below about how I did this</a>), Honey popped up despite stand-down rules.&nbsp; See <a href="https://vptdigital.com/wp-content/uploads/2026/12/v2-affillink-sharperimage-highpoints-nostanddown-fiddler-2025-11-15.mp4" data-fancybox="">video 2</a>.&nbsp; I repeated this test over multiple days, as to multiple merchants.&nbsp; The finding was the same every time.&nbsp; The only thing I changed between the “video 1” tests and “video 2” tests was the number of points supposedly associated with my account.</p><p>To demonstrate Honey checking for affiliate industry cookies, I added a step to my test scenario. With Honey tricked into thinking I had ample points, same as video 2, I began a test run by logging into a CJ portal used by affiliates.&nbsp; In all other respects, my test run was the same as video 2.&nbsp; Seeing the CJ portal cookie, Honey stood down.&nbsp; See <a href="https://vptdigital.com/wp-content/uploads/2026/12/v3-affillink-console-sharperimage-highpoints-standdown-fiddler-2025-11-16.mp4" data-fancybox="">video 3</a>.</p><h2>Evidence from technical analysis</h2><p>Some might ask whether the findings in the prior section could be coincidence.&nbsp; Maybe Honey just happened to open in some scenarios and not others.&nbsp; Maybe I’m ascribing intentionality to acts that are just coincidence.&nbsp; Let me offer two responses to this hypothesis.&nbsp; One, my findings are repeatable, countering any claim of coincidence.&nbsp; Second, separate from hands-on testing, three separate types of technical analysis—config files, telemetry, and source code—all confirm the accuracy of the prior section.</p><h2 id="configfiles">Evidence from configuration files</h2><p>Honey retrieves its configuration settings from JSON files on a Honey server. Honey’s core stand-down configuration is in <a href="https://cdn.honey.io/standdown-rules.json">standdown-rules.json</a>, while the selective stand-down—declining to stand down according to the criteria described above—is in the separate config file <a href="https://cdn.honey.io/ab/ssd.json">ssd.json</a>.&nbsp; Here’s the contents of ssd.json as of October 22, 2025, with // comments added by me</p><pre>{"ssd": {
"base": {
	"gca": 1, //enable affiliate console cookie check
	"bl": 1,  //enable blacklist check
   <span>"uP":</span> <span>65000</span>, //min points to disable standdown
  	"adb": 26298469858850
	},
	<span>"affiliates": ["https://www.cj.com", "https://www.linkshare", "https://www.rakuten.com", "https://ui.awin.com", "https://www.swagbucks.com"]</span>, //affiliate console cookie domains to check
	"LS": { //override points threshold for LinkShare merchants
		"uP": 5001
	},
	"PAYPAL": {
		"uL": 1,
		"uP": 5000001,
		"adb": 26298469858850
	}
   },
	<span>"ex"</span>: { //ssd exceptions
		"7555272277853494990": {  //TJ Maxx
			"uP": 5001
		},
		"7394089402903213168": { //booking.com
			"uL": 1,
			"adb": 120000,
			"uP": 1001
		},
		"243862338372998182": { //kayosports
			"uL": 0,
			"uP": 100000
		},
		"314435911263430900": {
			"adb": 26298469858850
		},
		"315283433846717691": {
			"adb": 26298469858850
		},
		<span>"GA": ["CONTID", "s_vi", "_ga", "networkGroup", "_gid"]</span> //which cookies to check on affiliate console cookie domains
	}
}</pre><p>On its own, the ssd config file is not a model of clarity.&nbsp; But source code (discussed below) reveals the meaning of abbreviations in ssd.&nbsp; <span>uP</span> (yellow) refers to user points—the minimum number of points a user must have in order for Honey to dishonor stand-down.&nbsp; Note the current <span>base</span> (default) requirement of <span>uP</span> user points at least 65,000 (green), though the subsequent section <span>LS</span> sets a lower threshold of just 5001 for merchants on the Rakuten Advertising (LinkShare) network.&nbsp; <span>bl</span> set to <span>1</span> instructs the Honey plugin to stand down if the server-side blacklist so instructs.</p><p>Meanwhile, the <span>affiliates</span> and <span>ex GA</span> data structures (blue), establish the affiliate industry cookie checks mentioned above.&nbsp; The “affiliates” entry lists domain where cookies are to be checked.&nbsp; The <span>ex GA</span> data structure lists which cookie is to be checked for each domain.&nbsp; Though these are presented as two one-dimensional lists, Honey’s code actually checks them in conjunction – checks the first-listed affiliate network domain for the first-listed cookie, then the second, and so forth.&nbsp; One might ask why Honey stored the domain names and cookie names in two separate one-dimensional lists, rather than in a two-dimensional list, name-value pair, or similar.&nbsp; The obvious answer is that Honey’s approach kept the domain names more distant from the cookies on those domains, making its actions that much harder for testers to notice even if they got as far as this config file.</p><p>The rest of <span>ex</span> (red) sets exceptions to the standard (“base”) ssd.&nbsp; This lists five specific ecommerce sites (each referenced with an 18-digit ID number previously assigned by Honey) with adjusted ssd settings.&nbsp; For Booking.com and Kayosports, the ssd exceptions set even higher points requirements to cancel standdown (120,000 and 100,000 points, respectively), which I interpret as response to complaints from those sites.</p><h2 id="telemetry">Evidence from telemetry</h2><p>Honey’s telemetry is delightfully verbose and, frankly, easy to understand, including English explanations of what data is being collected and why.&nbsp; Perhaps Google demanded improvements as part of approving Honey’s submission to Chrome Web Store.&nbsp; (Google <a href="https://developer.chrome.com/docs/webstore/program-policies/policies">enforces</a> what it calls “strict guidelines” for collecting user data.&nbsp; <a href="https://developer.chrome.com/docs/webstore/program-policies/user-data-faq">Rule 12</a>: data collection must be “necessary for a user-facing feature.”&nbsp; The English explanations are most consistent with seeking to show Google that Honey’s data collection is proper and arguably necessary.)&nbsp; Meanwhile, Honey submitted much the same code to Apple as an iPhone app, and Apple is known to be quite strict in its app review.&nbsp; Whatever the reason, Honey telemetry reveals some important aspects of what it is doing and why.</p><p>When a user with few points gets a stand-down, Honey reports that in telemetry with the JSON data structure <span>“method”:”suspend”</span>.&nbsp; Meanwhile, the nearby JSON variable <span>state</span> gives the specific ssd requirement that the user didn’t satisfy—in my video 1: <span>“state”:”uP:5001”</span> reporting that, in this test run, my Honey app had less than 5001 points, and the ssd logic therefore decided to stand down.&nbsp; See video 1 at 0:37-0:41, or screenshots below for convenience.&nbsp; (My network tracing tool converted the telemetry from plaintext to a JSON tree for readability.)</p><p><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMjQiIGhlaWdodD0iMzkiIHZpZXdCb3g9IjAgMCAzMjQgMzkiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNjZmQ0ZGI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" decoding="async" data-src="https://vptdigital.com/wp-content/uploads/2026/12/honey1.png" alt="Fiddler reference to Honey telemetry transmission" width="324" height="39" data-srcset="https://vptdigital.com/wp-content/uploads/2026/12/honey1.png 324w, https://vptdigital.com/wp-content/uploads/2026/12/honey1-300x36.png 300w" data-sizes="(max-width: 324px) 100vw, 324px"></p><p><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2MjQiIGhlaWdodD0iNTgiIHZpZXdCb3g9IjAgMCA2MjQgNTgiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNjZmQ0ZGI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" decoding="async" data-src="https://vptdigital.com/wp-content/uploads/2026/12/honey2.png" alt="Fiddler decodes Honey JSON telemetry reporting standdown (&quot;method=suspend&quot;)" width="624" height="58" data-srcset="https://vptdigital.com/wp-content/uploads/2026/12/honey2.png 624w, https://vptdigital.com/wp-content/uploads/2026/12/honey2-300x28.png 300w" data-sizes="(max-width: 624px) 100vw, 624px"></p><p><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI5MiIgaGVpZ2h0PSIxNSIgdmlld0JveD0iMCAwIDkyIDE1Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" decoding="async" data-src="https://vptdigital.com/wp-content/uploads/2026/12/honey3.png" alt="Fiddler decodes Honey JSON telemetry reporting the reason for stand-down, namely insufficient points (&quot;uP&quot;), less than the 5001 threshold applicable for this network" width="92" height="15"></p><p>When I gave myself more points (video 2), <span>state</span> instead reported <span>ssd</span>—indicating that all ssd criteria were satisfied, and Honey presented its offer and did not stand down.&nbsp; See <a href="https://vptdigital.com/wp-content/uploads/2026/12/v2-affillink-sharperimage-highpoints-nostanddown-fiddler-2025-11-15.mp4" data-fancybox="">video 2</a> at 0:32.</p><p><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI2NSIgaGVpZ2h0PSIxNiIgdmlld0JveD0iMCAwIDY1IDE2Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" loading="lazy" decoding="async" data-src="https://vptdigital.com/wp-content/uploads/2026/12/honey4.png" alt="Fiddler decodes Honey JSON telemetry reporting the decision not to stand down (&quot;state=ssd&quot;)" width="65" height="16"></p><p>Finally, when I browsed an affiliate network console and allowed its cookie to be placed on my PC, Honey telemetry reported <span>“state”:“gca”</span>.&nbsp; Like <a href="https://vptdigital.com/wp-content/uploads/2026/12/v1-affillink-sharperimage-lowpoints-standdown-fiddler-2025-11-14b.mp4" data-fancybox="">video 1</a>, the state value reports that ssd criteria were not satisfied, in this case because the gca (affiliate dashboard cookie) requirement was triggered, causing ssd to decide to stand down.&nbsp; See <a href="https://vptdigital.com/wp-content/uploads/2026/12/v3-affillink-console-sharperimage-highpoints-standdown-fiddler-2025-11-16.mp4" data-fancybox="">video 3</a> at 1:04-1:14.</p><p data-wp-editing="1"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MSIgaGVpZ2h0PSIxNyIgdmlld0JveD0iMCAwIDgxIDE3Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojY2ZkNGRiO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" loading="lazy" decoding="async" data-src="https://vptdigital.com/wp-content/uploads/2026/12/honey5.png" alt="Fiddler decodes Honey JSON telemetry reporting gca=1, meaning that an affiliate network console cookie was detected." width="81" height="17"> <img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMDciIGhlaWdodD0iMzEiIHZpZXdCb3g9IjAgMCAxMDcgMzEiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNjZmQ0ZGI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" loading="lazy" decoding="async" data-src="https://vptdigital.com/wp-content/uploads/2026/12/honey6.png" alt="" width="107" height="31"></p><p>In each instance, the telemetry matched identifiers from the config file (<span>ssd</span>, <span>uP</span>, <span>gca</span>).&nbsp; And as I changed from one test run to another, the telemetry transmissions tracked my understanding of Honey’s operation.&nbsp; Readers can check this in my videos: After Honey does or doesn’t stand down, I opened Fiddler to show what Honey reported in telemetry, in each instance in one continuous video take.</p><h2>Evidence from code</h2><p>As a browser extension, Honey provides client-side code in JavaScript.&nbsp; Google’s <a href="https://developer.chrome.com/docs/webstore/program-policies/code-readability">Code Readability Requirements</a> allow minification—removing whitespace, shortening variable and function names.&nbsp; Honey’s code is substantial—after deminification, more than 1.5 million lines.&nbsp; But a diligent analyst can still find what’s relevant.&nbsp; In fact the relevant parts are clustered together, and easily found via searches for obvious string such as “ssd”.</p><p>In a surprising twist, Honey in one instance released something approaching original code to Apple as&nbsp; an iPhone app.&nbsp; In particular, Honey included <span>sourceMappingURL</span> metadata that allows an analyst to recover original function names and variable names.&nbsp; (<a href="https://stackoverflow.com/questions/32162445/recover-javascript-source-code-from-uglifyjs-source-map">Instructions</a>.)&nbsp; That release was from a moment in time, and Honey subsequently made revisions.&nbsp; But where that code is substantially the same as the code currently in use, I present the unobfuscated version for readers’ convenience.&nbsp; Here’s how it works:</p><p>First, there’s setup, including periodically checking the Honey killswitch URL <span>/ck/alive</span>:</p><pre>return e.next = 7, fetch("".concat("https://s.joinhoney.com", "/ck/alive"));</pre><p>If the killswitch returns “alive”, Honey sets the <span>bl</span> value to <span>0</span>:</p><pre>c = S().then((function(e) {
    e &amp;&amp; "alive" === e.is &amp;&amp; (o.bl = 0)
}))</pre><p>The ssd logic later checks this variable <span>bl</span>, among others, to decide whether to cancel standdown.</p><p>The core ssd logic is in a long function called <span>R()</span> which runs an infinite loop with a <span>switch</span> syntax to proceed through a series of numbered cases.</p><pre>function(e) {
for (;;) switch (e.prev = e.next) {</pre><p>Focusing on the sections relevant to the behavior described above: Honey makes sure the user’s email address doesn’t include the string “test”, and checks whether the user is on the killswitch blacklist.</p><pre>if (r.email &amp;&amp; r.email.match("test") &amp;&amp; (o.bl = 0), !r.isLoggedIn || t) {
  e.next = 7;
  break</pre><p>Honey computes the age of the user’s account by subtracting the account creation date (<span>r.created</span>) from the current time:</p><pre>case 8:
  o.uL = r.isLoggedIn ? 1 : 0, o.uA = Date.now() - r.created;</pre><p>Honey checks for the most recent time a resource was blocked by an ad blocker:</p><pre>case 20:
  return p = e.sent, l &amp;&amp; a.A.getAdbTab(l) ? o.adb = a.A.getAdbTab(l) : a.A.getState().resourceLastBlockedAt &gt; 0 ? o.adb = a.A.getState().resourceLastBlockedAt : o.adb = 0</pre><p>Honey checks whether any of the affiliate domains listed in the ssd <span>affiliates</span> data structure has the console cookie named in the GA data structure.</p><pre>m = p.ex &amp;&amp; p.ex.GA || []
g = i().map(p.ssd &amp;&amp; p.ssd.affiliates, (function(e) {
            return f += 1, u.A.get({
                name: m[f], //cookie name from GA array
                url: e  //domain to be checked
            }).then((function(e) {
                e &amp;&amp; (o.gca = 0) //if cookie found, set gca to 0
            }))</pre><p>Then the comparison function <span>P()</span> compares each retrieved or calculated value to the threshold from <span>ssd.json</span>.&nbsp; The fundamental logic is that if any retrieved or calculated value (received in variable <span>e</span> below) is less than the threshold <span>t</span> from <span>ssd</span>, the ssd logic will honor standdown.&nbsp; In contrast, if all four values exceed the threshold, ssd will cancel the standdown.&nbsp; If this function elects to honor standdown, the return value gives the name of the rule (<span>a</span>) and the threshold (<span>s</span>) that caused the decision (yellow highlighting).&nbsp; If this function elects to dishonor standdown, it returns <span>“ssd”</span> (red) (which is the function’s default if not overridden by the logic that folllows).&nbsp; This yields the <span>state=</span> values I showed in <a href="#telemetry">telemetry</a> and <a href="#handson">presented in screenshots and videos above</a>.</p><pre>function P(e, t) {
    var <span>r = "ssd"</span>;
    return Object.entries(t).forEach((function(t) {
        var n, o, i = (o = 2, _(n = t) || b(n, o) || y(n, o) || g()),
            a = i[0],  // field name (e.g., uP, gca, adb)
            s = i[1];  // threshold value from ssd.json
        "adb" === a &amp;&amp; (s = s &gt; Date.now() ? s : Date.now() - s),  // special handling for adb timestamps
        void 0 !== e[a] &amp;&amp; e[a] &lt; s &amp;&amp; <span>(r = "".concat(a, ":").concat(s))</span>  
    })), r
}</pre><h2>Special treatment of eBay</h2><p>Reviewing both config files and code, I was intrigued to see eBay called out for greater protections than others.&nbsp; Where Honey stands down for other merchant and networks for 3,600 seconds (one hour), eBay gets 86,400 seconds (24 hours).</p><pre>"regex": "^https?\\:\\/\\/rover\\.ebay((?![\\?\\&amp;]pub=5575133559).)*$",
"provider": "LS",
"overrideBl": true,
"ttl": 86400</pre><p>Furthermore, Honey’s code includes an additional eBay backstop.&nbsp; No matter what any config file might stay, Honey’s ssd selective stand-down logic will always stand down on ebay.com, even if standard ssd logic and config files would otherwise decide to disable stand-down.&nbsp; See this hard-coded eBay stand-down code:</p><pre>...
const r = e.determineSsdState ? await e.determineSsdState(_.provider, v.id, i).catch() : null,
a = "ssd" === r &amp;&amp; !/ebay/.test(p);
...
</pre><p>Why such favorable treatment of eBay?&nbsp; Affiliate experts may remember the <a href="https://www.benedelman.org/affiliate-litigation/#hogandunning">2008 litigation in which eBay and the United States brought civil and criminal charges against Brian Dunning and Shawn Hogan</a>, who were previously eBay’s two largest affiliates—jointly paid more than $20 million in just 18 months.&nbsp; I was proud to have caught them—a fact I can only reveal because <a href="https://www.benedelman.org/affiliate-litigation/hogan-opp-suppress-exhibit1.pdf#page=35">an FBI agent’s declaration credited me</a>.&nbsp; After putting its two largest affiliates in jail and demanding repayment of all the money they hadn’t spent or lost, eBay got a well-deserved reputation for being smart and tough at affiliate compliance.&nbsp; Honey is right to want to stay on eBay’s good side.&nbsp; At the same time, it’s glaring to see Honey treat eBay so much better than other merchants and networks.&nbsp; Large merchants on other networks could look at this and ask: If eBay get a 24 hour stand-down and a hard-coded ssd exception, why are they treated worse?</p><h2 id="changeovertime">Change over time</h2><p>I mentioned above that I have historic config files.&nbsp; First, VPT (the affiliate marketing compliance company where I am Chief Scientist) preserved a ssd.json from June 2022.&nbsp; As of that date, Honey ssd had no points requirement for most networks.&nbsp; See yellow “base” below, notably in this version including a <span>uP</span> section.&nbsp; For LinkShare (Rakuten Advertising), the June 2022 ssd file required 501 points (green), equal to about $5 of earning to date.</p><pre>{"ssd": {
	<span>"base": {"gca": 1, "bl": 1}</span>,
	"affiliates": ["https://www.cj.com", "https://www.linkshare", "https://www.rakuten.com", "https://ui.awin.com", "https://www.swagbucks.com"],
	<span>"LS"</span>: {"uL": 1, "uA": 2592000, <span>"uP": 501</span>, "SF": {"uP": 200} }, ...
</pre><p>In April 2023, <a href="https://web.archive.org/web/20230414052839/https:/cdn.honey.io/ab/ssd.json">Archive.org preserved ssd.json</a>, with the same settings.</p><p>Notice the changes from 2022-2023 to the present—most notably, a huge increase in points required for Honey to not stand-down.&nbsp; The obvious explanation for the change is MegaLag’s December 2024 video, and resulting litigation, which brought new scrutiny to whether Honey honors stand-down.</p><p>A second relevant change is that, as of 2022-2023, the ssd.json included a <span>uA</span> setting for LinkShare, requiring an account age of at least 2,592,000 seconds (30 days).&nbsp; But the current version of ssd.json has no <span>uA</span> setting, not for LinkShare merchants nor for any other merchants.&nbsp; Perhaps Honey thinks the high points requirement (65,000) now obviates the need for a 30-day account age.</p><p>In litigation, plaintiffs should be able to obtain copies of Honey config files indicating when the points requirement increased, and for that matter management discussions about whether and why to make this change.&nbsp; If the config files show ssd in similar configuration from 2022 through to fall 2024, but cutoffs increased shortly after MegaLag’s video, it will be easy to infer that Honey reduced ssd, and increased standdown, after getting caught.</p><p>Despite Honey’s recently narrowing ssd to more often honor stand-down, this still isn’t what the rules require.&nbsp; Rather than comply in full, Honey continued not to comply for the highest-spending users, those with &gt;65k points—who Honey seems to figure must be genuine users, not testers or industry insiders.</p><h3 id="tensionsrakuten">Tensions between Honey and LinkShare (Rakuten Advertising)</h3><p>Honey’s LinkShare exception presents a puzzle. &nbsp;In 2022 and 2023, Honey was <em>stricter</em> for LinkShare merchants—more often honoring stand-down, and dishonoring stand-down only for users with at least 501 points. &nbsp;But in the current configuration, Honey applies a <em>looser</em> standard for LinkShare merchants: Honey now dishonors LinkShare stand-down once a user has 5,001 points, compared to the much higher 65,000-point requirement for merchants on other networks. &nbsp;What explains this reversal?&nbsp; Honey previously wanted to be extra careful for LinkShare merchants—so why now be <em>less</em> careful?</p><p>The best interpretation is a two-step sequence. &nbsp;First, at some point Honey raised the LinkShare threshold from 501 to 5,001 points—likely in response to a merchant complaint or LinkShare network quality concerns. &nbsp;Second, when placing that LinkShare-specific override into ssd.json, Honey staff didn’t consider how it would interact with later global rules—especially since the overall points requirement (<span>base uA</span>) didn’t yet exist. &nbsp;Later, MegaLag’s video pushed Honey to impose a 65,000-point threshold for dishonoring stand-down across <em>all</em> merchants—and when Honey staff imposed that new rule, they overlooked the lingering LinkShare override. A rule intended to be <em>stricter</em> for LinkShare now inadvertently makes LinkShare <em>more permissive</em>.</p><h2>Reflections on hiding from testers</h2><p>In a broad sense, the closest analogue to Honey’s tactics is Volkswagen Dieselgate&nbsp; Recall the 2015 discovery that Volkswagen programmed certain diesel engines to activate their emission controls only during laboratory testing, but not in real-world driving.&nbsp; Revelation of Volkswagen’s misconduct led to the resignation of Volkswagen’s CEO.&nbsp; Fines, penalties, settlements, and buyback costs exceeded $33 billion.</p><p>In affiliate marketing, numbers are smaller, but defeating testing is, regrettably, more common.&nbsp; For decades I’ve been <a href="https://www.benedelman.org/cookiestuffing/">tracking cookie-stuffers</a>, which routinely use tiny web elements (1×1 <span>IFRAME</span>s and <span>IMG</span> tags) to load affiliate cookies, and sometimes further conceal those elements using CSS such as <span>visibility:none</span>.&nbsp; Invisibility quite literally conceals what occurs.&nbsp; In parallel, affiliates also deployed additional concealment methods.&nbsp; Above, I mentioned Dunning and Hogan, who concealed their miscondudct in two additional ways.&nbsp; First, they stuffed each IP address at most once.&nbsp; Consider a researcher who suspected a problem, but didn’t catch it the first time.&nbsp; (Perhaps the screen-recorder and packet sniffer weren’t running.&nbsp; Or maybe this happened on a tester’s personal machine, not a dedicated test device.)&nbsp; With a once-per-IP-address rule, the researcher couldn’t easily get the problem to recur.&nbsp; (Source: <a href="https://www.benedelman.org/affiliate-litigation/ebay-digitalpoint-hogan-kessler-thunderwood-dunning-complaint.pdf#page=8">eBay complaint</a>, paragraph 27: “… only on those computers that had not been previously stuffed…”)&nbsp; Second, they geofenced eBay and CJ headquarters. (<a href="https://www.benedelman.org/affiliate-litigation/ebay-digitalpoint-hogan-kessler-thunderwood-dunning-complaint.pdf#page=8">Source</a>.) &nbsp;Shawn Hogan even <a href="https://web.archive.org/web/20130321093705/https:/shawnhogan.com/2010/08/what-does-carmen-electra-cyber-terrorism-and-meg-whitman-have-in-common-ebay.html#:~:text=blanket%20filter%20(via-,geo%2Dtargeting,-)%20the%20area%20were">admitted</a> intentionally not targeting the geographic areas where he thought I might go.&nbsp; Honey’s use of a server-side blacklist allows similar IP filtering and geofencing, as well as more targeted filtering such as always standing down for the specific IPs, cookies, and accounts that previously submitted complaints.</p><p>A <a href="https://www.brandverity.com/blog/395/affiliate-tactics-css-history-hack/">2010 blog</a> from affiliate trademark testers BrandVerity uncovered an anti-test strategy arguably even closer to what Honey is doing.&nbsp; In this period, <a href="https://en.wikipedia.org/wiki/History_sniffing">history sniffing vulnerabilities</a> let web sites see what other pages a user had visited: Set visited versus unvisited links to different colors, link to a variety of pages, and check the color of each link.&nbsp; BV’s perpetrator used this tactic to see whether a user had visited tools used by affiliate compliance staff (BV’s own login page, LinkShare’s dashboard and internal corporate email, and ad-buying dashboards for Google and Microsoft search ads).&nbsp; If a user had visited any of these tools, the perpetrator would not invoke its affiliate link—thereby avoiding revealing its prohibited behavior (trademark bidding) to users who were plainly affiliate marketing professionals.&nbsp; For other users, the affiliate bid on prohibited trademark terms and invoked affiliate links. &nbsp;Like Honey, this affiliate distinguished normal users from industry insiders based on prior URL visits.&nbsp; Of course Honey’s superior position, as a browser plugin, lets it directly read cookies without resorting to CSS history.&nbsp; But that only makes Honey worse.&nbsp; No one defended the affiliate BV caught, and I can’t envision anyone defending Honey’s tactic here.</p><p>In a slightly different world, it might be considered part of the rough-and-tumble world of commerce that Honey sometimes takes credit for referrals that others think should accrue to them.&nbsp; (In fact, that’s <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.441974/gov.uscourts.cand.441974.204.0.pdf">an argument Honey recently made</a> in litigation: “any harm [plaintiffs] may have experienced is traceable not to Honey but to the industry standard ‘last-click’ attribution rules.”)&nbsp; There, Honey squarely ignores network rules, which require Honey to stand down although MegaLag showed Honey does not.&nbsp; But if Honey just ignored network stand-down rules, brazenly, it could push the narrative that networks and merchants agreed since, admittedly, they didn’t stop Honey.&nbsp; By hiding, Honey instead reveals that they know their conduct is prohibited.&nbsp; When we see networks and merchants that didn’t ban Honey, the best interpretation (in light of Honey’s trickery) is not that they <em>approved</em> of Honey’s tactics, but rather that Honey’s concealment <em>prevented them from figuring out</em> what Honey was doing.&nbsp; And the effort Honey expended, to conceal its behavior from industry insiders, makes it particularly clear that Honey knew it would be in trouble if it was caught.&nbsp; Honey’s knowledge of misconduct is precisely opposite to its media response to MegaLag’s video, and equally opposite to its position in litigation.</p><p>Five years ago Amazon <a href="https://www.wired.com/story/amazon-honey-security-warning/">warned</a> shoppers that Honey was a “security risk.”&nbsp; At the time, I wrote this off as sour grapes—a business dispute between two goliaths.&nbsp; I agreed with Amazon’s bottom line that Honey was up to no good, but I thought the real problems with Honey were harm to other affiliates and harm to merchants’ marketing programs, not harms to security.&nbsp; With the passage of time, and revelation of Honey’s tactics including checking other companies’ cookies and hiding from testers, Amazon is vindicated.&nbsp; Notice Honey’s excessive permission—which includes letting Honey read users’ cookies at all sites.&nbsp; That’s well beyond what a shopping assistant truly needs, and it allows all manner of misconduct including, unfortunately, what I explain above.&nbsp; Security risk, indeed.&nbsp; Kudos to Amazon for getting this right from the outset.</p><p>At VPT, we <a href="https://vptdigital.com/shopping-plugins/">monitor shopping plugins</a> for abusive behavior.&nbsp; We hope shopping plugins will behave forthrightly—doing the same thing in our test lab that they do for users.&nbsp; But we don’t assume it, and we have multiple strategies to circumvent the techniques that bad actors use to trick those monitoring their methods.&nbsp; We constantly iterate on these approaches as we find new ways of concealment.&nbsp; And when we catch a shopping plugin hiding from us, we alert our clients not just to their misconduct but also to their concealment—an affirmative indication that this plugin can’t be trusted.&nbsp; We have scores of historic test runs showing misconduct by Honey in a variety of configurations, targeting dozens of merchants on all the big networks, including both low points and high points, with both screen-cap video and packet log evidence of Honey’s actions.&nbsp; We’re proud that we’ve been testing Honey’s misconduct <em>for years</em>.</p><h2>What comes next</h2><p>I’m looking forward to Honey’s response.&nbsp; Can Honey leaders offer a proper reason why their product behaves differently when under test, versus when used by normal users?&nbsp; I’m all ears.</p><p>Honey should expect skepticism from Google, operator of the Chrome Web Store.&nbsp; Google is likely to take a dim view of a Chrome plugin hiding from testers.&nbsp; Chrome Web Store <a href="https://developer.chrome.com/docs/webstore/program-policies/user-data-faq">requires</a> “developer transparency” and specifically bans “dishonest behavior.”&nbsp; Consider also Google’s <a href="https://developer.chrome.com/docs/webstore/program-policies/code-readability">prohibition on “conceal[ing] functionality”</a>.&nbsp; Here, Honey was hiding not from Google staff but from merchants and networks, but this still violates the plain language of Google’s policy as written.</p><p>Honey also distributes its Safari extension through the Apple App Store, requiring compliance with Apple Developer Program policies.&nbsp; Apple’s extension policies are less developed, yet Apple’s broader app review process is notoriously strict.&nbsp; Meanwhile Apple operates an affiliate marketing program, making it particularly natural for Apple to step into the shoes of merchants who were tricked by Honey’s concealment.&nbsp; I expect a tough sanction from Apple too.</p><p>Meanwhile, <a href="https://www.courtlistener.com/docket/69503243/in-re-paypal-honey-browser-extension-litigation/?page=1">class action litigation is ongoing</a> on behalf of publishers who lose marketing commissions when Honey didn’t stand down.&nbsp; Nothing in the docket indicates that Plaintiff’s counsel know the depths of Honey’s efforts to conceal its stand-down violations.&nbsp; With evidence that Honey was intentionally hiding from testers, Plaintiffs should be able to strengthen their allegations of both the underlying misconduct and Honey’s knowledge of wrongdoing.&nbsp; My analysis also promises to simplify other factual aspects of the litigation.&nbsp; The <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.441974/gov.uscourts.cand.441974.161.0.pdf#page=34">consolidated class action complaint</a> discusses unpredictability of Honey’s standdown but doesn’t identify the factors that make Honey seem unpredictable—by all indications because plaintiffs (quite understandably) don’t know.&nbsp; Faced with unpredictability, plaintiffs resorted to monte carlo simulation to analyze the probability that Honey harmed a given publisher in a series of affiliate referrals.&nbsp; But with clarity on what’s really going on, there’s no need for statistical analysis, and the case gets correspondingly simpler.&nbsp; The court recently <a href="https://storage.courtlistener.com/recap/gov.uscourts.cand.441974/gov.uscourts.cand.441974.237.0.pdf">instructed plaintiffs to amend their complaint</a>, and surely counsel will emphasize Honey’s concealment in their next filing.</p><p>See also my <a href="https://vptdigital.com/wp-content/uploads/2026/12/explainer.mp4" data-fancybox="">narrated explainer video</a>.</p><h2 id="testingmethods">Notes on hands-on testing methods</h2><p>Hands-on testing of the relevant scenarios presented immediate challenges.&nbsp; Most obviously, I needed to test what Honey would do if it had tens of thousands of points, valued at hundreds of dollars.&nbsp; But I didn’t want to make hundreds or thousands of dollars of test purchases through Honey.</p><p>To change the Honey client’s understanding of my points earned to date, I used Fiddler, a standard network forensics tool.&nbsp; I wrote a few lines of FiddlerScript to intercept messages between the Honey plug-in and the Honey server to report that I had however many points I wanted for a given test.&nbsp; Here’s my code, in case others want to test themselves:</p><pre>//buffer responses for communications to/from joinhoney.com
//buffer allows response revisions by Fiddler
static function OnBeforeRequest(oSession: Session) {
  if (oSession.fullUrl.Contains("joinhoney.com"))	{
    oSession.bBufferResponse = true;
  }
}

//rewrite Honey points response to indicate high values 
static function OnBeforeResponse(oSession: Session) {
  if (oSession.HostnameIs("d.joinhoney.com") &amp;&amp; oSession.PathAndQuery.Contains("ext_getUserPoints")){
	s = '{"data":{"getUsersPointsByUserId":{"pointsPendingDeposit":67667,"pointsAvailable":98765,"pointsPendingWithdrawal":11111,"pointsRedeemed":22222}}}';
    oSession.utilSetResponseBody(s);
  }
}</pre><p>This fall, VPT added this method, and variants of it, to our <a href="https://vptdigital.com/shopping-plugins/">automated monitoring of shopping plugins</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's cash burn will be one of the big bubble questions of 2026 (217 pts)]]></title>
            <link>https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026</link>
            <guid>46438390</guid>
            <pubDate>Tue, 30 Dec 2025 21:44:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026">https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026</a>, See on <a href="https://news.ycombinator.com/item?id=46438390">Hacker News</a></p>
Couldn't get https://www.economist.com/leaders/2025/12/30/openais-cash-burn-will-be-one-of-the-big-bubble-questions-of-2026: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Sabotaging Bitcoin (112 pts)]]></title>
            <link>https://blog.dshr.org/2025/12/sabotaging-bitcoin.html</link>
            <guid>46437876</guid>
            <pubDate>Tue, 30 Dec 2025 20:53:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.dshr.org/2025/12/sabotaging-bitcoin.html">https://blog.dshr.org/2025/12/sabotaging-bitcoin.html</a>, See on <a href="https://news.ycombinator.com/item?id=46437876">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-4794815683845431067" itemprop="description articleBody">
<p>
I find myself in the unusual position of defending Bitcoin from its critics, if only reluctantly.</p><p>

In 2024 Soroush Farokhnia &amp; Amir Kafshdar Goharshady published <a href="https://hal.science/hal-04616643/"><i>Options and Futures Imperil Bitcoin's Security</i></a> and:</p><blockquote>
showed that (i) a successful block-reverting attack does not necessarily require ... a majority of the hash power; (ii) obtaining a majority of the hash power ... costs roughly 6.77 billion ... and (iii) Bitcoin derivatives, i.e. options and futures, imperil Bitcoin’s security by creating an incentive for a block-reverting/majority attack. 
</blockquote>
<p>
It is worth noting that they are not talking about profiting from double-spending. The Bitcoin blockchain transacts around $17B/day of nominal value in around 450K transactions (average ~$38K), but in 2021 <a href="https://www.nber.org/papers/w29396">Igor Makarov &amp; Antoinette Schoar found that</a>:</p><blockquote>
90% of transaction volume on the Bitcoin blockchain is not tied to economically meaningful activities but is the byproduct of the Bitcoin protocol design as well as the preference of many participants for anonymity ... exchanges play a central role in the Bitcoin system. They explain 75% of real Bitcoin volume.
</blockquote><p>
Of course, just because they aren't "economically meaningful" doesn't mean they aren't worth attacking! The average block has ~3.2K transactions, so ~$121.6M/block. As a check. $121.6M * 144 block/day = $17.5B. So to recover their cost for a 51% attack would require double-spending about 8 hours worth of transactions.</p><p>

I agree with their technical analysis of the attack, but I believe there would be significant difficulties in putting it into practice. Below the fold I try to set out these difficulties.<br>
<span><a name="more"></a></span></p>
<p>
First, I should point out that I wrote about using derivatives to profit from manipulating Bitcoin's price more than three years ago in <a href="https://blog.dshr.org/2022/07/pump-and-dump-schemes.html"><i>Pump-and-Dump Schemes</i></a>. These schemes have a long history in cryptocurrencies, but they are not the attack involved here. I don't claim expertise in derivatives trading, so it is possible my analysis is faulty. If so, please point out the problems in a comment.</p><h3>The Attack</h3><p>
Farokhnia &amp; Goharshady build on the 2018 work of Ittay Eyal &amp; Emin Gün Sirer in <a href="http://dx.doi.org/10.1145/3212998"><i>Majority is not enough: Bitcoin mining is vulnerable</i></a>:</p><blockquote>
The key idea behind this strategy, called Selfish Mining, is for a pool to keep its discovered blocks private, thereby intentionally forking the chain. The honest nodes continue to mine on the public chain, while the pool mines on its own private branch. If the pool discovers more blocks, it develops a longer lead on the public chain, and continues to keep these new blocks private. When the public branch approaches the pool's private branch in length, the selfish miners reveal blocks from their private chain to the public.<br>
...<br>
We further show that the Bitcoin mining protocol will never be safe against attacks by a selfish mining pool that commands more than 1/3 of the total mining power of the network. Such a pool will always be able to collect mining rewards that exceed its proportion of mining power, even if it loses every single block race in the network. The resulting bound of 2/3 for the fraction of Bitcoin mining power that needs to follow the honest protocol to ensure that the protocol remains resistant to being gamed is substantially lower than the 50% figure currently assumed, and difficult to achieve in practice.
</blockquote><p>
In April 2024  Farokhnia &amp; Goharshady <a href="https://hal.science/hal-04616643/">observed that</a>:</p><blockquote>
Given that the rule of thumb followed by most practitioners is to wait for 6 confirmations, a fork that goes 6 levels deep can very likely diminish the public’s trust in Bitcoin and cause a crash in its market price. It is also widely accepted that a prolonged majority attack (if it happens) would be catastrophic to the cryptocurrency and can cause its downfall.
</blockquote><p>
But, as they lay out, this possibility is <a href="https://hal.science/hal-04616643/">discounted</a>:</p><blockquote>
The conventional wisdom in the blockchain community is to assume that such block-reverting attacks are highly unlikely to happen. The reasoning goes as follows:<br>
<ol>
<li>Reverting multiple blocks and specifically double-spending a transaction that has 6 confirmations requires control of a majority of the mining power;</li>
<li>Having a majority of the mining power is prohibitively expensive and requires an outlandish investment in hardware;</li>
<li>Even if a miner, mining pool or group of pools does control a majority of the mining power, they have no incentive to act dishonestly and revert the blockchain, as that would crash the price of Bitcoin, which is ultimately not in their favor, since they rely on mining rewards denominated in BTC for their income.</li>
</ol>
</blockquote>
<table><tbody><tr><td><a href="https://blogger.googleusercontent.com/img/a/AVvXsEgLQthi1KB_neIKS70s-cNZXNufVGCch-B5Agowuq2jkGGrQzySmBRmbAufDkzl95djkxUjA7Vg9Lv01CyhHK9qvJ89uLbtfNO7ipXofReJQysViZwBYFSOtQOJzT-eiTcSlwravdn3DUA0RD10QdhatnXqa4kyZtvKQcONZCElx0TIoTKvOX-cJ6DO2A=s731"><img data-original-height="731" data-original-width="300" height="200" src="https://blogger.googleusercontent.com/img/a/AVvXsEgLQthi1KB_neIKS70s-cNZXNufVGCch-B5Agowuq2jkGGrQzySmBRmbAufDkzl95djkxUjA7Vg9Lv01CyhHK9qvJ89uLbtfNO7ipXofReJQysViZwBYFSOtQOJzT-eiTcSlwravdn3DUA0RD10QdhatnXqa4kyZtvKQcONZCElx0TIoTKvOX-cJ6DO2A=w82-h200" width="82"></a></td></tr><tr><td>Source</td></tr></tbody></table><p>
Starting in late 2020, as shown in <a href="https://www.economist.com/christmas-specials/2021/12/18/the-most-powerful-people-in-crypto"><i>The Economist</i>'s graphic</a>, the spot market in Bitcoin became dwarfed by the derivatives markets. In the last month <a href="https://www.theblock.co/data/crypto-markets/futures/volume-of-bitcoin-futures-monthly">$1.7T</a> of Bitcoin futures traded on unregulated exchanges, and <a href="https://www.theblock.co/data/crypto-markets/options">$6.4B</a> on regulated exchanges. Compare this with the <a href="https://coinmarketcap.com/currencies/volume/monthly/">$1.8B</a> of the spot market in the same month.</p><p>

These huge futures markets enable Farokhnia &amp; Goharshady's <a href="https://hal.science/hal-04616643/">attack</a>:</p><blockquote>
In short, an attacker can first use the Bitcoin derivatives market to short Bitcoin by purchasing a sufficient amount of put options or other equivalent financial instruments. She can then invest any of the amounts calculated above, depending on the timeline of the attack, to obtain the necessary hardware and hash power to perform the attack. If the attacker chooses to obtain a majority of the hash power, her success is guaranteed and she can revert the blocks as deeply as she wishes. However, she also has the option of a smaller upfront investment in hardware in exchange for longer wait times to achieve a high probability of success. In any case, as long as her earnings from shorting Bitcoin and then causing an intentional price crash outweighs her investments in hardware, there is a clear financial incentive to perform such an attack. The numbers above show that the annual trade volume in Bitcoin derivatives is more than three orders of magnitude larger than the required investment in hardware. Thus, it is possible and profitable to perform such an attack.
</blockquote>
<h3>Assumptions</h3><p>
Farokhnia &amp; Goharshady make some <a href="https://hal.science/hal-04616643/">simplifying assumptions</a>:</p><blockquote>
<ul>
<li>We only consider the cost of hardware at the time of writing. We assume the attacker is buying the hardware, rather than renting it and do not consider potential discounts on bulk orders.</li>
<li>We ignore electricity costs as they vary widely based on location.</li>
</ul>
The justification for the first assumption is that it keeps our analysis sound, i.e. we can only over-approximate the cost by making this assumption. As for the second assumption, we note that electricity costs are often negligible in comparison to hardware costs and that our main argument, i.e. the vulnerability of Bitcoin to majority attacks and block-reverting attacks, remains intact even if the estimates we obtain here are doubled. Indeed, as we will soon see, the trade volume of Bitcoin derivatives is more than three orders of magnitude larger than the numbers obtained here.
</blockquote>
<h3>Goal</h3><p>
As Farokhnia &amp; Goharshady stress, the success of a block-reverting attack is probabilistic, so the attacker needs to have a high enough probability of making a large enough profit to make up for the risk of failure.</p><p>

My analysis thus assumes that the goal of the attacker is to have a 95% probability of earning at least double the cost of the attack.</p><h3>Attacker</h3><p>
There are two different kinds of attackers with different sets of difficulties:</p><ul>
<li><b>Outsiders:</b> someone who has to acquire or rent sufficient hash power.</li>
<li><b>Insiders:</b> someone or some mining pool who already controls sufficient hash power.</li>
</ul><p>
Farokhnia &amp; Goharshady study the outsider case. Both kinds of attacker's practical problems occur in two areas:</p><ul>
<li>Obtaining and maintaining for the duration of the attack sufficient hash power without detection.</li>
<li>Obtaining and maintaining for the duration of the attack a sufficient short position in Bitcoin without detection.</li>
</ul><p>
The short position must be maintained for the duration of the attack because succeess may come at any 10-minute block time, and there would not be time to obtain a large enough short position in ten minutes.</p><h3>Hash Power</h3><p>
The outsider's problems are more complex than the insider's.</p><h4>Outsider Attack</h4><p>
The outsider attacker requires three kinds of resource:</p><ul>
<li>Mining rigs.</li>
<li>Power to run the rigs.</li>
<li>Data center space to hold the rigs.</li>
</ul><p>
Each of these is problematic, but assuming that the difficulties could be overcome, there is then the question of what it would cost to run the attack..</p><h5>Mining rigs</h5>
<ul>
<li>Could they acquire mining rigs sufficient to provide 30% of the combined insider and outsider hash power, or ~43% of the pre-attack hash power?</li>
<li>How long would it take to acquire the rigs?</li>
<li>Would their acquisition of the rigs be detected?</li>
</ul><p>
Bitmain is estimated to have <a href="https://www.jbs.cam.ac.uk/wp-content/uploads/2025/04/2025-04-cambridge-digital-mining-industry-report.pdf">82% of the market for mining rigs</a>, and they either control or have very close relations with <a href="https://papers.ssrn.com/sol3/Delivery.cfm?abstractid=3320437">all the major mining pools</a>, who thus have priority access to the latest rigs. Because rigs <a href="https://blog.dshr.org/2022/05/generally-accepted-accounting-principles.html">depreciate rapidly</a>, position in the queue for rigs has a big impact on the profitability  of mining. Bitmain is unlikely to give a new customer priority access to rigs.</p><p>

Because the economic life of mining rigs is <a href="https://blog.dshr.org/2022/05/generally-accepted-accounting-principles.html">less than two years</a>, the first part of Bitmain's production goes into maintaining the hash rate by replacing obsolete rigs. The second part goes into increasing the hash rate.  If we assume that the outsider attacker could absorb the second part of Bitmain's production, how long would it take to get the necessary 43% of the previous hash power?</p><p>
This can be estimated by examining the <a href="https://mempool.space/graphs/mining/hashrate-difficulty#3y">hash power through time graph</a>. Over the last 3 years the hash rate has increased from about 240EH/s to about 1120EH/s, or about 24EH/s/month. Roughly, 82% of this is Bitmain's output, or about 20EH/s/month. The attacker needs 43% of the current hash rate, or about 482EH/s, or 24 months of the second part of Bitmain's production. At the <a href="https://data.hashrateindex.com/chart/asic-price-index">current price</a> for leading-edge rigs of $14.11/TH/s this would cost about $6.8B plus say $340M in interest at 5%, or $7.14B.</p><p>

The lack of rigs to increase the hash rate over a period of much less than two years would clearly be detectable.</p><h5>Power</h5><p>
The <a href="https://ccaf.io/cbnsi/cbeci">Cambridge Bitcoin Energy Consumption Index</a>'s current estimate is that the network consumes 22GW. The outside attacker would need 43% of this, or about 9.5GW, for the duration of the attack. For context, Meta's extraordinarily aggressive <a href="https://techcrunch.com/2025/07/14/mark-zuckerberg-says-meta-is-building-a-5gw-ai-data-center/">AI data center plans</a> claim to bring a single 1GW data center online in 2026, and the first 2GW phase of their planned $27B 5GW Louisiana data center in 2030. The constraint on the roll-out is largely that lack of access to sufficient power. The attacker would need double the power Meta's Louisiana data center plans to have in 2030.</p><p>

Access to gigawatts of power is available only on long-term contracts and only after significant delays.</p><h5>Data centers</h5>
<p>
Meta's 5GW Louisiana "Hyperion" data center's "<a href="https://techcrunch.com/2025/07/14/mark-zuckerberg-says-meta-is-building-a-5gw-ai-data-center/">footprint will be large enough to cover most of Manhattan</a>", and the outsider attacker would need two of them. If Meta expects to take more than 5 years to build one of them, the outsider attacker is likely to need a decade.</p><p>

Estimates for AI data centers are that 60% of the capital cost is the hardware and 40% everything else. Thus the "everything else" for Meta's $27B 5GW data center is $10.8B. "Everything else" for the attacker's two similar data centers would thus be $21.6B. Plus say 5 years of interest at 5% or $5.4B.</p><h5>Operational cost</h5><p>
Ignoring the evident impossibility of the outsider attacker amassing the necessary mining rigs, power and data center space, what would the operational costs of the attack be?</p><p>

It is hard to estimate the costs for power, data center space, etc. But an estimate can be based upon the cost to rent hash power, noting that in practice renting 43% of the total would be impossible, and guessing that renters have a 30% margin. A typical rental fee would be $0.10/TH/day so the costs might be $0.07/TH/day. The attack would have a 95% probability of needing 482EH/s over 34 days or less, so $516M or less.</p><p>

Thus the estimated total cost for the hash power used in the attack would have a 95% probability of being no more than $7.66B. Plus about $27B in data center cost, which could presumably be repurposed to AI after the attack.</p><h4>Insider Attack</h4>
<p>
The insider attacker already controls the 30% of the hash power they need, so only the question of detection remains. The essence of the block-reverting attack is that the attacker mines in secret until they can publish a chain with 6 blocks following a target block. A reduction of 30% of the public hash rate over an average period of 17 days would clearly be detectable. The hash rate is noisy, but the graph shows that over the last year the largest drop was 16% from June 14<sup>th</sup> to 27<sup>th</sup>. There was one large drop in the hash rate, 51% between May 10<sup>th</sup> and July 1<sup>st</sup> 2021 as <a href="https://blog.dshr.org/2021/07/graphing-chinas-cryptocurrency-crackdown.html">China cracked down</a> on mining.</p><p>

The insider's loss of income from the blocks they would otherwise have mined would have a 95% probability of being 4,590 BTC or less, or about $425M.</p><h3>Short Position</h3><p>
Both kinds of attackers need to ensure that, when the attack succeeds, they have a large enough short position in Bitcoin that would generate their expected return from the attack's decrease in the Bitcoin price. There are two possibilities:</p><ul>
<li>When the attacker's chain is within one block of being the longest, they have ten minutes to purchase the shorts. There is unlikely to be enough liquidity in the market to accommodate this sudden demand, which in any case would greatly increase the price of the shorts. I will ignore this possibility in what follows.</li>
<li>At the start of the attack the attacker gradually accumulates sufficient shorts. Even assuming there were enough liquidity, and that the purchases didn't increase the price, the attacker has to bear both the cost of maintaining the shorts for the duration of the attack, and the risk of the market moving up enough to cause the position to be liquidated.</li>
</ul><p>
The success of a block-reverting attack on Bitcoin would have implications on other cryptocurrencies. It would likely increase the prices fo Proof-of-Stake coins such as Ethereum, as being much ore difficult to attack, and decrease the price of other Proof-of-Work coins. Derivatives on these coins might be included int he attacker's toolkit, but I will ignore this possibility as the open interest on these coins is smaller.</p><p>

Farokhnia &amp; Goharshady <a href="https://hal.science/hal-04616643/">note that</a>:</p><blockquote>
At the time of writing, the open interest of BTC options is a bit more than 20 billion USD. Thus, a malicious party performing the attack mentioned in this work would need to obtain a considerable amount of the available put contracts. This may lead to market disruptions whose analysis is beyond the scope of this work. This being said, if the derivatives market continues to grow and becomes much larger than it currently is, purchasing this amount of contracts might not even be detected.
</blockquote><p>
There are two different kinds of market in which Bitcoin shorts are available:</p><ul>
<li><b>Regulated exchanges</b> such as the CME offering options on Bitcoin and stock exchanges with Bitcoin ETFs and Bitcoin treasury companies such as Strategy.</li>
<li><b>Unregulated exchanges</b> such as Binance offering "perpetual futures" (perps) on Bitcoin.</li>
</ul>
<h4>Unregulated Exchanges</h4><p>
Patrick McKenzie's <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/"><i>Perpetual futures, explained</i></a> is a clear and comprehensive description of the derivative common on unregulated exchanges:</p><blockquote>
Instead of all of a particular futures vintage settling on the same day, perps settle multiple times a day for a particular market on a particular exchange. The mechanism for this is the <i>funding rate</i>. At a high level: winners get paid by losers every e.g. 4 hours and then the game continues, unless you’ve been blown out due to becoming overleveraged or for other reasons (discussed in a moment).<p>

Consider a toy example: a retail user buys 0.1 Bitcoin via a perp. The price on their screen, which they understand to be for Bitcoin, might be $86,000 each, and so they might pay $8,600 cash. Should the price rise to $90,000 before the next settlement, they will get +/- $400 of winnings credited to their account, and their account will continue to reflect exposure to 0.1 units of Bitcoin via the perp. They might choose to sell their future at this point (or any other). They’ll have paid one commission (and a spread) to buy, one (of each) to sell, and perhaps they’ll leave the casino with their winnings, or perhaps they’ll play another game.</p><p>

Where did the money come from? Someone else was symmetrically short exposure to Bitcoin via a perp. It is, with some very important caveats incoming, a closed system: since no good or service is being produced except the speculation, winning money means someone else lost.
</p></blockquote><p>
So the exchange makes money from commissions, and from the spread against the actual spot price. The price of the perp is maintained close to the spot price by the "basis trade", traders providing liquidity by shorting the perp and buying the spot when the perp is above spot, and vice versa. Of course, the spot price itself may have been manipulated, for example by <a href="https://blog.dshr.org/2022/07/pump-and-dump-schemes.html"><i>Pump-and-Dump Schemes</i></a>.</p><p>

How else does the exchange <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">make money</a>?</p><blockquote>
Perp funding rates also embed an interest rate component. This might get quoted as 3 bps a day, or 1 bps every eight hours, or similar. However, because of the impact of leverage, gamblers are paying more than you might expect: at 10X leverage that’s 30 bps a day.
</blockquote><p>
A "basis point (bps)" is "<a href="https://www.investopedia.com/terms/b/basispoint.asp">one hundredth of 1 percentage point</a>", so 30bps/day is 0.3%/day or around 120%/year.  But the lure of leverage is the competitive advantage of <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">unregulated exchanges</a>:</p><blockquote>
In a standard U.S. brokerage account, Regulation T has, for almost 100 years now, set maximum leverage limits (by setting minimums for margins). These are 2X at position opening time and 4X “maintenance” (before one closes out the position). Your brokerage would be obligated to forcibly close your position if volatility causes you to exceed those limits.
</blockquote><p>
Unregulated markets <a href="https://www.binance.com/en/square/post/24757521817370">are different</a>:</p><blockquote>
Binance allows up to 125x leverage on BTC.
</blockquote><p>
Although these huge amounts of leverage greatly increase the reward from a small market movement in favor of the position, they greatly reduce the amount the market has to move against the position before something bad happens. The first bad thing is <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">liquidation</a>:</p><blockquote>
One reason perps are structurally better for exchanges and market makers is that they simplify the business of blowing out leveraged traders. The exact mechanics depend on the exchange, the amount, etc, but generally speaking you can either force the customer to enter a closing trade or you can assign their position to someone willing to bear the risk in return for a discount.<p>

Blowing out losing traders is lucrative for exchanges except when it catastrophically isn’t. It is a priced service in many places. The price is quoted to be low (“a nominal fee of 0.5%” is one way Binance describes it) but, since it is calculated from the amount at risk, it can be a large portion of the money lost. If the account’s negative balance is less than the liquidation fee, wonderful, thanks for playing and the exchange / “the insurance fund” keeps the rest, as a tip.
</p></blockquote><p>
The bigger and faster the market move, the more likely the loss exceeds your <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">collateral</a>:</p><blockquote>
In the case where the amount an account is negative by is more than the fee, that “insurance fund” can choose to pay the winners on behalf of the liquidated user, at management’s discretion. Management will <i>usually</i> decide to do this, because a casino with a reputation for not paying winners will not long remain a casino.<p>

But tail risk is a real thing. The capital efficiency <i>has a price</i>: there physically does not exist enough money in the system to pay all winners given sufficiently dramatic price moves. Forced liquidations happen. Sophisticated participants withdraw liquidity (for reasons we’ll soon discuss) or the exchange becomes overwhelmed technically / operationally. The forced liquidations eat through the diminished / unreplenished liquidity in the book, and the magnitude of the move increases.
</p></blockquote><p>
The second bad thing is <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">automatic de-leveraging (ADL)</a>:</p><blockquote>
Risk in perps has to be symmetric: if (accounting for leverage) there are 100,000 units of Somecoin exposure long, then there are 100,000 units of Somecoin exposure short. This does not imply that the shorts or longs are sufficiently capitalized to <i>actually pay</i> for all the exposure in all instances.<p>

In cases where management deems paying winners from the insurance fund would be too costly and/or impossible, they automatically deleverage some winners.
</p></blockquote><p>
McKenzie illustrates ADL with <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">an example</a>:</p><blockquote>
So perhaps you understood, prior to a 20% move, that you were 4X leveraged. You just earned 80%, right? Ah, except you were only 2X leveraged, so you earned 40%. Why were you <i>retroactively</i> only 2X? That’s what automatic deleveraging means. Why couldn’t you get the other 40% you feel entitled to? Because the collective group of losers doesn’t have enough to pay you your winnings and the insurance fund was insufficient or deemed insufficient by management.
</blockquote><p>
For our purposes, this is an <a href="https://www.bitsaboutmoney.com/archive/perpetual-futures-explained/">important note</a>:</p><blockquote>
In theory, this can happen to the upside or the downside. <i>In practice</i> in crypto, this seems to usually happen after sharp decreases in prices, not sharp increases. For example, October 2025 saw widespread ADLing as (more than) <a href="https://www.bloomberg.com/news/articles/2025-11-22/crypto-s-brutal-month-triggers-a-stress-test-for-wall-street">$19 billion of liquidations</a> happened, across a variety of assets.
</blockquote><p>
How does this affect the outsider attacker? Lets assume that the attack has a 95% probability of costing no more than $7.5B and would reduce the Bitcoin price from $100K to $80K in a single 4-hour period. With 10X leverage this would generate $200K/BTC in gains.</p><p>
The outsider wants to double the cost of the attack, so needs to short $15B/$180K BTC, or 83,333BTC at 10X leverage for the duration of the attack. Establishing the position costs $8.333B. Assuming the BTC price is fixed at $100K until the attack succeeds the funding rate is zero. But we have to assume that the attacker borrowed the $8.333B for the duration, so would pay interest, plus two commissions plus two spreads. I'll ignore these costs.</p><p>
I will also ignore the fact that $83B is around 148% of the peak aggregated open interest in Bitcoin options over the past year of about $56B.</p><p>

The way liquidation of a short works is that as the market moves up, the initial leverage increases. Each exchange will have a limit on the leverage it will allow so, allowing for the liquidation fee, if the leverage of the short position gets to this limit the exchange will liquidate it.</p><table>
<thead>
  <tr><td>Move %</td><td>Leverage</td></tr>
</thead><tbody>
<tr><td>0</td><td>10</td></tr>
<tr><td>1</td><td>11.1</td></tr>
<tr><td>2</td><td>12.5</td></tr>
<tr><td>3</td><td>14.3</td></tr>
<tr><td>4</td><td>16.7</td></tr>
<tr><td>5</td><td>20</td></tr>
<tr><td>6</td><td>25</td></tr>
<tr><td>7</td><td>33.3</td></tr>
<tr><td>8</td><td>50</td></tr>
<tr><td>9</td><td>100</td></tr>
</tbody></table><p>
The table shows the effect of increasing percentage moves against an initial 10X leveraged short. If we assume a short with an initial 10X leverage and an exchange limit of 50X was taken out on the first of each month of 2025, on 9 of the 12 months it would have been liquidated before the month was out. So Bitcoin is volatile enough that the attacker's short has a high probability of being liquidated before the attack succeeds.  And note Binance's "nominal fee" of 0.5% for liquidating $83.33B, or $417M.</p><p>

In the unlikely event that the attack succeeds early enough to avoid liquidation there would have been one of those "sharp decreases in prices" that cause ADL, so as a huge winner it would be essentially certain that the attacker would suffer ADL and most of the winnings needed to justify the attack would evaporate.</p><h4>Regulated Exchanges</h4><p>
The peak open interest in Bitcoin futures on the Chicago Mercantile Exchange over the past year was less than $20B, so even if we add together both kinds of exchange, the peak open interest over the last year isn't enough for the attacker.
</p><h3>Conclusions</h3><p>
Neither an outsider nor an insider attack appears feasible.</p><h4>Outsider Attack</h4><p>
An outsider attack seems infeasible because in practice:</p><ul>
<li>They could not acquire 43% or more  of the hash power.</li>
<li>Even if they could it would take so long as to make detection inevitable.</li>
<li>Even if they could and they were not detected, the high cost of the rigs makes the necessary shorts large relative to the open interest, and expensive to maintain.</li>
<li>These large shorts would need to be leveraged perpetual futures, bringing significant risks of loss of collateral through liquidation, and of the potential payoff being reduced through automatic de-leveraging.</li>
<li>The attacker would need more than the peak aggregate open interest in Bitcoin futures over the past year.</li>
</ul>
<h4>Insider Attack</h4><p>
The order-of-magnitude lower direct cost of an insider attack makes it appear less infeasible, but insiders have to consider the impact on their continuing mining business. If the assumed 20% drop in the Bitcoin price were sustained for a year, the cost to the miner controlling 30% of the hash rate would be about 15,750 BTC or nearly $1.5B making the total cost of the attack (excluding the cost of carrying the shorts) almost $2B.</p><p>
The drop in Bitcoin's price and the smaller, lagging <a href="https://www.ft.com/content/2012681b-67b2-496a-a7cd-4811eb497883">drop in network difficulty</a> over the last three months has decreased miners' revenue by about 25%. In the medium term a further drop is in prospect.  Sometime in April 2028 the regular Bitcoin halvening will occur, halving the income of miners in aggregate Bitcoin terms.</p><p>
These drops turn the insiders' access to data center space and power into a double-edged sword because, as Vicky Ge Huang explains in <a href="https://www.wsj.com/tech/ai/bitcoin-miners-thrive-off-a-new-side-hustle-retooling-their-data-centers-for-ai-bdc408a9"><i>Bitcoin Miners Thrive Off a New Side Hustle: Retooling Their Data Centers for AI</i></a>:</p><blockquote>
mining-company stocks are still flying, even with cryptocurrency prices in retreat. That's because these firms have something in common with the hottest investment theme on the planet: the massive, electricity-hungry data centers expected to power the artificial-intelligence boom. Some companies are figuring out how to remake themselves as vital suppliers to Alphabet, Amazon, Meta, Microsoft and other "hyperscalers" bent on AI dominance.<br>
...<br>
Miners often have to build new, specialized facilities, because running AI requires more-advanced cooling and network systems, as well as replacing bitcoin-mining computers with AI-focused graphics processing units. But signing deals with miners allows AI giants to expand faster and cheaper than starting new facilities from scratch.<br>
...<br>
Shares of Core Scientific quadrupled in 2024 after the company signed its first AI contract that February. The stock has gained 10% this year. The company now expects to exit bitcoin mining entirely by 2028.
</blockquote><p>
I wonder why the date is 2028! As profit-driven miners use their bouyant stock price to fund a <a href="https://pivot-to-ai.com/">pivot to AI</a> the hash rate and the network difficuty will decrease, making an insider attack less infeasible. The drop in their customer's income will likely encourage Bitmain to similarly pivot to AI, devoting an increasing proportion of their wafers to AI chips, especially given the Chinese government's goal of localizing AI.</p><p>

 A 30% miner whose rigs were fully depreciated might consider an insider attack shortly before the halvening as a viable exit strategy, since their future earnings from mining would be greatly reduced. But they would still be detected.</p><h3>Counter-measures</h3><p>
Even if we assume the feasibility of both the hash rate and the short position aspects of the attack, it is still the case that for example, an attack with 30% of the hash power and a 95% probability of success will, on average, last 17 days.  it seems very unlikely that the coincidence over an extended period of a large reduction in the expected hash rate and a huge increase in short interest would escape attention from Bitcoin HODl-ers, miners and exchanges, not to mention Bitmain. What counter-measures could they employ?</p><p>
The theoretically correct counter-measure would be to raise the 6-block finality criterion to the 24 blocks that corresponds to a pool with 30% of the hash power. But this would violate what people incorrectly believe is the revealed word of Satoshi. And Goharshady correctly pointed out in email that this is in any case impractical:</p><ul>
<li>The 6-block rule is just a convention, there is no dial that can be turned.</li>
<li>Much of the access to the Bitcoin blockchain is via APIs that typically have the 6-block rule hard-codded in.</li>
<li>Many, typically low-value, transactions do not wait for even a single confirmation.</li>
<li>Even it were possible, changing from a one-hour to a four-hour confirmation would have significant negative impacts on the Bitcoin ecosystem.</li>
</ul><p>
In the case of an insider attack, the absence of a pool previously mining around one in three of all blocks would readily de-anonymize the attacker. Bitmain would necessarily be aware of the identity of an outside attacker. Although unregulated exchanges are notoriously poor at KYC/AML, the sums involved in the shorts are so large that they would be highly motivated to use the blockchain information to de-anonymize the attacker. Given their terms of service, and the lack of effective recourse, they would be able to ham-string the attack.</p><h3>Acknowledgements</h3><p>
This post benefited greatly from insightful comments on a draft from Jonathan Reiter, Amir Kafshdar Goharshady and Joel Wallenberg, but the errors are all mine.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Professional software developers don't vibe, they control (122 pts)]]></title>
            <link>https://arxiv.org/abs/2512.14012</link>
            <guid>46437391</guid>
            <pubDate>Tue, 30 Dec 2025 20:06:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2512.14012">https://arxiv.org/abs/2512.14012</a>, See on <a href="https://news.ycombinator.com/item?id=46437391">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2512.14012">View PDF</a>
    <a href="https://arxiv.org/html/2512.14012v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>The rise of AI agents is transforming how software can be built. The promise of agents is that developers might write code quicker, delegate multiple tasks to different agents, and even write a full piece of software purely out of natural language. In reality, what roles agents play in professional software development remains in question. This paper investigates how experienced developers use agents in building software, including their motivations, strategies, task suitability, and sentiments. Through field observations (N=13) and qualitative surveys (N=99), we find that while experienced developers value agents as a productivity boost, they retain their agency in software design and implementation out of insistence on fundamental software quality attributes, employing strategies for controlling agent behavior leveraging their expertise. In addition, experienced developers feel overall positive about incorporating agents into software development given their confidence in complementing the agents' limitations. Our results shed light on the value of software development best practices in effective use of agents, suggest the kinds of tasks for which agents may be suitable, and point towards future opportunities for better agentic interfaces and agentic use guidelines.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Brian Hempel [<a href="https://arxiv.org/show-email/67c67c82/2512.14012" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Tue, 16 Dec 2025 02:15:06 UTC (941 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Everything as Code: How We Manage Our Company in One Monorepo (182 pts)]]></title>
            <link>https://www.kasava.dev/blog/everything-as-code-monorepo</link>
            <guid>46437381</guid>
            <pubDate>Tue, 30 Dec 2025 20:05:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kasava.dev/blog/everything-as-code-monorepo">https://www.kasava.dev/blog/everything-as-code-monorepo</a>, See on <a href="https://news.ycombinator.com/item?id=46437381">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p>Last week, I updated our pricing limits. One JSON file. The backend started enforcing the new caps, the frontend displayed them correctly, the marketing site showed them on the pricing page, and our docs reflected the change—all from a single commit.</p>
<p>No sync issues. No "wait, which repo has the current pricing?" No deploy coordination across three teams. Just one change, everywhere, instantly.</p>
<p>At Kasava, our entire platform lives in a single repository. Not just the code—<em>everything</em>:</p>
<pre><code>kasava/                              # 5,470+ files TypeScript files
├── frontend/                       # Next.js 16 + React 19 application
│   └── src/
│       ├── app/                   # 25+ route directories
│       └── components/            # 45+ component directories
├── backend/                        # Cloudflare Workers API
│   └── src/
│       ├── services/              # 55+ business logic services
│       └── workflows/             # Mastra AI workflows
├── website/                        # Marketing site (kasava.ai)
├── docs/                           # Public documentation (Mintlify)
├── docs-internal/                  # 12+ architecture docs &amp; specs
├── marketing/
│   ├── blogs/                     # Blog pipeline (drafts → review → published)
│   ├── investor-deck/             # Next.js site showing investment proposal
│   └── email/                     # MJML templates for Loops.so campaigns
├── external/
│   ├── chrome-extension/          # WXT + React bug capture tool
│   ├── google-docs-addon/         # @helper AI assistant (Apps Script)
│   └── google-cloud-functions/
│       ├── tree-sitter-service/   # AST parsing for 10+ languages
│       └── mobbin-research-service/
├── scripts/                        # Deployment &amp; integration testing
├── infra-tester/                   # Integration test harness
└── github-simulator/               # Mock GitHub API for local dev

</code></pre>
<hr>
<h2>Why This Matters: AI-Native Development</h2>
<p>This isn't about abstract philosophies on design patterns for 'how we should work.' It's about velocity in an era where products change fast and context matters.</p>
<p>AI is all about context. And this monorepo <strong>is</strong> our company—not just the product.</p>
<p>When our AI tools help us write documentation, they have immediate access to the actual code being documented. When we update our marketing website, the AI can verify claims against the real implementation. When we write blog posts like this one, the AI can fact-check every code example, every number, every architectural claim against the source of truth.</p>
<p><strong>This means we move faster</strong>:</p>
<ul>
<li><strong>Documentation updates faster</strong> because the AI sees code changes and suggests doc updates in the same context</li>
<li><strong>Website updates faster</strong> because pricing, features, and capabilities are pulled from the same config files that power the app</li>
<li><strong>Blog posts ship faster</strong> because the AI can run self-referential checks—validating that our "5,470+ TypeScript files" claim is accurate by actually counting them</li>
<li><strong>Nothing goes out of sync</strong> because there's only one source of truth, and AI has access to all of it</li>
</ul>
<p>When you ask Claude to "update the pricing page to reflect the new limits," it can:</p>
<ol>
<li>Read the backend service that enforces limits</li>
<li>Check the frontend that displays them</li>
<li>Update the marketing site</li>
<li>Verify the docs are consistent</li>
<li>Flag any blog posts that might mention outdated numbers</li>
</ol>
<p>All in one conversation. All in one repository.</p>
<p>This is what "AI-native development" actually means: structuring your work so AI can be maximally helpful, not fighting against fragmentation.</p>
<p><strong>And it reinforces a shipping culture.</strong></p>
<p>Everything-as-code means everything ships the same way: <code>git push</code>. Want to update the website pricing page? <code>git push</code>. New blog post ready to go live? <code>git push</code>. Fix a typo in the docs? <code>git push</code>. Deploy a backend feature? <code>git push</code>.</p>
<p>No separate CMSs to log into. No WordPress admin panels. No waiting for marketing tools to sync. No "can someone with Contentful access update this?" The same Git workflow that ships code also ships content, documentation, and marketing. Everyone on the team can ship anything, and it all goes through the same review process, the same CI/CD, the same audit trail.</p>
<p>This uniformity removes friction and removes excuses. Shipping becomes muscle memory.</p>
<hr>
<h2>Why Everything in One Repo?</h2>
<h3>1. Atomic Changes Across Boundaries (That AI Can Understand)</h3>
<p>When a backend API changes, the frontend type definitions update in the same commit. When we add a new feature, the documentation can ship alongside it. No version mismatches. No "which version of the API does this frontend need?"</p>
<p><strong>AI can see and validate the entire change in context</strong>.</p>
<p>When we ask Claude to add a feature, it doesn't just write backend code. It sees the frontend that will consume it, the docs that need updating, and the marketing site that might reference it. All in one view. All in one conversation.</p>
<p><strong>Real example from our codebase—adding Asana integration:</strong></p>
<pre><code>commit: "feat: add Asana integration"
├── backend/src/services/AsanaService.ts
├── backend/src/routes/api/integrations/asana.ts
├── frontend/src/components/integrations/asana/
├── frontend/src/app/integrations/asana/
├── docs/integrations/asana.mdx
└── website/src/app/integrations/page.tsx
</code></pre>
<p>One PR. One review. One merge. Everything ships together.</p>
<p><strong>Another example—keeping pricing in sync:</strong></p>
<p>We have a single <code>billing-plans.json</code> that defines all plan limits and features:</p>
<pre><code><span>// frontend/src/config/billing-plans.json (also copied to website/src/config/)</span>
<span>{</span>
  <span>"plans"</span><span>:</span> <span>{</span>
    <span>"free"</span><span>:</span> <span>{</span> <span>"limits"</span><span>:</span> <span>{</span> <span>"repositories"</span><span>:</span> <span>1</span><span>,</span> <span>"aiChatMessagesPerDay"</span><span>:</span> <span>10</span> <span>}</span> <span>}</span><span>,</span>
    <span>"starter"</span><span>:</span> <span>{</span>
      <span>"limits"</span><span>:</span> <span>{</span> <span>"repositories"</span><span>:</span> <span>10</span><span>,</span> <span>"aiChatMessagesPerDay"</span><span>:</span> <span>100</span> <span>}</span>
    <span>}</span><span>,</span>
    <span>"professional"</span><span>:</span> <span>{</span>
      <span>"limits"</span><span>:</span> <span>{</span> <span>"repositories"</span><span>:</span> <span>50</span><span>,</span> <span>"aiChatMessagesPerDay"</span><span>:</span> <span>1000</span> <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre>
<p>The backend enforces these limits. The frontend displays them in settings. The marketing website shows them on the pricing page. When we change a limit, one JSON update propagates everywhere—no "the website says 50 repos but the app shows 25" bugs.</p>
<p><strong>And AI validates all of it.</strong> When we update <code>billing-plans.json</code>, we can ask Claude to verify that the backend, frontend, and website are all consistent. It reads all three implementations and confirms they match—or tells us what needs fixing.</p>
<h3>2. Cross-Project Refactoring</h3>
<p>Renaming a function? Your IDE finds all usages across frontend, backend, docs examples, and blog code snippets. One find-and-replace. One commit.</p>
<h3>3. Single Source of Truth</h3>
<ul>
<li><strong>Dependencies</strong>: Shared tooling configured once</li>
<li><strong>CI/CD</strong>: One pipeline to understand</li>
<li><strong>Search</strong>: Find anything with one <code>grep</code></li>
</ul>
<hr>
<h2>The Structure: What Lives Where</h2>
<h3>Core Application</h3>
<pre><code>frontend/                        # Customer-facing Next.js app
├── src/
│   ├── app/                    # Next.js 15 App Router
│   │   ├── analytics/         # Semantic commit analysis
│   │   ├── bug-reports/       # AI-powered bug tracking
│   │   ├── chat/              # AI assistant interface
│   │   ├── code-search/       # Semantic code search
│   │   ├── dashboard/         # Main dashboard
│   │   ├── google-docs-assistant/
│   │   ├── integrations/      # GitHub, Linear, Jira, Asana
│   │   ├── prd/               # PRD management
│   │   └── ...                # 25+ route directories total
│   ├── components/            # 45+ component directories
│   │   ├── ai-elements/      # AI-specific UI
│   │   ├── bug-reports/      # Bug tracking UI
│   │   ├── dashboard/        # Dashboard widgets
│   │   ├── google-docs/      # Google Docs integration
│   │   ├── onboarding/       # User onboarding flow
│   │   └── ui/               # shadcn/ui base components
│   ├── mastra/               # Frontend Mastra integration
│   └── lib/                  # SDK, utilities, hooks

backend/                        # Cloudflare Workers API
├── src/
│   ├── routes/               # Hono API endpoints
│   ├── services/             # 55+ business logic services
│   ├── workflows/            # Mastra AI workflows
│   │   ├── steps/           # Reusable workflow steps
│   │   └── RepositoryIndexingWorkflow.ts
│   ├── db/                   # Drizzle ORM schema
│   ├── durable-objects/      # Stateful edge computing
│   ├── workers/              # Queue consumers
│   └── mastra/               # AI agents and tools
</code></pre>
<p>These two talk to each other constantly. Having them in the same repo means:</p>
<ul>
<li>API changes include frontend updates</li>
<li>Type safety across the boundary</li>
<li>Shared testing utilities</li>
</ul>
<h3>Marketing Properties</h3>
<pre><code>website/                        # kasava.ai marketing site
├── src/
│   ├── app/                   # Landing pages, blog
│   ├── components/            # Shared marketing components
│   └── lib/                   # Utilities

marketing/
├── blogs/
│   ├── queue/
│   │   └── drafts/           # Ideas and drafts
│   ├── review/               # Ready for editing
│   └── published/            # Live on the site
├── investor-deck/            # Next.js presentation (not PowerPoint!)
└── email/
    ├── CLAUDE.md             # Email writing guidelines
    └── mjml/                 # 7+ email campaign loops
        ├── loop-1-welcome/
        ├── loop-2-github-connected/
        ├── loop-3-trial-conversion/
        └── ...
</code></pre>
<p>Yes, even blog posts are code. They're Markdown files with frontmatter, versioned in Git, reviewed in PRs. Email templates are MJML that version controls our entire customer communication system.</p>
<p>Even our investor deck is code — a Next.js 16 static site with 17 React slide components, keyboard navigation, and PDF export. No PowerPoint, no Google Slides. When we update metrics or messaging, it's a code change with full Git history, reviewed in a PR, and deployed with <code>git push</code>.</p>
<p><strong>Why this matters</strong>:</p>
<ul>
<li>Marketing can update copy without engineering</li>
<li>Changes are reviewed and tracked</li>
<li>Rollback is one <code>git revert</code> away</li>
<li>Email campaigns are testable and diffable</li>
</ul>
<h3>Documentation</h3>
<pre><code>docs/                           # Public docs (Mintlify)
├── index.mdx                  # Landing page
├── quickstart.mdx             # Getting started
├── demo-mode.mdx              # Demo mode guide
├── features/                  # Product features
│   ├── ai-chat.mdx
│   ├── code-intelligence.mdx
│   ├── code-search.mdx
│   └── prds.mdx
├── integrations/              # Integration guides
│   ├── github.mdx
│   ├── linear.mdx
│   ├── jira.mdx
│   └── asana.mdx
└── bug-tracking/              # Bug tracking docs

docs-internal/                  # Engineering knowledge base
├── GITHUB_CHAT_ARCHITECTURE.md
├── QUEUE_ARCHITECTURE_SUMMARY.md
├── UNIFIED_TASK_ANALYTICS_QUEUE.md
├── features/                  # Feature specs
├── migrations/                # Migration guides
├── plans/                     # Implementation plans
└── research/                  # Research notes
</code></pre>
<p>Public docs deploy automatically when we push. Internal docs are searchable alongside code—when someone asks "how does the queue work?", they find the actual architecture document, not a stale wiki page.</p>
<h3>External Services</h3>
<pre><code>external/
├── chrome-extension/          # WXT-based bug capture tool
│   ├── entrypoints/          # popup, content scripts, background
│   ├── lib/                  # Screen capture, console logging
│   ├── components/           # React UI components
│   └── wxt.config.ts         # WXT configuration
│
├── google-docs-addon/        # @helper mentions in Docs
│   ├── Code.gs              # Main Apps Script (18KB)
│   ├── Sidebar.html         # React-like UI (26KB)
│   ├── Settings.html        # Configuration UI
│   └── appsscript.json      # Manifest
│
└── google-cloud-functions/
    ├── tree-sitter-service/  # AST parsing
    │   └── Supports: JS, TS, Python, Go, Rust,
    │       Java, C, C++, Ruby, PHP, C#
    └── mobbin-research-service/  # UX research
</code></pre>
<p>These deploy to completely different platforms (Chrome Web Store, Google Apps Script, GCP) but live together because:</p>
<ul>
<li>They share API contracts with the main app</li>
<li>Changes often span boundaries</li>
<li>One team maintains everything</li>
</ul>
<h3>Development Infrastructure</h3>
<pre><code>github-simulator/              # Mock GitHub API for local dev
infra-tester/                  # Integration test harness
scripts/
├── google-cloud/             # GCP deployment scripts
├── test-credentials.ts       # Credential testing
└── test-webhook-integration.ts
</code></pre>
<p>Local development shouldn't require external services. Mock servers live with the code they simulate.</p>
<hr>
<h2>What Deploys Where</h2>
<table><thead><tr><th>Component</th><th>Tech Stack</th><th>Deploys To</th></tr></thead><tbody><tr><td>Frontend</td><td>Next.js 15, React 19, Tailwind v4</td><td>Vercel</td></tr><tr><td>Backend</td><td>Cloudflare Workers, Hono, Mastra</td><td>Cloudflare</td></tr><tr><td>Website</td><td>Next.js, custom components</td><td>Vercel</td></tr><tr><td>Investor Deck</td><td>Next.js, custom components</td><td>Vercel</td></tr><tr><td>Docs</td><td>Mintlify MDX</td><td>Mintlify</td></tr><tr><td>Chrome Extension</td><td>WXT, React, Tailwind</td><td>Chrome Web Store</td></tr><tr><td>Google Docs Add-on</td><td>Apps Script, HTML</td><td>Google Workspace Marketplace</td></tr><tr><td>Tree-sitter Service</td><td>Node.js, GCP Functions</td><td>Google Cloud</td></tr><tr><td>Email Templates</td><td>MJML</td><td>Loops.so</td></tr></tbody></table>
<hr>
<h2>How We Make It Work</h2>
<h3>No Workspaces (And That's Fine)</h3>
<p>We deliberately don't use npm/yarn workspaces. (Well, we do in <em>one</em> specific use case but that's for another post.) Each directory is its own independent npm project:</p>
<pre><code><span>cd</span> frontend &amp;&amp; npm install    <span># Frontend dependencies</span>
<span>cd</span> backend &amp;&amp; npm install     <span># Backend dependencies</span>
<span>cd</span> external/chrome-extension &amp;&amp; npm install  <span># Extension dependencies</span>
</code></pre>
<p>Why? Simplicity. No hoisting confusion. No "which version of React am I actually getting?" Each project is isolated and predictable.</p>
<h3>Selective CI/CD</h3>
<p>We run 5 GitHub Actions workflows, each triggered by specific paths:</p>
<pre><code><span># .github/workflows/frontend-tests.yml</span>
<span>name:</span> <span>Frontend</span> <span>Tests</span>
<span>on:</span>
  <span>push:</span>
    <span>paths:</span>
      <span>-</span> <span>"frontend/**"</span>
      <span>-</span> <span>".github/workflows/frontend-tests.yml"</span>
<span># Runs: type-check, lint, demo data validation, tests with coverage</span>
</code></pre>
<pre><code><span># .github/workflows/backend-tests.yml</span>
<span>name:</span> <span>Backend</span> <span>Tests</span>
<span>on:</span>
  <span>push:</span>
    <span>paths:</span>
      <span>-</span> <span>"backend/**"</span>
      <span>-</span> <span>".github/workflows/backend-tests.yml"</span>
<span># Runs: unit tests, integration tests, e2e tests</span>
</code></pre>
<pre><code><span># .github/workflows/tree-sitter-tests.yml</span>
<span>name:</span> <span>Tree-sitter</span> <span>Tests</span>
<span>on:</span>
  <span>push:</span>
    <span>paths:</span>
      <span>-</span> <span>"external/google-cloud-functions/tree-sitter-service/**"</span>
<span># Runs: parsing tests for all 10+ supported languages</span>
</code></pre>
<p>Change the Chrome extension? Only relevant tests run. Update the backend? Backend tests plus any integration tests that depend on it.</p>
<h3>The CLAUDE.md Convention</h3>
<p>Every major directory has a CLAUDE.md file that documents:</p>
<ul>
<li>What this code does</li>
<li>Tech stack and versions</li>
<li>Quick start commands</li>
<li>Architecture decisions</li>
<li>Common patterns</li>
</ul>
<pre><code>CLAUDE.md                          # Root-level overview
├── frontend/CLAUDE.md            # Next.js 15, React 19, Tailwind v4
├── backend/CLAUDE.md             # Cloudflare Workers, Hono, Mastra
├── external/chrome-extension/CLAUDE.md
├── external/google-cloud-functions/CLAUDE.md
└── marketing/email/CLAUDE.md     # MJML email guidelines
</code></pre>
<p>This isn't just for humans—AI coding assistants read these files. When Claude Code works on our frontend, it reads <code>frontend/CLAUDE.md</code> and knows we're using Next.js 15 with React 19, npm (not pnpm), and specific patterns.</p>
<h3>Consistent Tooling</h3>
<p>One configuration, everywhere:</p>
<pre><code>.prettierrc              # Formatting (all JS/TS)
.eslintrc               # Linting (shared rules)
tsconfig.json           # TypeScript base config
</code></pre>
<p>New developer? <code>npm install</code> in the directory you're working on. Everything works.</p>
<hr>
<h2>The Challenges (And How We Handle Them)</h2>
<h3>Challenge: Repository Size</h3>
<p><strong>Why it's not a problem (yet):</strong></p>
<ul>
<li>Clone time: ~20 seconds</li>
<li>Git operations: still snappy</li>
<li>We haven't needed sparse checkout, LFS, or shallow clones</li>
</ul>
<p><strong>When we might need to:</strong></p>
<ul>
<li>Large binary assets would go to R2/S3, not git</li>
<li>If we hit 1GB+, we'd look at shallow clones for CI</li>
<li>Truly independent services could be extracted</li>
</ul>
<h3>Challenge: Build Times</h3>
<p><strong>Problem</strong>: If everything is connected, does everything rebuild?</p>
<p><strong>Reality</strong>: No. Each project builds independently:</p>
<pre><code><span># Frontend build (only rebuilds frontend)</span>
<span>cd</span> frontend &amp;&amp; npm run build

<span># Backend build (only rebuilds backend)</span>
<span>cd</span> backend &amp;&amp; npm run build

<span># Extension build (only rebuilds extension)</span>
<span>cd</span> external/chrome-extension &amp;&amp; npm run build
</code></pre>
<p>We use Turbopack for frontend dev (fast HMR), Wrangler for backend dev (fast reload), and WXT for extension dev (fast rebuild).</p>
<h3>Challenge: Permission Boundaries</h3>
<p><strong>Problem</strong>: Not everyone should see everything.</p>
<p><strong>Our situation</strong>: We're a small team. Everyone can see everything. That's a feature, not a bug—it enables cross-pollination.</p>
<p><strong>If we grew and needed boundaries:</strong></p>
<ul>
<li>GitHub CODEOWNERS for review requirements</li>
<li>Branch protection rules</li>
<li>Potentially split truly sensitive codebases (but we'd resist this)</li>
</ul>
<h3>Challenge: Context Switching</h3>
<p><strong>Problem</strong>: Jumping between TypeScript (frontend), TypeScript (backend), Apps Script (Google add-on), and MJML (emails) feels disorienting.</p>
<p><strong>Solutions:</strong></p>
<ul>
<li>Consistent patterns across projects (same linting, same formatting)</li>
<li>CLAUDE.md files explain context immediately</li>
<li>IDE workspace configurations</li>
</ul>
<hr>
<h2>Conclusion</h2>
<p>Our monorepo isn't about following a trend. It's about removing friction between things that naturally belong together, something that is critical when related context is everything.</p>
<p>When a feature touches the backend API, the frontend component, the documentation, and the marketing site—why should that be four repositories, four PRs, four merge coordination meetings?</p>
<p>The monorepo isn't a constraint. It's a force multiplier.</p>
<hr>
<p><em>Kasava is built as a unified platform. <a href="https://kasava.dev/">See what we've built</a></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zpdf: PDF text extraction in Zig – 5x faster than MuPDF (132 pts)]]></title>
            <link>https://github.com/Lulzx/zpdf</link>
            <guid>46437288</guid>
            <pubDate>Tue, 30 Dec 2025 19:57:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Lulzx/zpdf">https://github.com/Lulzx/zpdf</a>, See on <a href="https://news.ycombinator.com/item?id=46437288">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">zpdf (alpha stage - early version)</h2><a id="user-content-zpdf-alpha-stage---early-version" aria-label="Permalink: zpdf (alpha stage - early version)" href="#zpdf-alpha-stage---early-version"></a></p>
<p dir="auto">A PDF text extraction library written in Zig.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Memory-mapped file reading for efficient large file handling</li>
<li>Streaming text extraction with efficient arena allocation</li>
<li>Multiple decompression filters: FlateDecode, ASCII85, ASCIIHex, LZW, RunLength</li>
<li>Font encoding support: WinAnsi, MacRoman, ToUnicode CMap</li>
<li>XRef table and stream parsing (PDF 1.5+)</li>
<li>Configurable error handling (strict or permissive)</li>
<li>Multi-threaded parallel page extraction</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark</h2><a id="user-content-benchmark" aria-label="Permalink: Benchmark" href="#benchmark"></a></p>
<p dir="auto">Text extraction performance vs MuPDF 1.26 (<code>mutool convert -F text</code>) on Apple M4 Pro:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sequential</h3><a id="user-content-sequential" aria-label="Permalink: Sequential" href="#sequential"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Document</th>
<th>Pages</th>
<th>Size</th>
<th>zpdf</th>
<th>MuPDF</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://open-std.org/jtc1/sc22/wg21/docs/papers/2023/n4950.pdf" rel="nofollow">C++ Standard Draft</a></td>
<td>2,134</td>
<td>8 MB</td>
<td>250 ms</td>
<td>968 ms</td>
<td><strong>3.9x</strong></td>
</tr>
<tr>
<td><a href="https://pandas.pydata.org/pandas-docs/version/1.4/pandas.pdf" rel="nofollow">Pandas Documentation</a></td>
<td>3,743</td>
<td>15 MB</td>
<td>395 ms</td>
<td>1,112 ms</td>
<td><strong>2.8x</strong></td>
</tr>
<tr>
<td><a href="https://cdrdv2.intel.com/v1/dl/getContent/671200" rel="nofollow">Intel SDM</a></td>
<td>5,252</td>
<td>25 MB</td>
<td>451 ms</td>
<td>2,099 ms</td>
<td><strong>4.7x</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parallel (default)</h3><a id="user-content-parallel-default" aria-label="Permalink: Parallel (default)" href="#parallel-default"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Document</th>
<th>Pages</th>
<th>Size</th>
<th>zpdf</th>
<th>MuPDF</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>C++ Standard Draft</td>
<td>2,134</td>
<td>8 MB</td>
<td>131 ms</td>
<td>966 ms</td>
<td><strong>7.4x</strong></td>
</tr>
<tr>
<td>Pandas Documentation</td>
<td>3,743</td>
<td>15 MB</td>
<td>218 ms</td>
<td>1,117 ms</td>
<td><strong>5.1x</strong></td>
</tr>
<tr>
<td>Intel SDM</td>
<td>5,252</td>
<td>25 MB</td>
<td>117 ms</td>
<td>2,098 ms</td>
<td><strong>17.9x</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Peak throughput: <strong>45,000 pages/sec</strong> (Intel SDM, parallel)</p>
<p dir="auto">Build with <code>zig build -Doptimize=ReleaseFast</code> for these results.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SIMD Acceleration</h3><a id="user-content-simd-acceleration" aria-label="Permalink: SIMD Acceleration" href="#simd-acceleration"></a></p>
<p dir="auto">zpdf uses SIMD-accelerated routines for hot paths:</p>
<ul dir="auto">
<li>Whitespace skipping (content streams are whitespace-heavy)</li>
<li>Delimiter detection (tokenization)</li>
<li>Keyword search (<code>stream</code>, <code>endstream</code>, <code>startxref</code>)</li>
<li>String boundary scanning</li>
</ul>
<p dir="auto">Auto-detects: NEON (ARM64), AVX2/SSE4.2 (x86_64), or scalar fallback.</p>
<p dir="auto"><em>Note: MuPDF's threading (<code>-T</code> flag) is for rendering/rasterization only. Text extraction via <code>mutool convert -F text</code> is single-threaded by design. zpdf parallelizes text extraction across pages.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Accuracy</h3><a id="user-content-accuracy" aria-label="Permalink: Accuracy" href="#accuracy"></a></p>
<p dir="auto">Text extraction accuracy vs MuPDF (reference) on US Constitution (85 pages):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Tool</th>
<th>Char Accuracy</th>
<th>WER</th>
<th>Time</th>
<th>vs MuPDF</th>
</tr>
</thead>
<tbody>
<tr>
<td>zpdf</td>
<td>99.6%</td>
<td>2.1%</td>
<td>2 ms</td>
<td><strong>24x faster</strong></td>
</tr>
<tr>
<td>MuPDF</td>
<td>100%</td>
<td>0%</td>
<td>54 ms</td>
<td>1x</td>
</tr>
<tr>
<td>Tika</td>
<td>97.4%</td>
<td>10.6%</td>
<td>1,307 ms</td>
<td>24x slower</td>
</tr>
<tr>
<td>pdftotext</td>
<td>57.0%</td>
<td>19.8%</td>
<td>90 ms</td>
<td>1.7x slower</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<ul dir="auto">
<li><strong>Char Accuracy</strong>: Sequence similarity vs MuPDF baseline (higher = better)</li>
<li><strong>WER</strong>: Word Error Rate vs MuPDF baseline (lower = better)</li>
</ul>
<p dir="auto">MuPDF is the accuracy baseline (100%). zpdf is 650x faster than Tika with better accuracy.</p>
<p dir="auto">Run <code>PYTHONPATH=python python benchmark/accuracy.py</code> to reproduce.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>Zig 0.15.2 or later</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="zig build              # Build library and CLI
zig build test         # Run tests"><pre>zig build              <span><span>#</span> Build library and CLI</span>
zig build <span>test</span>         <span><span>#</span> Run tests</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Library</h3><a id="user-content-library" aria-label="Permalink: Library" href="#library"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="const zpdf = @import(&quot;zpdf&quot;);

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    const doc = try zpdf.Document.open(allocator, &quot;file.pdf&quot;);
    defer doc.close();

    var buf: [4096]u8 = undefined;
    var writer = std.fs.File.stdout().writer(&amp;buf);
    defer writer.interface.flush() catch {};

    for (0..doc.pages.items.len) |page_num| {
        try doc.extractText(page_num, &amp;writer.interface);
    }
}"><pre><span>const</span> <span>zpdf</span> <span>=</span> <span>@import</span>(<span>"zpdf"</span>);

<span>pub</span> <span>fn</span> <span>main</span>() <span>!</span><span>void</span> {
    <span>var</span> <span>gpa</span> <span>=</span> <span>std</span>.<span>heap</span>.<span>GeneralPurposeAllocator</span>(.{}){};
    <span>defer</span> <span>_</span> <span>=</span> <span>gpa</span>.<span>deinit</span>();
    <span>const</span> <span>allocator</span> <span>=</span> <span>gpa</span>.<span>allocator</span>();

    <span>const</span> <span>doc</span> <span>=</span> <span>try</span> <span>zpdf</span>.<span>Document</span>.<span>open</span>(<span>allocator</span>, <span>"file.pdf"</span>);
    <span>defer</span> <span>doc</span>.<span>close</span>();

    <span>var</span> <span>buf</span>: [<span>4096</span>]<span>u8</span> <span>=</span> <span>undefined</span>;
    <span>var</span> <span>writer</span> <span>=</span> <span>std</span>.<span>fs</span>.<span>File</span>.<span>stdout</span>().<span>writer</span>(<span>&amp;</span><span>buf</span>);
    <span>defer</span> <span>writer</span>.<span>interface</span>.<span>flush</span>() <span>catch</span> {};

    <span>for</span> (0<span>..</span><span>doc</span>.<span>pages</span>.<span>items</span>.<span>len</span>) <span>|</span><span>page_num</span><span>|</span> {
        <span>try</span> <span>doc</span>.<span>extractText</span>(<span>page_num</span>, <span>&amp;</span><span>writer</span>.<span>interface</span>);
    }
}</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">CLI</h3><a id="user-content-cli" aria-label="Permalink: CLI" href="#cli"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="zpdf extract document.pdf           # Extract all pages to stdout
zpdf extract -p 1-10 document.pdf   # Extract pages 1-10
zpdf extract -o out.txt document.pdf # Output to file
zpdf info document.pdf              # Show document info
zpdf bench document.pdf             # Run benchmark"><pre>zpdf extract document.pdf           <span><span>#</span> Extract all pages to stdout</span>
zpdf extract -p 1-10 document.pdf   <span><span>#</span> Extract pages 1-10</span>
zpdf extract -o out.txt document.pdf <span><span>#</span> Output to file</span>
zpdf info document.pdf              <span><span>#</span> Show document info</span>
zpdf bench document.pdf             <span><span>#</span> Run benchmark</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import zpdf

with zpdf.Document(&quot;file.pdf&quot;) as doc:
    print(doc.page_count)

    # Single page
    text = doc.extract_page(0)

    # All pages (parallel by default)
    all_text = doc.extract_all()

    # Page info
    info = doc.get_page_info(0)
    print(f&quot;{info.width}x{info.height}&quot;)"><pre><span>import</span> <span>zpdf</span>

<span>with</span> <span>zpdf</span>.<span>Document</span>(<span>"file.pdf"</span>) <span>as</span> <span>doc</span>:
    <span>print</span>(<span>doc</span>.<span>page_count</span>)

    <span># Single page</span>
    <span>text</span> <span>=</span> <span>doc</span>.<span>extract_page</span>(<span>0</span>)

    <span># All pages (parallel by default)</span>
    <span>all_text</span> <span>=</span> <span>doc</span>.<span>extract_all</span>()

    <span># Page info</span>
    <span>info</span> <span>=</span> <span>doc</span>.<span>get_page_info</span>(<span>0</span>)
    <span>print</span>(<span>f"<span><span>{</span><span>info</span>.<span>width</span><span>}</span></span>x<span><span>{</span><span>info</span>.<span>height</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto">Build the shared library first:</p>
<div dir="auto" data-snippet-clipboard-copy-content="zig build -Doptimize=ReleaseFast
PYTHONPATH=python python3 examples/basic.py"><pre>zig build -Doptimize=ReleaseFast
PYTHONPATH=python python3 examples/basic.py</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="src/
├── root.zig         # Document API and core types
├── capi.zig         # C ABI exports for FFI
├── parser.zig       # PDF object parser
├── xref.zig         # XRef table/stream parsing
├── pagetree.zig     # Page tree resolution
├── decompress.zig   # Stream decompression filters
├── encoding.zig     # Font encoding and CMap parsing
├── interpreter.zig  # Content stream interpreter
├── simd.zig         # SIMD string operations
└── main.zig         # CLI

python/zpdf/         # Python bindings (cffi)
examples/            # Usage examples"><pre><code>src/
├── root.zig         # Document API and core types
├── capi.zig         # C ABI exports for FFI
├── parser.zig       # PDF object parser
├── xref.zig         # XRef table/stream parsing
├── pagetree.zig     # Page tree resolution
├── decompress.zig   # Stream decompression filters
├── encoding.zig     # Font encoding and CMap parsing
├── interpreter.zig  # Content stream interpreter
├── simd.zig         # SIMD string operations
└── main.zig         # CLI

python/zpdf/         # Python bindings (cffi)
examples/            # Usage examples
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Comparison with MuPDF</h2><a id="user-content-comparison-with-mupdf" aria-label="Permalink: Comparison with MuPDF" href="#comparison-with-mupdf"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>zpdf</th>
<th>MuPDF</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Text Extraction</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Reading order / layout analysis</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Two-column detection</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Paragraph grouping</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Word/line bounding boxes</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Font Support</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>WinAnsi/MacRoman</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>ToUnicode CMap</td>
<td>Partial*</td>
<td>Yes</td>
</tr>
<tr>
<td>CID fonts (Type0)</td>
<td>Partial*</td>
<td>Yes</td>
</tr>
<tr>
<td>Embedded fonts</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>Compression</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>FlateDecode, LZW, ASCII85/Hex</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>JBIG2, JPEG2000</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td><strong>PDF Features</strong></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Incremental updates</td>
<td>Yes</td>
<td>Yes</td>
</tr>
<tr>
<td>Encrypted PDFs</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Forms / Annotations</td>
<td>No</td>
<td>Yes</td>
</tr>
<tr>
<td>Rendering</td>
<td>No</td>
<td>Yes</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><em>*ToUnicode/CID fonts: Works when CMap is embedded directly. References to compressed object streams not yet supported (affects some Greek, Chinese, Japanese, Korean PDFs).</em></p>
<p dir="auto"><strong>Use zpdf when:</strong> Speed matters, simple layouts, batch processing raw text.</p>
<p dir="auto"><strong>Use MuPDF when:</strong> Complex layouts, encrypted PDFs, non-Latin scripts.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">WTFPL</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FediMeteo: A €4 FreeBSD VPS Became a Global Weather Service (232 pts)]]></title>
            <link>https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/</link>
            <guid>46436889</guid>
            <pubDate>Tue, 30 Dec 2025 19:21:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/">https://it-notes.dragas.net/2025/02/26/fedimeteo-how-a-tiny-freebsd-vps-became-a-global-weather-service-for-thousands/</a>, See on <a href="https://news.ycombinator.com/item?id=46436889">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main" itemprop="articleBody"><h2>Personal Introduction</h2><p>Weather has always significantly influenced my life. When I was a young athlete, knowing the forecast in advance would have allowed me to better plan my training sessions. As I grew older, I could choose whether to go to school on my motorcycle or, for safety reasons, have my grandfather drive me. And it was him, my grandfather, who was my go-to meteorologist. He followed all weather patterns and forecasts, a remnant of his childhood in the countryside and his life on the move. It's to him that I dedicate <a href="https://fedimeteo.com/">FediMeteo</a>.</p><p>The idea for <a href="https://fedimeteo.com/">FediMeteo</a> started almost by chance while I was checking the holiday weather forecast to plan an outing. Suddenly, I thought how nice it would be to receive regular weather updates for my city directly in my timeline. After reflecting for a few minutes, I registered a domain and started planning.</p><h2>Design Principles</h2><p>The choice of operating system was almost automatic. The idea was to separate instances by country, and FreeBSD jails are one of the most useful tools for this purpose.</p><p>I initially thought the project would generate little interest. I was wrong. After all, weather affects many of our lives, directly or indirectly. So I decided to structure everything in this way:</p><ul><li><p>I would use a test VPS to see how things would go. The VPS <em>was a small VM on a German provider with 4 shared cores, 4GB of RAM, 120GB of SSD disk space, and a 1Gbit/sec internet connection</em> and now is a 4 euro per month VPS in Milano, Italy - 4 shared cores, 8 GB RAM and 75GB disk space.</p></li><li><p>I would separate various countries into different instances, for both management and security reasons, as well as to have the possibility of relocating just some of them if needed.</p></li><li><p>Weather data would come from a reliable and open-source friendly source. I narrowed it down to two options: <a href="https://wttr.in/">wttr.in</a> and <a href="https://open-meteo.com/">Open-Meteo</a>, two solutions I know and that have always given me reliable results.</p></li><li><p>I would pay close attention to accessibility: forecasts would be in local languages, consultable via text browsers, with emojis to give an idea even to those who don't speak local languages, and everything would be accessible without JavaScript or other requirements. One's mother tongue is always more "familiar" than a second language, even if you're fluent.</p></li><li><p>I would manage everything according to Unix philosophy: small pieces working together. The more years pass, the more I understand how valuable this approach is.</p></li><li><p>The software chosen to manage the instances is <a href="https://codeberg.org/grunfink/snac2">snac</a>. Snac embodies my philosophy of minimal and effective software, perfect for this purpose. It provides clear web pages for those who want to consult via the web, "speaks" the ActivityPub protocol perfectly, produces RSS feeds for each user (i.e., city), has extremely low RAM and CPU consumption, compiles in seconds, and is stable. The developer is an extremely helpful and positive person, and in my opinion, this carries equal weight as everything else.</p></li><li><p>I would do it for myself. If there was no interest, I would have kept it running anyway, without expanding it. So no anxiety or fear of failure.</p></li></ul><h2>Technical Implementation</h2><p>I started setting up the first "pieces" during the days around Christmas 2024. The scheme was clear: each jail would handle everything internally. A Python script would download data, city by city, and produce markdown. The city coordinates would be calculated via the <a href="https://geopy.readthedocs.io/en/stable/">geopy</a> library and passed to <a href="https://wttr.in/">wttr.in</a> and <a href="https://open-meteo.com/">Open-Meteo</a>. No data would be stored locally. This approach gives the ability to process all cities together. Just pass the city and country to the script, and the markdown would be served. At that point, snac comes into play: without the need to use external utilities, the "snac note" command allows posting from stdin by specifying the instance directory and the user to post from. No need to make API calls with external utilities, having to manage API keys, permissions, etc.</p><h3>Setting Up for Italy</h3><p>To simplify things, I first structured the jail for Italy. I made a list of the main cities, normalizing them. For example, La Spezia became la_spezia. Forlì, with an accent, became forli - this for maximum compatibility since each city would be a snac user. I then created a script that takes this list and creates snac users via "snac adduser." At that point, after creating all the users, the script would modify the JSON of each user to convert the city name to uppercase, insert the bio (a standard text), activate the "bot" flag, and set the avatar, which was the same for all users at the time. This script is also able to add a new city: just run the script with the (normalized) name of the city, and it will add it - also adding it to the "cities.txt" file, so it will be updated in the next weather update cycle.</p><h3>Core Application Development</h3><p>I then created the heart of the service. A Python application (initially only in Italian, then multilingual, separating the operational part from the text) able to receive (via command line) the name of a city and a country code (corresponding to the file with texts in the local language). The script determines the coordinates and then, using API calls, requests the current weather conditions, those for the next 12 hours, and the next 7 days. I conducted experiments with both wttr.in and Open-Meteo, and both gave good results. However, I settled on Open-Meteo because, for my uses, it has always provided very reliable results. This application directly provides an output in Markdown since snac supports it, at least partially.</p><p>The cities.txt file is also crucial for updates. I created a script - post.sh, in pure sh, that scrolls through all cities, and for each one, launches the FediMeteo application and publishes its output using snac directly via command line. Once the job is finished, it makes a call to my instance of <a href="https://it-notes.dragas.net/2024/07/22/install-uptime-kuma-freebsd-jail/">Uptime-Kuma</a>, which keeps an eye on the situation. In case of failure, the monitoring will alert me that there have been no recent updates, and I can check.</p><p>At this point, the system cron takes care of launching post.sh every 6 hours. The requests are serialized, so the cities will update one at a time, and the posts will be sent to followers.</p><h2>Growth and Unexpected Success</h2><p>After listing all Italian provincial capitals, I started testing everything. It worked perfectly. Of course, I had to make some adjustments at all levels. For example, one of the problems encountered was that snac did not set the language of the posts, and some users could have missed them. The developer was very quick and, as soon as I exposed the problem, immediately modified the program so that the post could keep the system language, set as an environment variable in the sh script.</p><p>After two days, I decided to start adding other countries and announce the project. And the announcement was unexpectedly well received: there were many boosts, and people started asking me to add their cities or countries. I tried to do what I could, within the limits of my physical condition, as in those days, I had the flu that kept me at home with a fever and illness for several days. I started adding many countries in the heart of Europe, translating the main indications into local languages but maintaining emojis so that everything would be understandable even to those who don't speak the local language. There were some small problems reported by some users. One of them: not all weather conditions had been translated, so sometimes they appeared in Italian - as well as errors. In bilingual countries, I tried to include all local languages. Sometimes, unfortunately, making mistakes as I encountered dynamics unknown to me or difficult to interpret. For example, in Ireland, forecasts were published in Irish, but it was pointed out to me that not everyone speaks it, so I modified and published in English.</p><h3>A Turning Point</h3><p>The turning point was when FediFollows (<a href="https://social.growyourown.services/@FediFollows">@FediFollows@social.growyourown.services</a> - who also manages the site <a href="https://fedi.directory/">Fedi Directory</a>) started publishing the list of countries and cities, highlighting the project. Many people became aware of FediMeteo and started following the various accounts, the various cities. And from here came requests to add new countries and some new information, such as wind speed. Moreover, I was asked (rightly, to avoid flooding timelines) to publish posts as unlisted - this way, followers would see the posts, but they wouldn't fill local timelines. Snac didn't support this, but again, the snac dev came to my rescue in a few hours.</p><h2>Scaling Challenges</h2><p>But with new countries came new challenges. For example, in my original implementation, all units of measurement were in metric/decimal/Celsius - and this doesn't adapt well to realities like the USA. Moreover, focusing on Europe, almost all countries were located in a single timezone, while for larger countries (such as Australia, USA, Canada, etc.), this is totally different. So I started developing a more complete and global version and, in the meantime, added almost all of Europe. The new version would have to be backward compatible, would have to take into account timezone differences for each city, different measurements (e.g., degrees C and F), as well as, initially more difficult part, being able to separate cities with the same name based on states or provinces. I had already seen a similar problem with the implementation of support for Germany, so it had to be addressed properly.</p><p>The original goal was to have a VPS for each continent, but I soon realized that thanks to the quality of snac's code and FreeBSD's efficient management, even keeping countries in separate jails, the load didn't increase much. So I decided to challenge myself and the limits of the economical 4 euros per month VPS. That is, to insert as much as possible until seeing what the limits were. Limits that, to date, I have not yet reached. I would also soon exhaust the available API calls for Open-Meteo's free accounts, so I tried to contact the team and explain everything. I was positively surprised to read that they appreciated the project and provided me with a dedicated API key.</p><p>Compatible with my free time, I managed to complete the richer and more complete version of my Python program. I'm not a professional dev, I'm more oriented towards systems, so the code is probably quite poor in the eyes of an expert dev. But, in the end, it just needs to take an input and give me an output. It's not a daemon, it's not a service that responds on the network. For that, snac takes care of it.</p><h2>Expansion to North America</h2><p>So I decided to start with a very important launch: the USA and Canada. A non-trivial part was identifying the main cities in order to cover, state by state, all the territory. In the end, I identified more than 1200 cities. A number that, by itself, exceeded the sum of all other countries (at that time). And the program, now, is able to take an input with a separator (two underscores: __) between city and state. In this way, it's possible to perfectly understand the differences between city and state: new_york__new_york is an example I like to make, but there are many.</p><p>The launch of the USA was interesting: despite having had many previous requests, the reception was initially quite lukewarm, to my extreme surprise. The number of followers in Canada, in a few hours, far exceeded that of the USA. On the contrary, the country with the most followers (in a few days, more than 1000) was Germany. Followed by the UK - which I expected would have been the first.</p><h2>System Performance</h2><p>The VPS held up well. Except for the moments when FediFollows launched (after fixing some FreeBSD tuning, the service slowed slightly but didn't crash), the load remained extremely low. So I continued to expand: Japan, Australia, New Zealand, etc.</p><h2>Current Status</h2><p>At the time of the last update of this article (30 December 2025), the supported countries are 38: Argentina, Australia, Austria, Belgium, Brazil, Bulgaria, Canada, Croatia, Czechia, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, India, Ireland, Italy, Japan, Latvia, Lithuania, Malta, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Romania, Slovakia, Slovenia, Spain, Sweden, Switzerland, Taiwan, the United Kingdom, and the United States of America (with more regions coming soon!).</p><p>Direct followers in the Fediverse are around 7,707 and growing daily, excluding those who follow hashtags or cities via RSS, whose number I can't estimate. However, a quick look at the logs suggests there are many more.</p><p>The cities currently covered are 2937 - growing based on new countries and requests.</p><h2>Challenges Encountered</h2><p>There have been some problems. The most serious, by my fault, was the API key leak: I had left a debug code active and, the first time Open-Meteo had problems, the error message also included the API call - including the API key. Some users reported it to me (others just mocked) and I fixed the code and immediately reported everything to the Open-Meteo team, who kindly gave me a new API Key and deactivated the old one.</p><p>A further problem was related to geopy. It makes a call to Nominatim to determine coordinates. One of the times Nominatim didn't respond, my program wasn't able to determine the position and went into error. I solved this by introducing coordinate caching: now the program, the first time it encounters a city, requests and saves the coordinates. If present, they will be used in the future without making a new request via geopy. This is both lighter on their servers and faster and safer for us.</p><h2>Infrastructure Details</h2><p>And the VPS? It has no problems and is surprisingly fast and effective. FreeBSD 14.3-RELEASE, BastilleBSD to manage the jails. Currently, there are 39 jails - one for haproxy, the <a href="https://fedimeteo.com/">FediMeteo website</a>, so nginx, and the snac instance for <a href="https://fedimeteo.com/fedi/admin">FediMeteo announcements and support</a> - the other 38 for the individual instances. Each of them, therefore, has its autonomous ZFS dataset. Every 15 minutes, there is a local snapshot of all datasets. Every hour, the homepage is regenerated: a small script calculates the number of followers (counting, instance by instance, the followers of individual cities, since I don't publish except in aggregate to avoid possible triangulations and privacy leaks of users). Every hour, moreover, an external backup is made via <a href="https://it-notes.dragas.net/2022/05/30/how-we-are-migrating-many-of-our-servers-from-linux-to-freebsd-part-2/">zfs-autobackup</a> (on encrypted at rest dataset), and once a day, a further backup is made in my datacenter, on disks encrypted with geli. The occupied RAM is 501 MB (yes, exactly: 501 MB), which rises slightly when updates are in progress. Updates normally occur every 6 hours. I have tried, as much as possible, to space them out to avoid overloads in timelines (or on the server itself). Only for the USA, I added a sleep of 5 seconds between one city and another, to give snac the opportunity to better organize the sending of messages. It probably wouldn't be necessary, with the current numbers, but better safe than sorry. In this way, the USA is processed in about 2 and a half hours, but the other jails (thus countries) can work autonomously and send their updates.</p><p>The average load of the VPS (taking as reference both the last 24 hours and the last two weeks) is about 25%, as it rises to 70/75% when updates occur for larger instances (such as the USA), or when it is announced by FediFollows. Otherwise, it is on average less than 10%. So, the VPS still has huge margin, and new instances, with new nations, will still be inside it.</p><h2>Conclusion</h2><p>This article, although in some parts very conversational, aims to demonstrate how it's possible to build solid, valid, and efficient solutions without the need to use expensive and complex services. Moreover, this is the demonstration of how it's possible to have your online presence without the need to put your data in the hands of third parties or without necessarily having to resort to complex stacks. Sometimes, less is more.</p><p>The success of this project demonstrates, once again, that my grandfather was right: weather forecasts interest everyone. He worried about my health and, thanks to his concerns, we spent time together. In the same way, I see many followers and friends talking to me or among themselves about the weather, their experiences, what happens. Again, in my life, weather forecasts have helped sociality and socialization.</p><p>Thank you, Grandpa.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Now That He Has No Power, Mitt Romney Says "Tax the Rich" (111 pts)]]></title>
            <link>https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/</link>
            <guid>46436687</guid>
            <pubDate>Tue, 30 Dec 2025 19:00:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/">https://jacobin.com/2025/12/romney-tax-rich-op-ed-nyt/</a>, See on <a href="https://news.ycombinator.com/item?id=46436687">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="post-content"><p>Why is it that powerful people typically wait until they have no power to take the right position and effectively admit they were wrong when they had more power to do something about it?</p>
<p>We see this happen so often that it’s barely noticeable anymore. There were the Iraq War proponents <a href="https://time.com/6107901/colin-powell-legacy/?utm_source=chatgpt.com" target="_blank" rel="noreferrer noopener">renouncing</a> their <a href="https://www.politico.com/story/2007/02/half-of-democratic-senators-regret-iraq-vote-002639" target="_blank" rel="noreferrer noopener">past actions</a>. There was Barack Obama <a href="https://www.npr.org/2009/07/24/106969104/single-payer-the-health-care-plan-not-on-the-table" target="_blank" rel="noreferrer noopener">marginalizing</a> single-payer health care as president and then <a href="https://thehill.com/policy/healthcare/405597-obama-calls-medicare-for-all-a-good-idea/" target="_blank" rel="noreferrer noopener">touting</a> Medicare for All after he left office. There was James Carville telling Democrats to <a href="https://www.nytimes.com/2025/02/25/opinion/democrats-trump-congress.html" target="_blank" rel="noreferrer noopener">play dead</a> and then recognizing the zeitgeist and saying they should actually <a href="https://www.nytimes.com/2025/11/24/opinion/democrats-platform-economic-rage.html" target="_blank" rel="noreferrer noopener">go populist</a>. There’s the Lincoln Project founder who, when he <a href="https://x.com/SteveSchmidtSES/status/1314649342901456898" target="_blank" rel="noreferrer noopener">had power</a>, helped install John Roberts and Sam Alito on the Supreme Court — and who now casts himself as a leader of the resistance. There was Dick Cheney creating the tyrannical executive power for someone like Donald Trump to use and then Cheney at the tail end of his life becoming a big critic of Trump.</p>
<p>Now comes Mitt Romney — who campaigned for president on tax cuts for the wealthy — publishing a <em>New York Times</em> <a href="https://www.nytimes.com/2025/12/19/opinion/romney-tax-the-rich.html?partner=slack&amp;smid=sl-share" target="_blank" rel="noreferrer noopener">op-ed</a> arguing for higher taxes on the rich.</p>
<p>The obvious news of the op-ed is that we’ve reached a point in which even American politics’ very own Gordon Gekko — a private equity mogul turned Republican politician — is now admitting the tax system has been rigged for his fellow oligarchs.</p>
<p>And, hey, that’s good. I believe in the politics of addition. I believe in welcoming converts to good causes in the spirit of “better late than never.” I believe there should be space for people to change their views for the better. And I appreciate Romney offering at least some pro forma explanation about what allegedly changed his thinking (sidenote: I say “allegedly” because it’s not like Romney only just now learned that the tax system was rigged — he was literally a cofounder of Bain Capital!).</p>
<p>And yet these kinds of reversals (without explicit apologies, of course) often come off as both long overdue but also vaguely inauthentic, or at least not as courageous and principled as they seem.</p>
<p>Reversals held until after people leave positions of power often seem less like genuine efforts to change policy and more like after-the-fact attempts to belatedly repair their personal legacies for posterity. Worse, our society so often rewards that not just with a “better late than never” welcome but with valorization — as if the political icon who was so wrong for so long actually has more credibility on the issue rather than the people who were right all along.</p>
<p>In doing that, we remove a deterrent against people doing horrible things when they have agency. They know they can use their power in all sorts of venal ways in the here and now — and then still be celebrated as principled truth-tellers when they are later given coveted space in fancy newspapers like the <em>New York Times</em> to fess up to their bad behavior and/or reverse their awful positions.</p>
<p>This is the standard legacy-washing playbook among America’s elite — and it works as a PR strategy, at least for a time. But <em>real</em> legacies — the legacy of what actually happened in history and who is actually responsible for those events — are forged not by what people say after the fact, but by what they actually do when they have power and when there are real stakes in their policy positions.</p>
<p>For example: John McCain’s <a href="https://www.levernews.com/master-plan-ep-6-the-maverick-vs-the-corruption_machine/">legacy</a> as a campaign finance reformer was earned not because he got singed by the Keating Five scandal, then retired, and then wrote some op-eds about how bad corruption is. He earned his legacy because he remained in the Senate after that scandal, changed his whole posture on corruption, and actually used his power to pass campaign finance legislation.</p>
<p>McCain stands out on that set of issues because he did the opposite of what we typically witness. So often when politicians have power — when there are real stakes and when they need to have courage — they don’t do the right thing and take the obviously correct/moral position. Instead, they champion the very policy they later try to cleanse from their brand.</p>
<p>Here the Romney example is illustrative: When he was in a position to actually sculpt the national political discourse, the Republican Party platform, and ultimately the tax policy of the United States of America, Romney decided to run for president on a tax cut plan that would “bestow most of its benefits on those with the highest incomes,” according to the <a href="https://taxpolicycenter.org/taxvox/romneys-tax-plan-big-benefits-wealthy-and-higher-deficits" target="_blank" rel="noreferrer noopener">Tax Policy Center</a>. He also decided to <a href="https://www.motherjones.com/politics/2023/10/mitt-romney-a-reckoning-mcckay-coppins-47-percent-tailspin-2012/" target="_blank" rel="noreferrer noopener">portray</a> the bottom 47 percent of income earners as America’s real tax scofflaws — not his fellow private equity tycoons, who get to exploit the carried interest loophole <a href="https://www.npr.org/sections/money/2012/01/19/145449117/carried-interest-why-mitt-romneys-tax-rate-is-15-percent" target="_blank" rel="noreferrer noopener">he exploited</a> and that he only now criticizes in his op-ed.</p>
<p>And during his Senate tenure, while Romney did occasionally&nbsp;<a href="https://www.taxnotes.com/featured-news/romney-bennet-plan-curb-stepped-basis-may-be-step-too-far/2019/12/16/2bprl" target="_blank" rel="noreferrer noopener">explore</a> closing some loopholes, I don’t recall him using his platform to champion the tax-the-billionaires cause, and I don’t recall him cosponsoring the&nbsp;<a href="https://www.congress.gov/bill/118th-congress/senate-bill/4123/cosponsors" target="_blank" rel="noreferrer noopener">major</a>&nbsp;bills to&nbsp;<a href="https://www.congress.gov/bill/117th-congress/senate-bill/1598/cosponsors" target="_blank" rel="noreferrer noopener">close</a>&nbsp;the tax <a href="https://www.congress.gov/bill/118th-congress/senate-bill/3317" target="_blank" rel="noreferrer noopener">loophole</a>&nbsp;that he and Wall Street tycoons&nbsp;<a href="https://archive.nytimes.com/dealbook.nytimes.com/2012/01/17/romney-disclosure-reignites-debate-over-carried-interest-tax/" target="_blank" rel="noreferrer noopener">benefited from</a>.</p>
<p>In short, when Romney had real power, he fortified the rigged tax system that he’s only now criticizing from the sidelines.</p>
<p>Notably, Romney doesn’t explicitly apologize for any of that in his essay. He avoids apology not because he’s an archetypical American man who, like <a href="https://www.dailymotion.com/video/x26yzgd" target="_blank" rel="noreferrer noopener">the Fonz</a>, can’t bring himself to say “Sorry” or “I was wrong.” He doesn’t offer contrition because that might remind us of what he actually did when he had power and there were <em>real</em> stakes in his declarations about tax policy.</p>
<p>And so, when I think of that history and that context, I don’t find myself thinking “Wow, even Mitt Romney agrees we shouldn’t cut taxes for rich people, which means he’s courageous and principled, and means that only now is that tax position credible and serious.”</p>
<p>I instead find myself thinking: “Mitt Romney kinda looks like the hot-dog-guy saying he’s trying to find the guy who did this to our tax policy, and the real courageous heroes on taxes are those who had the guts to try to actually use their power in public office to push for a fairer tax system when it wasn’t cool to do so.”</p>
<p>Again, yes: Better late than never that someone like Romney is finally admitting what was obvious to most Americans over the last fifty years. And better late than never when anyone finally comes over to the right side of history on any issue.</p>
<p>But where is the courage from powerful people when they actually have power to do something? The answer is it’s often nowhere, because they derive their own power and prominence by fortifying other elites’ power rather than challenging it.</p>
<p>That is their real legacy, no matter what they say after the fact.</p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A faster heart for F-Droid. Our new server is here (294 pts)]]></title>
            <link>https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html</link>
            <guid>46436409</guid>
            <pubDate>Tue, 30 Dec 2025 18:36:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html">https://f-droid.org/2025/12/30/a-faster-heart-for-f-droid.html</a>, See on <a href="https://news.ycombinator.com/item?id=46436409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Donations are a key part of what keeps F-Droid independent and reliable and
our latest hardware update is a direct result of your support. Thanks to
donations from our incredible community, F-Droid has replaced one of its
most critical pieces of infrastructure, our core server hardware. It was
overdue for a refresh, and now we are happy to give you an update on the new
server and how it impacts the project.</p>

<p>This upgrade touches a core part of the infrastructure that builds and
publishes apps for the main F-Droid repository. If the server is slow,
everything downstream gets slower too. If it is healthy, the entire
ecosystem benefits.</p>

<h2 id="why-did-we-wait">Why did we wait?</h2>

<p>This server replacement took a bit longer than we would have liked. The
biggest reason is that sourcing reliable parts right now is genuinely
hard. Ongoing global trade tensions have made supply chains unpredictable,
and that hit the specific components we needed. We had to wait for quotes,
review, replan, and wait again when quotes turned out to have unexpected
long waits, before we finally managed to receive hardware that met our
requirements.</p>

<p>Even with the delays, the priority never changed. We were looking for the
right server set up for F-Droid, built to last for the long haul.</p>

<h2 id="a-note-about-the-host">A note about the host</h2>

<p>Another important part of this story is where the server lives and how it is
managed. F-Droid is not hosted in just any data center where commodity
hardware is managed by some unknown staff. We worked out a special
arrangement so that this server is physically held by a long time
contributor with a proven track record of securely hosting services. We can
control it remotely, we know exactly where it is, and we know who has
access. That level of transparency and trust is not common in
infrastructure, but it is central to how we think about resilience and
stewardship.</p>

<p>This was not the easiest path, and it required careful coordination and
negotiation. But we are glad we did it this way. It fits our values and our
threat model, and it keeps the project grounded in real people rather than
anonymous systems.</p>

<h2 id="old-hardware-new-momentum">Old hardware, new momentum</h2>

<p>The previous server was 12 year old hardware and had been running for about
five years. In infrastructure terms, that is a lifetime. It served F-Droid
well, but it was reaching the point where speed and maintenance overhead
were becoming a daily burden.</p>

<p>The new system is already showing a huge improvement. Stats of the running
cycles from the last two months suggest it can handle the full build and
publish actions much faster than before. E.g. this year, between January and
September, we published updates once every 3 or 4 days, that got down to
once every 2 days in October, to every day in November and it’s reaching
twice a day in December. <em>(You can see this in the frequency of index
publishing after October 18, 2025 in our <a href="https://gitlab.com/fdroid/f-droid.org-transparency-log/-/commits/master">f-droid.org transparency
log</a>)</em>.
That extra capacity gives us more breathing room and helps shorten the gap
between when apps are updated and when those updates reach users. We can now
build all the <a href="https://gitlab.com/fdroid/wiki/-/wikis/FAQ#finding-updates">auto-updated
apps</a> in the
<em>(UTC)</em> morning in one cycle, and all the newly included apps, fixed apps
and manually updated apps, through the day, in the evening cycle.</p>

<p>We are being careful here, because real world infrastructure always comes
with surprises. But the performance gains are real, and they are exciting.</p>

<h2 id="what-donations-make-possible">What donations make possible</h2>

<p>This upgrade exists because of community support, pooled over time, turned
into real infrastructure, benefiting everyone who relies on F-Droid.</p>

<p>A faster server does not just make our lives easier. It helps developers get
timely builds. It reduces maintenance risk. It strengthens the health of the
entire repository.</p>

<p>So thank you. Every <a href="https://f-droid.org/en/donate/">donation</a>, whether large
or small, is part of how this project stays reliable, independent, and
aligned with free software values.</p>

  </div>

</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Electrolysis can solve one of our biggest contamination problems (130 pts)]]></title>
            <link>https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html</link>
            <guid>46436127</guid>
            <pubDate>Tue, 30 Dec 2025 18:08:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html">https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems.html</a>, See on <a href="https://news.ycombinator.com/item?id=46436127">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
                
                    
    
    <!-- Panorama header -->
    

    <!-- Blog header -->
    
    <!-- Tags when not blog -->
    
        
    

    <!-- Articleheader -->
    <div>
    <p>
            ETH Zurich researchers have developed a process that can be used on site to render environmental toxins such as DDT and lindane harmless and convert them into valuable chemicals – a breakthrough for the remediation of contaminated sites and a sustainable circular economy.&nbsp;
        </p>
    

</div>

    <!-- Nav & News images -->
    

    <!-- Details -->
    

    <!-- ArticleLeadImage -->
    
        <div>
            <figure>
            <img alt="Patrik Domke is standing in front of a window in the laboratory. This window is covered with notes. He is holding a construction with a balloon in his hand." src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/articleLeadImage/image.imageformat.carousel.1046845309.png">
			<figcaption>
			    <p>
			      Removing insecticides from contaminated soils – Patrick Domke (pictured) and other ETH researchers found the solution in electrolysis.&nbsp; (Image: Hannes Cullum /  IVY Filmstudio GmbH)</p>
			  </figcaption>
			</figure>
    
          </div>
    

    <!-- Parsys 1 -->
    <div>

<div>
                
                	<h2>In brief</h2>
                
                
                <ul> 
 <li><p>Persistent organic pollutants such as DDT and lindane still pollute the environment and affect humans decades after their use.&nbsp;</p> </li> 
 <li><p>ETH researchers have developed a new electrochemical process that completely dehalogenates these long-lived toxins and converts them into valuable industrial chemicals.&nbsp;</p> </li> 
 <li><p>The method uses cheap equipment, prevents side reactions and could be used on contaminated landfills, soils or sludge.&nbsp;</p> </li> 
 <li><p>Mobile systems could be used on site in the future – an important step towards the remediation of contaminated sites and the creation of a sustainable circular economy.&nbsp;</p> </li> 
</ul>
            </div>
<div>
                
                
                <p>They were once considered miracle workers – insecticides such as lindane or DDT were produced and used millions of times during the 20th century. But what was hailed as progress led to a global environmental catastrophe: persistent organic pollutants (POPs) are so chemically stable that they remain in soil, water and organisms for decades. They accumulate in the fatty tissue of animals and thus enter the human food chain. Many of these substances were banned long ago, but their traces can still be found today – even in human blood.</p> 
<p>How to remediate such contaminated sites, be they soils, bodies of water or landfills, is one of the major unresolved questions of environmental protection. How can highly stable poisons be rendered harmless without creating new problems? Researchers at ETH Zurich, led by Bill Morandi, Professor of Synthetic Organic Chemistry, have now found a promising approach. Using an innovative electrochemical method, they are not only able to break down these long-lived pollutants but also to convert them into valuable raw materials for the chemical industry.</p> 
<h2>Converting pollutants into raw materials</h2> 
<p>A key distinction between this and previous work is that the carbon skeleton of the pollutants is recycled and made reusable, while the halide component is sequestered as a harmless inorganic salt. “The previous methods were also energetically inefficient,” says Patrick Domke, a doctoral student in Morandi’s group. He explains: “The processes were expensive and still led to outcomes that were harmful to the environment.”&nbsp;</p> 
<p>Together with electrochemistry specialist Alberto Garrido-Castro, a former postdoc in this group, Domke developed a process that renders the pollutants in question completely harmless. During this project, the two researchers were able to draw on the many years of experience of ETH professor Morandi, who has been working on the transformation of such compounds for years. “The key advance of this new technology is the use of alternating current to sequester the problematic halogen atoms as innocuous salts such as NaCl (table salt), while still generating valuable hydrocarbons,” says Morandi.&nbsp;</p> 
<h2>Using electricity to break down toxins&nbsp;&nbsp;</h2> 
<p>Electrolysis enables almost complete dehalogenation of pollutants under mild, environmentally friendly and cost-effective conditions. It cleaves the stable carbon-halogen bonds, leaving behind only harmless salts such as table salt and useful hydrocarbons such as benzene, diphenylethane or cyclododecatriene. These are actually sought-after intermediates in the chemical industry, for example, for plastics, varnishes, coatings and pharmaceutical applications. In this way, the technology not only contributes to the remediation of contaminated sites but also to the sustainable circular economy.</p>
            </div>
<div>
                        <figure>
            <img alt="Four small glass containers are standing on a shelf. They are labelled &quot;soil and HCL&quot;, the second from the left with NACL, the third with C6H6 and the last with clean soil." src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/wide_content/image/image.imageformat.1286.834672465.png">
			<figcaption>
			    <p>
			      The contaminated soil (soil + HCH) becomes table salt (NaCl), benzene (C<sub>6</sub>H<sub>6</sub>), and clean soil through electrolysis.&nbsp;&nbsp;(Image: Patrick Domke / ETH Zurich)</p>
			  </figcaption>
			</figure>
    
                    </div>
<div>
                
                
                <p>“What makes our process so special from a technical point of view is that we supply electricity using alternating current, similar to the electrical waveform delivered to households. It is one of the most cost-effective resources in chemistry,” explains Garrido-Castro. “Alternating current protects the electrodes from wear, which is why we can reuse them for many subsequent electrolysis cycles. In addition, the alternating current suppresses unwanted side reactions and the formation of poisonous chlorine gas, allowing the pollutant’s halogen atoms to be fully converted to inorganic salts.” The reactor used by the researchers consists of an undivided electrolysis cell in which dimethyl sulfoxide (DMSO) is used as a solvent – itself a by-product of the pulp process in paper production.&nbsp;</p> 
<h2>A fully thought-out circular economy</h2> 
<p>The process can be applied not only to pure substances but also to mixtures from contaminated soils. Soil or sludge can therefore be treated without pre-treatment or further separation processes. A prototype of the reactor has already been successfully tested on classic environmental toxins such as lindane and DDT. “Our system is mobile and can be assembled on site. This eliminates the need to transport these hazardous substances,” explains Domke.&nbsp;</p>
            </div>
<div tabindex="-1">
                            <p><img alt="Portrait photograph of Alberto Garrido-Castro " title="" src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/wide_content/citation/image.imageformat.fullwidth.1235311956.png">
    </p>
                            <blockquote>
                                <span>
                                  “Our motivation was to solve one of the biggest environmental problems of the last century. We cannot simply leave the pollution to future generations.”</span>
                                <div>
                                    <p><img alt="Portrait photograph of Alberto Garrido-Castro " title="" src="https://ethz.ch/en/news-and-events/eth-news/news/2025/11/electrolysis-can-solve-one-of-our-biggest-contamination-problems/_jcr_content/wide_content/citation/image.imageformat.fullwidth.1235311956.png">
    </p>
                                    <p><cite>Alberto Garrido-Castro </cite>
                                </p></div>
                            </blockquote>
                        </div>

<div>
                
                	<h2>Spark Award 2025 – these projects have made it to the finals &nbsp;</h2>
                
                
                <p>On <b>27 November 2025</b> at <a href="https://ethz.ch/en/news-and-events/events/eth-open-i.html">ETH Zurich @ Open-i</a>, ETH Zurich will award the Spark Award for the best invention of the year for the 14th time. The criteria for this award are originality, patent strength and market potential.&nbsp;&nbsp;</p>
<p>Click here to find all the <a href="https://transfer.ethz.ch/impact/sparkaward.html">Spark Award nominees of 2025.</a> &nbsp;</p>
<p>Spark Award ceremony, <a href="https://ethz.ch/en/news-and-events/events/eth-open-i/program.html">Industry Day @ Open-i</a>, Thursday, 27 November 2025, 1.30 p.m., Zurich Convention Center. Registration is required. &nbsp;</p>
            </div>

</div>
    <!-- Socialsharing (display only) -->
    
    
        
            
            
            
        
        
    


    <!-- Parsys 2 -->
    

    <!-- Rightside Parsys -->
    

    <!-- Taglist -->
    
        
            
        
    

    <!-- Comments -->
    
    	
	    
    

                
                
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Vulnerability in Libsodium (222 pts)]]></title>
            <link>https://00f.net/2025/12/30/libsodium-vulnerability/</link>
            <guid>46435614</guid>
            <pubDate>Tue, 30 Dec 2025 17:24:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://00f.net/2025/12/30/libsodium-vulnerability/">https://00f.net/2025/12/30/libsodium-vulnerability/</a>, See on <a href="https://news.ycombinator.com/item?id=46435614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    
    <main id="main-content" role="main" aria-label="Main content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting" role="article">
  
  
  <div itemprop="articleBody">
    <p>Libsodium is now 13 years old!</p>

<p>I started that project to pursue Dan Bernstein’s desire to make cryptography simple to use. That meant exposing a limited set of high-level functions and parameters, providing a simple API, and writing documentation for users, not cryptographers. Libsodium’s goal was to expose APIs to perform operations, not low-level functions. Users shouldn’t even have to know or care about what algorithms are used internally. This is how I’ve always viewed libsodium.</p>

<p>Never breaking the APIs is also something I’m obsessed with. APIs may not be great, and if I could start over from scratch, I would have made them very different, but as a developer, the best APIs are not the most beautifully designed ones, but the ones that you don’t have to worry about because they don’t change and upgrades don’t require any changes in your application either. Libsodium started from the NaCl API, and still adheres to it.</p>

<p>These APIs exposed high-level functions, but also some lower-level functions that high-level functions wrap or depend on. Over the years, people started using these low-level functions directly. Libsodium started to be used as a toolkit of algorithms and low-level primitives.</p>

<p>That made me sad, especially since it is clearly documented that only APIs from builds with <code>--enable-minimal</code> are guaranteed to be tested and stable. But after all, it makes sense. When building custom protocols, having a single portable library with a consistent interface for different functions is far better than importing multiple dependencies, each with their own APIs and sometimes incompatibilities between them.</p>

<p>That’s a lot of code to maintain. It includes features and target platforms I don’t use but try to support for the community. I also maintain a large number of other open source projects.</p>

<p>Still, the security track record of libsodium is pretty good, with zero CVEs in 13 years even though it has gotten a lot of scrutiny.</p>

<p>However, while recently experimenting with adding support for batch signatures, I noticed inconsistent results with code originally written in Zig. The culprit was a check that was present in a function in Zig, but that I forgot to add in libsodium.</p>

<h2 id="the-bug">The bug</h2>

<p>The function <code>crypto_core_ed25519_is_valid_point()</code>, a low-level function used to check if a given elliptic curve point is valid, was supposed to reject points that aren’t in the main cryptographic group, but some points were slipping through.</p>

<h2 id="why-does-this-matter">Why does this matter?</h2>

<p>Edwards25519 is like a special mathematical playground where cryptographic operations happen.</p>

<p>It is used internally for Ed25519 signatures, and includes multiple subgroups of different sizes (order):</p>

<ul>
  <li>Order 1: just the identity (0, 1)</li>
  <li>Order 2: identity + point (0, -1)</li>
  <li>Order 4: 4 points</li>
  <li>Order 8: 8 points</li>
  <li>Order L: the “main subgroup” (L = ~2^252 points) where all operations are expected to happen</li>
  <li>Order 2L, 4L, 8L: very large, but not prime order subgroups</li>
</ul>

<p>The validation function was designed to reject points not in the main subgroup. It properly rejected points in the small-order subgroups, but not points in the mixed-order subgroups.</p>

<h2 id="what-went-wrong-technically">What went wrong technically?</h2>

<p>To check if a point is in the main subgroup (the one of order L), the function multiplies it by L. If the order is L, multiplying any point by L gives the identity point (the mathematical equivalent of zero). So, the code does the multiplication and checks that we ended up with the identity point.</p>

<p>Points are represented by coordinates. In the internal representation used here, there are three coordinates: X, Y, and Z. The identity point is represented internally with coordinates where X = 0 and Y = Z. Z can be anything depending on previous operations; it doesn’t have to be 1.</p>

<p>The old code only checked X = 0. It forgot to verify Y = Z. This meant some invalid points (where X = 0 but Y ≠ Z after the multiplication) were incorrectly accepted as valid.</p>

<p>Concretely: take any main-subgroup point Q (for example, the output of <code>crypto_core_ed25519_random</code>) and add the order-2 point (0, -1), or equivalently negate both coordinates. Every such Q + (0, -1) would have passed validation before the fix, even though it’s not in the main subgroup.</p>

<h2 id="the-fix">The fix</h2>

<p><a href="https://github.com/jedisct1/libsodium/commit/f2da4cd8cb26599a0285a6ab0c02948e361a674a">The fix</a> is trivial and adds the missing check:</p>

<div><pre><code><span>// OLD:</span>
<span>return</span> <span>fe25519_iszero</span><span>(</span><span>pl</span><span>.</span><span>X</span><span>);</span>
</code></pre></div>

<div><pre><code><span>// NEW:</span>
<span>fe25519_sub</span><span>(</span><span>t</span><span>,</span> <span>pl</span><span>.</span><span>Y</span><span>,</span> <span>pl</span><span>.</span><span>Z</span><span>);</span>
<span>return</span> <span>fe25519_iszero</span><span>(</span><span>pl</span><span>.</span><span>X</span><span>)</span> <span>&amp;</span> <span>fe25519_iszero</span><span>(</span><span>t</span><span>);</span>
</code></pre></div>

<p>Now it properly verifies both conditions: X must be zero and Y must equal Z.</p>

<h2 id="who-is-affected">Who is affected?</h2>

<p>You may be affected if you:</p>

<ul>
  <li>Use a point release &lt;= <code>1.0.20</code> or a version of <code>libsodium</code> released before December 30, 2025.</li>
  <li>Use <code>crypto_core_ed25519_is_valid_point()</code> to validate points from untrusted sources</li>
  <li>Implement custom cryptography using arithmetic over the Edwards25519 curve</li>
</ul>

<p>But don’t panic. Most users are not affected.</p>

<p>None of the high-level APIs (<code>crypto_sign_*</code>) are affected; they don’t even use or need that function. Scalar multiplication using <code>crypto_scalarmult_ed25519</code> won’t leak anything even if the public key is not on the main subgroup. And public keys created with the regular <code>crypto_sign_keypair</code> and <code>crypto_sign_seed_keypair</code> functions are guaranteed to be on the correct subgroup.</p>

<h2 id="recommendation">Recommendation</h2>

<p>Support for the Ristretto255 group was added to libsodium in 2019 specifically to solve cofactor-related issues. With Ristretto255, if a point decodes, it’s safe. No further validation is required.</p>

<p>If you implement custom cryptographic schemes doing arithmetic over a finite field group, using Ristretto255 is recommended. It’s easier to use, and as a bonus, low-level operations will run faster than over Edwards25519.</p>

<p>If you can’t update libsodium and need an application-level workaround, use the following function:</p>

<div><pre><code><span>int</span> <span>is_on_main_subgroup</span><span>(</span><span>const</span> <span>unsigned</span> <span>char</span> <span>p</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>])</span>
<span>{</span>
    <span>/* l - 1 (group order minus 1) */</span>
    <span>static</span> <span>const</span> <span>unsigned</span> <span>char</span> <span>L_1</span><span>[</span><span>crypto_core_ed25519_SCALARBYTES</span><span>]</span> <span>=</span> <span>{</span>
        <span>0xec</span><span>,</span> <span>0xd3</span><span>,</span> <span>0xf5</span><span>,</span> <span>0x5c</span><span>,</span> <span>0x1a</span><span>,</span> <span>0x63</span><span>,</span> <span>0x12</span><span>,</span> <span>0x58</span><span>,</span>
        <span>0xd6</span><span>,</span> <span>0x9c</span><span>,</span> <span>0xf7</span><span>,</span> <span>0xa2</span><span>,</span> <span>0xde</span><span>,</span> <span>0xf9</span><span>,</span> <span>0xde</span><span>,</span> <span>0x14</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x10</span>
    <span>};</span>
    <span>/* Identity point encoding: (x=0, y=1) */</span>
    <span>static</span> <span>const</span> <span>unsigned</span> <span>char</span> <span>ID</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>]</span> <span>=</span> <span>{</span>
        <span>0x01</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span>
        <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span><span>,</span> <span>0x00</span>
    <span>};</span>
    <span>unsigned</span> <span>char</span> <span>t</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>];</span>
    <span>unsigned</span> <span>char</span> <span>r</span><span>[</span><span>crypto_core_ed25519_BYTES</span><span>];</span>
    <span>if</span> <span>(</span><span>crypto_scalarmult_ed25519_noclamp</span><span>(</span><span>t</span><span>,</span> <span>L_1</span><span>,</span> <span>p</span><span>)</span> <span>!=</span> <span>0</span> <span>||</span>
        <span>crypto_core_ed25519_add</span><span>(</span><span>r</span><span>,</span> <span>t</span><span>,</span> <span>p</span><span>)</span> <span>!=</span> <span>0</span><span>)</span> <span>{</span>
        <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>sodium_memcmp</span><span>(</span><span>r</span><span>,</span> <span>ID</span><span>,</span> <span>sizeof</span> <span>ID</span><span>)</span> <span>==</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div>

<h2 id="fixed-packages">Fixed packages</h2>

<p>This issue was fixed immediately after discovery. All <code>stable</code> packages released after December 30, 2025 include the fix:</p>

<ul>
  <li>official tarballs</li>
  <li>binaries for Visual Studio</li>
  <li>binaries for MingW</li>
  <li>NuGet packages for all architectures including Android</li>
  <li><code>swift-sodium</code> xcframework (but <code>swift-sodium</code> doesn’t expose low-level functions anyway)</li>
  <li>Rust <code>libsodium-sys-stable</code></li>
  <li><code>libsodium.js</code></li>
</ul>

<p>A new point release is also going to be tagged.</p>

<p>If <code>libsodium</code> is useful to you, please keep in mind that it is maintained by one person, for free, in time I could spend with my family or on other projects. The best way to help the project would be to consider <a href="https://opencollective.com/libsodium/contribute">sponsoring it</a>, which helps me dedicate more time to improving it and making it great for everyone, for many more years to come.</p>

  </div>
  
  <!-- JSON-LD for Blog Post -->
  
</article>







    </main>
    
    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Toro: Deploy Applications as Unikernels (119 pts)]]></title>
            <link>https://github.com/torokernel/torokernel</link>
            <guid>46435418</guid>
            <pubDate>Tue, 30 Dec 2025 17:09:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/torokernel/torokernel">https://github.com/torokernel/torokernel</a>, See on <a href="https://news.ycombinator.com/item?id=46435418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">Toro<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8797ce828a9ef346ee3d86ab93bf27c8321aec24f327c89915da16df108b4911/68747470733a2f2f6170692e7472617669732d63692e6f72672f746f726f6b65726e656c2f746f726f6b65726e656c2e7376673f6272616e63683d6d6173746572"><img src="https://camo.githubusercontent.com/8797ce828a9ef346ee3d86ab93bf27c8321aec24f327c89915da16df108b4911/68747470733a2f2f6170692e7472617669732d63692e6f72672f746f726f6b65726e656c2f746f726f6b65726e656c2e7376673f6272616e63683d6d6173746572" alt="build passing" data-canonical-src="https://api.travis-ci.org/torokernel/torokernel.svg?branch=master"></a></h2><a id="user-content-toro" aria-label="Permalink: Toro" href="#toro"></a></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">Toro is a unikernel dedicated to deploy applications as microVMs. Toro leverages on virtio-fs and virtio-vsocket to provide a minimalistic architecture.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Support x86-64 architecture</li>
<li>Support up to 512GB of RAM</li>
<li>Support QEMU-KVM microvm and Firecracker</li>
<li>Cooperative and I/O bound threading scheduler</li>
<li>Support virtio-vsocket for networking</li>
<li>Support virtio-fs for filesystem</li>
<li>Fast boot up</li>
<li>Tiny image</li>
<li>Built-in gdbstub</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How try Toro?</h2><a id="user-content-how-try-toro" aria-label="Permalink: How try Toro?" href="#how-try-toro"></a></p>
<p dir="auto">You can try Toro by running the HelloWorld example using a Docker image that includes all the required tools. To do so, execute the following commands in a console (these steps require you to install before KVM and Docker):</p>
<div dir="auto" data-snippet-clipboard-copy-content="wget https://raw.githubusercontent.com/torokernel/torokernel/master/ci/Dockerfile
sudo docker build -t torokernel-dev .
sudo docker run --privileged --rm -it torokernel-dev
cd examples/HelloWorld
python3 ../CloudIt.py -a HelloWorld"><pre>wget https://raw.githubusercontent.com/torokernel/torokernel/master/ci/Dockerfile
sudo docker build -t torokernel-dev <span>.</span>
sudo docker run --privileged --rm -it torokernel-dev
<span>cd</span> examples/HelloWorld
python3 ../CloudIt.py -a HelloWorld</pre></div>
<p dir="auto">If these commands execute successfully, you will get the output of the HelloWorld example.
You can also pull the image from dockerhub instead of building it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo docker pull torokernel/torokernel-dev:latest
sudo docker run --privileged --rm -it torokernel/torokernel-dev:latest"><pre>sudo docker pull torokernel/torokernel-dev:latest
sudo docker run --privileged --rm -it torokernel/torokernel-dev:latest</pre></div>
<p dir="auto">You can share a directory from the host by running:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo docker run --privileged --rm --mount type=bind,source=&quot;$(pwd)&quot;,target=/root/torokernel -it torokernel/torokernel-dev:latest"><pre>sudo docker run --privileged --rm --mount type=bind,source=<span><span>"</span><span><span>$(</span>pwd<span>)</span></span><span>"</span></span>,target=/root/torokernel -it torokernel/torokernel-dev:latest</pre></div>
<p dir="auto">You will find $pwd from host at <code>/root/torokernel</code> in the container.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How build Toro locally?</h2><a id="user-content-how-build-toro-locally" aria-label="Permalink: How build Toro locally?" href="#how-build-toro-locally"></a></p>
<p dir="auto">Execute the commands in <code>ci/Dockerfile</code> to install the required components locally. Then, Go to <code>torokernel/examples</code> and edit <code>CloudIt.py</code> to set the correct paths to Qemu and fpc. Optionally, you can install vsock-socat from <a href="https://github.com/stefano-garzarella/socat-vsock">here</a> and virtio-fs from <a href="https://gitlab.com/virtio-fs/virtiofsd.git" rel="nofollow">here</a>. You need to set the correct path to virtiofsd and socat.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run the HelloWorld Example</h2><a id="user-content-run-the-helloworld-example" aria-label="Permalink: Run the HelloWorld Example" href="#run-the-helloworld-example"></a></p>
<p dir="auto">Go to <code>examples/HelloWorld/</code> and execute:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 ../CloudIt.py -a HelloWorld"><pre>python3 ../CloudIt.py -a HelloWorld</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/torokernel/torokernel/wiki/images/helloworld.gif"><img src="https://github.com/torokernel/torokernel/wiki/images/helloworld.gif" alt="HelloWorld" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run the StaticWebServer Example</h2><a id="user-content-run-the-staticwebserver-example" aria-label="Permalink: Run the StaticWebServer Example" href="#run-the-staticwebserver-example"></a></p>
<p dir="auto">To run the StaticWebserver, you require virtiofsd and socat. To compile socat, execute the following commands:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:stefano-garzarella/socat-vsock.git
cd socat-vsock
autoreconf -fiv
./configure
make socat"><pre>git clone git@github.com:stefano-garzarella/socat-vsock.git
<span>cd</span> socat-vsock
autoreconf -fiv
./configure
make socat</pre></div>
<p dir="auto">Set the path to socat binary in CloudIt.py and then execute:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 ../CloudIt.py -a StaticWebServer -r -d /path-to-directory/ -f 4000:80"><pre>python3 ../CloudIt.py -a StaticWebServer -r -d /path-to-directory/ -f 4000:80</pre></div>
<p dir="auto">You have to replace the <code>/path-to-directory/</code> to a directory that containing the files, e.g., index.html. To try it, you can execute:</p>
<div data-snippet-clipboard-copy-content="wget http://127.0.0.1:4000/index.html"><pre><code>wget http://127.0.0.1:4000/index.html
</code></pre></div>
<p dir="auto">The <code>-f</code> parameter indicates a forwarding of the 4000 port from the host to the 80 port in the guest using vsock.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/torokernel/torokernel/wiki/images/staticwebser.gif"><img src="https://github.com/torokernel/torokernel/wiki/images/staticwebser.gif" alt="HelloWorld" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Run the Intercore Communication example</h2><a id="user-content-run-the-intercore-communication-example" aria-label="Permalink: Run the Intercore Communication example" href="#run-the-intercore-communication-example"></a></p>
<p dir="auto">This example shows how cores can communicate by using the VirtIOBus device. In this example, core #0 sends a packet to every core in the system with the <strong>ping</strong> string. Each core responds with a packet that contains the message <strong>pong</strong>. This example is configured to use three cores. To launch it, simply executes the following commands in the context of the container presented above:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 ../CloudIt.py -a InterCoreComm"><pre>python3 ../CloudIt.py -a InterCoreComm</pre></div>
<p dir="auto">You will get the following output:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/torokernel/torokernel/wiki/images/intercom.gif"><img src="https://github.com/torokernel/torokernel/wiki/images/intercom.gif" alt="InterComm" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You have many ways to contribute to Toro. One of them is by joining the Google Group <a href="https://groups.google.com/forum/#!forum/torokernel" rel="nofollow">here</a>. In addition, you can find more information <a href="https://github.com/MatiasVara/torokernel/wiki/How-to-Contribute">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">GPLv3</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">References</h2><a id="user-content-references" aria-label="Permalink: References" href="#references"></a></p>
<p dir="auto">[0] A Dedicated Kernel named Toro. Matias Vara. FOSDEM 2015.</p>
<p dir="auto">[1] Reducing CPU usage of a Toro Appliance. Matias Vara. FOSDEM 2018.</p>
<p dir="auto">[2] Toro, a Dedicated Kernel for Microservices. Matias Vara and Cesar Bernardini. Open Source Summit Europe 2018.</p>
<p dir="auto">[3] Speeding Up the Booting Time of a Toro Appliance. Matias Vara. FOSDEM 2019.</p>
<p dir="auto">[4] Developing and Deploying Microservices with Toro Unikernel. Matias Vara. Open Source Summit Europe 2019.</p>
<p dir="auto">[5] Leveraging Virtio-fs and Virtio-vsocket in Toro Unikernel. Matias Vara. DevConfCZ 2020.</p>
<p dir="auto">[6] Building a Cloud Infrastructure to Deploy Microservices as Microvm Guests. Matias Vara. KVM Forum 2020.</p>
<p dir="auto">[7] Running MPI applications on Toro unikernel. Matias Vara. FOSDEM 2023.</p>
<p dir="auto">[8] Is Toro unikernel faster for MPI?. Matias Vara. FOSDEM 2024.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: 22 GB of Hacker News in SQLite (361 pts)]]></title>
            <link>https://hackerbook.dosaygo.com</link>
            <guid>46435308</guid>
            <pubDate>Tue, 30 Dec 2025 17:01:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackerbook.dosaygo.com">https://hackerbook.dosaygo.com</a>, See on <a href="https://news.ycombinator.com/item?id=46435308">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <td>
        <p>
          Viewing HN on <span id="snapInfo">Someday, Month 00, 0000</span>. Times are relative to 11:59 PM.
        </p>
        
        <div><p>
          Made by <a href="https://github.com/DOSAYGO-STUDIO">DOSAYGO</a> · <a href="https://dosaygo-studio.github.io/HackerBook/">[GET THIS]</a>
        </p></div>
      </td>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Public Sans – A strong, neutral typeface (223 pts)]]></title>
            <link>https://public-sans.digital.gov/</link>
            <guid>46433579</guid>
            <pubDate>Tue, 30 Dec 2025 14:23:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://public-sans.digital.gov/">https://public-sans.digital.gov/</a>, See on <a href="https://news.ycombinator.com/item?id=46433579">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Official government website">
    <header>
      <div>
        <p><img src="https://public-sans.digital.gov/assets/uswds/img/us_flag_small.png" alt="U.S. flag">
        </p>
        <div>
          <p>
            An official website of the United States government
          </p>
          
        </div>
        </div>
    </header>
    <div id="gov-banner">
        <div>
          <p><img src="https://public-sans.digital.gov/assets/uswds/img/icon-dot-gov.svg" role="img" alt=""></p><p>
              <strong>Official websites use .gov</strong>
              <br>
              A <strong>.gov</strong> website belongs to an official government organization in the United States.
            </p>
        </div>
        <div>
          <p><img src="https://public-sans.digital.gov/assets/uswds/img/icon-https.svg" role="img" alt=""></p><p>
              <strong>Secure .gov websites use HTTPS</strong>
              <br>
              A <strong>lock</strong> (
<span><svg xmlns="http://www.w3.org/2000/svg" width="52" height="64" viewBox="0 0 52 64" role="img" aria-labelledby="banner-lock-title banner-lock-description"><title id="banner-lock-title">Lock</title><desc id="banner-lock-description">A locked padlock</desc><path fill="#000000" fill-rule="evenodd" d="M26 0c10.493 0 19 8.507 19 19v9h3a4 4 0 0 1 4 4v28a4 4 0 0 1-4 4H4a4 4 0 0 1-4-4V32a4 4 0 0 1 4-4h3v-9C7 8.507 15.507 0 26 0zm0 8c-5.979 0-10.843 4.77-10.996 10.712L15 19v9h22v-9c0-6.075-4.925-11-11-11z"></path></svg></span>
) or <strong>https://</strong> means you’ve safely connected to the .gov website. Share sensitive information only on official, secure websites.
            </p>
        </div>
      </div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Win32 is the stable Linux ABI (165 pts)]]></title>
            <link>https://loss32.org/</link>
            <guid>46433035</guid>
            <pubDate>Tue, 30 Dec 2025 13:15:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loss32.org/">https://loss32.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46433035">Hacker News</a></p>
<div id="readability-page-1" class="page">
<img src="https://loss32.org/favicon.ico" id="logo" alt="A logo that consists of four quadrants: cyan blue in the top-left, magenta in the top-right, yellow in the bottom-left, blue in the bottom-right. There is also a vertical white line in the top-left quadrant, two vertical white lines in the top-right and bottom-left quadrants, and one vertical and one horizontal white line in the bottom-right quadrant.">
<p>The future of the Linux desktop can look like this:</p>
<img src="https://loss32.org/screenshot.png" id="screenshot" alt="A screenshot of an desktop where the windows and their content look like the Windows Classic theme. There is a taskbar with the WINE logo on the Start button. There is a file explorer window with the WINE logo in its top-left; there is a window for what looks like MS Paint; there is a window titled “About Paint for ReactOS”; there is a window for xeyes; and there is a window for xterm. Many clues on screen suggest everything is running in WINE on top of Debian.">
<p><a href="#help">Let's build it!</a></p>

<hr>

<h2>Win32/Linux?</h2>
<p> I'd just like to interject for a moment. What you're refering to as Linux, is in fact, Win32/Linux, or as I've recently taken to calling it, <del>loss32</del> Win32 plus Linux. Linux is not an operating system unto itself, but rather another free component of a fully functioning system made useful by WINE, the ReactOS userland, and other vital system components comprising a full OS as defined by Microsoft.

</p><h2>Okay, but seriously what is this?</h2>
<p>A dream of a Linux distribution where the entire desktop environment is Win32 software running under WINE. A completely free and open-source OS where you can just download <tt>.exe</tt> files and run them, for the power user who isn't necessarily a Unixhead, or just for someone who thinks this sounds fun.

</p><h2>Isn't this just ReactOS?</h2>
<p>ReactOS tries to reimplement the Windows NT kernel, and that has always been its Achilles heel, holding it back from a hardware compatibility and stability standpoint. The loss32 concept is to achieve a similar-feeling end result to ReactOS, but built on a more usable foundation, using components known to work well (the Linux kernel, WINE, everything that glues those together, and a sprinkling of ReactOS userland niceties). As a bonus, the OS would still technically be a Linux distro, so it would be possible to run Linux software when necessary, something ReactOS can't do.

</p><h2>Why build this?</h2>

<ul>
<li>The late-90's-to-early-2010's PC desktop experience was great for power users, especially creative users. Let's keep the dream alive.
</li><li>WINE has a lot of unfortunate rough edges that people only tolerate because they use WINE as a last resort. A desktop environment where everything runs in WINE will stimulate making WINE better for everyone, whether they're going to use this project or not.
</li><li>Win32 is the stable Linux ABI!
</li><li>Because we can.
</li></ul>

<h2>Win32 is the stable Linux ABI?!</h2>
<p>Yes. I can't tell you how many times the ability to just download a goddamn <tt>.exe</tt> file and run it in WINE has saved my ass. Seemingly every creative project I undertake eventually requires downloading <em>some</em> piece of software which is either impossible or impractical to rebuild myself, and whose Linux and macOS ports no longer work or never existed. There's more than three decades of Win32 software — <tt>.exe</tt> files! — that can run in WINE or (of course) on Windows. No other ABI has that kind of compatibility record. WINE can even run Win16 stuff too.

</p><p>The really cool thing about Win32 is it's also the <em>world's</em> stable ABI. There's lots of fields of software where the GNU/Linux and POSIX-y offerings available are quite limited and generally poor in quality, e.g. creative software and games. Win32 gives you access to a much larger slice of humanity's cultural inheritance.

</p><h2>Is that a real screenshot?</h2>
<p>Yes! That's just stable WINE running on Debian 13. There's a lot of rough edges you can't see in the screenshot that make it somewhat uncomfortable for use for the time being. The goal of the project is to fix many of the rough edges and package up this environment in an easily installable form.

</p><h2 id="help">How do I help?</h2>
<p>Thanks for asking! This website was written by <a href="https://hikari.noyu.me/">hikari_no_yume</a> on 2025-12-29, who is currently at 39C3 (I'm usually at the assembly called <tt>&amp;nbsp;</tt> – ask for me there!). You can <a href="mailto:hikari@noyu.me?subject=loss32">email me</a>, or you can lurk in <tt>#loss32</tt> on <tt>irc.libera.chat</tt>. I'd especially like to hear from you if you know things about or would be willing to help with:

</p><ul>
<li>How to package a desktop environment (e.g. on Debian) so that it will show up in the list of desktop environments on the login screen
</li><li>Wayland compositors that don't impose a desktop environment on you (currently I'm using the standalone version of mutter)
</li><li>WINE, especially its version of explorer.exe, shell32.dll stuff, HiDPI scaling, packaging, how it handles the Start Menu entries, …
</li><li>ReactOS, epecially its version of explorer.exe, shell32.dll stuff, how the ReactOS userland differs from WINE's, …
</li><li>Making a Linux distro generally
</li><li>Statically linking WINE to musl and freetype and so on and throwing out as much of the Linux userland as possible (mostly to make jokes about how it's not actually GNU/Linux if there's no GNU)
</li><li>Win32 programming
</li><li>Or anything you think might be useful for this project :)
</li></ul>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[No strcpy either (177 pts)]]></title>
            <link>https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/</link>
            <guid>46433029</guid>
            <pubDate>Tue, 30 Dec 2025 13:14:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/">https://daniel.haxx.se/blog/2025/12/29/no-strcpy-either/</a>, See on <a href="https://news.ycombinator.com/item?id=46433029">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">

	<div id="primary" role="main">
			
<article id="post-28909">
	
		<p><img width="672" height="336" src="https://daniel.haxx.se/blog/wp-content/uploads/2025/10/sourcecode.jpg" alt="" decoding="async">		</p>

		
	<!-- .entry-header -->

		<div>
		
<p>Some time ago I mentioned that we went through the curl source code and eventually got rid of all <code>strncpy</code>() calls.</p>



<p>strncpy() is a weird function with a crappy API. It might not null terminate the destination and it <em>pads</em> the target buffer with zeroes. Quite frankly, most code bases are probably better off completely avoiding it because each use of it is a potential mistake.</p>



<p>In that particular rewrite when we made strncpy calls extinct, we made <em>sure</em> we would either copy the full string properly or return error. It is rare that copying a partial string is the right choice, and if it is, we can just as well <code>memcpy</code> it and handle the null terminator explicitly. This meant no case for using strlcpy or anything such either.</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;6953fde7adae0&quot;}" data-wp-interactive="core/image" data-wp-key="6953fde7adae0"><img decoding="async" width="2668" height="1501" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://daniel.haxx.se/blog/wp-content/uploads/2025/12/Screenshot-2025-12-29-at-17-08-28-curl-Project-status-dashboard.png" alt=""><figcaption>strncpy density in curl over time</figcaption></figure>
</div>


<h2>But strcpy?</h2>



<p>strcpy however, has its valid uses and it has a less bad and confusing API. The main challenge with strcpy is that when using it we do not specify the length of the target buffer nor of the source string.</p>



<p>This is normally not a problem because in a C program <code>strcpy</code> should only be used when we have full control of both.</p>



<p>But <em>normally</em> and <em>always</em> are not necessarily the same thing. We are but all human and we all do mistakes. Using strcpy implies that there is at least one or maybe two, buffer size checks done prior to the function invocation. In a good situation.</p>



<p>Over time however – let’s imagine we have code that lives on for decades – when code is maintained, patched, improved and polished by many different authors with different mindsets and approaches, those size checks and the function invoke may glide apart. The further away from each other they go, the bigger is the risk that something happens in between that nullifies one of the checks or changes the conditions for the strcpy.</p>



<h2>Enforce checks close to code</h2>



<p>To make sure that the size checks cannot be separated from the copy itself we introduced a string copy replacement function the other day that takes the <em>target buffer</em>, <em>target size</em>, <em>source buffer</em> and <em>source string length</em> as arguments and only if the copy can be made and the null terminator also fits there, the operation is done.</p>



<p>This made it possible to implement the replacement using memcpy(). Now we can completely ban the use of strcpy in curl source code, like we already did strncpy.</p>



<p>Using this function version is a little more work and more cumbersome than strcpy since it needs more information, but we believe the upsides of this approach will help us have an oversight for the extra pain involved. I suppose we will see how that will fare down the road. Let’s come back in a decade and see how things developed!</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;6953fde7addec&quot;}" data-wp-interactive="core/image" data-wp-key="6953fde7addec"><img loading="lazy" decoding="async" width="2668" height="1501" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://daniel.haxx.se/blog/wp-content/uploads/2025/12/Screenshot-2025-12-29-at-17-08-50-curl-Project-status-dashboard.png" alt=""><figcaption>strcpy density in curl over time</figcaption></figure>
</div>


<pre>void curlx_strcopy(char *dest,<br>                   size_t dsize,<br>                   const char *src,<br>                   size_t slen)<br>{<br>  DEBUGASSERT(slen &lt; dsize);<br>  if(slen &lt; dsize) {<br>    memcpy(dest, src, slen);<br>    dest[slen] = 0;<br>  }<br>  else if(dsize)<br>    dest[0] = 0;<br>}</pre>



<p><a href="https://github.com/curl/curl/blob/master/lib/curlx/strcopy.c">the strcopy source</a></p>



<h2>AI slop</h2>



<p>An additional minor positive side-effect of this change is of course that this should effectively prevent the AI chatbots to report strcpy uses in curl source code and insist it is insecure if anyone would ask (as people still apparently do). It has been proven numerous times already that strcpy in source code is like a honey pot for generating hallucinated vulnerability claims.</p>



<p>Still, this will just make them find something else to make up a report about, so there is probably no net gain. AI slop is not a game we can win.</p>
	</div><!-- .entry-content -->
	
	</article><!-- #post-28909 -->
		<nav>
		<h2>
			Post navigation		</h2>
		<!-- .nav-links -->
		</nav><!-- .navigation -->
		
<!-- #comments -->
		</div><!-- #primary -->

<!-- #content-sidebar -->
<div id="secondary">
		<h2>curl, open source and networking</h2>
	
	
		<!-- #primary-sidebar -->
	</div><!-- #secondary -->

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The British empire's resilient subsea telegraph network (165 pts)]]></title>
            <link>https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html</link>
            <guid>46432999</guid>
            <pubDate>Tue, 30 Dec 2025 13:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html">https://subseacables.blogspot.com/2025/12/the-british-empires-resilient-subsea.html</a>, See on <a href="https://news.ycombinator.com/item?id=46432999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="2" id="Blog1">
<article>
<div>

<h3>
The British Empire's Resilient Subsea Telegraph Network
</h3>


<div id="post-body-484312278907445582">
<p>The British empire had largely completed its Red Line cable network by 1902. This network allowed news and messages to be delivered in a few minutes or several hours at most depending on the message queue's length. It spanned the globe and formed a network ring so traffic could be routed in the opposite direction in case of disruption. It was, as <a data-entity-urn="urn:li:fsd_profile:ACoAAA4yq5YBSeoQka__LIW-DUSY96qYhels8bY" data-guid="0" data-object-urn="urn:li:fsd_profile:ACoAAA4yq5YBSeoQka__LIW-DUSY96qYhels8bY" data-original-text="Dr. Michael Delaunay" data-test-ql-mention="true" href="https://www.linkedin.com/in/roderick-beck-94868948/recent-activity/all/#" spellcheck="false">Dr. Michael Delaunay</a> has argued, a highly resilient network. Besides the ring configuration, the network relied on multiple cables between any pair of given end points to ensure uptime. The British military believed it would be impossible for an enemy to cut enough cables on any route to sever all communications between any given pair of  end points. The Committee of Imperial Defense concluded that 57 cables must be shut down to isolate the British Isles from the Red Line network. The figure was 15 for Canada and 7 for South Africa. The Empire was self sufficient in terms of manufacturing the components for a subsea telegraph cable and repairing it. Its navy had no peers.&nbsp;</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxdPUjhIYaHDXjA8B4dWPTlz5TKHwnpqte-GoEjTBvZWTPhBx3_qHDi_3mIXODUB1G8M0iHBNA4B5PMBkSLJOVTfrHbVSrSe8eb6YGiHyPymziABkD9cWnf4ADsVuAFCo9gNXXcrNB4OViNqouOdMCBdLFFqhoOqe6ze6wvcLcwQpD9gvqbZF_UgP6-qk/s1100/1902AllRedLineMap.jpg" imageanchor="1"><img alt="Map of the British Empires Global Telegraph Network" data-original-height="649" data-original-width="1100" height="378" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjxdPUjhIYaHDXjA8B4dWPTlz5TKHwnpqte-GoEjTBvZWTPhBx3_qHDi_3mIXODUB1G8M0iHBNA4B5PMBkSLJOVTfrHbVSrSe8eb6YGiHyPymziABkD9cWnf4ADsVuAFCo9gNXXcrNB4OViNqouOdMCBdLFFqhoOqe6ze6wvcLcwQpD9gvqbZF_UgP6-qk/w640-h378/1902AllRedLineMap.jpg" title="Map of the British Empires Global Telegraph Network" width="640"></a></p><br>
</div>

</div>


</article>
</div><div data-version="2" id="PopularPosts1">
<h3>
Popular posts from this blog
</h3>
<div role="feed">
<article role="article">
<h3><a href="https://subseacables.blogspot.com/2025/07/the-low-satellite-life-expectancy-of.html"> The Short Life Expectancy of Starlink's LEO Satellites</a></h3>

<div>
<p><a href="https://subseacables.blogspot.com/2025/07/the-low-satellite-life-expectancy-of.html">
<img alt="Image" sizes="72px" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWMYe9_pzc5BqF3HvoyzUWJSYunhu3xNOXCb_d2Ue0y0VZvhsqRCTaTLye2-ZkkzR_PWHefM5w8sNPwIwlTVG_FwxOTsiDbYFmMuf29xIPz6CHflw_APvWHPzoWNOfZm9wYo9St38ZH6B1zgn0PXPltaHAj3FhcUUgcBBvkF2b5PsWvmTsMnr444DE90A/w640-h426/falcon-9-1404x936.jpeg" srcset="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWMYe9_pzc5BqF3HvoyzUWJSYunhu3xNOXCb_d2Ue0y0VZvhsqRCTaTLye2-ZkkzR_PWHefM5w8sNPwIwlTVG_FwxOTsiDbYFmMuf29xIPz6CHflw_APvWHPzoWNOfZm9wYo9St38ZH6B1zgn0PXPltaHAj3FhcUUgcBBvkF2b5PsWvmTsMnr444DE90A/w72-h72-p-k-no-nu/falcon-9-1404x936.jpeg 72w, https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjWMYe9_pzc5BqF3HvoyzUWJSYunhu3xNOXCb_d2Ue0y0VZvhsqRCTaTLye2-ZkkzR_PWHefM5w8sNPwIwlTVG_FwxOTsiDbYFmMuf29xIPz6CHflw_APvWHPzoWNOfZm9wYo9St38ZH6B1zgn0PXPltaHAj3FhcUUgcBBvkF2b5PsWvmTsMnr444DE90A/w144-h144-p-k-no-nu/falcon-9-1404x936.jpeg 144w">
</a>
</p>
<div>
<p>
According to FCC filings Starlink shut down almost 500 Starlink satellites during the first half of 2025. The company had them reenter the atmosphere where they burned up. What is striking is that these satellites were all less than 5 years old. The general consensus is that LEOs have a life expectancy ranging from 5 to 8 years. Shorter than expected life spans for the satellites will hit Starlink's income statement hard by increasing network depreciation and replacement needs. However, Starlink has managed to lower its LEO's manufacturing costs down to $500K versus initial figures around $1 million. So these production economies of scale might offset some of the higher than expected depreciation. However, there are also rocket launch costs as well. It costs Starlink about $3 million to put a satellite into orbit. The Falcon 9 costs $67 million per flight and delivers 23 LEOs into low Earth orbit. As a private company Starlink financials are a bit of mystery. The company press ...
</p>
</div>

</div>
</article>
<article role="article">
<h3><a href="https://subseacables.blogspot.com/2025/09/here-we-go-again-several-major-cables.html"> Here We Go Again: Several Major Cables Down Off Yemen</a></h3>

<div>
<p><a href="https://subseacables.blogspot.com/2025/09/here-we-go-again-several-major-cables.html">
<img alt="Image" sizes="72px" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg11Ssf5eFDtxAtUDVGnkhlCsmFop48R2dks5mUajwyMMBSHFO0d4xCAQsFtBKcx5K0c5zDW6m5DGwN7yc8XHApwsw4ehTuVdsdgN0zu-nGK9GSmXu0FeIGPJSyJeWUqgFg0zm1r8d1rliIV90GZ-YQFbQk0X5vQScD_oMgMR4ZLE9EDrPtJcA6rnyw2WY/w640-h402/Screenshot%202025-09-07%20204019.png" srcset="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg11Ssf5eFDtxAtUDVGnkhlCsmFop48R2dks5mUajwyMMBSHFO0d4xCAQsFtBKcx5K0c5zDW6m5DGwN7yc8XHApwsw4ehTuVdsdgN0zu-nGK9GSmXu0FeIGPJSyJeWUqgFg0zm1r8d1rliIV90GZ-YQFbQk0X5vQScD_oMgMR4ZLE9EDrPtJcA6rnyw2WY/w72-h72-p-k-no-nu/Screenshot%202025-09-07%20204019.png 72w, https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg11Ssf5eFDtxAtUDVGnkhlCsmFop48R2dks5mUajwyMMBSHFO0d4xCAQsFtBKcx5K0c5zDW6m5DGwN7yc8XHApwsw4ehTuVdsdgN0zu-nGK9GSmXu0FeIGPJSyJeWUqgFg0zm1r8d1rliIV90GZ-YQFbQk0X5vQScD_oMgMR4ZLE9EDrPtJcA6rnyw2WY/w144-h144-p-k-no-nu/Screenshot%202025-09-07%20204019.png 144w">
</a>
</p>
<div>
<p>
Three industry insiders have confirmed the 'epicenter' of the outages is in Yemen coastal waters at a depth of only one 100 meters. This strongly suggests fishing or more likely an anchor is responsible. Multiple sources have told me that neither Egyptian or Saudi Internet services has been degraded, but the Persian Gulf has been hit hard as well as Pakistan. This is consistent with the epicenter being off Yemen. It is also consistent with the cables reported down below. Four Cables Definitely Down: 1. EIG. 2. SWM4. 3. IMEWE. 4. Falcon Lower left map is SMW4. Center is EIG. Far right is IMEWE. Total capacity of these four cables is approximately 44 Tbps. Pakistan is heavily dependent on SWM4, EIG, and IMEWE. Scattered reports initially suggest AAE1 may also be down. But it is not.
</p>
</div>

</div>
</article>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Approachable Swift Concurrency (162 pts)]]></title>
            <link>https://fuckingapproachableswiftconcurrency.com/en/</link>
            <guid>46432916</guid>
            <pubDate>Tue, 30 Dec 2025 13:01:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fuckingapproachableswiftconcurrency.com/en/">https://fuckingapproachableswiftconcurrency.com/en/</a>, See on <a href="https://news.ycombinator.com/item?id=46432916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<div id="async-await">
<h2><a href="#async-await">Async Code: async/await</a></h2>
<p>Most of what apps do is wait. Fetch data from a server - wait for the response. Read a file from disk - wait for the bytes. Query a database - wait for the results.</p>
<p>Before Swift's concurrency system, you'd express this waiting with callbacks, delegates, or <a href="https://developer.apple.com/documentation/combine">Combine</a>. They work, but nested callbacks get hard to follow, and Combine has a steep learning curve.</p>
<p><code>async/await</code> gives Swift a new way to handle waiting. Instead of callbacks, you write code that looks sequential - it pauses, waits, and resumes. Under the hood, Swift's runtime manages these pauses efficiently. But making your app actually stay responsive while waiting depends on <em>where</em> code runs, which we'll cover later.</p>
<p>An <strong>async function</strong> is one that might need to pause. You mark it with <code>async</code>, and when you call it, you use <code>await</code> to say "pause here until this finishes":</p>
<pre><code><span>func</span> <span>fetchUser</span><span>(</span>id<span>:</span> <span>Int</span><span>)</span> <span>async</span> <span>throws</span> <span>-&gt;</span> <span>User</span> <span>{</span>
    <span>let</span> url <span>=</span> <span>URL</span><span>(</span>string<span>:</span> <span><span>"https://api.example.com/users/</span><span>\(</span><span>id</span><span>)</span><span>"</span></span><span>)</span><span>!</span>
    <span>let</span> <span>(</span>data<span>,</span> <span>_</span><span>)</span> <span>=</span> <span>try</span> <span>await</span> <span>URLSession</span><span>.</span>shared<span>.</span><span>data</span><span>(</span>from<span>:</span> url<span>)</span>  <span>// Suspends here</span>
    <span>return</span> <span>try</span> <span>JSONDecoder</span><span>(</span><span>)</span><span>.</span><span>decode</span><span>(</span><span>User</span><span>.</span><span>self</span><span>,</span> from<span>:</span> data<span>)</span>
<span>}</span>

<span>// Calling it</span>
<span>let</span> user <span>=</span> <span>try</span> <span>await</span> <span>fetchUser</span><span>(</span>id<span>:</span> <span>123</span><span>)</span>
<span>// Code here runs after fetchUser completes</span></code></pre>
<p>Your code pauses at each <code>await</code> - this is called <strong>suspension</strong>. When the work finishes, your code resumes right where it left off. Suspension gives Swift the opportunity to do other work while waiting.</p>
<h3>Waiting for <em>them</em></h3>
<p>What if you need to fetch several things? You could await them one by one:</p>
<pre><code><span>let</span> avatar <span>=</span> <span>try</span> <span>await</span> <span>fetchImage</span><span>(</span><span><span>"avatar.jpg"</span></span><span>)</span>
<span>let</span> banner <span>=</span> <span>try</span> <span>await</span> <span>fetchImage</span><span>(</span><span><span>"banner.jpg"</span></span><span>)</span>
<span>let</span> bio <span>=</span> <span>try</span> <span>await</span> <span>fetchBio</span><span>(</span><span>)</span></code></pre>
<p>But that's slow - each waits for the previous one to finish. Use <code>async let</code> to run them in parallel:</p>
<pre><code><span>func</span> <span>loadProfile</span><span>(</span><span>)</span> <span>async</span> <span>throws</span> <span>-&gt;</span> <span>Profile</span> <span>{</span>
    <span>async</span> <span>let</span> avatar <span>=</span> <span>fetchImage</span><span>(</span><span><span>"avatar.jpg"</span></span><span>)</span>
    <span>async</span> <span>let</span> banner <span>=</span> <span>fetchImage</span><span>(</span><span><span>"banner.jpg"</span></span><span>)</span>
    <span>async</span> <span>let</span> bio <span>=</span> <span>fetchBio</span><span>(</span><span>)</span>

    <span>// All three are fetching in parallel!</span>
    <span>return</span> <span>Profile</span><span>(</span>
        avatar<span>:</span> <span>try</span> <span>await</span> avatar<span>,</span>
        banner<span>:</span> <span>try</span> <span>await</span> banner<span>,</span>
        bio<span>:</span> <span>try</span> <span>await</span> bio
    <span>)</span>
<span>}</span></code></pre>
<p>Each <code>async let</code> starts immediately. The <code>await</code> collects the results.</p>
<div>
<h4>await needs async</h4>
<p>You can only use <code>await</code> inside an <code>async</code> function.</p>
</div>
  </div>
<div id="tasks">
<h2><a href="#tasks">Managing Work: Tasks</a></h2>
<p>A <strong><a href="https://developer.apple.com/documentation/swift/task">Task</a></strong> is a unit of async work you can manage. You've written async functions, but a Task is what actually runs them. It's how you start async code from synchronous code, and it gives you control over that work: wait for its result, cancel it, or let it run in the background.</p>
<p>Let's say you're building a profile screen. Load the avatar when the view appears using the <a href="https://developer.apple.com/documentation/swiftui/view/task(priority:_:)"><code>.task</code></a> modifier, which cancels automatically when the view disappears:</p>
<pre><code><span>struct</span> <span>ProfileView</span><span>:</span> <span>View</span> <span>{</span>
    <span>@State</span> <span>private</span> <span>var</span> avatar<span>:</span> <span>Image</span><span>?</span>

    <span>var</span> body<span>:</span> <span>some</span> <span>View</span> <span>{</span>
        avatar
            <span>.</span>task <span>{</span> avatar <span>=</span> <span>await</span> <span>downloadAvatar</span><span>(</span><span>)</span> <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<p>If users can switch between profiles, use <code>.task(id:)</code> to reload when the selection changes:</p>
<pre><code><span>struct</span> <span>ProfileView</span><span>:</span> <span>View</span> <span>{</span>
    <span>var</span> userID<span>:</span> <span>String</span>
    <span>@State</span> <span>private</span> <span>var</span> avatar<span>:</span> <span>Image</span><span>?</span>

    <span>var</span> body<span>:</span> <span>some</span> <span>View</span> <span>{</span>
        avatar
            <span>.</span><span>task</span><span>(</span>id<span>:</span> userID<span>)</span> <span>{</span> avatar <span>=</span> <span>await</span> <span>downloadAvatar</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<p>When the user taps "Save", create a Task manually:</p>
<pre><code><span>Button</span><span>(</span><span><span>"Save"</span></span><span>)</span> <span>{</span>
    <span>Task</span> <span>{</span> <span>await</span> <span>saveProfile</span><span>(</span><span>)</span> <span>}</span>
<span>}</span></code></pre>
<p>What if you need to load the avatar, bio, and stats all at once? Use a <a href="https://developer.apple.com/documentation/swift/taskgroup"><code>TaskGroup</code></a> to fetch them in parallel:</p>
<pre><code><span>try</span> <span>await</span> <span>withThrowingTaskGroup</span><span>(</span>of<span>:</span> <span>Void</span><span>.</span><span>self</span><span>)</span> <span>{</span> group <span>in</span>
    group<span>.</span>addTask <span>{</span> avatar <span>=</span> <span>try</span> <span>await</span> <span>downloadAvatar</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    group<span>.</span>addTask <span>{</span> bio <span>=</span> <span>try</span> <span>await</span> <span>fetchBio</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    group<span>.</span>addTask <span>{</span> stats <span>=</span> <span>try</span> <span>await</span> <span>fetchStats</span><span>(</span><span>for</span><span>:</span> userID<span>)</span> <span>}</span>
    <span>try</span> <span>await</span> group<span>.</span><span>waitForAll</span><span>(</span><span>)</span>
<span>}</span></code></pre>
<p>Tasks inside a group are <strong>child tasks</strong>, linked to the parent. A few things to know:</p>
<ul>
<li><strong>Cancellation propagates</strong>: cancel the parent, and all children get cancelled too</li>
<li><strong>Errors</strong>: a thrown error cancels siblings and rethrows, but only when you consume results with <code>next()</code>, <code>waitForAll()</code>, or iteration</li>
<li><strong>Completion order</strong>: results arrive as tasks finish, not the order you added them</li>
<li><strong>Waits for all</strong>: the group doesn't return until every child completes or is cancelled</li>
</ul>
<p>This is <strong><a href="https://developer.apple.com/videos/play/wwdc2021/10134/">structured concurrency</a></strong>: work organized in a tree that's easy to reason about and clean up.</p>
  </div>
<div id="execution">
<h2><a href="#execution">Where Things Run: From Threads to Isolation Domains</a></h2>
<p>So far we've talked about <em>when</em> code runs (async/await) and <em>how to organize</em> it (Tasks). Now: <strong>where does it run, and how do we keep it safe?</strong></p>
<div>
<h4>Most apps just wait</h4>
<p>Most app code is <strong>I/O-bound</strong>. You fetch data from a network, <em>await</em> a response, decode it, and display it. If you have multiple I/O operations to coordinate, you resort to <em>tasks</em> and <em>task groups</em>. The actual CPU work is minimal. The main thread can handle this fine because <code>await</code> suspends without blocking.</p>
<p>But sooner or later, you'll have <strong>CPU-bound work</strong>: parsing a giant JSON file, processing images, running complex calculations. This work doesn't wait for anything external. It just needs CPU cycles. If you run it on the main thread, your UI freezes. This is where "where does code run" actually matters.</p>
</div>
<h3>The Old World: Many Options, No Safety</h3>
<p>Before Swift's concurrency system, you had several ways to manage execution:</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>What it does</th>
<th>Tradeoffs</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://developer.apple.com/documentation/foundation/thread">Thread</a></td>
<td>Direct thread control</td>
<td>Low-level, error-prone, rarely needed</td>
</tr>
<tr>
<td><a href="https://developer.apple.com/documentation/dispatch">GCD</a></td>
<td>Dispatch queues with closures</td>
<td>Simple but no cancellation, easy to cause thread explosion</td>
</tr>
<tr>
<td><a href="https://developer.apple.com/documentation/foundation/operationqueue">OperationQueue</a></td>
<td>Task dependencies, cancellation, KVO</td>
<td>More control but verbose and heavyweight</td>
</tr>
<tr>
<td><a href="https://developer.apple.com/documentation/combine">Combine</a></td>
<td>Reactive streams</td>
<td>Great for event streams, steep learning curve</td>
</tr>
</tbody>
</table>
<p>All of these worked, but safety was entirely on you. The compiler couldn't help if you forgot to dispatch to main, or if two queues accessed the same data simultaneously.</p>
<h3>The Problem: Data Races</h3>
<p>A <a href="https://developer.apple.com/documentation/xcode/data-race">data race</a> happens when two threads access the same memory at the same time, and at least one is writing:</p>
<pre><code><span>var</span> count <span>=</span> <span>0</span>

<span>DispatchQueue</span><span>.</span><span>global</span><span>(</span><span>)</span><span>.</span><span>async</span> <span>{</span> count <span>+=</span> <span>1</span> <span>}</span>
<span>DispatchQueue</span><span>.</span><span>global</span><span>(</span><span>)</span><span>.</span><span>async</span> <span>{</span> count <span>+=</span> <span>1</span> <span>}</span>

<span>// Undefined behavior: crash, memory corruption, or wrong value</span></code></pre>
<p>Data races are undefined behavior. They can crash, corrupt memory, or silently produce wrong results. Your app works fine in testing, then crashes randomly in production. Traditional tools like locks and semaphores help, but they're manual and error-prone.</p>
<div>
<h4>Concurrency amplifies the problem</h4>
<p>The more concurrent your app is, the more likely data races become. A simple iOS app might get away with sloppy thread safety. A web server handling thousands of simultaneous requests will crash constantly. This is why Swift's compile-time safety matters most in high-concurrency environments.</p>
</div>
<h3>The Shift: From Threads to Isolation</h3>
<p>Swift's concurrency model asks a different question. Instead of "which thread should this run on?", it asks: <strong>"who is allowed to access this data?"</strong></p>
<p>This is <a href="https://developer.apple.com/documentation/swift/isolation">isolation</a>. Rather than manually dispatching work to threads, you declare boundaries around data. The compiler enforces these boundaries at build time, not runtime.</p>
<div>
<h4>Under the hood</h4>
<p>Swift Concurrency is built on top of <a href="https://github.com/swiftlang/swift-corelibs-libdispatch">libdispatch</a> (the same runtime as GCD). The difference is the compile-time layer: actors and isolation are enforced by the compiler, while the runtime handles scheduling on a <a href="https://developer.apple.com/videos/play/wwdc2021/10254/">cooperative thread pool</a> limited to your CPU's core count.</p>
</div>
<h3>The Three Isolation Domains</h3>
<p><strong>1. MainActor</strong></p>
<p><a href="https://developer.apple.com/documentation/swift/mainactor"><code>@MainActor</code></a> is a <a href="https://developer.apple.com/documentation/swift/globalactor">global actor</a> that represents the main thread's isolation domain. It's special because UI frameworks (UIKit, AppKit, SwiftUI) require main thread access.</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>var</span> items<span>:</span> <span>[</span><span>Item</span><span>]</span> <span>=</span> <span>[</span><span>]</span>  <span>// Protected by MainActor isolation</span>
<span>}</span></code></pre>
<p>When you mark something <code>@MainActor</code>, you're not saying "dispatch this to the main thread." You're saying "this belongs to the main actor's isolation domain." The compiler enforces that anything accessing it must either be on MainActor or <code>await</code> to cross the boundary.</p>
<div>
<h4>When in doubt, use @MainActor</h4>
<p>For most apps, marking your ViewModels with <code>@MainActor</code> is the right choice. Performance concerns are usually overblown. Start here, optimize only if you measure actual problems.</p>
</div>
<p><strong>2. Actors</strong></p>
<p>An <a href="https://developer.apple.com/documentation/swift/actor">actor</a> protects its own mutable state. It guarantees that only one piece of code can access its data at a time:</p>
<pre><code><span>actor</span> <span>BankAccount</span> <span>{</span>
    <span>var</span> balance<span>:</span> <span>Double</span> <span>=</span> <span>0</span>

    <span>func</span> <span>deposit</span><span>(</span><span>_</span> amount<span>:</span> <span>Double</span><span>)</span> <span>{</span>
        balance <span>+=</span> amount  <span>// Safe: actor guarantees exclusive access</span>
    <span>}</span>
<span>}</span>

<span>// From outside, you must await to cross the boundary</span>
<span>await</span> account<span>.</span><span>deposit</span><span>(</span><span>100</span><span>)</span></code></pre>
<p><strong>Actors are not threads.</strong> An actor is an isolation boundary. The Swift runtime decides which thread actually executes actor code. You don't control that, and you don't need to.</p>
<p><strong>3. Nonisolated</strong></p>
<p>Code marked <a href="https://developer.apple.com/documentation/swift/nonisolated"><code>nonisolated</code></a> opts out of actor isolation. It can be called from anywhere without <code>await</code>, but it cannot access the actor's protected state:</p>
<pre><code><span>actor</span> <span>BankAccount</span> <span>{</span>
    <span>var</span> balance<span>:</span> <span>Double</span> <span>=</span> <span>0</span>

    <span>nonisolated</span> <span>func</span> <span>bankName</span><span>(</span><span>)</span> <span>-&gt;</span> <span>String</span> <span>{</span>
        <span><span>"Acme Bank"</span></span>  <span>// No actor state accessed, safe to call from anywhere</span>
    <span>}</span>
<span>}</span>

<span>let</span> name <span>=</span> account<span>.</span><span>bankName</span><span>(</span><span>)</span>  <span>// No await needed</span></code></pre>
<div>
<h4>Approachable Concurrency: Less Friction</h4>
<p><a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a> simplifies the mental model with two Xcode build settings:</p>
<ul>
<li><strong><code>SWIFT_DEFAULT_ACTOR_ISOLATION</code></strong> = <code>MainActor</code>: Everything runs on MainActor unless you say otherwise</li>
<li><strong><code>SWIFT_APPROACHABLE_CONCURRENCY</code></strong> = <code>YES</code>: <code>nonisolated</code> async functions stay on the caller's actor instead of jumping to a background thread</li>
</ul>
<p>New Xcode 26 projects have both enabled by default. When you need CPU-intensive work off the main thread, use <code>@concurrent</code>.</p>
<pre><code>// Runs on MainActor (the default)
func updateUI() async { }

// Runs on background thread (opt-in)
@concurrent func processLargeFile() async { }</code></pre>
</div>
<div>
<h4>The Office Building</h4>
<p>Think of your app as an office building. Each <strong>isolation domain</strong> is a private office with a lock on the door. Only one person can be inside at a time, working with the documents in that office.</p>
<ul>
<li><strong><code>MainActor</code></strong> is the front desk - where all customer interactions happen. There's only one, and it handles everything the user sees.</li>
<li><strong><code>actor</code></strong> types are department offices - Accounting, Legal, HR. Each protects its own sensitive documents.</li>
<li><strong><code>nonisolated</code></strong> code is the hallway - shared space anyone can walk through, but no private documents live there.</li>
</ul>
<p>You can't just barge into someone's office. You knock (<code>await</code>) and wait for them to let you in.</p>
</div>
  </div>
<div id="sendable">
<h2><a href="#sendable">What Can Cross Isolation Domains: Sendable</a></h2>
<p>Isolation domains protect data, but eventually you need to pass data between them. When you do, Swift checks if it's safe.</p>
<p>Think about it: if you pass a reference to a mutable class from one actor to another, both actors could modify it simultaneously. That's exactly the data race we're trying to prevent. So Swift needs to know: can this data be safely shared?</p>
<p>The answer is the <a href="https://developer.apple.com/documentation/swift/sendable"><code>Sendable</code></a> protocol. It's a marker that tells the compiler "this type is safe to pass across isolation boundaries":</p>
<ul>
<li><strong>Sendable</strong> types can cross safely (value types, immutable data, actors)</li>
<li><strong>Non-Sendable</strong> types can't (classes with mutable state)</li>
</ul>
<pre><code><span>// Sendable - it's a value type, each place gets a copy</span>
<span>struct</span> <span>User</span><span>:</span> <span>Sendable</span> <span>{</span>
    <span>let</span> id<span>:</span> <span>Int</span>
    <span>let</span> name<span>:</span> <span>String</span>
<span>}</span>

<span>// Non-Sendable - it's a class with mutable state</span>
<span>class</span> <span>Counter</span> <span>{</span>
    <span>var</span> count <span>=</span> <span>0</span>  <span>// Two places modifying this = disaster</span>
<span>}</span></code></pre>
<h3>Making Types Sendable</h3>
<p>Swift automatically infers <code>Sendable</code> for many types:</p>
<ul>
<li><strong>Structs and enums</strong> with only <code>Sendable</code> properties are implicitly <code>Sendable</code></li>
<li><strong>Actors</strong> are always <code>Sendable</code> because they protect their own state</li>
<li><strong><code>@MainActor</code> types</strong> are <code>Sendable</code> because MainActor serializes access</li>
</ul>
<p>For classes, it's harder. A class can conform to <code>Sendable</code> only if it's <code>final</code> and all its stored properties are immutable:</p>
<pre><code><span>final</span> <span>class</span> <span>APIConfig</span><span>:</span> <span>Sendable</span> <span>{</span>
    <span>let</span> baseURL<span>:</span> <span>URL</span>      <span>// Immutable</span>
    <span>let</span> timeout<span>:</span> <span>Double</span>   <span>// Immutable</span>
<span>}</span></code></pre>
<p>If you have a class that's thread-safe through other means (locks, atomics), you can use <a href="https://developer.apple.com/documentation/swift/uncheckedsendable"><code>@unchecked Sendable</code></a> to tell the compiler "trust me":</p>
<pre><code><span>final</span> <span>class</span> <span>ThreadSafeCache</span><span>:</span> <span>@unchecked</span> <span>Sendable</span> <span>{</span>
    <span>private</span> <span>let</span> lock <span>=</span> <span>NSLock</span><span>(</span><span>)</span>
    <span>private</span> <span>var</span> storage<span>:</span> <span>[</span><span>String</span><span>:</span> <span>Data</span><span>]</span> <span>=</span> <span>[</span><span>:</span><span>]</span>
<span>}</span></code></pre>
<div>
<h4>@unchecked Sendable is a promise</h4>
<p>The compiler won't verify thread safety. If you're wrong, you'll get data races. Use sparingly.</p>
</div>
<div>
<h4>Approachable Concurrency: Less Friction</h4>
<p>With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a>, Sendable errors become much rarer:</p>
<ul>
<li>If code doesn't cross isolation boundaries, you don't need Sendable</li>
<li>Async functions stay on the caller's actor instead of hopping to a background thread</li>
<li>The compiler is smarter about detecting when values are used safely</li>
</ul>
<p>Enable it by setting <code>SWIFT_DEFAULT_ACTOR_ISOLATION</code> to <code>MainActor</code> and <code>SWIFT_APPROACHABLE_CONCURRENCY</code> to <code>YES</code>. New Xcode 26 projects have both enabled by default. When you do need parallelism, mark functions <code>@concurrent</code> and then think about Sendable.</p>
</div>
<div>
<h4>Photocopies vs. Original Documents</h4>
<p>Back to the office building. When you need to share information between departments:</p>
<ul>
<li><strong>Photocopies are safe</strong> - If Legal makes a copy of a document and sends it to Accounting, both have their own copy. They can scribble on them, modify them, whatever. No conflict.</li>
<li><strong>Original signed contracts must stay put</strong> - If two departments could both modify the original, chaos ensues. Who has the real version?</li>
</ul>
<p><code>Sendable</code> types are like photocopies: safe to share because each place gets its own independent copy (value types) or because they're immutable (nobody can modify them). Non-<code>Sendable</code> types are like original contracts: passing them around creates the potential for conflicting modifications.</p>
</div>
  </div>
<div id="isolation-inheritance">
<h2><a href="#isolation-inheritance">How Isolation Is Inherited</a></h2>
<p>You've seen that isolation domains protect data, and Sendable controls what crosses between them. But how does code end up in an isolation domain in the first place?</p>
<p>When you call a function or create a closure, isolation flows through your code. With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a>, your app starts on <a href="https://developer.apple.com/documentation/swift/mainactor"><code>MainActor</code></a>, and that isolation propagates to the code you call, unless something explicitly changes it. Understanding this flow helps you predict where code runs and why the compiler sometimes complains.</p>
<h3>Function Calls</h3>
<p>When you call a function, its isolation determines where it runs:</p>
<pre><code><span>@MainActor</span> <span>func</span> <span>updateUI</span><span>(</span><span>)</span> <span>{</span> <span>}</span>      <span>// Always runs on MainActor</span>
<span>func</span> <span>helper</span><span>(</span><span>)</span> <span>{</span> <span>}</span>                    <span>// Inherits caller's isolation</span>
<span>@concurrent</span> <span>func</span> <span>crunch</span><span>(</span><span>)</span> <span>async</span> <span>{</span> <span>}</span>  <span>// Explicitly runs off-actor</span></code></pre>
<p>With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a>, most of your code inherits <code>MainActor</code> isolation. The function runs where the caller runs, unless it explicitly opts out.</p>
<h3>Closures</h3>
<p>Closures inherit isolation from the context where they're defined:</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>func</span> <span>setup</span><span>(</span><span>)</span> <span>{</span>
        <span>let</span> closure <span>=</span> <span>{</span>
            <span>// Inherits MainActor from ViewModel</span>
            <span>self</span><span>.</span><span>updateUI</span><span>(</span><span>)</span>  <span>// Safe, same isolation</span>
        <span>}</span>
        <span>closure</span><span>(</span><span>)</span>
    <span>}</span>
<span>}</span></code></pre>
<p>This is why SwiftUI's <code>Button</code> action closures can safely update <code>@State</code>: they inherit MainActor isolation from the view.</p>
<h3>Tasks</h3>
<p>A <code>Task { }</code> inherits actor isolation from where it's created:</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>func</span> <span>doWork</span><span>(</span><span>)</span> <span>{</span>
        <span>Task</span> <span>{</span>
            <span>// Inherits MainActor isolation</span>
            <span>self</span><span>.</span><span>updateUI</span><span>(</span><span>)</span>  <span>// Safe, no await needed</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<p>This is usually what you want. The task runs on the same actor as the code that created it.</p>
<h3>Breaking Inheritance: Task.detached</h3>
<p>Sometimes you want a task that doesn't inherit any context:</p>
<pre><code><span>@MainActor</span>
<span>class</span> <span>ViewModel</span> <span>{</span>
    <span>func</span> <span>doHeavyWork</span><span>(</span><span>)</span> <span>{</span>
        <span>Task</span><span>.</span>detached <span>{</span>
            <span>// No actor isolation, runs on cooperative pool</span>
            <span>let</span> result <span>=</span> <span>await</span> <span>self</span><span>.</span><span>expensiveCalculation</span><span>(</span><span>)</span>
            <span>await</span> <span>MainActor</span><span>.</span>run <span>{</span>
                <span>self</span><span>.</span>data <span>=</span> result  <span>// Explicitly hop back</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre>
<div>
<h4>Task.detached is usually wrong</h4>
<p>The Swift team recommends <a href="https://forums.swift.org/t/revisiting-when-to-use-task-detached/57929">Task.detached as a last resort</a>. It doesn't inherit priority, task-local values, or actor context. Most of the time, regular <code>Task</code> is what you want. If you need CPU-intensive work off the main actor, mark the function <code>@concurrent</code> instead.</p>
</div>
<div>
<h4>Walking Through the Building</h4>
<p>When you're in the front desk office (MainActor), and you call someone to help you, they come to <em>your</em> office. They inherit your location. If you create a task ("go do this for me"), that assistant starts in your office too.</p>
<p>The only way someone ends up in a different office is if they explicitly go there: "I need to work in Accounting for this" (<code>actor</code>), or "I'll handle this in the back office" (<code>@concurrent</code>).</p>
</div>
  </div>
<div id="putting-it-together">
<h2><a href="#putting-it-together">Putting It All Together</a></h2>
<p>Let's step back and see how all the pieces fit.</p>
<p>Swift Concurrency can feel like a lot of concepts: <code>async/await</code>, <code>Task</code>, actors, <code>MainActor</code>, <code>Sendable</code>, isolation domains. But there's really just one idea at the center of it all: <strong>isolation is inherited by default</strong>.</p>
<p>With <a href="https://www.swift.org/documentation/articles/swift-6.2-release-notes.html">Approachable Concurrency</a> enabled, your app starts on <a href="https://developer.apple.com/documentation/swift/mainactor"><code>MainActor</code></a>. That's your starting point. From there:</p>
<ul>
<li>Every function you call <strong>inherits</strong> that isolation</li>
<li>Every closure you create <strong>captures</strong> that isolation</li>
<li>Every <a href="https://developer.apple.com/documentation/swift/task"><code>Task { }</code></a> you spawn <strong>inherits</strong> that isolation</li>
</ul>
<p>You don't have to annotate anything. You don't have to think about threads. Your code runs on <code>MainActor</code>, and the isolation just propagates through your program automatically.</p>
<p>When you need to break out of that inheritance, you do it explicitly:</p>
<ul>
<li><strong><code>@concurrent</code></strong> says "run this on a background thread"</li>
<li><strong><code>actor</code></strong> says "this type has its own isolation domain"</li>
<li><strong><code>Task.detached { }</code></strong> says "start fresh, inherit nothing"</li>
</ul>
<p>And when you pass data between isolation domains, Swift checks that it's safe. That's what <a href="https://developer.apple.com/documentation/swift/sendable"><code>Sendable</code></a> is for: marking types that can safely cross boundaries.</p>
<p>That's it. That's the whole model:</p>
<ol>
<li><strong>Isolation propagates</strong> from <code>MainActor</code> through your code</li>
<li><strong>You opt out explicitly</strong> when you need background work or separate state</li>
<li><strong>Sendable guards the boundaries</strong> when data crosses between domains</li>
</ol>
<p>When the compiler complains, it's telling you one of these rules was violated. Trace the inheritance: where did the isolation come from? Where is the code trying to run? What data is crossing a boundary? The answer is usually obvious once you ask the right question.</p>
<h3>Where to Go From Here</h3>
<p>The good news: you don't need to master everything at once.</p>
<p><strong>Most apps only need the basics.</strong> Mark your ViewModels with <code>@MainActor</code>, use <code>async/await</code> for network calls, and create <code>Task { }</code> when you need to kick off async work from a button tap. That's it. That handles 80% of real-world apps. The compiler will tell you if you need more.</p>
<p><strong>When you need parallel work</strong>, reach for <code>async let</code> to fetch multiple things at once, or <a href="https://developer.apple.com/documentation/swift/taskgroup"><code>TaskGroup</code></a> when the number of tasks is dynamic. Learn to handle cancellation gracefully. This covers apps with complex data loading or real-time features.</p>
<p><strong>Advanced patterns come later</strong>, if ever. Custom actors for shared mutable state, <code>@concurrent</code> for CPU-intensive processing, deep <code>Sendable</code> understanding. This is framework code, server-side Swift, complex desktop apps. Most developers never need this level.</p>
<div>
<h4>Start simple</h4>
<p>Don't optimize for problems you don't have. Start with the basics, ship your app, and add complexity only when you hit real problems. The compiler will guide you.</p>
</div>
  </div>
<div id="mistakes">
<h2><a href="#mistakes">Watch Out: Common Mistakes</a></h2>
<h3>Thinking async = background</h3>
<pre><code><span>// This STILL blocks the main thread!</span>
<span>@MainActor</span>
<span>func</span> <span>slowFunction</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>let</span> result <span>=</span> <span>expensiveCalculation</span><span>(</span><span>)</span>  <span>// Synchronous work = blocking</span>
    data <span>=</span> result
<span>}</span></code></pre>
<p><code>async</code> means "can pause." The actual work still runs wherever it runs. Use <code>@concurrent</code> (Swift 6.2) or <code>Task.detached</code> for CPU-heavy work.</p>
<h3>Creating too many actors</h3>
<pre><code><span>// Over-engineered</span>
<span>actor</span> <span>NetworkManager</span> <span>{</span> <span>}</span>
<span>actor</span> <span>CacheManager</span> <span>{</span> <span>}</span>
<span>actor</span> <span>DataManager</span> <span>{</span> <span>}</span>

<span>// Better - most things can live on MainActor</span>
<span>@MainActor</span>
<span>class</span> <span>AppState</span> <span>{</span> <span>}</span></code></pre>
<p>You need a custom actor only when you have shared mutable state that can't live on <code>MainActor</code>. <a href="https://www.massicotte.org/actors/">Matt Massicotte's rule</a>: introduce an actor only when (1) you have non-<code>Sendable</code> state, (2) operations on that state must be atomic, and (3) those operations can't run on an existing actor. If you can't justify it, use <code>@MainActor</code> instead.</p>
<h3>Making everything Sendable</h3>
<p>Not everything needs to cross boundaries. If you're adding <code>@unchecked Sendable</code> everywhere, step back and ask if the data actually needs to move between isolation domains.</p>
<h3>Using MainActor.run when you don't need it</h3>
<pre><code><span>// Unnecessary</span>
<span>Task</span> <span>{</span>
    <span>let</span> data <span>=</span> <span>await</span> <span>fetchData</span><span>(</span><span>)</span>
    <span>await</span> <span>MainActor</span><span>.</span>run <span>{</span>
        <span>self</span><span>.</span>data <span>=</span> data
    <span>}</span>
<span>}</span>

<span>// Better - just make the function @MainActor</span>
<span>@MainActor</span>
<span>func</span> <span>loadData</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>self</span><span>.</span>data <span>=</span> <span>await</span> <span>fetchData</span><span>(</span><span>)</span>
<span>}</span></code></pre>
<p><code>MainActor.run</code> is rarely the right solution. If you need MainActor isolation, annotate the function with <code>@MainActor</code> instead. It's clearer and the compiler can help you more. See <a href="https://www.massicotte.org/problematic-patterns/">Matt's take on this</a>.</p>
<h3>Blocking the cooperative thread pool</h3>
<pre><code><span>// NEVER do this - risks deadlock</span>
<span>func</span> <span>badIdea</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>let</span> semaphore <span>=</span> <span>DispatchSemaphore</span><span>(</span>value<span>:</span> <span>0</span><span>)</span>
    <span>Task</span> <span>{</span>
        <span>await</span> <span>doWork</span><span>(</span><span>)</span>
        semaphore<span>.</span><span>signal</span><span>(</span><span>)</span>
    <span>}</span>
    semaphore<span>.</span><span>wait</span><span>(</span><span>)</span>  <span>// Blocks a cooperative thread!</span>
<span>}</span></code></pre>
<p>Swift's cooperative thread pool has limited threads. Blocking one with <code>DispatchSemaphore</code>, <code>DispatchGroup.wait()</code>, or similar calls can cause deadlocks. If you need to bridge sync and async code, use <code>async let</code> or restructure to stay fully async.</p>
<h3>Creating unnecessary Tasks</h3>
<pre><code><span>// Unnecessary Task creation</span>
<span>func</span> <span>fetchAll</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>Task</span> <span>{</span> <span>await</span> <span>fetchUsers</span><span>(</span><span>)</span> <span>}</span>
    <span>Task</span> <span>{</span> <span>await</span> <span>fetchPosts</span><span>(</span><span>)</span> <span>}</span>
<span>}</span>

<span>// Better - use structured concurrency</span>
<span>func</span> <span>fetchAll</span><span>(</span><span>)</span> <span>async</span> <span>{</span>
    <span>async</span> <span>let</span> users <span>=</span> <span>fetchUsers</span><span>(</span><span>)</span>
    <span>async</span> <span>let</span> posts <span>=</span> <span>fetchPosts</span><span>(</span><span>)</span>
    <span>await</span> <span>(</span>users<span>,</span> posts<span>)</span>
<span>}</span></code></pre>
<p>If you're already in an async context, prefer structured concurrency (<code>async let</code>, <code>TaskGroup</code>) over creating unstructured <code>Task</code>s. Structured concurrency handles cancellation automatically and makes the code easier to reason about.</p>
  </div>
<div id="glossary">
<h2><a href="#glossary">Cheat Sheet: Quick Reference</a></h2>
<table>
<thead>
<tr>
<th>Keyword</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>async</code></td>
<td>Function can pause</td>
</tr>
<tr>
<td><code>await</code></td>
<td>Pause here until done</td>
</tr>
<tr>
<td><code>Task { }</code></td>
<td>Start async work, inherits context</td>
</tr>
<tr>
<td><code>Task.detached { }</code></td>
<td>Start async work, no inherited context</td>
</tr>
<tr>
<td><code>@MainActor</code></td>
<td>Runs on main thread</td>
</tr>
<tr>
<td><code>actor</code></td>
<td>Type with isolated mutable state</td>
</tr>
<tr>
<td><code>nonisolated</code></td>
<td>Opts out of actor isolation</td>
</tr>
<tr>
<td><code>Sendable</code></td>
<td>Safe to pass between isolation domains</td>
</tr>
<tr>
<td><code>@concurrent</code></td>
<td>Always run on background (Swift 6.2+)</td>
</tr>
<tr>
<td><code>async let</code></td>
<td>Start parallel work</td>
</tr>
<tr>
<td><code>TaskGroup</code></td>
<td>Dynamic parallel work</td>
</tr>
</tbody>
</table>
<h2>Further Reading</h2>


  </div>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Times New American: A Tale of Two Fonts (219 pts)]]></title>
            <link>https://hsu.cy/2025/12/times-new-american/</link>
            <guid>46432862</guid>
            <pubDate>Tue, 30 Dec 2025 12:56:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hsu.cy/2025/12/times-new-american/">https://hsu.cy/2025/12/times-new-american/</a>, See on <a href="https://news.ycombinator.com/item?id=46432862">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>A less romantic truth is that aesthetic standards rarely travel alone; power tends to follow in their wake. An episode at the U.S. State Department this month makes exactly this point.</p>
<p>On December 9, Secretary of State Marco Rubio issued a memo titled “Return to Tradition” that <a href="https://www.nytimes.com/2025/12/09/us/politics/rubio-state-department-typeface.html">required</a> all State Department documents to switch back to 14-point Times New Roman, overturning a Biden-era <a href="https://www.washingtonpost.com/world/2023/01/18/state-department-times-new-roman-calibri/">directive</a> from 2023 that had turned to 15-point Calibri.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/2826e5fc02cb3a35ba040dce9a8b8c4f.jpg">
<figcaption>State Department correspondence in Calibri and Times New Roman (Credit: <em>The New York Times</em>)</figcaption>
</figure>
<p>Frankly, most people likely view both of these simply as “standard typefaces” without distinguishing much difference between them. So why would an institution of the State Department’s scale bother, twice in three years, to take a stance on something as seemingly trivial as a default typeface?</p>
<p>John Gruber, an Apple-sphere blogger with a well-known appetite for political commentary, obtained the <a href="https://daringfireball.net/misc/2025/12/state-department-return-to-tradition.text">full text</a> of Rubio’s memo and published it. <sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> (It is worth reading first.) Rubio’s rationale, in simplified form, has three parts. First, serif typefaces are said to better communicate professionalism, formality, and authority in official documents (¶¶ 6–8). Second, using a serif typeface is aligning with the White House, the courts, and the State Department’s own historical practice (¶ 9). Third, the 2023 decision was a “cosmetic” gesture associated with diversity, equity, inclusion, and accessibility (DEIA) politics, and the reversion a correction to that (¶ 10).</p>
<p>Commentary on American partisan politics is beyond the scope of this article. Still, in neutral terms, Trump’s second term has been marked by an <a href="https://www.pewresearch.org/short-reads/2025/12/16/trump-has-already-issued-more-executive-orders-in-his-second-term-than-in-his-first/">unusually rapid and sweeping effort</a> to repeal or reverse the prior administration’s policies, with DEIA among the earliest targets. The memo itself cites <a href="https://www.federalregister.gov/documents/2025/01/29/2025-01953/ending-radical-and-wasteful-government-dei-programs-and-preferencing">Executive Order 14151</a>, signed on the first day of the term, that instructed federal agencies to terminate all DEIA-related activities, offices, positions, policies, programs, and contracts.</p>
<p>That makes the political element of this typography decision fairly plain: it coheres with, and signals loyalty to, a broader anti-DEIA agenda. The remaining question is whether it is only politics. Put differently, how persuasive are Rubio’s first two, ostensibly nonpolitical claims about design and conventions? Or are they merely pretexts?</p>
<p>To recap, a <em>serif</em> typeface is one with extra decorative strokes, or “serifs,” at the ends of main strokes. A popular narrative links serifs to stone inscriptions: Roman craftsmen would sketch letter outlines on stone and carve along them; at stroke endings and corners, the chisel work flared outward, leaving the small protrusions we now call serifs. That lineage likely underwrites the memo’s association of serifs with “tradition,” “formality,” and “ceremony.”</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/60c7889a28a5b2c040d5a64ea32a7688.jpg">
<figcaption>A Roman stone inscription (Credit: <em>Wikipedia</em>)</figcaption>
</figure>
<p>However, most people don’t actually know this history, and many cannot reliably distinguish serif from sans-serif in the first place. The general public doesn’t perceive serif typefaces as professional and authoritative, <em>a priori</em>, before prioritizing their use in formal settings. Instead, people first observe that government, academia, and corporate workplaces disproportionately use serif faces — or are trained to use them — and only then infer that serifs must mean professionalism and authority.</p>
<p>Even if we limit ourselves to design and historical considerations, Times New Roman, despite being a serif typeface, possesses little of the “professional, solemn, and authoritative” aura. The typeface was designed in 1931 for <em>The Times</em> of London, and newspaper typefaces are typically engineered to print cleanly on cheap paper, conserve space, and support rapid scanning.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/0ef1b7bb8588fbdffff653d05a7b8c17.jpg">
<figcaption>Times New Roman on newsprint (<em>Wikipedia</em>)</figcaption>
</figure>
<p>Those goals are visible in the details. The strokes of Times New Roman are relatively thin (leaving tolerance for ink spread on newsprint), the letterforms are narrow, and the x-height (the height of the lowercase “x”) is comparatively large. There is nothing inherently wrong with such functional design; it simply doesn’t map neatly onto the “traditional” look of older serifs. On a modern, high-resolution display, the typeface can appear spindly, more utilitarian than ceremonial.</p>
<p>Indeed, the stronger explanation for Times New Roman’s long reign isn’t aesthetic excellence, but practicality and inertia. Times New Roman was among the small set of <a href="https://web.archive.org/web/20020511131315/http://www.melbpc.org.au/pcupdate/9303/9303article3.htm">typefaces bundled with early versions of Windows</a>. It was also promoted as “web-safe,” meaning webmasters could reasonably assume it would render properly across platforms. In the early era of digitalization, choosing Times New Roman was often less a deliberate endorsement than a default imposed by limited options. Over time, the habit hardened into a standard, and institutions began to require it without much reflection, effectively borrowing their own authority to confer authority upon the typeface.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/6cc62e4fe079ba6cdbfe404f902c86f4.png">
<figcaption>The font dialog on Windows 95 (Credit: <em>GUIdebook</em>)</figcaption>
</figure>
<p>Professionals who genuinely focus on typography have advised against Times New Roman. For example, type designer Matthew Butterick eloquently <a href="https://practicaltypography.com/a-brief-history-of-times-new-roman.html#:~:text=When%20Times%20New%20Ro%C2%ADman%20ap%C2%ADpears">comments</a>:</p>
<blockquote>
<p>When Times New Roman appears in a book, document, or advertisement, it connotes apathy. It says, “I submitted to the typeface of least resistance.” Times New Roman isn’t a typeface choice so much as the absence of a typeface choice, like the blackness of deep space isn’t a color. To look at Times New Roman is to gaze into the void.</p>
</blockquote>
<p>Similarly, the U.S. Court of Appeals for the Eighth Circuit, in its formatting advice for lawyers, specifically <a href="https://federalcourt.press/wp-content/uploads/2018/03/Eighth-Circuit-Checklist.pdf">cautions</a>:</p>
<blockquote>
<p>Typographic decisions should be made for a purpose. <em>The Times of London</em> chose the typeface Times New Roman to serve an audience looking for a quick read. Lawyers don’t want their audience to read fast and throw the document away; they want to maximize retention. Achieving that goal requires a different approach — different typefaces, different column widths, different writing conventions. Briefs are like books rather than newspapers. The most important piece of advice we can offer is this: read some good books and try to make your briefs more like them.</p>
</blockquote>
<p>As for the other U.S. official bodies Rubio cites in the memo, many don’t actually use Times New Roman either. The Supreme Court’s rules <a href="https://www.law.cornell.edu/rules/supct/rule_33">require</a> booklet-format filings to be set in the Century family, and its own opinions are typeset in Century Schoolbook from that family. Originating in the 19th century, the typeface features more expansive proportions, balanced stroke contrast, and an elegant form, exuding a far more assertive presence than Times New Roman. As the name suggests, it also began life as a textbook face, optimized for legibility. With proper typesetting, it reads far better than a haphazardly produced Word document set in Times New Roman.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/9c3f70b2e92f14cf0477dc2cb25b336c.png">
<figcaption>A U.S. Supreme Court opinion set in Century Schoolbook (the infamous <em>Dobbs</em> decision)</figcaption>
</figure>
<p>Looking at the legislature, the official PDFs of U.S. Congressional bills use <a href="https://en.wikipedia.org/wiki/Cheltenham_%28typeface%29">Cheltenham</a> for titles and <a href="https://typefacesinuse.com/typefaces/253/de-vinne-linotype">De Vinne</a> for body text. De Vinne, first released in 1902, shares similarities in style with Century Schoolbook but features stronger stroke contrast and more decorative serifs, giving it an “engraved” quality. Objectively speaking, this design borders on being a display typeface — imagine the logotype of <em>Harper’s Bazaar</em>, Didot — and is somewhat tiring to read in body text. But when it comes to conveying ceremony and solemnity, it’s far more qualified than Times New Roman. (After a bill is enacted into law, it will be typeset in New Century Schoolbook.)</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/7929f56f8523adfb86024959464adaee.png">
<figcaption>A U.S. House bill PDF page from the initial submission of the “One Big Beautiful” Bill</figcaption>
</figure>
<p>Even the Trump administration, to which Rubio pledges allegiance, contradicts the “serif tradition” by using a fashionable tall, high-contrast serif (<a href="https://github.com/Instrument/instrument-serif">Instrument Serif</a>) on the <a href="https://www.whitehouse.gov/">White House website</a>. It may look a bit mannered by government standards — an impression no less bolstered by its bombastic rhetoric — but it does manage to appear assertive and emphatic. Swap in Times New Roman and “AMERICA IS BACK” would read more like a mutter.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/8989ca4f8eace4c82d367731360d192b.png">
<figcaption>WhiteHouse.gov design in Trump’s second term</figcaption>
</figure>
<p>Thus, the design and historical reasons cited in Rubio’s memo don’t hold up. The formality and authority of serif typefaces are largely socially constructed, and Times New Roman’s origin story and design constraints don’t express these qualities. If Times New Roman carries authority at all, it’s primarily borrowed from the authority of institutions that have adhered to it. If the sincere goal were to “return to tradition” by returning to a serif, there are many choices with deeper pedigree and more fitting gravitas.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/c998e9b9e9f2d2a87fe9d13a9cd5b6b4.png">
<figcaption>Times New Roman compared with select serif typefaces with stronger reputations</figcaption>
</figure>
<p>At this point, it might sound as though the argument is trending toward a defense of the Department’s earlier choice: Calibri. Unfortunately, Calibri is also a poor fit for formal contexts. While seriousness and authority aren’t the exclusive province of serifs, Calibri does little to convey those traits.</p>
<p>Typographically, Calibri is a <em>humanist</em> sans-serif. Such typefaces tend to have open, rounded forms and generous apertures (look at the wide openings in letters like a, c, e, and s). Calibri takes that softness especially far: terminals are visibly rounded, and many letters appear almost handwritten, to the extent that its designer described its quality as “warm and soft.”</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/bd20435252554d90c4f09e14a8633c36.png">
<figcaption>Calibri specimen (Credit: Microsoft)</figcaption>
</figure>
<p>There’s nothing inherently wrong with this style, but one would hardly want an official document or legal contract to appear “warm and soft.” That is why I have long disliked Microsoft’s decision to make Calibri the default Office typeface starting with Office 2007. A default body typeface should be neutral and versatile, not exude a temperature. (Microsoft replaced Calibri with <a href="https://en.wikipedia.org/wiki/Aptos_%28typeface%29">Aptos</a> as the default in 2023, but inertia being what it is, Aptos still appears relatively rarely in the wild.)</p>
<p>To be fair, the State Department’s 2023 change was justified less as a matter of taste than as an accessibility and inclusion initiative. That is, to make documents easier to read for individuals with various physical and cognitive conditions. This goal is commendable in itself, but the means were, at best, loosely connected to the end, much like many inclusive measures that were once fashionable in U.S. politics and business in recent years.</p>
<p>First, Calibri was not designed with accessibility in mind. It was commissioned by Microsoft to promote its ClearType technology, with the design objective of appearing clear on the low-resolution displays of its time. This means it prioritizes smoothness under specific sub-pixel rendering techniques, rather than ensuring the glyphs are easy to tell apart. If accessibility were truly the goal, one might select a typeface created for that purpose. For example, Atkinson Hyperlegible addresses character differentiation by adding serifs, exaggerating shapes, and slanting strokes, making it legible even under low-vision conditions. In contrast, Calibri has no anti-ambiguity design: the uppercase <code>I</code> and lowercase <code>l</code> are nearly identical. So much for “accessibility.”</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/8a780297ed7d3d9af3a27977fbcab7f1.jpeg">
<figcaption>A publication set in Atkinson Hyperlegible (Credit: Studiokwi)</figcaption>
</figure>
<p>Furthermore, accessibility doesn’t depend solely on a document’s appearance but more on its internal structure and presentation mechanisms. For instance, the W3C’s <a href="https://www.w3.org/WAI/standards-guidelines/wcag/glance/">Web Content Accessibility Guidelines (WCAG)</a> state that accessible content should be perceivable, operable, understandable, and robust. This means that documents should have proper semantic structure (so tools like screen readers can interpret content correctly), support customizable layouts and fonts, and be compatible with various applications and devices. If these principles were met, the specific font used would matter little, as users can access the content with their preferred tools in their preferred manner. Conversely, if a document is technically crude, like a scanned PDF — as many official documents are — the use of an “inclusive” font is merely self-congratulatory.</p>
<p>If one insisted on a sans-serif for official writing, there are many better candidates than Calibri: Frutiger (common in airport wayfinding), Myriad (used by Apple for years), the cool and serious Univers (or a well-set Helvetica Neue), or contemporary neutral workhorses like Inter. If a “made in America” signal mattered, <a href="https://public-sans.digital.gov/">Public Sans</a> (funded under the 21st Century Integrated Digital Experience Act passed during Trump’s first term) and used by many U.S. government websites is also a good option.</p>
<figure>
<img src="https://static.hsu.cy/blog/2025/25ca7740c5eccb4aea031953d26ef037.png">
<figcaption>Calibri compared with several higher-regarded sans-serif typefaces</figcaption>
</figure>
<p>Therefore, Rubio’s criticism that the previous move was “cosmetic,” while being politically charged, isn’t entirely unfounded.</p>
<p>Taken together, the Department had previously pursued a defensible goal with a poorly matched design intervention and landed on an ill-fitting typeface. Now, for political motives, it has reversed that decision and returned to a bland, unremarkable default. Between the two, Times New Roman may be the lesser evil: it is more widely recognized, and it doesn’t clash with the official context as overtly as Calibri does. Still, Rubio, or whoever drafted the memo for him, could have been more candid. There was no need to dress up a political gesture with faux-erudite claims or to lavish praise on a mediocre typeface.</p>
<p>Because Times New Roman just will not make America great again.</p>


        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Non-Zero-Sum Games (323 pts)]]></title>
            <link>https://nonzerosum.games/</link>
            <guid>46432311</guid>
            <pubDate>Tue, 30 Dec 2025 11:42:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nonzerosum.games/">https://nonzerosum.games/</a>, See on <a href="https://news.ycombinator.com/item?id=46432311">Hacker News</a></p>
<div id="readability-page-1" class="page"><a name="Top"></a>
    
    

    <!-- For Facebook and LinkedIn -->
    <meta property="og:image" content="https://nonzerosum.games/Images/Social/alignment1.png">
    <meta property="og:title" content="NON-ZERO-SUM GAMES">
    <meta property="og:description" content="~ a world-help site ~">

    <!-- For Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:site" content="@NonZeroSumJames">
    <meta name="twitter:image" content="https://nonzerosum.games/Images/Social/alignment1.png">
    <meta name="twitter:title" content="NON-ZERO-SUM GAMES">
    <meta name="twitter:description" content="~ a world-help site ~">
    



    <!-- Linking to Menu.html -->
    
    

    <h3>WELCOME TO</h3>
    
    <h2>a <strong>world</strong>-help site &amp; <a href="https://pod.link/1810797958">podcast</a></h2>

    <p><img id="animation-frame" src="https://nonzerosum.games/Images/Content/Frames_Rabbits_0000.png" alt="Animation Frame">
    </p>
    
    <p>Hi, I'm Non-Zero-Sum <a href="https://nonzerosum.games/aboutme.html">James</a>, your companion on this exploration of <a href="https://nonzerosum.games/whatarenonzerosumgames.html">win-win games</a> and how they are essential for a better future. <a href="https://nonzerosum.games/blog.html">Each week</a> we'll explore a new aspect of <a href="https://nonzerosum.games/gametheory.html">game theory</a>, <a href="https://nonzerosum.games/map-moralphilosophy.html">moral philosophy</a>, <a href="https://nonzerosum.games/map-ethicaleconomics.html">ethical economics</a> and <a href="https://nonzerosum.games/map-ai.html">artificial intelligence</a>—looking to solve the complex problems we face in our world <em><strong>together</strong></em>.</p>

    <a name="WhatsNew"></a>
<!-- NEW Section -->
<h3>WHAT'S NEW?</h3>
<br>
    

<h3>WHAT'S NEXT?</h3>
<p>All the posts are connected through the lens of non-zero-sum games, but they fall into a few broad categories. You can start your journey with whatever appeals to you:</p>



<br>
<blockquote>
  "It is well to remember that the entire universe, <em><strong>with one trifling exception</strong></em>, is composed of others."<br>—<b>John Holmes</b>
</blockquote>



    
    
    
<p>Your thoughts and contributions are welcome. Share, debate, and co-create in the comments.</p>


    
    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nicolas Guillou, French ICC judge sanctioned by the US and “debanked” (353 pts)]]></title>
            <link>https://www.lemonde.fr/en/international/article/2025/11/19/nicolas-guillou-french-icc-judge-sanctioned-by-the-us-you-are-effectively-blacklisted-by-much-of-the-world-s-banking-system_6747628_4.html</link>
            <guid>46432057</guid>
            <pubDate>Tue, 30 Dec 2025 11:13:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lemonde.fr/en/international/article/2025/11/19/nicolas-guillou-french-icc-judge-sanctioned-by-the-us-you-are-effectively-blacklisted-by-much-of-the-world-s-banking-system_6747628_4.html">https://www.lemonde.fr/en/international/article/2025/11/19/nicolas-guillou-french-icc-judge-sanctioned-by-the-us-you-are-effectively-blacklisted-by-much-of-the-world-s-banking-system_6747628_4.html</a>, See on <a href="https://news.ycombinator.com/item?id=46432057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">                                         <section id="habillagepub">             <header> <div>     <ul>  <li>   <a href="https://www.lemonde.fr/en/international/" aria-label="World">    <span>World</span>    <span>World</span>   </a>   </li>  <li>   <a href="https://www.lemonde.fr/en/france/" aria-label="France">    <span>France</span>    <span>France</span>   </a>   </li>  </ul>          <div>     <p><span> Six judges and three prosecutors at the International Criminal Court have been sanctioned by the Trump administration. In an interview with Le Monde, Guillou discusses the impact of these measures on his work and daily life. </span> </p> </div>   <section>      <a href="https://www.lemonde.fr/international/article/2025/11/19/nicolas-guillou-juge-francais-de-la-cpi-sanctionne-par-les-etats-unis-face-aux-attaques-les-magistrats-de-la-cour-tiendront_6654016_3210.html" hreflang="fr">  <span>Lire en français</span>  </a>  </section>                         </div> </header>     <p data-tracking="article-status">          <span>Subscribers only</span> </p>       <section> <article>                   <figure> <img src="https://img.lemde.fr/2025/11/18/0/0/4000/2668/664/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg" alt="French judge Nicolas Guillou is sworn in at the headquarters of the International Criminal Court in The Hague, Netherlands, on March 8, 2024." srcset=" https://img.lemde.fr/2025/11/18/0/0/4000/2668/320/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 320w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/556/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 556w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/640/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 640w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/664/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 664w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/960/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 960w,   https://img.lemde.fr/2025/11/18/0/0/4000/2668/1112/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1112w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/1328/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1328w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/1668/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1668w,   https://img.lemde.fr/2025/11/18/0/0/4000/2668/1992/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 1992w,  https://img.lemde.fr/2025/11/18/0/0/4000/2668/2301/0/75/0/5093217_upload-1-yw9zacv3adsg-53574143067-98d5f27f98-4k.jpg 2301w,  ">     </figure>             <p>Nicolas Guillou, a French judge at the International Criminal Court (ICC), was sanctioned by the United States under a decision made by Donald Trump on August 20. The US Treasury Department justified the action, stating that "Guillou is being designated for ruling to authorize the ICC's issuance of arrest warrants for Israeli Prime Minister Benjamin Netanyahu and former Minister of Defense Yoav Gallant." Both men are indicted for war crimes and crimes against humanity for their roles in the destruction of the Gaza Strip.</p>                 <p>In total, six judges and three prosecutors from the ICC, including Chief Prosecutor Karim Khan, have been sanctioned by the US. In an interview with <em>Le Monde</em>, the judge explained the impact of these measures on his work and daily life. Without commenting on ongoing cases, he called on European authorities to activate a mechanism that could limit the impact of US restrictions.</p>           <h3>What is the purpose of the American sanctions mechanism?</h3>           <p>Initially, it was created to address human rights violations, counter terrorism and combat drug trafficking. Today, nearly 15,000 individuals are on the US sanctions list, mostly members of Al-Qaeda, the Islamic State group (IS), mafia organizations and the leaders of authoritarian regimes. Among this long list are nine ICC judges.</p>         <p><strong>You have 81.05% of this article left to read. The rest is for subscribers only.</strong></p>     </article>       </section>     </section>      <section id="js-capping" data-full="0" data-mini="0">  <section id="js-capping-content"> <p>Vous pouvez lire <i>Le Monde</i> sur un seul appareil à la fois</p>   <p>Ce message s’affichera sur l’autre appareil.</p> <a href="https://moncompte.lemonde.fr/" id="js-capping-yellow-button"> <span>Ajouter un compte</span> <span>Découvrir l’offre Famille</span> <span>Découvrir les offres multicomptes</span> </a> </section> <section id="js-capping-bottom">  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>En cliquant sur «&nbsp;&nbsp;» et en vous assurant que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</p> </li> <li> <p>Vous ignorez qui est l’autre personne ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous utilisez ce compte à plusieurs, <a href="https://moncompte.lemonde.fr/">créez un compte pour votre proche</a> (inclus dans votre abonnement). Puis connectez-vous chacun avec vos identifiants. <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ces identifiants ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous êtes bénéficiaire de l’abonnement, connectez-vous avec vos identifiants. <span>Si vous êtes 3 ou plus à utiliser l’abonnement, <a href="https://moncompte.lemonde.fr/">passez à l’offre Famille</a>.</span> <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ces identifiants ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous êtes bénéficiaire de l’abonnement, connectez-vous avec vos identifiants. <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ce compte ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>Si vous utilisez ce compte à plusieurs, <a href="https://moncompte.lemonde.fr/">passez à une offre multicomptes</a> pour faire profiter vos proches de votre abonnement avec leur propre compte. <span>Sinon, cliquez sur «&nbsp;&nbsp;» et assurez-vous que vous êtes la seule personne à consulter Le Monde avec ce compte.</span> </p> </li> <li> <p>Vous ignorez qui d’autre utilise ce compte ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> </ul>  <ul id="js-capping-faq"> <li> <p>Parce qu’une autre personne (ou vous) est en train de lire <i>Le Monde</i> avec ce compte sur un autre appareil.</p> <p>Vous ne pouvez lire <i>Le Monde</i> que sur <strong>un seul appareil</strong> à la fois (ordinateur, téléphone ou tablette).</p> </li> <li> <p>Comment ne plus voir ce message ?</p> <p>En cliquant sur «&nbsp;&nbsp;» et en vous assurant que vous êtes la seule personne à consulter <i>Le Monde</i> avec ce compte.</p> </li> <li> <p>Que se passera-t-il si vous continuez à lire ici ?</p> <p>Ce message s’affichera sur l’autre appareil. Ce dernier restera connecté avec ce compte.</p> </li> <li> <p>Y a-t-il d’autres limites ?</p> <p>Non. Vous pouvez vous connecter avec votre compte sur autant d’appareils que vous le souhaitez, mais en les utilisant à des moments différents.</p> </li> <li> <p>Vous ignorez qui est l’autre personne ?</p> <p>Nous vous conseillons de <a href="https://secure.lemonde.fr/sfuser/password/lost">modifier votre mot de passe</a>.</p> </li> </ul>  </section> </section> <section id="js-capping-old-article" data-full="0" data-mini="0"> <section id="js-capping-old-article-header"> <span></span> <p>Lecture restreinte</p> </section> <section id="js-capping-old-article-content"> <p>Votre abonnement n’autorise pas la lecture de cet article</p>  <p>Pour plus d’informations, merci de contacter notre service commercial.</p> </section> </section>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Netflix: Open Content (574 pts)]]></title>
            <link>https://opencontent.netflix.com/</link>
            <guid>46431560</guid>
            <pubDate>Tue, 30 Dec 2025 10:11:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opencontent.netflix.com/">https://opencontent.netflix.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46431560">Hacker News</a></p>
<div id="readability-page-1" class="page"><div jsname="ZBtY8b" tabindex="-1" dir="ltr"><div id="h.INITIAL_GRID.t5w57pd7xu1k" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><p role="main" tabindex="0"><h2 id="h.hao2e5ffslk1" dir="ltr"><span><strong>OPEN SOURCE CONTENT</strong></span></h2></p></div><div id="h.424e02f0723faf59_3" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><p dir="ltr">At Netflix, we are always exploring ways to make our content look and sound even better. To provide a common reference for prototyping bleeding-edge technologies within entertainment, technology and academic circles without compromising the security of our original and licensed programming, we've developed test titles oriented around documentary, live action, and animation.</p><p dir="ltr">Many open source assets are available from each project listed below. Our hope is this will encourage more experimentation, learning, and discovery that will benefit the whole industry. Many of these titles are also streaming on Netflix and are best enjoyed with any HDR configured device with your Premium subscription.</p><p dir="ltr">You can download single files directly through your web browser, but for large files and long frame sequences, you may wish to use command line tools. Guidance is included below. Ad Blockers may cause errors in your downloading process, so try turning it off if you have issues.</p><p dir="ltr">Our open source content is available under the <span><a href="https://www.google.com/url?q=https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby%2F4.0%2Flegalcode&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3DDX6ldzWtAO5wOs5KkByf" target="_blank">Creative Commons Attribution 4.0 International Public License</a></span>.</p></div><div id="h.5c2279c0a0764436_0" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><p dir="ltr">We’ve had great success remastering titles like <em>Knights of Sidonia</em>, <em>Flavours of Youth</em> and <em>Godzilla</em> from SDR to HDR over the last few years. But what if we increase the resolution and create anime with HDR in mind from conception? Working with Japan's Production I.G, we set out to create the first 4K HDR Atmos anime short and discover what would need to change in anime workflows.</p><p dir="ltr">Read more about <em>Sol Levante</em> in the Netflix <span><a href="https://www.google.com/url?q=https%3A%2F%2Fnetflixtechblog.com%2Fbringing-4k-and-hdr-to-anime-at-netflix-with-sol-levante-fa68105067cd&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw31OTOl32tb3gNn46s-zEgf" target="_blank">Tech Blog</a></span>.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DSolLevante%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1Ecn23QB92g0bq0JsDR4nW" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">HDR10 2020 ST2084 UHD 24fps 1000nit</p></li><li dir="ltr"><p dir="ltr">DolbyVision PQ/P3 D65 UHD 24fps IMF</p></li><li dir="ltr"><p dir="ltr">Atmos ADM and DAMF files</p></li><li dir="ltr"><p dir="ltr">ProTools Final Mix Session and Mastered Session</p></li><li dir="ltr"><p dir="ltr">4K HDR 16bit P3/PQ D65 Dolby Vision 2.9 XML + VDM</p></li><li dir="ltr"><p dir="ltr">Animatics, storyboard, selected After Effects projects, PSDs, and TGA in-betweens.</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F81017017&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3GbhByygE0zMS0-F55mxIK" target="_blank">Watch Sol Levante on Netflix</a></span></p></div><div tabindex="-1" id="h.5c2279c0a0764436_9"><div id="h.5c2279c0a0764436_17" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr">A live action test piece, <em>Nocturne</em> was shot at 120fps and sought to investigate footage with spatially complex scenes that mimic other professionally generated content to challenge codecs on both the encoding and decoding sides. This piece was also mastered in Dolby Vision and Atmos.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DNocturne%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0k-lgAAtZucT-XwDgOdI9L" target="_blank">Assets Available to Download</a></span>: </p><ul><li dir="ltr"><p dir="ltr">120fps Video Display Master</p></li><li dir="ltr"><p dir="ltr">60fps Video Display Master</p></li><li dir="ltr"><p dir="ltr">ADM WAV File</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80987558&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0tcEiSwiKx5uRsnzPRfo3k" target="_blank">Watch Nocturne on Netflix</a></span></p></div><div id="h.5c2279c0a0764436_67" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkdlK74wPldvSS2xbYVel6Apl4kP1UT5QDPyRg1d1aNwyt0zhNiQnCDsEttn9n9lKtB7247J5Woif1RSYOoZ_-G8hANMwqBTZ221ZES9SqATfZ1B4Wd0PovROH9nIzQ_dzqB5_gQ-xOJJF7rjDH7HZJYls6DWxaxKsKKyT5eq8GUL5Kc9tJ39Fm4YFOnyLVSGLDLUMs2lMojMkc=w1280" role="img"></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_18"><div id="h.5c2279c0a0764436_68" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkck_Ug0KB82ES0N1B_6DNoJPsVHZzsLM-uJnD3n1rXGwL8NGk8RxvE38B6KkyP_IJKqID1uNLTMobwRUCYAJdaiHGG9KZSvYTyS9__B5hDwgw86ZkOcL0KLAD114XiILiXNUlL865RPtnqd1hbj1RlSNQRpO9UqqNcq0jCkRIt3TEYOcmhL0fUcPMBVORhVY-lAhcLPIsCXSIA=w1280" role="img"></p></div><div id="h.5c2279c0a0764436_26" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr">Upon noticing the contrast in dark shadows against the bright sky and sparks from a welder working on a new Netflix building, the encoding team acquired a Sony PMW-F55 and the AXS-R5 RAW recorder to shoot 16-bit RAW SQ and produce <em>Sparks</em>.</p><p dir="ltr">Sparks was shot 4K HFR and finished at 4000 nits using ACES. Read more about Sparks on the <span><a href="https://www.google.com/url?q=https%3A%2F%2Fnetflixtechblog.com%2Fengineers-making-movies-aka-open-source-test-content-f21363ea3781&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0FxnUO5CAJaNyyZfMyk8uR" target="_blank">Netflix Tech Blog</a></span>.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3Dsparks%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1JxkoD8D89veBk8dyGf9Pb" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">4K P3 PQ 4000nits Dolby Vision IMF</p></li><li dir="ltr"><p dir="ltr">HDR10 1000nit PQ 2020 image sequence</p></li><li dir="ltr"><p dir="ltr">4K P3/PQ 4000nits EXR</p></li><li dir="ltr"><p dir="ltr">4K P3/PQ 4000nits EXR Dolby Vision metadata</p></li><li dir="ltr"><p dir="ltr">ACES 59.94fps image sequence</p></li><li dir="ltr"><p dir="ltr">Original Camera Files</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80156943&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1xfgRA8JGGKutKDQwWWUW_" target="_blank">Watch Sparks on Netflix</a></span></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_27"><div id="h.5c2279c0a0764436_35" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span>Following the industry shift from “more pixels” to “better pixels,” we produced </span><span><em>Meridian, </em></span><span>our first test title to tell a story. </span><span><em>Meridian </em></span><span>was mastered in Dolby Vision high dynamic range (HDR) with a P3-D65 color space and PQ (perceptual quantizer) transfer function. It also contained a Dolby Atmos mix, multiple language tracks, and subtitles. You can read more about Meridian </span><span><a href="http://www.google.com/url?q=http%3A%2F%2Fvariety.com%2F2016%2Fdigital%2Fnews%2Fnetflix-meridian-imf-tools-open-source-1201859416%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw35I1RorUVcGxJ-b7K7k1pK" target="_blank">on Variety</a></span>.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DMeridian%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1UTIRtEMMmvGHiGd9cjiiE" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">UHD IMF</p></li><li dir="ltr"><p dir="ltr">Zipped UHD VDM</p></li><li dir="ltr"><p dir="ltr">UHD 4k 5994 HDR P3/PQ (mp4)</p></li><li dir="ltr"><p dir="ltr">UHD VDM Image Sequence</p></li><li dir="ltr"><p dir="ltr">Dolby Atmos Metadata File</p></li><li dir="ltr"><p dir="ltr">Atmos BWAV ADM</p></li><li dir="ltr"><p dir="ltr">TIFF Sequence</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80141336&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1XMqFuLvHCLgfh-c0dvqjT" target="_blank">Watch Meridian on Netflix</a></span></p></div><div id="h.5c2279c0a0764436_69" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkfpn_aZrb3HH-13XDuj1rQ2Gbp7QYyDeWJlhqw6Ham7o5KtG9_5mAAVjO5xVANNczBNLkyN3ruyaamztFmD3xwOX9cFmpdi4Ym_4vyzxs1HGbgUaaAwGoPaQmbTCEXWKXiFLVnl7S0E7RWH4C_XGmEf5nwkJzroCtyQQZOEQ2CMA8LzmjOsfrLq4Dv1-o3YZw8MXGI9PfknE14=w1280" role="img"></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_36"><div id="h.5c2279c0a0764436_70" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkctwJ-90C2LUXO20Q5HTyv2-cXWL8N9f66xpalqKpEgBTAoX9WYTEcMq7MYicWjjiQAt_gnU49PSa8YbhaljoOVfKn1SwTPmqa5groflbuxrGFavzMk3E9AEBXjQ-D4MfaJCNAUmJIGs6j6bDejYV9X48dgk1TswGFD9QBKMsrkRvz6sk6D2aNjwBgE94wROrhLGLgMzu5P2qk=w1280" role="img"></p></div><div id="h.5c2279c0a0764436_44" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span>We felt a need to include animated content in our test title library, so we partnered with Blender Foundation and Fotokem’s Keep Me Posted to re-grade Cosmos Laundromat, an award-winning short film in Dolby Vision HDR.</span></p><p dir="ltr"><span>Cosmos Laundromat is an Open Movie project created by </span><span><a href="https://www.google.com/url?q=https%3A%2F%2Fstudio.blender.org%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0ECNq0x9oqXh1tiiKD9h2x" target="_blank">Blender Studio</a></span><span> and directed by Mathieu Auvray. The film was made entirely in Blender, an open source 3D content creation tool. </span></p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DCosmosLaundromat%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw1-fXfugSAUbfB6iedsZtZP" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">2k 24p HDR P3/PQ (mp4)</p></li><li dir="ltr"><p dir="ltr">EXR to TIFF Nuke Script File</p></li><li dir="ltr"><p dir="ltr">EXR Sequence</p></li></ul><p dir="ltr"><span><a href="https://www.google.com/url?q=https%3A%2F%2Fwww.netflix.com%2Fwatch%2F80114804&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw0hEUGziup-TVSYasKgibK4" target="_blank">Watch Cosmos Laundromat on Netflix</a></span></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_45"><div id="h.5c2279c0a0764436_53" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span><em>Chimera</em></span><span> is technically comparable to El Fuente, but its scenes are more representative of existing titles on Netflix. The dinner scene attempts to recreate a codec-challenging sequence from </span><span><em>House of Cards</em></span><span>.</span></p><p dir="ltr">Prior to <em>Chimera</em>, there wasn’t any open source 4K test material that exhibited real world live action material.</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DChimera%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw2UBRKw_TqKUFN3-uRCzIEg" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">DCI 4k 2398p HDR P3/PQ</p></li><li dir="ltr"><p dir="ltr">DCI 4k 5994p HDR P3/PQ</p></li><li dir="ltr"><p dir="ltr">TIFF Sequence: DCI 4k 2398p</p></li><li dir="ltr"><p dir="ltr">TIFF Sequence: DCI 4k 5994p</p></li></ul></div><div id="h.5c2279c0a0764436_71" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkdxK4hymyHZSA6I1FVqikW6q33HgsCj0IkhoWBRbTqOb4zLmEXkAj117Pw3gma9zA6E6zMu2Pbe5_kpQP0By-aBQwdOTWZOfo4swXG_JIQjzNeT6xVX24Rc2y7ONRXOwzPfzBxBg3HyJx1_fvvS7ViWfLOPkRZDLd74EqLLzkxHJYyDOseAdHgz1uav09jIbDBquJhzU_3oRoU=w1280" role="img"></p></div></div><div tabindex="-1" id="h.5c2279c0a0764436_54"><div id="h.5c2279c0a0764436_72" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p><img src="https://lh3.googleusercontent.com/sitesv/AAzXCkfT0CozN_IwZyFcA1aKG6oS2FRu3yH4qcH7Tk6JNIy3eq_L_IlimCD2kwtiifDqPNSuEWEhaJWQhC12UB35DfxN3ggQcwN1Nga5sgK6lv4Vbz0ND_jXbA7DJUIAGyCfL3ByPSMY_y2Xk0UzFDF_bwvO8ES-tK6XxM9z3Rsf8YjGpEOQL5KoKAs-2la0rJitXTGau3JBoLz4ceM=w1280" role="img"></p></div><div id="h.5c2279c0a0764436_62" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId"><p dir="ltr"><span>As the demand for more pixels increased, so did appropriate test content. Documentary short </span><span><em>El Fuente </em></span><span>was shot in Mexico by a local DP at 4K at both 48 and 59.94 fps to meet increasing resolution and frame rate requirements. </span></p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3DElFuente%2F&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3CJ0dsnigs5uzK9PX3ZT30" target="_blank">Assets Available to Download</a></span>:</p><ul><li dir="ltr"><p dir="ltr">Boat: 4096x2160 60fps 10bit 420 (YUV4Mpeg format)</p></li><li dir="ltr"><p dir="ltr">FoodMarket: 4096x2160 60fps 10bit 420 (YUV4Mpeg format)</p></li></ul></div></div><div id="h.424e02f0723faf59_7" jscontroller="sGwD4d" jsaction="zXBUYb:zTPCnb;zQF9Uc:Qxe3nd;" jsname="F57UId" tabindex="-1"><h2 id="h.ybuehwfpw41c_l" dir="ltr" tabindex="-1"></h2><p dir="ltr">The assets on this page can be browsed on the Netflix OpenContent bucket here:</p><p dir="ltr"><span><a href="http://www.google.com/url?q=http%3A%2F%2Fdownload.opencontent.netflix.com.s3.amazonaws.com%2Findex.html%3Fprefix%3D&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw13gxO2u8ohKDF8n8ciAAHN" target="_blank">http://download.opencontent.netflix.com/</a></span></p><p dir="ltr">You can download single files directly through your web browser on each page, but for large files and long frame sequences, you may wish to use command line tools such as aws cli. <span><a href="https://www.google.com/url?q=https%3A%2F%2Fdocs.aws.amazon.com%2Fcli%2Flatest%2Fuserguide%2Finstalling.html&amp;sa=D&amp;sntz=1&amp;usg=AOvVaw3PGFJ8r8nYfq7XpBLgMOdA" target="_blank">Instructions are posted on their website</a></span>. After installation, you should be able to download the public assets. Try running these sample commands. If the download is interrupted, you can run the same command immediately and aws cli will resume the download where it left off.</p><p dir="ltr">Download a single file (0.7 kB):</p><p dir="ltr">Usage:   aws s3 cp --no-sign-request &lt;s3 URI&gt; &lt;local destination&gt;</p><p dir="ltr">Example: aws s3 cp --no-sign-request s3://download.opencontent.netflix.com/TechblogAssets/Sparks/sparks_license.txt .</p><p dir="ltr">Sync entire directory (1406.1 MB):</p><p dir="ltr">Usage:   aws s3 sync --no-sign-request &lt;s3 URI&gt; &lt;local destination&gt;</p><p dir="ltr">Example: aws s3 sync --no-sign-request s3://download.opencontent.netflix.com/TechblogAssets/CosmosLaundromat/encodes/ .</p><p dir="ltr">The download links on this page will bring you to the root directory for that title's assets. You may need to navigate around to find the folder you want.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HSBC blocks its app due to F-Droid-installed Bitwarden (231 pts)]]></title>
            <link>https://mastodon.neilzone.co.uk/@neil/115807834298031971</link>
            <guid>46431453</guid>
            <pubDate>Tue, 30 Dec 2025 09:57:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mastodon.neilzone.co.uk/@neil/115807834298031971">https://mastodon.neilzone.co.uk/@neil/115807834298031971</a>, See on <a href="https://news.ycombinator.com/item?id=46431453">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Go Away Python (319 pts)]]></title>
            <link>https://lorentz.app/blog-item.html?id=go-shebang</link>
            <guid>46431028</guid>
            <pubDate>Tue, 30 Dec 2025 08:50:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lorentz.app/blog-item.html?id=go-shebang">https://lorentz.app/blog-item.html?id=go-shebang</a>, See on <a href="https://news.ycombinator.com/item?id=46431028">Hacker News</a></p>
Couldn't get https://lorentz.app/blog-item.html?id=go-shebang: Error: getaddrinfo ENOTFOUND lorentz.app]]></description>
        </item>
        <item>
            <title><![CDATA[Charm Ruby – Glamorous Terminal Libraries for Ruby (126 pts)]]></title>
            <link>https://charm-ruby.dev/</link>
            <guid>46430558</guid>
            <pubDate>Tue, 30 Dec 2025 07:36:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://charm-ruby.dev/">https://charm-ruby.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=46430558">Hacker News</a></p>
<div id="readability-page-1" class="page">
  <nav>
    
  </nav>

  <header>
    
    <div>
      <p><a href="https://marcoroth.dev/posts/glamorous-christmas" target="_blank" rel="noopener">
        <span>NEW</span>
        <span><span>Read the Introduction → </span>A Glamorous Christmas</span>
      </a></p><div>
<pre> ██████╗██╗  ██╗ █████╗ ██████╗ ███╗   ███╗
██╔════╝██║  ██║██╔══██╗██╔══██╗████╗ ████║
██║     ███████║███████║██████╔╝██╔████╔██║
██║     ██╔══██║██╔══██║██╔══██╗██║╚██╔╝██║
╚██████╗██║  ██║██║  ██║██║  ██║██║ ╚═╝ ██║
       ╚═════╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝  <span>RUBY</span>
</pre>
      </div>
      <div><p>
        Ruby bindings and ports of the beloved <a href="https://charm.sh/" target="_blank" rel="noopener">Charm</a> terminal libraries.</p><p>
        <span>Build glamorous TUIs, style terminal output, create beautiful forms,<br>
        and make your Ruby CLIs sparkle.</span></p></div>
      <p><code>gem install bubbletea lipgloss bubbles glamour</code>
      </p>
      
    </div>
  </header>

  <div id="libraries">
      <h2>The Library Collection</h2>

      <div>
        <h3>Build Terminal Apps</h3>
        <div>

          <article>
            <p>🫧</p>
            <h4>Bubbletea</h4>
            <p>Build terminal UIs from the future, today.</p>
            <p>A powerful TUI framework using the Elm Architecture. Handle keyboard, mouse, and window events with commands for side effects.</p>
            <p><code>gem "bubbletea"</code>
            </p>
            
          </article>

          <article>
            <p>🧩</p>
            <h4>Bubbles</h4>
            <p>The Bubble Tea component toolkit.</p>
            <p>Pre-built components: Spinner, Progress, Timer, TextInput, TextArea, Viewport, List, Table, FilePicker, and more.</p>
            <p><code>gem "bubbles"</code>
            </p>
            
          </article>

          <article>
            <p>🔲</p>
            <h4>Bubblezone</h4>
            <p>Track clickable regions in terminal UIs.</p>
            <p>Mark zones with IDs, check mouse coordinates, and handle click events in your Bubble Tea applications.</p>
            <p><code>gem "bubblezone"</code>
            </p>
            
          </article>

        </div>
      </div>

      <div>
        <h3>Style Your Output</h3>
        <div>

          <article>
            <p>💄</p>
            <h4>Lipgloss</h4>
            <p>Your terminal style and layout toolkit.</p>
            <p>Borders, padding, margins, colors (hex, ANSI, adaptive), tables, lists, trees, and layout utilities.</p>
            <p><code>gem "lipgloss"</code>
            </p>
            
          </article>

          <article>
            <p>✨</p>
            <h4>Glamour</h4>
            <p>The stylesheet-driven markdown renderer.</p>
            <p>Render markdown in your terminal with built-in themes (dark, light, dracula), custom styles via DSL, and emoji support.</p>
            <p><code>gem "glamour"</code>
            </p>
            
          </article>

          <article>
            <p>📊</p>
            <h4>NTCharts</h4>
            <p>Terminal charts for beautiful data viz.</p>
            <p>Sparkline, Barchart, LineChart, WaveLineChart, StreamLineChart (real-time), and TimeSeriesLineChart.</p>
            <p><code>gem "ntcharts"</code>
            </p>
            
          </article>

        </div>
      </div>

      <div>
        <h3>Interactive Tools</h3>
        <div>

          <article>
            <p>🤔</p>
            <h4>Huh?</h4>
            <p>Simple, powerful forms in the terminal.</p>
            <p>Input, Text, Select, MultiSelect, Confirm, Note, Spinner. Built-in validation, themes, and a block-based DSL.</p>
            <p><code>gem "huh", github: "marcoroth/huh-ruby"</code>
            </p>
            
          </article>

          <article>
            <p>🍬</p>
            <h4>Gum</h4>
            <p>A tool for glamorous shell scripts.</p>
            <p>Ruby wrapper with idiomatic API: input, write, choose, filter, confirm, file, pager, spin, style, format. Bundles the gum binary.</p>
            <p><code>gem "gum"</code>
            </p>
            
          </article>

          <article>
            <p>🎵</p>
            <h4>Harmonica</h4>
            <p>A physics-based animation library.</p>
            <p>Damped harmonic oscillator (Spring), projectile motion, Point &amp; Vector math, and frame rate helpers for smooth UI animations.</p>
            <p><code>gem "harmonica"</code>
            </p>
            
          </article>

        </div>
      </div>

    </div>

  <div id="getting-started">
      <h2>Getting Started</h2>

      <div>
        <div>
          <h3><span>##</span> Installation</h3>
          <p>Add the gems you need to your Gemfile:</p>
          <div>
            <pre><code><span># Gemfile</span>

<span># Core TUI framework</span>
gem <span>"bubbletea"</span>

<span># Styling</span>
gem <span>"lipgloss"</span>

<span># Components</span>
gem <span>"bubbles"</span>

<span># Markdown rendering</span>
gem <span>"glamour"</span>

<span># Shell scripts</span>
gem <span>"gum"</span>

<span># Animations</span>
gem <span>"harmonica"</span>

<span># Charts</span>
gem <span>"ntcharts"</span>

<span># Mouse tracking</span>
gem <span>"bubblezone"</span></code></pre>
          </div>

        </div>

        <div>
          <h3><span>##</span> Your First TUI</h3>
          <p>A simple Bubbletea app with Lipgloss styling:</p>
          <div>
            <pre><code><span>require</span> <span>"bubbletea"</span>
<span>require</span> <span>"lipgloss"</span>

<span>class</span> <span>HelloWorld</span>
  <span>include</span> <span>Bubbletea::Model</span>

  <span>def</span> <span>initialize</span>
    <span>@style</span> = <span>Lipgloss::Style</span>.new
      .border(<span>:rounded</span>)
      .border_foreground(<span>"#7D56F4"</span>)
      .padding(<span>1</span>, <span>2</span>)
  <span>end</span>

  <span>def</span> <span>init</span> = [<span>self</span>, <span>nil</span>]

  <span>def</span> <span>update</span>(message)
    <span>case</span> message
    <span>when</span> <span>Bubbletea::KeyMessage</span>
      <span>return</span> [<span>self</span>, <span>Bubbletea</span>.quit] <span>if</span> message.to_s == <span>"q"</span>
    <span>end</span>

    [<span>self</span>, <span>nil</span>]
  <span>end</span>

  <span>def</span> <span>view</span>
    <span>@style</span>.render(<span>"Hello, Charm Ruby!\n\nPress q to quit"</span>)
  <span>end</span>
<span>end</span>

<span>Bubbletea</span>.run(<span>HelloWorld</span>.new)</code></pre>
          </div>
        </div>
      </div>
    </div>

  <div id="examples">
      <h2>Examples</h2>

      <div>

        <div>
          <h4>Counter with Styling</h4>
          <div>
            <pre><code><span>require</span> <span>"bubbletea"</span>
<span>require</span> <span>"lipgloss"</span>

<span>class</span> <span>Counter</span>
  <span>include</span> <span>Bubbletea::Model</span>

  <span>def</span> <span>initialize</span>
    <span>@count</span> = <span>0</span>
    <span>@style</span> = <span>Lipgloss::Style</span>.new
      .bold(<span>true</span>)
      .foreground(<span>"#FF6B6B"</span>)
  <span>end</span>

  <span>def</span> <span>update</span>(message)
    <span>case</span> message
    <span>when</span> <span>Bubbletea::KeyMessage</span>
      <span>case</span> message.to_s
      <span>when</span> <span>"q"</span>, <span>"ctrl+c"</span>
        <span>return</span> [<span>self</span>, <span>Bubbletea</span>.quit]
      <span>when</span> <span>"up"</span> <span>then</span> <span>@count</span> += <span>1</span>
      <span>when</span> <span>"down"</span> <span>then</span> <span>@count</span> -= <span>1</span>
      <span>end</span>
    <span>end</span>

    [<span>self</span>, <span>nil</span>]
  <span>end</span>

  <span>def</span> <span>view</span>
    <span>@style</span>.render(<span>"Count: </span>#{<span>@count</span>}<span>\n\nPress q to quit"</span>)
  <span>end</span>
<span>end</span>

<span>Bubbletea</span>.run(<span>Counter</span>.new)</code></pre>
          </div>
        </div>

        <div>
          <h4>Spinner Component</h4>
          <div>
            <pre><code><span>require</span> <span>"bubbletea"</span>
<span>require</span> <span>"bubbles"</span>

<span>class</span> <span>LoadingApp</span>
  <span>include</span> <span>Bubbletea::Model</span>

  <span>def</span> <span>initialize</span>
    <span>@spinner</span> = <span>Bubbles::Spinner</span>.new
  <span>end</span>

  <span>def</span> <span>init</span>
    [<span>self</span>, <span>@spinner</span>.tick]
  <span>end</span>

  <span>def</span> <span>update</span>(message)
    <span>case</span> message
    <span>when</span> <span>Bubbletea::KeyMessage</span>
      <span>case</span> message.to_s
      <span>when</span> <span>"q"</span>, <span>"ctrl+c"</span>
        <span>return</span> [<span>self</span>, <span>Bubbletea</span>.quit]
      <span>end</span>
    <span>end</span>

    <span>@spinner</span>, command = <span>@spinner</span>.update(message)

    [<span>self</span>, command]
  <span>end</span>

  <span>def</span> <span>view</span>
    <span>"</span>#{<span>@spinner</span>.view}<span> Loading..."</span>
  <span>end</span>
<span>end</span>

<span>Bubbletea</span>.run(<span>LoadingApp</span>.new)</code></pre>
          </div>
        </div>

        <div>
          <h4>Terminal Form</h4>
          <div>
            <pre><code><span>require</span> <span>"huh"</span>

form = <span>Huh</span>.form(
  <span>Huh</span>.group(
    <span>Huh</span>.input
      .key(<span>"name"</span>)
      .title(<span>"What's your name?"</span>)
      .placeholder(<span>"Enter name..."</span>),

    <span>Huh</span>.select
      .key(<span>"color"</span>)
      .title(<span>"Favorite color?"</span>)
      .options(*<span>Huh</span>.options(
        <span>"Red"</span>, <span>"Green"</span>, <span>"Blue"</span>
      ))
  )
).with_theme(<span>Huh::Themes</span>.charm)

form.run

puts <span>"Hello, </span>#{form[<span>"name"</span>]}<span>!"</span></code></pre>
          </div>
        </div>

        <div>
          <h4>Styled Table</h4>
          <div>
            <pre><code><span>require</span> <span>"lipgloss"</span>

headers = [<span>"Name"</span>, <span>"Language"</span>, <span>"Stars"</span>]

rows = [
  [<span>"bubbletea"</span>, <span>"Ruby"</span>, <span>"✨"</span>],
  [<span>"lipgloss"</span>, <span>"Ruby"</span>, <span>"💄"</span>],
  [<span>"glamour"</span>, <span>"Ruby"</span>, <span>"✨"</span>]
]

table = <span>Lipgloss::Table</span>.new
  .headers(headers)
  .rows(rows)
  .border(<span>:rounded</span>)

puts table.render</code></pre>
          </div>
        </div>

        <div>
          <h4>Markdown Rendering</h4>
          <div>
            <pre><code><span>require</span> <span>"glamour"</span>

markdown = <span>&lt;&lt;~MD
  # Hello Glamour :sparkles:

  This is **bold** and *italic*.

  - Item one
  - Item two
  - Item three

  ```ruby
  puts "Hello, World!"
  ```
MD</span>

puts <span>Glamour</span>.render(markdown,
  style: <span>"dark"</span>,
  width: <span>80</span>,
  emoji: <span>true</span>
)</code></pre>
          </div>
        </div>

        <div>
          <h4>Real-time Charts</h4>
          <div>
            <pre><code><span>require</span> <span>"ntcharts"</span>

chart = <span>Ntcharts::Streamlinechart</span>.new(<span>60</span>, <span>12</span>)

loop <span>do</span>
  chart.push(<span>Math</span>.sin(<span>Time</span>.now.to_f) * <span>4</span> + <span>5</span>)

  print <span>"\e[H\e[2J"</span>
  puts chart.render
  sleep <span>0.1</span>
<span>end</span></code></pre>
          </div>
        </div>

      </div>
    </div>

  <div>
      <h2>The Ecosystem</h2>
      <div>
        <p>
          These Ruby gems are ports and bindings of the original Go libraries from
          <a href="https://charm.sh/" target="_blank" rel="noopener">Charm</a>.
          They bring the same elegant APIs and glamorous terminal experiences to Ruby developers.
        </p>
        <p>
          Some gems use native C extensions that link to compiled Go shared libraries,
          while others are pure Ruby implementations.
        </p>
        <p><span>Ruby 3.2+</span>
          <span>MIT License</span>
        </p>
      </div>
    </div>

  



</div>]]></description>
        </item>
    </channel>
</rss>