<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 11 May 2025 13:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[One-Click RCE in Asus's Preinstalled Driver Software (326 pts)]]></title>
            <link>https://mrbruh.com/asusdriverhub/</link>
            <guid>43951588</guid>
            <pubDate>Sun, 11 May 2025 05:11:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mrbruh.com/asusdriverhub/">https://mrbruh.com/asusdriverhub/</a>, See on <a href="https://news.ycombinator.com/item?id=43951588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <h2 id="one-click-rce-in-asuss-preinstalled-driver-software">One-Click RCE in ASUS’s Preinstalled Driver Software</h2>
<h2 id="introduction">Introduction</h2>
<p>This story begins with a conversation about new PC parts.</p>
<p><img src="https://mrbruh.com/asusdriverhub/dms.avif" alt="dms.avif"></p>
<p>After ignoring the advice from my friend, I bought a new ASUS motherboard for my PC. I was a little concerned about having a BIOS that would by default silently install software into my OS in the background. But it could be turned off so I figured I would just do that.</p>
<p><img src="https://mrbruh.com/asusdriverhub/bios.avif" alt="bios.avif"></p>
<p>Immediately after logging into Windows I was hit with a notification requesting admin permissions to complete the installation of ASUS DriverHub, because I forgot to change the BIOS option. Since I needed to get a WiFi driver for the motherboard anyway, I got curious and installed it.</p>
<p><img src="https://mrbruh.com/asusdriverhub/admin_prompt.avif" alt="admin_prompt.avif"></p>
<p><em>I don’t have a screenshot of DriverHub but it showed a popup exactly like this in the bottom-right of my screen</em></p>
<h2 id="driverhub">DriverHub</h2>
<p><img src="https://mrbruh.com/asusdriverhub/driverhub_ui.avif" alt="driverhub_ui.avif"></p>
<p>DriverHub is an interesting piece of driver software because it doesn’t have any GUI. Instead it’s just a background process that communicates with the website <a href="https://driverhub.asus.com/">driverhub.asus.com</a> and tells you what drivers to install for your system and which ones need updating. Naturally I wanted to know more about how this website knew what drivers my system needed and how it was installing them, so I cracked open the Firefox network tab.</p>
<p>As I expected, the website uses RPC to talk to the background process running on my system. This is where the background process hosts an HTTP or Websocket service locally which a website or service can connect to by sending an API request to <code>127.0.0.1</code> on a predefined port, in this case <code>53000</code>.</p>
<p>Right about now my elite hacker senses started tingling.</p>
<p><img src="https://media1.tenor.com/m/9Z4aF3ksVH0AAAAd/joey-gibson.gif" alt="joey-gibson.gif"></p>
<p>This is a very sketchy way to design driver management software. If the RPC isn’t properly secured, it could be weaponized by an attacker to install malicious applications.</p>
<h2 id="finding-the-vulnerability">Finding the Vulnerability</h2>
<p>The next step was to see if I could call the RPC from any website, this was replicated by copying the request from my browser as a curl command and pasting it into my terminal.</p>
<p><img src="https://mrbruh.com/asusdriverhub/copyascurl.avif" alt="copyascurl.avif"></p>
<p>After fiddling with variations of the command for a while my assumptions were confirmed. DriverHub only responded to requests with the origin header set to “driverhub.asus.com”. So at least this software wasn’t completely busted and evil hackers can’t just send requests to DriverHub willy-nilly.</p>
<p>However I wasn’t done yet, presumably the program checks if the origin is <code>driverhub.asus.hub</code> and if so it’d accept RPC request. What I did next was see if the program did a direct comparison like <code>origin == driverhub.asus.hub</code> or if it was a wildcard match such as <code>origin.includes("driverhub.asus.com")</code>.</p>
<p>When I switched the origin to <code>driverhub.asus.com.mrbruh.com</code>, <strong>it allowed my request.</strong></p>
<p>It was obvious now there was a serious threat. The next step was to determine how much damage was possible.</p>
<h2 id="the-extent-of-the-damage">The Extent of the Damage</h2>
<p>By trawling through the Javascript on the website, and about 700k lines of decompiled code that the exe produced, I managed to create a list of callable endpoints including some unused ones sitting in the exe.</p>
<ul>
<li>
<p><strong>Initialize</strong>
This command is used by the website to check if the software is installed and returns basic installation information.</p>
</li>
<li>
<p><strong>DeviceInfo</strong>
This returns all installed ASUS’s software, all installed .sys drivers, all your hardware components, and your MAC address.</p>
</li>
<li>
<p><strong>Reboot</strong>
This reboots the target device immediately without confirmation.</p>
</li>
</ul>
<video width="100%" controls="">
    <source src="https://mrbruh.com/asusdriverhub/reboot_poc.mp4">
    Your browser does not support the video lmao
</video>
<ul>
<li>
<p><strong>Log</strong>
This returns a zipped copy of all of DriverHub’s logs.</p>
</li>
<li>
<p><strong>InstallApp</strong>
This installs an app or driver by its ID. The ID’s for all the apps are hard coded in an XML file which is provided by the DriverHub installer.</p>
</li>
<li>
<p><strong>UpdateApp</strong>
This self-updates DriverHub using a provided file URL to download and run.</p>
</li>
</ul>
<h2 id="achieving-rce">Achieving RCE</h2>
<p>I became fixated on the UpdateApp endpoint for obvious reasons. So I spent a few hours exploring the code in ghidra and hitting it with various curl requests to learn the intricacies of how it behaves.</p>
<p>A request to the endpoint looks like this:</p>
<div><pre tabindex="0"><code data-lang="shell"><span><span>curl <span>"http://127.0.0.1:53000/asus/v1.0/UpdateApp"</span> -X POST --data-raw <span>'{"List": [{"Url": "https://driverhub.asus.com/&lt;app.exe&gt;"}]}'</span>
</span></span></code></pre></div><p>Here were the observations I had made about the UpdateApp function at that point.</p>
<ul>
<li>The “Url” parameter must contain “.asus.com” but unlike the RPC origin check, it allows stupidity like <code>example.com/payload.exe?foo=.asus.com</code></li>
<li>It saves the file with the filename specified at the end of the URL.</li>
<li>Any file with any extension can be downloaded</li>
<li>If the file is an executable signed by ASUS it will be automatically executed with admin permissions</li>
<li>It will run <em>any</em> executable signed by ASUS, not just a DriverHub installer.</li>
<li><strong>If a downloaded file fails the signing check, it does not get deleted.</strong></li>
</ul>
<p>When I learned that DriverHub validates the signature of the executable I suspected an RCE may no longer be possible, however I soldiered on regardless.</p>
<p>My first thought was potentially a <em>timing attack</em>, where I tell DriverHub to install a valid executable, and after it validates the signature, but just before it installs the exe, I swap it out with a malicious executable. I theorized this could be possible by making two UpdateApp requests in parallel, with the malicious update being just after the legitimate one.</p>
<p>However timing attacks need to be extremely precise and having that timing being affected by files needing to be downloaded made it a very unreliable option. Given that, I decided to take a step back and think if there were any other options.</p>
<p>Eventually I was led back to the standalone WiFi driver I was going to install all along. The driver was distributed in the following zip file.</p>
<p><img src="https://mrbruh.com/asusdriverhub/zip_contents.avif" alt="Zip Contents"></p>
<p>The files of importance here are the <code>AsusSetup.exe</code>, <code>AsusSetup.ini</code> and <code>SilentInstall.cmd</code>. When executing AsusSetup.exe it first reads from AsusSetup.ini, which contains metadata about the driver. I took interest in a property in the file: <code>SilentInstallRun</code>.</p>
<p>When you double-click AsusSetup.exe it launches a simple gui installer thingy. But if you run AsusSetup.exe with the <code>-s</code> flag (DriverHub calls it using this to do a silent install), it will execute <em>whatever’s</em> specified in SilentInstallRun. In this case the ini file specifies a cmd script that performs an automated headless install of the driver, <strong>but it could run anything</strong>.</p>
<h4 id="here-is-the-completed-exploit-chain">Here is the completed exploit chain</h4>
<ol>
<li>
<p>Visit website with <code>driverhub.asus.com.*</code> subdomain</p>
</li>
<li>
<p>Site makes UpdateApp request for PoC executable “calc.exe”</p>
<blockquote>
<p>“calc.exe” will be downloaded, fail the signature check and not be executed</p>
</blockquote>
</li>
<li>
<p>Site makes UpdateApp request for custom AsusSetup.ini</p>
<blockquote>
<p>This will also be downloaded and not executed</p>
</blockquote>
</li>
</ol>
<div><pre tabindex="0"><code data-lang="ini"><span><span>   <span>[InstallInfo]</span>
</span></span><span><span>   <span>SilentInstallPath</span><span>=</span><span>.\
</span></span></span><span><span><span>   SilentInstallRun=calc.exe</span>
</span></span></code></pre></div><ol start="4">
<li>
<p>Site makes UpdateApp request for signed ASUS binary “AsusSetup.exe”</p>
<blockquote>
<p>This will be downloaded and executed with admin permissions and does a silent install using <code>-s</code>, which will cause it to read the AsusSetup.ini file and run “calc.exe” specified in “SilentInstallRun” also <strong>with admin permissions</strong></p>
</blockquote>
</li>
</ol>
<p>PoC in action:
<video width="100%" controls="">
<source src="https://mrbruh.com/asusdriverhub/website_poc.mp4">
Your browser does not support the video lmao
</video></p>
<h2 id="reporting-timeline-ddmmyyyy">Reporting Timeline (DD/MM/YYYY)</h2>
<ul>
<li>07/04/2025 - Found the initial vulnerability</li>
<li>08/04/2025 - Escalated the vulnerability to RCE</li>
<li>08/04/2025 - Reported the vulnerability</li>
<li>09/04/2025 - Automated response from ASUS</li>
<li>17/04/2025 - I followed up and got a human response letting me know they had patched the software and sent me a build to verify</li>
<li>18/04/2025 - ASUS confirmed the fix was live</li>
<li>09/05/2025 - <a href="https://www.cve.org/CVERecord?id=CVE-2025-3462">CVE-2025-3462</a> (8.4) and <a href="https://www.cve.org/CVERecord?id=CVE-2025-3463">CVE-2025-3463</a> (9.4) were published</li>
</ul>
<h2 id="assessing-the-damage">Assessing the Damage</h2>
<p>Almost immediately after reporting the RCE to ASUS I wrote a script to track <a href="https://certificate.transparency.dev/">certificate transparency</a> updates on my VPS, so I could see if anyone else had a domain with <code>driverhub.asus.com.*</code> registered. From looking at other websites certificate transparency logs, I could see that domains and subdomains would appear in the logs usually within a month.</p>
<p>After a month of waiting I am happy to say that my test domain is the only website that fits the regex, meaning <strong>it is unlikely that this was being actively exploited</strong> prior to my reporting of it.</p>
<h2 id="bug-bounty">Bug Bounty</h2>
<p>I asked ASUS if they offered bug bounties. They responded saying they do not, but they would instead put my name in their&nbsp;<a href="https://www.asus.com/content/asus-product-security-advisory/#header2025">“hall of fame”</a>. This is understandable since ASUS is just a&nbsp;<a href="https://companiesmarketcap.com/asus/marketcap/">small startup</a> and likely does not have the capital to pay a bounty.</p>
<h2 id="fun-notes">Fun Notes</h2>
<ul>
<li>
<p>When submitting the vulnerability report through ASUS’s <a href="https://www.asus.com/securityadvisory/">Security Advisory form</a>, Amazon CloudFront <strong>flagged the attached PoC as a malicious request</strong> and blocked the submission. So I had to strip out some of the PoC code and link video recordings instead.</p>
</li>
<li>
<p>If you click “Install All” in DriverHub instead of manually clicking install on each recommended driver, it will also install ArmouryCrate, ASUS’s custom CPU-Z, Norton360 and WinRAR.</p>
</li>
<li>
<p>Their CVE description for the RCE is a little misleading. They say <em>“This issue is limited to motherboards and does not affect laptops, desktop computers”</em>, however this affects any computer including desktops/laptops that have DriverHub installed. Also, instead of them saying it allows for arbitrary/remote code execution they say it <em>“may allow untrusted sources to affect system behaviour”</em>.</p>
</li>
<li>
<p><strong>MY ONBOARD WIFI STILL DOESN’T WORK</strong>, I had to buy an external USB WiFi adapter. Thanks for nothing DriverHub.</p>
</li>
</ul>

<ul>
<li>If you have any questions you can contact me on Signal (preferred) @paul19.84 or via email <code>contact [at] mrbruh.com</code></li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Fan Service (110 pts)]]></title>
            <link>https://flak.tedunangst.com/post/fan-service</link>
            <guid>43951368</guid>
            <pubDate>Sun, 11 May 2025 04:26:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flak.tedunangst.com/post/fan-service">https://flak.tedunangst.com/post/fan-service</a>, See on <a href="https://news.ycombinator.com/item?id=43951368">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>ASUS laptops generally have a feature that lets the user toggle the fan speed. Fn-F5 on some models, Fn-F on others. The direct effect is to limit the fan speed, from whisper mode to megablast, and indirectly control performance. But it doesn’t work in OpenBSD, so I needed to write an ASUS ACPI WMI driver.</p><h3 id="acpi">acpi</h3><p>ACPI is a hardware abstraction layer that lets the computer tell the operating system how to do things. It provides functions in byte code which the OS interprets to perform certain tasks. So instead of having to write a driver for every CPU, you call the ACPI method _PSS and that tells you what to do.</p><p>Of course, vendors want to include functionality that isn’t defined in the standard, so they add some extra methods, and then you end up writing some custom drivers anyway, for the little buttons that turn the microphone on and off, etc. OpenBSD (and other OSs) have lots of little drivers for ThinkPads and whatnot.</p><p>ACPI method names are only four letters long, so what do we do if two vendors include a method called WMNB and how do we determine what it does? (Technically, the ACPI nodes are identified by seven letter names, and the methods live under them, so it’s not really a problem, but somebody got paid to make a solution anyway.)</p><h3 id="wmi">wmi</h3><p>The solution is an extension to ACPI called WMI, which stands for Windows Multiplies Irritations or something. You ask ACPI for a buffer called _WDG, and this contains a table mapping GUIDs (globally unique, says so right there in the name) to local method names. Looking through this table, we come across <span>DCBA-FE-10-23-456789</span>, which we recognize as a GUID of interest, and this tells us the method to call is WMNB, but now we know it’s the right one.</p><p>OpenBSD does not have a WMI driver, which is part of what I need to set the fan profile. There is a WMI driver in Linux, and it includes an ASUS support driver for a variety of functions I’m interested in.</p><h3 id="first-steps">first steps</h3><p>First, I wrote a little acpi driver that attaches to PNP0C14. Read the _WDG buffer and print out all the GUIDs. Didn’t recognize any of the values, then realized I got the byte order wrong. Fixed that, saw something very close, realized I still didn’t get the byte order quite right. GUIDs are not big endian, they are not little endian, they are Goldilocks endian.</p><p>With that sorted out, I was able to enable events and get a printf every time I pushed a hotkey.</p><h3 id="events">events</h3><p>After receiving an interrupt and landing in our callback, we need to identify which event just happened by calling _WED. I did this, but was only getting 1 in response every time, regardless of key. I was a little stuck here. Very close to getting what I wanted, but without much clue as to what went wrong.</p><p>Turns out you can just look at your system’s ACPI code. OpenBSD runs <i>acpidump</i> at boot and saves all the files. Copy them to a work directory, run <i>iasl -d</i>, and have a look. A quick grep for _WED reveals the source.</p><pre><code>            Method (_WED, 1, NotSerialized)
            {   
                If ((Arg0 == 0xFF))
                {
                    Return (GANQ ())
                }
     
                Return (One)
            }
            Method (GANQ, 0, Serialized)
            {
                P8XH (Zero, 0xF2)
                If (AQNO)
                {
                    AQNO--
                    Local0 = DerefOf (ATKQ [AQHI])
                    AQHI++ 
                    AQHI &amp;= 0x0F
                    Return (Local0)
                }

                Return (Ones)
            }</code></pre><p>Even without knowing anything at all about ASL, this looks like a function that dequeues an event, but only if called with an argument of 255. That was the bug! Once I called it with the correct argument, I started receiving different event codes for backlight toggle, fan toggle, AC attach, etc.</p><h3 id="devices">devices</h3><p>Wrote some more code to handle getting and setting device state. There’s a magic incantation to call an ACPI method and pass it a device id, which could be the keyboard backlight, or the wifi led, or the fan profile, etc. Started with the keyboard backlight, since this was pretty easy to observe.</p><p>After fixing a few simple bugs like reversing the device ids for fnlock and backlight, I was able to blink the keyboard light by pressing F7. It’s all coming together.</p><p>Toggling the fan profile didn’t seem to accomplish anything, though. Under Windows, there is an audible difference switching to whisper mode, but I didn’t observe any change.</p><p>The Linux driver includes code for at least three different fan and performance profile settings. The same driver is used for a wide range of laptops, from thin and lights to gaming fraggers. According to the Linux driver, you can detect which devices are present by reading their state, then checking for a high bit, and then getting the value by masking off some low bits. This seemed to indicate I had a fan boost device, but it wasn’t responding to my changes.</p><p>After printing out the raw values, I noticed they were all -2. That doesn’t seem very likely. But it definitely has a high bit set, and masking off the low bits made it look reasonable. I think I missed something in the Linux driver? There’s lots of shifts and masks in lots of places.</p><p>Back to the ACPI dump, the WMNB method is a giant switch statement that ends with  Return (0xFFFFFFFE). So sure enough, there’s the -2 for a missing device, but I still don’t know which device id I should be using.</p><p>Back to the Linux driver, there’s an epic norse define for  <span>ASUS_WMI_DEVID_THROTTLE_THERMAL_POLICY_VIVO</span> which I hadn’t yet integrated because I was testing on a Zenbook, not a Vivobook. Added a check anyway, rebooted, and that’s a bingo! The Linux define name is a lie. Confirmed by inspecting the ASL code.</p><pre><code>            If ((IIA0 == 0x00110019))
            {
                Return (FANL (IIA1))
            }</code></pre><p>Now I had all the pieces. After a bit of cleanup and refactoring, my driver is complete. Kinda. There’s still a bunch of sensors that would be interesting to read, but my immediate concern has been addressed.</p><h3 id="results">results</h3><p>Pressing Fn-F after boot drops the fan speed noticeably, from a medium whir to barely a whisper. This has only a moderate effect on ordinary performance. The processor’s power budget is reduced, but not its (single core) clock speeds, so everything still runs smoothly. Lengthy compiles are slower, but I can also switch back to megablast turbo mode with the tap of a button.</p><p>Battery life is also much better. The fan itself is obviously eating less power. I think the CPU also enters a somewhat lower power state in whisper mode, or it’s willing to sleep a little deeper. It’s not clear everything that changes, and it varies by machine, but that’s the beauty of it. I wrote the driver on an AMD Zenbook, but it works without changes on an Intel Vivobook. Very convenient.</p><h3 id="misc">misc</h3><p>I also looked at the FreeBSD driver. FreeBSD directly uses the <span>ACPICA</span> code interfaces, calling function like <code>AcpiEvaluateObject</code> which personally look kinda out of place in BSD driver code. Linux does too, but all the functions have been renamed to <code>acpi_evaluate_object</code>, so they resemble the local style. I’m not entirely sure of the history here, but I think the generic <span>ACPICA</span> was at some pointer extracted and generified from the Linux code. OpenBSD uses a custom AML interpreter, so we have functions like <code>aml_evalname</code>.</p><p>In OpenBSD, nearly all header files are kept with their C files. So both dsdt.c and dsdt.h live in dev/acpi. (Notable exception is core C files in kern and headers in sys.) As a first time acpi driver writer, it was very convenient that all the OpenBSD code I needed to reference, from sample drivers to data structures to helper functions, was all in one spot.</p><p>Linux separates things such that I was looking at C files in drivers/platform/x86 and header files in include/linux/platform_data/x86. And the ACPI code lives other places as well. It’s all very orderly, but at times it felt like navigating a grocery store that arranges products in alphabetical order. Logical, but not exactly cozy.
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leaving Google (123 pts)]]></title>
            <link>https://www.airs.com/blog/archives/670</link>
            <guid>43950976</guid>
            <pubDate>Sun, 11 May 2025 03:01:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.airs.com/blog/archives/670">https://www.airs.com/blog/archives/670</a>, See on <a href="https://news.ycombinator.com/item?id=43950976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>I’ve left Google after working there for 19 years.</p>



<p>For most of that time I’ve been fortunate in being able to work on the <a href="https://go.dev/" data-type="link" data-id="https://go.dev/">Go programming language</a>. Go was started by Rob Pike, Ken Thompson, and Robert Griesemer in the fall of 2007. I joined the team in June, 2008, about the same time as Russ Cox. I’ve been very lucky to be able to work with such remarkable people on such an interesting project.</p>



<p>I am astonished at how much use Go has gotten over the years. Go has reached the status of being just another programming language, one that any programmer can choose when appropriate. That is far beyond what any of us expected in the early days, when our best hope was that Go might serve as an example for useful ideas that other languages and programming environments could adopt.</p>



<p>I started on Go by adding a Go frontend to the <a href="https://gcc.gnu.org/" data-type="link" data-id="https://gcc.gnu.org/">GCC compiler</a>. The Go project already had a compiler, of course, based on the Inferno C compiler. Having two compilers helped ensure that the language was clearly defined. When the two compilers differed, we knew that we had to clarify the spec and figure out what the right behavior should be.</p>



<p>In general my self-appointed role on the Go team consisted of tracking everything I could about the project and looking for areas that needed help. Among other things in the earlier years I added Go support to Google’s internal build system, and to <a href="https://www.swig.org/" data-type="link" data-id="https://www.swig.org/">the SWIG tool</a>. For a couple of years I was the team manager. From the first days of Go people asked for support for some sort of generics or type parameterization; working with Robert Griesemer I developed a series of language change proposals, and generics were added to the language in the <a href="https://go.dev/blog/intro-generics" data-type="link" data-id="https://go.dev/blog/intro-generics">Go 1.18 release in 2022</a>.</p>



<p>My approach had its good points and its bad points. I was quick to see the problems that people were running into today, and the problems they would run into tomorrow, and I was often able to get those problems addressed. But I was slow to see the ideas that would help people do new things that they weren’t trying to do and thus weren’t missing, things such as the Go module proxy and the Go vulnerability database.</p>



<p>Overall I think my approach was a good one in helping to build a successful project. But Gooogle has changed, and Go has changed, and the overall computer programming environment has changed. It’s become clear over the last year or so that I am no longer a good fit for the Go project at Google. I have to move on.</p>



<p>I’m still interested in Go. I don’t think that the language is done. I don’t think that any programming language is ever done–the programming environment changes all the time, and languages must evolve or die. That is doubly true for a language like Go that comes equipped with a substantial standard library, one that must adapt to the new needs of programmers.</p>



<p>I will be taking a break for a while, but I hope to be able to contribute to Go again in the future.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dotless Domains (137 pts)]]></title>
            <link>https://lab.avl.la/dotless/</link>
            <guid>43950525</guid>
            <pubDate>Sun, 11 May 2025 01:38:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lab.avl.la/dotless/">https://lab.avl.la/dotless/</a>, See on <a href="https://news.ycombinator.com/item?id=43950525">Hacker News</a></p>
Couldn't get https://lab.avl.la/dotless/: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[Fandom Sells Giant Bomb to Independent Creators (152 pts)]]></title>
            <link>https://about.fandom.com/news/fandom-sells-giant-bomb-to-independent-creators</link>
            <guid>43950046</guid>
            <pubDate>Sun, 11 May 2025 00:00:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://about.fandom.com/news/fandom-sells-giant-bomb-to-independent-creators">https://about.fandom.com/news/fandom-sells-giant-bomb-to-independent-creators</a>, See on <a href="https://news.ycombinator.com/item?id=43950046">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <main id="main" role="main">
        
    

  <div>
      
      






  



<picture>
    
    
    
    
    
    
    
    
                    
        
    
                        
      <source srcset="https://s3.us-east-1.amazonaws.com/fandom-craft-uploads/Screenshot-2025-05-09-at-1.59.17-PM.png 1x, https://s3.us-east-1.amazonaws.com/fandom-craft-uploads/Screenshot-2025-05-09-at-1.59.17-PM.png 2x" media="(min-width: 48em)">
      
    
    
                    
        
    
                        
      <source srcset="https://s3.us-east-1.amazonaws.com/fandom-craft-uploads/_725xAUTO_crop_center-center_90_none/Screenshot-2025-05-09-at-1.59.17-PM.png 1x, https://s3.us-east-1.amazonaws.com/fandom-craft-uploads/_1450xAUTO_crop_center-center_90_none/Screenshot-2025-05-09-at-1.59.17-PM.png 2x" media="(min-width: 40em)">
      
    
    
                    
        
    
                        
      <source srcset="https://s3.us-east-1.amazonaws.com/fandom-craft-uploads/_600xAUTO_crop_center-center_90_none/Screenshot-2025-05-09-at-1.59.17-PM.png 1x, https://s3.us-east-1.amazonaws.com/fandom-craft-uploads/_1200xAUTO_crop_center-center_90_none/Screenshot-2025-05-09-at-1.59.17-PM.png 2x">
      
    
    

  <img loading="lazy" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="Screenshot 2025 05 09 at 1 59 17 PM">

    
</picture>
      

      <div>
        <p dir="ltr"><strong>Gaming Content Creators &amp; Long-Time Giant Bomb Staff Jeff Bakalar &amp; Jeff Grubb Taking Full Ownership &amp; Operations of the Gaming Media Brand</strong></p>
<p dir="ltr"><strong>News Announced on Stage During Giant Bomb Panel at PAX East Conference</strong></p>
<p dir="ltr"><strong>San Francisco, CA - May 10, 2025 </strong>- <a href="https://www.fandom.com/"><strong>Fandom</strong></a>, the world’s largest fan platform, is selling <a href="https://www.giantbomb.com/"><strong>Giant Bomb</strong></a> to long-time Giant Bomb staff and gaming content creators Jeff Bakalar and Jeff Grubb. Financials of the deal were not disclosed. Giant Bomb’s programming, which was paused in order to work out the terms of this deal, will resume as quickly as possible. More details will be communicated soon by Giant Bomb’s new owners. </p>
<p dir="ltr"><strong><u>Statement from Fandom</u></strong></p>
<p dir="ltr">“Fandom has made the strategic decision to transition Giant Bomb back to its independent roots and the brand has been acquired by longtime staff and content creators, Jeff Bakalar and Jeff Grubb, who will now own and operate the site independently. Fans are at the core of everything we do at Fandom and we’re committed to not only serving them but also supporting the creators they love, and the sale of Giant Bomb represents a natural extension of that mission. We’re confident Giant Bomb is in good hands and its legacy will live on with Jeff and Jeff.”</p>
<p dir="ltr"><strong><u>Joint Statement from Jeff Bakalar and Jeff Grubb</u></strong></p>
<p dir="ltr">"Giant Bomb is now owned by the people who make Giant Bomb, and it would not have been possible without the speedy efforts of Fandom and our mutual agreement on what’s best for fans and creators. The future of Giant Bomb is now in the hands of our supporting community, who have always had our backs no matter what. We'll have a lot more to say about what this looks like soon, but for now, everyone can trust that all the support we receive goes directly to this team."</p>
<p dir="ltr"><strong><u>About Fandom</u><br></strong>Fandom is the world’s largest fan platform where fans immerse themselves in imagined worlds across entertainment and gaming. Reaching almost 350 million unique visitors per month and hosting more than 250,000 wikis, Fandom is the #1 source for in-depth information on pop culture, gaming, TV and film, where fans learn about and celebrate their favorite fandoms. Fandom’s Gaming division manages the online video game retailer Fanatical. Fandom Media, the content arm of Fandom, enhances the fan experience through curated editorial, video and branded content from trusted and established media brands Gamespot, TV Guide, Metacritic and the Emmy-nominated Honest Trailers from Screen Junkies. For more information follow @getfandom or visit: <a href="http://www.fandom.com/"><strong>www.fandom.com</strong></a>.<br><u><br><strong>About Giant Bomb</strong></u><br>Giant Bomb is a video game media brand and personality-driven network of gaming-focused content creators that features gaming news, reviews, commentary, and video. Founded in 2008, it offers unmatched access to the games industry with a focus on authenticity, while also covering the business in a unique and irreverent style. Giant Bomb pioneered many of the game content templates of today before they were internet mainstays and provides unique perspectives from a diverse range of industry personalities spanning multiple generations and decades of experience.</p>


<p dir="ltr"><strong><u>Press Contacts</u><br></strong><strong>Brenna Harran<br></strong>(631) 902-9801 | <a href="mailto:bharran@fandom.com">bharran@fandom.com</a> </p>


<p dir="ltr"><strong>Rachelle Savoia<br></strong>(917) 699-5028 | <a href="mailto:rsavoia@fandom.com">rsavoia@fandom.com</a> </p>
      </div>
    </div>
      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Observations from people watching (311 pts)]]></title>
            <link>https://skincontact.substack.com/p/21-observations-from-people-watching</link>
            <guid>43949542</guid>
            <pubDate>Sat, 10 May 2025 22:32:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://skincontact.substack.com/p/21-observations-from-people-watching">https://skincontact.substack.com/p/21-observations-from-people-watching</a>, See on <a href="https://news.ycombinator.com/item?id=43949542">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Painting weddings for a few years now, I have spent a fair bit of time observing strangers move through a room. Seeing someone new, I always have a feeling of noticing their internal architecture. I did not realize that some people do not feel this way, at least not as intensely.&nbsp;</p><div><li><p>By internal architecture, what I mean is, when someone talks to me, what I notice first are the supporting beams propping up their words: the cadence and tone and desire behind them. I hear if they are bored, fascinated, wanting validation or connection. I often feel like I can hear how much they like themselves. </p></li><li><p>I hear the speed at which they metabolize information and the nature of their attention. Attention falls on the spectrum of jumping bean to steady stream. Where it falls depends on a person’s nature, and also how much they want to be in that conversation. Someone’s quality of attention is evident from the questions they ask (how much they diverge from what the speaker is saying), if their gaze is wandering elsewhere, if they are fidgeting, restless. The outlier is dissociation, when someone is noticeably vacant, their attention completely absent. </p></li><li><p> Sometimes I see their feelings towards me when we talk, but that has the largest room for error in retrospect. Maybe the person I have the hardest time seeing clearly is still myself. I can see people more clearly when I am watching them talk to others.</p></li><li><p>I watch the person with the loudest laugh. The most striking thing isn't the volume—it's the feverish pitch. As the night goes on, it begins to sound more like desperation. Their joy has a fraying quality; it is exhausting to carry because it comes with a desire to seem happy and make others happy at all times.</p></li><li><p>When someone is flirting: Flirting is marketing, revealing yourself at a specific angle to coax a certain response. People have different marketing strategies, but this is always true: there is energy that is snaking outward, trying to find a surface to grip on. It can feel intrusive when un-welcomed, and pleasurably intimate if welcomed. Some people flirt with everyone. Some people only flirt with people they find hot. Some people never flirt.  </p></li><li><p>It is easy to tell how happy someone is to see another person enter a conversation. There is happy, and there is polite, and they look very different. Polite has a mechanical quality to it, like carrying out all the right movements to replace batteries in a remote. Happy has a boundless quality: unpredictable, even when it is at a low level. There is an openness, allowing another person to surprise and delight them. The easiest way to say this: there is no script for happy. It tumbles out of the body. Polite comes from the mind –it is restrained and calculated – measured lines and pauses. There are reinforcing loops in a polite person and a happy person. A person closed to the possibility of delight finds less of it. A person open to it finds more. </p></li><li><p>When someone is close enough for me to hear them in conversation, I can hear how receptive they are to other people’s worlds. This is often encoded in the pace of their back and forth; the brief pause after someone says something, or the absence of any breathing room. The pause is usually sinking into a feeling, allowing themselves to process and respond in real time. </p></li><li><p>People who don't pause exist more in their head than their body. The mind is top-down, rigid, quick, enforcing an established view. The mind is waiting for the other person to be done so they can say what’s rattling around inside. The body is slower, needs more time, and then words bubble up organically, one after another, without planning. People who exist more in their body are generally better at connecting emotionally with others. </p></li><li><p>I can see how much someone accepts themselves by looking for intense distortions in the way they are interacting with the world. Find the range in how they treat people; if there is a split difference in their stance towards people they admire, and people they look down on. I never met a person who looked down on others and unconditionally accepted themselves. For people who are self-accepting, it is usually less the case that some people are treated like they are golden and others like they are cursed. They may still have preferences to engage with some people over others, but their baseline patience and goodwill does not fall and rise intensely. </p></li><li><p>There are people who hate the world, and people who love a very narrow understanding of it, and people who love the world unconditionally, in all lifetimes, in all understandings. People who love a narrow understanding of the world exhibit a settledness in their bones; they are satisfied and not reaching outward. But their dynamic range moving through a room, moving through conversations, is limited. Opposing ideas often cause them to disengage. It is a little sad to see this, all the possibilities they don't even know they are missing by keeping their world narrow. </p></li><li><p>It is easy to spot the person in the room who thinks they are better than everyone. It is the person uninterested in giving any of their attention, the genuine and open-ended kind, to anyone else. This is also painful to see, because they often cannot see their own misery, how unpleasant the world is if no one is good enough to be loved.</p></li><li><p>Some people don't like themselves. They hide this from themselves by thinking they don’t like other people. They often bristle like a porcupine any time someone gets too close. That, or the opposite: they need to be insulated by other people's skin at all times. These are contrasting expressions of the same fundamental fracture. A person cannot stand themselves, and as a result, they either can only stand being unperceived, or they need other people to constantly perceive them to feel okay. </p></li><li><p>Watching someone reach for shiny things — not necessarily  the reaching, but the amount of hunger tangled with it— reveals how attached they are to their sense of desire and pleasure.</p></li><li><p>Look for unfounded apologies if you want to see how much someone believes in their right to exist. Look at the way they walk through a room, the way their shoulders are caved in or opened outward in relation to their ribcage, the way their eyes move to take in their surroundings, to see how much they believe in their belonging.</p></li><li><p>When I meet someone, I usually get a sense of whether they are generally happy, having a sad day, or generally sad, having a happy day. The emotional history of their life is often etched in the muscle tension in their face and their posture. </p></li><li><p>Some people are more like closed fists, others are more like open palms. Many of the driven people I have met are closed fists: warm, charming, and ready to punch through a wall at any point in time. There is a rigidity, a tunnel vision that naturally follows grasping for certain outcomes. An open palm has an expansive, receptive quality. They may still be incredibly intense and engaged with the world, but they are fluid, not forceful, in nature. </p></li><li><p>You can tell how controlling someone is by how forceful they are in conversation, how often they cut someone else off or steer the conversation towards what they want. Sometimes it is hard to see someone as controlling when what they desire is making you feel special and chosen. </p></li><li><p>&nbsp;It is easy to see when someone has a widely felt gravitational pull. Just watch where eyes congregate and return in room. </p></li><li><p>I can see when two people are close in a way that blocks their energy from the rest of the world, insulated and intimate and barring others from entering. I can also see when two people are close in a way that supports each other in being more engaged with the world. I admire the couples who are able to inhabit both states: experiencing the kind of connection that doesn’t allow outside entry, and then turning outward and drawing people in together. </p></li><li><p>I can see how much trust exists between couples, based on how men and women interact with their preferred sex. It is easy to sense wariness, someone watching their partner's face as they talk to a beautiful stranger, tension carried in their forehead and jaw, scanning for threats. It is also easy to sense complete ease and safety. It is the orientation I mentioned earlier, being an open palm. Beautiful strangers are not treated differently from anyone else. </p></li><li><p>My favorite kind of person has an elasticity in their movements. There is an openness that does not need to be announced, a curiosity that looks like turning towards all experience. They are not the loudest, but because they exhibit an unconditional acceptance of everyone, they are usually well loved. It makes sense, doesn't it? Unless there are many layers of contortions, most people love what loves them back. Not desire, not need, love — to see them wholly, with gentleness and acceptance. If you are able to do that, most people will sense it. And they will try to love you back. </p></li></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sierpiński Triangle? In My Bitwise and? (176 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/sierpinski-triangle-in-my-bitwise</link>
            <guid>43949238</guid>
            <pubDate>Sat, 10 May 2025 21:42:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/sierpinski-triangle-in-my-bitwise">https://lcamtuf.substack.com/p/sierpinski-triangle-in-my-bitwise</a>, See on <a href="https://news.ycombinator.com/item?id=43949238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>I’m an </span><a href="https://lcamtuf.substack.com/p/getting-silly-with-c-part-void2" rel="">ethusiastic promoter</a><span> of the C language. One of the outmoded cultural phenomena associated with C are </span><em>bit-twiddling hacks</em><span>: a collection of brain-teasers that implement improbably complex algorithms using bitwise arithmetic. They are often developed under the guise of code optimization, but they mostly serve to impress your friends and confuse enemies.</span></p><p><span>I have also </span><a href="https://lcamtuf.substack.com/p/you-cant-handle-the-buddhabrot" rel="">previously written</a><span> about fractals; they’re pieces of mathematical curiosa that enjoyed a near-mythical status in 1980s, but are no longer talked about in polite company. One of the better-known fractals is the Sierpiński triangle. It is constructed by taking an ordinary triangle and then successively removing the middle one-fourth from what’s left:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png" width="1456" height="490" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:490,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:403651,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fede9de9d-e511-43f2-98e8-4519bd8f5ca5_4696x1581.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><em>The first steps of building the Sierpiński triangle.</em></figcaption></figure></div><p>The fractal has some interesting properties; most notably, the surface area decreases by 25% in each iteration while the perimeter increases by 50%, so the respective limits are 0 and ∞. This is despite the figure retaining the same overall footprint as the starting triangle.</p><p><span>Anyway — there is this astonishingly simple bit-twiddling hack that </span><em>somehow </em><span>produces the Sierpiński triangle (</span><a href="https://godbolt.org/z/KbMqba9vY" rel="">demo</a><span>):</span></p><blockquote><pre><code>#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;

#define LEN (1 &lt;&lt; 6)

int main() {
  for (uint32_t y = 0; y &lt; LEN; y++) {
    for (uint32_t x = 0; x &lt; LEN; x++)
      printf((x &amp; y) ? "  " : "MM");
    putchar('\n');
  }
}</code></pre></blockquote><p><span>In essence, we iterate over a pair of integer coordinates, </span><em>x </em><span>and </span><em>y</em><span>, and then color each cell depending on whether bitwise </span><em>x &amp; y</em><span> is zero or non-zero. That’s it! For a pair of counters running from 0 to 63, the result is this:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png" width="1456" height="1344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1344,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57777,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0eb7330d-1b22-421d-ad4b-1fe57a25cb05_2031x1875.png 1456w" sizes="100vw"></picture></div></a><figcaption><em>What.</em></figcaption></figure></div><p>Increasing the range of the counters adds more detail, producing a finer-grained fractal with more and more nested triangles. But… why?</p><p>A hand-wavy explanation is that the bit-twiddling part is mostly a red herring. There’s nothing clever about bitwise AND; the magic is the positional numeral system! If we visualize the process of counting from 0 to 63 in binary, we get the following bit pattern:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png" width="1456" height="485" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:485,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:28010,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F112b5ec9-d910-4036-a22f-796cf25d3755_2344x781.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Binary count from 0 to 63 (left to right).</em></figcaption></figure></div><p>The value of the least significant bit is toggling with every tick, the next bit is flipping back and forth at half the frequency, and so on. This can be thought as a fractal pattern in itself: as we increase the size of the counter, the visualization acquires more and more self-similar detail, with no hard limit in sight. In fact, if you squint your eyes, the pattern does look a bit like a succession of somewhat squished (log-scale) triangles.</p><p><span>For a more precise tie-in to the Sierpiński shape, we do need to peek under the hood of the </span><em>x &amp; y </em><span>operation. We’re calculating a bitwise AND of two counters, but what is the result of that?</span></p><p><span>Well, it’s sufficient for any bit of </span><em>x &amp; y</em><span> to be set to satisfy the condition in the program, so let’s start by looking at the MSB. If you’re familiar with binary numbers, it should be obvious that in our 6-bit (64-value) case, the most significant bit of the x coordinate will be zero for all values less than 32, and one for all values equal to or above that threshold:</span></p><div data-component-name="Latex"><p><span>\(\begin{array}{|c|c|}
\hline
\textbf{Counter state} &amp; \textbf{Binary} \\
\hline
x = 0 &amp; 000000 \\
x = 1 &amp; 000001 \\
x = 2 &amp; 000010 \\
... &amp; ... \\
x = 31 &amp; 011111 \\
x = 32 &amp; \color{crimson}1\color{black}00000 \\
x = 33 &amp; \color{crimson}1\color{black}00001 \\
... &amp; ...\\
x = 63 &amp; \color{crimson}1\color{black}11111 \\
\hline
\end{array}\)</span></p></div><p>This divides the x axis into two halves; the same is true for the y coordinate, so we end up with four quadrants in the two-dimensional plot. Only in the bottom right quadrant (32x32 cells), both of the MSBs are set:</p><div data-component-name="Latex"><p><span>\(\begin{array}{|c|c|c|}
\hline
&amp; MSB(x) = 0 &amp; MSB(x) = 1 \\
\hline
MSB(y) = 0 &amp; 0 &amp; 0 \\
\hline
MSB(y) = 1 &amp; 0 &amp; \color{crimson}{1} \\
\hline
\end{array}\)</span></p></div><p><span>In other words, plotting the MSB of </span><em>x &amp; y </em><span>nets us the following:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png" width="1456" height="1344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1344,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:52976,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd65be3b4-89aa-419f-9a75-85ec88cdd446_2031x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Plotting the value of the MSB of x &amp; y.</em></figcaption></figure></div><p><span>Next, let’s have a look at the second most significant bit (#4). The value cycles at twice the frequency of the MSB, so the x axis is divided into four sections. The same is happening in the y axis, together producing a pattern of sixteen square segments on the plot, four of which are “set” after calculating </span><em>x &amp; y. </em></p><p>These four segments are pictured below, shown in teal and superimposed on top of the previously-calculated output for the MSB:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png" width="1456" height="1344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1344,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:53460,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F78c51bd4-a896-4295-9344-eb939f85c07d_2031x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Squares set after taking into account bit #4.</em></figcaption></figure></div><p>Another way to look at it is that we divided each of the four original quadrants into four sub-quadrants, and set the bottom right portions of each sub-quadrant to 1. This mimics the MSB operation, except on a finer scale:</p><div data-component-name="Latex"><p><span>\(\begin{array}{|c c| c c|}
\hline
* &amp; * &amp; * &amp; *  \\
*&amp; 1 &amp; * &amp; 1 \\
\hline
* &amp; * &amp; * &amp; *  \\
*&amp; 1 &amp; * &amp; 1 \\
\hline
\end{array}\)</span></p></div><p>After that, bit 3 is toggled eight times in each axis, lighting up the following regular grid of blocks:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png" width="1456" height="1344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1344,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57744,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F396f4b73-3e02-454b-94ac-e46a5aa38f99_2031x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Contributions of bit #3 (in teal).</em></figcaption></figure></div><p>Again, we can express it as a divide-and-set operation for the bottom right sub-sub-quadrants:</p><div data-component-name="Latex"><p><span>\(\begin{array}{|c c| c c|c c| c c|}
\hline
* &amp; * &amp; * &amp; * &amp; * &amp; * &amp; * &amp; *  \\
* &amp; 1 &amp; * &amp; 1  &amp; *&amp; 1 &amp; * &amp; 1 \\
\hline
* &amp; * &amp; * &amp; * &amp; * &amp; * &amp; * &amp; *  \\
* &amp; 1 &amp; * &amp; 1  &amp; *&amp; 1 &amp; * &amp; 1 \\
\hline
* &amp; * &amp; * &amp; * &amp; * &amp; * &amp; * &amp; *  \\
* &amp; 1 &amp; * &amp; 1  &amp; *&amp; 1 &amp; * &amp; 1 \\
\hline
* &amp; * &amp; * &amp; * &amp; * &amp; * &amp; * &amp; *  \\
* &amp; 1 &amp; * &amp; 1  &amp; *&amp; 1 &amp; * &amp; 1 \\
\hline

\end{array}\)</span></p></div><p>The same goes for bit 2, lighting up a regular pattern  of 4x4 blocks:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png" width="1456" height="1344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1344,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:66925,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F54f38f9e-fa91-4c23-83f5-3b5861aa54c7_2031x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Contributions of bit #2 (in teal).</em></figcaption></figure></div><p>After two more steps, we end up with the following result; the dark blue cells are coordinates that were never set in any of the passes, netting the familiar triangle:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png" width="1456" height="1344" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1344,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:57728,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/163283294?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3df018eb-b5f9-4160-a49c-00524ce129b4_2031x1875.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Mr. Sierpiński, I presume?</em></figcaption></figure></div><p>In effect, the algorithm is an iterative block-removal approach in disguise; it just doesn’t look that way because the passes are “parallelized” by the arithmetic logic unit of a CPU — at least up to the maximum hardware-supported bit width of an integer.</p><p><em><span>I write well-researched, original articles about geek culture, electronic circuit design, and more. </span><strong>If you like the content, please subscribe.</strong><span> It’s increasingly difficult to stay in touch with readers via social media; my typical post on X is shown to less than 5% of my followers and gets a ~0.2% clickthrough rate.</span></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why the Apple II Didn't Support Lowercase Letters (2020) (103 pts)]]></title>
            <link>https://www.vintagecomputing.com/index.php/archives/2833/why-the-apple-ii-didnt-support-lowercase-letters</link>
            <guid>43949056</guid>
            <pubDate>Sat, 10 May 2025 21:15:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vintagecomputing.com/index.php/archives/2833/why-the-apple-ii-didnt-support-lowercase-letters">https://www.vintagecomputing.com/index.php/archives/2833/why-the-apple-ii-didnt-support-lowercase-letters</a>, See on <a href="https://news.ycombinator.com/item?id=43949056">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><a href="https://www.vintagecomputing.com/wp-content/uploads/2020/09/apple_2_1977.jpg"><img src="https://www.vintagecomputing.com/wp-content/uploads/2020/09/apple_2_1977.jpg" alt="1977 Apple II Advertisement" width="450" height="319"></a></p>

<p><em>[Editor’s Note: I recently asked <a href="https://www.vintagecomputing.com/index.php/archives/2031/the-culture-of-tech-podcast-episode-1-steve-wozniak-and-television">Steve Wozniak</a> via email about why the original Apple II did not support lowercase letters. I could have guessed the answer, but it’s always good to hear the reason straight from the source. Woz’s response was so long and detailed that I asked him if I could publish the whole thing on VC&amp;G. He said yes, so here we are. –Benj]</em></p>

<p><img src="https://www.vintagecomputing.com/wp-content/images/forum_contest/divider2.jpg" alt="----------"></p>

<p>In the early 1970s, I was very poor, living paycheck to paycheck. While I worked at HP, any spare change went into my digital projects that I did on my own in my apartment. I was an excellent typist. I was proficient at typing by touch using keypunches with unusual and awkward special characters — even though some used two fingers of one hand.</p>
<p><a href="https://www.vintagecomputing.com/wp-content/uploads/2020/09/wozniak-and-jobs.jpg"><img src="https://www.vintagecomputing.com/wp-content/uploads/2020/09/wozniak-and-jobs.jpg" alt="Steve Wozniak and Steve Jobs with an Apple I" width="250"></a>I saw a friend typing on a teletype to the six computers on the early ARPAnet. I had to have this power over distant computers too. After building many arcade games on computers, how to build it was obvious to me instantly. I’d create a video generator (as with the arcade games) and display text using a character generator chip. But I needed a keyboard.</p>
<p>I’d show up at HP every morning around 6 AM to peruse engineering magazines and journals to see what new chips and products were coming. I found an offer for a $60 keyboard modeled after the upper-case-only ASR-33 teletype.</p>
<p>That $60 for the keyboard is probably like $500 today <em>[About $333 adjusted for inflation — Benj]</em>. This $60 was the single biggest price obstacle in the entire development of the early Apple computers. I had to gulp just to come up with $60, and I think my apartment rental check bounced that month — they put me on cash payment from then on. Other keyboards you could buy back then cost around $200, which might be $1000 or more now. There just wasn’t any mass manufacturing of digital keyboards in 1974.</p>
<p>So my TV Terminal, for accessing the ARPAnet, was uppercase only.</p>

<p><img src="https://www.vintagecomputing.com/wp-content/images/forum_contest/divider2.jpg" alt="----------"></p>

<p><a href="https://www.vintagecomputing.com/wp-content/uploads/2020/09/AP_81887390289-1000x532.jpg"><img src="https://www.vintagecomputing.com/wp-content/uploads/2020/09/AP_81887390289-1000x532.jpg" alt="Apple I Owned By Steve Jobs Auction Image" width="250"></a>The idea for my own computer came into my head the first day of the Homebrew Computer Club.</p>
<p>Maybe a year prior, I had looked at the 4-bit Intel 4004 microprocessor and determined that it could never be used to build the computer I wanted for myself — based on all the minicomputers that I’d designed on paper and desired since 1968-1970. But at the Homebrew Computer Club, they were talking about the 8008 and 8080 microprocessors, which I had not kept up with after my 4004 disappointment. I took home a data sheet for the 8008, based on a version of it from a Canadian company. That night, I discovered that this entire processor was capable of being a computer.</p>
<p>I already had my input and output, my TV Terminal. With that terminal, I’d type to a computer in Boston, for example, and that far-away computer, on the ARPAnet, would type back to my TV. I now saw that all I had to do was connect the microprocessor, with 4K of RAM (I’d built my tiny computer with the capability of the Altair, 5 years prior, in 1970, with my own TTL chips as the processor). 4K was the amount of RAM allowing you to type in a program on a human keyboard and run it.</p>
<p>My computer wasn’t designed from the ground up. I just added the 6502 microprocessor and 4K DRAMS (introduced that summer of 1975 and far less costly than Intel static RAMs) to have a complete computer with input and output.</p>
<p>So the uppercase keyboard was not designed as part of a computer. It already existed as my TV Terminal.</p>
<p><a href="https://www.vintagecomputing.com/wp-content/uploads/2020/09/awozjobs.png"><img src="https://www.vintagecomputing.com/wp-content/uploads/2020/09/awozjobs.png" alt="Steve Wozniak and Steve Jobs with an Apple II" width="250"></a>I truly would have wanted lower case on a keyboard, but I was still totally cash strapped, with no spare money. After already starting a BASIC interpreter for my computer, I would have had to re-assemble all my code. But here again, I did not have the money to have an account on a timeshare service for a 6502 interpreter. The BASIC was handwritten and hand-assembled. I’d write the source code and then write the binary that an interpreter would have turned my code into. To implement a major change like lower case (keeping 6 bits per character in my syntax table instead of 5 bits) would have been a horrendous and risky job to do by hand. If I’d had a time-share assembler, it would have been quick and easy. Hence, the Apple I wound up with uppercase only.</p>
<p>I discussed the alternatives with Steve Jobs. I was for lower case, but not for money (cost). Steve had little computer experience, and he said that uppercase was just fine. We both had our own reasons for not changing it before the computers were out. Even with the later Apple II (as with the Apple I), the code was again hand-written and hand-interpreted because I had no money. All 8 kB of code in the Apple II was only written by my own hand, including the binary object code. That made it impossible to add lower case into it easily.</p>
<p>So, in the end, the basic reason for no lowercase on the Apple I and Apple II was my own lack of money. Zero checking. Zero savings.</p>
	
				
				

				<p>

Tags: <a href="https://www.vintagecomputing.com/index.php/archives/tag/1974" rel="tag">1974</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/1976" rel="tag">1976</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/1977" rel="tag">1977</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/6502" rel="tag">6502</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/apple" rel="tag">Apple</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/apple-i" rel="tag">Apple I</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/apple-ii" rel="tag">Apple II</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/arpanet" rel="tag">ARPAnet</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/hp" rel="tag">HP</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/keyboards" rel="tag">keyboards</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/lowercase" rel="tag">lowercase</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/steve-jobs" rel="tag">Steve Jobs</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/steve-wozniak" rel="tag">Steve Wozniak</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/tv-terminal" rel="tag">TV Terminal</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/uppercase" rel="tag">uppercase</a>, <a href="https://www.vintagecomputing.com/index.php/archives/tag/woz" rel="tag">Woz</a><br>
				</p>

				

				<p>
					<small>
						This entry was posted
						 
						on Tuesday, September 8th, 2020 at 2:00 pm						and is filed under <a href="https://www.vintagecomputing.com/index.php/archives/category/computers/computer-info-and-history" rel="category tag">Computer History</a>, <a href="https://www.vintagecomputing.com/index.php/archives/category/computers" rel="category tag">Vintage Computing</a>.
						You can follow any responses to this entry through the <a href="https://www.vintagecomputing.com/index.php/archives/2833/why-the-apple-ii-didnt-support-lowercase-letters/feed">RSS 2.0</a> feed. 
						
													You can skip to the end and leave a response. Pinging is currently not allowed.
			
												
					</small>
				</p>
	
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Xenolab – Rasp Pi monitor for my pet carnivourus plants (113 pts)]]></title>
            <link>https://github.com/blackrabbit17/xenolab</link>
            <guid>43948945</guid>
            <pubDate>Sat, 10 May 2025 20:58:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/blackrabbit17/xenolab">https://github.com/blackrabbit17/xenolab</a>, See on <a href="https://news.ycombinator.com/item?id=43948945">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Xenolab - Rasp Pi monitor for my pet carnivorous plants</h2><a id="user-content-xenolab---rasp-pi-monitor-for-my-pet-carnivorous-plants" aria-label="Permalink: Xenolab - Rasp Pi monitor for my pet carnivorous plants" href="#xenolab---rasp-pi-monitor-for-my-pet-carnivorous-plants"></a></p>
<p dir="auto">The Xenolab Rasp Pi Monitor is a cutting-edge, semi-autonomous biosurveillance module engineered for the precise care and observation of exotic carnivorous flora.</p>
<blockquote>
<br>
<g-emoji alias="warning">⚠️</g-emoji> WARNING: MONITORING TRIFFIDS<p>
The Xenolab Rasp Pi Monitor is not certified for use with Triffids or other semi-sentient, ambulatory flora. Historical data suggests a high incidence of operator attrition and catastrophic habitat compromise when engaging with such species. While the system may successfully log preliminary biometric data, prolonged monitoring is statistically correlated with acute reductions in observer longevity.<br>— Xenolab Safety Directive 12.4B</p></blockquote>
<p dir="auto"><h3 tabindex="-1" dir="auto">Xenolab Running</h3><a id="user-content-xenolab-running" aria-label="Permalink: Xenolab Running" href="#xenolab-running"></a></p>
<hr>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/finished.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/finished.jpg" alt=""></a></p>
<p dir="auto">It's just past 8AM so it's about 50% though simulated sunrise.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/frontend/screenshot.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/frontend/screenshot.png" alt=""></a></p>
<p dir="auto">Main features:</p>
<ul dir="auto">
<li>Rasp Pi 5</li>
<li>7" 800x480 Touchscreen</li>
<li>Temperature Monitor</li>
<li>Humidity Monitor</li>
<li>Fan to simulate wind</li>
<li>24 R,G,B LED for light</li>
<li>Soil Moisture Sensor</li>
<li>USB relays so the Rasp Pi can control all of the sensors / fans etc</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Why?</h3><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<hr>
<p dir="auto">I wanted to have some fun with 3D printing and electronics, which gets me away from my normal day job running Atomic Tessellator (<a href="https://atomictessellator.com/" rel="nofollow">https://atomictessellator.com</a>). There are lots of aspects of this project that are wildly impractical and over-engineered and done just for fun.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Electrical components</h3><a id="user-content-electrical-components" aria-label="Permalink: Electrical components" href="#electrical-components"></a></p>
<hr>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Intel &amp; Control</th>
<th>Atmospherics</th>
<th>Temp + Moisture</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/usb-relay/USBPWR_RELAY_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/usb-relay/USBPWR_RELAY_preview.png" alt=""></a><br><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/subcomponents/usb-relay">USB Relay</a><br>USBPOWRL001</td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/LED-lighting/XC4385_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/LED-lighting/XC4385_preview.png" alt=""></a><br><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/subcomponents/LED-lighting">Sunlight Simulation</a><br>XC4380 24RGB</td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/temp-humidity/Y2163753_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/temp-humidity/Y2163753_preview.png" alt=""></a><br>Temp + Humidity <br>DHT11 v2</td>
</tr>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/camera/SEVRBP0544__5_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/camera/SEVRBP0544__5_preview.png" alt=""></a><br>Camera<br>12.3 MP Sony IMX500</td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/50mm-fan/XC5055_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/50mm-fan/XC5055_preview.png" alt=""></a><br>Wind Simulation<br>50mm 12V DC Fan</td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/soil-moisture/LM393_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/subcomponents/soil-moisture/LM393_preview.png" alt=""></a><br>Soil Moisture<br>LM393</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">Computing</h3><a id="user-content-computing" aria-label="Permalink: Computing" href="#computing"></a></p>
<hr>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/computing/rasp-pi-5">Rasp-pi 5</a></th>
<th><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/computing/cooling-hat">Cooling Hat</a></th>
<th><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/computing/display">Display</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/computing/rasp-pi-5/pi5_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/computing/rasp-pi-5/pi5_preview.png" alt=""></a><br>R-Pi 5 - 8GB<br>Quad Core 2.4GHz<br>ARM Cortex-A76</td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/computing/cooling-hat/cooling-hat_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/computing/cooling-hat/cooling-hat_preview.png" alt=""></a><br>R-Pi 5<br>RGB Cooling Hat<br>w/ OLED Display</td>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/computing/display/dfrobot-7in-800x480_preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/computing/display/dfrobot-7in-800x480_preview.png" alt=""></a><br>7" 800x480<br>DSI Capacitive<br>Touchscreen</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">CAD + Physical Design</h3><a id="user-content-cad--physical-design" aria-label="Permalink: CAD + Physical Design" href="#cad--physical-design"></a></p>
<hr>
<p dir="auto">I'm really new at CAD, this was my first time. It's ok, you can laugh at my designs.</p>
<p dir="auto">I used the wonderful <a href="https://github.com/blackrabbit17/xenolab/blob/main">tinkercad.com</a> because I found that to be the most intuitive.</p>
<div data-snippet-clipboard-copy-content="I can code in my sleep, make logic unfold,
But hand me some CAD and my courage turns cold.
Lines go zig when they clearly should zag,
My blueprints look more like a digital gag."><pre><code>I can code in my sleep, make logic unfold,
But hand me some CAD and my courage turns cold.
Lines go zig when they clearly should zag,
My blueprints look more like a digital gag.
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/CAD/main_housing/preview2.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/CAD/main_housing/preview2.png" width="383"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/CAD/main_housing/preview1.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/CAD/main_housing/preview1.png" width="250"></a></p>
<p dir="auto"><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/CAD/main_housing">Model File</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/CAD/fan_housing/preview.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/CAD/fan_housing/preview.png" width="383"></a></p>
<p dir="auto"><a href="https://github.com/blackrabbit17/xenolab/tree/main/physical-build/CAD/fan_housing">Model File</a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Build Pics</h3><a id="user-content-build-pics" aria-label="Permalink: Build Pics" href="#build-pics"></a></p>
<hr>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5546.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5546.jpg" width="500"></a></p>
<p dir="auto">Setting up the RASP Pi 5s and testing some sensors</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/3dprinted.png"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/3dprinted.png" width="500"></a></p>
<p dir="auto">Fresh from the 3D printer!</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/FA9DE0F2-8E53-48A8-A0B5-AE390EFE8164.JPG"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/FA9DE0F2-8E53-48A8-A0B5-AE390EFE8164.JPG" width="500"></a></p>
<p dir="auto">Coated in black because it looks better</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5797.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5797.jpg" width="500"></a></p>
<p dir="auto">Starting to wire up the relays and power and sensors</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5815.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5815.jpg" width="500"></a></p>
<p dir="auto">Power-on tests</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/PHOTO-2025-05-06-14-32-45.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/PHOTO-2025-05-06-14-32-45.jpg" width="500"></a></p>
<p dir="auto">Sensor integration tests</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5913.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/construction_pics/IMG_5913.jpg" width="500"></a></p>
<p dir="auto">Finished connecting all the sensors up</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/finished.jpg"><img src="https://raw.githubusercontent.com/blackrabbit17/xenolab/refs/heads/main/physical-build/finished.jpg" alt=""></a></p>
<p dir="auto">Finished and running!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft Teams will soon block screen capture during meetings (192 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-will-soon-block-screen-capture-during-meetings/</link>
            <guid>43948291</guid>
            <pubDate>Sat, 10 May 2025 19:39:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-will-soon-block-screen-capture-during-meetings/">https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-will-soon-block-screen-capture-during-meetings/</a>, See on <a href="https://news.ycombinator.com/item?id=43948291">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="Teams" height="900" src="https://www.bleepstatic.com/content/hl-images/2024/08/20/Microsoft-Teams.jpg" width="1600"></p>

<p>Microsoft is working on adding a new Teams feature&nbsp;that will prevent users from capturing screenshots of sensitive information shared during meetings.</p>

<p>Those joining from unsupported platforms will be automatically placed in audio-only mode to protect shared content.&nbsp;The company&nbsp;plans to start rolling out this new Teams feature to Android, desktop, iOS, and web&nbsp;users worldwide in July 2025.</p>

<p>"To address the issue of unauthorized screen captures during meetings, the Prevent Screen Capture feature ensures that if a user attempts to take a screen capture, the meeting window will turn black, thereby protecting sensitive information," <a href="https://www.microsoft.com/ro-ro/microsoft-365/roadmap?id=490051" target="_blank" rel="nofollow noopener">Microsoft shared</a> in a new&nbsp;Microsoft 365 roadmap entry.</p>

<p>"This feature will be available on Teams desktop applications (both Windows and Mac) and Teams mobile applications (both iOS and Android)."</p>

<p>However, it should be noted that, even if screenshots are blocked, sensitive media and information shared in Teams meetings can still be captured by taking a photo of the conversation.</p>

<p>Last month, Meta introduced a similar WhatsApp feature named "<a href="https://www.bleepingcomputer.com/news/security/whatsapps-new-advanced-chat-privacy-protects-sensitive-messages/" target="_blank" rel="nofollow noopener">Advanced Chat Privacy</a>," which protects sensitive information exchanged in private chats and group conversations by blocking attempts to save shared media and export chat content.</p>

<p>Redmond will also roll out&nbsp;a&nbsp;<a href="https://www.microsoft.com/ro-ro/microsoft-365/roadmap?id=490050" target="_blank" rel="nofollow noopener">town hall screen privilege management update</a>&nbsp;in Teams Rooms on Windows,&nbsp;<a href="https://www.microsoft.com/ro-ro/microsoft-365/roadmap?id=490564" target="_blank" rel="nofollow noopener">interactive BizChat/Copilot Studio agents</a>&nbsp;in meetings and 1-on-1 calls, and a Copilot feature to help&nbsp;<a href="https://www.microsoft.com/ro-ro/microsoft-365/roadmap?id=488807" target="_blank" rel="nofollow noopener">generate audio overviews</a>&nbsp;of transcribed meetings in June.</p>

<p>Another Copilot feature to help&nbsp;<a href="https://www.microsoft.com/ro-ro/microsoft-365/roadmap?id=488807" target="_blank" rel="nofollow noopener">generate audio overviews</a>&nbsp;of transcribed meetings is also under development and&nbsp;will let users choose the speakers, adjust the tone, and tailor the length.</p>

<p>In January, the company&nbsp;<a href="https://www.bleepingcomputer.com/news/security/microsoft-teams-phishing-attack-alerts-coming-to-everyone-next-month/" target="_blank" rel="nofollow noopener">reminded Microsoft 365 admins</a>&nbsp;that its new Teams Chat brand impersonation protection feature, which alerts users when detecting phishing attacks targeting organizations with external Teams access toggled on, will be made generally available for all customers by mid-February 2025.</p>

<p>At last year's&nbsp;Enterprise Connect enterprise communications and collaboration conference, Microsoft&nbsp;<a href="https://techcommunity.microsoft.com/blog/microsoftteamsblog/microsoft-teams-building-a-foundation-for-the-future/4090393" target="_blank" rel="nofollow noopener">announced</a>&nbsp;that the Teams platform had reached over 320 million monthly active users across 181 markets and 44 languages.</p>

	   
<div>
    <p><a href="https://hubs.li/Q039Tm490" target="_blank" rel="noopener sponsored">
            <img src="https://www.bleepstatic.com/c/p/picus/red-report-in-article.jpg" alt="Red Report 2025"></a>
    </p>
    
</div>

           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pope Leo XIV: "AI poses new challenges re: human dignity, justice and labour" (234 pts)]]></title>
            <link>https://www.vatican.va/content/leo-xiv/en/speeches/2025/may/documents/20250510-collegio-cardinalizio.html</link>
            <guid>43948130</guid>
            <pubDate>Sat, 10 May 2025 19:20:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vatican.va/content/leo-xiv/en/speeches/2025/may/documents/20250510-collegio-cardinalizio.html">https://www.vatican.va/content/leo-xiv/en/speeches/2025/may/documents/20250510-collegio-cardinalizio.html</a>, See on <a href="https://news.ycombinator.com/item?id=43948130">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Thank you very much, Your Eminence. Before taking our seats, let us begin with a prayer, asking the Lord to continue to accompany this College, and above all the entire Church with this spirit, with enthusiasm, but also with deep faith. Let us pray together in Latin.</p> 
<p>Pater noster… Ave Maria…</p> 
<p>In the first part of this meeting, there will be a short talk with some reflections that I would like to share with you. But then there will be a second part, a bit like the opportunity that many of you had asked for: a sort of dialogue with the College of Cardinals to hear what advice, suggestions, proposals, concrete things, which have already been discussed in the days leading up to the Conclave.</p> 
<p>Dear Brother Cardinals,</p> 
<p>I greet all of you with gratitude for this meeting and for the days that preceded it. Days that were sad because of the loss of the Holy Father Pope Francis and demanding due to the responsibilities we confronted together, yet at the same time, in accordance with the promise Jesus himself made to us, days rich in grace and consolation in the Spirit (cf. <i>Jn</i> 14:25-27).</p> 
<p>You, dear Cardinals, are the closest collaborators of the Pope. This has proved a great comfort to me in accepting a yoke clearly far beyond my own limited powers, as it would be for any of us. Your presence reminds me that the Lord, who has entrusted me with this mission, will not leave me alone in bearing its responsibility. I know, before all else, that I can always count on his help, the help of the Lord, and through his grace and providence, on your closeness and that of so many of our brothers and sisters throughout the world who believe in God, love the Church and support the Vicar of Christ by their prayers and good works.</p> 
<p>I thank the Dean of the College of Cardinals, Cardinal Giovanni Battista Re – who deserves applause, at least once, if not more – whose wisdom, the fruit of a long life and many years of faithful service to the Apostolic See, has helped us greatly during this time. I thank the Camerlengo of the Holy Roman Church, Cardinal Kevin Joseph Farrell – I believe he is present today – for the important and demanding work that he has done throughout the period of the Vacant See and for the convocation of the Conclave. My thoughts also go to our brother Cardinals who, for reasons of health, were unable to be present, and I join you in embracing them in communion of affection and prayer.</p> 
<p>At this moment, both sad and joyful, providentially bathed in the light of Easter, I would like all of us to see the passing of our beloved Holy Father Pope Francis and the Conclave as a paschal event, a stage in that long exodus through which the Lord continues to guide us towards the fullness of life. In this perspective, we entrust to the “merciful Father and God of all consolation” (<i>2 Cor</i> 1:3) the soul of the late Pontiff and also the future of the Church.</p> 
<p>Beginning with Saint Peter and up to myself, his unworthy Successor, the Pope has been a humble servant of God and of his brothers and sisters, and nothing more than this. It has been clearly seen in the example of so many of my Predecessors, and most recently by Pope Francis himself, with his example of complete dedication to service and to sober simplicity of life, his abandonment to God throughout his ministry and his serene trust at the moment of his return to the Father’s house. Let us take up this precious legacy and continue on the journey, inspired by the same hope that is born of faith.</p> 
<p>It is the Risen Lord, present among us, who protects and guides the Church, and continues to fill her with hope through the love “poured into our hearts through the Holy Spirit who has been given to us” (<i>Rom</i> 5:5). It is up to us to be docile listeners to his voice and faithful ministers of his plan of salvation, mindful that God loves to communicate himself, not in the roar of thunder and earthquakes, but in the “whisper of a gentle breeze” (<i>1 Kings</i> 19:12) or, as some translate it, in a “sound of sheer silence.” It is this essential and important encounter to which we must guide and accompany all the holy People of God entrusted to our care.</p> 
<p>In these days, we have been able to see the beauty and feel the strength of this immense community, which with such affection and devotion has greeted and mourned its Shepherd, accompanying him with faith and prayer at the time of his final encounter with the Lord. We have seen the true grandeur of the Church, which is alive in the rich variety of her members in union with her one Head, Christ, “the shepherd and guardian” (<i>1 Peter</i> 2:25) of our souls. She is the womb from which we were born and at the same time the flock (cf. <i>Jn</i> 21:15-17), the field (cf. <i>Mk</i> 4:1-20) entrusted to us to protect and cultivate, to nourish with the sacraments of salvation and to make fruitful by our sowing the seed of the Word, so that, steadfast in one accord and enthusiastic in mission, she may press forward, like the Israelites in the desert, in the shadow of the cloud and in the light of God’s fire (cf. <i>Ex</i> 13:21).</p> 
<p>In this regard, I would like us to renew together today our complete commitment to the path that the universal Church has now followed for decades in the wake of the <a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/index.htm">Second Vatican Council</a>. Pope Francis masterfully and concretely set it forth in the Apostolic Exhortation <i><a href="https://www.vatican.va/content/francesco/en/apost_exhortations/documents/papa-francesco_esortazione-ap_20131124_evangelii-gaudium.html">Evangelii Gaudium</a></i>, from which I would like to highlight several fundamental points: the return to the primacy of Christ in proclamation (cf. No. 11); the missionary conversion of the entire Christian community (cf. No. 9); growth in collegiality and synodality (cf. No. 33); attention to the <i>sensus fidei</i> (cf. Nos. 119-120), especially in its most authentic and inclusive forms, such as popular piety (cf. No. 123); loving care for the least and the rejected (cf. No. 53); courageous and trusting dialogue with the contemporary world in its various components and realities (cf. No. 84; Second Vatican Council, Pastoral Constitution <i><a href="https://www.vatican.va/archive/hist_councils/ii_vatican_council/documents/vat-ii_const_19651207_gaudium-et-spes_en.html">Gaudium et Spes</a></i>, 1-2).</p> 
<p>These are evangelical principles that have always inspired and guided the life and activity of God’s Family. In these values, the merciful face of the Father has been revealed and continues to be revealed in his incarnate Son, the ultimate hope of all who sincerely seek truth, justice, peace and fraternity (cf. Benedict XVI, <i><a href="https://www.vatican.va/content/benedict-xvi/en/encyclicals/documents/hf_ben-xvi_enc_20071130_spe-salvi.html">Spe Salvi</a></i>, 2; Francis, <i><a href="https://www.vatican.va/content/francesco/en/bulls/documents/20240509_spes-non-confundit_bolla-giubileo2025.html">Spes Non Confundit</a></i>, 3).</p> 
<p>Sensing myself called to continue in this same path, I chose to take the name Leo XIV. There are different reasons for this, but mainly because Pope Leo XIII in his historic Encyclical <i><a href="https://www.vatican.va/content/leo-xiii/en/encyclicals/documents/hf_l-xiii_enc_15051891_rerum-novarum.html">Rerum Novarum</a></i> addressed the social question in the context of the first great industrial revolution. In our own day, the Church offers to everyone the treasury of her social teaching in response to another industrial revolution and to developments in the field of artificial intelligence that pose new challenges for the defence of human dignity, justice and labour.</p> 
<p>Dear brothers, I would like to conclude the first part of our meeting by making my own – and proposing to you as well – the hope that Saint Paul VI expressed at the inauguration of his Petrine Ministry in 1963: “May it pass over the whole world like a great flame of faith and love kindled in all men and women of good will. May it shed light on paths of mutual cooperation and bless humanity abundantly, now and always, with the very strength of God, without whose help nothing is valid, nothing is holy” (<a href="https://www.vatican.va/content/paul-vi/la/speeches/1963/documents/hf_p-vi_spe_19630622_first-message.html">Message <i>Qui Fausto Die </i>addressed to the entire human family</a>, 22 June 1963).</p> 
<p>May these also be our sentiments, to be translated into prayer and commitment, with the Lord’s help. Thank you!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[For $595, you get what nobody else can give you for twice the price (1982) [pdf] (213 pts)]]></title>
            <link>https://s3data.computerhistory.org/brochures/commodore.commodore64.1982.102646264.pdf</link>
            <guid>43947630</guid>
            <pubDate>Sat, 10 May 2025 18:05:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://s3data.computerhistory.org/brochures/commodore.commodore64.1982.102646264.pdf">https://s3data.computerhistory.org/brochures/commodore.commodore64.1982.102646264.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43947630">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse engineering the 386 processor's prefetch queue circuitry (151 pts)]]></title>
            <link>http://www.righto.com/2025/05/386-prefetch-circuitry-reverse-engineered.html</link>
            <guid>43946824</guid>
            <pubDate>Sat, 10 May 2025 16:23:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.righto.com/2025/05/386-prefetch-circuitry-reverse-engineered.html">http://www.righto.com/2025/05/386-prefetch-circuitry-reverse-engineered.html</a>, See on <a href="https://news.ycombinator.com/item?id=43946824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-6792624295909344732" itemprop="description articleBody">
<p>In 1985, Intel introduced the groundbreaking 386 processor, the first 32-bit processor in the x86 architecture.
To improve performance, the 386 has a 16-byte instruction prefetch queue.
The purpose of the prefetch queue is to fetch instructions from memory before they are needed,
so the processor usually doesn't need to wait on memory while executing instructions.
Instruction prefetching takes advantage of times when the processor is "thinking" and the memory bus would otherwise be unused.</p>
<p>In this article, I look at the 386's prefetch queue circuitry in detail.
One interesting circuit is the incrementer, which adds 1 to a pointer to step through memory.
This sounds easy enough, but the incrementer uses complicated circuitry for high performance.
The prefetch queue uses a large network
to shift bytes around so they are properly aligned.
It also has a compact circuit to extend signed 8-bit and 16-bit
numbers to 32 bits.
There aren't any major discoveries in this post, but if you're interested in low-level circuits and dynamic logic, keep reading.</p>
<p>The photo below shows the 386's shiny fingernail-sized silicon die under a microscope.
Although it may look like an aerial view of a strangely-zoned city, the die photo reveals the functional blocks
of the chip.
The Prefetch Unit in the upper left is the relevant block.
In this post, I'll discuss the
prefetch queue circuitry (highlighted in red), skipping over the prefetch control circuitry to the right.
The Prefetch Unit receives data from the Bus Interface Unit (upper right) that communicates with memory.
The Instruction Decode Unit receives prefetched instructions from the Prefetch Unit, byte by byte, and decodes the
opcodes for execution.</p>
<p><a href="https://static.righto.com/images/386-prefetch/386-die-labeled.jpg"><img alt="This die photo of the 386 shows the location of the registers. Click this image (or any other) for a larger version." height="534" src="https://static.righto.com/images/386-prefetch/386-die-labeled-w500.jpg" title="This die photo of the 386 shows the location of the registers. Click this image (or any other) for a larger version." width="500"></a></p><p>This die photo of the 386 shows the location of the registers. Click this image (or any other) for a larger version.</p>
<p>The left quarter of the chip consists of stripes of circuitry that appears much more orderly than the rest of the chip.
This grid-like appearance arises because
each functional block is constructed (for the most part) by repeating the same circuit 32 times, once for each bit, side by side.
Vertical data lines run up and down, in groups of 32 bits, connecting the functional blocks.
To make this work, each circuit must fit into the same width on the die; this layout constraint forces the circuit
designers to develop a circuit that uses this width efficiently without exceeding the allowed width.
The circuitry for the prefetch queue uses the same approach: each circuit is 66 µm wide<span id="fnref:width"><a href="#fn:width">1</a></span> and repeated 32 times.
As will be seen, fitting the prefetch circuitry into this fixed width requires some layout tricks.</p>
<h2>What the prefetcher does</h2>
<p>The purpose of the prefetch unit is to speed up performance by reading instructions from memory before they are needed,
so the processor won't need to wait to get instructions from memory.
Prefetching takes advantage of times when the memory bus is otherwise idle, minimizing conflict with other instructions
that are reading or writing data.
In the 386, prefetched instructions are stored in a 16-byte queue, consisting of four 32-bit blocks.<span id="fnref:cache"><a href="#fn:cache">2</a></span></p>
<p>The diagram below zooms in on the prefetcher and shows its main components.
You can see how the same circuit (in most cases) is repeated 32 times, forming vertical bands.
At the top are 32 bus lines from the Bus Interface Unit. These lines provide the connection between the datapath and
external memory, via the Bus Interface Unit.
These lines form a triangular pattern as the 32 horizontal lines on the right branch off and form 32 vertical lines, one for each bit.
Next are the fetch pointer and the limit register, with a circuit to check if the fetch pointer has
reached the limit.
Note that the two low-order bits (on the right) of the incrementer and limit check circuit are
missing.
At the bottom of the incrementer, you can see that some bit positions have a blob of circuitry missing from others,
breaking the pattern of repeated blocks.
The 16-byte prefetch queue is below the incrementer. Although this memory is the heart of the prefetcher, its
circuitry takes up a relatively small area.</p>
<p><a href="https://static.righto.com/images/386-prefetch/prefetcher-labeled.jpg"><img alt="A close-up of the prefetcher with the main blocks labeled. At the right, the prefetcher receives control signals." height="387" src="https://static.righto.com/images/386-prefetch/prefetcher-labeled-w600.jpg" title="A close-up of the prefetcher with the main blocks labeled. At the right, the prefetcher receives control signals." width="600"></a></p><p>A close-up of the prefetcher with the main blocks labeled. At the right, the prefetcher receives control signals.</p>
<p>The bottom part of the prefetcher shifts data to align it as needed.
A 32-bit value can be split across two 32-bit
rows of the prefetch buffer.
To handle this, the prefetcher includes a data shift network to shift and align its data.
This network occupies a lot of space, but there is no active circuitry here: just a grid of horizontal and vertical wires.</p>
<p>Finally, the sign extend circuitry converts a signed 8-bit or 16-bit value into a signed 16-bit or 32-bit value
as needed.
You can see that the sign extend circuitry is highly irregular, especially in the middle.
A latch stores the output of the prefetch queue for use by the rest of the datapath.</p>
<h2>Limit check</h2>
<p>If you've written x86 programs, you probably know about the processor's Instruction Pointer (EIP) that holds the
address of the next instruction to execute.
As a program executes, the Instruction Pointer moves from instruction to instruction.
However, it turns out that the Instruction Pointer doesn't actually exist!
Instead, the 386 has an "Advance Instruction Fetch Pointer", which holds the address of the next instruction to
fetch into the prefetch queue.
But sometimes the processor needs to know the Instruction Pointer value, for instance, to determine the return
address when calling a subroutine or to compute the destination address of a relative jump.
So what happens?
The processor gets the Advance Instruction Fetch Pointer address from the prefetch queue circuitry and subtracts
the current length of the prefetch queue.
The result is the address of the next instruction to execute, the desired Instruction Pointer value.</p>
<p>The Advance Instruction Fetch Pointer—the address of the next instruction to prefetch—is stored
in a register at the
top of the prefetch queue circuitry.
As instructions are prefetched, this pointer is incremented by the prefetch circuitry. (Since instructions are fetched 32 bits at a time,
this pointer is incremented in steps of four and the bottom two bits are always 0.)</p>
<p>But what keeps the prefetcher from prefetching too far and going outside the valid memory range?
The x86 architecture infamously uses segments to define valid regions of memory.
A segment has a start and end address (known as the base and limit) and memory is protected by blocking accesses
outside the segment.
The 386 has six active segments; the relevant one is the Code Segment that holds program instructions.
Thus, the limit address of the Code Segment controls when the prefetcher must stop prefetching.<span id="fnref:paging"><a href="#fn:paging">3</a></span>
The prefetch queue contains a circuit to stop prefetching when the fetch pointer reaches the limit of the Code Segment.
In this section, I'll describe that circuit.</p>
<p>Comparing two values may seem trivial, but the 386 uses a few tricks to make this fast.
The basic idea is to use 30 XOR gates to compare the bits of the two registers.
(Why 30 bits and not 32? Since 32 bits are fetched at a time, the bottom bits of the address are 00 and can be ignored.)
If the two registers match, all the XOR values will be 0, but if they don't match, an XOR value will be 1.
Conceptually, connecting the XORs to a 32-input OR gate will yield the desired result:
0 if all bits match and 1 if there is a mismatch.
Unfortunately, building a 32-input OR gate using standard CMOS logic is impractical for electrical reasons, as well as
inconveniently large to fit into the circuit.
Instead, the 386 uses dynamic logic to implement a spread-out NOR gate with one transistor in each column of the 
prefetcher.</p>
<p>The schematic below shows the implementation of one bit of the equality comparison.
The mechanism is that if the two registers differ, the transistor on the right is turned on, pulling the equality bus low.
This circuit is replicated 30 times, comparing all the bits: if there is any mismatch, the equality bus will be pulled
low, but if all bits match, the bus remains high.
The three gates on the left implement XNOR; this circuit may seem overly complicated, but it is a standard way
of implementing XNOR.
The NOR gate at the right blocks the comparison except during clock phase 2.
(The importance of this will be explained below.)</p>
<p><a href="https://static.righto.com/images/386-prefetch/equality-logic.jpg"><img alt="This circuit is repeated 30 times to compare the registers." height="120" src="https://static.righto.com/images/386-prefetch/equality-logic-w500.jpg" title="This circuit is repeated 30 times to compare the registers." width="500"></a></p><p>This circuit is repeated 30 times to compare the registers.</p>
<p>The equality bus travels horizontally through the prefetcher, pulled low if any bits don't match.
But what pulls the bus high?
That's the job of the dynamic circuit below.
Unlike regular static gates, dynamic logic is controlled by the processor's clock signals and depends on capacitance in the circuit to hold data.
The 386 is controlled by a two-phase clock signal.<span id="fnref:clock"><a href="#fn:clock">4</a></span>
In the first clock phase, the precharge transistor below turns on, pulling the
equality bus high.
In the second clock phase, the XOR circuits above are enabled, pulling the equality bus low if the two registers don't
match.
Meanwhile, the CMOS switch turns on in clock phase 2, passing the equality bus's value to the latch.
The "keeper" circuit keeps the equality bus held high unless it is explicitly pulled low, to avoid the risk of
the voltage on the equality bus slowly dissipating.
The keeper uses a weak transistor to keep the bus high while inactive. But if the bus is pulled low, the
keeper transistor is overpowered and turns off.</p>
<p><a href="https://static.righto.com/images/386-prefetch/equality-out.jpg"><img alt="This is the output circuit for the equality comparison.  This circuit is located to the right of the prefetcher." height="171" src="https://static.righto.com/images/386-prefetch/equality-out-w600.jpg" title="This is the output circuit for the equality comparison.  This circuit is located to the right of the prefetcher." width="600"></a></p><p>This is the output circuit for the equality comparison.  This circuit is located to the right of the prefetcher.</p>
<p>This dynamic logic reduces power consumption and circuit size.
Since the bus is charged and discharged during opposite
clock phases, you avoid steady current through the transistors.
(In contrast, an NMOS processor like the 8086 might use a pull-up on the bus.
When the bus is pulled low, would you end up with current flowing through the pull-up and the pull-down transistors.
This would increase power consumption, make the chip run hotter, and limit your clock speed.)</p>
<h2>The incrementer</h2>
<p>After each prefetch, the Advance Instruction Fetch Pointer must be incremented to hold the address of the next
instruction to prefetch.
Incrementing this pointer is the job of the incrementer.
(Because each fetch is 32 bits, the pointer is incremented by 4 each time.
But in the die photo, you can see a notch in the incrementer and limit check circuit where the circuitry for the
bottom two bits has been omitted.
Thus, the incrementer's circuitry increments its value by 1, so the pointer (with two zero bits appended)
increases in steps of 4.)</p>
<p>Building an incrementer circuit is straightforward, for example, you can use a chain of 30 half-adders.
The problem is that incrementing a 30-bit value at high speed is difficult because of the carries from one position to the next.
It's similar to calculating 99999999 + 1 in decimal; you need to tediously carry the 1, carry the 1, carry the 1, and so forth,
through all the digits, resulting in a slow, sequential process.</p>
<p>The incrementer uses a faster approach. First, it computes all the carries at high speed, almost in parallel.
Then it computes each output bit in parallel from the carries—if there is a carry into a position, it toggles that bit.</p>
<p>Computing the carries is straightforward in concept: if there is a block of 1 bits at the end of the value,
all those bits will
produce carries, but carrying is stopped by the rightmost 0 bit.
For instance, incrementing binary 11011 results in 11100; there are carries from the last two bits, but the zero
stops the carries.
A circuit to implement this was developed at the University of Manchester in England way back in 1959, and is known as the Manchester
carry chain.</p>
<p>In the Manchester carry chain, you build a chain of switches, one for each data bit, as shown below.
For a 1 bit, you close the switch, but for a 0 bit you open the switch.
(The switches are implemented by transistors.)
To compute the carries, you start by feeding in a carry signal at the right
The signal will go through the closed switches
until it hits an open switch, and then it will be blocked.<span id="fnref:manchester"><a href="#fn:manchester">5</a></span>
The outputs along the chain give us the desired carry value at each position.</p>
<p><a href="https://static.righto.com/images/386-prefetch/chain.jpg"><img alt="Concept of the Manchester carry chain, 4 bits." height="149" src="https://static.righto.com/images/386-prefetch/chain-w500.jpg" title="Concept of the Manchester carry chain, 4 bits." width="500"></a></p><p>Concept of the Manchester carry chain, 4 bits.</p>
<p>Since the switches in the Manchester carry chain can all be set in parallel and the carry signal blasts through
the switches at high speed, this circuit rapidly computes the carries we need.
The carries then flip the associated bits (in parallel), giving us the result much faster than a straightforward adder.</p>
<p>There are complications, of course, in the actual implementation.
The carry signal in the carry chain is inverted, so a low signal propagates through the carry chain to indicate a carry.
(It is faster to pull a signal low than high.)
But <em>something</em> needs to make the line go high when necessary.
As with the equality circuitry, the solution is dynamic logic.
That is, the carry line is precharged high during one clock phase and then processing happens in the
second clock phase, potentially pulling the line low.</p>
<p>The next problem is that the carry signal weakens as it passes through multiple transistors and long
lengths of wire. 
The solution is that each segment has a circuit to amplify the signal, using a clocked inverter and an asymmetrical
inverter.
Importantly, this amplifier is not in the carry chain path, so it doesn't slow down the signal through the chain.</p>
<p><a href="https://static.righto.com/images/386-prefetch/chain-circuit.jpg"><img alt="The Manchester carry chain circuit for a typical bit in the incrementer." height="275" src="https://static.righto.com/images/386-prefetch/chain-circuit-w500.jpg" title="The Manchester carry chain circuit for a typical bit in the incrementer." width="500"></a></p><p>The Manchester carry chain circuit for a typical bit in the incrementer.</p>
<p>The schematic above shows the implementation of the Manchester carry chain for a typical bit.
The chain itself is at the bottom, with the transistor switch as before.
During clock phase 1,
the precharge transistor pulls this segment of the carry chain high.
During clock phase 2, the signal on the chain goes through the "clocked inverter" at the right to produce the local carry signal.
If there is a carry, the next bit is flipped by the XOR gate, producing the incremented output.<span id="fnref:xor"><a href="#fn:xor">6</a></span>
The "keeper/amplifier" is an asymmetrical inverter that produces a strong low output but a weak high output.
When there is no carry, its weak output keeps the carry chain pulled high.
But as soon as a carry is detected, it strongly pulls the carry chain low to boost the carry signal.</p>
<p>But this circuit still isn't enough for the desired performance. The incrementer uses a second carry technique in parallel:
carry skip.
The concept is to look at blocks of bits and allow the carry to jump over the entire block.
The diagram below shows a simplified implementation of the carry skip circuit. Each block consists of 3 to 6 bits.
If all the bits in a block are 1's, then the AND gate turns on the associated transistor in the carry skip line.
This allows the carry skip signal to propagate (from left to right), a block at a time. When it reaches a block with a
0 bit, the corresponding transistor will be off, stopping the carry as in the Manchester carry chain.
The AND gates all operate in parallel, so the transistors are rapidly turned on or off in parallel.
Then, the carry skip signal passes through a small number of transistors, without going through any logic.
(The carry skip signal is like an express train that skips most stations, while the Manchester carry chain
is the local train to all the stations.)
Like the Manchester carry chain, the implementation of carry skip needs precharge
circuits on the lines, a keeper/amplifier, and clocked logic, but I'll skip the details.</p>
<p><a href="https://static.righto.com/images/386-prefetch/carry-skip.jpg"><img alt="An abstracted and simplified carry-skip circuit. The block sizes don't match the 386's circuit." height="133" src="https://static.righto.com/images/386-prefetch/carry-skip-w600.jpg" title="An abstracted and simplified carry-skip circuit. The block sizes don't match the 386's circuit." width="600"></a></p><p>An abstracted and simplified carry-skip circuit. The block sizes don't match the 386's circuit.</p>
<p>One interesting feature is the layout of the large AND gates.
A 6-input AND gate is a large device, difficult to fit into one cell of the incrementer.
The solution is that the gate is spread out across multiple cells.
Specifically, the gate uses a standard CMOS NAND gate circuit with NMOS transistors in series and PMOS transistors
in parallel.
Each cell has an NMOS transistor and a PMOS transistor, and the chains are connected at the end to form the desired
NAND gate. (Inverting the output produces the desired AND function.)
This spread-out layout technique is unusual, but keeps each bit's circuitry approximately the same size.</p>
<p>The incrementer circuitry was tricky to reverse engineer because of these techniques.
In particular, 
most of the prefetcher consists of a single block of circuitry repeated 32 times, once for each bit.
The incrementer, on the other hand, consists of <em>four</em> different blocks of circuitry, repeating in an irregular pattern.
Specifically, one block starts a carry chain, a second block continues the carry chain, and a third block ends
a carry chain.
The block before the ending block is different (one large transistor to drive the last block), making four variants in
total.
This irregular pattern is visible in the earlier photo of the prefetcher.</p>
<h2>The alignment network</h2>
<p>The bottom part of the prefetcher rotates data to align it as needed.
Unlike some processors, the x86 does not enforce aligned memory accesses.
That is, a 32-bit value does not need to start on a 4-byte boundary in memory.
As a result, a 32-bit value may be split across two 32-bit rows of the prefetch queue.
Moreover, when the instruction decoder fetches one byte of an instruction, that byte may be at any position in the prefetch queue.</p>
<p>To deal with these problems, the prefetcher includes an alignment network that can rotate bytes to output a byte, word, or four bytes with the alignment required by the rest of the processor.</p>
<p>The diagram below shows part of this alignment network.
Each bit exiting the prefetch queue (top) has four wires, for rotates of 24, 16, 8, or 0 bits.
Each rotate wire is connected to one of the 32 horizontal bit lines.
Finally, each horizontal bit line has an output tap, going to the datapath below.
(The vertical lines are in the chip's lower M1 metal layer, while the horizontal lines are in the upper M2 metal layer.
For this photo, I removed the M2 layer to show the underlying layer.
Shadows of the original horizontal lines are still visible.)</p>
<p><a href="https://static.righto.com/images/386-prefetch/alignment-network.jpg"><img alt="Part of the alignment network." height="411" src="https://static.righto.com/images/386-prefetch/alignment-network-w600.jpg" title="Part of the alignment network." width="600"></a></p><p>Part of the alignment network.</p>
<p>The idea is that by selecting one set of vertical rotate lines, the 32-bit output from the prefetch queue will be
rotated left by that amount.
For instance, to rotate by 8, bits are sent down the "rotate 8" lines. Bit 0 from the prefetch queue will energize
horizontal line 8, bit 1 will energize horizontal line 9, and so forth, with bit 31 wrapping around to horizontal line 7. Since horizontal bit line 8 is connected to
output 8, the result is that bit 0 is output as bit 8, bit 1 is output as bit 9, and so forth.</p>
<p><a href="https://static.righto.com/images/386-prefetch/alignment-diagram.jpg"><img alt="The four possibilities for aligning a 32-bit value. The four bytes above are shifted as specified to produce the desired output below." height="115" src="https://static.righto.com/images/386-prefetch/alignment-diagram-w500.jpg" title="The four possibilities for aligning a 32-bit value. The four bytes above are shifted as specified to produce the desired output below." width="500"></a></p><p>The four possibilities for aligning a 32-bit value. The four bytes above are shifted as specified to produce the desired output below.</p>
<p>For the alignment process,
one 32-bit output may be split across two 32-bit entries in the prefetch queue in four different ways, as shown above.
These combinations are implemented by multiplexers and drivers.
Two 32-bit multiplexers select the two relevant rows in the prefetch queue (blue and green above).
Four 32-bit drivers are connected to the four sets of vertical lines, with one set of drivers activated to
produce the desired shift.
Each byte of each driver is wired to achieve the alignment shown above. For instance, the rotate-8 driver gets
its top byte from the "green" multiplexer and the other three bytes from the "blue" multiplexer.
The result is that the four bytes, split across two queue rows, are rotated to form an aligned 32-bit value.</p>
<h2>Sign extension</h2>
<p>The final circuit is sign extension. Suppose you want to add an 8-bit value to a 32-bit value.
An unsigned 8-bit value can be extended to 32 bits by simply filling the upper bits with zeroes.
But for a signed value, it's trickier. For instance, -1 is the eight-bit value 0xFF, but the 32-bit value is
0xFFFFFFFF.
To convert an 8-bit signed value to 32 bits, the top 24 bits must be filled in with the top bit of the original
value (which indicates the sign).
In other words, for a positive value, the extra bits are filled with 0, but for a negative value, the extra bits are
filled with 1.
This process is called sign extension.<span id="fnref:sex"><a href="#fn:sex">9</a></span></p>
<p>In the 386, a circuit at the bottom of the prefetcher performs sign extension for values in instructions.
This circuit supports extending an 8-bit value to 16 bits or 32 bits, as well as extending a 16-bit value to 32 bits.
This circuit will extend a value with zeros or with the sign, depending on the instruction.</p>
<p>The schematic below shows one bit of this sign extension circuit. It consists of a latch on the left and right, with a
multiplexer in the middle.
The latches are constructed with a standard 386 circuit using a CMOS switch (see footnote).<span id="fnref:latch"><a href="#fn:latch">7</a></span>
The multiplexer selects one of three values: the bit value from the swap network, 0 for sign extension, or 1 for
sign extension.
The multiplexer is constructed from a CMOS switch if the bit value is selected and two transistors for the 0 or 1 values.
This circuit is replicated 32 times, although the bottom byte only has the latches, not the multiplexer, as
sign extension does not modify the bottom byte.</p>
<p><a href="https://static.righto.com/images/386-prefetch/sign-extend-circuit.jpg"><img alt="The sign extend circuit associated with bits 31-8 from the prefetcher." height="195" src="https://static.righto.com/images/386-prefetch/sign-extend-circuit-w600.jpg" title="The sign extend circuit associated with bits 31-8 from the prefetcher." width="600"></a></p><p>The sign extend circuit associated with bits 31-8 from the prefetcher.</p>
<p>The second part of the sign extension circuitry determines if the bits should be filled with 0 or 1 and sends the control
signals to the circuit above.
The gates on the left determine if the sign extension bit should be a 0 or a 1. For a 16-bit sign extension, this
bit comes from bit 15 of the data, while for an 8-bit sign extension, the bit comes from bit 7.
The four gates on the right generate the signals to sign extend each bit, producing separate signals for the
bit range 31-16 and the range 15-8.</p>
<p><a href="https://static.righto.com/images/386-prefetch/sign-extend-logic.jpg"><img alt="This circuit determines which bits should be filled with 0 or 1." height="165" src="https://static.righto.com/images/386-prefetch/sign-extend-logic-w500.jpg" title="This circuit determines which bits should be filled with 0 or 1." width="500"></a></p><p>This circuit determines which bits should be filled with 0 or 1.</p>
<p>The layout of this circuit on the die is somewhat unusual.
Most of the prefetcher circuitry consists of 32 identical columns, one for each bit.<span id="fnref:extension"><a href="#fn:extension">8</a></span>
The circuitry above is implemented once, using about 16 gates (buffers and inverters are not shown above).
Despite this, the circuitry above is crammed into bit positions 17 through 7, creating irregularities in the layout.
Moreover, the implementation of the circuitry in silicon is unusual compared to the rest of the 386.
Most of the 386's circuitry uses the two metal layers for interconnection, minimizing the use of polysilicon wiring.
However, the circuit above also uses long stretches of polysilicon to connect the gates.</p>
<p><a href="https://static.righto.com/images/386-prefetch/sign-extension-layout.jpg"><img alt="Layout of the sign extension circuitry. This circuitry is at the bottom of the prefetch queue." height="165" src="https://static.righto.com/images/386-prefetch/sign-extension-layout-w600.jpg" title="Layout of the sign extension circuitry. This circuitry is at the bottom of the prefetch queue." width="600"></a></p><p>Layout of the sign extension circuitry. This circuitry is at the bottom of the prefetch queue.</p>
<p>The diagram above shows the irregular layout of the sign extension circuitry amid the regular datapath circuitry that
is 32 bits wide.
The sign extension circuitry is shown in green; this is the circuitry described at the top of this section, repeated
for each bit 31-8.
The circuitry for bits 15-8 has been shifted upward, perhaps to make room for the sign extension control circuitry,
indicated in red.
Note that the layout of the control circuitry is completely irregular, since there is one copy of the circuitry and
it has no internal structure.
One consequence of this layout is the wasted space to the left and right of this circuitry block, the
tan regions with no circuitry except vertical metal lines passing through.
At the far right, a block of circuitry to control the latches has been wedged under bit 0.
Intel's designers go to great effort to minimize the size of the processor die since a smaller die saves substantial
money.
This layout must have been the most efficient they could manage, but I find it aesthetically displeasing compared
to the regularity of the rest of the datapath.</p>
<h2>How instructions flow through the chip</h2>
<p>Instructions follow a tortuous path through the 386 chip.
First, 
the Bus Interface Unit in the upper right
corner reads instructions from memory and sends them over a 32-bit bus (blue) to the prefetch unit.
The prefetch unit stores the instructions in the 16-byte prefetch queue.</p>
<p><a href="https://static.righto.com/images/386-prefetch/386-instr-labeled.jpg"><img alt="Instructions follow a twisting path to and from the prefetch queue." height="641" src="https://static.righto.com/images/386-prefetch/386-instr-labeled-w600.jpg" title="Instructions follow a twisting path to and from the prefetch queue." width="600"></a></p><p>Instructions follow a twisting path to and from the prefetch queue.</p>
<p>How is an instruction executed from the prefetch queue? It turns out that there are two distinct paths.
Suppose you're executing an instruction to add 12345678 to the EAX register.
The prefetch queue will hold the five bytes 05 (the opcode), 78, 56, 34, and 12.
The prefetch queue provides opcodes to the decoder one byte at a time over the 8-bit bus shown in red.
The bus takes the lowest 8 bits from the prefetch queue's alignment network and sends this byte to a buffer
(the small square at the head of the red arrow).
From there, the opcode travels to the instruction decoder.<span id="fnref:decoder"><a href="#fn:decoder">10</a></span>
The instruction decoder, in turn, uses large tables (PLAs) to convert the x86 instruction into a 111-bit internal format
with 19 different fields.<span id="fnref:slager"><a href="#fn:slager">11</a></span></p>
<p>The data bytes of an instruction, on the other hand, go from the prefetch queue to the ALU (Arithmetic Logic Unit) through a 32-bit data bus (orange).
Unlike the previous buses, this data bus is spread out, with one wire through each column of the datapath.
This bus extends through the entire datapath so values can also be stored into registers.
For instance,
the <code>MOV</code> (move) instruction can store a value from an instruction (an "immediate" value) into a register.</p>
<h2>Conclusions</h2>
<p>The 386's prefetch queue contains about 7400 transistors, more than an Intel 8080 processor.
(And this is just the queue itself; I'm ignoring the prefetch control logic.)
This illustrates the rapid advance of processor technology: part of one functional unit in the 386 contains more
transistors than an entire 8080 processor from 11 years earlier.
And this unit is less than 3% of the entire 386 processor.</p>
<!-- about 230 transistors per column -->

<p>Every time I look at an x86 circuit, I see the complexity required to support backward compatibility, and
I gain more understanding of why RISC became popular.
The prefetcher is no exception.
Much of the complexity is due to the 386's support for unaligned memory accesses, requiring a byte shift network to
move bytes into 32-bit alignment.
Moreover, at the other end of the instruction bus is the complicated instruction decoder that decodes
intricate x86 instructions. Decoding RISC instructions is much easier.</p>
<p>In any case, I hope you've found this look at the prefetch circuitry interesting.
I plan to write more about the 386, so
follow me on Bluesky (<a href="https://bsky.app/profile/righto.com">@righto.com</a>) or <a href="https://www.righto.com/feeds/posts/default">RSS</a> for updates.
I've written multiple articles on the 386 previously; a good place to start might be my <a href="https://www.righto.com/2023/10/intel-386-die-versions.html">survey of the 368 dies</a>.</p>
<h2>Footnotes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman Wants Your Eyeball (148 pts)]]></title>
            <link>https://www.privacyguides.org/articles/2025/05/10/sam-altman-wants-your-eyeball/</link>
            <guid>43946766</guid>
            <pubDate>Sat, 10 May 2025 16:14:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.privacyguides.org/articles/2025/05/10/sam-altman-wants-your-eyeball/">https://www.privacyguides.org/articles/2025/05/10/sam-altman-wants-your-eyeball/</a>, See on <a href="https://news.ycombinator.com/item?id=43946766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><a data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="Image of a red circle of light that resembles a human iris over a black background." src="https://www.privacyguides.org/articles/assets/images/sam-altman-wants-your-eyeball/orb-cover.webp"></a></p>

<p>Last week, OpenAI's CEO Sam Altman announced in San Francisco that the World project he co-founded, formerly known as Worldcoin, is opening six stores across the United States, allowing users of the project's app to scan their eyeballs.</p>
<p>Simply put, the premise is this: scan your eyeball, get a biometric tag, verify yourself, buy our apps (and cryptocurrency). The scary part is the for-profit company developing the project has now gathered millions in venture capital investment, powerful partners, and is ready to expand and impose its <a href="https://en.wikipedia.org/wiki/Minority_Report_(film)">Minority Report</a> style technology everywhere. <strong>Welcome to Dystopialand.</strong><!-- more --></p>
<p>The World(coin) project is an initiative from the startup Tools for Humanity, co-founded by its CEO Alex Blania. Despite its friendly name, the for-profit corporation has been on the radar of many critics through the years already. From experts to journalists to privacy commissioners around the world, not everyone shares Blania's enthusiasm for his biometric-based technology.</p>
<h2 id="what-is-the-world-app">What is the World App?</h2>
<p>The World project, recently rebranded from the Worldcoin project (possibly to convey better its expansionist ambitions) presented its plan for the World App to Americans this week. The project is now expanding well beyond the cryptocurrency it started from.</p>
<p>The World App is an everything app, providing users with a <em>World ID</em>, that can be verified through the collection of biometric data in the form of an iris scan.</p>
<p>The scan is then filtered and hashed to create a unique identifier that is stored as a so-called "proof of personhood" on the <em>World Network</em>, a blockchain-based protocol.</p>
<p>The World App itself contains a collection of "Mini Apps", where users can manage their cryptocurrencies, chat together, play games, receive their pay check even, and ultimately live their whole life within the closed "verified" ecosystem of the app.</p>
<p>For a company constantly praising decentralization, it sure looks like they want to make sure they are the center of it all.</p>
<p>To obtain this coveted verification code, users <em>must</em> be ready to share their precious eyeball data with the Orb.</p>
<p>The Orb is a piece of hardware designed by Tools for Humanity to perform iris scans. It is available to access in the United States at one of the currently six locations in Austin, Atlanta, Los Angeles, Miami, Nashville and San Francisco (more to come soon), like some sort of biometrics collection ATM.</p>
<p>The World project has for ambition to expand its reach across the United States to install 7,500 Orbs by the end of this year, so be prepared to see this dystopian technology everywhere soon.</p>
<p>The San Francisco <a href="https://www.theregister.com/2025/05/04/sam_altman_startup_world/">presentation last week</a> was clearly prepared to impress investors with its Apple announcement vibe. The promise of a quickly growing startup that everyone will soon want to work with, was repeated over and over in different flavors.</p>
<p>Tools for Humanity bragged about many large partnerships that should make any privacy advocates shiver in dread: the Match Group dating apps conglomerate (Tinder, OkCupid, Hinge, Plenty of Fish), Stripe, and Visa are some of them.</p>
<p>If they succeed in convincing enough people, many of us could soon have little choice but to unwillingly have to enroll.</p>
<h2 id="worldcoin-isnt-new-you-might-have-heard-of-its-unethical-practices-already">World(coin) isn't new, you might have heard of its unethical practices already</h2>
<p>The project <a href="https://techcrunch.com/2025/04/30/sam-altmans-world-unveils-a-mobile-verification-device/">claims</a> to have onboarded 26 million people already, including 12 millions "users" who are verified (had their biometric data collected).</p>
<p>These "users" are largely located in Latin America, Africa, and Asia. This is because the company started testing for its project there a few years ago, in regions where people often have fewer legal protections.</p>
<p>In 2022, MIT Technology Review produced <a href="https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/">an extensive investigation</a> on the startup's debut in an article titled: <em>Deception, exploited workers, and cash handouts: How Worldcoin recruited its first half a million test users.</em></p>
<p>The investigation revealed a collection of unethical practices to pressure the most vulnerable populations in signing up for Worldcoin, and <strong>have their eyeball scanned in exchange for money</strong> they desperately needed.</p>
<p>Some participants had to provide much more personal information than the company says is required, such as emails, phone numbers, and even photos of official ID. Many people who gave their biometric data to Worldcoin were rushed and misinformed. Some who signed up didn't even have an email and had to create one. The "Orb operators" hired to perform the scans locally were often poorly trained, poorly informed, and unable to answer the questions asked by participants.</p>
<p>So much so that <a href="https://techcrunch.com/2023/08/02/kenya-suspends-worldcoin-scans-over-security-privacy-and-financial-concerns/">Kenya suspended the company's operations</a> in 2023 over concerns for privacy, security, and financial service practices.</p>
<p>Some people who signed up never received the promised money. Some officials were bribed to give the impression to participants these operations were official and supported by the government.</p>
<p>As Ruswandi, one of the person targeted by this early campaign <a href="https://www.technologyreview.com/2022/04/06/1048981/worldcoin-cryptocurrency-biometrics-web3/">remarked</a>: "why did Worldcoin target lower-income communities in the first place, instead of crypto enthusiasts or communities?"</p>
<p>Exploiting people in situation of poverty in order to test a biometric identification technology isn't a great way to start a project developed by a company called "Tools for Humanity".</p>
<h2 id="creating-the-problem-selling-the-solution">Creating the problem, selling the solution</h2>
<p>Why developing such a technology in the first place?</p>
<p>Sam Altman himself have <a href="https://www.wired.com/story/sam-altman-orb-eyeball-scan-launch-us/">expressed concern</a> about the problem this alleged solution solves: the avalanche of fake accounts and pretend persons online caused by the new AI tools unleashed everywhere.</p>
<p>The proposed use of a "proof of personhood" claims to solve this problem by allocating a unique identifier to each human, a personal code supposedly impossible to duplicate or cheat. Of course, this has <a href="https://gizmodo.com/worldcoin-black-market-iris-data-identity-orb-1850454037">already been proven wrong</a>.</p>
<p>No one will miss the irony of the CEO of OpenAI, responsible for creating the largest share of this problem, expressing such concern <strong>while continuing to feed the fire</strong>.</p>
<p>This is a classic case of creating a problem and selling the solution. Well, in this case it is more like <strong><em>selling</em> the problem and selling the solution</strong>. As researcher and cryptocurrency critic <a href="https://www.citationneeded.news/worldcoin-a-solution-in-search-of/">Molly White pointed out</a> in 2023:</p>
<p>"That's right, the guy who's going to sell us all the solution to a worsening AI-powered bot infestation of the Internet and to AI-induced mass unemployment is the same guy who's making the AI in question."</p>
<p>Sadly, this proposed solution also isn't really a solution, or at least it isn't a <em>good</em> solution. Indeed, this will <strong>create a whole collection of new problems</strong>, many much worse than a bot infestation.</p>
<h2 id="the-risks-of-sharing-biometric-data">The risks of sharing biometric data</h2>
<p>Biometric data is incredibly sensitive data, because it's irrevocably attached to a person. Whether it's from a face scan, palm scan, fingerprint, keystroke pattern, or iris scan, this data is part of our bodies and <strong>cannot be changed like a password</strong> if it gets compromised.</p>
<p>For this reason, a growing number of legislations around the world now include special categories for such data collection, and require extra protections and supervision for it.</p>
<p>There are many dangers in collecting and potentially endangering biometric data. First, if this data gets stolen, criminals can impersonate a victim much more convincingly, because they will have the "proof" to "verify" this is really you.</p>
<p>While straight-up stealing your eyeball or face might still belong to science-fiction, the risk of getting the data produced <em>from</em> the scan stolen is very real.</p>
<p>When the World project claims it is secure because biometric data isn't stored anywhere, even if that was true, the iris <em>code</em> derivative of this data is indeed stored and processed somewhere, and this can potentially be stolen.</p>
<p>How hard will it be for a victim to recover an account from a biometric thief when everything is reinforcing the false narrative shared with investors that this technology can't be cheated?</p>
<p>Then, there is the loss of pseudonymity protections online.</p>
<p>If every social media account becomes tied to a unique biometric-based identifier, whether directly or indirectly, there is no pseudonymity anymore.</p>
<p>Further, if only one account is allowed by "verified human", then no one can create separate accounts for their work life and personal life anymore. Creating separate accounts for separate purposes is an excellent privacy-preserving practice.</p>
<p>Even if the identifier isn't tied to a legal name directly, accounts on different platforms using the same identifier could potentially get liked together. To be fair, it does seem Tools for Humanity worked to prevent different platforms from having access to the same code, but how well will this hold the test of time? Will platforms increasingly escalate privacy-invasive requests from this point, like they often do?</p>
<p><strong>Pseudonymity saves lives.</strong> It is an essential tool for the safety of the most vulnerable online. Killing pseudonymity by requiring unique biometric identification could endanger millions.</p>
<p>This is a serious problem coming up with <a href="https://www.privacyguides.org/articles/2025/05/06/age-verification-wants-your-face/">age verification</a> processes as well, which World ID will soon also be a part of when <a href="https://www.engadget.com/cybersecurity/sam-altmans-eyeball-scanning-id-technology-debuts-in-the-us-130032856.html">testing</a> its implementation for Tinder in Japan.</p>
<p>Biometric data should never be used lightly. It should be reserved for the most extreme cases only.</p>
<p>The regions who have adopted stronger regulations for biometric data collection are moving in the right direction. But will protective legislation be enough to resist the pressure from a for-profit VC-backed corporation with a valuation at billions?</p>
<h2 id="flipping-the-coin">Flipping the coin</h2>
<p>Tools for Humanity seems to be well aware of its creepiness factor, and of the criticisms brought by privacy commissioners around the world.</p>
<p>Its recent Orb redesign from the previous cold (Black)mirror finish clearly tries hard to replace creepiness with cuteness.</p>
<p>The company has also evidently invested a lot in presenting a pro-privacy image, likely in an attempt to reassure users (and investors).</p>
<p>Unfortunately, many of these privacy-preserving claims are inaccurate. Some claims promoting "features" that might sound impressive to a neophyte's ear are actually just the baseline, and others sadly are misleading <em>at best</em>.</p>
<p>While a few privacy-preserving efforts are indeed positive, most of the focus on privacy relates to marketing much more than any serious protections.</p>
<h2 id="how-privacy-preserving-is-it">How privacy-preserving is it?</h2>
<p>Most people are still put off by the idea of having their eyeball scanned, and the company has evidently invested a lot in promoting a "privacy-preserving" image, possibly as an attempt to reassure unconvinced humans and <a href="#privacy-legislators-arent-on-board">privacy commissioners</a> alike.</p>
<p>But how much can we trust those claims?</p>
<h3 id="flawed-assumption-about-what-constitutes-personal-data">Flawed assumption about what constitutes personal data</h3>
<p>The largest assumption about why this technology is "privacy-preserving" seems to come from the fact that the World App doesn't collect names, official IDs (<a href="https://www.toolsforhumanity.com/legal/privacy-notice#6-2-credentials-">unless it does</a>), emails (<a href="https://www.toolsforhumanity.com/legal/privacy-notice#annex-i-%E2%80%93-legal-grounds/purposes-for-tools-for-humanity-data-processing-activities-">unless it does</a>), phone numbers (<a href="https://www.toolsforhumanity.com/legal/privacy-notice#5-1-data-you-provide-to-us">unless it does</a>), date of birth (<a href="https://world.org/blog/announcements/worldcoin-new-world-id-unverify-option-increases-personal-control-over-data">unless it does</a>), or other identifiers.</p>
<p>This assumption however neglects the fact that 1) even data that isn't attached to a legal name can be personal data, and 2) the iris code it produces from the iris scan <em>is</em> indeed personal data.</p>
<p>While there are variations, most privacy regulations have similar definitions of what constitute personal data. The European General Data Protection Regulation (<abbr title="General Data Protection Regulation">GDPR</abbr>) <a href="https://gdpr-info.eu/art-4-gdpr/">defines</a> it as "any information relating to an identified or identifiable natural person". An iris code derived from an iris scan of course fits this definition.</p>
<p>Moreover, to create a World ID, the company also collects a face image. Together, the original iris scan and face photo are referred to as <em>Image Data</em>. For "privacy-preserving" purposes, Image Data of course never leaves the Orb device (<a href="https://world.org/legal/biometric-data-consent-form">unless it does</a>).</p>
<p>While it seems some effort has been made to protect the Image Data in some ways, the idea that derivative data from the scans isn't still sensitive personal information anymore is wrong.</p>
<p>If there is a way for a person to scan their iris again and generate the same code, then this data relates to their identifiable person. This also means that <em>someone else</em> could scan their iris and generate the same code.</p>
<p>As whistleblower <a href="https://x.com/Snowden/status/1451990496537088000">Edward Snowden rightfully pointed out</a> in a 2021 tweet:</p>
<p>“This looks like it produces a global (hash) database of people's iris scans (for 'fairness'), and waves away the implications by saying 'we deleted the scans!' Yeah, but you save the <em>hashes</em> produced by the scans. Hashes that match <em>future</em> scans. Don't catalogue eyeballs.”</p>
<h3 id="questionable-reassurance-about-local-data">Questionable reassurance about local data</h3>
<p>One of the biggest reassurance relates to the claim that sensitive biometric data (Image Data) is only stored locally. But this isn't completely accurate either, and there seems to be conflicting information about it from the company's own documentation.</p>
<p>The World <a href="https://whitepaper.world.org/#enrollment-process">white paper</a> specifies that:</p>
<p>"The Orb verifies that it sees a human, runs local fraud prevention checks, and takes pictures of both irises. The iris images are converted on the Orb hardware into the iris code. Raw biometric data does not leave the device (unless explicitly approved by the user for training purposes)."</p>
<p>However, according to the <a href="https://world.org/legal/biometric-data-consent-form">Biometric Data Consent Form</a> users have to sign prior to data collection, if a user needs a fully verified World ID, inevitably this sensitive biometric data will be sent to their phone, therefore leaving the Orb.</p>
<p>After a user agrees to the form, they can keep the option for <em>Data Custody</em> disabled to have their biometric data deleted from the Orb "later", and have it uploaded to their phone (with all the risk that this entails).</p>
<p>The other option users have is to enable Data Custody (if allowed in the user's country) and have this sensitive data sent to both their phone <em>and</em> to Tools for Humanity.</p>
<p>This means the Orb inevitably sends this sensitive data to a mobile device. Then, this data is only as secure as the mobile device is. Which isn't so reassuring.</p>
<p>The documentation does maintain this biometric data is sent as an "end-to-end encrypted data bundle", but this doesn't mean the data never leaves the Orb, it just means it leaves it while encrypted (which is really just the basics), and copies it to the user's device.</p>
<p>Furthermore, future users are <em>strongly</em> incentivized to share their Image Data with Tools for Humanity, for algorithm improvement purposes. Pressure to opt in is even presented as a <em>convenience</em> option, because it would be cumbersome to have to come over for another scan after every update.</p>
<p>As <a href="https://world.org/legal/biometric-data-consent-form">stated</a> in the Biometric Data Consent Form:</p>
<p>"This will likely help you avoid some inconvenience because, if we have your Image Data, then you will not need to return to an Orb to re-verify your digital identity when we update the software."</p>
<p>The company continues to repeat they have a "privacy by default and by design approach". But <strong>you can't keep your privacy-preserving cake and eat it, too</strong>.</p>
<h3 id="what-does-the-white-paper-say">What does the white paper say</h3>
<p>In tech, a white paper is usually a research-based document produced by the developers that presents more technical details on an application, product, or process. It is especially valuable for products like the Orb and the World App, where security and privacy <em>should</em> be paramount, and therefore examined closer.</p>
<p>Because it isn't an independent review, a white paper can also not be worth much more than a marketing pamphlet.</p>
<p>To its credit, Tools for Humanity does <a href="https://whitepaper.world.org/#nature-of-the-whitepaper">warn</a> in its white paper that this information is "intended for general informational purposes and community discussion only and do not constitute a prospectus, an offer document, an offer of securities, a solicitation for investment, or any offer to sell any product, item or asset (whether digital or otherwise)."</p>
<p>Furthermore, the company makes sure to specify that "circumstances may change and that the Whitepaper or the Website may become outdated as a result; and the [World] Foundation is not under any obligation to update or correct this document in connection therewith."</p>
<p>The document is also described as a "crypto-asset white paper".</p>
<p>We have been warned.</p>
<p>In its Privacy section, the white paper <a href="https://whitepaper.world.org/#image-custody-opt-in">states</a> that "no data collected, including images taken by the Orb has or will ever be sold. Nor will it be used for any other intent than to improve World ID."</p>
<p>However, its <a href="https://world.org/legal/privacy-notice#8--when-we-share-your-data">Privacy Notice also states</a> that they may "share your personal information in connection with, or during negotiations concerning, any merger, sale of company assets, financing, or acquisition of all or a portion of our business by another company."</p>
<p>If this happens, many regretful users might find themselves in <a href="https://www.techradar.com/health-fitness/23andme-is-bankrupt-and-about-to-sell-your-dna-heres-how-to-stop-that-from-happening">the same shoes as 23andMe users this year</a>, where the DNA collecting company started to look for buyers of its biometric data assets after filling for bankruptcy.</p>
<p>Additionally, the Face Authentication section of the white paper <a href="https://whitepaper.world.org/#face-authentication">describes</a> a process where encrypted facial biometrics collected from the Orb are used for authentication in the World App.</p>
<p>Even if this data is stored on-device, it is still biometric data getting collected by the Orb then processed by the phone app. There is no question this is sensitive and personal biometric data, and it is indeed kept outside the orb.</p>
<p>Tools for Humanity lacks consistency in the various claims and statements found through its documentation and promotion material. It becomes difficult to know which version to trust, and if it is to be trusted at all.</p>
<h3 id="no-deletion-on-the-blockchain">No deletion on the blockchain</h3>
<p>Tools for Humanity's Privacy Policy declares that the company will delete all account data (when laws allow it) one month after it is closed, this is good. They also state they will delete entirely any inactive account after 2 years, and this is actually a great policy.</p>
<p>But what happens to the World ID, transactions, and other data stored on the blockchain?</p>
<p>While some thoughts have been put into deletion and some good mechanisms seem to have been implemented, unfortunately data stored on the blockchain might be "deletion-resistant".</p>
<p>There's a possibility that <strong>what happens on the blockchain stays on the blockchain, forever</strong>.</p>
<p>The policy <a href="https://www.toolsforhumanity.com/legal/privacy-notice#11--how-long-do-we-keep-your-data-">notes</a> that:</p>
<p>"Due to the public and immutable nature of blockchain technology, we cannot amend, erase, or control the disclosure of data that is stored on blockchains."</p>
<p>So that is something to keep in mind if you value your right to delete.</p>
<h2 id="data-security-considerations">Data security considerations</h2>
<p>Even if some thoughtful security features seem to have been implemented for the World App and its Orbs, nothing processing sensitive data at such a large scale should be left in the hands of a single for-profit, largely unregulated, organization.</p>
<p>This would be like putting 8 billion eggs in a very fragile basket, held by someone paid to make the basket pretty and convince as many people as possible to put their precious single egg in it, with no incentive whatsoever to ensure the basket doesn't break. I would not want to put my egg in there, especially with how much it costs now.</p>
<p>The idea of using one single <em>for-profit</em> app worldwide for "human verification", identity verification, age verification, money transactions, and storing official IDs (and so on and so forth) makes this application a <em>huge</em> target for criminals and hostile governments alike.</p>
<p>It's good that the app had <a href="https://github.com/trailofbits/publications/blob/master/reviews/2023-08-worldcoin-orb-securityreview.pdf">security audits</a>, made some <a href="https://github.com/worldcoin">code available</a> as open source, and reportedly <a href="https://whitepaper.world.org/#why-custom-hardware-is-needed">plans</a> to open a bug bounty program.</p>
<p>However, there are still problems that remain. For example, the phone in this case becomes a single point of failure. The easiest way to steal someone's identity and money (all at once) will be to steal their phone data (whether physically or remotely). Even without criminal intent, what happens when someone just loses their phone? Or accidentally drop it in the pool? Or step on it?</p>
<p>With <strong>everything relying on a single app and a single device</strong>, risk is greatly amplified.</p>
<p>Outside the user's responsibility, Orb operators and Orb stores are susceptible to various attacks. This will increase exponentially with the number of users of course, as the target becomes bigger. In fact, Orb operators have <a href="https://techcrunch.com/2023/05/12/hackers-stole-passwords-of-worldcoin-orb-operators/">already been hacked</a>.</p>
<p>Then, there is the appeal of fake identities and money fraud for criminals. Already, there is a <a href="https://gizmodo.com/worldcoin-black-market-iris-data-identity-orb-1850454037">black market</a> for iris data in China, where people buy iris data (or verified World ID according to World) from people in Cambodia, Kenya, and other countries for a few dollars only. The vulnerability allowing this was reportedly fixed, but it is doubtful this is the last one we hear about.</p>
<p>The Orb itself is also an important potential <abbr title="The total number of possible entry points for unauthorized access to a system">attack surface</abbr>. With Tools for Humanity's ambition to fill the world with Orbs everywhere, will Orbs become the next version of the sketchy ATM? Where you might wonder if this funny-looking Orb is trustworthy enough to pay your bar tab without risking emptying your crypto wallet?</p>
<h2 id="privacy-legislators-arent-on-board">Privacy legislators aren't on board</h2>
<p>Despite all its privacy promotion material, the World project has failed to convince privacy commissioners around the world of their supposedly good intentions. Perhaps in this case actions speak louder than words, and privacy commissioners aren't so gullible.</p>
<p>With the expansion the project plans this year, we can expect even more experts will examine the company's claims and challenge its "privacy-preserving" assumptions</p>
<p>There are many reasons to remain skeptical about these promises of privacy. Indeed, numerous countries have already suspended, fined, or called for investigation on the company's (mal)practices.</p>
<h3 id="the-company-was-fined-for-personal-data-violation">The company was fined for personal data violation</h3>
<p>In 2024, the company was <a href="https://cointelegraph.com/news/south-korea-fines-worldcoin-personal-data-violations">fined</a> 1.1 billion Korean won for violating South Korea's Personal Information Protection Act (PIPA). The Worldcoin Foundation was also imposed corrective orders and recommendations. Organizations that are truly "privacy-first" rarely reach this point.</p>
<p>The Data Custody feature, which allows (and encourages) users to share their biometric data with Tools for Humanity is now unavailable in South Korea.</p>
<h3 id="brazil-has-banned-worldcoin-in-the-country">Brazil has banned Worldcoin in the country</h3>
<p>In January this year, the National Data Protection Authority (ANPD) <a href="https://decrypt.co/305639/brazilian-regulator-denies-worldcoin-appeal-ban">banned</a> Worldcoin's operations in Brazil, after the company's appeal was rejected.</p>
<p>The ban comes from regulation stating that consent to process biometric data must be "free, informed, and unequivocal", which cannot be the case with the World project paying users in cryptocurrency in exchange for their iris scans. Data deletion concerns were also raised by the regulator.</p>
<p>The World project tried again to appeal the decision, in vain.</p>
<h3 id="kenya-and-indonesia-suspended-its-operations">Kenya and Indonesia suspended its operations</h3>
<p>In 2023, Kenya, one of the first country where Worldcoin was available, <a href="https://techcrunch.com/2023/08/02/kenya-suspends-worldcoin-scans-over-security-privacy-and-financial-concerns/">suspended</a> Worldcoin's operations citing concerns over the "authenticity and legality" of its activities related to privacy, security, and financial services.</p>
<p>The worse part is, months before the Office of the Data Protection Commissioner (ODPC) of the country had ordered Tools for Humanity to stop collecting personal information from its citizens. The company simply <a href="https://techcrunch.com/2023/08/15/worldcoin-in-kenya/">ignored the ODPC order</a> and continued to collect biometric data from Kenyans. It only stopped after Kenya's ministry of interior and administration gave the suspension order later on.</p>
<p>This again is quite far from the behavior of a company who genuinely values privacy.</p>
<p>More recently on May 4th 2025, Indonesia also <a href="https://en.antaranews.com/news/353861/indonesia-suspends-worldcoin-world-id-operations-over-public-concerns">suspended</a> the World project's operation in the country over concerns related to user privacy and security. The Ministry of Communication and Digital will be summoning the project's local operators to clarify the operations and determine potential violation of the Indonesia's electronic system regulation.</p>

<p>In December 2024, the German regulator, the Bavarian State Office for Data Protection Supervision (BayLDA), <a href="https://decrypt.co/298090/german-watchdog-cracks-down-on-worldcoin-over-biometric-data">issued an order</a> to obligate proving deletion procedures that comply with the <abbr title="General Data Protection Regulation">GDPR</abbr> within one month. Additionally, the BayLDA ordered the complete deletion of certain data records that were previously collected without sufficient legal basis.</p>
<p>Again, the World Foundation is fighting the order and will <a href="https://cointelegraph.com/news/german-watchdog-order-worldcoin-delete-data">appeal</a> the decision. The company tries to argue the data collected was "anonymized", a common strategy to try evading <abbr title="General Data Protection Regulation">GDPR</abbr> compliance, which does not regulate anonymized data.</p>

<p>In 2023, France's data protection authority the CNIL <a href="https://www.reuters.com/technology/worldcoin-paris-office-checked-by-french-data-watchdog-2023-08-31/">investigated</a> Worldcoin's activities in the country. The same year, UK's privacy watchdog started its own <a href="https://www.reuters.com/technology/uk-data-watchdog-make-enquiries-worldcoin-crypto-project-2023-07-25/">inquiry</a> into the company's operations.</p>
<p>In 2024, Hong Kong's Office of the Privacy Commissioner for Personal Data <a href="https://www.scmp.com/news/hong-kong/law-and-crime/article/3250480/hong-kong-eye-scan-cryptocurrency-scheme-probed-citys-privacy-watchdog">raided</a> six Worldcoin offices citing personal information privacy and security concerns.</p>
<p>There is no doubt more countries and regions will follow with similar investigations and bans as the World project expands to its ambition.</p>
<h3 id="in-the-united-states-the-app-is-restricted-in-some-states">In the United States, the app is restricted in some states</h3>
<p>Even in the US where the company is headquartered, the app is <a href="https://www.wired.com/story/sam-altman-orb-eyeball-scan-launch-us/">restricted</a> in some states. The announcement for its event this month carried a warning the World is “not available for distribution via World App to people, companies or organizations who are residents of, or are located or incorporated in the State of New York or other restricted territories.”</p>
<p>We can also expect the project will encounter roadblocks in states that have passed <a href="https://www.huschblackwell.com/2024-state-biometric-privacy-law-tracker">regulations specific to the collection of biometric data</a>. This includes states like Illinois, Texas, Washington, and Colorado.</p>
<h3 id="some-regions-have-special-regulations-for-biometric-data">Some regions have special regulations for biometric data</h3>
<p>Around the world the number of biometric-specific regulations is growing. Even without a regulation specific to this type of data, many privacy laws have started to include special categories and requirements to govern the collection and processing of sensitive biometric data. As companies are increasingly requesting such collection, legislations to protect users are essential.</p>
<p>For example, the province of Quebec in Canada has recently implemented <a href="https://www.cai.gouv.qc.ca/protection-renseignements-personnels/sujets-et-domaines-dinteret/biometrie?%2F">strong protections for biometric data</a> with its new privacy law, the Law 25. Consent isn't sufficient to collect biometric data, as the law requires organizations to explicitly justify the necessity for such collection in the first place. Importantly, any violation of Law 25 comes with fines as hefty as the <abbr title="General Data Protection Regulation">GDPR</abbr>'s.</p>
<p>More privacy laws should implement such protections quickly, as corporations collecting biometric information carelessly are multiplying fast.</p>
<h2 id="welcome-to-full-dystopia">Welcome to full dystopia</h2>
<p>The most concerning part of the World project's recent expansion isn't its cryptocurrency grift as much as stepping out of it.</p>
<p>If cryptocurrency enthusiasts wish to share their personal data to get into a special cryptocurrency club, they might (although privacy regulations should still protect them). But using financial coercion to get new users by exploiting vulnerable communities living in poverty is <strong>absolutely despicable</strong>.</p>
<p>Further, the fact that the World project has partnered with powerful players in the financial, gaming, and even dating sectors <em>should terrify everyone</em>.</p>
<p>Beyond cryptocurrency, if platforms start to demand users everywhere to verify they are a human and verify they are an adult through the World ID system, then <strong>everyone will soon be subjected to this</strong>.</p>
<p>The amount of money invested in the project means there will be an incredible pressure to spread it everywhere soon, and <em>monetize</em> it. There will be a <em>strong</em> incentive to monetize our data and to monetize our proof of humanity. This isn't trivial.</p>
<p>The well-known dating app Tinder has already partnered with World ID to verify the age of users in Japan. If this experiment works well, and if users comply without objection, this could be soon mandatory for <em>all</em> dating apps.</p>
<p>Let's not stop at dating apps, the World project has already announced last week they will also be working with Razer to verify humanity of online gamers. How far can this go in the age of age verification? Will every online games with mature content soon require a World ID to play?</p>
<p>What about social media? Tools for Humanity's team have insisted the age of AI made us incapable of detecting if we are interacting with bots online. Therefore, they must valiantly come to our rescue to verify our humanity scanning our eyeballs (which bots tragically lack). What if this human verification is expanded to all our social media accounts? Certainly, regulators pushing for authoritarian age verification online would be delighted by such a product.</p>
<p>Then, it comes for our money. The everything app of course offers payment and money management features. This is the app where you can keep your whole wallet, containing all your official IDs, your cryptocurrencies of all kind, and even connect with your less hyped regular bank accounts.</p>
<p>Imagine a single app, owned by a single for-profit corporation, that collects and processes all the data from all your transactions online, all your communications online, that you absolutely have to continue using for your other social media accounts, your gaming life, and your dating life.</p>
<p>There could soon be no way to escape the grasp of World's everything app. Actually, <a href="https://www.theregister.com/2025/05/04/sam_altman_startup_world/">some governments</a> (Taiwan and Malesia) have already started using it for official services, because why not.</p>
<p><strong>The ways this could degenerate fast into full dystopia are infinite</strong>, and very real.</p>
<p>The company even plans to ship next year the Orb Mini, a pocket-size personal spy-device with which users will be able to scan their own eyeballs on the go!</p>
<p>But why stop there? Why not scan other people's eyeballs as well? Maybe all government officials could carry one? Maybe every payment terminal could have one too?</p>
<p>We will find out soon, in one or two years.</p>
<p>Tools for Humanity also bragged about the numerous utilities its new technology could make possible. For example, for event tickets! Order a concert ticket with your "proof of personhood" then maybe confirm you are the owner by having your eyeballs scanned to assist to a Rage Against the Machine concert?</p>
<p>The only fun part in this is the irony.</p>
<p>Tools for Humanity with its expansionist dream is without a doubt hungry enough to eat the whole World™️.</p>
<h3 id="a-new-world-of-wealth-inequalities">A new world of wealth inequalities</h3>
<p>The company brings up a few times the mention of Universal Basic Income (UBI) in its documentation, it even mentions it briefly in its <a href="https://whitepaper.world.org/#ubi">white paper</a>.</p>
<p>While puzzling, it appears Tools for Humanity might consider its cryptocurrency bribe to sign up and subsequent token giveaways as some form of UBI? Or perhaps this is only one of its other ambition to control all the financial systems in the entire world. Why UBI is even mentioned at all in this context is unclear.</p>
<p>Regardless, it's worth mentioning a for-profit company giving cash back in exchange for biometric data isn't UBI at all, it's just a <strong>creepy membership card points</strong>, at best.</p>
<p>While the World project works hard to present the idea this is a tool for the people, where everyone is equal, wealth will definitely <a href="https://whitepaper.world.org/#wld-token-allocation">not be distributed evenly</a> in this new World order.</p>
<p>Already, 11.1% of World's cryptocurrency tokens (WLD) have been distributed to the World's team, 13.6% to investors, and 0.3% are reserved for Tools for Humanity. This means these entities would share together 25% of the wealth, while 75% of the world's population (according the Tools for Humanity's ambition) would have to share 75% of what's left.</p>
<p>In the new "human" world this corporation envisions, Tools for Humanity and its investors would own 1 quarter of the entire world's wealth. There is nothing equitable or communal in a system like this.</p>
<p>It's important not to forget this everything app will do everything to pressure its users in eventually using Worldcoins, its ultimate goal.</p>
<p>From Tinder's mandatory age verification to cryptocurrency financial ruin in one single move.</p>
<h2 id="the-normalization-of-surveillance">The normalization of surveillance</h2>
<p>Even if this process was perfectly secure and perfectly private (which it is definitely not), the problem remains the normalization of surveillance.</p>
<p>This isn't limited to Tools for Humanity, although the way the company tries to advertise itself as a privacy-first organization makes it even more important to scrutinize.</p>
<p>But anyone else with a similar approach to biometric data collection for verifying humanity or age or legal names should be on our radar. Moreover, if it's a for-profit corporation with the power to impose this technology on us everywhere in the world.</p>
<p>One company should never have such power.</p>
<p>Further, biometric data should never be used for trivial purposes like "proof of personhood" or age verification. No amount of supposedly "privacy-preserving" features can change this.</p>
<p>The premise itself is flawed from the start to respect privacy rights.</p>
<p>While the problem of proving identify can still be an important one to solve in <em>some</em> context, the solution to this can never be monopolized by for-profit corporations.</p>
<p>Regardless of Tools for Humanity's intentions and efforts to convince us to trust them, any similar technology is just another step towards a global system of mass surveillance, where ultimately privacy rights and human rights are lost.</p>
<p>So, should you scan your eyeball to get a verified World ID?</p>
<p><strong>No.</strong></p>
<p><strong>No, you really shouldn't.</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['We Currently Have No Container Ships,' Seattle Port Says (220 pts)]]></title>
            <link>https://www.newsweek.com/seattle-port-says-no-container-ships-tariffs-2069464</link>
            <guid>43946601</guid>
            <pubDate>Sat, 10 May 2025 15:49:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.newsweek.com/seattle-port-says-no-container-ships-tariffs-2069464">https://www.newsweek.com/seattle-port-says-no-container-ships-tariffs-2069464</a>, See on <a href="https://news.ycombinator.com/item?id=43946601">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="block-system-main" data-gtm-action="Main_Page_Content"><div>
<article><div id="v_article">      <div><p>
By <span>
<span id="tooltip_reporter_0"><p>Hugh Cameron is Newsweek U.S. news reporter based in London, U.K. with a focus on covering American economic and business news. Hugh joined Newsweek in 2024, having worked at Alliance News Ltd where he specialised in global and regional business developments, economic news, and market trends. He graduated from the University of Warwick with a bachelor's degree in politics in 2022, and from the University of Cambridge with a master's degree in international relations in 2023. Languages: English. You can get in touch with Hugh by emailing <a href="mailto:h.cameron@newsweek.com" data-mce-href="mailto:h.cameron@newsweek.com">h.cameron@newsweek.com</a></p>
</span>

</span></p><p>U.S. News Reporter</p></div>  <div id="audio-player-container">
<p>🎙️ Voice is AI-generated. Inconsistencies may occur.</p>
</div>   <div><p>Another shipping port official voiced concern about the drastic decline in imports as a result of President <a href="https://www.newsweek.com/topic/donald-trump" data-sys="1">Donald Trump</a>'s tariffs.</p><p>"I can see it right over my shoulder here, I'm looking out at the Port of Seattle right now, and we currently have no container ships at berth," Seattle port commissioner Ryan Calkins told <a href="https://www.newsweek.com/topic/cnn" data-sys="1">CNN</a> on Wednesday.</p><p>"That happens every once in a while at normal times, but it's pretty rare," he added. "And so to see it tonight is I think a stark reminder that the impacts of the tariffs have real implications."</p><p><em>Newsweek</em> has reached out to the Port of Seattle via email outside of business hours for further comment.</p><h2><strong>Why It Matters</strong></h2><p>Several port authorities have observed a similar drop in cargo volumes over the past few weeks, warning that such a decline could have significant and adverse effects on consumers—who may face rising prices and limited product availability—as well as the supply chain-linked sectors of the U.S. economy.</p><h2><strong>What To Know</strong></h2><p>Calkins told CNN that the current situation would impact the job security of longshoremen and those dealing directly with the freight, as well as industries responsible for transporting imports nationwide.</p><p>"And that's hundreds of jobs right here in our region and across the country," he said, adding that his port had not witnessed such a significant downturn in activity since the height of the COVID-19 pandemic.</p><figure><div>
<picture width="1200" height="737"><source type="image/webp" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.webp?w=790&amp;f=de4f6f411f352bf8362de54e322f073f 1x"><source type="image/jpeg" media="(min-width: 992px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.jpg?w=790&amp;f=de4f6f411f352bf8362de54e322f073f 1x"><source type="image/webp" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.webp?w=900&amp;f=145863f61cacbe72f2261e9983e5d3c8 1x"><source type="image/jpeg" media="(min-width: 768px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.jpg?w=900&amp;f=145863f61cacbe72f2261e9983e5d3c8 1x"><source type="image/webp" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.webp?w=790&amp;f=de4f6f411f352bf8362de54e322f073f 1x"><source type="image/jpeg" media="(min-width: 481px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.jpg?w=790&amp;f=de4f6f411f352bf8362de54e322f073f 1x"><source type="image/webp" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.webp?w=450&amp;f=dcbc26bd72ffc9f26e2cbfb143474ea3 1x"><source type="image/jpeg" media="(min-width: 0px)" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.jpg?w=450&amp;f=dcbc26bd72ffc9f26e2cbfb143474ea3 1x"><source type="image/webp" srcset="https://d.newsweek.com/en/full/2640751/seattle-port.webp?w=1200&amp;f=7215fd04e51a44ae96d4126efdd90722"><img loading="lazy" id="i2640751" src="https://d.newsweek.com/en/full/2640751/seattle-port.jpg?w=1200&amp;f=7215fd04e51a44ae96d4126efdd90722" alt="seattle port" width="1200" height="737"></picture></div><figcaption>
<span id="short-cap-description">Stacked containers in the Port of Los Angeles, California, on May 6, 2025.</span>

<span>Frederic J. Brown/AFP via Getty Images</span>
</figcaption>  </figure><p>Long Beach Port CEO Mario Cordero similarly compared the current decline in traffic to COVID-era disruptions, <a href="https://www.newsweek.com/busiest-ports-dire-warning-trump-tariffs-2068414" target="_blank" title="America's Busiest Ports Issue 'Dire' Warning Over Trump Tariffs" rel="noopener">describing the situation as "dire"</a> in an interview with <a href="https://www.newsweek.com/topic/nbc" data-sys="1">NBC</a>.</p><p>"<a href="https://www.newsweek.com/boss-biggest-us-port-predicts-when-tariffs-could-bite-consumers-2067641" target="_blank" rel="noopener">You could hear a pin drop</a>," Port of Los Angeles Director Gene Seroka said, telling NPR this week that imports at the ordinarily busy port were down by around 35 percent on an annual basis.</p><p>"The impact the Port of Los Angeles has on the city, the region and the country cannot be understated," Seroka told NPR. "The cargo that moves through this port reaches not only all 50 states, but each one of our 435 congressional districts."</p><h2><strong>What People Are Saying</strong></h2><p><strong>Gene Seroka, executive director of the Port of Los Angeles</strong>, told CNN on Tuesday: "This week, we're down about 35 percent compared to the same time last year, and these cargo ships coming in are the first ones to be attached to the tariffs that were levied against China and other locations last month. That's why the cargo volume is so light."</p><p><strong>Seroka</strong> said last week: "American importers, especially in the retail sector, are telling me that they have about <a href="https://www.newsweek.com/boss-biggest-us-port-predicts-when-tariffs-could-bite-consumers-2067641" target="_blank" rel="noopener">five to seven weeks of normal inventory</a> on hand today."</p><p><strong>Ryan Young, senior economist at the Competitive Enterprise Institute, </strong><a href="https://www.newsweek.com/americans-face-empty-shelves-within-weeks-2067118" target="_blank" rel="noopener">previously told <em>Newsweek</em></a>: "Tariff-related shipping slowdowns will cause a regional cascade effect in the U.S., a little like when COVID-19 first hit. It will first be visible in West Coast ports, which have the fastest shipping times from Asia. After that it will spread to Gulf ports like Houston, which take a little longer to reach, then East Coast ports from the Carolinas up to New England."</p>	<figure data-gtm-category="Related In-Text A" data-gtm-action="Click">
</figure><h2><strong>What Happens Next</strong></h2><p>The administration has been deliberating a deal with China it says could result in duties on its imports dropping significantly. However, Beijing has <a href="https://www.newsweek.com/china-trade-talks-narrative-trump-messages-us-negotiation-2067193" target="_blank" rel="noopener">given equivocal statements</a> regarding its readiness to negotiate with the U.S.</p><p>In his testimony before the House Financial Services Committee on Tuesday, Treasury Secretary <a href="https://www.newsweek.com/topic/scott-bessent" data-sys="1">Scott Bessent</a> said that he, alongside U.S. Trade Representative Jamieson Greer would <a href="https://www.newsweek.com/trump-china-tariff-meeting-geneva-switzerland-bessent-2068860" target="_blank" rel="noopener">commence negotiations with China</a> on Saturday in Geneva, Switzerland.</p>  </div></div>   <div data-pollid="7" data-articleid="2069464" data-gtm-category="FairnessMeter" data-gtmaction="original"><div><div>
<p><img src="https://g.newsweek.com/www/images/NW_ICON_CommonGround.png" alt="Newsweek Logo" width="92" height="113"></p><h2>fairness meter</h2><div><h2>fairness meter</h2><div><p>Newsweek is committed to journalism that's factual and fair.</p><p>Hold us accountable and submit your rating of this article on the meter. <a href="https://www.newsweek.com/fairness-meter" data-gtm-action="Fairness_Meter_original_Support_Page"><span></span></a></p></div></div></div><div><p>Newsweek is committed to journalism that's factual and fair.</p><p>Hold us accountable and submit your rating of this article on the meter. <a href="https://www.newsweek.com/fairness-meter" data-gtm-action="Fairness_Meter_original_Support_Page"><span></span></a></p></div></div><div>
<figure><p><span>Click On Meter </span><span>To Rate This Article</span></p>
</figure></div></div></article></div>     <div data-gtm-action="Top_Stories"><h2>
Top stories</h2></div><section data-gtm-action="About_The_Writer"><h3>About the writer</h3>
<span>
<span id="tooltip_reporter_0"><p>Hugh Cameron is Newsweek U.S. news reporter based in London, U.K. with a focus on covering American economic and business news. Hugh joined Newsweek in 2024, having worked at Alliance News Ltd where he specialised in global and regional business developments, economic news, and market trends. He graduated from the University of Warwick with a bachelor's degree in politics in 2022, and from the University of Cambridge with a master's degree in international relations in 2023. Languages: English. You can get in touch with Hugh by emailing <a href="mailto:h.cameron@newsweek.com" data-mce-href="mailto:h.cameron@newsweek.com">h.cameron@newsweek.com</a></p>
</span>
<a href="javascript:void(0);" rel="author" data-id="reporter_0"> Hugh Cameron </a>
</span>            
<p>
<span id="dots-description"><p>Hugh Cameron is Newsweek U.S. news reporter based in London, U.K. with a focus on covering American economic and business                                    ...
<a onclick="toggleDescription()" id="read-more-btn">Read more</a>
</p></span></p>  </section>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA['It cannot provide nuance': UK experts warn AI therapy chatbots are not safe (147 pts)]]></title>
            <link>https://www.theguardian.com/technology/2025/may/07/experts-warn-therapy-ai-chatbots-are-not-safe-to-use</link>
            <guid>43946498</guid>
            <pubDate>Sat, 10 May 2025 15:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2025/may/07/experts-warn-therapy-ai-chatbots-are-not-safe-to-use">https://www.theguardian.com/technology/2025/may/07/experts-warn-therapy-ai-chatbots-are-not-safe-to-use</a>, See on <a href="https://news.ycombinator.com/item?id=43946498">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Having an issue with your romantic relationship? Need to talk through something? <a href="https://www.theguardian.com/technology/mark-zuckerberg" data-link-name="in body link" data-component="auto-linked-tag">Mark Zuckerberg</a> has a solution for that: a chatbot. Meta’s chief executive believes everyone should have a therapist and if they don’t – artificial intelligence can do that job.</p><p>“I personally have the belief that everyone should probably have a therapist,” he said last week. “It’s like someone they can just talk to throughout the day, or not necessarily throughout the day, but about whatever issues they’re worried about and for people who don’t have a person who’s a therapist, I think everyone will have an AI.”</p><p>The Guardian spoke to mental health clinicians who expressed concern about AI’s emerging role as a digital therapist. <a href="https://www.theguardian.com/uk-news/2016/jan/01/damehood-for-professor-til-wykes-is-a-recognition-of-mental-health-work" data-link-name="in body link">Prof Dame Til Wykes</a>, the head of mental health and psychological sciences at King’s College London, cites the example of an eating disorder chatbot that was <a href="https://www.psychiatrist.com/news/neda-suspends-ai-chatbot-for-giving-harmful-eating-disorder-advice/" data-link-name="in body link">pulled in 2023</a> after giving dangerous advice.</p><p>“I think AI is not at the level where it can provide nuance and it might actually suggest courses of action that are totally inappropriate,” she said.</p><figure id="d717a53d-1bb0-4a3d-996a-6e6c377d467f" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:4,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;Heavy ChatGPT users tend to be more lonely, suggests research&quot;,&quot;elementId&quot;:&quot;d717a53d-1bb0-4a3d-996a-6e6c377d467f&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/technology/2025/mar/25/heavy-chatgpt-users-tend-to-be-more-lonely-suggests-research&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>Wykes also sees chatbots as being potential disruptors to established relationships.</p><p>“One of the reasons you have friends is that you share personal things with each other and you talk them through,” she says. “It’s part of an alliance, a connection. And if you use AI for those sorts of purposes, will it not interfere with that relationship?”</p><p>For many AI users, Zuckerberg is merely marking an increasingly popular use of this powerful technology. There are mental health chatbots such as Noah and Wysa, while the Guardian has spoken to users of AI-powered “grieftech” – or <a href="https://www.theguardian.com/lifeandstyle/article/2024/jun/14/i-felt-i-was-talking-to-him-are-ai-personas-of-the-dead-a-blessing-or-a-curse" data-link-name="in body link">chatbots that revive the dead</a>.</p><p>There is also their casual use as virtual friends <a href="https://www.theguardian.com/technology/article/2024/jun/16/computer-says-yes-how-ai-is-changing-our-romantic-lives" data-link-name="in body link">or partners</a>, with bots such as character.ai and Replika offering personas to interact with. ChatGPT’s owner, OpenAI, admitted last week that a version of its groundbreaking chatbot was responding to users in a <a href="https://www.theguardian.com/commentisfree/2025/may/01/chatgpt-chatbot-truth-user-update-ai" data-link-name="in body link">tone that was “overly flattering”</a> and withdrew it.</p><p>“Seriously, good for you for standing up for yourself and taking control of your own life,” it reportedly responded to a user, who claimed they had stopped taking their medication and had left their family because they were “responsible for the radio signals coming in through the walls”.</p><p>In an interview with the Stratechery newsletter, Zuckerberg, whose company owns Facebook, Instagram and WhatsApp, added that AI would not squeeze people out of your friendship circle but add to it. “That’s not going to replace the friends you have, but it will probably be additive in some way for a lot of people’s lives,” he said.</p><p>Outlining uses for Meta’s AI chatbot – available across its platforms – he said: “One of the uses for <a href="https://www.theguardian.com/technology/meta" data-link-name="in body link" data-component="auto-linked-tag">Meta</a> AI is basically: ‘I want to talk through an issue’; ‘I need to have a hard conversation with someone’; ‘I’m having an issue with my girlfriend’; ‘I need to have a hard conversation with my boss at work’; ‘help me roleplay this’; or ‘help me figure out how I want to approach this’.”</p><p>In a separate interview last week, Zuckerberg said “the average American has three friends, but has demand for 15” and AI could plug that gap.</p><figure id="0bc631b2-4246-43cc-810d-d0844eed007d" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:13,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;‘Dangerous nonsense’: AI-authored books about ADHD for sale on Amazon&quot;,&quot;elementId&quot;:&quot;0bc631b2-4246-43cc-810d-d0844eed007d&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/technology/2025/may/04/dangerous-nonsense-ai-authored-books-about-adhd-for-sale-on-amazon&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;design&quot;:0,&quot;display&quot;:0,&quot;theme&quot;:0}}"></gu-island></figure><p>Dr Jaime Craig, who is about to take over as chair of the UK’s Association of Clinical Psychologists, says it is “crucial” that mental health specialists engage with AI in their field and “ensure that it is informed by best practice”. He flags Wysa as an example of an AI tool that “users value and find more engaging”. But, he adds, more needs to be done on safety.</p><p>“Oversight and regulation will be key to ensure safe and appropriate use of these technologies. Worryingly we have not yet addressed this to date in the UK,” Craig says.</p><p>Last week it was reported that Meta’s AI Studio, which allows users to create chatbots with specific personas, was hosting bots claming to be therapists – with fake credentials. A journalist at 404 Media, a tech news site, said <a href="https://www.404media.co/instagram-ai-studio-therapy-chatbots-lie-about-being-licensed-therapists/" data-link-name="in body link">Instagram had been putting those bots in her feed</a>.</p><p>Meta said its AIs carry a disclaimer that “indicates the responses are generated by AI to help people understand their limitations”.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparison of C/POSIX standard library implementations for Linux (124 pts)]]></title>
            <link>https://www.etalabs.net/compare_libcs.html</link>
            <guid>43946149</guid>
            <pubDate>Sat, 10 May 2025 14:55:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.etalabs.net/compare_libcs.html">https://www.etalabs.net/compare_libcs.html</a>, See on <a href="https://news.ycombinator.com/item?id=43946149">Hacker News</a></p>
<div id="readability-page-1" class="page">




<p>A project of <a href="https://www.etalabs.net/">Eta Labs</a>.

</p><p>The table below and notes which follow are a comparison of some of
the different standard library implementations available for Linux,
with a particular focus on the balance between feature-richness and
bloat. I have tried to be fair and objective, but as I am the author
of <b><a href="http://www.musl-libc.org/">musl</a></b>, that may have
influenced my choice of which aspects to compare.

</p><p>Future directions for this comparison include detailed performance
benchmarking and inclusion of additional library implementations,
especially Google's Bionic and other BSD libc ports.

</p><div><table>

<colgroup><col><col><col><col><col>

</colgroup><tbody><tr><th>Bloat comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Complete .a set
</th><td>426k
</td><td>500k
</td><td>120k
</td><td>2.0M †

</td></tr><tr><th>Complete .so set
</th><td>527k
</td><td>560k
</td><td>185k
</td><td>7.9M †

</td></tr><tr><th>Smallest static C program
</th><td>1.8k
</td><td>5k
</td><td>0.2k
</td><td>662k

</td></tr><tr><th>Static hello (using printf)
</th><td>13k
</td><td>70k
</td><td>6k
</td><td>662k

</td></tr><tr><th>Dynamic overhead (min. dirty)
</th><td>20k
</td><td>40k
</td><td>40k
</td><td>48k

</td></tr><tr><th>Static overhead (min. dirty)
</th><td>8k
</td><td>12k
</td><td>8k
</td><td>28k

</td></tr><tr><th>Static stdio overhead (min. dirty)
</th><td>8k
</td><td>24k
</td><td>16k
</td><td>36k

</td></tr><tr><th>Configurable featureset
</th><td>no
</td><td>yes
</td><td>minimal
</td><td>minimal


</td></tr><tr><th>Behavior on resource exhaustion
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Thread-local storage
</th><td>reports failure
</td><td>aborts
</td><td>n/a
</td><td>aborts

</td></tr><tr><th>SIGEV_THREAD timers
</th><td>no failure
</td><td>n/a
</td><td>n/a
</td><td>lost overruns

</td></tr><tr><th>pthread_cancel
</th><td>no failure
</td><td>aborts
</td><td>n/a
</td><td>aborts

</td></tr><tr><th>regcomp and regexec
</th><td>reports failure
</td><td>crashes
</td><td>reports failure
</td><td>crashes

</td></tr><tr><th>fnmatch
</th><td>no failure
</td><td>unknown
</td><td>no failure
</td><td>reports failure

</td></tr><tr><th>printf family
</th><td>no failure
</td><td>no failure
</td><td>no failure
</td><td>reports failure

</td></tr><tr><th>strtol family
</th><td>no failure
</td><td>no failure
</td><td>no failure
</td><td>no failure





</td></tr><tr><th>Performance comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Tiny allocation &amp; free
</th><td>0.005
</td><td>0.004
</td><td>0.013
</td><td>0.002

</td></tr><tr><th>Big allocation &amp; free
</th><td>0.027
</td><td>0.018
</td><td>0.023
</td><td>0.016

</td></tr><tr><th>Allocation contention, local
</th><td>0.048
</td><td>0.134
</td><td>0.393
</td><td>0.041

</td></tr><tr><th>Allocation contention, shared
</th><td>0.050
</td><td>0.132
</td><td>0.394
</td><td>0.062

</td></tr><tr><th>Zero-fill (memset)
</th><td>0.023
</td><td>0.048
</td><td>0.055
</td><td>0.012

</td></tr><tr><th>String length (strlen)
</th><td>0.081
</td><td>0.098
</td><td>0.161
</td><td>0.048

</td></tr><tr><th>Byte search (strchr)
</th><td>0.142
</td><td>0.243
</td><td>0.198
</td><td>0.028

</td></tr><tr><th>Substring (strstr)
</th><td>0.057
</td><td>1.273
</td><td>1.030
</td><td>0.088

</td></tr><tr><th>Thread creation/joining
</th><td>0.248
</td><td>0.126
</td><td>45.761
</td><td>0.142

</td></tr><tr><th>Mutex lock/unlock
</th><td>0.042
</td><td>0.055
</td><td>0.785
</td><td>0.046

</td></tr><tr><th>UTF-8 decode buffered
</th><td>0.073
</td><td>0.140
</td><td>0.257
</td><td>0.351

</td></tr><tr><th>UTF-8 decode byte-by-byte
</th><td>0.153
</td><td>0.395
</td><td>0.236
</td><td>0.563

</td></tr><tr><th>Stdio putc/getc
</th><td>0.270
</td><td>0.808
</td><td>7.791
</td><td>0.497

</td></tr><tr><th>Stdio putc/getc unlocked
</th><td>0.200
</td><td>0.282
</td><td>0.269
</td><td>0.144

</td></tr><tr><th>Regex compile
</th><td>0.058
</td><td>0.041
</td><td>0.014
</td><td>0.039

<!--
<tr><th>Regex search
<td class=half>0.180
<td class=good>0.007
<td class=good>0.
<td class=good>0.014
-->

</td></tr><tr><th>Regex search (a{25}b)
</th><td>0.188
</td><td>0.188
</td><td>0.967
</td><td>0.137

</td></tr><tr><th>Self-exec (static linked)
</th><td>234µs
</td><td>245µs
</td><td>272µs
</td><td>457µs

</td></tr><tr><th>Self-exec (dynamic linked)
</th><td>446µs
</td><td>590µs
</td><td>675µs
</td><td>864µs




</td></tr><tr><th>ABI and versioning comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Stable ABI
</th><td>yes
</td><td>no
</td><td>unofficially
</td><td>yes

</td></tr><tr><th>LSB-compatible ABI
</th><td>incomplete
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>Backwards compatibility
</th><td>yes
</td><td>no
</td><td>unofficially
</td><td>yes

</td></tr><tr><th>Forwards compatibility
</th><td>yes
</td><td>no
</td><td>unofficially
</td><td>no

</td></tr><tr><th>Atomic upgrades
</th><td>yes
</td><td>no
</td><td>no
</td><td>no

</td></tr><tr><th>Symbol versioning
</th><td>no
</td><td>no
</td><td>no
</td><td>yes



</td></tr><tr><th>Algorithms comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Substring search (strstr)
</th><td>twoway
</td><td>naive
</td><td>naive
</td><td>twoway

</td></tr><tr><th>Regular expressions
</th><td>dfa
</td><td>dfa
</td><td>backtracking
</td><td>dfa

</td></tr><tr><th>Sorting (qsort)
</th><td>smoothsort
</td><td>shellsort
</td><td>naive quicksort
</td><td>introsort

</td></tr><tr><th>Allocator (malloc)
</th><td>musl-native
</td><td>dlmalloc
</td><td>diet-native
</td><td>ptmalloc






</td></tr><tr><th>Features comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Conformant printf
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>Exact floating point printing
</th><td>yes
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>C99 math library
</th><td>yes
</td><td>partial
</td><td>no
</td><td>yes

</td></tr><tr><th>C11 threads API
</th><td>yes
</td><td>no
</td><td>no
</td><td>no

</td></tr><tr><th>C11 thread-local storage
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>GCC libstdc++ compatibility
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>POSIX threads
</th><td>yes
</td><td>yes, on most archs
</td><td>broken
</td><td>yes

</td></tr><tr><th>POSIX process scheduling
</th><td>stub
</td><td>incorrect
</td><td>no
</td><td>incorrect

</td></tr><tr><th>POSIX thread priority scheduling
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>POSIX localedef
</th><td>no
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>Wide character interfaces
</th><td>yes
</td><td>yes
</td><td>minimal
</td><td>yes

</td></tr><tr><th>Legacy 8-bit codepages
</th><td>no
</td><td>yes
</td><td>minimal
</td><td>slow, via gconv

</td></tr><tr><th>Legacy CJK encodings
</th><td>no
</td><td>no
</td><td>no
</td><td>slow, via gconv

</td></tr><tr><th>UTF-8 multibyte
</th><td>native; 100% conformant
</td><td>native; nonconformant
</td><td>dangerously nonconformant
</td><td>slow, via gconv; nonconformant

</td></tr><tr><th>Iconv character conversions
</th><td>most major encodings
</td><td>mainly UTFs
</td><td>no
</td><td>the kitchen sink

</td></tr><tr><th>Iconv transliteration extension
</th><td>no
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>Openwall-style TCB shadow
</th><td>yes
</td><td>no
</td><td>no
</td><td>no

</td></tr><tr><th>Sun RPC, NIS
</th><td>no
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>Zoneinfo (advanced timezones)
</th><td>yes
</td><td>no
</td><td>yes
</td><td>yes

</td></tr><tr><th>Gmon profiling
</th><td>no
</td><td>no
</td><td>yes
</td><td>yes

</td></tr><tr><th>Debugging features
</th><td>no
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>Various Linux extensions
</th><td>yes
</td><td>yes
</td><td>partial
</td><td>yes

</td></tr><tr><th>Target architectures comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>i386
</th><td>yes
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>x86_64
</th><td>yes
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>x86_64 x32 ABI (ILP32)
</th><td>experimental
</td><td>no
</td><td>no
</td><td>non-conforming

</td></tr><tr><th>ARM
</th><td>yes
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>Aarch64 (64-bit ARM)
</th><td>yes
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>MIPS
</th><td>yes
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>SuperH
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>Microblaze
</th><td>yes
</td><td>partial
</td><td>no
</td><td>yes

</td></tr><tr><th>PowerPC (32- and 64-bit)
</th><td>yes
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>Sparc
</th><td>no
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>Alpha
</th><td>no
</td><td>yes
</td><td>yes
</td><td>yes

</td></tr><tr><th>S/390 (32-bit)
</th><td>no
</td><td>no
</td><td>yes
</td><td>yes

</td></tr><tr><th>S/390x (64-bit)
</th><td>yes
</td><td>no
</td><td>yes
</td><td>yes

</td></tr><tr><th>OpenRISC 1000 (or1k)
</th><td>yes
</td><td>no
</td><td>no
</td><td>not upstream

</td></tr><tr><th>Motorola 680x0 (m68k)
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>MMU-less microcontrollers
</th><td>yes, elf/fdpic
</td><td>yes, bflt
</td><td>no
</td><td>no

</td></tr><tr><th>Build environment comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Legacy-code-friendly headers
</th><td>partial
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>Lightweight headers
</th><td>yes
</td><td>no
</td><td>yes
</td><td>no

</td></tr><tr><th>Usable without native toolchain
</th><td>yes
</td><td>no
</td><td>yes
</td><td>no

</td></tr><tr><th>Respect for C namespace
</th><td>yes
</td><td>LFS64 problems
</td><td>no
</td><td>LFS64 problems

</td></tr><tr><th>Respect for POSIX namespace
</th><td>yes
</td><td>LFS64 problems
</td><td>no
</td><td>LFS64 problems


</td></tr><tr><th>Security/hardening comparison
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>Attention to corner cases
</th><td>yes
</td><td>yes
</td><td>no
</td><td>too much malloc

</td></tr><tr><th>Safe UTF-8 decoder
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>Avoids superlinear big-O's
</th><td>yes
</td><td>sometimes
</td><td>no
</td><td>yes

</td></tr><tr><th>Stack smashing protection
</th><td>yes
</td><td>yes
</td><td>no
</td><td>yes

</td></tr><tr><th>Heap corruption detection
</th><td>yes
</td><td>no
</td><td>no
</td><td>yes

</td></tr><tr><th>Misc. comparisons
</th><th>musl</th><th>uClibc</th><th>dietlibc</th><th>glibc

</th></tr><tr><th>License
</th><td>MIT
</td><td>LGPL 2.1
</td><td>GPL 2
</td><td>LGPL 2.1+ w/exceptions

</td></tr></tbody></table></div>


<h2>Notes</h2>

<h3>In general</h3>

<p>For each comparison in the table, each library is marked in red,
yellow, or green. Red or yellow indicates that the library fails to
support a feature or satisfy an optimality condition that may be
desirable to <i>some users</i>.

</p><p>For comparisons involving testing and measurement, the particular
library versions compared are:

</p><ul>
<li>musl 1.1.5
</li><li>uClibc 0.9.33.2 (Buildroot 2015.02)
</li><li>dietlibc 0.32
</li><li>glibc 2.19
</li></ul>

<p>Note that previous versions of this comparison included eglibc
rather than glibc, mainly since Debian-based distributions were using
the eglibc fork during the time in which glibc was essentially
unmaintained. Since most of eglibc has been merged back into glibc and
eglibc is being discontinued, the comparison has been updated based on
glibc.


</p><h3>Bloat comparison</h3>

<p>Roughly speaking, “bloat” is used to refer to overhead cost that
does not contribute to the functioning of an application.

</p><p>All figures are approximate based on the tests of versions of these
libraries available on systems I use. I've used <tt>size(1)</tt>
instead of file size since static library files are roughly 80% ELF
header overhead for the contained object files. Part of what makes the
shared libraries larger than their static equivalents is that they
include parts of libgcc for long division and other math functions.

</p><p>The size totals for glibc include the size of iconv modules,
roughly 5M, in the “Complete .so set” figure. These are essential to
providing certain functionality, and should be installed whether
static or dynamic linking is being used.

</p><p>The smallest C program is:</p>

<pre>int main() {}</pre>

<p>And the "hello" program I used is:</p>

<pre>#include &lt;stdio.h&gt;
int main(int argc, char **argv) { printf("hello %d\n", argc); }</pre>

<p>I've written it this way to ensure that the compiler cannot
optimize the string printed to a constant and replace the call
to <tt>printf</tt> with a call to <tt>puts</tt>.

</p><p>Overhead is measured in dirty pages, i.e. the amount of swap-backed
physical memory each process requires. These are a mix of private
copy-on-write maps of the program image on disk, the heap, the stack,
and anonymous maps. The <tt>/proc/$pid/smaps</tt> file was used to
obtain the numbers for a program spinning in an infinite loop.

</p><p>Dynamic linking overhead is largely dependent on the dynamic
linker. A good 12-16k of the dynamic overhead is due to inefficiency
in the standard dynamic linker. Ideally, replacing it could drop the
overhead difference between static- and dynamic-linked programs to a
single page.

</p><p>It should be noted that uClibc was tested with many optional
features enabled, particularly locale. Due to a bug (design flaw) in
uClibc's locale support, locale loading code and <tt>malloc</tt> get
linked even in programs which never use <tt>setlocale</tt>.

</p><h3>Behavior on resource exhaustion</h3>

<p>These comparions deal with the robstness of various interfaces when
the amount of free memory or other system resources are extremely low.
Reporting failure is shaded green when it is the theoretical optimal
behavior; it is shaded yellow when an alternate implementation could
successfully perform the operation with no resource usage.

</p><p>Thread-local storage covers both the case of attempting to create a
new thread when there is insufficient memory available to satisfy the
thread-local storage requirements of all loaded modules, and the case
of attempting to load a new module with thread-local storage
via <tt>dlopen</tt> when there is insufficient memory available to
satisfy the storage requirements of all extant threads.

</p><p>In the case of <tt>pthread_cancel</tt>, NPTL dynamically
loads <tt>libgcc_s.so.1</tt> at runtime upon the first cancellation
request, and aborts the program if loading fails for any reason,
including but not limited to resource exhaustion.



</p><h3>Performance comparison</h3>

<p>All of these figures were obtained using
my <a href="https://www.etalabs.net/libc-bench.html"><tt>libc-bench</tt></a> suite, in UTF-8
locales, on one particular Intel Atom N280-based machine. They are not
intended to be rigorous, only to give a rough idea of relative
order-of-magnitude performance.

</p><p>The tiny and big allocation figures are
from <tt>b_malloc_tiny1</tt> and <tt>b_malloc_big1</tt>. The
allocation contention tests measure malloc performance when two
threads are simultaneously performing allocation and free operations.
In the first test (local), each thread frees its own allocations. In
the second (shared), the allocating and freeing thread are often not
the same, breaking thread-local arena/cache optimizations.

</p><p>The strstr figure is the max time taken by any of the strstr tests,
in the interest of measuring worst-case time; which case is worst
varies by implementation. glibc's bad performance could be fixed
trivially by removing the code that disables the best optimization for
needles shorter than 32 bytes; with this change it should match or
slightly outperform musl.

</p><p>The thread create and join figure is
from <tt>b_pthread_createjoin_serial1</tt>.

</p><h3>ABI and versioning comparison</h3>

<p>Backwards compatibility means the usual thing, that new versions of
the library are compatible with programs compiled against an older
version. "Forwards compatibility" is a term I may have invented, but
the idea it's intended to convey is that old versions of the library
are compatible with programs compiled against a newer version, as long
as the program does not depend on features that were missing from the
older library version. In the latter case, the program would simply
fail at (static or dynamic) link time with missing symbols.

</p><p>Perhaps the simplest way to think of "forwards compatibility" is
that it means you're not required to upgrade the library unless a
program actually needs functionality that's missing in your version.

</p><p>Symbol versioning and forwards compatibility both have merits, but
they're essentially mutually exclusive.

</p><p>"Atomic upgrades" means that a single atomic filesystem operation
upgrades the library, with no race condition window during which
dynamic-linked programs might fail to run. The canonical way to ensure
atomic upgrades is having the whole library in a single <tt>.so</tt>
file.

</p><h3>Algorithms comparison</h3>

<p>When comparing substring search algorithms, <i>m</i> typically
refers to the length of the needle (substring) and <i>n</i> typically
refers to the length of the haystack (string to be searched). The
two-way algorithm is <i>O(n)</i>, and with the Boyer-Moore-like
improvements musl uses (and which glibc uses, but only for extremely
long needles), typical runtime is proportional to <i>n/m</i>. The
naive algorithm is <i>O(nm)</i>.

</p><p>Backtracking regular expression implementations are simple to
write, but have pathologically bad performance on many simile
real-world expressions, and fail to take advantage of the regularity
of the language.

</p><p>The naive quicksort dietlibc uses has <i>O(n)</i> space requirement
on the stack, meaning it can and will lead to stack-overflow crashes
in real-world usage. This can be fixed by choosing the optimal order
of recursion and performing tail-call optimizations. Quicksort is
also <i>O(n²)</i> in time, and while typical performance is much
better, worst-case performance is very bad. Shell sort is
typically <i>O(n<sup>α</sup>)</i> where 1&lt;<i>α</i>&lt;2, though it
can be optimized to <i>O(n(log n)²)</i>. Determining the
characteristics of uClibc's version would require some analysis.
Smooth sort is <i>O(n log n)</i> and interpolates smoothly down
to <i>O(n)</i> proportional roughly to the degree to which the input
is already sorted. Intro sort is a variant of quicksort which detects
worst-case recursion and switches to heap sort to maintain <i>O(n log
n)</i> bounds.

</p><h3>Features comparison</h3>

<p>Exact floating point printing refers to the ability to print the
exact value of floating point numbers with <tt>printf</tt> when the
specified precision is high enough. For instance, as a
double-precision value, <tt>0.1</tt> is
0.1000000000000000055511151231257827021181583404541015625, which is
the diadic rational 115292150460684704/2<sup>60</sup>. Perhaps more
usefully, the (exactly representable) number 2<sup>-60</sup> should
print as
0.000000000000000000867361737988403547205962240695953369140625 rather
than some inexact approximation.

</p><p>A complete C99 math library consists of the new single-precision
and extended-precision versions of all the previously existing math
functions, as well as their complex versions and <tt>tgmath.h</tt>.

</p><p>POSIX threads refers to threads with real POSIX semantics, not the
historical broken LinuxThreads (where each thread behaves like a
distinct process) or similar implementations.

</p><p>POSIX localedef refers to the ability to define custom locales,
including charsets, etc.

</p><p><a href="http://www.openwall.com/tcb/">TCB passwords</a> are a
feature from <a href="http://www.openwall.com/">Openwall</a> which
move the password hashes from <tt>/etc/shadow</tt>
to <tt>/etc/tcb/<i>username</i>/shadow</tt>. This allows users to
change passwords and allows programs running as the user (for example,
screen lockers) to authenticate the user's password without special
suid or sgid privileges.

</p><p>Linux extensions refer to kernel interfaces provided by Linux
outside the scope of POSIX and historical behavior
- <tt>epoll</tt>, <tt>signalfd</tt>, extended attributes,
capabilities, module loading, and so on.

</p><h3>Target architectures comparison</h3>

<p>There are a number of conformance issues in glibc's x32 support,
the most notable being that it defines the <tt>tv_nsec</tt> member
of <tt>struct timespec</tt> as <tt>long long</tt> despite both POSIX
and C11 requiring it to have type <tt>long</tt>. This discrepency
affects use with formatted printing functions and use of pointers to
the member, among other things. A number of other interfaces also have
been changed to use <tt>long long</tt> instead of <tt>long</tt> in
structures; in many cases there is no standard governing the affected
interface, but the changes break the interface contract published in
other documentation such a Linux man pages.

</p><p>uClibc's microblaze port is marked partial because it lacks support
for threads and possibly other core features.

</p><p>Ports marked "experimental" are those documented as such; this may
mean some functionality is broken and/or ABI is not stable.

</p><h3>Build environment comparison</h3>

<p>"Legacy-code-friendly headers" means that the system C header files
evolved out of historical practice, and by default define/declare many
things they shouldn't but which some legacy code might expect. They
typically rely on deep levels of nested inclusion and complex
conditional compilation.

</p><p>"Lightweight headers" are roughly the opposite, written from
scratch to match the C and POSIX standards, with minimal nested
inclusion and preprocessor conditionals. This leads to an enormous
performance advantage compiling large numbers of small files, but it
also means poorly-written programs that relied on certain
implementation-specific legacy characteristics might need minor fixes
to compile.

</p><p>Some of the libraries reviewed are virtually impossible to use
without having built GNU binutils and gcc specifically targetting them
(i.e. a native toolchain). Others make it easy to use an existing
toolchain originally targetting a different library, overriding
certain compiler and linker options to use the alternate library
implementation.

</p><p>Respect for the C and POSIX namespaces means that the namespace
used by the standard C and standard POSIX functions and headers
conforms to what these standards say about which names are reserved
for the implementation versus reserved for the application. One common
area of non-conformance is remapping functions
like <tt>open</tt>, <tt>lseek</tt>, etc.
to <tt>open64</tt>, <tt>lseek64</tt>, etc. - names which are reserved
for the application. This is flagged as "LFS64 problems" in the table.

</p><h3>Security/hardening comparison</h3>

<p>"Attention to corner cases" means that the library follows a
general philosophy of being careful to support all possible inputs
that don't explicitly invoke <i>undefined behavior</i>, especially
when the input may come from a source external to the program.
Over-use of <tt>malloc</tt> is flagged in the comparison when some
interfaces that should not have any failure cases have created
artificial ones due to the possibility of memory exhaustion.

</p><p>An unsafe UTF-8 decoder is one which fails to detect invalid
sequences and happens to decode them as aliases for valid characters.

</p><p>Heap corruption detection means <tt>malloc</tt> makes an effort to
detect, report, and abort when it detects double-free, attempts to
free a pointer not obtained via <tt>malloc</tt>, etc.

</p><h3>Misc. comparisons</h3>

<p>The choice of license affects the usability of a standard library
implementation. GPL v2-only is shaded as the "worst" choice, in that
it is incompatible with a large volume of Open Source/Free Software,
namely anything using GPL v3-only. LGPL v2.1-only is much less
problematic; it does not allow creation of a new LGPL-licensed library
by merging with LGPL v3-only code, but it allows the merged program to
be released under version 3 or later of the GPL. LGPL v2.1-or-later is
very flexible, and MIT or BSD even moreso.






</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Code Claude Code (106 pts)]]></title>
            <link>https://github.com/RVCA212/codesys</link>
            <guid>43946066</guid>
            <pubDate>Sat, 10 May 2025 14:47:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/RVCA212/codesys">https://github.com/RVCA212/codesys</a>, See on <a href="https://news.ycombinator.com/item?id=43946066">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">codesys SDK</h2><a id="user-content-codesys-sdk" aria-label="Permalink: codesys SDK" href="#codesys-sdk"></a></p>
<p dir="auto">A Python SDK for interacting with the Claude CLI tool.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>Python 3.8+</li>
<li>Claude CLI tool must be installed, available in your PATH, and set up with your api key.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from codesys import Agent

# Initialize with a working directory
agent = Agent(working_dir=&quot;/Users/seansullivan/lmsys-sdk/&quot;)

# This can be a prompt string or claude code command (treat it as your claude code input)
lines = agent.run(&quot;&quot;&quot;/init&quot;&quot;&quot;, stream=True)"><pre><span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>

<span># Initialize with a working directory</span>
<span>agent</span> <span>=</span> <span>Agent</span>(<span>working_dir</span><span>=</span><span>"/Users/seansullivan/lmsys-sdk/"</span>)

<span># This can be a prompt string or claude code command (treat it as your claude code input)</span>
<span>lines</span> <span>=</span> <span>agent</span>.<span>run</span>(<span>"""/init"""</span>, <span>stream</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Practical Use:</h3><a id="user-content-practical-use" aria-label="Permalink: Practical Use:" href="#practical-use"></a></p>
<p dir="auto">the most effective way I've found of using this sdk is by mimicing my actual workflow with claude code which I've found extremely effective.</p>
<p dir="auto">the workflow is simple: plan the task by exploring the codebase, then implement the plan</p>
<div dir="auto" data-snippet-clipboard-copy-content="
#!/usr/bin/env python3

import argparse
import os
from codesys import Agent



# Hardcoded defaults - modify these values directly in the code if desired
DEFAULT_WORKING_DIR = os.getcwd()  # Use the current working directory by default


DEFAULT_USER_MESSAGE = &quot;Describe your task here&quot;




def generate_plan(working_dir, user_message):
    prompt = f'''
generate a plan into plan.md file given the following task:
<task>
{user_message}
</task>
Given this task, explore the codebase and create a plan for the implementation into plan.md. ultrathink
'''
    Agent(working_dir=working_dir).run(prompt, stream=True)





def execute_plan(working_dir):
    prompt = '''
Implement the task laid out in plan.md: ultrathink
'''
    Agent(working_dir=working_dir).run(prompt, stream=True)



# Run the File
def main():
    parser = argparse.ArgumentParser(description='Generate and execute a plan based on a task.')
    parser.add_argument('--working-dir', '-w', help='Working directory for the agent')
    parser.add_argument('--message', '-m', help='Task message to generate plan for')

    args = parser.parse_args()

    # Use command-line args if provided, otherwise use hardcoded defaults
    working_dir = args.working_dir if args.working_dir else DEFAULT_WORKING_DIR
    user_message = args.message if args.message else DEFAULT_USER_MESSAGE

    print(f&quot;Working directory: {working_dir}&quot;)
    print(f&quot;Generating plan for task: {user_message}&quot;)
    generate_plan(working_dir, user_message)

    print(&quot;Executing plan from plan.md&quot;)
    execute_plan(working_dir)

if __name__ == &quot;__main__&quot;:
    main()"><pre><span>#!/usr/bin/env python3</span>

<span>import</span> <span>argparse</span>
<span>import</span> <span>os</span>
<span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>



<span># Hardcoded defaults - modify these values directly in the code if desired</span>
<span>DEFAULT_WORKING_DIR</span> <span>=</span> <span>os</span>.<span>getcwd</span>()  <span># Use the current working directory by default</span>


<span>DEFAULT_USER_MESSAGE</span> <span>=</span> <span>"Describe your task here"</span>




<span>def</span> <span>generate_plan</span>(<span>working_dir</span>, <span>user_message</span>):
    <span>prompt</span> <span>=</span> <span>f'''</span>
<span>generate a plan into plan.md file given the following task:</span>
<span>&lt;task&gt;</span>
<span><span><span>{</span><span>user_message</span><span>}</span></span></span>
<span>&lt;/task&gt;</span>
<span>Given this task, explore the codebase and create a plan for the implementation into plan.md. ultrathink</span>
<span>'''</span>
    <span>Agent</span>(<span>working_dir</span><span>=</span><span>working_dir</span>).<span>run</span>(<span>prompt</span>, <span>stream</span><span>=</span><span>True</span>)





<span>def</span> <span>execute_plan</span>(<span>working_dir</span>):
    <span>prompt</span> <span>=</span> <span>'''</span>
<span>Implement the task laid out in plan.md: ultrathink</span>
<span>'''</span>
    <span>Agent</span>(<span>working_dir</span><span>=</span><span>working_dir</span>).<span>run</span>(<span>prompt</span>, <span>stream</span><span>=</span><span>True</span>)



<span># Run the File</span>
<span>def</span> <span>main</span>():
    <span>parser</span> <span>=</span> <span>argparse</span>.<span>ArgumentParser</span>(<span>description</span><span>=</span><span>'Generate and execute a plan based on a task.'</span>)
    <span>parser</span>.<span>add_argument</span>(<span>'--working-dir'</span>, <span>'-w'</span>, <span>help</span><span>=</span><span>'Working directory for the agent'</span>)
    <span>parser</span>.<span>add_argument</span>(<span>'--message'</span>, <span>'-m'</span>, <span>help</span><span>=</span><span>'Task message to generate plan for'</span>)

    <span>args</span> <span>=</span> <span>parser</span>.<span>parse_args</span>()

    <span># Use command-line args if provided, otherwise use hardcoded defaults</span>
    <span>working_dir</span> <span>=</span> <span>args</span>.<span>working_dir</span> <span>if</span> <span>args</span>.<span>working_dir</span> <span>else</span> <span>DEFAULT_WORKING_DIR</span>
    <span>user_message</span> <span>=</span> <span>args</span>.<span>message</span> <span>if</span> <span>args</span>.<span>message</span> <span>else</span> <span>DEFAULT_USER_MESSAGE</span>

    <span>print</span>(<span>f"Working directory: <span><span>{</span><span>working_dir</span><span>}</span></span>"</span>)
    <span>print</span>(<span>f"Generating plan for task: <span><span>{</span><span>user_message</span><span>}</span></span>"</span>)
    <span>generate_plan</span>(<span>working_dir</span>, <span>user_message</span>)

    <span>print</span>(<span>"Executing plan from plan.md"</span>)
    <span>execute_plan</span>(<span>working_dir</span>)

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>main</span>()</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Simple interface to the Claude CLI tool</li>
<li>Support for all Claude CLI options</li>
<li>Automatic or manual streaming output</li>
<li>Customizable tool access</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">API Reference</h2><a id="user-content-api-reference" aria-label="Permalink: API Reference" href="#api-reference"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Agent Class</h3><a id="user-content-agent-class" aria-label="Permalink: Agent Class" href="#agent-class"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="Agent(working_dir=None, allowed_tools=None)"><pre><span>Agent</span>(<span>working_dir</span><span>=</span><span>None</span>, <span>allowed_tools</span><span>=</span><span>None</span>)</pre></div>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>working_dir</code> (str, optional): The working directory for Claude to use. Defaults to current directory.</li>
<li><code>allowed_tools</code> (list, optional): List of tools to allow Claude to use. Defaults to ["Edit", "Bash", "Write"].</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Methods</h3><a id="user-content-methods" aria-label="Permalink: Methods" href="#methods"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">run</h4><a id="user-content-run" aria-label="Permalink: run" href="#run"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="run(prompt, stream=False, output_format=None, additional_args=None, auto_print=True)"><pre><span>run</span>(<span>prompt</span>, <span>stream</span><span>=</span><span>False</span>, <span>output_format</span><span>=</span><span>None</span>, <span>additional_args</span><span>=</span><span>None</span>, <span>auto_print</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">Run Claude with the specified prompt.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>prompt</code> (str): The prompt to send to Claude.</li>
<li><code>stream</code> (bool): If True, handles streaming output. If False, returns the complete output.</li>
<li><code>output_format</code> (str, optional): Optional output format (e.g., "stream-json").</li>
<li><code>additional_args</code> (dict, optional): Additional arguments to pass to the Claude CLI.</li>
<li><code>auto_print</code> (bool): If True and stream=True, automatically prints output. If False, you need to handle streaming manually.</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li>If <code>stream=False</code>: Returns the complete output as a string.</li>
<li>If <code>stream=True</code> and <code>auto_print=False</code>: Returns a subprocess.Popen object for manual streaming.</li>
<li>If <code>stream=True</code> and <code>auto_print=True</code>: Automatically prints output and returns collected lines as a list.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">run_with_tools</h4><a id="user-content-run_with_tools" aria-label="Permalink: run_with_tools" href="#run_with_tools"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="run_with_tools(prompt, tools, stream=False, auto_print=True)"><pre><span>run_with_tools</span>(<span>prompt</span>, <span>tools</span>, <span>stream</span><span>=</span><span>False</span>, <span>auto_print</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">Run Claude with specific allowed tools.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>prompt</code> (str): The prompt to send to Claude.</li>
<li><code>tools</code> (list): List of tools to allow Claude to use.</li>
<li><code>stream</code> (bool): If True, handles streaming output.</li>
<li><code>auto_print</code> (bool): If True and stream=True, automatically prints output.</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li>If <code>stream=False</code>: Returns the complete output as a string.</li>
<li>If <code>stream=True</code> and <code>auto_print=False</code>: Returns a subprocess.Popen object.</li>
<li>If <code>stream=True</code> and <code>auto_print=True</code>: Automatically prints output and returns collected lines.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example: Automatic Streaming</h2><a id="user-content-example-automatic-streaming" aria-label="Permalink: Example: Automatic Streaming" href="#example-automatic-streaming"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from codesys import Agent

agent = Agent()
# This will automatically print the output line by line
lines = agent.run(&quot;Generate a short story&quot;, stream=True)"><pre><span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>

<span>agent</span> <span>=</span> <span>Agent</span>()
<span># This will automatically print the output line by line</span>
<span>lines</span> <span>=</span> <span>agent</span>.<span>run</span>(<span>"Generate a short story"</span>, <span>stream</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example: Manual Streaming with JSON parsing</h2><a id="user-content-example-manual-streaming-with-json-parsing" aria-label="Permalink: Example: Manual Streaming with JSON parsing" href="#example-manual-streaming-with-json-parsing"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from codesys import Agent
import json

agent = Agent()
process = agent.run(&quot;Generate a short story&quot;, stream=True, output_format=&quot;stream-json&quot;, auto_print=False)

for line in process.stdout:
    if line.strip():
        try:
            data = json.loads(line)
            print(data.get(&quot;content&quot;, &quot;&quot;))
        except json.JSONDecodeError:
            print(f&quot;Error parsing JSON: {line}&quot;)"><pre><span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>
<span>import</span> <span>json</span>

<span>agent</span> <span>=</span> <span>Agent</span>()
<span>process</span> <span>=</span> <span>agent</span>.<span>run</span>(<span>"Generate a short story"</span>, <span>stream</span><span>=</span><span>True</span>, <span>output_format</span><span>=</span><span>"stream-json"</span>, <span>auto_print</span><span>=</span><span>False</span>)

<span>for</span> <span>line</span> <span>in</span> <span>process</span>.<span>stdout</span>:
    <span>if</span> <span>line</span>.<span>strip</span>():
        <span>try</span>:
            <span>data</span> <span>=</span> <span>json</span>.<span>loads</span>(<span>line</span>)
            <span>print</span>(<span>data</span>.<span>get</span>(<span>"content"</span>, <span>""</span>))
        <span>except</span> <span>json</span>.<span>JSONDecodeError</span>:
            <span>print</span>(<span>f"Error parsing JSON: <span><span>{</span><span>line</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="from codesys import Agent

# Initialize with a working directory
agent = Agent(working_dir=&quot;/Users/seansullivan/lmsys-sdk/&quot;)

# Run Claude with a prompt and automatically print streaming output
lines = agent.run(&quot;create another example of example1_custom_tools.py which shows how to use read only tools. note the source code of the sdk in codesys/agent.py&quot;, stream=True)
"><pre><span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>

<span># Initialize with a working directory</span>
<span>agent</span> <span>=</span> <span>Agent</span>(<span>working_dir</span><span>=</span><span>"/Users/seansullivan/lmsys-sdk/"</span>)

<span># Run Claude with a prompt and automatically print streaming output</span>
<span>lines</span> <span>=</span> <span>agent</span>.<span>run</span>(<span>"create another example of example1_custom_tools.py which shows how to use read only tools. note the source code of the sdk in codesys/agent.py"</span>, <span>stream</span><span>=</span><span>True</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;&quot;&quot;
Example 1: Customizing tools during initialization

This example demonstrates how to initialize an Agent with only specific tools.
&quot;&quot;&quot;

from codesys import Agent

# Initialize with only specific tools
restricted_agent = Agent(
    working_dir=&quot;./&quot;,
    allowed_tools=[&quot;Edit&quot;, &quot;Write&quot;, &quot;View&quot;]  # Only allow editing, writing files and viewing
)  # Implementation in agent.py lines 19-39

print(f&quot;Agent initialized with tools: {restricted_agent.allowed_tools}&quot;)"><pre><span>"""</span>
<span>Example 1: Customizing tools during initialization</span>
<span></span>
<span>This example demonstrates how to initialize an Agent with only specific tools.</span>
<span>"""</span>

<span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>

<span># Initialize with only specific tools</span>
<span>restricted_agent</span> <span>=</span> <span>Agent</span>(
    <span>working_dir</span><span>=</span><span>"./"</span>,
    <span>allowed_tools</span><span>=</span>[<span>"Edit"</span>, <span>"Write"</span>, <span>"View"</span>]  <span># Only allow editing, writing files and viewing</span>
)  <span># Implementation in agent.py lines 19-39</span>

<span>print</span>(<span>f"Agent initialized with tools: <span><span>{</span><span>restricted_agent</span>.<span>allowed_tools</span><span>}</span></span>"</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="
from codesys import Agent

# Initialize with default tools
agent = Agent(working_dir=&quot;./&quot;)  # Implementation in agent.py lines 19-39
print(f&quot;Default tools: {agent.allowed_tools}&quot;)

# Run with only specific tools for one operation
bash_only_response = agent.run_with_tools(
    prompt=&quot;List files in the current directory&quot;,
    tools=[&quot;Bash&quot;],  # Only allow Bash for this specific run
    stream=False
)  # Implementation in agent.py lines 132-155

print(f&quot;Tools after run_with_tools: {agent.allowed_tools}  # Original tools are restored&quot;)"><pre><span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>

<span># Initialize with default tools</span>
<span>agent</span> <span>=</span> <span>Agent</span>(<span>working_dir</span><span>=</span><span>"./"</span>)  <span># Implementation in agent.py lines 19-39</span>
<span>print</span>(<span>f"Default tools: <span><span>{</span><span>agent</span>.<span>allowed_tools</span><span>}</span></span>"</span>)

<span># Run with only specific tools for one operation</span>
<span>bash_only_response</span> <span>=</span> <span>agent</span>.<span>run_with_tools</span>(
    <span>prompt</span><span>=</span><span>"List files in the current directory"</span>,
    <span>tools</span><span>=</span>[<span>"Bash"</span>],  <span># Only allow Bash for this specific run</span>
    <span>stream</span><span>=</span><span>False</span>
)  <span># Implementation in agent.py lines 132-155</span>

<span>print</span>(<span>f"Tools after run_with_tools: <span><span>{</span><span>agent</span>.<span>allowed_tools</span><span>}</span></span>  # Original tools are restored"</span>)</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;&quot;&quot;
Example 3: Manual handling of streaming output

This example demonstrates how to manually handle streaming output from the agent.
&quot;&quot;&quot;

from codesys import Agent
import json
import time

# Initialize an agent
agent = Agent(working_dir=&quot;./&quot;)

# Get a process for streaming manually
process = agent.run(
    prompt=&quot;Explain what an LLM Agent is in 3 sentences&quot;,
    stream=True,
    auto_print=False  # Don't auto-print, we'll handle the output manually
)  # Implementation in agent.py lines 41-96 (stream=True, auto_print=False path)

print(&quot;Streaming output manually, processing each line:&quot;)
for i, line in enumerate(process.stdout):
    # Parse the JSON line
    try:
        data = json.loads(line)
        # Do something with each piece of output
        print(f&quot;Line {i+1}: {data.get('content', '')}&quot;)
    except json.JSONDecodeError:
        print(f&quot;Raw line: {line}&quot;)

    # Simulate processing time
    time.sleep(0.1)
    # Compare with agent.py lines 98-116 (auto-handling of streaming)"><pre><span>"""</span>
<span>Example 3: Manual handling of streaming output</span>
<span></span>
<span>This example demonstrates how to manually handle streaming output from the agent.</span>
<span>"""</span>

<span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>
<span>import</span> <span>json</span>
<span>import</span> <span>time</span>

<span># Initialize an agent</span>
<span>agent</span> <span>=</span> <span>Agent</span>(<span>working_dir</span><span>=</span><span>"./"</span>)

<span># Get a process for streaming manually</span>
<span>process</span> <span>=</span> <span>agent</span>.<span>run</span>(
    <span>prompt</span><span>=</span><span>"Explain what an LLM Agent is in 3 sentences"</span>,
    <span>stream</span><span>=</span><span>True</span>,
    <span>auto_print</span><span>=</span><span>False</span>  <span># Don't auto-print, we'll handle the output manually</span>
)  <span># Implementation in agent.py lines 41-96 (stream=True, auto_print=False path)</span>

<span>print</span>(<span>"Streaming output manually, processing each line:"</span>)
<span>for</span> <span>i</span>, <span>line</span> <span>in</span> <span>enumerate</span>(<span>process</span>.<span>stdout</span>):
    <span># Parse the JSON line</span>
    <span>try</span>:
        <span>data</span> <span>=</span> <span>json</span>.<span>loads</span>(<span>line</span>)
        <span># Do something with each piece of output</span>
        <span>print</span>(<span>f"Line <span><span>{</span><span>i</span><span>+</span><span>1</span><span>}</span></span>: <span><span>{</span><span>data</span>.<span>get</span>(<span>'content'</span>, <span>''</span>)<span>}</span></span>"</span>)
    <span>except</span> <span>json</span>.<span>JSONDecodeError</span>:
        <span>print</span>(<span>f"Raw line: <span><span>{</span><span>line</span><span>}</span></span>"</span>)

    <span># Simulate processing time</span>
    <span>time</span>.<span>sleep</span>(<span>0.1</span>)
    <span># Compare with agent.py lines 98-116 (auto-handling of streaming)</span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;&quot;&quot;
Example 4: Using output formats and additional arguments

This example demonstrates how to use different output formats and pass additional arguments.
&quot;&quot;&quot;

from codesys import Agent

# Initialize an agent
agent = Agent(working_dir=&quot;./&quot;)

# Run with custom output format and additional arguments
response = agent.run(
    prompt=&quot;What can you tell me about this codebase?&quot;,
    output_format=&quot;json&quot;,  # Request JSON output
    additional_args={
        &quot;temperature&quot;: 0.7,     # Set temperature
        &quot;max-tokens&quot;: 500,      # Limit output tokens
        &quot;silent&quot;: True          # Suppress progress output
    }
)  # Implementation in agent.py lines 41-70 (output_format handling), 74-80 (additional_args)

print(f&quot;Response type: {type(response)}&quot;)
print(&quot;First 100 characters of response:&quot;, response[:100] if isinstance(response, str) else &quot;Not a string&quot;)"><pre><span>"""</span>
<span>Example 4: Using output formats and additional arguments</span>
<span></span>
<span>This example demonstrates how to use different output formats and pass additional arguments.</span>
<span>"""</span>

<span>from</span> <span>codesys</span> <span>import</span> <span>Agent</span>

<span># Initialize an agent</span>
<span>agent</span> <span>=</span> <span>Agent</span>(<span>working_dir</span><span>=</span><span>"./"</span>)

<span># Run with custom output format and additional arguments</span>
<span>response</span> <span>=</span> <span>agent</span>.<span>run</span>(
    <span>prompt</span><span>=</span><span>"What can you tell me about this codebase?"</span>,
    <span>output_format</span><span>=</span><span>"json"</span>,  <span># Request JSON output</span>
    <span>additional_args</span><span>=</span>{
        <span>"temperature"</span>: <span>0.7</span>,     <span># Set temperature</span>
        <span>"max-tokens"</span>: <span>500</span>,      <span># Limit output tokens</span>
        <span>"silent"</span>: <span>True</span>          <span># Suppress progress output</span>
    }
)  <span># Implementation in agent.py lines 41-70 (output_format handling), 74-80 (additional_args)</span>

<span>print</span>(<span>f"Response type: <span><span>{</span><span>type</span>(<span>response</span>)<span>}</span></span>"</span>)
<span>print</span>(<span>"First 100 characters of response:"</span>, <span>response</span>[:<span>100</span>] <span>if</span> <span>isinstance</span>(<span>response</span>, <span>str</span>) <span>else</span> <span>"Not a string"</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">CodeSYS</h4><a id="user-content-codesys" aria-label="Permalink: CodeSYS" href="#codesys"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Critical Look at MCP (503 pts)]]></title>
            <link>https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp</link>
            <guid>43945993</guid>
            <pubDate>Sat, 10 May 2025 14:37:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp">https://raz.sh/blog/2025-05-02_a_critical_look_at_mcp</a>, See on <a href="https://news.ycombinator.com/item?id=43945993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    <nav>

<ul>
<li>
<ul>
<li><a href="#toc_0" rel="nofollow">TL;DR</a></li>

<li><a href="#toc_1" rel="nofollow">Background</a></li>

<li><a href="#toc_2" rel="nofollow">Protocol</a></li>

<li><a href="#toc_3" rel="nofollow">Transport</a>
<ul>
<li><a href="#toc_4" rel="nofollow">Stdio</a></li>

<li><a href="#toc_5" rel="nofollow">HTTP+SSE / Streamable HTTP</a></li>
</ul></li>

<li><a href="#toc_6" rel="nofollow">A Descent into Madness</a>
<ul>
<li><a href="#toc_7" rel="nofollow">The Warning Signs...</a></li>

<li><a href="#toc_8" rel="nofollow">The Problem</a>
<ul>
<li><a href="#toc_9" rel="nofollow">HTTP+SSE Mode</a></li>

<li><a href="#toc_10" rel="nofollow">"Streamable HTTP" Mode</a></li>
</ul></li>

<li><a href="#toc_11" rel="nofollow">What Are the Implications for SSE Mode?</a></li>

<li><a href="#toc_12" rel="nofollow">What Are the Implications for "Streamable HTTP"?</a>
<ul>
<li><a href="#toc_13" rel="nofollow">General implications</a></li>

<li><a href="#toc_14" rel="nofollow">Security Implications</a></li>
</ul></li>

<li><a href="#toc_15" rel="nofollow">Authorization</a></li>
</ul></li>

<li><a href="#toc_16" rel="nofollow">What Should Be Done</a></li>

<li><a href="#toc_17" rel="nofollow">Side note: Alternatives and Additions</a></li>
</ul></li>
</ul>

</nav>

<blockquote>
<p>"MCP is an open protocol that standardizes how applications provide context to LLMs. Think of MCP like a USB-C port for AI
applications. Just as USB-C provides a standardized way to connect your devices to various peripherals and accessories, MCP
provides a standardized way to connect AI models to different data sources and tools."</p>

<p>― Anthropic</p>
</blockquote>

<h2 id="toc_0">TL;DR</h2>

<p>I would like for this to turn out to be a skill issue on my part, and hope that I'm missing something.</p>

<p>During the past month,<a href="https://modelcontextprotocol.io/specification/2025-03-26" rel="nofollow noopener" target="_blank">MCP (Model Context Protocol)</a>, which would enable
LLMs to become agents and interact with the world, has really been blowing up. The idea is straightforward: let's standardize an
API for LLM/Agents to interact with the world and how to inform the LLM/Agent about it.</p>

<p>Things are moving really fast, and IBM recently released their own "orthogonal standard" to MCP
called <a href="https://agentcommunicationprotocol.dev/" rel="nofollow noopener" target="_blank">Agent Communication Protocol (ACP)</a>, followed closely by Google
announcing <a href="https://google.github.io/A2A" rel="nofollow noopener" target="_blank">Agent2Agent (A2A)</a>.</p>

<p>MCP Servers and Clients are being built and published daily, and can be found at sites like <a href="https://mcp.so/" rel="nofollow noopener" target="_blank">mcp.so</a>
and <a href="https://www.pulsemcp.com/" rel="nofollow noopener" target="_blank">pulsemcp.com</a>.</p>

<p>However, I'm astonished by the apparent lack of mature engineering practices. All the major players spend billions of dollars on
training and tuning their models, only to turn around and, from what I can tell, have an interns write the documentation,
providing subpar SDKs and very little in terms of implementation guidance.</p>

<p>This trend seems to have continued with MCP, resulting in some very strange design decisions, poor documentation, and an even
worse specification of the actual protocols.</p>

<p>My conclusion is that the whole suggested setup for HTTP transport (SSE+HTTP and Streamable HTTP) should be thrown out and
replaced
with something that mimics stdio... Websockets.</p>

<h2 id="toc_1">Background</h2>

<p>About three weeks ago, I decided to jump on the MCP bandwagon to give it a try and see how it could be used in our own
environment. I'm very much a person who wants to understand how things actually work under the hood before I start using
abstractions. Here we have a new protocol that works over different transports — how exciting!</p>

<p>Anthropic is the company behind the MCP standardization effort, and MCP seems to be one of the major reasons Anthropic's CEO is
thinking that most code will be written by LLMs within a year or so. The bet on coding tooling in particular seems to have been
the guiding principle of the standardization effort based on how it feels to work with it.</p>

<h2 id="toc_2">Protocol</h2>

<p>Simply put, it is a JSON-RPC protocol with predefined methods/endpoints designed to be used in conjunction with an LLM. This is
not really the focus of this post, but there are things to be criticized about the protocol itself.</p>

<h2 id="toc_3">Transport</h2>

<p>As with many applications post-2005, they're supposedly "local first" (<em>ironically</em>), and this seems to be very much the case with
MCP. Looking at the transport protocol, you get a sense of where
they're coming from—if their intention is to build LLM tools for coding on your laptop. They're probably looking at local IDEs (or
more realistically, Cursor or Windsurf) and how to have the LLM interact with the local file system, databases, editors, language
servers, and so on.</p>

<p>There are essentially two main transport protocols (or three):</p>

<ol>
<li>stdio</li>
<li>"Something over HTTP, the web seems to be a thing we probably should support."</li>
</ol>

<h3 id="toc_4">Stdio</h3>

<p>Using stdio essentially means starting a local MCP Server, hooking up <code>stdout</code> and <code>stdin</code> pipes from the server to the client,
and starting to send JSON and using <code>stderr</code> for logging. It kind of breaks the Unix/Linux piping paradigm using these streams for
bidirectional communication. When bidirectional communication is needed, we usually reach for a socket, unix socket or even a net
socket.</p>

<p>However, it is straightforward and easy to reason about, works out of the box in all OSes, no need to deal with sockets, and so
on. So even if there is a critique to be made, I get it.</p>

<h3 id="toc_5">HTTP+SSE / Streamable HTTP</h3>

<p>The HTTP transport is another story. There are two versions of the same mistake: HTTP+SSE (Server-Sent Events) transport, which is
being replaced by "Streamable HTTP" (a made-up term) that uses REST semantics with SSE. But with a whole lot of extra confusion
and corner cases on top.</p>

<p>It can be summarized as: "Since we like SSE for LLM streaming, we're not using WebSockets. Instead, we're effectively implementing
WebSockets on top of SSE and calling it 'Streamable HTTP' to make people think it's an accepted/known way of doing things."</p>

<p>They discuss the problems with WebSockets (and the reason for Streamable HTTP) in this
PR: <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/206" rel="nofollow noopener" target="_blank">modelcontextprotocol/pull/206</a>, making some very
strange contortions and straw-man arguments to <strong>not</strong> use WebSockets. At least one other person in the thread seems to agree with
me: <a href="https://github.com/modelcontextprotocol/modelcontextprotocol/pull/206#issuecomment-2766559523" rel="nofollow noopener" target="_blank">modelcontextprotocol/pull/206#issuecomment-2766559523</a>.</p>

<h2 id="toc_6">A Descent into Madness</h2>

<p>I set out to implement an MCP server in Golang. There isn't an official Go SDK, and I wanted to understand the protocol. This
turned out to be a mistake for mental health...</p>

<h3 id="toc_7">The Warning Signs...</h3>

<p>Looking at <a href="https://modelcontextprotocol.io/" rel="nofollow noopener" target="_blank">https://modelcontextprotocol.io</a>, the documentation is poorly written (all LLM vendors seem to have an internal
competition in writing confusing documentation). The specification glosses over or ignores important aspects of the protocol and
provides no examples of conversation flow. In fact, it seems the entire website is not meant for reading the standard; instead, it
pushes you toward tutorials on how to implement their SDKs.</p>

<p>All example servers are implemented in Python or JavaScript, with the intention that you download and run them locally using
stdio. Python and JavaScript are probably one of the worst choices of languages for something you want to work on anyone else's
computer. The authors seem to realize this since all examples are available as Docker containers.</p>

<blockquote>
<p>Be honest... when was the last time you ran <code>pip install</code> and didn't end up in dependency hell?</p>
</blockquote>

<p>Am I being pretentious/judgmental in thinking that people in AI only really know Python, and the "well, it works on my computer"
approach is still considered acceptable? This should be glaringly obvious to anyone that ever tried to run anything from
Hugging Face.</p>

<p>If you want to run MCP locally, wouldn't you prefer a portable language like Rust, Go, or even VM-based options such as Java or
C#?</p>

<h3 id="toc_8">The Problem</h3>

<p>When I started implementing the protocol, I immediately felt I had to reverse-engineer it. Important aspects of the SSE portion
are missing from the documentation, and no one seemed to have implemented the "Streamable HTTP" yet; not even their own tooling
like <code>npx @modelcontextprotocol/inspector@latest</code>. (To be fair, it might have been a skill issue on my part, pulling the wrong
version, since it was available when I checked again a few weeks later. You can also find version at
<a href="https://inspect.mcp.garden/" rel="nofollow noopener" target="_blank">inspect.mcp.garden</a>, which might be more convenient.)</p>

<p>Once you grasp the architecture, you quickly realize that implementing an MCP server, or a client, could be a huge effort. The
problem is that the SSE/Streamable HTTP implementations are trying to act like sockets, emulating stdio, without being one and is
trying to do <em>Everything Everywhere All at Once</em>.</p>

<h4 id="toc_9">HTTP+SSE Mode</h4>

<p><a href="https://modelcontextprotocol.io/specification/2024-11-05/basic/transports" rel="nofollow noopener" target="_blank">modelcontextprotocol.io/specification/2024-11-05/basic/transports</a></p>

<p>In <strong>HTTP+SSE mode</strong>, to achieve full duplex, the client sets up an SSE session to (e.g.) <code>GET /sse</code> for reads. The first read provides
a URL where writes can be posted. The client then proceeds to use the given endpoint for writes, e.g., a request to
<code>POST /a-endpoint?session-id=1234</code>. The server returns a 202 Accepted with no body, and the response to the request should be read
from the pre-existing open SSE connection on <code>/sse</code>.</p>

<h4 id="toc_10">"Streamable HTTP" Mode</h4>

<p><a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports" rel="nofollow noopener" target="_blank">modelcontextprotocol.io/specification/2025-03-26/basic/transports</a></p>

<p>In <strong>"Streamable HTTP" mode</strong>, they realized that instead of providing a new endpoint in the first request, they could use an
HTTP header for the session ID and REST semantics for the endpoint. For example, <code>GET</code> or <code>POST /mcp</code> can open an SSE session and
return an <code>mcp-session-id=1234</code> HTTP header. To send data, the client does requests to <code>POST /mcp</code> and adds the HTTP header
<code>mcp-session-id=1234</code>. The response may:</p>

<ul>
<li>Open a new SSE stream and post the reply</li>
<li>Return a 200 with the reply in the body</li>
<li>Return a 202, indicating the reply will be written to one of any pre-existing SSE stream</li>
</ul>

<p>To end the session, the client may or may not send a <code>DELETE /mcp</code> with the header <code>mcp-session-id=1234</code>. The server must maintain
state with no clear way to know when the client has abandoned the session unless the client nicely ends it properly.</p>

<h3 id="toc_11">What Are the Implications for SSE Mode?</h3>

<p>This is such a problematic design that I don't know where to begin.</p>

<p>While some key features of SSE mode are undocumented, it's fairly straightforward once you reverse-engineer it. But this still
puts a huge and unnecessary burden on the server implementation, which needs to "join" connections across calls. Doing anything
real will pretty much force you to use a message queue to reply to any request. E.g., running the server in any redundant way will
mean that the SSE stream might come from one server to the client, while the requests are being sent to a completely different
server.</p>

<h3 id="toc_12">What Are the Implications for "Streamable HTTP"?</h3>

<p>The <strong>Streamable HTTP</strong> approach takes it to another level with a host of security concerns and obfuscated control flow. While
keeping all the bad parts from SSE mode, Streamable HTTP seems to be more of a super-set of confusion over SSE mode.</p>

<p>In terms of implementation I have just scratched the surface, but from what I understand in the docs...</p>

<p><strong>A new session can be created in 3 ways:</strong></p>

<ul>
<li>An empty <code>GET</code> request</li>
<li>An empty <code>POST</code> request</li>
<li>A <code>POST</code> request containing the RPC call</li>
</ul>

<p><strong>An SSE can be opened in 4 different ways:</strong></p>

<ul>
<li>A <code>GET</code> to initialize</li>
<li>A <code>GET</code> to join an earlier session</li>
<li>A <code>POST</code> to initialize a session</li>
<li>A <code>POST</code> that contains a request and answers with an SSE</li>
</ul>

<p><strong>A request may be answered in any of 3 different ways:</strong></p>

<ul>
<li>As an HTTP response to a <code>POST</code> with an RPC call</li>
<li>As an event in an SSE that was opened as a response to the <code>POST</code> RPC call</li>
<li>As an event to any SSE that was opened at some earlier point</li>
</ul>

<h4 id="toc_13">General implications</h4>

<p>With its multiple ways to initiate sessions, open SSE connections, and respond to requests, this introduces significant
complexity.
This complexity has several general implications:</p>

<ul>
<li><strong>Increased Complexity</strong>: The multiple ways of doing the same thing (session creation, SSE opening, response delivery) increases
the cognitive load for developers. It becomes harder to understand, debug, and maintain code.</li>
<li><strong>Potential for Inconsistency</strong>: With various ways to achieve the same outcome, there's a higher risk of inconsistent
implementations across different servers and clients. This can lead to interoperability issues and unexpected behavior. Clients
and servers just implementing the parts they feel are necessary.</li>
<li><strong>Scalability Concerns</strong>: While Streamable HTTP aims to improve efficiency, with a charitable interpretation, the complexity
will introduce scalability bottlenecks that need to be overcome. Servers might struggle to manage the diverse connection states,
response mechanisms over a large number of machines.</li>
</ul>

<h4 id="toc_14">Security Implications</h4>

<p>The "flexibility" of Streamable HTTP introduces several security concerns, and here are just a few of them:</p>

<ul>
<li><strong>State Management Vulnerabilities</strong>: Managing session state across different connection types (HTTP and SSE) is complex. This
could lead to vulnerabilities such as session hijacking, replay attacks or DoS attacks by creating state on the server that
needs to be managed and kept around waiting for a session to be resumed.</li>
<li><strong>Increased Attack Surface</strong>: The multiple entry points for session creation and SSE connections expand the attack surface. Each
entry point represents a potential vulnerability that an attacker could exploit.</li>
<li><strong>Confusion and Obfuscation</strong>: The variety of ways to initiate sessions and deliver responses can be used to obfuscate malicious
activity.</li>
</ul>

<h3 id="toc_15">Authorization</h3>

<p>The latest version of the protocol contains some very opinionated requirements on how authorization should be done.</p>

<p><a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/authorization" rel="nofollow noopener" target="_blank">modelcontextprotocol.io/specification/2025-03-26/basic/authorization</a></p>

<blockquote>
<ul>
<li>Implementations using an HTTP-based transport SHOULD conform to this specification.</li>
<li>Implementations using an STDIO transport SHOULD NOT follow this specification, and instead retrieve credentials from the
environment.</li>
</ul>
</blockquote>

<p>I'm reading it like, for stdio, do whatever. For HTTP, you better fucking jump through these OAuth2 hoops. Why do I need to
implement OAuth2 if I'm using HTTP as transport, while an API key is enough for stdio?</p>

<h2 id="toc_16">What Should Be Done</h2>

<p>I don't know, just kind of feel sad about it all...
It seems like the industry is peeing their pants at the moment ― <em>it feels great now, but it's going to be hard to deal with
later.</em></p>

<p>There is one JSON RPC protocol, and Stdio is clearly preferred as the transport protocol. Then we should try to have the HTTP
transport be as much like Stdio as we can make it, and only really deviate if we really, really need to.</p>

<ul>
<li>In Stdio, we have Environment Variables, in HTTP we have HTTP Headers</li>
<li>In Stdio, we have <em>socket-like</em> behavior with input and output streams, in HTTP we have WebSockets</li>
</ul>

<p>That's it really. We should be able to accomplish the same thing on WebSockets as we do on Stdio. WebSockets are the appropriate
choice for transport over HTTP. We can do away with complex cross-server state management for sessions. We can do away with a
multitude of corner-cases and on and on.</p>

<p>Sure some things, like authorization, might be a bit more complicated in some instances (and easier in some); some firewalls out
there might block WebSockets; there might be extra overhead for small sessions; it might be harder to resume a broken session. But
as
<em>they</em> say:</p>

<blockquote>
<p>Clients and servers MAY implement additional custom transport mechanisms to suit their specific needs. The protocol is
transport-agnostic and can be implemented over any communication channel that supports bidirectional message exchange</p>

<p><a href="https://modelcontextprotocol.io/specification/2025-03-26/basic/transports#custom-transports" rel="nofollow noopener" target="_blank">modelcontextprotocol.io/specification/2025-03-26/basic/transports#custom-transports</a></p>
</blockquote>

<p>As an industry, we should optimize for the most common use-cases, not the corner-cases.</p>

<h2 id="toc_17">Side note: Alternatives and Additions</h2>

<p>As discussed above, there seem to be more protocols emerging. MCP is effectively "a protocol to expose an API to an LLM" (which
can create an agent). The more recent protocols from IBM and Google (ACP and A2A) are effectively "protocols to expose an Agent to
an LLM" (which can create an agent of agents).</p>

<p>Looking through the A2A specification, it seems like there's a very limited need for them. Even though they claim to be
orthogonal, most things in A2A could be accomplished with MCP as is or with small additions.</p>

<p>It boils down to two entire protocols that could just as well be tools in an MCP server. Even IBM seems to acknowledge that their
protocol isn't really necessary:</p>

<blockquote>
<p>"Agents can be viewed as MCP resources and further invoked as MCP tools. Such a view of ACP agents allows MCP clients to
discover and run ACP agents..."</p>

<p>― IBM / <a href="https://agentcommunicationprotocol.dev/ecosystem/mcp-adapter" rel="nofollow noopener" target="_blank">agentcommunicationprotocol.dev/ecosystem/mcp-adapter</a></p>
</blockquote>

<p>My initial feeling is that the ACP protocol mostly seems like an attempt for IBM to promote their "
agent-building-tool" <a href="https://beeai.dev/" rel="nofollow noopener" target="_blank">BeeAI</a></p>

<p>What both of the A** protocols bring to the table is a sane transport layer and a way to discover agents.</p>

<p><img src="https://imgs.xkcd.com/comics/standards.png" alt="14 competing standards"></p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US vs. Google Amicus Curiae Brief of Y Combinator in Support of Plaintiffs [pdf] (379 pts)]]></title>
            <link>https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1300.1.pdf</link>
            <guid>43945820</guid>
            <pubDate>Sat, 10 May 2025 14:15:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1300.1.pdf">https://storage.courtlistener.com/recap/gov.uscourts.dcd.223205/gov.uscourts.dcd.223205.1300.1.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43945820">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>