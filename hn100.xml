<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 04 Dec 2023 16:00:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Spotify cuts almost 1,600 jobs amid rising costs (181 pts)]]></title>
            <link>https://www.theguardian.com/technology/2023/dec/04/spotify-cut-jobs-amid-rising</link>
            <guid>38515863</guid>
            <pubDate>Mon, 04 Dec 2023 11:02:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2023/dec/04/spotify-cut-jobs-amid-rising">https://www.theguardian.com/technology/2023/dec/04/spotify-cut-jobs-amid-rising</a>, See on <a href="https://news.ycombinator.com/item?id=38515863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Spotify is cutting almost 1,600 jobs as the music streaming service blamed a slowing economy and higher borrowing costs in the latest round of redundancies at big tech companies.</p><p>Daniel Ek, Spotify’s billionaire founder and chief executive, revealed that the company had decided to cut 17% of its workforce, the third and steepest round of redundancies of 2023.</p><p>Ek told employees they would receive a calendar invitation “within the next two hours from HR for a one-on-one conversation” if they were affected by the cuts, in a message to staff published on Spotify’s website on Monday.</p><figure id="33f06d99-e313-45d2-a0a7-fe0ecf73a2a1" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:3,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/commentisfree/2023/nov/27/openai-microsoft-big-tech-monopoly&quot;,&quot;text&quot;:&quot;The real story of the OpenAI debacle is the tyranny of big tech | Courtney Radsch&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;33f06d99-e313-45d2-a0a7-fe0ecf73a2a1&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>Big tech companies ranging from <a href="https://www.theguardian.com/technology/2023/may/24/meta-layoffs-final-round-facebook" data-link-name="in body link">Meta</a> and <a href="https://www.theguardian.com/technology/2023/oct/16/linkedin-layoffs-microsoft-second-job-cuts" data-link-name="in body link">Microsoft</a> to <a href="https://www.theguardian.com/technology/2023/mar/20/amazon-cut-jobs-layoffs" data-link-name="in body link">Amazon</a> and <a href="https://www.theguardian.com/technology/2023/jan/20/google-parent-firm-alphabet-to-cut-12000-jobs-worldwide" data-link-name="in body link">Alphabet</a> have retrenched and made large-scale redundancies during 2023 after interest rates rose and investors focused on their ability to cut costs to protect profits.</p><p>Stockholm-based Spotify is the dominant player in global music streaming, and is one of the few European companies to take on US rivals. Yet as the global economy’s momentum has waned, it has held back from its previous <a href="https://www.theguardian.com/technology/2022/feb/04/spotify-crises-podcasts-culture-wars-competition-concerns" data-link-name="in body link">heavy investment into podcasting</a>. That investment included backing a podcast from Prince Harry and the Duchess of Sussex in a deal that <a href="https://www.theguardian.com/media/2023/jun/19/spotify-executive-calls-harry-and-meghan-grifters-after-podcast-deal-ends" data-link-name="in body link">ended in apparent acrimony this year</a>. Spotify continues to maintain high-value podcasting tie-ups, including a <a href="https://www.theguardian.com/culture/2022/feb/07/spotify-ceo-condemns-joe-rogan-over-use-of-n-word-but-wont-silence-him" data-link-name="in body link">controversial deal with Joe Rogan</a> and others with the influencer Emma Chamberlain and the comedian Trevor Noah.</p><p>Ek said Spotify had taken advantage of cheap borrowing during 2020 and 2021, when central bankers cut interest rates sharply in response to coronavirus pandemic lockdowns, but that “we now find ourselves in a very different environment”.</p><p>“Despite our efforts to reduce costs this past year, our cost structure for where we need to be is still too big,” he wrote.</p><p>Spotify reported that it had 9,400 employees at the end of the third quarter of 2023. It had already cut back employee numbers by 6% in January and by a further 2% in June.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-9">skip past newsletter promotion</a><p id="EmailSignup-skip-link-9" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Redundant employees will receive an average of five months of severance pay plus unused holiday pay, Ek said.</p><p>“Embracing this leaner structure will also allow us to invest our profits more strategically back into the business,” he added. “Today is a difficult but important day for the company.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HTML attributes for improved accessibility and user experience (124 pts)]]></title>
            <link>https://www.htmhell.dev/adventcalendar/2023/4/</link>
            <guid>38515779</guid>
            <pubDate>Mon, 04 Dec 2023 10:47:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.htmhell.dev/adventcalendar/2023/4/">https://www.htmhell.dev/adventcalendar/2023/4/</a>, See on <a href="https://news.ycombinator.com/item?id=38515779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main id="content"><div><p>by <a href="https://dnikub.dev/">Daniela Kubesch</a> published on <time datetime="2023-12-04">Dec 04, 2023</time></p><p>In the fast-paced world of web development, it's easy to get caught up in the latest frameworks, libraries and cutting-edge technologies. But sometimes, the most impactful improvements come from revisiting the fundamentals.</p><p>In this blog post, I'll guide you through five HTML attributes that not only improve accessibility but also enhance the overall user experience. Whether you are an experienced developer or just starting, let's explore the potential of these elements to create a more inclusive web experience.</p><h2 id="1-hreflang">1. hreflang</h2><p>The <a href="https://www.w3.org/TR/2014/REC-html5-20141028/links.html#attr-hyperlink-hreflang"><code>hreflang</code> attribute</a> <strong>specifies the language of a linked resource</strong> on an <code>&lt;a&gt;</code> or <code>&lt;link&gt;</code> element. It works like the <code>lang</code> attribute but is specifically used for links.</p><h3 id="why-use-hreflang?">Why use <code>hreflang</code>?</h3><p>You can improve the user experience and SEO by using <code>hreflang</code> for both internal and external site links.<br>Using <code>hreflang</code> on internal website links provides a way to tell search engines about different variations of a page for other languages or regions. This means that English speakers would receive the English version of the site, while Swedish speakers would receive the Swedish version. There is no need for manual switching on the user's end, resulting in a smoother experience.</p><h3 id="how-to-use-hreflang">How to use <code>hreflang</code></h3><p>Add the <code>hreflang</code> attribute with the needed <a href="https://www.iana.org/assignments/language-subtag-registry/language-subtag-registry">ISO language code</a> to your <code>&lt;a&gt;</code> element. For an English website, this would be <code>en</code>.</p><pre><code><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>en<span>"</span></span><span>&gt;</span></span>English Website<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span></code></pre><p>You can also be more specific with the language code and use regional variations. For example, we can add <code>en-GB</code> for British English.</p><pre><code><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.at<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>en-GB<span>"</span></span><span>&gt;</span></span>English Website<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span></code></pre><p>If your website is available in multiple languages, you can use <code>hreflang</code> to specify the language and region of a document associated with a specific URL. Adding the attribute will help search engines understand the language and regional targeting of different web page versions.</p><p>Add <code>hreflang</code> with the required language code to each link. One link should act as the default fallback version, identifiable by adding <code>hreflang="x-default"</code> instead of the language code. Lastly, set the value of the <code>rel</code> attribute to <code>"alternate"</code> for each link in the language switcher to indicate that the linked pages are alternatives to the present page.</p><pre><code><span><span><span><span>&lt;</span>link</span> <span>href</span><span><span>=</span><span>"</span>https://example.com<span>"</span></span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>x-default<span>"</span></span> <span>/&gt;</span></span></span><br><span><span><span><span>&lt;</span>link</span> <span>href</span><span><span>=</span><span>"</span>https://example.com/de<span>"</span></span> <span>rel</span><span><span>=</span><span>"</span>alternate<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>de<span>"</span></span> <span>/&gt;</span></span></span></code></pre><p>You can also use <code>hreflang</code> in your language switcher.</p><pre><code><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>x-default<span>"</span></span><span>&gt;</span></span>English<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com/de<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>de<span>"</span></span><span>&gt;</span></span>German<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span></code></pre><p>Sometimes, language switchers use link text in the language they are switching to. You can indicate this by additionally using the <code>lang</code> attribute.</p><pre><code><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>x-default<span>"</span></span><span>&gt;</span></span>English<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com/de<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>de<span>"</span></span> <span>lang</span><span><span>=</span><span>"</span>de<span>"</span></span><span>&gt;</span></span>Deutsch<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span></code></pre><p><strong>Note:</strong> Adding the <code>lang</code> attribute is particularly important for assistive technology users. For instance, screen readers alter their voice and pronunciation based on the language attribute.</p><p>An additional way to enhance accessibility is to include <code>aria-current="true"</code> to the presently active link.</p><pre><code><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>x-default<span>"</span></span> <span>aria-current</span><span><span>=</span><span>"</span>true<span>"</span></span><span>&gt;</span></span>English<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;</span>a</span> <span>href</span><span><span>=</span><span>"</span>https://example.com/de<span>"</span></span> <span>hreflang</span><span><span>=</span><span>"</span>de<span>"</span></span> <span>lang</span><span><span>=</span><span>"</span>de<span>"</span></span><span>&gt;</span></span>Deutsch<span><span><span>&lt;/</span>a</span><span>&gt;</span></span></span></code></pre><h2 id="2-translate">2. translate</h2><p>The <a href="https://html.spec.whatwg.org/multipage/dom.html#attr-translate"><code>translate</code> attribute</a> is used to <strong>indicate whether an element should be translated</strong> or not.</p><h3 id="why-use-translate?">Why use <code>translate</code>?</h3><p>Most website text is translatable by default (with some exceptions such as text on images or within SVGs). Translation tools, such as Google Translate, may suggest translation of page contents if the site's defined language differs from the browser's default language. However, there may be instances where this behaviour is unwanted.<br>Specific terms like company names, e-mail addresses or code examples should generally not be translated to avoid confusion. Automated translations are not always completely accurate, particularly with niche or technical words.</p><h3 id="how-to-use-translate">How to use <code>translate</code></h3><p>You can use translate on any HTML element. Assign an empty string (<code>""</code>) or <code>yes</code> for translation and <code>no</code> to avoid translation.</p><pre><code><span><span>&lt;!-- Original German text --&gt;</span></span><br><span><span><span><span>&lt;</span>p</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>span</span><span>&gt;</span></span>Wien<span><span><span>&lt;</span>span</span><span>&gt;</span></span> </span><br><span>  ist (wieder) die lebenswerteste Stadt der Welt!</span><br><span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;</span>p</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>span</span> <span>translate</span><span><span>=</span><span>"</span>no<span>"</span></span><span>&gt;</span></span>Wien<span><span><span>&lt;</span>span</span><span>&gt;</span></span> </span><br><span>  ist (wieder) die lebenswerteste Stadt der Welt!</span><br><span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></span><br><span></span><br><span><span>&lt;!-- What it would look like translated into English --&gt;</span></span><br><span><span><span><span>&lt;</span>p</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>span</span><span>&gt;</span></span>Vienna<span><span><span>&lt;</span>span</span><span>&gt;</span></span> </span><br><span>  named world's most liveable city (again)!</span><br><span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;</span>p</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>span</span> <span>translate</span><span><span>=</span><span>"</span>no<span>"</span></span><span>&gt;</span></span>Wien<span><span><span>&lt;</span>span</span><span>&gt;</span></span> </span><br><span>  named world's most liveable city (again)!</span><br><span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span></span><br><span></span></code></pre><h2 id="3-reversed">3. reversed</h2><p>The <a href="https://html.spec.whatwg.org/multipage/grouping-content.html#attr-ol-reversed"><code>reversed</code> attribute</a> is used to <strong>reverse ordered lists</strong> (<code>&lt;ol&gt;</code>) in the opposite order.</p><h3 id="why-use-reversed?">Why use <code>reversed</code>?</h3><p>Using the <code>reversed</code> attribute keeps the order of visual and semantic list items the same, but they are numbered from highest to lowest. This means adding this attribute to your ordered list (<code>&lt;ol&gt;</code>) will not reverse the list items but only the list numbers. For instance, this behaviour is helpful if you want to count down your top five desserts. However, the reversed attribute does not affect unordered lists (<code>&lt;ul&gt;</code>).</p><p><strong>Note:</strong> The reversed attribute does not affect unordered lists (<code>&lt;ul&gt;</code>).</p><h3 id="how-to-use-reversed">How to use <code>reversed</code></h3><p>Add the <code>reversed</code> attribute to your list element.</p><pre><code><span><span><span><span>&lt;</span>ol</span> <span>reversed</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>li</span><span>&gt;</span></span>Cookies<span><span><span>&lt;/</span>li</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>li</span><span>&gt;</span></span>Crema Catalana<span><span><span>&lt;/</span>li</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>li</span><span>&gt;</span></span>Tiramisu<span><span><span>&lt;/</span>li</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>li</span><span>&gt;</span></span>Pastel de Nata<span><span><span>&lt;/</span>li</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>li</span><span>&gt;</span></span>Sacher cake<span><span><span>&lt;/</span>li</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;/</span>ol</span><span>&gt;</span></span></span></code></pre><p>This will result in the following reversed list:</p><ol reversed=""><li>Cookies</li><li>Crema Catalana</li><li>Tiramisu</li><li>Pastel de Nata</li><li>Sacher cake</li></ol><p><strong>Note:</strong> Screen readers announce the list in DOM order along with the correct number: "5. Cookies, 4. Crema Catalana, etc.".</p><h2 id="4-controls">4. controls</h2><p>The <a href="https://html.spec.whatwg.org/multipage/media.html#attr-media-controls"><code>controls</code> attribute</a> instructs the browser to <strong>show the standard video or audio controls</strong>.</p><h3 id="why-use-controls?">Why use <code>controls</code>?</h3><p>Including playback controls on your video and audio content is essential for optimal user experience, accessibility and usability. These controls enable users to stop or adjust video/sound playback and assist those who may experience motion sickness or distraction while browsing your website.<br>The default controls include the playback essentials such as play, pause, seek (moving position) and volume, as well as fullscreen toggle, <a href="https://www.htmhell.dev/tips/the-track-element/">captions/subtitles and track</a> for video content only.</p><p><strong>Note:</strong> The browser controls provided as defaults should be used with caution. Sometimes keyboard-based navigation can cause problems, such as loss of focus, forcing the user to reposition themselves. Consider <a href="https://developer.mozilla.org/en-US/docs/Learn/Accessibility/Multimedia#creating_custom_audio_and_video_controls">implementing custom controls</a> or integrating an external media player equipped with accessibility features. <strong>However, it is still preferable to include controls than not to.</strong></p><h3 id="how-to-use-controls">How to use <code>controls</code></h3><p>You can add the <code>controls</code> attribute to the <code>&lt;video&gt;</code> or <code>&lt;audio&gt;</code> element.</p><pre><code><span><span><span><span>&lt;</span>video</span> <span>controls</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>source</span> <span>src</span><span><span>=</span><span>"</span>movie.mp4<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>video/mp4<span>"</span></span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>source</span> <span>src</span><span><span>=</span><span>"</span>movie.ogg<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>video/ogg<span>"</span></span><span>&gt;</span></span></span><br><span></span><br><span>  <span><span><span>&lt;</span>track</span> <span>kind</span><span><span>=</span><span>"</span>captions<span>"</span></span> <span>src</span><span><span>=</span><span>"</span>sampleCaptions.vtt<span>"</span></span> <span>srclang</span><span><span>=</span><span>"</span>en<span>"</span></span> <span>/&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>track</span> <span>kind</span><span><span>=</span><span>"</span>subtitles<span>"</span></span> <span>src</span><span><span>=</span><span>"</span>sampleSubtitles_en.vtt<span>"</span></span> <span>srclang</span><span><span>=</span><span>"</span>en<span>"</span></span> <span>/&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>track</span> <span>kind</span><span><span>=</span><span>"</span>subtitles<span>"</span></span> <span>src</span><span><span>=</span><span>"</span>sampleSubtitles_de.vtt<span>"</span></span> <span>srclang</span><span><span>=</span><span>"</span>de<span>"</span></span> <span>/&gt;</span></span></span><br><span></span><br><span>  Your browser does not support the video tag.</span><br><span><span><span><span>&lt;/</span>video</span><span>&gt;</span></span></span></code></pre><p><strong>Note:</strong> The default controls cannot be styled with CSS.</p><h2 id="5-autocomplete">5. autocomplete</h2><p>The <a href="https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#attr-fe-autocomplete"><code>autocomplete</code> attribute</a> <strong>enables the browser to complete form values automatically</strong> and can be applied to the <code>&lt;form&gt;</code>, <code>&lt;input&gt;</code>, <code>&lt;select&gt;</code>, and <code>&lt;textarea&gt;</code> elements.</p><h3 id="why-use-autocomplete?">Why use <code>autocomplete</code>?</h3><p>With the <code>autocomplete</code> attribute present, a browser can suggest a previous user's input for a form field's value, meaning a user does not have to remember or manually enter personal information. This results in significant benefits for individuals with cognitive impairments, reduced mobility, attention deficits, low vision, or blindness. Some people may find reduced manual input in forms particularly beneficial by lowering the need for extensive typing.</p><p>The <code>autocomplete</code> attribute improves the usability and efficiency of an HTML form for users by informing browsers and assistive technologies about the intended use of a specific form field. Screen readers use these autocomplete values to understand the nature of input fields and help users enter information more efficiently. For example, if a user's browser has saved information for a particular field (such as their name or e-mail), the screen reader will prompt them to fill in that information automatically.</p><h3 id="how-to-use-autocomplete">How to use <code>autocomplete</code></h3><p>You can assign different values to <code>autocomplete</code>.</p><p>If you choose <code>off</code>, the browser cannot automatically enter or select a value for this field.</p><pre><code><span><span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>email<span>"</span></span><span>&gt;</span></span>E-Mail<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span><span><span><span>&lt;</span>input</span> <span>name</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>autocomplete</span><span><span>=</span><span>"</span>off<span>"</span></span> <span>/&gt;</span></span></span></code></pre><p><strong>Note:</strong> Many password managers may still prompt the user to save information or use previously stored data.</p><p>If you choose <code>on</code>, the browser will complete the input automatically. However, since no further information concerning the expected data is given, the browser may use its own judgement.</p><pre><code><span><span><span><span>&lt;</span>form</span> <span>action</span><span><span>=</span><span>"</span>/<span>"</span></span> <span>autocomplete</span><span><span>=</span><span>"</span>on<span>"</span></span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>firstname<span>"</span></span><span>&gt;</span></span>First Name<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>firstname<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>firstname<span>"</span></span> <span>/&gt;</span></span></span><br><span></span><br><span>  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>lastname<span>"</span></span><span>&gt;</span></span>Last Name<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>lastname<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>lastname<span>"</span></span> <span>/&gt;</span></span></span><br><span></span><br><span>  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>email<span>"</span></span><span>&gt;</span></span>Email<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>/&gt;</span></span></span><br><span><span><span><span>&lt;/</span>form</span><span>&gt;</span></span></span></code></pre><p>The optimal solution is to specify distinct values for the required data by opting for the corresponding value from a <a href="https://www.w3.org/TR/WCAG21/#input-purposes">list of available input purposes</a>.</p><p>Your form could look like this:</p><pre><code><span><span><span><span>&lt;</span>form</span> <span>action</span><span><span>=</span><span>"</span>/<span>"</span></span> <span>autocomplete</span><span><span>=</span><span>"</span>on<span>"</span></span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>firstName<span>"</span></span><span>&gt;</span></span>First Name<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>input</span> <span>autocomplete</span><span><span>=</span><span>"</span>given-name<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>firstName<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>firstName<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>/&gt;</span></span></span><br><span>  </span><br><span>  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>lastName<span>"</span></span><span>&gt;</span></span>Last Name<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>input</span> <span>autocomplete</span><span><span>=</span><span>"</span>family-name<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>lastName<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>lastName<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>/&gt;</span></span></span><br><span>  </span><br><span>  <span><span><span>&lt;</span>label</span> <span>for</span><span><span>=</span><span>"</span>email<span>"</span></span><span>&gt;</span></span>Email<span><span><span>&lt;/</span>label</span><span>&gt;</span></span></span><br><span>  <span><span><span>&lt;</span>input</span> <span>autocomplete</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>id</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>email<span>"</span></span> <span>/&gt;</span></span></span><br><span><span><span><span>&lt;/</span>form</span><span>&gt;</span></span></span></code></pre><p><strong>Note:</strong> The absence or incorrect use of an <code>autocomplete</code> attribute in an input field can cause inconvenience to users, particularly those with cognitive disabilities. Browsers cannot suggest accurate values, making it difficult for individuals to provide the expected input. Please make sure you choose the correct value.</p><h2 id="conclusion">Conclusion</h2><p>I hope the exploration of these attributes has sparked your interest. When you embark on your next project, remember the significance of prioritising usability, accessibility and simplicity.</p><h2 id="about-daniela-kubesch">About Daniela Kubesch</h2><p>Daniela Kubesch is a frontend developer and designer who is passionate about accessibility and inclusive design. She strongly believes in equality and inclusion and is committed to making digital services accessible. Daniela is also a co-creator of <a href="https://a11yphant.com/">a11yphant.com</a>, a platform that teaches the basics of web accessibility.</p><p>Website/Blog: <a href="https://dnikub.dev/">dnikub.dev</a><br>Mastodon: <a href="https://front-end.social/@dnikub">front-end.social/@dnikub</a><br>Twitter: <a href="https://twitter.com/dnikub">@dnikub</a><br>LinkedIn: <a href="https://linkedin.com/in/danikubesch">danikubesch</a></p><h2 id="more-articles">More articles</h2><nav aria-label="Select next or previous entry"><ol><li><a href="https://www.htmhell.dev/adventcalendar/2023/3/" rel="prev"><p>Previous day (3)</p>The Form Attribute - Enhancing Form Layout Flexibility</a></li></ol></nav></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Spotify will reduce total headcount by 17% across the company (310 pts)]]></title>
            <link>https://newsroom.spotify.com/2023-12-04/an-update-on-december-2023-organizational-changes/</link>
            <guid>38514537</guid>
            <pubDate>Mon, 04 Dec 2023 07:23:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newsroom.spotify.com/2023-12-04/an-update-on-december-2023-organizational-changes/">https://newsroom.spotify.com/2023-12-04/an-update-on-december-2023-organizational-changes/</a>, See on <a href="https://news.ycombinator.com/item?id=38514537">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-off-canvas-content="">

        <main role="main">

            
            
<article id="post-26893" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">

        <header>
    

    
</header> <!-- end article header -->    

    <div itemprop="text">
                                                            <p><i><span>Earlier today, CEO <strong>Daniel Ek</strong> shared the following note about the company’s organizational changes with all Spotify employees.</span></i></p>
<p><span>Team,&nbsp;</span></p>
<p><span>Over the last two years, we’ve put significant emphasis on building Spotify into a truly great and sustainable business – one designed to achieve our goal of being the world’s </span><span>leading audio company</span> <span>and</span><span> one that will consistently drive profitability and growth into the future. While we’ve made worthy strides, as I’ve shared many times, we still have work to do. </span><span>Economic growth has slowed dramatically and capital has become more expensive. Spotify is not an exception to these realities.</span></p>
<p><span>This brings me to a decision that will mean a significant step change for our company. To align Spotify with our future goals and ensure we are right-sized for the challenges ahead, I have made the difficult decision to reduce our total headcount by approximately 17% across the company. I recognize this will impact a number of individuals who have made valuable contributions. To be blunt, many smart, talented and hard-working people will be departing us.</span></p>
<p><span>For those leaving, we’re a better company because of your dedication and hard work. Thank you for sharing your talents with us. I hope you know that your contributions have impacted more than half a billion people and millions of artists, creators, and authors around the world in profound ways.&nbsp;</span></p>
<p><span>I realize that for many, a reduction of this size will feel surprisingly large given the recent positive earnings report and our performance. We debated making smaller reductions throughout 2024 and 2025. Yet, considering the gap between our financial goal state and our current operational costs, I decided that a substantial action to rightsize our costs was the best option to accomplish our objectives. While I am convinced this is the right action for our company, I also understand it will be incredibly painful for our team.&nbsp;</span></p>
<p><span>To understand this decision, I think it is important to assess Spotify with a clear, objective lens. In 2020 and 2021, we took advantage of the opportunity presented by lower-cost capital and invested significantly in team expansion, content enhancement, marketing, and new verticals. These investments generally worked, contributing to Spotify’s increased output and the platform’s robust growth this past year. However, we now find ourselves in a very different environment. And despite </span><span>our efforts to reduce costs this past year, our cost structure for where we need to be is still too big.</span></p>
<p><span>When we look back on 2022 and 2023, it has truly been impressive what we have accomplished. But, at the same time, the reality is much of this output was linked to having more resources. By most metrics, we were more productive but less efficient. We need to be both. While we have done some work to mitigate this challenge and become more efficient in 2023, we still have a ways to go before we are both productive and efficient. Today, we still have too many people dedicated to supporting work and even doing work around the work rather than contributing to opportunities with real impact. More people need to be focused on delivering for our key stakeholders – creators and consumers. In two words, we have to become </span><span>relentlessly resourceful</span><span>.</span></p>
<p><span>I know you will all be anxious to hear the next steps about how this process will work. If you are an impacted employee, you will receive a calendar invite within the next two hours from HR for a one-on-one conversation. These meetings will take place before the end of the day on Tuesday, and while <strong>Katarina</strong> will provide more detail on all of the specifics, please know the following will apply to all of these bandmates:</span></p>
<ul>
<li aria-level="1"><i><span>Severance pay: </span></i><span>We will start with a baseline for all employees, with the average employee receiving approximately five months of severance. This will be calculated based on local notice period requirements and employee tenure.</span></li>
<li aria-level="1"><i><span>PTO:</span></i><span> All accrued and unused vacation will be paid out to any departing employee.</span></li>
<li aria-level="1"><i><span>Healthcare:</span></i><span> We will continue to cover healthcare for employees during their severance period.&nbsp;</span></li>
<li aria-level="1"><i><span>Immigration support:</span></i><span> For employees whose immigration status is connected with their employment, HRBPs are working with each impacted individual in concert with our mobility team.&nbsp;</span></li>
<li aria-level="1"><i><span>Career Support:</span></i> <i><span>&nbsp;</span></i><span>All employees will be eligible for outplacement services for two months.</span></li>
</ul>
<p><span>For the team that will remain at Spotify, I know this decision will be difficult for many. Please know we are focused on treating our impacted colleagues with the respect and compassion they deserve.</span></p>
<h2><b>Looking Ahead</b></h2>
<p><span>The decision to reduce our team size is a hard but crucial step towards forging a stronger, more efficient Spotify for the future. But it also highlights that we need to change how we work. In Spotify’s early days, our success was hard won. We had limited resources and had to make the most of every asset. Our ingenuity and creativity were what set us apart. As we’ve grown, we’ve moved too far away from this core principle of resourcefulness.&nbsp;</span></p>
<p><span>The Spotify of tomorrow must be defined by being relentlessly resourceful in the ways we operate, innovate, and tackle problems. This kind of resourcefulness transcends the basic definition – it’s about preparing for our next phase, where being lean is not just an option but a necessity.</span></p>
<p><span>Embracing this leaner structure will also allow us to invest our profits more strategically back into the business. With a more targeted approach, every investment and initiative becomes more impactful, offering greater opportunities for success. This is not a step back; it’s a strategic reorientation. We’re still committed to investing and making bold bets, but now, with a more focused approach, ensuring Spotify’s continued profitability and ability to innovate. Lean doesn’t mean small ambitions; it means smarter, more impactful paths to achieve them.&nbsp;</span></p>
<p><span>Today is a difficult but important day for the company. To be very clear, my commitment to our mission and belief in our ability to achieve it has never been stronger. I hope you will join me on Wednesday for Unplugged to discuss how we move forward together. A reduction of this size will make it necessary to change the way we work, and we will share much more about what this will mean in the days and weeks ahead. Just as 2023 marked a new chapter for us, so will 2024 as we build an even stronger Spotify.&nbsp;</span></p>
<p><span>– Daniel</span></p>
                </div> <!-- end article section -->

    </article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lack of sunlight during the day is worse than electric lighting at night (211 pts)]]></title>
            <link>https://english.elpais.com/health/2023-12-01/chronobiologist-and-nobel-laureate-in-medicine-michael-rosbash-lack-of-sunlight-during-the-day-is-worse-than-electric-lighting-at-night.html</link>
            <guid>38513782</guid>
            <pubDate>Mon, 04 Dec 2023 04:35:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/health/2023-12-01/chronobiologist-and-nobel-laureate-in-medicine-michael-rosbash-lack-of-sunlight-during-the-day-is-worse-than-electric-lighting-at-night.html">https://english.elpais.com/health/2023-12-01/chronobiologist-and-nobel-laureate-in-medicine-michael-rosbash-lack-of-sunlight-during-the-day-is-worse-than-electric-lighting-at-night.html</a>, See on <a href="https://news.ycombinator.com/item?id=38513782">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>The Earth had been spinning on its axis for a billion years when the first living beings appeared. Since then, we have adapted to alternate between light and darkness. Geneticist and chronobiologist Michael Rosbash, 79, a professor at Brandeis University in Massachusetts and a researcher at the Howard Hughes Medical Institute in Maryland, reminded us of that fact in his acceptance speech for <a href="https://www.youtube.com/watch?v=0X2jY8isna8" target="_blank">the 2017 Nobel Prize in Medicine</a>. The award, which he shares with his friend and collaborator Jeffrey C. Hall and Michael W. Young, recognized their contribution to deciphering the molecular gears of the biological clock that controls our circadian rhythms. From the Latin circa, “around” and dies, “day,” circadian rhythms are the 24-hour changes in our physiology that synchronize with the day-night cycle and modulate when we are hungry, sleepy, want sex and have asthma attacks or a fever in the afternoon.</p><p>Bacteria, plants and biomedical research’s most popular insect, the <i>Drosophila melanogaster</i> or fruit fly—the basis of Rosbash’s findings—also have biological clocks. On November 13, wearing a tie with Santiago Ramón y Cajal’s neuronal designs, the chronobiologist gave a lecture for young researchers, at the Madrid hospital named for the Spanish Nobel Prize winner, now celebrating two decades of its research foundation (FIBioHRC). The event took place within the framework of the <a href="https://www.nobelprize.org/nobel-prize-inspiration-initiative/" target="_blank">Nobel Prize Inspiration</a> Initiative and in collaboration with the AstraZeneca Foundation, which arranged this interview with EL PAÍS in a nearby hotel.</p><p><b>Question</b>. During your Nobel Prize acceptance speech, you mentioned that 50% of our genes were regulated by circadian rhythms, but in your talk you said that it is at least 70%?</p><p><b>Answer</b>. I have updated the figure due to new research done over the past six years. The 50% figure came from research in rodents, but in 2019 there was a large study done on baboons, the first in primates, and [the figure] went to 70%.</p><p><b>Q</b>. How did you become interested in <a href="https://english.elpais.com/science-tech/2023-08-14/why-do-we-often-wake-up-just-before-the-alarm-goes-off.html">chronobiology</a>?</p><p><b>A</b>. [It began] almost 50 years ago, through my friend Jeffrey C. Hall, who also started as a professor at my university. He was already working on fly neurogenetics and knew about circadian rhythms. I had laboratory expertise that could be useful for his research. I suggested that we collaborate and see if that would go anywhere.</p><p><b>Q</b>. And you two have made it this far.</p><p><b>A</b>. To my surprise [smiles].</p><p><b>Q</b>. You have forged your career with basic research, which is sometimes undervalued. How would you encourage young researchers to explore it and institutions or companies to fund it?</p><p><b>A</b>. I tell young researchers that I hope they do something interesting and that they like it. Public funding agencies face the biggest challenge, because basic research is the foundation for applied research; it is very short-sighted to try to short-circuit the process by going directly to something translational. It is politically convenient because the public understands if you say you are going to cure <a href="https://english.elpais.com/science-tech/2023-07-07/azheimers-drug-leqembi-granted-full-fda-approval-paving-the-way-for-medicare-coverage.html">Alzheimer’s</a>, but if the foundations do not exist, it is money wasted. On the other hand, the pharmaceutical and biotech industries are very good at applied science. They make money and, when they see an opportunity, they go for it. I think public research organizations should focus on basic science, and industry should focus on applied science.</p><p><b>Q</b>. What links the circadian rhythms of flies, which have 100,000 neurons, and those of people, who have 86 billion?</p><p><b>A</b>. The basic process of keeping time. What happens in neurons is the same, although mammals have a larger number. From there, we try to use these neurons as a window into more general questions about brain science and behavior.</p><p><b>Q</b>. For example?</p><p><b>A</b>. Wiring. The general question is how animal brains carry out behavioral programs, how behavior works. Of course, a fruit fly performs simpler behaviors than we do and [is] simpler to investigate. So what is the program that enables complex behavior? We are making progress in appreciating how complex the circuits are at the anatomical level, even in the fly brain. It all has to do with the wiring, how the circuitry is designed to carry out a behavioral program.</p><figure><span><img alt="Michael Rosbash" decoding="auto" height="291" srcset="https://images.english.elpais.com/resizer/KEIB7gzSA0Z8VMQcncJT-GLvFgc=/414x0/filters:focal(1411x591:1421x601)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/MFEO3HRUIZAMDOCM73D5YUNUUI.jpg 414w,https://images.english.elpais.com/resizer/w5kfpCLOZCxwttmkkR6ZrxJvt1E=/828x0/filters:focal(1411x591:1421x601)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/MFEO3HRUIZAMDOCM73D5YUNUUI.jpg 640w,https://images.english.elpais.com/resizer/riaEPf0kAuE0wUP8-zZeM8KqpQg=/980x0/filters:focal(1411x591:1421x601)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/MFEO3HRUIZAMDOCM73D5YUNUUI.jpg 1000w,https://images.english.elpais.com/resizer/wjwAC9RjP3x23Nu09QZltFiSmiI=/1960x0/filters:focal(1411x591:1421x601)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/MFEO3HRUIZAMDOCM73D5YUNUUI.jpg 1960w" width="414" loading="lazy" src="https://images.english.elpais.com/resizer/KEIB7gzSA0Z8VMQcncJT-GLvFgc=/414x0/filters:focal(1411x591:1421x601)/cloudfront-eu-central-1.images.arcpublishing.com/prisa/MFEO3HRUIZAMDOCM73D5YUNUUI.jpg" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw"><svg viewBox="0 0 40 40"><use xlink:href="#svg-ampliar"></use></svg></span><figcaption><span>Nobel Laureate in Medicine Michael Rosbash, wearing a tie with Santiago Ramón y Cajal’s neuronal designs. </span><span>Jaime Villanueva</span></figcaption></figure><p><b>Q</b>. One of the things that flies and privileged people have in common is napping and sleeping at night. What is the biological purpose of sleep and of these intermediate pauses during the day?</p><p><b>A</b>. We do not know. Memories are consolidated <a href="https://english.elpais.com/health/2023-11-30/why-do-sleep-attacks-occur-during-the-day.html">during sleep</a> and neuronal morphology is modified during sleep. All that happens, but I do not think that is the major purpose of sleep. We do not know what fly and human sleep, for example, have in common. My guess is that it is related to metabolism, such as recharging ATP [adenosine triphosphate, a key energy molecule in cells]. The brain is the largest consumer of ATP; perhaps there is a metabolic need for recharging.</p><p><b>Q</b>. <a href="https://www.science.org/doi/10.1126/science.284.5423.2177" target="_blank">Our internal clock has a natural 24-and-a-quarter-hour cycle</a>. After millions of years here, why is it not set to 24 hours, and we have to synchronize daily?</p><p><b>A</b>. For humans, we don’t know, but there is information from other animals. Some, like sheep and rodents, are seasonal in terms of reproduction. Their physiology changes with the season, and the seasons are determined by the length of the day. To control their reproductive physiology, they compare the offset of their clocks with the length of the photoperiod, the amount of daylight, which varies throughout the year. That is, they use it as a measuring device, although this [explanation] is partly speculative.</p><p><b>Q</b>. How does electric light, which we even take to bed with us with our screens, contribute to chronodisruption?</p><p><b>A</b>. It is a problem, but it is difficult to estimate its severity. We are exposed to too much light at night and not enough during the day because indoor electric lighting is far inferior to sunlight. In fact, according to recent research, a lack of sunlight during the day is even worse than the presence of light at night. Many cases of sleep problems are cured by addressing these environmental factors.</p><p>On the other hand, research conducted in Colorado on people who camp out in nature for a couple of weeks found that they sleep better, go to bed when it gets dark and wake up earlier. There are also studies in Brazil comparing those who stayed in the jungle with those who moved to the city. They are like us, they sleep worse, they go to bed later; you can immediately see the change in pattern. All of them, like you and me, are slightly sleep deprived. If the lights go out in a seminar room at 4 p.m., half the audience is snoring right away. That does not happen with well-rested individuals. It’s a totally sleep-deprived culture.</p><p><b>Q</b>. You said you take your statins at night, when they are most effective. The time of day also influences the efficacy or adverse effects of antihypertensives, corticosteroids and <a href="https://english.elpais.com/health/2023-10-25/andres-cervantes-oncologist-innovative-cancer-drugs-have-similar-costs-regardless-of-their-benefit.html">chemotherapy</a>. Should we change the way they are prescribed?</p><p><b>A</b>. The short answer is yes. The more important question—as with almost everything in pharmacology and in life—is what is the cost-benefit analysis? For society, physicians and the pharmaceutical industry, what is gained versus what is lost by taking this into account? Giving chemotherapy for some cancers at 3 a.m. has worked better, but people don’t want to work at that hour. Until very convincing research is published, there is not going to be a significant change because there is so much inertia in everything we do.</p><p><b>Q</b>. <a href="https://www.thelancet.com/journals/lanonc/article/PIIS1470-2045(19)30455-3/fulltext" target="_blank">According to the WHO cancer agency (IARC), shift work or night work is potentially carcinogenic.</a> What would you advise people with those jobs?</p><p><b>A</b>. The trick is to pretend that night is day and vice versa. If you do this very rigorously, you can avoid most problems because your body doesn’t know what is day and what is night. What matters is how much light comes in and when you eat. If there is no light and you keep the room dark for eight hours of sleep, you are not interrupted and you don’t eat during that period, your body doesn’t know the difference. The problem is interacting with your family, with the rest of the world.</p><p><b>Q</b>. Why does snacking at night <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6288903/" target="_blank">increase the risk of obesity and metabolic syndrome</a>?</p><p><b>A</b>. We don’t really understand why. One hypothesis has to do with our DNA damage repair systems, which are regulated by the circadian clock. Food contains a mixture of nutrients and toxins. Plants produce toxins to avoid being eaten, such as psoralen, which is abundant in celery. Snacking at night introduces toxins that, at that hour, our repair systems are not ready to eliminate. There is also speculation that the major epidemic of epithelial cancers, such as colon cancer, in the U.S. is because of this.</p><p><b>Q</b>. Is this related to time-restricted feeding, which follows the pattern of light and dark?</p><p><b>A</b>. That diet is not much different from avoiding snacking at night. No one knows why these patterns are beneficial, but metabolism changes depending on the time of day, so eating food in sync with circadian metabolic processes makes sense. If something is not too difficult or painful and it makes sense, why not do it?</p><p><b>Q</b>. Juan Antonio Madrid, one of the pioneers of chronobiology in Spain, poses this question to you: Would it be possible to address the chronodisruption that comes with aging by manipulating the molecular clock with drugs?</p><p><b>A</b>. I think so. Older flies have the same sleep pattern as older people, fragmented sleep: in the first four hours, sleep is solid and then they start waking up frequently. In young people, sleep also becomes lighter after a few hours, but not so much that they wake up. Why this happens is not well understood. To some extent, this goes back to the previous question, what is sleep for? The two things are almost certainly related.</p><p><i>Sign up for&nbsp;</i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i>our weekly newsletter</i></a><i>&nbsp;to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Paper vs. devices: Brain activation differences during memory retrieval (127 pts)]]></title>
            <link>https://www.frontiersin.org/articles/10.3389/fnbeh.2021.634158/full</link>
            <guid>38513617</guid>
            <pubDate>Mon, 04 Dec 2023 04:04:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.frontiersin.org/articles/10.3389/fnbeh.2021.634158/full">https://www.frontiersin.org/articles/10.3389/fnbeh.2021.634158/full</a>, See on <a href="https://news.ycombinator.com/item?id=38513617">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Introduction</h2>
<p>The properties of human memory have been investigated with several approaches, including clinical, psychological, and neuroimaging studies (<a href="#B34">Tulving, 2002</a>; <a href="#B33">Schacter et al., 2007</a>; <a href="#B21">Miyashita, 2019</a>). It remains to be elucidated how brain activations during retrieval processes are modulated by different encoding procedures, because it has been reported that retrieval performances on paired words became worse when the categorically similar target words were simultaneously encoded, suggesting the importance of the context-dependent encoding (<a href="#B26">Nairne, 2002</a>; <a href="#B12">Goh and Lu, 2012</a>). It is also possible that the manner with which specific information is encoded—e.g., whether by using a paper notebook, computer, or mobile device—may affect retrieval processes. A recent behavioral study showed that students who took longhand notes performed better on conceptual questions than those who took notes on laptop computers (<a href="#B25">Mueller and Oppenheimer, 2014</a>). A reasonable explanation for this interesting finding would be that the use of a paper notebook enables users to summarize and reframe information in their own words for encoding, while the use of a laptop tends to encourage them to write down information more passively (i.e., more nearly verbatim). The former processes thus naturally ensure deeper and more solid encoding <i>via</i> the active process of making notes. Moreover, it has been reported that longhand note-taking enhanced the performance of students on recognition of memorized words, even though typing on a computer keyboard allowed greater speed (<a href="#B1">Aragón-Mendizábal et al., 2016</a>).</p>
<p>Another possible explanation for the superiority of longhand note-taking for conceptual understanding is related to the use of paper for writing/reading since a behavioral study reported the superiority of paper to computer screens in terms of reading comprehension (<a href="#B36">Wästlund et al., 2005</a>; <a href="#B20">Mangen et al., 2013</a>). These studies indicated the importance of visual and tactile cues for perceiving <i>constant</i> physical sizes and spatial locations, because “the material substrate of paper provides physical, tactile, spatiotemporally fixed cues to the length of the text” (<a href="#B20">Mangen et al., 2013</a>). We hypothesized that the use of a paper notebook, together with longhand note-taking, would enhance both memory encoding and later retrieval processes that could then be investigated at the brain level. More specifically, the utilization of the paper likely enhances the processes of associating episodic (<i>what</i>) and spatial (<i>where</i>) information, especially in the hippocampus, given its well-established role in the integration of what/where/when information (<a href="#B4">Broadbent et al., 2004</a>; <a href="#B7">Eichenbaum, 2004</a>; <a href="#B5">Chadwick et al., 2010</a>).</p>
<p>To address this issue, we compared three groups of participants who used a paper notebook (Note), electronic tablet (Tablet), or smartphone (Phone) during the encoding phase. Participants in the Tablet group used a stylus pen, thereby controlling for the effects of longhand writing with a pen in the Note group. It should be noted that physical sizes and spatial locations of a document remain constant for a paper notebook, whereas they become variable on the display of a tablet or smartphone. Moreover, not only the physical interaction of the hand with the pen/paper during note-taking but the actual writing of notes relative to each page of the real paper provides more concrete encoding information, because that information can be easily erased and updated by new information on the physically same screen of a tablet or smartphone.</p>
<p>We asked participants to write down scheduled appointments, and then, after one hour during which they performed an interference task, we conducted a retrieval task in which we tested participants’ recognition memory of those appointments (<a href="#F1">Figure 1</a>). We further hypothesized that the interaction with physical paper, rather than the mental editing/preparation of the notes or the physical act of handwriting, provides episodic and spatial information of notes relative to each page of real paper, together with visual/tactile information from the paper. These properties and cues of papers could help to retrieve specific information, and thus lead to increased activations in specified brain regions for the Note group, compared with the other groups using mobile devices lacking such processes.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g001.jpg" name="figure1" target="_blank">
<img id="F1" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g001.jpg" src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g001.jpg"></a></p><p><strong>Figure 1</strong>. Recording and retrieval of schedule information. Participants first read dialogues (in Japanese), then extracted scheduled appointments contained in the dialogues, and wrote them down with a paper notebook (<i>Note</i> group), electronic tablet (<i>Tablet</i> group), or smartphone (<i>Phone</i> group). This procedure reproduces the daily making of to-do lists and naturally involves encoding processes. The upper panel shows a typical example (English translation) written by a participant. After an hour including an interference task, the participants were asked to answer questions about the appointments and reported their level of confidence in their answer to each question. The lower panel shows a typical trial in this retrieval task.</p>
</div> 


<p>It has been proposed that the hippocampus and the prefrontal cortex support complementary functions in episodic memory and that the bidirectional information flow between these regions may play a crucial role in integrating and consolidating individual information (<a href="#B23">Moscovitch et al., 2016</a>; <a href="#B8">Eichenbaum, 2017</a>). A previous functional magnetic resonance imaging (fMRI) study reported that episodic memory of a word or picture is related to a functional network that includes the left posterior precuneus and the left lateral prefrontal cortex (<a href="#B19">Lundstrom et al., 2003</a>). On the other hand, language function is critically involved in human episodic memory, and some language-related regions would be recruited during both memory encoding and retrieval. The left lateral premotor cortex (LPMC) and left opercular/triangular parts of the inferior frontal gyrus (F3op/F3t) are suggested to have central roles in syntactic processing, whereas the left angular/supramarginal gyri (AG/SMG) make a major contribution to lexical processing (<a href="#B31">Sakai, 2005</a>). Moreover, the right frontal cortex was identified as a supportive region for syntactic processing (<a href="#B17">Kinno et al., 2014</a>). Activations in these regions would be observed during memory retrieval because fMRI studies showed that the hippocampus and language-related regions involved in the encoding phase were also activated during the retrieval phase (<a href="#B30">Rugg et al., 2008</a>). The retrieval task we used critically involved episodic memory of scheduled appointments, and thus activations in these regions would be increased more for the Note group than the other groups.</p>
<h2>Materials and Methods</h2>
<h3>Participants</h3>
<p>University student volunteers (48 native Japanese speakers, 18 females) aged 18–29 years were openly recruited from multiple sources, including the University of Tokyo and Sophia University, as well as the participant pool of the NTT Data Institute of Management Consulting. The laterality quotient (LQ) was measured according to the Edinburgh inventory (<a href="#B27">Oldfield, 1971</a>); all participants but one were right-handed, and the exception was both-handed (LQ: −14). As stated above, the participants were divided into three groups: Note, Tablet, and Phone groups (<a href="#T1">Table 1</a>). These three groups were age- and LQ-matched (Kruskal–Wallis test, <i>p</i> &gt; 0.1), as well as gender-matched (Fisher’s exact test for count data, <i>p</i> = 0.17). Each participant first answered a questionnaire on their daily use of paper notebooks, electronic tablets, and smartphones for scheduling in an academic or personal context (seven-point scale for each). Based on this result, electronic tablet users were assigned to the Tablet group, and smartphone users (those on the highest scale for smartphone use) were assigned to either the Tablet or Phone group. To estimate short-term memory ability, we used the number-letter sequencing in the Wechsler Adult Intelligence Scale—Fourth Edition (<a href="#B6">Drozdick et al., 2012</a>), and the maximum length of memorized sequences was not significantly different among the three groups (<i>p</i> = 0.4). All participants in the Note group used paper notebooks for daily schedule management, whereas eight and seven participants in the Tablet and Phone groups, respectively, also used paper notebooks for that purpose. To control the experience and accustomedness of using paper notebooks for daily schedule management, these 15 participants (with eight females) were separately designated the <i>Device</i> group, which was used in behavioral and activation analyses.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t001.jpg" name="Table1" target="_blank">
<img id="T1" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t001.jpg" src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t001.jpg"></a></p><p><strong>Table 1</strong>. Basic data on participants.</p></div> 


<p>Before they participated in the study, the nature and possible consequences of the studies were explained to each participant and written informed consent was obtained afterward. None of the participants had a history of neurological or psychological disorders. Approval for the experiments was obtained from the institutional review board of the University of Tokyo, Komaba.</p>
<h3>Stimuli and Tasks</h3>
<p>Two sets of written dialogues between two or three persons (a set of dialogues on academic matters and a set on personal matters) were presented to the participants, who were asked to imagine that they were participating in those dialogues. There were seven daily scheduled appointments for the academic context and seven for the personal context (in February and March, respectively). While silently reading the dialogues, participants were asked to enter each of these appointments into a monthly calendar (<a href="#F1">Figure 1</a>, upper panel). The participants used either a paper notebook [Noritsu NOLTY Notebook (2017), size 20.6 × 17.6 cm<sup>2</sup> when opened], an electronic tablet [iPad Pro 10.5 inch (2017), screen size 21.4 × 16.1 cm<sup>2</sup> in landscape orientation], or a smartphone (Google Nexus 5 LG-D821, screen size 6.2 × 10.9 cm<sup>2</sup> in portrait orientation), where the paper notebook and electronic tablet were similar in physical layout (size and orientation). All three types of calendars had a day, week, and month view, but we used only the month view. In the case of the paper notebook and electronic tablet, appointments could only be viewed and edited individually in the relevant month (i.e., discrete views). In the smartphone, individual weeks could be viewed and edited by swiping continuously (i.e., continuous views). This difference was notable, in that schedule information would be encoded relative to the <i>spatial configuration</i> of one month (see <a href="#F1">Figure 1</a>) for the paper notebook and electronic tablet.</p>
<p>Regarding input methods, a four-color pen was used to write in the paper notebook [the use of color(s) was up to each participant], and a stylus pen was used to write on the electronic tablet with a free choice of multiple colors (without using a virtual keyboard). In the case of the smartphone, the text was written by either flick input with the finger(s) or by using a virtual keyboard. In Japanese, there are three types of characters (<i>hiragana</i>, <i>katakana</i>, and <i>kanji</i>; kanji basically consists of Chinese characters), and kana-kanji transformation is usually used for inputs in mobile devices and computers (kana-kanji transformation converts a limited number of hiragana to vast numbers of kanji by requiring users to select appropriate kanji from multiple candidates). The flick input utilizes a telephone keypad with a three by four layout, and one hiragana character can be selected by either tapping a keypad or flicking from a keypad to one of four directions (up, down, left, or right) to enter one of five hiragana characters sharing the same initial consonant.</p>
<p>We measured the time required by participants to write down the appointments, but we set no time limit. When the participants finished writing down, they were instructed to review the calendar for 30 s. Then, after the retention period for an hour including an interference task, participants were asked to recall those appointments in a retrieval task; the experimental purpose of writing down the appointments was not disclosed to them. The interference task involved listening comprehension; participants were informed that they would hear a story, and then be asked about its contents while lying in an MRI scanner. We used the first 6 min of a narrated version of a Japanese classic short story called “<i>Ma-jutsu</i> (<i>Magic</i>)” (written by Ryūnosuke Akutagawa, narrated by Takeshi Sasaki, and published by Pan Rolling, Japan). This story was unfamiliar to all participants. The auditory stimuli were presented through a headphone and participants were not permitted to take notes while listening. Sixteen questions about the detailed contents of the story were displayed inside the scanner (two questions per run), and the participants pressed one of four buttons to select the right answer.</p>
<p>After a short break outside the scanner to adjust the time between the encoding and retrieval phases to 1 h, participants performed a retrieval task inside the scanner (<a href="#F1">Figure 1</a>, lower panel), in which 16 questions about detailed contents of the appointments were displayed (two questions per run). Out of the 16 questions, seven required recalling of the relationships between multiple appointments, one required the conversion from the date to the day of the week (using the spatial information of the calendar), and three required recalling from similar or confusing appointments. The remaining five questions were more straightforward and thus considered as the <i>easier</i> questions. In each trial, a question was presented with four choices, and the participants pressed a button to select the right answer within 10 s. After an interval of 1 s, participants reported their level of confidence (1–4 scale, 4 = very confident) for that answer by pressing one of four buttons within 2 s. These responses were used to assess the correctness of each participant’s self-evaluation, where the true positive rate vs. the false positive rate was plotted for each of the four levels of confidence. By connecting these plots, we obtained a receiver operating characteristics curve (<a href="#B9">Fawcett, 2006</a>), and we used the area under the curve (AUC) for this assessment (0 = perfectly wrong; 0.5 = no distinction; 1 = perfectly correct).</p>
<p>As a control condition, we added a 2-back task into the run with the retrieval task. In each trial of the 2-back task, two different non-words, each with three Japanese characters, were sequentially displayed (each for 2 s). These characters were randomly selected from those used in the retrieval tasks, where the same type of characters (either hiragana, katakana, or kanji) was presented in a block of trials. Then four choices were shown for 5 s with a new non-word to be remembered. The correct answer was the non-word that appeared 2-back before but in a different order of three characters. There were two to four continuous trials with button pressings in each block.</p>
<p>Each run consisted of three 2-back blocks and two retrieval task trials, in which a 2-back block always started first, and the 2-back blocks and retrieval task trials were alternated. As fMRI events, we estimated the 6-s memory retrieval phase [determined by response times (RTs)] and the subsequent 4-s <i>post hoc</i> period from each 10-s period of the retrieval task, as well as a 5-s event for the 2-back task. With regards to contrasts between events, we always applied an exclusive mask of negative activations for the control conditions (one-sample <i>t-test</i>, uncorrected <i>p</i> &lt; 0.05). During the scans, the participants wore earplugs and an eyeglass-like MRI-compatible display (resolution = 800 × 600 pixels, framerate = 60 fps; VisuaStim Digital, Resonance Technology Inc., Northridge, CA, USA). The stimuli were all presented in yellow letters on a black background. For fixation, a small red cross was shown at the center of the screen when a stimulus was not shown. The stimulus presentation and collection of behavioral data (accuracy and RTs) were controlled using the Presentation software package (Neurobehavioral Systems, Albany, CA, USA).</p>
<h3>MRI Data Acquisition</h3>
<p>The MRI scans were conducted in a 3.0 T scanner (Signa HDxt; GE Healthcare, Milwaukee, WI, USA) with a bird-cage head coil. Each participant was in a supine position, and his or her head was immobilized inside the coil. As regards the structural images, high-resolution T1-weighted images of the whole brain (136 axial slices, 1 × 1 × 1 mm<sup>3</sup>) were acquired with a three-dimensional fast spoiled gradient-echo (3D FSPGR) acquisition [repetition time (TR) = 8.6 ms, echo time (TE) = 2.6 ms, flip angle (FA) = 25°, field of view (FOV) = 256 × 256 mm<sup>2</sup>]. With respect to the time-series data of fMRI, we used a gradient-echo echo-planar imaging (EPI) sequence (TR = 2 s, TE = 30 ms, FA = 78°, FOV = 192 × 192 mm<sup>2</sup>, resolution = 3 × 3 mm<sup>2</sup>). We scanned a set of 30 axial slices that were 3-mm thick with a 0.5-mm gap, covering the range of −38.5 to 66 mm from the line of the anterior commissure to the posterior commissure (AC-PC). In a single scanning run, we obtained 45 volumes and dropped the initial four volumes from analyses due to MR signal increases.</p>
<h3>fMRI Data Analyses</h3>
<p>The fMRI data were analyzed in a standard manner using SPM12 statistical parametric mapping software (Wellcome Trust Center for Neuroimaging<sup id="footnotesuper1"><a id="note1a"></a><a href="#note1">1</a></sup>; <a href="#B10">Friston et al., 1994</a>) implemented on MATLAB (Math Works, Natick, MA, USA). The acquisition timing of each slice was corrected using the middle slice (the 15th slice chronologically) as a reference for the functional images. We spatially realigned each volume to the first volume of consecutive runs, and a mean volume was obtained. We set the threshold of head movement during a single run as follows: within a displacement of 2 mm in any of the three directions, and a rotation of 1.4° around any of the three axes. These thresholds were empirically determined in our previous studies (<a href="#B16">Kinno et al., 2008</a>). If a run included one or several images over this threshold, we replaced the outlying image with an interpolated image, which was the average of the chronologically former and latter ones, and conducted the realignment procedure again. The realigned data were resliced every 3 mm using seventh-degree B-spline interpolation.</p>
<p>Each individual’s structural image was matched with the mean functional image generated during realignment. The resultant structural image was spatially normalized to the standard brain space as defined by the Montreal Neurological Institute (MNI) using the extended version of the unified segmentation algorithm with light regularization; this is a generative model that combines tissue segmentation, bias correction, and spatial normalization in a single model (<a href="#B2">Ashburner and Friston, 2005</a>). The resultant deformation field was applied to each realigned functional image to be spatially normalized with non-linear transformation. All normalized functional images were then smoothed by using an isotropic Gaussian kernel of 9 mm full-width at half maximum (FWHM). Low-frequency noise was removed by high-pass filtering at 1/128 Hz.</p>
<p>In the first-level analysis (i.e., the fixed-effects analysis within a participant), each participant’s hemodynamic responses were modeled for the following types of events: initial 2-back trials with encoding alone, other 2-back trials, 6-s memory retrieval phase of retrieval trials, and 4-s <i>post hoc</i> period of retrieval trials. These event types were separately set for each group. Each event was modeled with the boxcar function overlaid with a hemodynamic response function. To minimize the effects of head movement, the six realignment parameters obtained from preprocessing were included as a nuisance factor in a general linear model.</p>
<p>These modeled responses were then generated in a general linear model for each participant and used for the inter-subject comparison in a second-level analysis (i.e., the random-effects analysis for a group). To examine the activation of the regions in an unbiased manner, we adopted whole-brain analyses. For statistical analyses, a two-way ANOVA (group × event type) with <i>t</i>-tests was performed with three nuisance factors (age, gender, and laterality quotient), where the statistical threshold was set to family-wise error (FWE) corrected <i>p</i> &lt; 0.05 for the voxel level. For the anatomical identification of activated regions, essentially we used the Anatomical Automatic Labeling (AAL) method<sup id="footnotesuper2"><a id="note2a"></a><a href="#note2">2</a></sup> (<a href="#B35">Tzourio-Mazoyer et al., 2002</a>) and the labeled data as provided by Neuromorphometrics Inc.<sup id="footnotesuper3"><a id="note3a"></a><a href="#note3">3</a></sup>, under academic subscription. In addition to whole-brain analyses, we adopted analyses of each region of interest (ROI) by using the MarsBaR-toolbox<sup id="footnotesuper4"><a id="note4a"></a><a href="#note4">4</a></sup>, in which an ROI was taken from a cluster identified by the “retrieval—2-back” contrast for all participants, which were further extracted with an AAL mask of each region.</p>
<h2>Results</h2>
<h3>Behavioral Results</h3>
<p>We first compared the amounts of time required to write down the scheduled appointments (i.e., the duration of schedule recording) among the Note, Tablet, and Phone groups, and we observed a significant difference by a one-way ANOVA (<i>F</i><sub>(2,45)</sub> = 6.5, <i>p</i> = 0.003; <a href="#F2">Figure 2A</a>). The duration was significantly shorter for the Note group compared to the Tablet and Phone groups combined (<i>t-test</i>, <i>t</i><sub>(46)</sub> = 3.2, <i>p</i> = 0.002). We also confirmed a significant difference between the Note and Device groups (<i>t</i><sub>(29)</sub> = 3.0, <i>p</i> = 0.003).</p>
<p>Relative to the chance level of 25% accuracy, the accuracy for the retrieval task was reliable and well below the ceiling level (<a href="#F2">Figure 2B</a>). The participants’ self-evaluation on confidence was also correct, because the AUC for the Note, Tablet, and Phone groups were 0.77 ± 0.14, 0.77 ± 0.12, and 0.74 ± 0.11, respectively, where group differences were not significant (<i>F</i><sub>(2,45)</sub> = 0.2, <i>p</i> = 0.8). The accuracy or RTs in the retrieval was not significantly different among the three groups (accuracy: <i>F</i><sub>(2,45)</sub> = 0.5, <i>p</i> = 0.6; RTs: <i>F</i><sub>(2,45)</sub> = 0.8, <i>p</i> = 0.5; <a href="#F2">Figure 2C</a>); the accuracy and RTs in the interference and 2-back tasks were also comparable among the three groups (<i>p</i> &gt; 0.4). However, we observed significant group differences when we focused on the easier questions of scheduled appointments (see “Materials and Methods” section; <a href="#F2">Figure 2B</a>). According to non-parametric tests for the data showing ceiling effects, the accuracy of the easier questions was significantly higher for the Note group than the Tablet group (Wilcoxon rank-sum test, <i>W</i> = 179, <i>p</i> = 0.04), and the difference between the Note and Device groups was marginally significant (<i>W</i> = 164, <i>p</i> = 0.06).</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g002.jpg" name="figure2" target="_blank">
<img id="F2" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g002.jpg" src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g002.jpg"></a></p><p><strong>Figure 2</strong>. Behavioral data. <strong>(A)</strong> The intergroup differences in the mean duration of schedule recording (see <a href="#F1">Figure 1</a>), together with individual data points overlapped. In addition to the three groups (Note, Tablet, and Phone), we also introduced a <i>Device</i> group, which consisted of participants who used mainly notebooks daily and were assigned to either the Tablet or Phone group. <strong>(B)</strong> Accuracy in the retrieval task. The broken line denotes the chance level of 25% accuracy. For the easier (i.e., more straightforward) questions, the Note group showed significantly higher accuracy than the Tablet group. <strong>(C)</strong> Response times (RTs) in the retrieval task. Error bars indicate standard errors of the mean. *<i>p</i> &lt; 0.05.</p>
</div> 


<p>The Tablet and Phone groups (or Device group) took more time for writing down (<a href="#F2">Figure 2A</a>), and this might be due to slower input of characters with such mobile devices (no typing on the computer keyboard). However, at least between the Note and Tablet groups, the use of a stylus pen was just similar to writing with a four-color pen, and the physical layout of a notebook or tablet was equated as much as possible (see “Materials and Methods” section). Moreover, there was ample time for every group to write down all appointments into a monthly calendar. Therefore, <i>shorter</i> amounts of time for writing down and <i>higher</i> accuracy in easier questions for the Note group suggest that those cognitive processes for the Note group were actually deeper and more solid.</p>
<p>When all participants in the three groups were combined, the accuracy in the retrieval and 2-back tasks were significantly correlated (Pearson’s correlation, <i>r</i> = 0.31, <i>t</i><sub>(46)</sub> = 2.2, <i>p</i> = 0.03). RTs showed a significant correlation as well (<i>r</i> = 0.33, <i>t</i><sub>(46)</sub> = 2.4, <i>p</i> = 0.02). These results confirm consistent immediate- and short-term memory capacities for every participant.</p>
<h3>Enhanced Activations in Bilateral Regions for the Note Group</h3>
<p>To identify brain regions specifically involved in the memory retrieval process, we directly compared activations between the 6-s memory retrieval phase and the 4-s <i>post hoc</i> period from each 10-s period of the retrieval task, denoted as “First 6 s—Last 4 s” contrast. This was because the mean RTs were less than 6 s for all but two participants (see <a href="#F2">Figure 2C</a>). With this stringent contrast during the same stimulus presentation and task, dynamic signal changes induced by such active retrieval processes should be revealed. As shown in <a href="#F3">Figure 3A</a>, localized activations were found bilaterally in the middle frontal gyrus, F3op/F3t, fusiform gyrus, AG/SMG, middle/inferior occipital gyrus (MOG/IOG), pallidum, and hippocampus; we also observed left-lateralized activation in the LPMC and precuneus.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g003.jpg" name="figure3" target="_blank">
<img id="F3" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g003.jpg" src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g003.jpg"></a></p><p><strong>Figure 3</strong>. Activated regions for the retrieval task. <strong>(A)</strong> Results of the “First 6 s—Last 4 s” contrast within the retrieval task period are shown for all participants. <strong>(B)</strong> Results of the “retrieval—2-back” contrast are shown for all participants. The lines indicate the locations of the sections. Localized activations were observed bilaterally in the lateral premotor cortex/opercular/triangular parts of the inferior frontal gyrus (LPMC/F3op/F3t), angular/supramarginal gyri (AG/SMG), hippocampus, precuneus, and lingual gyrus/calcarine/inferior occipital gyrus (LG/calcarine/IOG; see <a href="#T2">Table 2</a> for the list of local maxima).</p>
</div> 


<p>It is still possible that these activations reflect immediate memory processes that were necessary to solve the retrieval task; note the above-mentioned correlation between performances of the two tasks. Thus, we further compared activations in the retrieval task (10-s period) against those in the 2-back task with more demanding immediate memory, which successfully removed common factors in both tasks (<a href="#F3">Figure 3B</a>). The result of activations replicated the above-mentioned regions (<a href="#T2">Table 2</a>), providing appropriate ROIs for further analyses. Additional activations were found bilaterally in the lingual gyrus (LG) and calcarine sulcus; we also observed left-lateralized activation in the orbital part of the inferior frontal gyrus (F3O).</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t002.jpg" name="Table2" target="_blank">
<img id="T2" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t002.jpg" src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-t002.jpg"></a></p><p><strong>Table 2</strong>. ROIs determined by the contrast of “retrieval—2-back” for all participants.</p></div> 


<p>We assessed percent signal changes for these ROIs, and found significant intergroup differences in the posterior hippocampus, precuneus, LG/calcarine/IOG, LPMC/F3op/F3t, and AG/SMG (<a href="#F4">Figures 4A–E</a>). Activations in the first four regions were significantly different between the Note group and the combined Tablet and Phone groups (hippocampus: <i>t</i><sub>(94)</sub> = 2.4, <i>p</i> = 0.02; precuneus: <i>t</i><sub>(94)</sub> = 2.3, <i>p</i> = 0.03; LG/calcarine/IOG: <i>t</i><sub>(94)</sub> = 2.7, <i>p</i> = 0.008; LPMC/F3op/F3t: <i>t</i><sub>(94)</sub> = 2.0, <i>p</i> = 0.05), whereas those in the last region were significantly different between the Note and Phone groups (<i>t</i><sub>(62)</sub> = 2.2, <i>p</i> = 0.03). Activations in the LG/calcarine/IOG and LPMC/F3op/F3t were also significantly different between the Note and Device groups (LG/calcarine/IOG: <i>t</i><sub>(60)</sub> = 2.2, <i>p</i> = 0.03; LPMC/F3op/F3t: <i>t</i><sub>(60)</sub> = 2.4, <i>p</i> = 0.02), even when the experience/accustomedness of using paper notebooks was equated. Moreover, we observed a significant positive correlation between the RTs in the retrieval task and the averaged signal changes in the ROIs of LPMC/F3op/F3t and AG/SMG for all participants (<i>r</i> = 0.31, <i>t</i><sub>(46)</sub> = 2.2, <i>p</i> = 0.03; <a href="#F4">Figure 4F</a>). This link between behavioral results and brain activations indicates that inner language processes were indeed involved in during memory retrieval <i>via</i> the function of the language-related regions.</p>


<div>
<p><a href="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g004.jpg" name="figure4" target="_blank">
<img id="F4" alt="www.frontiersin.org" data-src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g004.jpg" src="https://www.frontiersin.org/files/Articles/634158/fnbeh-15-634158-HTML/image_m/fnbeh-15-634158-g004.jpg"></a></p><p><strong>Figure 4</strong>. Intergroup differences in brain activations for the retrieval task. <strong>(A–E)</strong> Mean percent signal changes, together with individual data points overlapped, for the three groups in the regions of interest (ROIs) of the hippocampus <strong>(A)</strong>, precuneus <strong>(B)</strong>, LG/calcarine/IOG <strong>(C)</strong>, LPMC/F3op/F3t <strong>(D)</strong>, and AG/SMG <strong>(E)</strong>. The signal changes of an ROI in each hemisphere were treated as independent samples, in reference to those in the 2-back task. Error bars indicate standard errors of the mean. *<i>p</i> &lt; 0.05. <strong>(F)</strong> A significant correlation between the RTs in the retrieval task and the averaged signal changes in the ROIs of the LPMC/F3op/F3t and AG/SMG (the language-related regions) for all participants.</p>
</div> 


<h2>Discussion</h2>
<p>Using three groups of participants who performed a schedule-recording task using a paper notebook, electronic tablet, or smartphone, followed by a retrieval task (<a href="#F1">Figure 1</a>), we obtained three major results. First, the duration of schedule recording was significantly shorter for the Note group than the Tablet and Phone groups, and accuracy was much higher for the Note group in easier (i.e., more straightforward) questions (<a href="#F2">Figure 2</a>). Because the input methods were equated as much as possible between the Note and Tablet groups, these results indicate that the cognitive processes for the Note group were actually deeper and more solid. Second, brain activations for all groups during the retrieval phase were localized in the bilateral hippocampus, precuneus, LG/calcarine/IOG, and LPMC/F3op/F3t (<a href="#F3">Figure 3</a>), confirming the involvement of verbalized memory retrieval processes for appointments. Third, activations in these regions were significantly higher for the Note group than those for the Tablet and Phone groups (<a href="#F4">Figure 4</a>). These enhanced activations for the Note group could not be explained by general cognitive loads or task difficulty, because overall task performances were similar among the groups. Brain activations for the Tablet and Phone groups were similar, where the difference in input methods did not affect the results. On the other hand, the Note and Tablet groups showed a clear difference in brain activations even if the physical layout and input methods were controlled. Brain activations were significantly different also between the Note and Device groups, even when accustomedness to paper notebooks or mobile devices was equated for daily usage. The significant superiority in both accuracy and activations for the Note group suggested that the use of a paper notebook promoted the acquisition of rich encoding information and/or spatial information of real papers (see the “Introduction” section) and that this information could be utilized as effective retrieval clues, leading to higher activations in these specific regions.</p>
<p>The hippocampus is crucially involved not only in memory encoding and retrieval processes but also in spatial memory itself. The hippocampal-entorhinal cortex provides spatial representations, as demonstrated by grid cells (<a href="#B13">Hartley et al., 2014</a>; <a href="#B24">Moser et al., 2015</a>). It has also been suggested that activations in the human hippocampus encode distances between locations in the real world (<a href="#B22">Morgan et al., 2011</a>; <a href="#B15">Howard et al., 2014</a>). In a recent fMRI study using a graph structure of pictures, the adaptation signals in the hippocampal-entorhinal cortex were suppressed for shorter distances on the graph, indicating that non-spatial relationships were also encoded in these regions (<a href="#B11">Garvert et al., 2017</a>). Other neuroimaging studies have shown that activations in the left posterior hippocampus were enhanced during retrieval compared with the encoding of word pairs (<a href="#B29">Prince et al., 2005</a>) and that better recollection of proverbs was associated with a larger volume of the bilateral posterior hippocampus (<a href="#B28">Poppenk and Moscovitch, 2011</a>). The results of the present study are consistent with these previous findings, in that the scheduled appointments included various cues of spatial and structural information in the calendar, which were especially abundant when participants used paper notebooks. Moreover, the retrieval of such encoded information was explicitly required by our retrieval task and was shown to elicit activations in the bilateral posterior hippocampus.</p>
<p>Concerning activation in the visual cortex, a previous study reported that the visual cortex was activated during the retrieval of pictorial visual information without actual visual stimulation (<a href="#B37">Wheeler et al., 2000</a>). The visual areas play a key role in visual imagery as well, and activations in those regions could be affected by focal attention during imagery (<a href="#B32">Sakai and Miyashita, 1994</a>). Indeed, a study with fMRI decoding revealed activation in the V1–V3 when participants reported visual imagery of an object during dreaming, about which was inquired afterward (<a href="#B14">Horikawa et al., 2013</a>). Another study reported that retrieval of visual information was related to activation patterns in the V1–V3, and further showed that the activation patterns in the hippocampus predicted the mnemonic strength (<a href="#B3">Bosch et al., 2014</a>). As regards the precuneus, a positron emission tomography (PET) study with a paired-word retrieval task showed memory-related activation for both visual and auditory stimuli, indicating a modality-general role of the precuneus (<a href="#B18">Krause et al., 1999</a>). The internal representation for visual imagery of the encoded calendar provides a plausible account for our results, in which the paper notebook provides richer information than mobile devices.</p>
<p>According to our previous study, the left F3op/F3t, right LPMC, and right F3op/F3t are included in the network for syntax and its supportive system (Network I; <a href="#B17">Kinno et al., 2014</a>), whereas the left LPMC is critical to the network for syntax and input/output interface (Network II). In the present study, we observed activation in the left F3t/F3O, which is an essential part of the network for syntax and semantics (Network III). Thus all three networks that are crucial for syntactic processing were involved in the retrieval of scheduled appointments. The enhanced activations for the Note group suggest that the use of paper notebooks even influenced natural language processes, possibly reflecting the encoding of specific episodes.</p>
<p>Our present experiments demonstrated that brain activations related to memory, visual imagery, and language during the retrieval of specific information, as well as the deeper encoding of that information, were stronger in participants using a paper notebook than in those using electronic devices. Our results suggest that the use of a paper notebook affects these higher-order brain functions, and this could have important implications for education, particularly in terms of the pros and cons of e-learning. The expanded use of mobile devices or computers could undercut the use of traditional textbooks and paper notebooks, which may in fact provide richer information from the perspective of memory encoding. Further research is needed to elucidate the actual changes in brain activation due to the long-term exposure to mobile devices.</p>
<h2>Data Availability Statement</h2>
<p>The raw data supporting the conclusions of this article will be made available by the authors, without undue reservation.</p>
<h2>Ethics Statement</h2>
<p>The studies involving human participants were reviewed and approved by the Institutional Review Board of the University of Tokyo, Komaba Campus. The patients/participants provided their written informed consent to participate in this study.</p>
<h2>Author Contributions</h2>
<p>KU and KLS designed the study, analyzed the data, and wrote the manuscript. TI and TY contributed to the initial discussion. KU conducted the experiment. All authors contributed to the article and approved the submitted version.</p>
<h2>Funding</h2>
<p>The authors declare that this study received funding from the Consortium for Applied Neuroscience, NTT Data Institute of Management Consulting, Inc. The funder was not involved in the study design, collection, analysis, interpretation of data, the writing of this article, or the decision to submit it for publication.</p>
<h2>Conflict of Interest</h2>
<p>TI and TY were employed by the company NTT Data Institute of Management Consulting, Inc.</p>
<p>The remaining authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p>
<h2>Acknowledgments</h2>
<p>We would like to thank the members of the Consortium for Applied Neuroscience for their input on the use of media, Yuma Tsuta for contributions to the design of the experiments, the MR scanning, and the analysis of behavioral results, Naoko Komoro for technical assistance, and Hiromi Matsuda for administrative assistance.</p>
<h2>Footnotes</h2>
<ol>
<li id="note1"><strong><a href="#note1a" title="">^</a></strong> <a href="http://www.fil.ion.ucl.ac.uk/spm">www.fil.ion.ucl.ac.uk/spm</a></li>
<li id="note2"><strong><a href="#note2a" title="">^</a></strong> <a href="http://www.gin.cnrs.fr/AAL2/">www.gin.cnrs.fr/AAL2/</a></li>
<li id="note3"><strong><a href="#note3a" title="">^</a></strong> <a href="http://neuromorphometrics.com/">http://Neuromorphometrics.com/</a></li>
<li id="note4"><strong><a href="#note4a" title="">^</a></strong> <a href="http://marsbar.sourceforge.net/">http://marsbar.sourceforge.net/</a></li>
</ol>
<h2>References</h2>
<div>
<p><a name="B1" id="B1"></a>Aragón-Mendizábal, E., Delgado-Casas, C., Navarro-Guzmán, J., Menacho-Jiménez, I., and Romero-Oliva, M. (2016). A comparative study of handwriting and computer typing in note-taking by university students. <i>Comunicar</i> 48, 101–107. doi: 10.1038/s42003-020-1052-8</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/32581304" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1038/s42003-020-1052-8" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=A+comparative+study+of+handwriting+and+computer+typing+in+note-taking+by+university+students&amp;author=Arag%C3%B3n-Mendiz%C3%A1bal+E.&amp;author=Delgado-Casas+C.&amp;author=Navarro-Guzm%C3%A1n+J.&amp;author=Menacho-Jim%C3%A9nez+I.&amp;author=Romero-Oliva+M.&amp;publication_year=2016&amp;journal=Comunicar&amp;volume=48&amp;pages=101-107" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B3" id="B3"></a>Bosch, S. E., Jehee, J. F. M., Fernández, G., and Doeller, C. F. (2014). Reinstatement of associative memories in early visual cortex is signaled by the hippocampus. <i>J. Neurosci.</i> 34, 7493–7500. doi: 10.1523/JNEUROSCI.0805-14.2014</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24872554" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/JNEUROSCI.0805-14.2014" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Reinstatement+of+associative+memories+in+early+visual+cortex+is+signaled+by+the+hippocampus&amp;author=Bosch+S.+E.&amp;author=Jehee+J.+F.+M.&amp;author=Fern%C3%A1ndez+G.&amp;author=Doeller+C.+F.&amp;publication_year=2014&amp;journal=J.+Neurosci.&amp;volume=34&amp;pages=7493-7500" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B4" id="B4"></a>Broadbent, N. J., Squire, L. R., and Clark, R. E. (2004). Spatial memory, recognition memory and the hippocampus. <i>Proc. Natl. Acad. Sci. U S A</i> 101, 14515–14520. doi: 10.1073/pnas.0406344101</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15452348" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1073/pnas.0406344101" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Spatial+memory,+recognition+memory+and+the+hippocampus&amp;author=Broadbent+N.+J.&amp;author=Squire+L.+R.&amp;author=Clark+R.+E.&amp;publication_year=2004&amp;journal=Proc.+Natl.+Acad.+Sci.+U+S+A&amp;volume=101&amp;pages=14515-14520" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B5" id="B5"></a>Chadwick, M. J., Hassabis, D., Weiskopf, N., and Maguire, E. A. (2010). Decoding individual episodic memory traces in the human hippocampus. <i>Curr. Biol.</i> 20, 544–547. doi: 10.1016/j.cub.2010.01.053</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/20226665" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2010.01.053" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Decoding+individual+episodic+memory+traces+in+the+human+hippocampus&amp;author=Chadwick+M.+J.&amp;author=Hassabis+D.&amp;author=Weiskopf+N.&amp;author=Maguire+E.+A.&amp;publication_year=2010&amp;journal=Curr.+Biol.&amp;volume=20&amp;pages=544-547" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B6" id="B6"></a>Drozdick, L. W., Wahlstrom, D., Zhu, J., and Weiss, L. G. (2012). “The Wechsler adult intelligence scale—fourth edition and the wechsler memory scale—fourth edition,” in <i>Contemporary Intellectual Assessment: Theories, Tests and Issues</i> eds D. P. Flanagan and P. L. Harrison (New York, NY: Guilford Press), 197–223.</p>
<p><a href="http://scholar.google.com/scholar_lookup?title=The+Wechsler+adult+intelligence+scale%E2%80%94fourth+edition+and+the+wechsler+memory+scale%E2%80%94fourth+edition&amp;author=Drozdick+L.+W.&amp;author=Wahlstrom+D.&amp;author=Zhu+J.&amp;author=Weiss+L.+G.&amp;publication_year=2012&amp;pages=197-223" target="_blank">Google Scholar</a></p>
</div>



<div>
<p><a name="B10" id="B10"></a>Friston, K. J., Holmes, A. P., Worsley, K. J., Poline, J.-P., Frith, C. D., and Frackowiak, R. S. J. (1994). Statistical parametric maps in functional imaging: a general linear approach. <i>Hum. Brain Mapp.</i> 2, 189–210. doi: 10.1002/hbm.460020402</p>
<p><a href="https://doi.org/10.1002/hbm.460020402" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Statistical+parametric+maps+in+functional+imaging%3A+a+general+linear+approach&amp;author=Friston+K.+J.&amp;author=Holmes+A.+P.&amp;author=Worsley+K.+J.&amp;author=Poline+J.-P.&amp;author=Frith+C.+D.&amp;author=Frackowiak+R.+S.+J.&amp;publication_year=1994&amp;journal=Hum.+Brain+Mapp.&amp;volume=2&amp;pages=189-210" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B11" id="B11"></a>Garvert, M. M., Dolan, R. J., and Behrens, T. E. J. (2017). A map of abstract relational knowledge in the human hippocampal-entorhinal cortex. <i>eLife</i> 6, 1–20. doi: 10.7554/eLife.17086</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28448253" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.7554/eLife.17086" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=A+map+of+abstract+relational+knowledge+in+the+human+hippocampal-entorhinal+cortex&amp;author=Garvert+M.+M.&amp;author=Dolan+R.+J.&amp;author=Behrens+T.+E.+J.&amp;publication_year=2017&amp;journal=eLife&amp;volume=6&amp;pages=1-20" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B13" id="B13"></a>Hartley, T., Lever, C., Burgess, N., and O’keefe, J. (2014). Space in the brain: how the hippocampal formation supports spatial cognition. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> 369, 1–18. doi: 10.1098/rstb.2012.0510</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24366125" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1098/rstb.2012.0510" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Space+in+the+brain%3A+how+the+hippocampal+formation+supports+spatial+cognition&amp;author=Hartley+T.&amp;author=Lever+C.&amp;author=Burgess+N.&amp;author=O%E2%80%99keefe+J.&amp;publication_year=2014&amp;journal=Philos.+Trans.+R.+Soc.+Lond.+B+Biol.+Sci.&amp;volume=369&amp;pages=1-18" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B15" id="B15"></a>Howard, L. R., Javadi, A. H., Yu, Y., Mill, R. D., Morrison, L. C., Knight, R., et al. (2014). The hippocampus and entorhinal cortex encode the path and euclidean distances to goals during navigation. <i>Curr. Biol.</i> 24, 1331–1340. doi: 10.1016/j.cub.2014.05.001</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24909328" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.cub.2014.05.001" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=The+hippocampus+and+entorhinal+cortex+encode+the+path+and+euclidean+distances+to+goals+during+navigation&amp;author=Howard+L.+R.&amp;author=Javadi+A.+H.&amp;author=Yu+Y.&amp;author=Mill+R.+D.&amp;author=Morrison+L.+C.&amp;author=Knight+R.&amp;+&amp;publication_year=2014&amp;journal=Curr.+Biol.&amp;volume=24&amp;pages=1331-1340" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B16" id="B16"></a>Kinno, R., Kawamura, M., Shioda, S., and Sakai, K. L. (2008). Neural correlates of noncanonical syntactic processing revealed by a picture-sentence matching task. <i>Hum. Brain Mapp.</i> 29, 1015–1027. doi: 10.1002/hbm.20441</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/17924553" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1002/hbm.20441" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Neural+correlates+of+noncanonical+syntactic+processing+revealed+by+a+picture-sentence+matching+task&amp;author=Kinno+R.&amp;author=Kawamura+M.&amp;author=Shioda+S.&amp;author=Sakai+K.+L.&amp;publication_year=2008&amp;journal=Hum.+Brain+Mapp.&amp;volume=29&amp;pages=1015-1027" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B17" id="B17"></a>Kinno, R., Ohta, S., Muragaki, Y., Maruyama, T., and Sakai, K. L. (2014). Differential reorganization of three syntax-related networks induced by a left frontal glioma. <i>Brain</i> 137, 1193–1212. doi: 10.1093/brain/awu013</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24519977" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1093/brain/awu013" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Differential+reorganization+of+three+syntax-related+networks+induced+by+a+left+frontal+glioma&amp;author=Kinno+R.&amp;author=Ohta+S.&amp;author=Muragaki+Y.&amp;author=Maruyama+T.&amp;author=Sakai+K.+L.&amp;publication_year=2014&amp;journal=Brain&amp;volume=137&amp;pages=1193-1212" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B18" id="B18"></a>Krause, B. J., Schmidt, D., Mottaghy, F. M., Taylor, J., Halsband, U., Herzog, H., et al. (1999). Episodic retrieval activates the precuneus irrespective of the imagery content of word pair associates—a PET study. <i>Brain</i> 122, 255–263. doi: 10.1093/brain/122.2.255</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/10071054" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1093/brain/122.2.255" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Episodic+retrieval+activates+the+precuneus+irrespective+of+the+imagery+content+of+word+pair+associates%E2%80%94a+PET+study&amp;author=Krause+B.+J.&amp;author=Schmidt+D.&amp;author=Mottaghy+F.+M.&amp;author=Taylor+J.&amp;author=Halsband+U.&amp;author=Herzog+H.&amp;+&amp;publication_year=1999&amp;journal=Brain&amp;volume=122&amp;pages=255-263" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B19" id="B19"></a>Lundstrom, B. N., Petersson, K. M., Andersson, J., Johansson, M., Fransson, P., and Ingvar, M. (2003). Isolating the retrieval of imagined pictures during episodic memory: activation of the left precuneus and left prefrontal cortex. <i>NeuroImage</i> 20, 1934–1943. doi: 10.1016/j.neuroimage.2003.07.017</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/14683699" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuroimage.2003.07.017" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Isolating+the+retrieval+of+imagined+pictures+during+episodic+memory%3A+activation+of+the+left+precuneus+and+left+prefrontal+cortex&amp;author=Lundstrom+B.+N.&amp;author=Petersson+K.+M.&amp;author=Andersson+J.&amp;author=Johansson+M.&amp;author=Fransson+P.&amp;author=Ingvar+M.&amp;publication_year=2003&amp;journal=NeuroImage&amp;volume=20&amp;pages=1934-1943" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B20" id="B20"></a>Mangen, A., Walgermo, B. R., and Brønnick, K. (2013). Reading linear texts on paper versus computer screen: effects on reading comprehension. <i>Int. J. Educ. Res.</i> 58, 61–68. doi: 10.1016/j.ijer.2012.12.002</p>
<p><a href="https://doi.org/10.1016/j.ijer.2012.12.002" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Reading+linear+texts+on+paper+versus+computer+screen%3A+effects+on+reading+comprehension&amp;author=Mangen+A.&amp;author=Walgermo+B.+R.&amp;author=Br%C3%B8nnick+K.&amp;publication_year=2013&amp;journal=Int.+J.+Educ.+Res.&amp;volume=58&amp;pages=61-68" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B22" id="B22"></a>Morgan, L. K., Macevoy, S. P., Aguirre, G. K., and Epstein, R. A. (2011). Distances between real-world locations are represented in the human hippocampus. <i>J. Neurosci.</i> 31, 1238–1245. doi: 10.1523/JNEUROSCI.4667-10.2011</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/21273408" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/JNEUROSCI.4667-10.2011" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Distances+between+real-world+locations+are+represented+in+the+human+hippocampus&amp;author=Morgan+L.+K.&amp;author=Macevoy+S.+P.&amp;author=Aguirre+G.+K.&amp;author=Epstein+R.+A.&amp;publication_year=2011&amp;journal=J.+Neurosci.&amp;volume=31&amp;pages=1238-1245" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B23" id="B23"></a>Moscovitch, M., Cabeza, R., Winocur, G., and Nadel, L. (2016). Episodic memory and beyond: the hippocampus and neocortex in transformation. <i>Annu. Rev. Psychol.</i> 67, 105–134. doi: 10.1146/annurev-psych-113011-143733</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/26726963" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1146/annurev-psych-113011-143733" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Episodic+memory+and+beyond%3A+the+hippocampus+and+neocortex+in+transformation&amp;author=Moscovitch+M.&amp;author=Cabeza+R.&amp;author=Winocur+G.&amp;author=Nadel+L.&amp;publication_year=2016&amp;journal=Annu.+Rev.+Psychol.&amp;volume=67&amp;pages=105-134" target="_blank">Google Scholar</a></p>
</div>

<div>
<p><a name="B25" id="B25"></a>Mueller, P. A., and Oppenheimer, D. M. (2014). The pen is mightier than the keyboard: advantages of longhand over laptop note taking. <i>Psychol. Sci.</i> 25, 1159–1168. doi: 10.1177/0956797614524581</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/24760141" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1177/0956797614524581" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=The+pen+is+mightier+than+the+keyboard%3A+advantages+of+longhand+over+laptop+note+taking&amp;author=Mueller+P.+A.&amp;author=Oppenheimer+D.+M.&amp;publication_year=2014&amp;journal=Psychol.+Sci.&amp;volume=25&amp;pages=1159-1168" target="_blank">Google Scholar</a></p>
</div>


<div>
<p><a name="B28" id="B28"></a>Poppenk, J., and Moscovitch, M. (2011). A hippocampal marker of recollection memory ability among healthy young adults: contributions of posterior and anterior segments. <i>Neuron</i> 72, 931–937. doi: 10.1016/j.neuron.2011.10.014</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/22196329" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1016/j.neuron.2011.10.014" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=A+hippocampal+marker+of+recollection+memory+ability+among+healthy+young+adults%3A+contributions+of+posterior+and+anterior+segments&amp;author=Poppenk+J.&amp;author=Moscovitch+M.&amp;publication_year=2011&amp;journal=Neuron&amp;volume=72&amp;pages=931-937" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B29" id="B29"></a>Prince, S. E., Daselaar, S. M., and Cabeza, R. (2005). Neural correlates of relational memory: successful encoding and retrieval of semantic and perceptual associations. <i>J. Neurosci.</i> 25, 1203–1210. doi: 10.1523/JNEUROSCI.2540-04.2005</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/15689557" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1523/JNEUROSCI.2540-04.2005" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Neural+correlates+of+relational+memory%3A+successful+encoding+and+retrieval+of+semantic+and+perceptual+associations&amp;author=Prince+S.+E.&amp;author=Daselaar+S.+M.&amp;author=Cabeza+R.&amp;publication_year=2005&amp;journal=J.+Neurosci.&amp;volume=25&amp;pages=1203-1210" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B30" id="B30"></a>Rugg, M. D., Johnson, J. D., Park, H., and Uncapher, M. R. (2008). “Encoding- retrieval overlap in human episodic memory: a functional neuroimaging perspective,” in <i>Essence of Memory, Progress in Brain Research 169</i>, eds W. S. Sossin, J.-C. Lacaille, V. F. Castellucci and S. Belleville (Amsterdam: Elsevier), 339–352.</p>
<p><a href="http://scholar.google.com/scholar_lookup?title=Encoding-+retrieval+overlap+in+human+episodic+memory%3A+a+functional+neuroimaging+perspective&amp;author=Rugg+M.+D.&amp;author=Johnson+J.+D.&amp;author=Park+H.&amp;author=Uncapher+M.+R.&amp;publication_year=2008&amp;pages=339-352" target="_blank">Google Scholar</a></p>
</div>




<div>
<p><a name="B35" id="B35"></a>Tzourio-Mazoyer, N., Landeau, B., Papathanassiou, D., Crivello, F., Etard, O., Delcroix, N., et al. (2002). Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain. <i>NeuroImage</i> 15, 273–289. doi: 10.1006/nimg.2001.0978</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11771995" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1006/nimg.2001.0978" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Automated+anatomical+labeling+of+activations+in+SPM+using+a+macroscopic+anatomical+parcellation+of+the+MNI+MRI+single-subject+brain&amp;author=Tzourio-Mazoyer+N.&amp;author=Landeau+B.&amp;author=Papathanassiou+D.&amp;author=Crivello+F.&amp;author=Etard+O.&amp;author=Delcroix+N.&amp;+&amp;publication_year=2002&amp;journal=NeuroImage&amp;volume=15&amp;pages=273-289" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B36" id="B36"></a>Wästlund, E., Reinikka, H., Norlander, T., and Archer, T. (2005). Effects of VDT and paper presentation on consumption and production of information: psychological and physiological factors. <i>Comput. Human Behav.</i> 21, 377–394. doi: 10.1016/j.chb.2004.02.007</p>
<p><a href="https://doi.org/10.1016/j.chb.2004.02.007" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Effects+of+VDT+and+paper+presentation+on+consumption+and+production+of+information%3A+psychological+and+physiological+factors&amp;author=W%C3%A4stlund+E.&amp;author=Reinikka+H.&amp;author=Norlander+T.&amp;author=Archer+T.&amp;publication_year=2005&amp;journal=Comput.+Human+Behav.&amp;volume=21&amp;pages=377-394" target="_blank">Google Scholar</a></p>
</div>
<div>
<p><a name="B37" id="B37"></a>Wheeler, M. E., Petersen, S. E., and Buckner, R. L. (2000). Memory’s echo: vivid remembering reactivates sensory-specific cortex. <i>Proc. Natl. Acad. Sci. U S A</i> 97, 11125–11129. doi: 10.1073/pnas.97.20.11125</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/11005879" target="_blank">PubMed Abstract</a> | <a href="https://doi.org/10.1073/pnas.97.20.11125" target="_blank">CrossRef Full Text</a> | <a href="http://scholar.google.com/scholar_lookup?title=Memory%27s+echo%3A+vivid+remembering+reactivates+sensory-specific+cortex&amp;author=Wheeler+M.+E.&amp;author=Petersen+S.+E.&amp;author=Buckner+R.+L.&amp;publication_year=2000&amp;journal=Proc.+Natl.+Acad.+Sci.+U+S+A&amp;volume=97&amp;pages=11125-11129" target="_blank">Google Scholar</a></p>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[D Programming Language (170 pts)]]></title>
            <link>https://dlang.org</link>
            <guid>38513347</guid>
            <pubDate>Mon, 04 Dec 2023 03:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dlang.org">https://dlang.org</a>, See on <a href="https://news.ycombinator.com/item?id=38513347">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">        

        
        
        



<div>    <div>        <div><p><b>D</b> is a general-purpose programming language with
        static typing, systems-level access, and C-like syntax.
        With the <b>D Programming Language</b>, write fast,
        read fast, and run fast.
        </p><p>Fast code, fast.</p></div>

        <br>

        
    </div>
    <div id="your-code-here">            <p><a href="https://forum.dlang.org/newpost/general?subject=%5Byour+code+here%5D">your code here</a></p><div>                <p>Got a brief example illustrating D?</p>
                <p>Submit your code to the digitalmars.D forum specifying
                    "[your code here]" in the subject.</p>
                <p>Upon approval it will be showcased here on a random schedule.</p>
            </div>
        </div> 
</div> 




<div>    <h2>Support the D language</h2>
    <p>D is made possible through the hard work and dedication of many volunteers,
        with the coordination and outreach of the D Language Foundation, a 501(c)(3) non-profit organization.
        You can help further the development of the D language and help grow our
        community by supporting the Foundation.
    </p>
    
</div>



<p><a href="https://medium.com/@NetflixTechBlog/introducing-vectorflow-fe10d7f126b8"><img src="https://dlang.org/images/orgs-using-d/netflix_small.png"></a>
    <a href="https://dlang.org/blog/2017/05/24/faster-command-line-tools-in-d/"><img src="https://dlang.org/images/orgs-using-d/ebay.jpg"></a>
    <a href="https://dconf.org/2019/talks/beer.html"><img src="https://dlang.org/images/orgs-using-d/funkwerk.png"></a>
    <a href="https://dconf.org/2019/talks/colvin.html"><img src="https://dlang.org/images/orgs-using-d/symmetry.png"></a>
    <a href="https://dlang.org/blog/2016/07/07/project-highlight-auburn-sounds/"><img src="https://dlang.org/images/orgs-using-d/auburn.png"></a>
    <a href="https://dconf.org/2016/talks/zvibel.html"><img src="https://dlang.org/images/orgs-using-d/weka.png"></a>
</p>



<div>


<div><h4><i></i>Run</h4>            <p>Configure linting,
                formatting or
                completion for
                your favorite <a href="https://wiki.dlang.org/IDEs">IDE</a>,
                <a href="https://wiki.dlang.org/Editors">editor</a> or
                use <a href="https://run.dlang.io/">run.dlang.io</a> to play and experiment
                with D code.
            </p>
        </div>

<div><h2>Fast code, fast.</h2>
<div><h3><i></i> Write Fast</h3>
<p>D allows writing large code fragments without redundantly specifying types,
like dynamic languages do. On the other hand, static inference deduces types and other
code properties, giving the best of both the static and the
dynamic worlds. <a id="a1-control"></a></p><div id="a1">
<pre><span>void</span> main()
{
                <span>auto</span> arr = [ 1, 2, 3.14, 5.1, 6 ];
            <span>auto</span> dictionary = [ <span>"one"</span> : 1, <span>"two"</span> : 2,
        <span>"three"</span> : 3 ];
        <span>auto</span> x = min(arr[0], dictionary[<span>"two"</span>]);
}
<span>auto</span> min(T1, T2)(T1 lhs, T2 rhs)
{
    <span>return</span> rhs &lt; lhs ? rhs : lhs;
}
</pre>


</div>

<p>Automatic memory management makes for safe, simple, and robust code.
D also supports scoped resource management (aka the
<a href="https://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization">RAII</a> idiom)
and <a href="https://dlang.org/spec/statement.html#ScopeGuardStatement"><span>scope</span> statements</a> for
deterministic transactional code that is easy to write and read. <a id="a2-control"></a></p><div id="a2">

<pre><span>import</span> std.stdio;

<span>class</span> Widget { }

<span>void</span> main()
{
        <span>auto</span> w = <span>new</span> Widget;
        <span>scope</span>(exit) { writeln(<span>"Exiting main."</span>); }
        <span>foreach</span> (line; File(<span>__FILE_FULL_PATH__</span>).byLine())
    {
        writeln(line);
    }
    writeln();
}
</pre>

</div>


<p>Built-in linear and associative arrays, slices, and ranges make daily
programming simple and pleasant for tasks, both small and large. <a id="a3-control"></a></p><div id="a3">
<p><code>The D programming language
Modern convenience.
Modeling power.
Native efficiency.</code></p><pre><span>void</span> main()
{
    <span>import</span> std.range, std.stdio;

    <span>auto</span> sum = 0.0;
    <span>auto</span> count = stdin.byLine
        .tee!(l =&gt; sum += l.length).walkLength;

    writeln(<span>"Average line length: "</span>,
        count ? sum / count : 0);
}
</pre>

</div>

</div>

<div><h3><i></i> Read Fast</h3>
<p>The best paradigm is to not impose something at the expense of others.
D offers classic polymorphism, value semantics, functional
style, generics, generative programming, contract programming,
and more—all harmoniously integrated. <a id="a4-control"></a></p><div id="a4">
<pre><span>interface</span> Printable
{
   <span>void</span> print(<span>uint</span> level)
      <span>in</span> { <span>assert</span>(level &gt; 0); }
}

<span>class</span> Widget : Printable
{
   <span>void</span> print(<span>uint</span> level)
   <span>in</span>{ }
   <span>do</span>{ }
}

<span>class</span> ExtendedWidget : Widget
{
   <span>override</span> <span>void</span> print(<span>uint</span> level)
   <span>in</span> {   }
   <span>do</span>
   {
          }
}

<span>immutable</span> string programName = <span>"demo"</span>;
<span>int</span> perThread = 42;
<span>shared</span> <span>int</span> perApp = 5;

<span>struct</span> BigNum
{
        <span>this</span>(<span>this</span>) { }
        ~<span>this</span>() { }
}

<span>void</span> main()
{
    }
</pre>

</div>

<p>D offers an innovative approach to concurrency, featuring true
immutable data, message passing, no sharing by default, and
controlled mutable sharing across threads. <a href="http://informit.com/articles/article.aspx?p=1609144">Read more</a>.</p>

<p>From simple scripts to large projects, D has the breadth
to scale with any application's needs: unit testing,
information hiding, refined modularity, fast compilation, precise
interfaces. <a href="http://drdobbs.com/high-performance-computing/217801225">Read more</a>.</p>

</div>

<div><h3><i></i> Run Fast</h3>
<p>D compiles naturally to efficient native code.</p>

<p>D is designed such that most "obvious" code is fast <i>and</i>
safe. On occasion a function might need to escape the confines of type
safety for ultimate speed and control. For such rare cases D offers
native pointers, type casts, access to any C function without any
intervening translation, manual memory management, custom allocators
and even inline assembly code. <a id="a5-control"></a></p><div id="a5">
<pre><span>import</span> core.stdc.stdlib;

<span>void</span> livingDangerously()
{
        <span>enum</span> bytes = <span>float</span>.sizeof * 1024 * 1024;
    <span>auto</span> buf = malloc(bytes);
        <span>scope</span>(exit) free(buf);
        <span>auto</span> floats = <span>cast</span>(<span>float</span>[]) buf[0 .. bytes];
        <span>auto</span> moreBuf = alloca(4096 * 100);
    }

<span>uint</span> checked_multiply(<span>uint</span> x, <span>uint</span> y)
{
    <span>uint</span> result;
    <span>version</span> (D_InlineAsm_X86)
    {
                <span>asm</span>
        {
            mov     EAX,x        ;
            mul     EAX,y        ;
            mov     result,EAX   ;
            jc      Loverflow    ;
        }
        <span>return</span> result;
    }
    <span>else</span>
    {
        result = x * y;
        <span>if</span> (!y || x &lt;= <span>uint</span>.max / y)
           <span>return</span> result;
   }
Loverflow:
   <span>throw</span> <span>new</span> Exception(<span>"multiply overflow"</span>);
}

<span>void</span> main()
{
    }
</pre>

</div>

<p>The <span>@safe</span>, <span>@trusted</span>, and <span>@system</span> function
attributes allow the programmer to best decide the safety-efficiency
tradeoffs of an application, and have the compiler check for
consistency. <a href="https://dlang.org/spec/memory-safe-d.html">Read more</a>.</p>

</div>

</div> 
</div> 
 
 


        <p>Copyright © 1999-2023 by the <a href="https://dlang.org/foundation_overview.html">D Language Foundation</a> | Page generated by
<a href="https://dlang.org/spec/ddoc.html">Ddoc</a> on Sun Dec  3 19:28:42 2023
</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tyrian purple: Ancient pigment that was more valuable than gold (136 pts)]]></title>
            <link>https://www.bbc.com/future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold</link>
            <guid>38513073</guid>
            <pubDate>Mon, 04 Dec 2023 02:28:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold">https://www.bbc.com/future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold</a>, See on <a href="https://news.ycombinator.com/item?id=38513073">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="futurearticle20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold"><div id="headline-futurearticle20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpdpn.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpdpn.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpdpn.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpdpn.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpdpn.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpdpn.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpdpn.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpdpn.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="A mosaic of the Byzantine empress Theodora from 547AD (Credit: Alamy)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpdpn.jpg" alt="A mosaic of the Byzantine empress Theodora from 547AD (Credit: Alamy)" id=""></picture></div><div><article><div><p>For millennia, Tyrian purple was the most valuable colour on the planet. Then the recipe to make it was lost. By piecing together ancient clues, could one man bring it back?</p><div><p>A</p><div><p>At first, they just looked like stains. It was 2002 at the <a href="https://www.cambridge.org/core/journals/antiquity/article/abs/high-prestige-royal-purple-dyed-textiles-from-the-bronze-age-royal-tomb-at-qatna-syria/69EC1A74600EC74AAAC26D2F585ACF5A">site of Qatna</a> – a ruined palace at the edge of the Syrian desert, on the shores of a <a href="https://www.torrossa.com/en/resources/an/2422040">long-vanished lake</a>. Over three millennia after it was abandoned, a team of archaeologists had been granted permission to investigate – and they were on the hunt for the royal tomb.</p>
<p>After navigating through large hallways and narrow corridors, down crumbling steps, they came across a deep shaft. On one side were two identical statues guarding a sealed door: they had found it. Inside was a hoard of ancient wonders – 2,000 objects, including jewellery and a large golden hand. But there were also some intriguing dark patches on the ground. They sent a sample for testing – eventually separating out a <a href="https://www.cambridge.org/core/journals/antiquity/article/abs/high-prestige-royal-purple-dyed-textiles-from-the-bronze-age-royal-tomb-at-qatna-syria/69EC1A74600EC74AAAC26D2F585ACF5A">vivid purple layer</a> from the dust and muck.</p>
<p>The researchers had uncovered one of the most legendary commodities in the ancient world. This precious product forged empires, <a href="https://livrepository.liverpool.ac.uk/2032421/1/A%20Zadorojnyi%20Colour%20in%20Suetonius.pdf">felled kings</a>, and cemented the power of generations of global rulers. The Egyptian Queen Cleopatra was so obsessed with it, she even used it for the <a href="https://books.google.com/books?hl=en&amp;lr=&amp;id=86MaBQAAQBAJ&amp;oi=fnd&amp;pg=PA185&amp;dq=cleopatra+tyrian+purple+sails+barge&amp;ots=LNomeumMkA&amp;sig=GWkGxXgykg_LQrTI3158PpF_Dc4">sails of her boat</a>, while some Roman emperors decreed that anyone caught wearing it – other than them – would be sentenced to death. &nbsp;</p>
<p>That invention was Tyrian purple, otherwise known as shellfish purple. But though this noble pigment was the most expensive product in antiquity – worth more than <a href="https://www.sciencedirect.com/science/article/abs/pii/S138614251930071X">three times</a> its weight in gold, according to a Roman edict issued in 301 AD – no one living today knows how to make it. By the <a href="https://journals.sagepub.com/doi/abs/10.3184/003685013X13680345111425">15th Century</a>, the elaborate recipes to extract and process the dye had been lost.</p>
<p>But why did this alluring colour disappear? And can it be resurrected?</p>
<p>In a small garden hut in north-eastern Tunisia, just a short distance from what was once the Phoenician city of Carthage, one man has spent most of the last 16 years smashing up sea snails – attempting to coax their entrails into something resembling Tyrian purple.</p></div></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvpdcg"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpdcg.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpdcg.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpdcg.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpdcg.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpdcg.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpdcg.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpdcg.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpdcg.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="After more than three thousand years of mingling with sediment, the Tyrian purple found in Qatna’s royal tomb was still intensely colourful (Credit: Alamy)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpdcg.jpg" alt="After more than three thousand years of mingling with sediment, the Tyrian purple found in Qatna’s royal tomb was still intensely colourful (Credit: Alamy)" id=""></picture><div><p>After more than three thousand years of mingling with sediment, the Tyrian purple found in Qatna’s royal tomb was still intensely colourful (Credit: Alamy)</p></div></div><div><p><strong>A fishy empire</strong></p>
<p>Tyrian purple was paraded by the most privileged in society for millennia – a symbol of strength, sovereignty and money. Ancient authors are particular about the precise hue that was worthy of the name: a <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=5750d98181fd002503d2b147235bf6fa75ad334c">deep reddish-purple</a>, like that of coagulated blood, tinged with black. Pliny the Elder described it as having a "<a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.02.0137%3Abook%3D9&amp;force=y">shining appearance</a> when held up to the light". &nbsp;</p>
<p>With its uniquely intense colour and resistance to fading, Tyrian purple was adored by ancient civilisations across Southern Europe, North Africa, and Western Asia. It was so central to the success of the Phoenicians it was named after their city-state Tyre, and they became known as the "purple people". The shade could be found on everything from cloaks to sails, paintings, furniture, plaster, <a href="https://www.mdpi.com/2571-9408/4/1/10">wall paintings</a>, jewellery and even burial shrouds.</p>
<p>In 40 AD, the king of Mauretania was killed in a surprise assassination in Rome, ordered by the emperor. Despite being a friend to the Romans, the unfortunate royal had caused grave offence when he <a href="https://livrepository.liverpool.ac.uk/2032421/1/A%20Zadorojnyi%20Colour%20in%20Suetonius.pdf">strode into an amphitheatre</a> to watch a gladiatorial match… wearing a purple robe. The jealous, insatiable lust that the colour ignited was sometimes <a href="https://www.loebclassics.com/view/pliny_elder-natural_history/1938/pb_LCL353.249.xml?readMode=recto">compared to a kind of madness</a>. &nbsp;</p>
<p><strong>A slimy mystery</strong></p>
<p>Oddly, the most celebrated pigment the world has known did not start life as a beautiful ultramarine gemstone, like its contemporary <a href="https://exhibitions.kelsey.lsa.umich.edu/ancient-color/blue.php">lapis lazuli</a> – or a vibrant <a href="https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/rubia-tinctorum">tangle of coral-pink roots</a>, like the red dye madder. Instead, it began as a clear fluid produced by sea snails in the Murex family. More specifically, it was mucous.&nbsp;</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvpb1s"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpb1s.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpb1s.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpb1s.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpb1s.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpb1s.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpb1s.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpb1s.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpb1s.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Tyrian purple has been found in paintings dating back to the Bronze Age (Credit: Alamy)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpb1s.jpg" alt="Tyrian purple has been found in paintings dating back to the Bronze Age (Credit: Alamy)" id=""></picture><div><p>Tyrian purple has been found in paintings dating back to the Bronze Age (Credit: Alamy)</p></div></div><div><p>Tyrian purple could be produced from the secretions of three species of sea snail, each of which made a different colour: <em>Hexaplex trunculus </em>(bluish purple), <em>Bolinus brandaris</em> (reddish purple), and <em>Stramonita haemastoma </em>(red).</p>
<p>Once snails had been collected, either by hand along rocky coastlines or with traps baited with other snails – Murex sea snails are predators – it was time to harvest the slime. In some places, the mucous gland was sliced it out using a specialised knife. One Roman author explained how <a href="https://digitalvirgil.co.uk/pvs/2013/part9.pdf">the snail's gore would then ooze out of its wounds</a>, "flowing out like tears", before being collected into mortars for grinding. Alternatively, smaller species could be crushed whole.</p>
<p>But this is the end of the certainty. Accounts of how colourless snail slime was transformed into the dye of legends are vague, contradictory and sometimes obviously mistaken – Aristotle said the mucous glands came from the throat of a "<a href="https://www.academia.edu/7606396/Dying_in_Purple_Life_Death_and_Tyrian_Dye_in_the_Aeneid">purple fish</a>". To complicate matters further, the dyeing industry was highly secretive – each manufacturer had their own recipe, and these complex, multi-step formulas were closely guarded.</p>
<p>"The problem is that people did not write down the important tricks," says Maria Melo, a professor of conservation science at NOVA University of Lisbon, Portugal.</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvnqdq"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvnqdq.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvnqdq.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvnqdq.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvnqdq.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvnqdq.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvnqdq.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvnqdq.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvnqdq.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Murex snails may also have been the historic source of “tekhelet” – a sacred colour in the Jewish tradition mentioned in the Hebrew Bible (Credit: Mohammed Ghassen Nouira)" src="https://ychef.files.bbci.co.uk/976x549/p0gvnqdq.jpg" alt="Murex snails may also have been the historic source of “tekhelet” – a sacred colour in the Jewish tradition mentioned in the Hebrew Bible (Credit: Mohammed Ghassen Nouira)" id=""></picture><div><p>Murex snails may also have been the historic source of “tekhelet” – a sacred colour in the Jewish tradition mentioned in the Hebrew Bible (Credit: Mohammed Ghassen Nouira)</p></div></div><div><h3>A purple pong</h3><div><p>In antiquity, Tyrian purple was not just renowned for its colour. Dyeworks were hotbeds of rotting fishy flesh with the added <a href="https://citeseerx.ist.psu.edu/document?repid=rep1&amp;type=pdf&amp;doi=5750d98181fd002503d2b147235bf6fa75ad334c">piquancy of urine</a> – often used to help <a href="https://www.smithsonianmag.com/science-nature/from-gunpowder-to-teeth-whitener-the-science-behind-historic-uses-of-urine-442390/">pigments stick</a>. Whole neighbourhoods could become enveloped in this putrid aroma, and cities where it was manufactured were considered <a href="https://journals.sagepub.com/doi/epdf/10.3184/003685013X13680345111425">unpleasant places to live</a>. The smell would permeate deep into the fibres of stained cloth, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6236399/">lingering</a> long after it was purchased. Since the wealthy had exclusive access to this shade, it may have been advisable to stay upwind of them. <strong><em>(Read more from the BBC about the </em></strong><a href="https://www.bbc.com/culture/article/20180801-tyrian-purple-the-regal-colour-taken-from-mollusc-mucus"><strong><em>disgusting origins of the colour purple</em></strong></a><strong><em>.)</em></strong></p></div></div><div><p>The most detailed record comes from Pliny, who explained the process in the 1st Century AD. It went something like this: after isolating the mucous glands, they were salted and left to ferment for three days. Next came the cooking, which was done in tin or possibly lead pots on a "moderate" heat. This continued until the whole mixture had been boiled down to a fraction of its original volume. On the tenth day, the dye was tested by dipping in some fabric – if it emerged stained with the desired shade, it was ready.&nbsp;</p>
<p>Given that each snail only contained the tiniest amount of mucous, it could take some 10,000 to make just a <a href="https://hrcak.srce.hr/255412">single gram of dye</a>. Mounds of <a href="https://www.journals.uchicago.edu/doi/abs/10.1086/371717?journalCode=jnes">billions of discarded sea snail shells</a> have been reported in areas where it was once manufactured. In fact, the production of Tyrian purple has been described as the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6236399/">first chemical industry</a> – and this not only applies to the scale of the operations, but their exacting nature.&nbsp;</p>
<p><strong><em>You might also like:</em></strong></p>
<ul>
<li><a href="https://www.bbc.com/future/article/20211105-the-bizarre-dog-breeds-time-forgot" target="_blank">The bizarre dog breeds that time forgot</a> </li>
<li><a href="https://www.bbc.com/future/article/20210316-the-legendary-fabric-that-no-one-knows-how-to-make" target="_blank">The ancient fabric that no one knows how to make</a> </li>
<li><a href="https://www.bbc.com/future/article/20210325-the-strange-medieval-fruit-the-world-forgot" target="_blank">The forgotten medieval fruit with a vulgar name</a> </li>
</ul>
<p>"It is not really easy to obtain the colour," says Ioannis&nbsp;Karapanagiotis, a professor of conservation chemistry at Aristotle University of Thessaloniki, Greece. He explains that Tyrian purple is totally unlike other dyes, where the raw material – such as leaves – contains the pigment already. Instead, the sea snail mucous contains chemicals which can be <a href="https://www.mdpi.com/2071-1050/11/13/3595">turned into a dye</a>, but only under the right conditions. "It is quite amazing," he says. And yet, many crucial details of the process are long forgotten.</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvpd89"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpd89.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpd89.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpd89.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpd89.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpd89.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpd89.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpd89.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpd89.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="In ancient and medieval times, Tyrian purple was so valuable, it was often faked – usually with a combination of blue dye from indigo plants and red madder (Credit: Alamy)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpd89.jpg" alt="In ancient and medieval times, Tyrian purple was so valuable, it was often faked – usually with a combination of blue dye from indigo plants and red madder (Credit: Alamy)" id=""></picture><div><p>In ancient and medieval times, Tyrian purple was so valuable, it was often faked – usually with a combination of blue dye from indigo plants and red madder (Credit: Alamy)</p></div></div><div><p><strong>An abrupt decline </strong></p>
<p>In the early hours of 29 May 1453, the Byzantine city of Constantinople was captured by the Ottomans. This was the end of the Eastern Roman Empire – and it <a href="https://journals.sagepub.com/doi/pdf/10.3184/003685013X13680345111425">took Tyrian purple with it</a>.</p>
<p>At the time, the city's dyeworks were at the centre of the industry. The colour had become deeply bound to Catholicism – worn by cardinals and used to dye the pages of religious manuscripts. But it had already been suffering, after a succession of excessive <a href="https://journals.sagepub.com/doi/pdf/10.3184/003685013X13680345111425">taxes</a>. Now the church had lost control of the pigment's production altogether. So, the pope soon decided that red would become the <a href="https://journals.sagepub.com/doi/pdf/10.3184/003685013X13680345111425">new symbol of Christian power</a>. This could be made easily and cheaply by crushing scale insects.</p>
<p>However, there may also have been another factor in the demise of Tyrian purple. In 2003, scientists stumbled upon a pile of sea snail shells at the site of the ancient port of Andriake in southern Turkey. In all, they estimated that this garbage heap, dating to the 6th Century AD, contained around 300 cubic metres (10,594 cubic ft) of their remains – corresponding to up to 60 million individuals.</p>
<p>Intriguingly, though the bottom of the pile – where the snails were discarded first – contained some plump, older specimens, those discarded more recently were <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0092.2007.00281.x">significantly smaller and younger</a>. One explanation is that the sea snails had been overexploited and eventually, there just weren't any mature snails left. This may have led to the extinction of <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-0092.2007.00281.x">dye production in the area</a>, the researchers suggest.</p>
<p>But just a few years after this discovery, another would raise hopes of reviving this ancient colour.</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvpdlm"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpdlm.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpdlm.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpdlm.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpdlm.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpdlm.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpdlm.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpdlm.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpdlm.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="In Mexico and Central America, indigenous people have a very different method for dyeing with Murex – they rub live snails onto fabric directly (Credit: Mohammed Ghassen Nouira)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpdlm.jpg" alt="In Mexico and Central America, indigenous people have a very different method for dyeing with Murex – they rub live snails onto fabric directly (Credit: Mohammed Ghassen Nouira)" id=""></picture><div><p>In Mexico and Central America, indigenous people have a very different method for dyeing with Murex – they rub live snails onto fabric directly (Credit: Mohammed Ghassen Nouira)</p></div></div><div><p><strong>A determined revival </strong></p>
<p>One day in September 2007, Mohammed Ghassen Nouira was taking his usual lunchtime walk on a beach on the outskirts of the city of Tunis, Tunisia. "There had been a horrible storm the previous night, so there were a lot of dead creatures on the sand, like jellyfish, seaweeds, small crabs, molluscs," he says. Then he noticed a smear of colour – an intensely reddish-purple liquid was oozing out of a cracked sea snail.</p>
<p>Nouira, who works as a consulting manager, was immediately reminded of a story he had learned at school – the legend of Tyrian purple. He raced to the local harbour, where he found many more snails, exactly like the one on the beach. Their little spiral bodies are covered in spikes, so they often become trapped in fishermen's nets. "They hate them," he says. One man was plucking them out of his net and putting them in an old tomato can – which Nouira later took back to his apartment.</p>
<p>To begin with, Nouira's experiment was extremely disappointing. That night, he cracked the snails open and looked for the vivid purple entrails he had seen on the beach. But there was nothing there except pale flesh. He put it all in a bag to throw away, and went to bed. The next day, the bag's contents had undergone a transformation. "At that time, I had no clue that the purple was initially transparent – it's like water," he says.</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvpbk4"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpbk4.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpbk4.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpbk4.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpbk4.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpbk4.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpbk4.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpbk4.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpbk4.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="For dyes to stick to fabric, their molecules need to be converted to a water-soluble form. It’s not clear how this was achieved in antiquity (Credit: Mohammed Ghassen Nouira)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpbk4.jpg" alt="For dyes to stick to fabric, their molecules need to be converted to a water-soluble form. It’s not clear how this was achieved in antiquity (Credit: Mohammed Ghassen Nouira)" id=""></picture><div><p>For dyes to stick to fabric, their molecules need to be converted to a water-soluble form. It’s not clear how this was achieved in antiquity (Credit: Mohammed Ghassen Nouira)</p></div></div><div><h3>A modern application</h3><div><p>Today scientists have been investigating a possible new use for Tyrian purple – or at least, one of the most important molecules involved. In its pure form, 6,6'-dibromoindigo is a deep purple powder, and it just so happens that it makes an&nbsp;<a href="https://pubs.acs.org/doi/full/10.1021/acs.jpcc.0c05186" target="_blank">excellent semiconductor</a>&nbsp;– the basis of modern electronics. As an organic material it's&nbsp;biodegradable and&nbsp;less alien to the human body than silicon, so as well as making electronics more ecofriendly, it could potentially be used in&nbsp;<a href="https://pubs.rsc.org/en/content/articlehtml/2022/tc/d1tc04997f" target="_blank">wearable technologies</a>. The best part? It can be&nbsp;<a href="https://www.tandfonline.com/doi/abs/10.1081/SCC-100107023" target="_blank">made in a laboratory</a>&nbsp;– with no sea snails involved.&nbsp;</p></div></div><div><p>Scientists now know that to jolt the chemicals in Murex snails out of their colourless state, they need to be <a href="https://link.springer.com/article/10.1007/s11224-017-0932-0">exposed to visible light</a>. Initially their secretions will turn yellow, then green, turquoise, blue and eventually a shade of purple, depending on the snail species. "If you do this process on a sunny day, it takes something like less than five minutes to have this transformation," says Karapanagiotis.</p>
<p>But this isn't instant Tyrian purple. The shade is actually made up of many different pigment molecules, all working together. Melo explains that there's indigo, which is blue, "brominated" indigo, which is purple, and indirubin, which is red. "Depending on the treatment of your extract, and on the dying, you can have very different colours," she says. Even once the desired colour has been achieved, there is still yet more processing to do to turn the pigments into a dye, such as converting them into forms that will stick to fabric.</p>
<p>For Nouira, this was the beginning of a 16-year obsession with uncovering the lost method for making Tyrian purple. Though others have <a href="https://journals.sagepub.com/doi/pdf/10.3184/003685013X13680345111425">investigated the secretions of sea snails</a> before – including a scientist who processed 12,000 individuals into 1.4g of pure powdered pigment using industrial techniques – Nouira wanted to make it the old way, and rediscover the authentic shade that was venerated for millennia.</p>
<p>When he took those first sea snails in his apartment back in 2007, it was just a week after his honeymoon. "My wife was horrified by the by the smell; she almost kicked me out of the house… But I had to carry on," he says.</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvp9p3"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvp9p3.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvp9p3.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvp9p3.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvp9p3.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvp9p3.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvp9p3.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvp9p3.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvp9p3.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="Ancient Roman authors compared Tyrian purple to the colour of clotted blood (Credit: Mohammed Ghassen Nouira)" src="https://ychef.files.bbci.co.uk/976x549/p0gvp9p3.jpg" alt="Ancient Roman authors compared Tyrian purple to the colour of clotted blood (Credit: Mohammed Ghassen Nouira)" id=""></picture><div><p>Ancient Roman authors compared Tyrian purple to the colour of clotted blood (Credit: Mohammed Ghassen Nouira)</p></div></div><div><p>It took years for Nouira to make his first powdered dye, and when he did, it was a pale indigo colour, nothing like Tyrian purple and extremely dusty. Through years of trial and error, Nouira gradually discovered tricks that he suspects may have been used in antiquity – blending secretions from all three sea snail species mentioned in Pliny's account, adjusting the acidity of the mixture, alternating exposure to sunlight with darkness during preparation, and cooking his mixtures for different lengths of time.</p>
<p>For references, Nouira mostly used Byzantine mosaics depicting Justinian I and his wife Theodora – though he also later compared his results with surviving fragments of fabric. Eventually he ended up with pure pigments and dyes that he thinks are uncannily close to true Tyrian purple – and live up to the ancient hype. "It [the colour] is very alive, very dynamic," he says. "Depending on the light, it shifts and shimmers… it keeps changing and playing tricks on your eyes."</p></div><div id="future/article/20231122-tyrian-purple-the-lost-ancient-pigment-that-was-more-valuable-than-gold-p0gvpcvz"><picture><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpcvz.webp" type="image/webp"><source media="(min-width:1200px)" srcset="https://ychef.files.bbci.co.uk/1600x900/p0gvpcvz.jpg" type="image/jpeg"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpcvz.webp" type="image/webp"><source media="(min-width:880px)" srcset="https://ychef.files.bbci.co.uk/1280x720/p0gvpcvz.jpg" type="image/jpeg"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpcvz.webp" type="image/webp"><source media="(min-width:576px)" srcset="https://ychef.files.bbci.co.uk/976x549/p0gvpcvz.jpg" type="image/jpeg"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpcvz.webp" type="image/webp"><source media="(min-width:224px)" srcset="https://ychef.files.bbci.co.uk/624x351/p0gvpcvz.jpg" type="image/jpeg"><img loading="lazy" draggable="false" title="It’s not known why Murex snails produce the chemical precursors to Tyrian purple, but one idea is that they are used to paralyse prey (Credit: Mohammed Ghassen Nouira)" src="https://ychef.files.bbci.co.uk/976x549/p0gvpcvz.jpg" alt="It’s not known why Murex snails produce the chemical precursors to Tyrian purple, but one idea is that they are used to paralyse prey (Credit: Mohammed Ghassen Nouira)" id=""></picture><div><p>It’s not known why Murex snails produce the chemical precursors to Tyrian purple, but one idea is that they are used to paralyse prey (Credit: Mohammed Ghassen Nouira)</p></div></div><div><p>After decades of pungent experiments in his shed, Nouira has been invited to display his pigments and dyed products at exhibitions all over the world, including <a href="https://www.youtube.com/watch?v=1bRO9P56WHE">the British Museum in London</a> and the Museum of Fine Arts Boston. He has also become something of a culinary expert on sea snail recipes; he recommends spicy Tunisian Murex pasta, or fried Murex. "It's crunchy, it's delicious, it's incredible," he says.</p>
<p>But Tyrian purple is again under threat. Today the challenge is not invasion, or secrecy surrounding how it's made – though like his ancient counterparts, Nouira is furtive about the exact details of his methods – but extinction. Murex sea snails are under threat from a barrage of human influences, including <a href="https://www.mdpi.com/2071-1050/11/13/3595">pollution</a> and <a href="https://www.nature.com/articles/srep36897">climate change</a>. <em>Stramonita haemastoma, </em>which lends the colour a reddish tint, has already <a href="https://www.nature.com/articles/srep36897">vanished from the eastern</a> Mediterranean. So, whether or not Tyrian purple has finally been revived, one thing is certain: it could easily be lost all over again.</p>
<p>--</p>
<p><em>If you liked this story,&nbsp;</em><a href="https://cloud.email.bbc.com/SignUp10_08?&amp;at_bbc_team=studios&amp;at_medium=Onsite&amp;at_objective=acquisition&amp;at_ptr_name=bbc.com&amp;at_link_origin=featuresarticle&amp;at_campaign=essentiallist&amp;at_campaign_type=owned">sign up for The Essential List newsletter</a><em>&nbsp;– a handpicked selection of features, videos and can't-miss news delivered to your inbox every Friday.</em></p>
<p><em>Join one million Future fans by liking us on </em><a href="https://www.facebook.com/BBCFuture/"><em>Facebook</em></a><em>, or follow us on </em><a href="https://twitter.com/BBC_Future"><em>Twitter</em></a><em> or </em><a href="https://www.instagram.com/bbcfuture_official/"><em>Instagram</em></a><em>.</em></p></div></div></article></div>;</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A case for moving away from the cloud and embracing local storage solutions (129 pts)]]></title>
            <link>https://blog.golivecosmos.com/embrace-independence-the-case-for-moving-away-from-the-cloud/</link>
            <guid>38512656</guid>
            <pubDate>Mon, 04 Dec 2023 01:23:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.golivecosmos.com/embrace-independence-the-case-for-moving-away-from-the-cloud/">https://blog.golivecosmos.com/embrace-independence-the-case-for-moving-away-from-the-cloud/</a>, See on <a href="https://news.ycombinator.com/item?id=38512656">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<main>


    <article>

        <header>
            
            <h2>Embrace Independence: The Case for Moving Away from the Cloud ⛓️‍💥</h2>
                <figure>
        <img srcset="https://blog.golivecosmos.com/content/images/size/w400/2023/12/DTS_Wellness-Worship_18-2-1.jpg 400w,
                    https://blog.golivecosmos.com/content/images/size/w750/2023/12/DTS_Wellness-Worship_18-2-1.jpg 750w,
                    https://blog.golivecosmos.com/content/images/size/w960/2023/12/DTS_Wellness-Worship_18-2-1.jpg 960w,
                    https://blog.golivecosmos.com/content/images/size/w1140/2023/12/DTS_Wellness-Worship_18-2-1.jpg 1140w,
                    https://blog.golivecosmos.com/content/images/size/w1920/2023/12/DTS_Wellness-Worship_18-2-1.jpg 1920w" sizes="(min-width: 960px) 960px, 92vw" src="https://blog.golivecosmos.com/content/images/size/w960/2023/12/DTS_Wellness-Worship_18-2-1.jpg" alt="The Case for Moving Away from the Cloud" loading="lazy">

    </figure>
        </header>

        <div>
            <p>In a world where more and more of our life, photos, and documents drift in the digital ether, it's time to reflect on the popular cloud trend and explore <a href="https://www.forbes.com/sites/forbestechcouncil/2023/04/18/the-rise-of-cloud-repatriation-why-companies-are-bringing-data-in-house/?sh=2b3cdf1b58f7&amp;ref=blog.golivecosmos.com" rel="noreferrer">the cloud repatriation movement</a> of bringing data in-house.</p><p>Storing files in the cloud has been a great way of saving space on a computer for a while now, but as storage providers get bigger and bigger, they may not be as secure, cost effective, and reliable. Just last month, <a href="https://www.theregister.com/2023/11/27/google_drive_files_disappearing/?ref=blog.golivecosmos.com" rel="noreferrer">reports emerged</a> of <a href="https://arstechnica.com/gadgets/2023/11/google-drive-is-investigating-sync-issues-as-users-complain-of-lost-files/?ref=blog.golivecosmos.com" rel="noreferrer">Google Drive users are complaining of lost files</a>. <a href="https://support.google.com/drive/thread/245861992?ref=blog.golivecosmos.com" rel="noreferrer">Google acknowledged that files for some users are not available</a> at the moment. What do you when your files are basically owned by someone else? Is it time to reconsider how we store our files? Should we go back to good old fashioned files sitting right in our computers? Why moving away from cloud storage could be worth it:</p><p><strong>1. Security</strong><br>The cloud may be a seemingly secure space, but storing your photos and documents on your computer provides an extra layer of control and security. There is less concern for unauthorized access or data breaches because your files are physically with you. With cloud storage providers, it's important to take into account what features are available for detecting unauthorized access to your files, as some providers, like <a href="https://www.mitiga.io/blog/mitiga-security-advisory-lack-of-forensic-visibility-with-the-basic-license-in-google-drive?ref=blog.golivecosmos.com" rel="noreferrer">Google Drive, only provide a record of access logs to your drive when using a paid license</a>. In theory, <a href="https://cybersecuritynews.com/google-drive-security-flaw/?ref=blog.golivecosmos.com" rel="noreferrer">someone could infiltrate your drive, download your files, and there would be no record of this access if you're using a free license on Google Drive</a>. </p><p><strong>2. Cost</strong><br>To guarantee access to your files, cloud providers charge monthly subscriptions that may increase as your storage needs increase. <a href="https://one.google.com/about/plans?ref=blog.golivecosmos.com" rel="noreferrer">Google One plans</a> store up to 2TB of files, while <a href="https://support.apple.com/en-us/HT201238?ref=blog.golivecosmos.com" rel="noreferrer">Apple iCloud plans</a> offer up to 12TB of storage. Instead of paying a monthly subscription to store and access your files, a one-time payment for an external hard drive may be a more economical alternative over time.</p><p><strong>3. Reliable Access</strong><br>With files stored directly on your computer, you're not at risk of losing access to your files when service outages happen. A service outage could become a huge interruption to your day if you depend on a cloud service for work. Back in 2020, on the first day of remote school for many students and teachers, <a href="https://www.cnn.com/2020/09/08/tech/google-drive-outage/index.html?ref=blog.golivecosmos.com" rel="noreferrer">several teachers reported not being able to access their Google drives</a> they relied on as a virtual classroom tool. Teachers couldn't resume classes until Google resolved the outage several hours later. There are also <a href="https://sixcolors.com/post/2023/10/bitten-by-the-black-box-of-icloud/?ref=blog.golivecosmos.com" rel="noreferrer">iCloud users who have reported losing access to their files during unannounced maintenance windows</a>. When your files are stored locally on your computer, a single provider's service outage or maintenance down time won't be a cause for concern.</p><p>Here's to safeguarding your digital world 🌐💾. Until next time, keep your data safe and your tech journeys thrilling.</p><p>Curious for more? Follow us on <a href="https://twitter.com/golivecosmos?ref=blog.golivecosmos.com" rel="noreferrer">X (Twitter)</a> to continue the conversation.</p>
        </div>

            
    </article>

        

        

</main>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[When product markets become collective traps: The case of social media (147 pts)]]></title>
            <link>https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/</link>
            <guid>38512506</guid>
            <pubDate>Mon, 04 Dec 2023 00:59:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/">https://bfi.uchicago.edu/insight/research-summary/when-product-markets-become-collective-traps-the-case-of-social-media/</a>, See on <a href="https://news.ycombinator.com/item?id=38512506">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In many contexts, the individual value from consuming a product or service increases as more people consume it. The more of your peers who join TikTok, for example, the more value you probably see in joining yourself. Building on this logic, it’s possible that products like social media not only offer greater utility to users as their market share grows, but greater disutility to non-users as well. Just imagine being the sole holdout during the TikTok craze. With each friend who joins, you likely feel increasingly left out. In this paper, the authors test for these spillovers and paint a more accurate picture of how social media impacts consumers.</p><p>To study this question, the authors design a largescale, online experiment aimed at measuring consumer welfare in the presence of both network effects—the phenomenon wherein the value of joining vs. not joining increases with the number of consumers—and consumption spillovers to non-users—for example, fear of missing out on the latest TikTok trend. Their survey-based experiment focuses on TikTok and Instagram and is administered to 1,000 college students.</p><p><img decoding="async" src="https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media.jpg" alt="" width="901" height="654" srcset="https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media.jpg 901w, https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media-551x400.jpg 551w, https://bfi.uchicago.edu/wp-content/uploads/2023/10/Burzstyn-When-Product-Markets-Become-Collective-Traps-The-Case-of-Social-Media-768x557.jpg 768w" sizes="(max-width: 901px) 100vw, 901px"></p><p>The authors begin by measuring the amount of money that users would accept to deactivate their accounts for four weeks, while keeping constant others’ social media use. They next measure how much users value their accounts when other students at their university are asked to deactivate their accounts as well. Finally, the authors measure users’ preferences over the deactivation of accounts of all participating students, including themselves. They find the following:</p><ul><li>Users would need to be paid $59 to deactivate TikTok and $47 to deactivate Instagram if others in their network were to continue using their accounts.</li><li>Users would be willing to pay $28 and $10 to have others, including themselves, deactivate TikTok and Instagram, respectively. Accounting for consumption spillovers to non-users reveals that 64% of active TikTok users and 48% of active Instagram users experience negative welfare from the products’ existence. Participants who do not have accounts would be willing to pay $67 and $39 to have others deactivate their TikTok and Instagram accounts, respectively.</li><li>Taken together, these results imply the existence of a “social media trap” for a large share of consumers, whose utility from the platforms is negative but would have been even more negative if they didn’t use social media.</li><li>The authors use these results to quantify the role of network effects on social media, or the extent to which users value social media platforms more when their peers use them. They find positive and quantitatively significant network effects: users value TikTok and Instagram 33% and 24% more, respectively, when their peers are on the sites compared to when they are not.</li></ul><p>Building on these results, the authors explore whether product market traps exist in other domains as well. They field online surveys with consumers concerning their opinions on luxury goods and technology, where similar spillover effects are a plausible driver of consumption. They find the following:</p><ul><li>Among respondents who own luxury brands that they themselves bought (e.g., Gucci, Versace, Rolex), 44% prefer to live in a world without any of those brands altogether. Among respondents not owning such brands, the fraction preferring to live in a world without them is 69%.</li><li>Among iPhone owners, a striking 91% of respondents indicate that they would prefer Apple to release the iPhone every other year rather than every year. Among respondents not owning the iPhone, this fraction is even larger, at 94%.</li></ul><p>This research challenges the standard argument that the mere existence of a product implies positive welfare for its users. This could help reconcile the seemingly contradictory findings in the social media literature of a large consumer surplus coexisting with negative effects on wellbeing. It also suggests a heightened need for regulators to assess whether different products create traps for consumers and whether they generate positive welfare. For instance, large tech companies commonly use tools that might decrease non-consumer surplus, such as increasing the salience of being a non-consumer or tying together messaging apps and social media platforms and thus increasing the cost of not being a user.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Writing a file system from scratch in Rust (195 pts)]]></title>
            <link>https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html</link>
            <guid>38512248</guid>
            <pubDate>Mon, 04 Dec 2023 00:20:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html">https://blog.carlosgaldino.com/writing-a-file-system-from-scratch-in-rust.html</a>, See on <a href="https://news.ycombinator.com/item?id=38512248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <p>Data produced by programs need to be stored somewhere for future reference, and
there must be some sort of organisation so we can quickly retrieve the desired
information. A file system (FS) is responsible for this task and provides an
abstraction over the storage devices where the data is physically stored.</p>

<p>In this post, we will learn more about the concepts used by file systems, and
how they fit together when writing your own.</p>

<h2 id="structuring-the-disk">Structuring the disk</h2>
<p>When data is stored in a hard-disk drive (HDD) or solid-state drive (SSD), it is
written in small units called sectors (or pages in the SSD case). The drives
don’t have any information about what that piece of data represents, for all it
is worth, the disk is just a giant array of sectors. It is the job of the file
system to make sense of it all.</p>

<p>A file system will divide the disk into fixed-sized blocks. The FS uses the
majority of these blocks to store user data, but some blocks are used to store
metadata that is essential for the file system operation.</p>

<p>The following figure gives an example of how a file system structures the
information on the disk:</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_filesystem_blocks.svg" alt="">
    <figcaption>File system structure in a disk</figcaption>
</figure>

<p>In the next sections, we will understand what each type of block means.</p>

<h3 id="superblock-and-bitmaps">Superblock and bitmaps</h3>

<p>The superblock stores most of the metadata about the file system, such as the
following: block size, timestamps, how many blocks and files are in use and how
many are free, etc.</p>

<p>Bitmaps are one way of tracking which data blocks and inodes are free. An index
in the bitmap set to <code>0</code> indicates a free slot, and an index set to <code>1</code>
indicates an occupied slot.</p>

<h3 id="inode">Inode</h3>

<p>The inode is the structure that stores metadata about a file. Attributes such as
permissions, size, location of data blocks that form the file and more are saved
in an inode.</p>

<p>The inodes are stored in blocks that together form the <em>inode table</em> as the
following figure shows.</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_inode_table.svg" alt="">
    <figcaption>Inode table (detailed view)</figcaption>
</figure>

<p>For each slot in the inode bitmap set to <code>1</code>, there will be a corresponding
inode in the table. The index of the slot is the same as the index in the table.
And this explains the name inode being a short name for <em>index node</em>.</p>

<h3 id="data-blocks">Data blocks</h3>

<p>As the name suggests, the data blocks are the blocks where the actual data
belonging to a file is written. These blocks are also used for different
purposes which we will see shortly.</p>

<h2 id="pointing-to-data">Pointing to data</h2>

<p>The inode needs to have a way of pointing to the data blocks that assemble the
file. The simplest way is to have <strong>direct pointers</strong>. In this case, each
pointer points to a block that has some of the file data. The problem is that
large files; where the size exceeds the number of direct pointers an inode can
have; are not supported in this mode. One way of overcoming this issue is to use
<strong>indirect pointers</strong>, which instead of storing user data they store pointers to
blocks that hold user data. For larger files, another layer of indirection is
added with <strong>double indirect pointers</strong>. And for even larger files, <strong>triple
indirect pointers</strong> are put to use.</p>

<figure>
    <img src="https://wiki.carlosgaldino.com/public/images/io_direct_pointers.svg" alt="">
    <figcaption>Inode multi-level index</figcaption>
</figure>

<p>To give an idea of the largest file size that each level permit let’s run an
example considering that each block size is 4 KiB. Research has shown that the
majority of files are small [1] so 12 direct pointers would allow for files up
to 48 KiB. Considering that each pointer takes 4 bytes, a single indirect
pointer would then allow a file to be up to around 4 MiB:</p>

<pre>(12 + 1024) * 4 KiB
</pre>

<p>With the addition of double indirect pointers the size would jump to around 4
GiB:</p>

<pre>(12 + 1024 + 1024<sup>2</sup>) * 4 KiB
</pre>

<p>And finally, with triple indirect pointers the files could have a size of around
4 TiB:</p>

<pre>(12 + 1024 + 1024<sup>2</sup> + 1024<sup>3</sup>) * 4 KiB
</pre>

<p>This approach might not be very efficient for handling large files. For example,
a file of 100 MiB requires the allocation of 25600 blocks. The performance can
be severely impacted in case the blocks were fragmented over the disk.</p>

<p>Some file systems use <strong>extents</strong> to help with this situation. In this approach,
there is a single pointer and a length to tell that the data starts at the
address of the pointer and runs for the given range of blocks. In our example
above, describing the same file would use a single extent of size 100 MiB.
Multiple extents can be used to support larger files.</p>

<h2 id="directories">Directories</h2>

<p>You may have noticed that there isn’t a specific structure for directories. The
reason behind it is the fact that inodes represent both files and directories.
The difference is in what is stored in the corresponding data blocks.
Directories are simply a list of all files that it includes. Each entry has the
form of <code>(name, index number)</code> so when looking up a particular file (or another
directory), the system uses the <code>name</code> to find the corresponding inode.</p>

<p>Searching for a file can be slow if a directory contains a large number of
files. This issue can be mitigated by maintaining the list sorted and using
binary search, or instead of representing it as a list, a hash table or a
balanced search tree could also be used.</p>

<h2 id="access-paths">Access paths</h2>

<h3 id="read">Read</h3>

<p>When reading from a file, the file system needs to traverse the entire path,
visiting each inode along the way until reaching the inode for the desired file.
Assuming the user has permission to access the file, the file system consults
which blocks are associated with it and then read the solicited data from them.</p>

<h3 id="write">Write</h3>

<p>When writing to a file, the same process has to happen to find the corresponding
inode. If a new block is required for the write, the file system has to allocate
the block, update the associated information (bitmap and inode), and write to
the block. So one write operation requires five I/O operations: one read to the
bitmap, one write to mark the new block as occupied, two to read and write to
the inode, and one writing the data in the block. This number can increase when
creating a new file because now the associated information of the directory also
has to be read and written to reflect this new file, and operations to create a
new inode.</p>

<h2 id="gotenksfs">GotenksFS</h2>

<p>As a side project, I decided to write my own file system in Rust as I’m learning
the language. Some aspects are inspired by ext4 [2] (and family), and in this
section, you will learn more about it. The file system uses FUSE [3], and the
disk is represented as a regular file. The block size can be configured as 1
KiB, 2 KiB, or 4 KiB. Files can have a size of up to 4 GiB for block sizes of 4
KiB while the file system could theoretically be up to 16 TiB in size.</p>

<h3 id="mkfs"><code>mkfs</code></h3>

<p>The first step is to create the image itself with the configuration values for
the file system. This is achieved via the <code>mkfs</code> command:</p>

<div><pre><code><span>$ </span>./gotenksfs mkfs disk.img <span>-s</span> <span>"10 GiB"</span> <span>-b</span> 4096
</code></pre></div>

<p>After running the command, the image is created with a total size of 10 GiB, and
each block in the file system has a size of 4 KiB.</p>

<p>In this step, the configuration values and other structures such as a root
directory are written to the image in the first block: the superblock. Its
corresponding bitmap entries, and data are also written. These values will be
necessary for the next step: mounting the file system.</p>

<h3 id="mount"><code>mount</code></h3>

<p>After creating the image, we need to mount it so we can start using it. The
<code>mount</code> command is used for this:</p>

<div><pre><code><span>$ </span>./gotenksfs mount disk.img gotenks
</code></pre></div>

<p>And you can see some information about it:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/gotenksfs-mount.png">
    <figcaption>File system after mounting</figcaption>
</figure>

<h3 id="on-disk-structure">On-disk structure</h3>

<p>The superblock is written in the first 1024 bytes, and it holds the
configuration values provided in the <code>mkfs</code> command.</p>

<div><pre><code><span>pub</span> <span>struct</span> <span>Superblock</span> <span>{</span>
    <span>pub</span> <span>magic</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>block_size</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>created_at</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>modified_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>last_mounted_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>u64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>block_count</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>inode_count</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>free_blocks</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>free_inodes</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>groups</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>data_blocks_per_group</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>uid</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>gid</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div>

<p>The next two blocks represent the data bitmap and inode bitmap. Then, a run of
<code>n</code> blocks are used for the inode table. And the blocks following that are the
ones where user data will be written.</p>

<p>The inode is defined as follows:</p>

<div><pre><code><span>pub</span> <span>struct</span> <span>Inode</span> <span>{</span>
    <span>pub</span> <span>mode</span><span>:</span> <span>libc</span><span>::</span><span>mode_t</span><span>,</span>
    <span>pub</span> <span>hard_links</span><span>:</span> <span>u16</span><span>,</span>
    <span>pub</span> <span>user_id</span><span>:</span> <span>libc</span><span>::</span><span>uid_t</span><span>,</span>
    <span>pub</span> <span>group_id</span><span>:</span> <span>libc</span><span>::</span><span>gid_t</span><span>,</span>
    <span>pub</span> <span>block_count</span><span>:</span> <span>u32</span><span>,</span> <span>// should be in 512 bytes blocks</span>
    <span>pub</span> <span>size</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>created_at</span><span>:</span> <span>u64</span><span>,</span>
    <span>pub</span> <span>accessed_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>modified_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>changed_at</span><span>:</span> <span>Option</span><span>&lt;</span><span>i64</span><span>&gt;</span><span>,</span>
    <span>pub</span> <span>direct_blocks</span><span>:</span> <span>[</span><span>u32</span><span>;</span> <span>DIRECT_POINTERS</span> <span>as</span> <span>usize</span><span>],</span>
    <span>pub</span> <span>indirect_block</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>double_indirect_block</span><span>:</span> <span>u32</span><span>,</span>
    <span>pub</span> <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div>

<p>As you can see above, inodes support double indirect pointers which means that
for a disk with a block size of 4 KiB, the maximum capacity of a file is 4 GiB.
The number of direct pointers is set to 12:</p>

<div><pre><code><span>pub</span> <span>const</span> <span>DIRECT_POINTERS</span><span>:</span> <span>u64</span> <span>=</span> <span>12</span><span>;</span>
</code></pre></div>

<p>When starting the FS for the first time, it will create the root directory using
the definition below:</p>

<div><pre><code><span>pub</span> <span>struct</span> <span>Directory</span> <span>{</span>
    <span>pub</span> <span>entries</span><span>:</span> <span>BTreeMap</span><span>&lt;</span><span>OsString</span><span>,</span> <span>u32</span><span>&gt;</span><span>,</span>
    <span>checksum</span><span>:</span> <span>u32</span><span>,</span>
<span>}</span>
</code></pre></div>

<h3 id="block-groups">Block groups</h3>

<p>The inode bitmap has 4 KiB meaning that each bitmap block will have a capacity
for 32768 inodes. Suppose we round up the size of an <code>Inode</code> to 128 bytes; the
corresponding inode table will require 4 MiB of space. One of the ways for
structuring them would be to have many blocks dedicated to the bitmaps, then the
corresponding number blocks to store the inodes, and the remaining blocks for
user data.</p>

<p>Instead of doing that, we can create <em>block groups</em> that will always have one
block for the data bitmap and one for the inode bitmap. The next 1024 blocks
contain the inode table, and following that, 32768 blocks which are used for
user data.</p>

<!--
For a disk as in our case of 10 GiB, how many blocks should be dedicated to inode bitmaps?

Increasing the number of blocks to be inode bitmaps reduces the amount of available data blocks. And reducing the number of inode bitmaps restricts the total number of files supported by the system.
-->

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/gotenksfs_block_group.svg" alt="">
    <figcaption>Block groups</figcaption>
</figure>

<h3 id="reading-and-writing-to-files">Reading and writing to files</h3>

<p>Now that the “disk” is set up, we can start writing and reading files from it. Creating a new directory using <code>mkdir</code>:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/mkdir.gif" alt="">
    <figcaption>Creating a directory</figcaption>
</figure>

<p>The process that occurs is the following: the system searches for the inode of
the root directory, looks up in which data block the contents are being written
to, allocates a new inode and data block for the new directory, writes the entry
to the root directory, and finally, writes the new directory to its data block.</p>

<p>Writing a new file follows a similar method. The system traverses the given path
until the final directory is reached and adds an entry representing the new
file.</p>

<p>The write function provides the path, buffer with the data, offset, and a file
info struct that may hold a file handle along with extra information about the
file:</p>

<div><pre><code><span>fn</span> <span>write</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>path</span><span>:</span> <span>&amp;</span><span>Path</span><span>,</span> <span>buf</span><span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>],</span> <span>offset</span><span>:</span> <span>u64</span><span>,</span> <span>file_info</span><span>:</span> <span>&amp;</span><span>mut</span> <span>fuse_rs</span><span>::</span><span>fs</span><span>::</span><span>WriteFileInfo</span><span>)</span>
</code></pre></div>

<p>In this case, instead of traversing the path again to find the inode, the system
uses the file handle (the FS previously sets it when creating the file). With
the inode in hand, the FS can build the struct by seeking to the exact location
where the <code>Inode</code> is written:</p>

<div><pre><code><span>fn</span> <span>inode_offsets</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>index</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>(</span><span>u64</span><span>,</span> <span>u64</span><span>)</span> <span>{</span>
    <span>let</span> <span>inodes_per_group</span> <span>=</span> <span>self</span><span>.superblock</span><span>()</span><span>.data_blocks_per_group</span> <span>as</span> <span>u64</span><span>;</span>
    <span>let</span> <span>inode_bg</span> <span>=</span> <span>(</span><span>index</span> <span>as</span> <span>u64</span> <span>-</span> <span>1</span><span>)</span> <span>/</span> <span>inodes_per_group</span><span>;</span>
    <span>let</span> <span>bitmap_index</span> <span>=</span> <span>(</span><span>index</span> <span>as</span> <span>u64</span> <span>-</span> <span>1</span><span>)</span> <span>&amp;</span> <span>(</span><span>inodes_per_group</span> <span>-</span> <span>1</span><span>);</span>
    <span>(</span><span>inode_bg</span><span>,</span> <span>bitmap_index</span><span>)</span>
<span>}</span>

<span>fn</span> <span>inode_seek_position</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>index</span><span>:</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>u64</span> <span>{</span>
    <span>let</span> <span>(</span><span>group_index</span><span>,</span> <span>bitmap_index</span><span>)</span> <span>=</span> <span>self</span><span>.inode_offsets</span><span>(</span><span>index</span><span>);</span>
    <span>let</span> <span>block_size</span> <span>=</span> <span>self</span><span>.superblock</span><span>()</span><span>.block_size</span><span>;</span>
    <span>group_index</span> <span>*</span> <span>util</span><span>::</span><span>block_group_size</span><span>(</span><span>block_size</span><span>)</span>
        <span>+</span> <span>2</span> <span>*</span> <span>block_size</span> <span>as</span> <span>u64</span>
        <span>+</span> <span>bitmap_index</span> <span>*</span> <span>INODE_SIZE</span>
        <span>+</span> <span>SUPERBLOCK_SIZE</span>
<span>}</span>
</code></pre></div>

<p>Now that the FS has information about which data blocks are currently allocated
to the <code>Inode</code>, it can use them to find the exact location where to write the
data, in a process similar as shown above. New blocks are first added to the
<code>Inode</code> direct blocks array, and if the file size exceeds <code>(12 * BLOCK_SIZE)</code>,
the FS allocates an <code>indirect_block</code> that holds the numbers identifying other
blocks containing user data. And in the case the file is even bigger requiring
more blocks, the system adds an extra layer of indirection using the
<code>double_indirect_block</code> field which points to more indirect blocks. Reading from
a file follows the same method. You can see it running here:</p>

<figure>
    <img src="https://blog.carlosgaldino.com/public/images/cp.gif" alt="">
    <figcaption>Reading and writing to files</figcaption>
</figure>

<h2 id="conclusion">Conclusion</h2>

<p>The idea behind a file system is to define a structure for the contents on disk
which then allow the system to operate on top of it when creating, writing and
reading from files and directories.</p>

<p>We learned some of the concepts used for the on-disk format, how directories and
files are represented. One interesting aspect is the usage of indirect pointers
to allow storing large files. If you are interested in learning more about file
systems, I would recommend reading more about other techniques that are used
such as journaling, copy-on-write, log-structured file systems, and also how
modern file systems apply these and other techniques. Maybe start learning about
the one you are using right now.</p>

<p>The code for GotenksFS can be accessed here: <a href="https://github.com/carlosgaldino/gotenksfs"><code>carlosgaldino/gotenksfs</code></a>.</p>

<h2 id="references">References</h2>

<ul>
  <li>[1] Agrawal, N., Bolosky, W.J., Douceur, J.R. and Lorch, J.R., 2007. <em><strong>A five-year study of file-system metadata</strong></em>. ACM Transactions on Storage (TOS), 3(3), pp.9-es.</li>
  <li>[2] ext4.wiki.kernel.org. 2020. <em><strong>Ext4 Disk Layout - Ext4</strong></em>. Available at: <a href="https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout#Overview">https://ext4.wiki.kernel.org/index.php/Ext4_Disk_Layout#Overview</a>.</li>
  <li>[3] en.wikipedia.org. 2020. <em><strong>Filesystem In Userspace</strong></em>. Available at: <a href="https://en.wikipedia.org/wiki/Filesystem_in_Userspace">https://en.wikipedia.org/wiki/Filesystem_in_Userspace</a>.</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stuxnet Source Code (148 pts)]]></title>
            <link>https://github.com/research-virus/stuxnet</link>
            <guid>38511563</guid>
            <pubDate>Sun, 03 Dec 2023 22:48:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/research-virus/stuxnet">https://github.com/research-virus/stuxnet</a>, See on <a href="https://news.ycombinator.com/item?id=38511563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Open MyRTUs aka Stuxnet</h2>
<p dir="auto">This repository contains RCEd code extracted from Stuxnet binaries via disassembler and decompilers.</p>
<h2 tabindex="-1" dir="auto">Authors</h2>
<p dir="auto">The code provided in this repository was published by</p>
<ul dir="auto">
<li><strong>dropper</strong> - Christian Roggia <a href="mailto:christian.roggia@gmail.com">christian.roggia@gmail.com</a></li>
<li><strong>rootkit</strong> - Amr Thabet <a href="mailto:amr.thabet@student.alx.edu.eg">amr.thabet@student.alx.edu.eg</a></li>
</ul>
<h2 tabindex="-1" dir="auto">Why a license</h2>
<p dir="auto">Many of you might find it wrong that both I and Mr. Amr Thabet copyrighted our code, I mean it is "stolen" code extracted from malware binaries, right?</p>
<p dir="auto">I understand that it might look silly, but both of us spent hundreds, if not thousands, of hours between ASM code trying to figure out what was behind those binaries and we are providing the product of our hard work (i.e. readable C code) to you for free.
It is not a simple job and it is not a short job, both our licenses are extremely permissive, you can do whatever you want with the code provided in this repository, the only thing I'd like to ask you is that our job get recognized and that when you use this code for analysis, blog posts, or university thesis you show us your support by giving us credit for what we did.</p>
<p dir="auto">That's all. Thanks to all of you!</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Fediverse is an opportunity learned societies can't ignore (186 pts)]]></title>
            <link>https://blogs.lse.ac.uk/impactofsocialsciences/2023/11/30/the-fediverse-is-an-opportunity-learned-societies-cant-ignore/</link>
            <guid>38511346</guid>
            <pubDate>Sun, 03 Dec 2023 22:23:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blogs.lse.ac.uk/impactofsocialsciences/2023/11/30/the-fediverse-is-an-opportunity-learned-societies-cant-ignore/">https://blogs.lse.ac.uk/impactofsocialsciences/2023/11/30/the-fediverse-is-an-opportunity-learned-societies-cant-ignore/</a>, See on <a href="https://news.ycombinator.com/item?id=38511346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>Just as social media has become ubiquitous in academia, its established formats and dynamics have been brought into doubt. </em><strong>Björn&nbsp;</strong><strong>Brembs </strong><em>argues that learned societies concerned with their core mission as societies should engage and lead developments on federated social media platforms, such as Mastodon.</em></p>
<hr>
<p>Maybe scholarly societies have taken the instruction to follow the money too literally? There now are <a href="https://doi.org/10.1098/rsos.230207" target="_blank" rel="noopener">societies</a> that make 83% of their nearly $700 million in revenue from publishing (American Chemical Society). Or 88% of $130 million (American Psychological Association). Or 91% of $5 million (Biochemical Society). In essence, societies like these (there are hundreds predominantly in STEM subjects) are publishers first and societies second. One could be forgiven if one imagined their business meetings involved intoning, “Publish or perish”.</p>
<p>But, there’s more. Some of these organizations have sided with corporate publishers against scholarship, e.g., when <a href="https://www.science.org/content/article/court-demands-search-engines-and-internet-service-providers-block-sci-hub" target="_blank" rel="noopener">litigating</a><a href="https://en.harrisco.net/blog/elsevier-and-american-chemical-society-sue-sci-hub-for-copyright-infringement/"> against</a> organisations or individuals striving to make research more accessible, or <a href="https://medium.com/@brembs/learned-societies-lean-to-the-green-f904336f51ad" target="_blank" rel="noopener">begging nationalist leaders</a> to protect their dated business models. Can it still be considered ethical to charge multiples of the publication costs of an article in order to finance executive salaries, subsidise member dues, sponsor prizes, host all-you-can-drink receptions at annual meetings, or pay lawyers to ensure nobody can read the works of your scholars?</p>
<blockquote><p>There is a reason these organisations were called “societies” before they became publishers.</p></blockquote>
<p>This single-minded focus becomes more absurd if one considers the role societies have played in pursuing their primary mission as ‘societies’: supporting scholars in making connections to like-minded individuals, exchanging ideas and promoting their respective fields of scholarly interest – in short ‘socialising’. There is a reason these organisations were called “societies” before they became publishers. The root of their names contains their essential function, as <a href="https://books.google.de/books?hl=en&amp;lr=&amp;id=a5FbAAAAQAAJ&amp;oi=fnd&amp;pg=PA1&amp;ots=MuxhHqH8ka&amp;sig=bIroAVU46xA-YO4j7WbwgehekT8&amp;redir_esc=y#v=onepage&amp;q&amp;f=false" target="_blank" rel="noopener">described</a> in 1660 for one of the first such societies, the Royal Society:</p>
<p><em>“Their first purpose was no more, then onely the satisfaction of breathing a freer air, and of conversing in quiet one with another, without being ingag’d in the passions, and madness of that dismal Age”.</em></p>
<p>It is ironic that these very societies, born in an era of intellectual enlightenment, seem to have missed the memo about social media’s advent some 15 years ago. A technology that has not only transformed their mission, but even shares the root of their names. These organisations could have embraced FriendFeed or Facebook. Yet, maybe many felt the threat such <a href="https://blogs.lse.ac.uk/impactofsocialsciences/2017/06/06/introducing-canary-haz-discovering-article-pdfs-with-one-click/" target="_blank" rel="noopener">#icanhazpdf</a>-technology may pose to their bottom line so acutely, they failed to envisage the opportunities it offered? Each scholarly society is different and many have belatedly embraced social technologies. However, it appears as if this engagement has only rarely exceeded the use of corporate platforms as broadcasting tools, rather than as a social technology that encourages, promotes and protects social interactions among scholars and with the general public.</p>
<blockquote><p>the ‘Fediverse’ provides tools and technologies that are ideally suited to bring scholarly societies out of their digital caves and into the 21st century.</p></blockquote>
<p>Today, we have technology that allows scholarly societies to make good on past mistakes and show their true colours: the ‘Fediverse’ provides tools and technologies that are ideally suited to bring scholarly societies out of their digital caves and into the 21st century. One of these is <a href="https://joinmastodon.org/" target="_blank" rel="noopener">Mastodon</a>. While some scholarly institutions, including some societies, have started to implement their own Mastodon instances, the large majority remain locked into their favourite corporate broadcasting platform formerly known as Twitter. A platform that is rapidly <a href="https://www.theguardian.com/technology/2023/sep/26/eu-warns-elon-musk-that-twitter-x-must-comply-with-fake-news-laws" target="_blank" rel="noopener">devolving</a> and losing many of its <a href="https://www.nature.com/articles/d41586-023-02554-0" target="_blank" rel="noopener">academic members</a>.</p>
<p>Where scholarly societies have seriously engaged with social technologies, they are using them not just for broadcasting, but for scholarly exchange and to facilitate social interactions, such as debate, discussion and critique among all persons interested in their research, not just their members. The different local and federated timelines in Mastodon allow seamless interactions both within the society and outside of it. Federation choices enable societies to choose which content matches their instance and they become the moderators of their own social media presence, rather than having to rely on the <a href="https://blogs.lse.ac.uk/impactofsocialsciences/2022/05/03/leave-adapt-resist-time-to-rethink-academic-twitter/" target="_blank" rel="noopener">whims of billionaires</a>.</p>
<blockquote><p>Due to the open source nature of the Fediverse and the widespread digital competence in the scholarly community, there is ample potential for societies to take a central role in developing a new scholarly commons</p></blockquote>
<p>Where are the societies that see this opportunity that could give marginalised groups within scholarship a voice in a town square protected by scholarly rules? Rather than being another content provider for AdTech-based surveillance platforms, societies now have the opportunity (again!) to become the designers of a new kind of digital scholarship, while at the same time contributing to protecting the privacy of scholars. Due to the open source nature of the Fediverse and the widespread digital competence in the scholarly community, there is ample potential for societies to take a central role in developing a new scholarly commons and integrate this social layer into the more formal literature as part of the “<a href="https://www.consilium.europa.eu/en/press/press-releases/2023/05/23/council-calls-for-transparent-equitable-and-open-access-to-scholarly-publications/" target="_blank" rel="noopener">open, interoperable, not-for-profit infrastructures</a>” the Council of the EU science ministers has recently called for.</p>
<p>Of course, their handling of social technology is just a litmus test for how seriously a learned society is taking its role in our modern world and what perspective it has taken with regard to scholarship more generally. It doesn’t seem like too many societies are passing that test these days and maybe for some their predilection for excessive executive pay is to blame?</p>
<p>So, to the scholarly societies out there, here’s a challenge: step up, embrace Mastodon, and give faux-societies a run for their money. Show scholars you’re for scholarship and not just the bottom line.</p>

<hr>
<p><i>This post draws on the author’s perspective article, <a href="https://doi.org/10.1098/rsos.230207" target="_blank" rel="noopener">Mastodon over Mammon: towards publicly owned scholarly knowledge</a>, published in Royal Society Open Science.</i></p>
<p><i>The content generated on this blog is for information purposes only. This Article gives the views and opinions of the authors and does not reflect the views and opinions of the Impact of Social Science blog (the blog), nor of the London School of Economics and Political Science.&nbsp;<em>Please review our&nbsp;</em><a href="https://blogs.lse.ac.uk/impactofsocialsciences/about-the-blog/comments-policy/" target="_blank" rel="noopener"><em>comments policy</em></a><em>&nbsp;if you have any concerns on posting a comment below.</em></i></p>
<p><em>Image Credit:&nbsp;<a href="https://www.flickr.com/photos/gpeters/" target="_blank" rel="noopener">Geoff Peters</a>.&nbsp;<a href="https://www.flickr.com/photos/gpeters/3250238096/" target="_blank" rel="noopener">Mammoth</a>,&nbsp;Royal Victoria Museum via Flickr (<a href="https://creativecommons.org/licenses/by/2.0/" target="_blank" rel="noopener">CC BY 2.0</a>)</em></p>
<hr>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://i2.wp.com/cdn.printfriendly.com/buttons/printfriendly-button.png?ssl=1" alt="Print Friendly, PDF &amp; Email" data-recalc-dims="1"></a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: What side projects landed you a job? (465 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38511280</link>
            <guid>38511280</guid>
            <pubDate>Sun, 03 Dec 2023 22:16:45 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38511280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38512291"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512291" href="https://news.ycombinator.com/vote?id=38512291&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I wrote a Dropbox-like file sync and share application called Syncany [1] as a side project back in 2014/2015. While it never made it out of alpha, it had gotten some traction, and looking back, I am still proud of the architecture and design (not so much of the code, hehe).<p>One day, a developer from this random company in Connecticut (I am German and lived in Germany at the time) reached out to me in my project's IRC channel, and asked if I wanted to interview. I did, and I got the job.</p><p>I moved to the UK, then to the US with my wife, and stayed with the company for 8 years. I got promoted from senior engineer to Sr. Principal Engineer and had an amazing time there. I now have a green card and live in CT with my 2 amazing children (with German and American citizenship).</p><p>I often think back about how much that project and that person who reached out to me changed my life. How different it would be if I hadn't worked on my side project, if it hadn't become semi-popular, or if he hadn't reached out. Butterfly effect at it's finest.</p><p>[1] <a href="https://www.syncany.org/" rel="nofollow noreferrer">https://www.syncany.org</a></p><p>Edit: Fun fact: Drew Houston (Dropbox CEO) emailed me at the time and wanted to hire me, but he didn't respond when I emailed him back. And even many years later when I applied at Dropbox they didn't want me, hehe.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512481"><td></td></tr>
                  <tr id="38511682"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511682" href="https://news.ycombinator.com/vote?id=38511682&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Back in 2002 I lost my job during a regional financial crisis (I’m from Uruguay).<p>I was working at a bank (as a contractors) and some coworkers and I were working on a HA project for MySQL at the moment (to use it at work). Once I got laid off, I focused on it to the point that it became quite useful, and at some point, someone from Israel reached out with questions.</p><p>I answered with a lot of delay, and when I explained that was due to me being out of a job and not able to afford a permanent internet connection, he offered to hire me and also set me up with a permanent connection with a contract paid by him.</p><p>If you’re reading this, thank you Aric, I’m forever grateful for that chance!</p><p>Curiously, last year I switched jobs and during the interview process it turned out the hiring manager had been a user of my project back in 2003 or so, which definitely helped with the interview process.</p><p>The project’s name was mysql-ha, later renamed to highbase due to a Copyright infringement notice from Sun (who were good about it and gave me a free 1 year subscription to Enterprise MySQL when I renamed the project). I abandoned it around 2008 as better things became available around that time .
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511858"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511858" href="https://news.ycombinator.com/vote?id=38511858&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>That must give you an adrenaline rush of another level when the interviewer turns out to be your user. I want to feel that one day</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512187"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512187" href="https://news.ycombinator.com/vote?id=38512187&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>It was great though honestly, my first reaction was a bit of panic. The first thoughts that came to my mind were "will he say it sucked? maybe he used it and lost some data?". Once that didn't happen then yeah, it was thrilling, and completely unexpected for a project I hadn't worked on for over a decade!</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512085"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512085" href="https://news.ycombinator.com/vote?id=38512085&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>That's a fantastic story. I hope fortune has followed you. I would be <i>thrilled</i> to find even one user of software I've wrote. To be <i>interviewed</i> by one for a job? That's amazing.<p>Good stuff!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512193"><td></td></tr>
                  <tr id="38512169"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512169" href="https://news.ycombinator.com/vote?id=38512169&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Que bueno ver otro Uruguayo aca en HN, somos pocos pero buenos!<p>Que estes bien Fernando, me alegro que prefieras quedarte en el paisito y cultivarlo ayudando a otros.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512229"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512229" href="https://news.ycombinator.com/vote?id=38512229&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>¡Muchas gracias!<p>Y si, espero que ahora que el trabajo remoto es mas aceptado, mucha mas gente pueda "irse sin irse", trabajando para donde sea pero desde acá.</p><p>¡Que estés bien también!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512312"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512312" href="https://news.ycombinator.com/vote?id=38512312&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; who were good about it and gave me a free 1 year subscription to Enterprise MySQL when I renamed the project<p>Sun really was good, huh?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512490"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512490" href="https://news.ycombinator.com/vote?id=38512490&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Considering I was (unknowingly) very obviously infringing their trademark (X for MySQL was OK, MySQL-X was not), yeah, I felt the whole thing was handled in a good way.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511760"><td></td></tr>
                <tr id="38511804"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511804" href="https://news.ycombinator.com/vote?id=38511804&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Thanks!<p>In 2009 I joined Percona and saw that, by then, it was better for me to contribute to other open source projects in the MySQL ecosystem than to continue trying to get highbase caught up with things like mysql-mmm.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511695"><td></td></tr>
                <tr id="38512332"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512332" href="https://news.ycombinator.com/vote?id=38512332&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Having done a large scale MySQL deployment (700+ servers), I still find the HA landscape in MySQL land pretty sad. It's all very manual, nad it's very easy to screw up failovers. Even with Vitesse or Orchestrator or semi-sync ...</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512474"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512474" href="https://news.ycombinator.com/vote?id=38512474&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Oh, definitely, I meant things better than my project had become available. MySQL still has a long way to go in terms of friendly HA, and I’m not sure it will ever get to the level of something like cockroachdb. There’s plenty of room for improvements in that area, just not through something like what I was doing (mostly shell scripts).</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38511649"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511649" href="https://news.ycombinator.com/vote?id=38511649&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>A long time ago sonos didn't support apple airplay.<p>I did some protocol reversing and wrote a small program that pretended to be an airplay speaker to pipe audio to a sonos speaker (archive: <a href="https://github.com/stephen/airsonos">https://github.com/stephen/airsonos</a>)</p><p>I ended up getting recruiting messages from both the airplay team at apple and some folks from sonos. I didn't end up taking either offer, but it was also an interesting talking point when interviewing for the job I did take.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512408"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512408" href="https://news.ycombinator.com/vote?id=38512408&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I remember seeing this published when I worked at Sonos. In fact, I might have been the one who put it on the Slack channel.<p>It was a cool project at a time when a lot of people were saying it was insurmountable to make us AirPlay compatible.</p><p>Sorry you didn’t get the job. I hope you didn’t lose much sleep over it. I left in 2020. I wouldn’t say you’re missing much any more.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511689"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511689" href="https://news.ycombinator.com/vote?id=38511689&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; I did some protocol reversing<p>This would make for an interesting blog post.</p><p>Could you recommended resources to learn to do the same?
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512117"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512117" href="https://news.ycombinator.com/vote?id=38512117&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Step 1 — study popular protocols to understand how client/server interactions typically work.<p>Step 2 — deploy the network appliance in question to your LAN and intercept its packets with wireshark.</p><p>Step 3 — begin inference of protocol from observed behavior and test hypothesis by sending hand-crafted payloads to the server in question.</p><p>Step 4 — rinse and repeat until assumptions are proven to be correct with a high degree of reliability.</p><p>A good way to ensure you’ve captured the major parts of the protocol is to record about 72 hours of traffic and then replay it through a proxy that directs traffic to your newly created service.</p><p>If you can interpret the vast majority of the messages without error, you’re getting close to a reliable implementation.</p><p>Step 5 — use this strategy to develop a deep understanding of both protocols in question.</p><p>Step 6 — write an “adapter” that can translate protocol A to protocol B and vice versa.</p><p>Step 7 — implement the adapter towards whatever use case you have in mind.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                      <tr id="38511845"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511845" href="https://news.ycombinator.com/vote?id=38511845&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I actually forgot that I did in fact write about this! <a href="https://medium.com/@stephencwan/hacking-airplay-into-sonos-93a41a1fcfbb" rel="nofollow noreferrer">https://medium.com/@stephencwan/hacking-airplay-into-sonos-9...</a><p>A bit light on the technical details perhaps, but I recall getting stuck on getting the right airplay parameters, learning how byte endianness works... happy to try to answer any other questions as best I can remember.</p><p>EDIT: Sorry, I realized that I didn't actually answer the other question. I first got interested in reversing from console hacking, specifically this talk about wii hacking: <a href="https://youtu.be/0rjaiNIc4W8" rel="nofollow noreferrer">https://youtu.be/0rjaiNIc4W8</a> (including marcan of asahi linux fame!). Their group also had more writing at: <a href="https://fail0verflow.com/blog/" rel="nofollow noreferrer">https://fail0verflow.com/blog/</a>. Also interesting to read about mgba emulator development: <a href="https://mgba.io/tag/debugging/" rel="nofollow noreferrer">https://mgba.io/tag/debugging/</a>, v8 internals: <a href="https://mrale.ph/" rel="nofollow noreferrer">https://mrale.ph</a>, react internals: <a href="https://overreacted.io/" rel="nofollow noreferrer">https://overreacted.io/</a></p><p>Consuming a lot of literature on how different systems work helped me develop intuitions around how you might take something apart. Then it's a matter of trying things and banging your head against the wall a lot, e.g. at some point I was interested in how compilers worked so I tried hacking typescript syntax support into babel (circa 2017 maybe) - I got pretty far! and got a lot better sense of how compilers work.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511876"><td></td></tr>
                <tr id="38511918"><td></td></tr>
                        <tr id="38511832"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511832" href="https://news.ycombinator.com/vote?id=38511832&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>So, respective teams from those two companies (or even other companies for that matter) are actively searching GH for any mods to their work?</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38511924"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511924" href="https://news.ycombinator.com/vote?id=38511924&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>More likely is employees use their own products and happen to see it while searching for a way to do the same thing.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511923"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511923" href="https://news.ycombinator.com/vote?id=38511923&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>In my experience it's more like people happen to stumble across your work or hear about it somehow, not a systematic search for people working on X thing.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511756"><td></td></tr>
            <tr id="38511827"><td></td></tr>
            <tr id="38511996"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511996" href="https://news.ycombinator.com/vote?id=38511996&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>You didn't miss out because Sonos continues to do an awful job software-wise. One of the things I'm most looking forward to as I de-IOT-ize my life is selling that system and running speaker wire like a true G.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512036"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512036" href="https://news.ycombinator.com/vote?id=38512036&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Sorry but this sounds like LARP, who the hell wouldnt jump on a job offer from apple? Even if it doesnt work out, having Apple on your resume wouldve been an insane career booster, telling people you got an offer from them but didnt take it sounds very unbelievable, atleast personally, I wouldnt have believed you</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512160"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512160" href="https://news.ycombinator.com/vote?id=38512160&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I am genuinely unsure if this is a parody comment. I am assuming that you are fairly green behind the ears? The thing about Big Tech companies is that they hire lots of developers. That’s in large part makes them Big Tech. “Having Apple on your CV” is not as prestigious as you’re making out. It doesn’t mean you have The Knowledge that makes you a ‘10x developer’ or whatever anywhere you work. In fact, it could mean that your mind has been poisoned by a Big Tech working style, and you’ve developed a bunch of habits that aren’t nearly as applicable to most other organisations.<p>I say this as someone that’s never worked for any tech company anybody has heard of, nor any hip SV startup.</p><p>It takes a particular sort of person to thrive in Big Tech. That isn’t just code for ‘really really really good’. It sounds like you still believe that it is. Plenty of ‘really really really good’ people wouldn’t do well at Apple, and plenty wouldn’t want to work there. I wouldn’t necessarily call myself ‘really really really good’, but I know that I don’t want to work at Apple. Not because I think I’m not good enough, not because k don’t think that I could keep up, and not because I don’t like their output as a company.</p><p>Putting companies in a pedestal the way that you are is ultimately damaging for the industry. It fosters the increasingly cringey “get a job at FAANG!!!” culture. I’m sick of my YouTube recommendations being poisoned with “here’s how you pass a system design interview at Google” BS. I implore you to stop putting companies on a pedestal. You need only look at accountants talking about working at the ‘big 4’ to see how utterly ridiculous it can get.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512263"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512263" href="https://news.ycombinator.com/vote?id=38512263&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>From a developers perspective youre right, most of us here probably wouldnt be able to keep up with the amount of work it takes to thrive at apple, sure. Im looking at it from a future employers view, who sees "Apple", has an iPhone, and immediately has an idea in his head about what kind of developer you are, even if its completely inaccurate- Its all marketing. But also, immediately assuming youre not gonna make it at Apple because of what you heard about their work culture alone sounds like a quitter mindset. I mean at least try. If its not right, good riddance. Its not like having been there is gonna cost anything besides the time you invested.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512390"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38512390" href="https://news.ycombinator.com/vote?id=38512390&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Apple recruiters have the professionalism and organizational skills of a shady manual labor staffing firm. 5 1-hour rounds, low-balled, and treated with what felt like an ad-hoc process. Wasn't impressed with the people, nor the caliber of engineering talent.<p>The same is true of Microsoft (Azure specifically), Google, and Amazon.</p><p>Only two "traditional" big tech companies of any note for having sharp people and all-around good vibes are Meta and Netflix. Otherwise, I'd rather go with a unicorn like Snowflake or Databricks, which feels more what software engineering was like in the aughts: exploratory, pioneering, actually building things that people haven't before, rather than gluing stuff together or being drowned in the machinations of some incompetent director.</p><p>I wouldn't make it at Apple, because I would get pissed off and quit. There's more to life than money. I don't want to work with people that see "FAANG" (or use "staffed by ex-FAANG" in their recruiting pitch) and think it's a good signal to be presenting.</p><p>Putting in a stint at any of these lower end tech companies would cost me intangibles that I'm not willing to give up at this stage of my life. Namely, my sanity, spiritual well-being, and fulfillment with life.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38512059"><td></td></tr>
                <tr id="38512151"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512151" href="https://news.ycombinator.com/vote?id=38512151&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Interesting projection, but to respond to your point: anyone could just put in a decade at Averagecorp inc. or even just hop around and throw together a decent resume. If a random OSS side project lands you an offer from apple thats gotta be jackpot level luck.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512058"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512058" href="https://news.ycombinator.com/vote?id=38512058&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; who the hell wouldnt jump on a job offer from apple?<p>Lots of people, including me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512153"><td></td></tr>
                <tr id="38512295"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38512295" href="https://news.ycombinator.com/vote?id=38512295&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not everyone shares your goals or values.<p>I've used Apple products for years and generally like them a lot as a company, but I have no interest in working for them or any other large US tech company.</p><p>The money is good, of course, but the quality of life sacrifices aren't worth it (for me).</p><p>That's not contrarianism. That's understanding what matters to me.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512344"><td></td></tr>
                  <tr id="38512350"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38512350" href="https://news.ycombinator.com/vote?id=38512350&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Would you say the majority of people who claim to be contrarian aren’t actual contrarians, in your experience? I’m not sure you can infer this in general.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512370"><td></td></tr>
                        <tr id="38512076"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512076" href="https://news.ycombinator.com/vote?id=38512076&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Not everyone is willing to uproot their life on a whim, even for a theoretically great job and a theoretically great company.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512181"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512181" href="https://news.ycombinator.com/vote?id=38512181&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Im sure "uproot your life and dedicate it to Apple" isnt on the job description and apple is very flexible with this stuff. You think all 164,000 apple employees live in silicon valley?</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38512468"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512468" href="https://news.ycombinator.com/vote?id=38512468&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I made a hobby of writing intro posts on deep technical topics, from DNS to concurrency to cutting cloud cost. From 2009 ish onwards all my gigs have been at least helped if not initiated by someone reading a post and saying "we should talk to this guy".<p>Not a magic spell. I had been writing for almost ten years prior before anyone noticed, and only a fraction get any play.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512478"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512478" href="https://news.ycombinator.com/vote?id=38512478&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I made and maintained a geo-based chat app for a friend/client (<a href="https://hihey.org/" rel="nofollow noreferrer">https://hihey.org</a>, though they took it offline for now I believe). I used Matrix as the basis for it and started putting that on my resumes after finding it fun to work with and experience.<p>I got a couple of reach outs based on having that keyword on my profile alone on YC's job board and on LinkedIn that led to some paid consulting.</p><p>Not as life changing as some of the other answers but I'm amazed when this sort of thing even happens
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512463"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512463" href="https://news.ycombinator.com/vote?id=38512463&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I stopped maintaining a popular JavaScript beautifier/diff/analysis tool 4 years ago that won me several jobs.<p>Since then I have been working on a file streaming application.  Its side items in that project that have been winning me jobs lately, primarily anything to do with full duplex socket streaming and browser test automation.</p><p>As a JavaScript developer took me months this year how to sell my experience and skills from my side projects.  As a JavaScript/TypeScript developer you can do the same shit everybody else does, which is put text on screen using a giant framework.  If that is the kind of employment you are looking for be prepared to degrade yourself to working with newbs that have high insecurity, low self-esteem, and spend all their time talking about how awesome they are.  Its all marketing all the time, no original application code, and outsourcing everything to some external tool.  As a developer you are a commodity product to hire/fire just like public is to social media.  This line of work no longer interested me, so I spent months unemployed figuring this out.</p><p>Instead your alternative as a JavaScript/TypeScript developer is niche skills, which is in higher demand than it sounds.  It seems almost nobody can figure out test automation in the browser.  Having application architecture skills is a huge plus, which typically means Java/C# and HTTP session management with something like Spring, but if you can demonstrate a more generalized approach to application architecture you have a skill that you can adapt to a bunch of different things.  It also helps having things like a security clearance and security certifications.  There are a huge number of cleared developer jobs that recruiters cannot fill.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511616"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511616" href="https://news.ycombinator.com/vote?id=38511616&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Well, a very long time ago, in a company funded far far away (and since defeated by the empire), I had the "joy" of working with Sendmail.  For you youngsters, back then, back when we had dial telephones (tell us more Grandpa!), there were multiple "mail networks", not just this fancy Internet you kids have.  Sendmail was a mail processor that could not only arrange to send and receive mail, but it could translate addressing between the different networks (ARPA, Bitnet, CSNET, UUCP, etc.)  The problem was, reading a sendmail config file was something like reading assembly code except you weren't allowed to by vowels.  It was nearly all symbols -- executable line noise.  
I got tired of working with it - so I wrote my own sendmail compiler/de-compiler of sorts just to work in English prose.  Got me my job at Sun.
These days, I'm not sure if it will let me keep my job, or be the justification for my losing it, but I'm working on a programming language for teens called Onyx (after my grandson, who has NO interest in this as he's intending to a be a pilot, but it means unless she works for Boeing, I'm safe for a few more years</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38511738"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511738" href="https://news.ycombinator.com/vote?id=38511738&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I used to work at Sendmail, it was my first job.  The entire premise of the company was "Sendmail is so hard to use, let us run it for you".  We had software that added a GUI for configuration and management, and Pro Services to set up big installs.<p>But also we had all the top maintainers of Sendmail.  And we ran Sendmail for our corp mail.</p><p>Once we had a problem with the network, so we had to reroute corporate mail over a phone line.  One of the maintainers came down, typed what looked like line noise for five minutes, and all of a sudden all the mail was working again.</p><p>It was crazy to watch him basically read and write raw Sendmail configs.  He didn't even use m4.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511732"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511732" href="https://news.ycombinator.com/vote?id=38511732&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not directly related, but I'm working on some short stories inspired by some of the hacker/cyberpunk literature from the 80's and since I grew up and learned programming in the late 90's early 2000's, I feel completely inadequate at writing cheesy hacker stories.<p>Keep them old timer stories a' comin'.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511656"><td></td></tr>
                  <tr id="38512047"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512047" href="https://news.ycombinator.com/vote?id=38512047&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I built <a href="https://foragoodstrftime.com/" rel="nofollow noreferrer">https://foragoodstrftime.com</a> ~10 years ago as I was sick of reading the docs for date formatting.<p>It generally gets around 1000 users a day.</p><p>Over the years, it's gotten me consulting gigs and the occasional job offer (amidst other projects).</p><p>Today, it sends a decent chunk of the traffic and sign-ups to my startup, Wafris -&gt; <a href="https://wafris.org/" rel="nofollow noreferrer">https://wafris.org</a></p><p>OP's asking for a strategy with these, and the advice I'd offer is to treat them like assets. You make these various side projects to learn something, take the extra 20% of time to package it up buy a domain, and spend $10 on a logo or something to make it a little more like a project and not just a repo.</p><p>If it's not something directly usable like this, take some screenshots and collect them into a gallery on a personal site.</p><p>You stack these assets over time (and like my example above), they pay off over years in all sorts of ways.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511593"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511593" href="https://news.ycombinator.com/vote?id=38511593&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My blog <a href="https://xeiaso.net/" rel="nofollow noreferrer">https://xeiaso.net</a> (source code: <a href="https://github.com/Xe/site">https://github.com/Xe/site</a>) and the stuff I've written for it ended up doing several things to help me get employed over the years:<p>1. Letting me have a place to write to get better at writing, which makes it easier to do my job in DevRel.</p><p>2. Lets me talk about all of the interesting projects I work on (eg: an AI novel writing experiment <a href="https://xeiaso.net/videos/2023/ai-hackathon/" rel="nofollow noreferrer">https://xeiaso.net/videos/2023/ai-hackathon/</a>) that people regularly find interesting. This gets people interested in wanting to employ me, which ends up working up well for me in the long run.</p><p>Do side projects, but write about what you did and what you learned.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511627"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511627" href="https://news.ycombinator.com/vote?id=38511627&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I've heard from many that writing can help build credibility for hiring purposes. I have committed myself to writing at least something on all future projects because of this. Thanks for the tip.<p>p.s your use of "Technophilosopher" and "chaos magician" to describe yourself is incredible
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512013"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512013" href="https://news.ycombinator.com/vote?id=38512013&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I have gotten very good engagement of my blog content as I write for fun sometimes<p>I got to learn a lot of from folks who read my Content.</p><p>Also if you don’t mind me asking</p><p>How can a blog aid in finding or landing a job
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512081"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38512081" href="https://news.ycombinator.com/vote?id=38512081&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Become an expert in a thing, companies that need expertise in that thing will come knocking.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512097"><td></td></tr>
                        <tr id="38511963"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511963" href="https://news.ycombinator.com/vote?id=38511963&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I've been meaning to write a longer rant about this, but I'm not an engineer. I'm a glorified product designer and marketer.<p>Also every title is made up. Some are more made up than others.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38512488"><td></td></tr>
            <tr id="38511984"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511984" href="https://news.ycombinator.com/vote?id=38511984&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I was one of the first backers of the Oculus Rift Kickstarter. When I got it I decided eye tracking was going to be huge for VR, so as a side project I cut a hole in my Rift and built my own eye tracker. I posted it on Hacker News: <a href="https://news.ycombinator.com/item?id=7876471">https://news.ycombinator.com/item?id=7876471</a><p>A few days later the CTO of a small eye tracking startup gave me a call. I quit Google and joined them. I built a (novel at the time) deep neural net based VR eye tracking system for them, and less than two years later Google acquired us.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512062"><td></td></tr>
                <tr id="38512228"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512228" href="https://news.ycombinator.com/vote?id=38512228&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>That's nothing, the Silicon Valley part is what happened after the acquisition. Google was so paranoid about "user data" that they forced us to delete every scrap of our training datasets, going as far as physically shredding any laptop that had contained the data. We had a memorable evening at the office with the onsite shredder truck. It couldn't shred the MacBooks due to the aluminum case and we ended up smashing them with hammers in the parking lot.<p>When we got to Google of course privacy concerns blocked new data collection until we completed an overengineered project to build a shiny new database with access controls and stuff. About a year later with no technology progress to speak of, the whole eye tracking project was shelved due to a strategy pivot from higher up (unrelated to anything we were doing) and we all went our separate ways. Fun times!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38511495"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511495" href="https://news.ycombinator.com/vote?id=38511495&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not a side project, per say, but I answered questions on my local Linux User Group almost daily. After applying for a job and not hearing back, I got a request to come in for an interview weeks afterwards. Long story short, the boss told me he saw my responses on the mailing list and it turns out I knew more than the RHCEs and CCNAs walking into his interviews.<p>That landed me my first job ever in IT as a Junior NetEng and eventually a Linux SysAd.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512419"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38512419" href="https://news.ycombinator.com/vote?id=38512419&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; Not a side project, per say<p>I'd disagree with that. Community building is every bit as much work, and arguably often more impactful than just putting up yet another OSS repo on github.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511772"><td></td></tr>
                <tr id="38512200"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38512200" href="https://news.ycombinator.com/vote?id=38512200&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>SO’s … ‘strict’ rules are in part informed by perceived shortcomings in communities that proceeded it. So, imagine something more chaotic :)</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511815"><td></td></tr>
                        <tr id="38512070"><td></td></tr>
            <tr id="38512378"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512378" href="https://news.ycombinator.com/vote?id=38512378&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>I purchased Dell's original Project Sputnik XPS 13 to be my daily driver and was dismayed at how awful the touchpad was. I couldn't disable tap-to-click, palm detection was terrible, you get the idea. I fixed it so it was bearable to use, upstreamed my patches, and ultimately got a job at Canonical thanks to the connections I made in the process.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512238"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512238" href="https://news.ycombinator.com/vote?id=38512238&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>In 2003/2004, during my undergrad, I observed a recurring trend in the university's IT department. They struggled to retain Unix/Linux engineers for more than three months, primarily due to two reasons: the university's remote location (apparently engineers loved the city life) and the local telecom companies' at the time hired anyone who could type "ls" on a Linux shell. Recognizing an opportunity, I began self-studying FreeBSD and Linux, the operating systems used by the university for their internet services like DNS, email, and proxy servers. Before completing my degree, I applied for the sysadmin position at the uni. In the interviews, I was able to explain and answer even the hardest of questions. I was hired. I eventually went to "ls" elsewhere as well but this role, which I held for eight years, provided me with a foundational knowledge that I believe influences my career even to date!</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38512346"><td></td></tr>
                  <tr id="38512360"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512360" href="https://news.ycombinator.com/vote?id=38512360&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>It is unclear to me whether this "landed me a job", but in advance of working at big tech, I made a presentation about Smithy (www.smithy.rs), in which there was an engineer in the audience (employed at the same big tech co). I believe he lobbied for my candidacy with the hiring committee.<p>Secondly, before taking my most recent job (at Pinterest), I had just secured a conference talk about Isograph (<a href="https://www.youtube.com/watch?v=gO65JJRqjuc" rel="nofollow noreferrer">https://www.youtube.com/watch?v=gO65JJRqjuc</a>). At both companies where I eventually got offers, I spent a good amount of interview time nerding about Isograph with the interviewers.</p><p>Ultimately, it's unclear if this tipped the balance in any case, but the side projects seemed helpful.</p><p>----</p><p>Previously, while interviewing at a previous place, I showed off a side project to the interviewers, ran into a bug, and deployed a fix in real time. I was later told that they had never seen that. I think I would've gotten that job anyway, though.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512221"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512221" href="https://news.ycombinator.com/vote?id=38512221&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Back in around 2004-2005, I was doing contracting work in Australia for a big retailer, maintaining one of their monolithic webapps that was built using C++, believe it or not.  At that time, Ruby on Rails was the new hotness, and I was trying to learn that on the side.<p>When MacOS released their "dashboard widgets" framework back around 2005ish, I wrote a widget for RubyDocs and released it, and it got quite popular.</p><p>At the same time, a US company I heard about via the Rails mailing list was investing pretty heavily in Rails and, as a long shot, I applied there and mentioned I made that widget.  It turns out they were all using it, and they basically gave me a job on the spot working remotely from Australia.</p><p>The experience I got in that job led me to get an job at Microsoft in 2007, and they moved me and my family to Seattle, where I still live to this day, though I left MS over five years ago now.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511598"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511598" href="https://news.ycombinator.com/vote?id=38511598&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not really a side project, but I used to be a lot more active on stackoverflow. A recruiter reached out to me through the job board that stackexchange used to host. Been with the job for about 5 years now.<p>Pretty lame that they discontinued that job board. It was a lot nicer experience than using linkedin.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511628"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511628" href="https://news.ycombinator.com/vote?id=38511628&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; Pretty lame that they discontinued that job board.<p>I used to hire people straight off of SO. Sometimes skipping the usual process of they has solid answers to the types of questions we’s ask - went straight for culture fit.</p><p>I think instead of blaming ai and other esoteric reasons for SO’a downfall leadership should look into the damage cancelling the job board has done. People helping others at least had the incentive of being given a job. Now there’s no point really.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511954"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511954" href="https://news.ycombinator.com/vote?id=38511954&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I still like to help people regardless of if it will directly benefit me. It was just a nice perk.<p>Although, since they made all of these controversial changes, it feels less like helping people and more like doing free work for a random company.</p><p>The real killer for me was limiting the data dumps to paying customers. They really let down the community who trusted SO would be a trustworthy steward of the data. The charm of the site is gone.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511929"><td></td></tr>
                  <tr id="38511426"><td></td></tr>
            <tr id="38512363"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512363" href="https://news.ycombinator.com/vote?id=38512363&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I was active in various areas of OpenSolaris, contributing to design discussions, code, and code review. Most of this was in the intersection of zones, installation, and zfs. Some were just scratching an itch, like “manwhich”.<p><a href="https://www.illumos.org/opensolaris/ARChive/PSARC/2007/688/mail" rel="nofollow noreferrer">https://www.illumos.org/opensolaris/ARChive/PSARC/2007/688/m...</a></p><p>Once Oracle acquired Sun and hiring started, I was hired into the zones team. While interviewing I discussed my ongoing work on zfs dataset aliasing to virtualize the zfs dataset hierarchy in zones. After being hired I was able to get this feature prioritized to make it into Solaris 11.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512053"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512053" href="https://news.ycombinator.com/vote?id=38512053&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>In 1999 my friend's band wanted to sell their music online and so I looked at the new Microsoft DRM that had just been released (don't kill me!) and set up a test web page. I ended up getting an interview (and a job) with a company that Peter Gabriel had just started as I was practically the only person in the country that had even looked at the SDK.<p>PG gave us an opening to every record label ("Hi, Peter Gabriel would like to come visit and show you something...") where we'd show them we could sell their music legally online. Five minutes after PG leaves each building a team from Apple would show up and show off what <i>they</i> were building too. Their meetings were much shorter as we always did all the heavy lifting first. (Note, we always had to use our own equipment because the MS stuff worked way better on Windows, but all the record labels were like 99% Mac).</p><p>On another one.. it wasn't a side project, but I "hacked" a competition on a popular TV show's web site and they ended up hiring me as the co-presenter o_O
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511532"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511532" href="https://news.ycombinator.com/vote?id=38511532&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I started <a href="https://github.com/thbar/kiba#kiba-etl">https://github.com/thbar/kiba#kiba-etl</a> to scratch my own itch &amp; be able to write properly structured ETL jobs in Ruby. It was a blank-slate rewrite of something larger (activewarehouse-etl) which I could not maintain anymore.<p>This landed me not strictly a job, but long term consulting gigs with a number of companies in EU, UK &amp; US.</p><p>The job was directly related to the project: companies wanted the expertise of data engineering &amp; ETL, often with Kiba directly, but also in general.</p><p>This "side project" was totally worth it :-)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512167"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512167" href="https://news.ycombinator.com/vote?id=38512167&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I have worked four jobs related to <a href="https://github.com/pion/webrtc">https://github.com/pion/webrtc</a> and one for <a href="https://webrtcforthecurious.com/" rel="nofollow noreferrer">https://webrtcforthecurious.com</a><p>* Amazon was using WebRTC, didn’t care about Pion</p><p>* Apple was the same. Just cared about my knowledge of WebRTC</p><p>* Twitch I joined because they use Pion</p><p>* LiveKit uses Pion and is very open about it!</p><p>Side projects/Open Source has been so beneficial for my career I can’t recommend it enough. It also frees you from defining your career by your employer.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511499"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511499" href="https://news.ycombinator.com/vote?id=38511499&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>This game I made and released on iPhone way back in the day directly led to me getting my first full-time job making mobile apps for a startup as the Lead Developer. I showed it during my interview.<p>It's no longer on the App Store as there's just been too many big changes I couldn't keep up with on that codebase. I'm working on a followup right now for Steam that I'd like to port to mobile afterwards.</p><p>Gameplay video: <a href="https://youtu.be/uy08ohBLGhE" rel="nofollow noreferrer">https://youtu.be/uy08ohBLGhE</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511629"><td></td></tr>
                <tr id="38511671"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511671" href="https://news.ycombinator.com/vote?id=38511671&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Hey quick question, how do I get a job at Amazon? ;) jk<p>I love "A job is not everything in someone’s life, but it’s very, very important to love your job." from your article. After a couple burnouts over a decade in this industry, I truly seek positions I at least <i>think</i> I'll love.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38512159"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512159" href="https://news.ycombinator.com/vote?id=38512159&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Earlier this year I went to the Australian F1 GP. Between qualifying on Saturday and the race on Sunday I built an integration between a live timing API and Telegram to send me position updates every minute with lap times.<p>This was because anywhere near a screen was packed with crowds and my mobile network couldn’t keep up using the official app.</p><p>I was job searching and wrote it up and posted to LinkedIn. My now manager saw it and was trying to hire for a role building integrations. My project was enough for him to reach out and set up a chat. Without the project we wouldn’t have connected.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512217"><td></td></tr>
                  <tr id="38511432"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511432" href="https://news.ycombinator.com/vote?id=38511432&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span><a href="https://git.gavinhoward.com/gavin/bc" rel="nofollow noreferrer">https://git.gavinhoward.com/gavin/bc</a><p>It got me a C programming job that had nothing to do with the side project.</p><p>I would say that it only helped me in the interview process, but it did so in two ways:</p><p>* I could actually answer C-related questions on top of the more generic questions.</p><p>* It showed that I had skill in C.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512410"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512410" href="https://news.ycombinator.com/vote?id=38512410&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My business partner and I built AsUnit in ~2004. [0]<p>The first fully functional Unit Test framework for ActionScript. It was great fun and helped get my career off the ground.</p><p>[0] <a href="https://asunit.org/" rel="nofollow noreferrer">https://asunit.org</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512261"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512261" href="https://news.ycombinator.com/vote?id=38512261&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>This has happened a few times to me.<p>First was some downhill skateboarding projects - a bushing recommendation system and a site that allowed me to search all NZ skate shops from one place.</p><p>A popular US skate shop posted on Reddit looking for interns, but they weren’t interested in  hiring so remotely.</p><p>Fast forward a week and the CTO got in touch to say that he’d interviewed a bunch of dud candidates, and meanwhile had been watching me commit exactly the code they were looking for.</p><p>Ended up contracting with them for a bit building an internal equivalent of the search tool, as well as bushing recommendations integrated with their listings.</p><p>The next is my work in the Cycle.js community (niche FRP JS framework). Mostly worked on trendy dev tools, but also did some valuable work on improving the speed, reliability and clarity of async UI tests that is still arguably close to best-in-class for JS.</p><p>That resulted in multiple job offers and an approach from Manning for a possible book deal, but none of it was that good of a fit.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511424"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511424" href="https://news.ycombinator.com/vote?id=38511424&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Working on cubesat club for my university. Helped me get 2nd round internship interview @ Mr. Beast studios. not sure if this counts since internship + haven't got job yet, but I think it played a big role in helping me advance.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38512246"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512246" href="https://news.ycombinator.com/vote?id=38512246&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>My first job was at a hydroponics store. I wanted to grow some fresh fruit in my basement over the winter, and wanted to build the system rather than buying an out-of-the-box one. I asked the owner a few questions about building a system, and got some advice from him. When I came back the second time to get more materials, I was offered a job.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511678"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511678" href="https://news.ycombinator.com/vote?id=38511678&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My contributions to SerenityOS[0] helped me get my current job. My team lead (who was also my interviewer) was interested in what I did since I listed some of it in my CV, and I showed him some PRs I made and explained what went into each of them. It was really exciting because I didn't have professional experience with low-level development, and basically got the job due to hobby programming.<p>[0]: <a href="https://github.com/SerenityOS/serenity/pulls?q=is%3Apr+author%3Asin-ack+is%3Aclosed">https://github.com/SerenityOS/serenity/pulls?q=is%3Apr+autho...</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512253"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512253" href="https://news.ycombinator.com/vote?id=38512253&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Way back when the Nintendo Wii was brand new and hard to find, I wrote a script to scrape Target.com for store inventory and notify me if a nearby store restocked. A few years after that I revamped it to check on inventory for newly released iPad models. I put the code up on GitHub [1] and the CTO for a company that had large-scale store inventory checking as part of their product emailed me out of the blue after seeing my repository. A little while later, I replied back, interviewed and got a pretty good job offer out of it. I wound up not taking the offer, but in hindsight I probably should have.<p>[1] <a href="https://github.com/polpo/ipad-target.py">https://github.com/polpo/ipad-target.py</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512405"><td></td></tr>
                  <tr id="38512243"><td></td></tr>
            <tr id="38511799"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511799" href="https://news.ycombinator.com/vote?id=38511799&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>20 years ago, I was a college kid who built a running log website as an alternative to keeping paper records. My college cross-country team lived all over the country, so this let us keep each other accountable during summer training. It was fairly early in the Internet, before GPS watches and not many runners had heart rate straps. It got featured in Women's Health and Runners' World (UK edition) magazines.<p>When I interviewed at Microsoft my senior year, this gave me a ton to talk about. It was real experience building a product and having customers. I could answer questions with something real and different than the other candidates. I know I bombed two of my interviews, but I ended up doing 7 interviews on the day and getting an offer.</p><p>The website is still around, but I haven't done anything to it other than delete the production log that fills up the server disk occasionally in the last 15 years. I don't know why anyone uses it, there are much better options. I still run and I certainly don't use it. But the server bills are cheap, so it lives on.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512415"><td></td></tr>
            <tr id="38511441"><td></td></tr>
                <tr id="38511838"><td></td></tr>
                  <tr id="38511703"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511703" href="https://news.ycombinator.com/vote?id=38511703&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>A few years ago I got fed up with then-popular JavaScript linter, JSLint, and forked it to make JSHint. I wouldn't say JSHint was the only criteria that landed me the job but it definitely help when interviewing for positions where JavaScript was important. At the very least, it put my name thru the first filter both at Mozilla and then at Medium.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511666"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511666" href="https://news.ycombinator.com/vote?id=38511666&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My side project NumPad <a href="https://numpad.io/" rel="nofollow noreferrer">https://numpad.io</a> got me my current job at Decipad <a href="https://www.decipad.com/" rel="nofollow noreferrer">https://www.decipad.com/</a> (the similar naming scheme is a coincidence!).<p>I came across Decipad while looking for a job, and messaged the founder, highlighting my work on NumPad. They were impressed enough that the hiring process ended up being just a few interviews, I've been there for almost a year now, and it's been pretty good!</p><p>If there's a moral to this story I think it's that you should aim for work that's highly relevant to your side project experience. In my case both NumPad and Decipad have a sort of programming language that can do calculations with units.</p><p>But ignore this advice if you can't find that work, or it doesn't seem good for whatever reason. You can still highlight your side project in an application, and they might be impressed anyway.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511692"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511692" href="https://news.ycombinator.com/vote?id=38511692&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>It's funny you say this. After struggling to find work (but mostly to find meaningful work), I've committed myself to pursuing jobs related to my curiosities/interests. I didn't really do that before. Over time, I've started to narrow down based off of what I'm genuinely interested in. That way I don't have to lie when I say I'm "passionate" about something I'm working on. :-)</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38511967"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38511967" href="https://news.ycombinator.com/vote?id=38511967&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>&gt; I've started to narrow down based off of what I'm genuinely interested in.<p>How do you do that if you’re past work is disconnected from what you’re interested in.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                        <tr id="38512154"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512154" href="https://news.ycombinator.com/vote?id=38512154&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Maybe it didn't land me a job on its own but it helped in the interview process. I wrote a limited Slay the Spire rules engine[0]. If I could do it again I wouldn't choose PHP, but my current job had an interview round where I walked the hiring manager through something I've written and it did a great job of showcasing a variety of things like writing testable code, separating concerns, making an extensible framework in which to easily implement new cards, etc.<p>In some ways the backend at my current job is slowly coming to resemble some of the patterns I used here, funnily enough.</p><p>[0]: <a href="https://github.com/dgunay/slay">https://github.com/dgunay/slay</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512183"><td></td></tr>
                  <tr id="38512421"><td></td></tr>
            <tr id="38511630"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511630" href="https://news.ycombinator.com/vote?id=38511630&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Not really a side project as I was trying to get traction on my ideas at my former employer.<p>I do contract work for a pretty niche industry and after you've done a couple big implementation projects, you've seen 80-90% of all user stories, integrations and edge cases.</p><p>I started a side project that was a combination of tooling, processes, checklists and methodology to stop reimplementing the same project work and stop approaching every client like it was greenfield work. Not fully productizing our approach but moving in that direction.</p><p>My company was not interested. During an interview I pitched my side project ideas and they immediately said they wanted to hire me. Skipped the rest of the hiring process and landed a new role doing exactly what I had wanted to do at my previous company.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511814"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511814" href="https://news.ycombinator.com/vote?id=38511814&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>did you consider making your own company? sounds like a prime opportunity.<p>looking to do the same, would appreciate any insight
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511676"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511676" href="https://news.ycombinator.com/vote?id=38511676&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>At a previous job, my interview was mostly me discussing my side project (and having given some folks on the team my testflight). I had a lot more prepared to talk about previous work projects but it wasn't needed. For context this was for a product design role, but I also built the backend and iOS app.<p>This was the side project that I ended up writing about in more detail later on: <a href="https://paulstamatiou.com/stocketa/" rel="nofollow noreferrer">https://paulstamatiou.com/stocketa/</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512265"><td></td></tr>
            <tr id="38511599"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511599" href="https://news.ycombinator.com/vote?id=38511599&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>My most recent post about my side project [0] got me some freelancing work as well as an internship for this summer. Project was related to both of them! Unbelievably grateful for the opportunities it’s given me.<p>I’ve got thoughts about the ability for side projects to directly demonstrate not just proficiency, but passion, which is very important in undergrad when looking for opportunities. Might end up writing a blog post about it.</p><p>[0]: <a href="https://news.ycombinator.com/item?id=38252566">https://news.ycombinator.com/item?id=38252566</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511733"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511733" href="https://news.ycombinator.com/vote?id=38511733&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>After discovering Erlang (thanks, Bruce Tate) I started following the community on Twitter and elsewhere, then created the Twitter account ErlangInfo to share news and resources about the language.<p>Because I was following multiple Erlang-related accounts I saw that Basho was hiring a tech evangelist in my region, and while I doubt there was a lot of competition for the role, my side “gig” as ErlangInfo at least didn’t hurt my chances.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38512267"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38512267" href="https://news.ycombinator.com/vote?id=38512267&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Recently someone reached out because of simdjzon, but I didn't write it, I just made some usage-driven changes and the actual author made me the maintainer on github xd</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511993"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511993" href="https://news.ycombinator.com/vote?id=38511993&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>A long time ago I built a business app for the company to replace our existing.  I first ran it in parallel and then had my boss do the same. They loved it and it went into production.<p>Later I applied for a job and all the work I did, backend and frontend and support and database and migrations and reports and visualizations showed my future employer that I knew every stage of work suddenly finding myself moving them into devops.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511648"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511648" href="https://news.ycombinator.com/vote?id=38511648&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>My AI sandbox game <a href="https://www.chesscraft.ca/" rel="nofollow noreferrer">https://www.chesscraft.ca</a> helped me get a great transfer within government to an AI prototyping team at Environment Canada. The job is a bit of a unicorn because it's full remote with tons of freedom.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511724"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511724" href="https://news.ycombinator.com/vote?id=38511724&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Another item (HN won't let me post a long reply), is a programming environment called Onyx.  (After my grandson in Africa, who has NO interest in it whatsoever as he intends to be a pilot -- but this is OK as, unless she works for Airbus, we're ignoring the ladies for a few more years. Sosongo Abasi as his father would say!)  Onyx is a language designed for 13-17 year olds who may not have the best command of English -- we can work in the language of the Igbo, the Yoruba and Erik.  Doesn't matter to my parser.  And it will all be free, documented, Github'ed and built with free tools.  Education is hard over there..</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511715"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511715" href="https://news.ycombinator.com/vote?id=38511715&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I have only worked for two companies so far. I got both jobs through my side projects. The first job was my apprenticeship. The second was with a Swiss sensor developer.<p>[0] The first was a Minecraft server software with a web interface similar to an operating system. Players could log in, upload items, xp and trade etc.</p><p>[1] The second was a note-taking app similar to Obsidian, but completely real-time, based on a CRDT (yjs)</p><p>[0] <a href="https://github.com/iojanis/creaftOS">https://github.com/iojanis/creaftOS</a>
[1] <a href="https://lity.cc/" rel="nofollow noreferrer">https://lity.cc</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511781"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511781" href="https://news.ycombinator.com/vote?id=38511781&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>During my physics PhD I built my own Segway (and a second one with a power tool company who came to me after first asking tlb) and did a bunch of projects with a high-power laser cutter that I got funding for in our lab.  I included these on my resume and they were much easier for interviewers to talk to me about than my PhD work.  I think they also helped me stand out a bit.  Receiving positive feedback about these projects gave me confidence to sell myself as someone who could build things.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511784"><td></td></tr>
            <tr id="38511508"><td></td></tr>
            <tr id="38511553"><td></td></tr>
            <tr id="38511848"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511848" href="https://news.ycombinator.com/vote?id=38511848&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>For a few years I devstreamed on Twitch. I got one of my longest running freelance clients when he watched me integrate Django authentication into VueJS which was a part of a web based game I was making. The game didn't go anywhere but Django has been my primary focus for most of my career and that was what I did for the client!</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511910"><td></td></tr>
            <tr id="38511551"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511551" href="https://news.ycombinator.com/vote?id=38511551&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>I built an early HTML5 game engine in 2010 called CraftyJS when Facebook games were starting to become big. The project itself got me the job at a gaming startup and an offer at Zynga.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511864"><td></td></tr>
            <tr id="38511500"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511500" href="https://news.ycombinator.com/vote?id=38511500&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I’ve learned an unbelievable amount trying to systematically invest on my own.<p>All of what I have learned is levered in my career and I’ve utilized that knowledge during all interviews.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38511596"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511596" href="https://news.ycombinator.com/vote?id=38511596&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Care to elaborate? Never had the money to invest but have dabbled with some very basic auto trading algos. Long story short, before I learned any math related to gambling, I didn't understand why martingale can't work in gambling or investment. Now I do. :P</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38511805"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511805" href="https://news.ycombinator.com/vote?id=38511805&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>Even though I haven't used Perl professionally for about 6 years or so, my Perl FOSS work has driven pretty much my entire career. Starting in around 2000 or so, I started producing a lot of Perl modules (libraries). You can see what I've uploaded to CPAN at <a href="https://metacpan.org/author/DROLSKY" rel="nofollow noreferrer">https://metacpan.org/author/DROLSKY</a>.<p>Some of those libraries became _very_ widely used in the Perl community. The number one most used is probably DateTime (<a href="https://metacpan.org/dist/DateTime" rel="nofollow noreferrer">https://metacpan.org/dist/DateTime</a>), and number two is probably (<a href="https://metacpan.org/dist/Log-Dispatch" rel="nofollow noreferrer">https://metacpan.org/dist/Log-Dispatch</a>). But some of the others also got a lot uptake.</p><p>I also contributed a lot to libraries create by others, most notably HTML::Mason and Moose, both of which were very widely used in Perl.</p><p>All of that, plus speaking at the Perl conferences, really helped me develop my professional network. If I recall correctly, all three of of my most recent jobs came about because of my Perl connections to varying degrees. Two of them were just because I posted on my blog that I was looking for work and someone I knew through Perl reached out.</p><p>Today I work in Golang at MongoDB. In 2022, I again posted that I was looking for something new and someone I knew from Perl who worked at MongoDB reached out to me. I'm really thankful he did, because working there has been great!</p><p>Nowadays I don't do much Perl any more, though I still maintain many of my modules (bug fixes and small feature requests only, though). I've also done some Golang (<a href="https://github.com/houseabsolute?q=&amp;type=public&amp;language=go">https://github.com/houseabsolute?q=&amp;type=public&amp;language=go</a>) and Rust (<a href="https://crates.io/users/autarch" rel="nofollow noreferrer">https://crates.io/users/autarch</a>).</p><p>But I think it would be _much_ harder for a young person to do the same things I did. Nowadays there are just so many freaking programmers. Someone invents a new language and five minutes later there are a huge number of foundational libraries for it. By the time I started with Go (mid-2010s), pretty much all the stuff I had done in Perl already existed in Go. And I found the same to be true with Rust when I started using it after Go.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38511807"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511807" href="https://news.ycombinator.com/vote?id=38511807&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>Is a different millennium did a website advertising a "film" I made with school friends. Hand coded HTML with lots of pre-rendered 3d spinning logos. Total mess that would never have loaded on an average PC but 100% was all that got me my first job.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511507"><td></td></tr>
                <tr id="38511600"><td></td></tr>
            <tr id="38511943"><td></td></tr>
                  <tr id="38512094"><td></td></tr>
            <tr id="38511690"><td></td></tr>
            <tr id="38511962"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511962" href="https://news.ycombinator.com/vote?id=38511962&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>going way back: Science Fair in High School landed me summer internships that rolled over into my first job out of college. ("Science and Engineering Fair" project was building robots with microcontrollers) I think it was the proof that I could do that kind of work in a self directed way that made them notice me.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511740"><td></td></tr>
            <tr id="38511708"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511708" href="https://news.ycombinator.com/vote?id=38511708&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><br><div>
                  <p><span>For current job, when I started interviewing with them, I mentioned a side project relevant to their space. I didn't learn until a few interviews in that they had started to build basically the same project. Now, that's the project I have been working on exclusively for them.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38511626"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38511626" href="https://news.ycombinator.com/vote?id=38511626&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>I was planning to go into grad school for computational biology, but an early Square engineer saw me playing with the thing I'd built on the side of a Waffle House at 2 or 3 AM [1,2].<p>We exchanged numbers, and after six or so months of talking to me, they convinced me to join them instead. I got in early and had a really good exit. Completely changed the course of my life.</p><p>My other passion (apart from biology) was film. I've made a lot of indie films over the last decade, but I always focused on film tech - volumetric video, mocap, etc. I'm currently building a startup in that space that started as one of my side projects. We're doing really well!</p><p>Side projects have <i>always</i> led to inflection points in my life. They have more pull than anything else, and they lead me down interesting problem gradients.</p><p>I'll get back to biology one day. I have some ideas there, too.</p><p>[1] <a href="https://youtu.be/5XTi-jf-ans" rel="nofollow noreferrer">https://youtu.be/5XTi-jf-ans</a></p><p>[2] <a href="https://youtu.be/x034jVB1avs" rel="nofollow noreferrer">https://youtu.be/x034jVB1avs</a>
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38512164"><td></td></tr>
            <tr id="38511816"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38511816" href="https://news.ycombinator.com/vote?id=38511816&amp;how=up&amp;goto=item%3Fid%3D38511280"></a></center>    </td><td><p><span>This is cool. If it were written into some movie I’d accuse the writer of lazy writing. Kudos to you.<p>A similar coincidence happened to me early career. I had finished an internship, wasn’t sure what to do full time after, and ran into my old boss in a grocery store. He had been impressed with my internship work and seeing me reminded him of me and we started talking, soon enough he invited me to be employee #6 at his new venture. It worked out really well.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MakeMake: Generate make files from C source code (122 pts)]]></title>
            <link>https://github.com/quelsolaar/makemake</link>
            <guid>38511084</guid>
            <pubDate>Sun, 03 Dec 2023 21:45:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/quelsolaar/makemake">https://github.com/quelsolaar/makemake</a>, See on <a href="https://news.ycombinator.com/item?id=38511084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">MakeMake</h2>
<p dir="auto">MakeMake is a tool for generateing and running make files from C code. It does so by parsing the .c and .h files in the same directory as a starting file (usualy the C file containging main), and determains recursivly what files are required to build the project. make make does this by looking for any function declaration using extern, and the searches for the corresponding function definition.</p>
<h3 tabindex="-1" dir="auto">building MakeMake:</h3>
<p dir="auto">To build makemake on unix platform you can use the shellscript MakeMakeMake, it will not only build makemake, it will also run it, and it therefor takes the same parameters as MakeMake. To build makemake:</p>
<div data-snippet-clipboard-copy-content="chmod -x makemakemake.sh
./makemakemake.sh"><pre><code>chmod -x makemakemake.sh
./makemakemake.sh
</code></pre></div>
<p dir="auto">If make a MakeMakeMake is given options it will run makemake and pass on the options to MakeMake. The MakeMakeMake script there for takes the exact same options as MakeMake. Once MakeMakeMake has built MakeMake you can call it directly.</p>
<h3 tabindex="-1" dir="auto">Running MakeMake</h3>
<p dir="auto">To run MakeMake the comandline format is
makemake  &lt;options ...&gt;</p>
<p dir="auto">The C file path will be used to identify the starting C file and the path where it resides. This path is the path that will be searched for other .c and .h files for possible inclution in the build.</p>
<h3 tabindex="-1" dir="auto">Options:</h3>
<p dir="auto">MakeMake can be given opetions in two ways, either using the comand line, or as pragmas in the .c and .h files. Each option consists of key-value pair, the name of the option and what the option is set to. The available options are:</p>
<p dir="auto">-name  Name of the executable.
-makefile  Name of the make file (or stdout).
-compilerflag  Custom compiler flags.
-platform  Platform define.
-dynamiclib  builds the application as a dynamicly linked library.
-lib  Library dependency.
-define  Adds a define.</p>
<p dir="auto">To use the options on the comand line use "-" followed by the option name and option.</p>
<div data-snippet-clipboard-copy-content="Example: To build project with a specifird name you may call:
./makemake ./example.c -name my_example"><pre><code>Example: To build project with a specifird name you may call:
./makemake ./example.c -name my_example
</code></pre></div>
<p dir="auto">To use options from within a .c or .h file, add MakeMake pragma in the following format:</p>
<div data-snippet-clipboard-copy-content="#pragma makemake <option name> <option value> <optional platform>"><pre><code>#pragma makemake &lt;option name&gt; &lt;option value&gt; &lt;optional platform&gt;
</code></pre></div>
<p dir="auto">If for instanc you have a .c file that depends on PTreads on posix platforms, you may add the pragma:</p>
<div data-snippet-clipboard-copy-content="#pragma makemake lib lpthread posix"><pre><code>#pragma makemake lib lpthread posix
</code></pre></div>
<p dir="auto">The MakeMake can also generate the MakeMakeMake script by calling:</p>
<div data-snippet-clipboard-copy-content="./makemake makemakemakemake"><pre><code>./makemake makemakemakemake
</code></pre></div>
<h3 tabindex="-1" dir="auto">Platforms</h3>
<p dir="auto">you can define as many platfroms as you want, if you do not define platforms on the command line, MakeMake will assume you are building for the platform you are on. For the following platforms, the pre defined platforms are:</p>
<div data-snippet-clipboard-copy-content="Linux: linux posix
Windows: win32
MacOS: macosx apple posix
Android: android posix"><pre><code>Linux: linux posix
Windows: win32
MacOS: macosx apple posix
Android: android posix
</code></pre></div>
<p dir="auto">pragma directives with a given platform will only operate of that platform is defined. You can define your own platforms for setting options this way.</p>
<p dir="auto">Make make has been tested on Linux, MacOS, and Windows (Make files have been generated on windows, but not tested on windows)</p>
<p dir="auto">Thanks to the work of Felix Klinge, MakeMake supports Android and the plan is to add iOS support.</p>
<h3 tabindex="-1" dir="auto">Test project</h3>
<p dir="auto">MakeMake comes with a simple "hello world" test project, called makemake_test... consisiting of 3 files. To test them call:</p>
<div data-snippet-clipboard-copy-content="chmod -x makemakemake.sh
./makemakemake.sh ./makemake_test_one.c"><pre><code>chmod -x makemakemake.sh
./makemakemake.sh ./makemake_test_one.c
</code></pre></div>
<p dir="auto">The file makemake_test_one.c, will include makemake_test_two.h that declares a funtion defined in makemake_test_three.c</p>
<h3 tabindex="-1" dir="auto">About the project</h3>
<p dir="auto">MakeMake was designed to solve my problem (Im a C developer that develops protable C programs using VisualStudio, and I do not want to maintain up todate make files for all projects and platforms). There are ways to write C code that makemake will not be able to parse, but for me that is a feature not a bug as it requires me to keep my code clean and simple.</p>
<p dir="auto">The main motivation for releasig MakeMake is to serve as a n inspiration for developers that they can wit relativly little effort build their own tooling, especially with a simple language like C. Feel free to be inspired by, use or fork the project.</p>
<p dir="auto">You can find my work on <a href="http://www.quelsolaar.com/" rel="nofollow">www.quelsolaar.com</a> and at @quelsolaar @eskilsteenberg, and <a href="https://www.youtube.com/@eskilsteenberg" rel="nofollow">https://www.youtube.com/@eskilsteenberg</a> you can also reach me at eskil at quelsolaar dot com.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gron: Make JSON greppable (232 pts)]]></title>
            <link>https://github.com/tomnomnom/gron</link>
            <guid>38511077</guid>
            <pubDate>Sun, 03 Dec 2023 21:45:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tomnomnom/gron">https://github.com/tomnomnom/gron</a>, See on <a href="https://news.ycombinator.com/item?id=38511077">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">gron</h2>
<p dir="auto"><a href="https://travis-ci.org/tomnomnom/gron" rel="nofollow"><img src="https://camo.githubusercontent.com/35f67e5eeb8835ca757873718707461f5bf4fd23e98f3c53de000347f5128850/68747470733a2f2f7472617669732d63692e6f72672f746f6d6e6f6d6e6f6d2f67726f6e2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/tomnomnom/gron.svg?branch=master"></a></p>
<p dir="auto">Make JSON greppable!</p>
<p dir="auto">gron transforms JSON into discrete assignments to make it easier to <code>grep</code> for what you want and see the absolute 'path' to it.
It eases the exploration of APIs that return large blobs of JSON but have terrible documentation.</p>
<pre>▶ <b>gron</b> "https://api.github.com/repos/tomnomnom/gron/commits?per_page=1" | fgrep "commit.author"
json[0].commit.author = {};
json[0].commit.author.date = "2016-07-02T10:51:21Z";
json[0].commit.author.email = "mail@tomnomnom.com";
json[0].commit.author.name = "Tom Hudson";
</pre>
<p dir="auto">gron can work backwards too, enabling you to turn your filtered data back into JSON:</p>
<pre>▶ gron "https://api.github.com/repos/tomnomnom/gron/commits?per_page=1" | fgrep "commit.author" | <b>gron --ungron</b>
[
  {
    "commit": {
      "author": {
        "date": "2016-07-02T10:51:21Z",
        "email": "mail@tomnomnom.com",
        "name": "Tom Hudson"
      }
    }
  }
]
</pre>
<blockquote>
<p dir="auto">Disclaimer: the GitHub API has fantastic documentation, but it makes for a good example.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">Installation</h2>
<p dir="auto">gron has no runtime dependencies. You can just <a href="https://github.com/tomnomnom/gron/releases">download a binary for Linux, Mac, Windows or FreeBSD and run it</a>.
Put the binary in your <code>$PATH</code> (e.g. in <code>/usr/local/bin</code>) to make it easy to use:</p>
<div data-snippet-clipboard-copy-content="▶ tar xzf gron-linux-amd64-0.1.5.tgz
▶ sudo mv gron /usr/local/bin/"><pre><code>▶ tar xzf gron-linux-amd64-0.1.5.tgz
▶ sudo mv gron /usr/local/bin/
</code></pre></div>
<p dir="auto">If you're a Mac user you can also <a href="http://braumeister.org/formula/gron" rel="nofollow">install gron via brew</a>:</p>

<p dir="auto">Or if you're a Go user you can use <code>go install</code>:</p>
<div data-snippet-clipboard-copy-content="▶ go install github.com/tomnomnom/gron@latest"><pre><code>▶ go install github.com/tomnomnom/gron@latest
</code></pre></div>
<p dir="auto">It's recommended that you alias <code>ungron</code> or <code>norg</code> (or both!) to <code>gron --ungron</code>. Put something like this in your shell profile (e.g. in <code>~/.bashrc</code>):</p>
<div data-snippet-clipboard-copy-content="alias norg=&quot;gron --ungron&quot;
alias ungron=&quot;gron --ungron&quot;"><pre><code>alias norg="gron --ungron"
alias ungron="gron --ungron"
</code></pre></div>
<p dir="auto">Or you could create a shell script in your $PATH named <code>ungron</code> or <code>norg</code> to affect all users:</p>

<h2 tabindex="-1" dir="auto">Usage</h2>
<p dir="auto">Get JSON from a file:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json 
json = {};
json.contact = {};
json.contact.email = &quot;mail@tomnomnom.com&quot;;
json.contact.twitter = &quot;@TomNomNom&quot;;
json.github = &quot;https://github.com/tomnomnom/&quot;;
json.likes = [];
json.likes[0] = &quot;code&quot;;
json.likes[1] = &quot;cheese&quot;;
json.likes[2] = &quot;meat&quot;;
json.name = &quot;Tom&quot;;"><pre><code>▶ gron testdata/two.json 
json = {};
json.contact = {};
json.contact.email = "mail@tomnomnom.com";
json.contact.twitter = "@TomNomNom";
json.github = "https://github.com/tomnomnom/";
json.likes = [];
json.likes[0] = "code";
json.likes[1] = "cheese";
json.likes[2] = "meat";
json.name = "Tom";
</code></pre></div>
<p dir="auto">From a URL:</p>
<div data-snippet-clipboard-copy-content="▶ gron http://headers.jsontest.com/
json = {};
json.Host = &quot;headers.jsontest.com&quot;;
json[&quot;User-Agent&quot;] = &quot;gron/0.1&quot;;
json[&quot;X-Cloud-Trace-Context&quot;] = &quot;6917a823919477919dbc1523584ba25d/11970839830843610056&quot;;"><pre><code>▶ gron http://headers.jsontest.com/
json = {};
json.Host = "headers.jsontest.com";
json["User-Agent"] = "gron/0.1";
json["X-Cloud-Trace-Context"] = "6917a823919477919dbc1523584ba25d/11970839830843610056";
</code></pre></div>
<p dir="auto">Or from <code>stdin</code>:</p>
<div data-snippet-clipboard-copy-content="▶ curl -s http://headers.jsontest.com/ | gron
json = {};
json.Accept = &quot;*/*&quot;;
json.Host = &quot;headers.jsontest.com&quot;;
json[&quot;User-Agent&quot;] = &quot;curl/7.43.0&quot;;
json[&quot;X-Cloud-Trace-Context&quot;] = &quot;c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147&quot;;"><pre><code>▶ curl -s http://headers.jsontest.com/ | gron
json = {};
json.Accept = "*/*";
json.Host = "headers.jsontest.com";
json["User-Agent"] = "curl/7.43.0";
json["X-Cloud-Trace-Context"] = "c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147";
</code></pre></div>
<p dir="auto">Grep for something and easily see the path to it:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | grep twitter
json.contact.twitter = &quot;@TomNomNom&quot;;"><pre><code>▶ gron testdata/two.json | grep twitter
json.contact.twitter = "@TomNomNom";
</code></pre></div>
<p dir="auto">gron makes diffing JSON easy too:</p>
<div data-snippet-clipboard-copy-content="▶ diff <(gron two.json) <(gron two-b.json)
3c3
< json.contact.email = &quot;mail@tomnomnom.com&quot;;
---
> json.contact.email = &quot;contact@tomnomnom.com&quot;;"><pre><code>▶ diff &lt;(gron two.json) &lt;(gron two-b.json)
3c3
&lt; json.contact.email = "mail@tomnomnom.com";
---
&gt; json.contact.email = "contact@tomnomnom.com";
</code></pre></div>
<p dir="auto">The output of <code>gron</code> is valid JavaScript:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json > tmp.js
▶ echo &quot;console.log(json);&quot; >> tmp.js
▶ nodejs tmp.js
{ contact: { email: 'mail@tomnomnom.com', twitter: '@TomNomNom' },
  github: 'https://github.com/tomnomnom/',
  likes: [ 'code', 'cheese', 'meat' ],
  name: 'Tom' }"><pre><code>▶ gron testdata/two.json &gt; tmp.js
▶ echo "console.log(json);" &gt;&gt; tmp.js
▶ nodejs tmp.js
{ contact: { email: 'mail@tomnomnom.com', twitter: '@TomNomNom' },
  github: 'https://github.com/tomnomnom/',
  likes: [ 'code', 'cheese', 'meat' ],
  name: 'Tom' }
</code></pre></div>
<p dir="auto">It's also possible to obtain the <code>gron</code> output as JSON stream via
the <code>--json</code> switch:</p>
<div data-snippet-clipboard-copy-content="▶ curl -s http://headers.jsontest.com/ | gron --json
[[],{}]
[[&quot;Accept&quot;],&quot;*/*&quot;]
[[&quot;Host&quot;],&quot;headers.jsontest.com&quot;]
[[&quot;User-Agent&quot;],&quot;curl/7.43.0&quot;]
[[&quot;X-Cloud-Trace-Context&quot;],&quot;c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147&quot;]"><pre><code>▶ curl -s http://headers.jsontest.com/ | gron --json
[[],{}]
[["Accept"],"*/*"]
[["Host"],"headers.jsontest.com"]
[["User-Agent"],"curl/7.43.0"]
[["X-Cloud-Trace-Context"],"c70f7bf26661c67d0b9f2cde6f295319/13941186890243645147"]
</code></pre></div>
<h2 tabindex="-1" dir="auto">ungronning</h2>
<p dir="auto">gron can also turn its output back into JSON:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | gron -u
{
  &quot;contact&quot;: {
    &quot;email&quot;: &quot;mail@tomnomnom.com&quot;,
    &quot;twitter&quot;: &quot;@TomNomNom&quot;
  },
  &quot;github&quot;: &quot;https://github.com/tomnomnom/&quot;,
  &quot;likes&quot;: [
    &quot;code&quot;,
    &quot;cheese&quot;,
    &quot;meat&quot;
  ],
  &quot;name&quot;: &quot;Tom&quot;
}"><pre><code>▶ gron testdata/two.json | gron -u
{
  "contact": {
    "email": "mail@tomnomnom.com",
    "twitter": "@TomNomNom"
  },
  "github": "https://github.com/tomnomnom/",
  "likes": [
    "code",
    "cheese",
    "meat"
  ],
  "name": "Tom"
}
</code></pre></div>
<p dir="auto">This means you use can use gron with <code>grep</code> and other tools to modify JSON:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | grep likes | gron --ungron
{
  &quot;likes&quot;: [
    &quot;code&quot;,
    &quot;cheese&quot;,
    &quot;meat&quot;
  ]
}"><pre><code>▶ gron testdata/two.json | grep likes | gron --ungron
{
  "likes": [
    "code",
    "cheese",
    "meat"
  ]
}
</code></pre></div>
<p dir="auto">or</p>
<div data-snippet-clipboard-copy-content="▶ gron --json testdata/two.json | grep likes | gron  --json --ungron
{
  &quot;likes&quot;: [
    &quot;code&quot;,
    &quot;cheese&quot;,
    &quot;meat&quot;
  ]
}"><pre><code>▶ gron --json testdata/two.json | grep likes | gron  --json --ungron
{
  "likes": [
    "code",
    "cheese",
    "meat"
  ]
}
</code></pre></div>
<p dir="auto">To preserve array keys, arrays are padded with <code>null</code> when values are missing:</p>
<div data-snippet-clipboard-copy-content="▶ gron testdata/two.json | grep likes | grep -v cheese
json.likes = [];
json.likes[0] = &quot;code&quot;;
json.likes[2] = &quot;meat&quot;;
▶ gron testdata/two.json | grep likes | grep -v cheese | gron --ungron
{
  &quot;likes&quot;: [
    &quot;code&quot;,
    null,
    &quot;meat&quot;
  ]
}"><pre><code>▶ gron testdata/two.json | grep likes | grep -v cheese
json.likes = [];
json.likes[0] = "code";
json.likes[2] = "meat";
▶ gron testdata/two.json | grep likes | grep -v cheese | gron --ungron
{
  "likes": [
    "code",
    null,
    "meat"
  ]
}
</code></pre></div>
<p dir="auto">If you get creative you can do <a href="https://github.com/tomnomnom/gron/blob/master/ADVANCED.mkd">some pretty neat tricks with gron</a>, and
then ungron the output back into JSON.</p>
<h2 tabindex="-1" dir="auto">Get Help</h2>
<div data-snippet-clipboard-copy-content="▶ gron --help
Transform JSON (from a file, URL, or stdin) into discrete assignments to make it greppable

Usage:
  gron [OPTIONS] [FILE|URL|-]

Options:
  -u, --ungron     Reverse the operation (turn assignments back into JSON)
  -v, --values     Print just the values of provided assignments
  -c, --colorize   Colorize output (default on tty)
  -m, --monochrome Monochrome (don't colorize output)
  -s, --stream     Treat each line of input as a separate JSON object
  -k, --insecure   Disable certificate validation
  -j, --json       Represent gron data as JSON stream
      --no-sort    Don't sort output (faster)
      --version    Print version information

Exit Codes:
  0	OK
  1	Failed to open file
  2	Failed to read input
  3	Failed to form statements
  4	Failed to fetch URL
  5	Failed to parse statements
  6	Failed to encode JSON

Examples:
  gron /tmp/apiresponse.json
  gron http://jsonplaceholder.typicode.com/users/1 
  curl -s http://jsonplaceholder.typicode.com/users/1 | gron
  gron http://jsonplaceholder.typicode.com/users/1 | grep company | gron --ungron"><pre><code>▶ gron --help
Transform JSON (from a file, URL, or stdin) into discrete assignments to make it greppable

Usage:
  gron [OPTIONS] [FILE|URL|-]

Options:
  -u, --ungron     Reverse the operation (turn assignments back into JSON)
  -v, --values     Print just the values of provided assignments
  -c, --colorize   Colorize output (default on tty)
  -m, --monochrome Monochrome (don't colorize output)
  -s, --stream     Treat each line of input as a separate JSON object
  -k, --insecure   Disable certificate validation
  -j, --json       Represent gron data as JSON stream
      --no-sort    Don't sort output (faster)
      --version    Print version information

Exit Codes:
  0	OK
  1	Failed to open file
  2	Failed to read input
  3	Failed to form statements
  4	Failed to fetch URL
  5	Failed to parse statements
  6	Failed to encode JSON

Examples:
  gron /tmp/apiresponse.json
  gron http://jsonplaceholder.typicode.com/users/1 
  curl -s http://jsonplaceholder.typicode.com/users/1 | gron
  gron http://jsonplaceholder.typicode.com/users/1 | grep company | gron --ungron
</code></pre></div>
<h2 tabindex="-1" dir="auto">FAQ</h2>
<h3 tabindex="-1" dir="auto">Wasn't this written in PHP before?</h3>
<p dir="auto">Yes it was! The original version is <a href="https://github.com/tomnomnom/gron/blob/master/original-gron.php">preserved here for posterity</a>.</p>
<h3 tabindex="-1" dir="auto">Why the change to Go?</h3>
<p dir="auto">Mostly to remove PHP as a dependency. There's a lot of people who work with JSON who don't have PHP installed.</p>
<h3 tabindex="-1" dir="auto">Why shouldn't I just use jq?</h3>
<p dir="auto"><a href="https://stedolan.github.io/jq/" rel="nofollow">jq</a> is <em>awesome</em>, and a lot more powerful than gron, but with that power comes
complexity. gron aims to make it easier to use the tools you already know, like <code>grep</code> and <code>sed</code>.</p>
<p dir="auto">gron's primary purpose is to make it easy to find the path to a value in a deeply nested JSON blob
when you don't already know the structure; much of jq's power is unlocked only once you know that structure.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Placeholder Girlfriend (192 pts)]]></title>
            <link>https://parhelia.conorbarnes.com/p/the-placeholder-girlfriend</link>
            <guid>38510997</guid>
            <pubDate>Sun, 03 Dec 2023 21:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://parhelia.conorbarnes.com/p/the-placeholder-girlfriend">https://parhelia.conorbarnes.com/p/the-placeholder-girlfriend</a>, See on <a href="https://news.ycombinator.com/item?id=38510997">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg" width="1365" height="828" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:828,&quot;width&quot;:1365,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:404539,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0ea83ab-0b0c-4f1c-8f54-ed26bc66fd87_1365x828.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>I had the feeling I was a placeholder girlfriend. That once the winter was over she wouldn’t need me anymore.&nbsp;</p><p>I had this feeling because it hadn’t started like my other relationships. I’d kept seeing her at parties with all the Toronto grad students that autumn and thought she was so different from me. Whatever the opposite of basic is. Advanced? I had the feeling she didn’t even own sweatpants, if that makes sense. She’d see me across the party and would watch me but wouldn’t return my waves. Somehow she found out I had a crush on her and it didn’t change anything. Just the stare, maybe a polite nod, then she’d go back to half-listening to whoever was trying to impress her. She was beautiful like an ice sculpture is beautiful.</p><p>I knew her thesis was on Italian autonomist feminism of the 1970s. I had no idea what that meant so I never risked talking to her and embarrassing myself. My thesis was on the history of memes. I wanted to change it but didn’t know what else I could talk about.&nbsp;</p><p>Then one night she called me. The wind of the first real snowstorm whistled through my window and made me cover my other ear while I listened to her talk to me for the first time. She told me she found me really pretty. That she’d always admired me from a distance. And would I come over?</p><p>We didn’t talk much that night or any night after. But on the subway back to my apartment in North York the next morning, in between games of Candy Crush, I realized we were going out. I had a nagging feeling I couldn’t explain though. Before she’d kissed me she’d told me that she’d been in a long distance relationship and they’d broken up that day. It flattered me that I was who she called but it wasn’t exactly romantic.&nbsp;</p><p>I only worried I was a placeholder girlfriend in the back of my mind though, like when I woke up or when videos were loading. It became real when I saw the list. When I saw the rubric.</p><p>She had been at the university and needed files off her computer. I was lazing around in her living room. I had four roommates and she had none. I should have been working on my thesis, but I enjoyed being in an apartment without roommates so much that I was just laying around listening to my Harry Potter podcasts. I didn’t know if she had rent control or was just rich but she did have an office. She was like what I imagined a grad student should be. She had me go into her office and she walked me through transferring the files. But she had left a spreadsheet open.</p><p>I tried not to look but I think that’s actually impossible. Because I saw my name at the top. And I saw numbers and a whole column of red cells. And then it clicked.</p><p>If you saw a sheet rating you in bed out of 10, with a hundred other ratings too, you would look. You would peek.</p><p>“Hey?” she said over the phone. “Did it go through?”</p><p>“Oh,” I said. I clicked through the remaining buttons. “Yeah. Yeah. There should be an email.” I swallowed dryly. “You should have everything.”</p><p>“Awesome. Okay, got it. Gotta run, bye!”</p><p>Then I was left with the sheet.</p><p>I tried not to keep reading. I tried to tell myself it was private. But it wasn’t. It was about me, so it wasn’t private. And then when I started to read it, started understanding what the numbers meant, I tried to tell myself I’d seen enough, I didn’t need to keep reading. But I did. I couldn’t stop.</p><p><em>Humor </em><strong>2.0</strong></p><p><em>Movie Taste </em><strong>5.0</strong></p><p><em>Love-making </em><strong>6.5</strong></p><p>I scrolled and scrolled. There were a hundred cells and almost every one was red. Almost every mark was shitty. The only green was:&nbsp;</p><p><em>Beauty </em><strong>8.0</strong></p><p><span>The fact that that was the only one where I passed made the whole thing even worse. Everything cut me. </span><em>Gift-giving. Punctuality. Memory.</em><span> The notes beside them only hurt more (“only funny unintentionally”, “un-self-aware Harry Potter nostalgia”, “Pillow princess”). I was mortified but I couldn’t stop reading. It even seemed like there were categories specifically invented to hurt me (</span><em>Freckles</em><strong>: 2</strong><span>). And there were others with entirely no explanation, just there to haunt (</span><em>Friends: </em><strong>4.5</strong><span>).</span></p><p><span>The worst part was that it all seemed true. It became clear as soon as I read it. I wasn’t smart enough (</span><strong>5.0</strong><span>) to create a narrative where I was actually a really good listener, I had just always hidden from myself the fact that I was a bad listener (</span><strong>3.0</strong><span>). My entire personality was getting pulled back like a hangnail.&nbsp;</span></p><p>My mind raced through thoughts until it settled on three it repeated over and over and over:</p><ul><li><p>Your girlfriend should think of you as a ten in everything.&nbsp;</p></li><li><p>No. You aren’t even supposed to think these things.</p></li><li><p>Why doesn’t she just break up with me?</p></li></ul><p>It burned through me until, finally, I reached the bottom. Then I truly broke down, staring at the big, bold, red cell:&nbsp;</p><p><strong>Status: Temporary</strong></p><p><span>If I had any </span><em>Imagination</em><span> (another </span><strong>2.0</strong><span>) I’d say something like: it made me feel like the sun laying down its judgment upon one of the barren and useless planets near it. But all I could really say is: it made me want to die. It made me cry huge gobby tears all over her desk and I should have realized that would happen because I was too </span><em>Emotional</em><span> (</span><strong>4.0</strong><span>). It made me wail like a child on the floor of her stupid, parent-paid office.</span></p><p>After minutes of this, it made me want revenge.&nbsp;</p><p>For one horrible second I contemplated killing her but that was wildly out of proportion and then I tried to pretend that I had only wished she was dead and then I just tried to forget about it.</p><p>My mom says that the best revenge is a life well lived. When I met my dad I asked him about that and he laughed oddly loudly and said once you’re thinking about getting revenge it’s too late to have a good life. Then he took pictures with me and the zoo pandas behind us and I never saw him again.</p><p><span>When I tried imagining a good life I couldn’t. I couldn’t imagine going to work thinking about my </span><em>Work ethic </em><span>(</span><strong>2.5</strong><span>) or </span><em>Problem-solving</em><span> (</span><strong>5.5</strong><span>) or </span><em>Punctuality</em><span> (</span><strong>4.0</strong><span>). I couldn’t imagine going to a party ever again with my lack of </span><em>Fashion</em><span> (</span><strong>6.0</strong><span>) and </span><em>Wit</em><span> (</span><strong>2.0</strong><span>). I’d always imagined that if I was on the run for a crime I’d hide away as a nun, but even that wouldn’t work because I had no </span><em>Patience</em><span> (</span><strong>3.0</strong><span>).</span></p><p>But then I realized that I hadn’t understood what a good life could be. I hadn’t been thinking about just how good life could be.&nbsp;</p><p><span>It’s all just numbers. It’s all just 1 to 10 (besides the 0 I got for math). If I changed, if I got everything to a 10, wouldn’t that mean that her wisdom was low? What I mean is, wouldn’t that show what an idiot she was? Right now if I told anybody about the list they’d think she was a monster. But they’d also know she was right and would reflect on how pathetic I was. But if I revealed the list after becoming a 10 in everything they’d think about how pathetic </span><em>she</em><span> was. An idiot and</span><em> </em><span>a monster. They’d say to me: who’s that girl you’re with? Is she your placeholder girlfriend? They’d say that to </span><em>me.</em></p><p><span>I got up off the floor. I went to the computer. I scrolled back to ambition, way at the beginning of her hundred row sheet. Its </span><strong>2.5</strong><span> stared at me. I changed it to a </span><strong>10</strong><span>.</span></p><p>The first thing I decided to learn was how to learn. I had to learn a lot of things so I had to do it fast and right. It was the beginning of winter and I wanted to emerge in spring like a cherry blossom or whatever kind of blossoms happen in spring. I wanted her to melt in embarrassment like the snow.</p><p>The problem was that I knew my mind just didn’t work like that. It liked going slowly. And detours. But I knew it was possible to change how your mind works, like melting an old ring into a pretty one. I went to some of the grad students and bought up the hallucinogens they were researching. Then I put all of them as far back on my tongue as I could, swallowed two big glasses of water, sat in my lightless room with my headphones on, and willed myself to become a good learner. I imagined squeezing my brain like play-doh until I could be like those robots that learn things faster than any human and it makes them powerful beyond belief.</p><p>Over the next 12 hours my mind split apart. When it reformed, it reformed softer. More ready. More malleable.</p><p><span>When I went back to the grad students the next day to swear them in as my practice partners, they joked they were worried about me but I could tell they were intrigued. Internally I changed my </span><em>Interesting</em><span> score from </span><strong>1.0</strong><span> to </span><strong>10</strong><span>.&nbsp;</span></p><p>Then began the work.</p><p>If you like, imagine a training montage. I really like the one in Harry Potter and the Order of the Phoenix when they’re all getting good at spells together. I knew I needed my own team but it had to be a secret. I had to take her by surprise. I’d meet my partners in hidden classrooms, prayer rooms, their apartments.&nbsp;</p><p>The grad students were all so curious and I knew I could use it. I swore each of them individually into secrecy. They all hated working on their theses. They were all bundled up in little apartments around the university waiting for spring like hibernating bears. It was like I could give them one little dream they didn’t understand but would always remember.</p><p><span>One guy was my </span><em>Humor</em><span> partner. I admitted to him that I didn’t really get jokes. I would just watch for other peoples’ reactions and nobody ever noticed me laughing a little late. He explained that it’s mostly about timing and the unexpected and being animated. “Like this?” I said, a little loudly and suddenly. He laughed, which I thought was good, but he said “No, you need energy. People aren’t entertained by a rock.”</span></p><p><span>So we drilled it. “Ayyyy babe,” I’d say as I walked in to a session, or “Yo!” Then I’d tease him, or myself, or our crazy mayor. I had a running joke with him about the snow (“What if we put all the global warming in Toronto?”). Very soon, he was chortling and sometimes outright laughing. </span><strong>10</strong><span>.</span></p><p><span>One girl was my </span><em>Culture</em><span> partner. I explained that I needed to become “cultured”. She asked what I meant and I admitted I didn’t know. Well, I had just come from a joke session, so what I said was “I was hoping you could tell me!” She laughed. But then she assigned me reading.</span></p><p>I had become very good at reading. Before my dark night of the soul I had only been seeing words. After that I saw ideas. I could rotate them and connect them like Lego. Reading the words was now as easy as grabbing a big handful of Lego.&nbsp;</p><p><span>I read through poetry and fiction and commentary and letters from this century and many others. The letters were my favourite because the writers didn’t take them as seriously as the books. I was big into not taking things too seriously now. Before it had bothered me that I was low on both </span><em>Ambition</em><span> and </span><em>Chill</em><span> (</span><strong>6.0</strong><span>). But now I was at </span><strong>10</strong><span> for both. I was going to humiliate my evil girlfriend. But I was chill about it because I knew it would happen.&nbsp;</span></p><p>My favourite writers were not chill. They were fucked up. I remembered that my girlfriend’s favourite writer was Sylvia Plath so I got really into her husband and the people Plath admired and considered better than her.&nbsp;</p><p><span>This didn’t take long at all. When my writing conspirator asked about my thesis on memes, I explained memetic contagion instead, including an aside on Burroughs’s assertion that language is a virus from outer space. When she asked which Beatle was best, I proved that Yoko Ono was superior. She was delighted. “I don’t know what’s going on with you. But would you review my novel when it’s ready?” I said yes, of course. </span><em>Culture</em><span>: </span><strong>10</strong><span>. And a bonus to </span><em>Selflessness</em><span> as well.</span></p><p><span>Both of those were hours in the morning. I wasn’t working on my thesis anymore. It could wait until spring. Instead I was doing eight sessions a day. When I solved a trait another one came in. At the bottom of winter, when the sun only peeks out at noon and then retreats, I added </span><em>Lovemaking</em><span>. I found a guy I had hooked up with in first year and told him I wanted to make love every weekday at 3PM. I wanted to become the best lover he could ever imagine. Because my thoughtfulness score was going up I asked him: How did that make him feel? Did any reservations come to mind? Would he like to take a few days to think about it?</span></p><p><span>He replied "Nah I'm down." So we began. I will spare you details about our progress. I will say that at first he didn’t understand the feedback phase but he came to appreciate it. I will say that he became a </span><strong>10</strong><span> lover as well.&nbsp;</span></p><p>Throughout all of this I saw my girlfriend less but not so little she’d dump me. I hid all my new powers besides the lovemaking from her. I knew that that would draw her in because she was shallow. Only shallow people make a sheet. Only shallow people rate their girlfriend’s tenderness out of 10.</p><p><span>Or at least that’s how I thought at first. Each time I hit a </span><strong>10</strong><span> I’d think about what number she’d have. She didn’t have much </span><em>Humor </em><span>either, maybe a </span><strong>5</strong><span>. She wasn’t that </span><em>Chill</em><span> — if you have a home office and desk and two monitors you aren’t </span><em>Chill</em><span>. She was only a </span><strong>10</strong><span> lover when I was a </span><strong>10</strong><span> lover with her.&nbsp;</span></p><p>Those were the hardest moments. We’d lay there gasping and I’d always tell her I’d need to clean up. But in the washroom I’d just shake and open the window and let the Toronto winter dive into my lungs and I’d wonder if I was doing the right thing. I was becoming a more thoughtful person and I knew revenge was wrong. I knew I didn’t wish my pain on anybody so why was I making an exception for her?&nbsp;</p><p><span>But I had to keep going. I had become a </span><strong>10</strong><span> in so many things that I couldn’t stop now. Thoughtfulness could be the last thing. I could even finish it a little after my big reveal. Not yet. Part of my thoughtfulness was realizing that nobody is perfect.</span></p><p>But I was getting there. I was closing in, more relentless than the blizzards that year, which came down like snow dumped from buckets.&nbsp;</p><p>I knew I was still emotional. My partner for that was an econ student. We met in her apartment on St. George Street just north of the university. I’d originally chosen her because I’d assumed an econ student would be more emotionally stable than all the humanities grads I knew. Honestly, I thought she’d be boring. I didn’t know how passionate she was.&nbsp;</p><p>She showed me pictures of dying animals and the horrible stories of how they’d become separated from their mothers. It made me weep.&nbsp;</p><p>She explained that people mostly donate to their universities and churches but for a little money you could save a child from a horrible death. It made me rage at people’s ignorance.&nbsp;</p><p>Finally, I made her tell me a story about a woman named Alice who rated her girlfriend Roberta and rated her badly. I wanted to be so emotionally strong that I could handle the greatest embarrassment of my life. But I couldn’t. It made me leave the session and wander the Annex pretending I was somebody else.</p><p>For a few days I tried becoming emotionless about these. I tried turning all my emotions off like taps. She realized what was going on. “Look. I can tell you’re still emotional even if you’re trying not to show it”. I was impressed by her wisdom. “You can have emotional responses,” she continued. “It’s healthy. These are horrible things. You just need to not let it ruin you. You need to have a plan for how to deal with it.”</p><p>The next day, when she showed me a dying bird, a single tear ran down my eye. I said: “We humans should disrupt the natural environment less.”&nbsp;</p><p>Then she showed me a child dying of malaria. I shook my head and said “Humans should try to be as effective with their charitable giving as they are with their big purchases. We have so much potential to do good in the world.”</p><p>Then she told me the story of the cruel girlfriend Alice again like I'd asked. She didn’t know it was my story, of course, but she was a good storyteller and some of the details were correct. She had Roberta (me) sobbing and everything.</p><p>When she finished I was proud. I had lasted through the whole thing. I had cried but not loudly, just little hiccup-y gasps. I looked up at her and said: "Roberta should get revenge."</p><p>“Revenge?” She looked surprised. “I get something like… I don’t know, but revenge is a leap.”</p><p>“Why not?” I asked. “Alice hurt her more than should even be possible.” The sky in the apartment windows was blue, a March-bright blue, and the glare made it hard for me to focus on her eyes, which were brighter than anybody’s I’d stared into all winter.</p><p>“Yeah but like. This says way more about her than about her girlfriend.”</p><p>“What?”</p><p>“Alice is crazy. If you make a sheet ranking a hundred attributes of your lover, you’re crazy, right?”</p><p>“Yeah, so?”</p><p>“So why would Roberta trust or care what Alice says about her? Why would Alice have a clue about any of this? I don’t think Alice knows the first thing about anything.”</p><p>I stopped myself from telling her I knew it was all true. I stopped myself from explaining that my girlfriend had known me better than I’d known myself. I was open mouthed and had nothing to say.</p><p>“Honestly, I feel sad for Alice, she’s so confused,” she continued. “I’d feel even worse for her if Roberta humiliated her. Would it be at a party or something? That would just suck.”</p><p>I stopped myself from telling her the contents of my revenge. But she was right. I had imagined it culminating in a party. I had imagined becoming the life of the party. In my first year I didn’t know anything about alcohol and when we played beer pong I was drinking pure vodka and I became drunker than anything and I suppose technically I was the life of the party because I got crazy nicknames that night. But this wouldn’t be like that at all. I’d actually be the life of the party. I’d be so interesting that people would tell each other they were going to the washroom but instead they’d come see me. If anybody got too drunk I’d lend them my spare room and appoint two trustworthy watchers. When, I’d return I’d turn it into a dance party complete with the playlist I’d been making for months. I would grab men and women and bring them to dance with me and I’d dance so well they wouldn’t be afraid to dance well too. I would make sure everybody would leave the party feeling not just that they were lucky to be there, but that I felt lucky to have them. Then I would retire with my girlfriend. I would make love to her perfectly. Then, a little while later, I would tell her she was a monster, that I was done with her, and I would call her a cab and I would never see her again.&nbsp;</p><p>I looked up at my friend now. She was waiting patiently, smiling slightly. She hadn’t judged me when I cried about the bird. She had held my hand when she told me about effective charity. Right now her long black hair was falling into her eyes the way it did when it leaned forward. I did not know if the shape of her body was beautiful under her layers but I knew the way she moved was beautiful. I began to get a curious feeling.</p><p><span>Then something horrible came over me. Numbers began floating into my mind. </span><em>Thoughtfulness</em><span>: </span><strong>10</strong><span>. </span><em>Interestingness</em><span>: </span><strong>8.0</strong><span>. </span><em>Beauty</em><span>: </span><strong>8.0</strong><span>.</span></p><p>I stood in terror and she looked surprised.&nbsp;</p><p>“Would you be around tonight?” I asked suddenly. “There’s something I have to finish. To end. Right now.”</p><p>Of course, she said. She’d be around tonight.</p><p>Winter was ending early. I ran through the campus and overheated and had to fold more and more layers to carry under my arms. I almost slipped on the melting and glistening sidewalks but I made it to my girlfriend’s house out of breath and red in the face.&nbsp;</p><p>It was not how I had imagined it. Her eyebrows rose and she looked me up and down as I panted on her porch.</p><p>“I need you to be honest,” I said. A screen separated us and I knew the same way I was constructing her image separated by the little squares of mesh, she was constructing her judgment of me out of all her tiny stupid spreadsheet cells.</p><p>Before she could reply, I said it: “I’m just your placeholder girlfriend.”</p><p>Her lips pursed and she couldn’t look at me anymore. I hadn’t asked her a question. She looked at the sidewalk and at the porch. She looked anywhere else. Then she slowly came back to me.</p><p>“I guess so. I guess you were.”</p><p>I couldn't reply. I registered that she hadn’t apologized.</p><p>“You found my sheet, didn’t you? I saw the ambition edit.”</p><p><span>Then I remembered way back at the beginning when I’d changed the </span><em>Ambition</em><span> rating to </span><strong>10</strong><span>. It had been a mistake, one I wouldn’t make now. I nodded.</span></p><p>She shrugged. “I like being real with myself about where I’m at. So I do those sheets. I’m sorry you saw it. But I can tell you’ve been working on things. I’ve admired it. The sex is great. I don’t think you’re a placeholder anymore.”</p><p>I felt several paths in front of me. I almost told her I needed a better apology. I almost told her I had hidden how much I had changed, I was basically a 10 in everything now. I almost told her she had hurt me more than she ever could have imagined.</p><p>This is what I did instead: I told her I was sorry she needed that. Then I kissed her cheek like the moon kisses the sun at the end of an eclipse. Then I left. Then I was gone.&nbsp;</p><p>It was not sweet. It was not the crowning achievement of my winter. It was just done.&nbsp;</p><p>That night I got coffee with my new friend. When her hair fell in front of her eyes, I moved it back. When she asked if everything was okay and I told her it was good now, I could feel the warmth of her happiness radiate across the table. When the date ended, I asked to see her again the next day. We could go to the ceramics museum down the street and I’d buy her blue china from the gift store where the old ladies slowly wrap and tie in layers and layers of bubble wrap. We could walk through the Annex and pick whichever restaurant was newest. We could go through High Park, through the zoo and meet the reindeer, who make me think of Christmas, and the peacocks, who make me think of the sun.&nbsp;</p><p>We decided to do it all. We were happy. I never thought about revenge again.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Three gaming-focused Linux operating systems beat Windows 11 in gaming benchmark (109 pts)]]></title>
            <link>https://www.tomshardware.com/software/linux/three-gaming-focused-linux-operating-systems-beat-windows-11-in-gaming-benchmarks</link>
            <guid>38510805</guid>
            <pubDate>Sun, 03 Dec 2023 21:11:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/software/linux/three-gaming-focused-linux-operating-systems-beat-windows-11-in-gaming-benchmarks">https://www.tomshardware.com/software/linux/three-gaming-focused-linux-operating-systems-beat-windows-11-in-gaming-benchmarks</a>, See on <a href="https://news.ycombinator.com/item?id=38510805">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" alt="Gamer sits in front of a monitor playing a game" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg"><source type="image/jpeg" alt="Gamer sits in front of a monitor playing a game" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg"><img src="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-320-80.jpg" alt="Gamer sits in front of a monitor playing a game" onerror="if(this.src &amp;&amp; this.src.indexOf('missing-image.svg') !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/rNHQQbdNyBuLUPCQYjud9W.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Shutterstock)</span>
</figcaption>
</div>

<div id="article-body">
<p>Linux gaming performance has been improving for years, but how good is it? <a data-analytics-id="inline-link" href="https://www.computerbase.de/2023-12/welche-linux-distribution-zum-spielen/2/" data-url="https://www.computerbase.de/2023-12/welche-linux-distribution-zum-spielen/2/">ComputerBase benchmarked</a> three different Linux operating systems against <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/windows-11" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/windows-11">Windows 11</a> in several gaming <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/benchmark" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/benchmark">benchmarks</a> and found all three were able to outperform <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/microsoft" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/microsoft">Microsoft</a>'s latest OS. On top of this, all three Linux variants were able to accomplish their impressive performance runs while running all benchmarked titles through <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/valve" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/valve">Valve</a>'s Proton compatibility layer.</p><p>The three Linux operating systems ComputerBase benchmarked are Arch Linux, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/pop-os-update-22-04" data-before-rewrite-localise="https://www.tomshardware.com/news/pop-os-update-22-04">Pop!_OS</a> and <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/cyberpunk-2077-31-percent-faster-on-amd-in-linux-vs-windows-11" data-before-rewrite-localise="https://www.tomshardware.com/news/cyberpunk-2077-31-percent-faster-on-amd-in-linux-vs-windows-11">Nobara OS</a>. Arch is the most "Linux-like" of the three featuring, a minimalistic default installation that requires user customization to get the most out of it. But at the same time, it also features some of the fastest software and OS updates of any Linux distro. If you didn't know, Valve's SteamOS 3, which powers the Steam Deck, is based on Arch Linux.</p><p>The other two Linux distros tested are far more friendly to Linux beginners, featuring default installations that come with loads of applications and plugins, with several designed for gaming. PoP!_OS is a Ubuntu-based operating system built by System76 that features Steam, Proton, and Lutris right out of the box. Nobara OS is a modified version of Fedora Linux that's designed specifically for gamers, featuring OBS, Wine and third-party Nvidia <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/drivers" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/drivers">drivers</a> (to name a few features) from the get-go.</p><p>ComputerBase's testing was done on an all-AMD test rig, featuring a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/amd-ryzen-7-5800x-zen-3-review" data-before-rewrite-localise="https://www.tomshardware.com/reviews/amd-ryzen-7-5800x-zen-3-review">Ryzen 7 5800X</a> (non-3D) and a <a data-analytics-id="inline-link" href="https://www.tomshardware.com/reviews/amd-radeon-rx-6700-xt-review" data-before-rewrite-localise="https://www.tomshardware.com/reviews/amd-radeon-rx-6700-xt-review">Radeon RX 6700 XT</a>. Games tested included <em>Cyberpunk 2077, Forspoken, Rachet &amp; Clank, Starfiel</em>d and <em>The Talos Principle II</em>. To reiterate: All of these games are Windows specific, and were run through Valve's Proton compatibility layer on their respective Linux operating systems.</p><p>Computerbase found that all three Linux operating systems were able to beat Windows 11 by a slim margin. Nobara OS took the top spot, achieving 100 fps flat, while Arch Linux and POP!_OS took second and third place, respectively, achieving 99 fps and 95 fps. Windows 11 took the last position, with an average frame rate of 94 fps (1 shy of POP!_OS).&nbsp;</p><p>In the pre-game analysis, the rankings were less consistent, but in three of the games (<em>Cyberpunk 2077, Forespoken and The Talos Principle II)</em> Nobara OS beat the other three contenders, and in <em>Starfield,</em> Arch Linux came out on top. The only game where Windows 11 came in first was <em>Rachet &amp; Clank Rift Apart</em>.</p><p>Similar to the overall results, the frame rate difference between each OS was very small, with most titles having an fps delta of less than eight between the fastest and slowest operating systems. The only exception was <em>Cyberpunk 2077</em> which had a substantially larger 17 fps gap between the slowest and fastest OS. Surprisingly, the slowest OS was POP!_OS, which achieved 72.7 fps in that title. Nobara, the highest performing OS, achieved 89.6 &nbsp;in <em>Cyberpunk</em>, while Windows 11 landed third, with an average frame rate of 82.3.</p><div><p>ComputerBase' gaming benchmarks show how good Linux gaming performance has become. Even with the additional overhead of Valve's Proton compatibility layer, these three Linux operating systems still managed to beat or achieve very similar performance to Windows 11's native performance.</p><p>

There's no doubt, then, that Linux is now a highly competitive gaming platform that can play Windows games (thanks to Proton) without sacrificing any serious performance penalties – at last on AMD hardware. It would be interesting to see how close to these tests the results would be with a comparable Intel / Nvidia test system.</p></div>
</div>
<div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-Tf72sJMo35SS3u3sjMNyXN"><section><p>Join the experts who read Tom's Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We'll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div>
<div id="slice-container-authorBio-Tf72sJMo35SS3u3sjMNyXN"><p>Aaron Klotz is a freelance writer for Tom’s Hardware US, covering news topics related to computer hardware such as CPUs, and graphics cards.</p></div>



<!-- Drop in a standard article here maybe? -->


</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let's learn how modern JavaScript frameworks work by building one (466 pts)]]></title>
            <link>https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/</link>
            <guid>38510209</guid>
            <pubDate>Sun, 03 Dec 2023 20:00:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/">https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/</a>, See on <a href="https://news.ycombinator.com/item?id=38510209">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<p><img data-attachment-id="13496" data-permalink="https://nolanlawson.com/2023/12/02/lets-learn-how-modern-javascript-frameworks-work-by-building-one/js-diy/" data-orig-file="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png" data-orig-size="2600,2600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="js-diy" data-image-description="" data-image-caption="" data-medium-file="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=300" data-large-file="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=570" src="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=570&amp;h=570" alt="Hand-drawn looking JavaScript logo saying DIY JS" srcset="https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=455 455w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=910 910w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=150 150w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=300 300w, https://nolanwlawson.files.wordpress.com/2023/12/js-diy.png?w=768 768w" sizes="(max-width: 455px) 100vw, 455px"></p>
<p>In my day job, I work on a JavaScript framework (<a href="https://lwc.dev/">LWC</a>). And although I’ve been working on it for almost three years, I still feel like a dilettante. When I read about what’s going on in the larger framework world, I often feel overwhelmed by all the things I don’t know.</p>
<p>One of the best ways to learn how something works, though, is to build it yourself. And plus, we gotta keep those <a href="https://dayssincelastjavascriptframework.com/">“days since last JavaScript framework”</a> memes going. So let’s write our own modern JavaScript framework!</p>
<h2>What is a “modern JavaScript framework”?</h2>
<p>React is a great framework, and I’m not here to dunk on it. But for the purposes of this post, “modern JavaScript framework” means “a framework from the post-React era” – i.e. <a href="https://lit.dev/">Lit</a>, <a href="https://www.solidjs.com/">Solid</a>, <a href="https://svelte.dev/">Svelte</a>, <a href="https://vuejs.org/">Vue</a>, etc.</p>
<p>React has dominated the frontend landscape for so long that every newer framework has grown up in its shadow. These frameworks were all heavily inspired by React, but they’ve evolved away from it in surprisingly similar ways. And although React itself has continued innovating, I find that the post-React frameworks are more similar to each other than to React nowadays.</p>
<p>To keep things simple, I’m also going to avoid talking about server-first frameworks like <a href="https://astro.build/">Astro</a>, <a href="https://markojs.com/">Marko</a>, and <a href="https://qwik.builder.io/docs/">Qwik</a>. These frameworks are excellent in their own way, but they come from a slightly different intellectual tradition compared to the client-focused frameworks. So for this post, let’s only talk about client-side rendering.</p>
<h2>What sets modern frameworks apart?</h2>
<p>From my perspective, the post-React frameworks have all converged on the same foundational ideas:</p>
<ol>
<li>Using reactivity (e.g. <a href="https://dev.to/this-is-learning/the-evolution-of-signals-in-javascript-8ob">signals</a>) for DOM updates.</li>
<li>Using cloned templates for DOM rendering.</li>
<li>Using modern web APIs like <code>&lt;template&gt;</code> and <code>Proxy</code>, which make all of the above easier.</li>
</ol>
<p>Now to be clear, these frameworks differ a lot at the micro level, and in how they handle things like web components, compilation, and user-facing APIs. <a href="https://github.com/sveltejs/svelte/issues/2626#issuecomment-489894747">Not all frameworks</a> even use <code>Proxy</code>s. But broadly speaking, most framework authors seem to agree on the above ideas, or they’re moving in that direction.</p>
<p>So for our own framework, let’s try to do the bare minimum to implement these ideas, starting with reactivity.</p>
<h2>Reactivity</h2>
<p>It’s often said that <a href="https://dev.to/this-is-learning/how-react-isn-t-reactive-and-why-you-shouldn-t-care-152m">“React is not reactive”</a>. What this means is that React has a more pull-based rather than a push-based model. To grossly oversimplify things: React assumes that your entire virtual DOM tree needs to be rebuilt from scratch, and the only way to prevent these updates is to implement <code>useMemo</code> (or in the old days, <code>shouldComponentUpdate</code>).</p>
<p>Using a virtual DOM mitigates some of the cost of the “blow everything away and start from scratch” strategy, but it doesn’t fully solve it. And asking developers to write the correct memo code is a losing battle. (See <a href="https://react.dev/blog/2023/03/22/react-labs-what-we-have-been-working-on-march-2023">React Forget</a> for an ongoing attempt to solve this.)</p>
<p>Instead, modern frameworks use a push-based reactive model. In this model, individual parts of the component tree subscribe to state updates and only update the DOM when the relevant state changes. This prioritizes a “performant by default” design in exchange for some upfront bookkeeping cost (especially in terms of memory) to keep track of which parts of the state are tied to which parts of the UI.</p>
<p>Note that this technique is not necessarily incompatible with the virtual DOM approach: tools like <a href="https://preactjs.com/guide/v10/signals/">Preact Signals</a> and <a href="https://million.dev/">Million</a> show that you can have a hybrid system. This is useful if your goal is to keep your existing virtual DOM framework (e.g. React) but to selectively apply the push-based model for more performance-sensitive scenarios.</p>
<p>For this post, I’m not going to rehash the details of signals themselves, or subtler topics like <a href="https://dev.to/ryansolid/a-hands-on-introduction-to-fine-grained-reactivity-3ndf">fine-grained reactivity</a>, but I am going to assume that we’ll use a reactive system.</p>
<h2>Cloning DOM trees</h2>
<p>For a long time, the collective wisdom in JavaScript frameworks was that the fastest way to render the DOM is to create and mount each DOM node individually. In other words, you use APIs like <code>createElement</code>, <code>setAttribute</code>, and <code>textContent</code> to build the DOM piece-by-piece:</p>
<pre title="">const div = document.createElement('div')
div.setAttribute('class', 'blue')
div.textContent = 'Blue!'
</pre>
<p>One alternative is to just shove a big ol’ HTML string into <code>innerHTML</code> and let the browser parse it for you:</p>
<pre title="">const container = document.createElement('div')
container.innerHTML = `
  &lt;div class="blue"&gt;Blue!&lt;/div&gt;
`
</pre>
<p>This naïve approach has a big downside: if there is any dynamic content in your HTML (for instance, <code>red</code> instead of <code>blue</code>), then you would need to parse HTML strings over and over again. Plus, you are blowing away the DOM with every update, which would reset state such as the <code>value</code> of <code>&lt;input&gt;</code>s.</p>

<p>At some point, though, folks figured out that parsing the HTML <em>once</em> and then calling <code>cloneNode(true)</code> on the whole thing is pretty danged fast:</p>
<pre title="">const template = document.createElement('template')
template.innerHTML = `
  &lt;div class="blue"&gt;Blue!&lt;/div&gt;
`
template.content.cloneNode(true) // this is fast!
</pre>
<p>Here I’m using a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/template"><code>&lt;template&gt;</code></a> tag, which has the advantage of creating “inert” DOM. In other words, things like <code>&lt;img&gt;</code> or <code>&lt;video autoplay&gt;</code> don’t automatically start downloading anything.</p>
<p>How fast is this compared to manual DOM APIs? To demonstrate, here’s <a href="https://github.com/nolanlawson/template-clone-demo">a small benchmark</a>. <a href="https://github.com/google/tachometer">Tachometer</a> reports that the cloning technique is about 50% faster in Chrome, 15% faster in Firefox, and 10% faster in Safari. (This will vary based on DOM size and number of iterations, but you get the gist.)</p>
<p>What’s interesting  is that <code>&lt;template&gt;</code> is a new-ish browser API, not available in IE11, and originally designed for web components. Somewhat ironically, this technique is now used in a variety of JavaScript frameworks, regardless of whether they use web components or not.</p>

<p>There is one major challenge with this technique, which is how to efficiently update dynamic content without blowing away DOM state. We’ll cover this later when we build our toy framework.</p>
<h2>Modern JavaScript APIs</h2>
<p>We’ve already encountered one new API that helps a lot, which is <code>&lt;template&gt;</code>. Another one that’s steadily gaining traction is <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Proxy"><code>Proxy</code></a>, which can make building reactivity system much simpler.</p>
<p>When we build our toy example, we’ll also use <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates">tagged template literals</a> to create an API like this:</p>
<pre title="">const dom = html`
  &lt;div&gt;Hello ${ name }!&lt;/div&gt;
`
</pre>
<p>Not all frameworks use this tool, but notable ones include Lit, <a href="https://viperhtml.js.org/hyper.html">HyperHTML</a>, and <a href="https://www.arrow-js.com/">ArrowJS</a>. Tagged template literals can make it much simpler to build ergonomic HTML templating APIs without needing a compiler.</p>
<h2>Step 1: building reactivity</h2>
<p>Reactivity is the foundation upon which we'll build the rest of the framework. Reactivity will define how state is managed, and how the DOM updates when state changes.</p>
<p>Let's start with some <a href="https://nobackend.org/2013/05/welcome-to-noBackend.html">"dream code"</a> to illustrate what we want:</p>
<pre title="">const state = {}

state.a = 1
state.b = 2

createEffect(() =&gt; {
  state.sum = state.a + state.b
})
</pre>
<p>Basically, we want a “magic object” called <code>state</code>, with two props: <code>a</code> and <code>b</code>. And whenever those props change, we want to set <code>sum</code> to be the sum of the two.</p>
<p>Assuming we don’t know the props in advance (or have a compiler to determine them), a plain object will not suffice for this. So let’s use a <code>Proxy</code>, which can react whenever a new value is set:</p>
<pre title="">const state = new Proxy({}, {
  get(obj, prop) {
    onGet(prop)
    return obj[prop]
  },
  set(obj, prop, value) {
    obj[prop] = value
    onSet(prop, value)
    return true
  }
})
</pre>
<p>Right now, our <code>Proxy</code> doesn’t do anything interesting, except give us some <code>onGet</code> and <code>onSet</code> hooks. So let’s make it flush updates after a microtask:</p>
<pre title="">let queued = false

function onSet(prop, value) {
  if (!queued) {
    queued = true
    queueMicrotask(() =&gt; {
      queued = false
      flush()
    })
  }
}
</pre>

<p>Why flush updates? Mostly because we don’t want to run too many computations. If we update whenever both <code>a</code> and <code>b</code> change, then we’ll uselessly compute the <code>sum</code> twice. By coalescing the flush into a single microtask, we can be much more efficient.</p>
<p>Next, let’s make <code>flush</code> update the sum:</p>
<pre title="">function flush() {
  state.sum = state.a + state.b
}
</pre>
<p>This is great, but it’s not yet our “dream code.” We’ll need to implement <code>createEffect</code> so that the <code>sum</code> is computed only when <code>a</code> and <code>b</code> change (and not when something else changes!).</p>
<p>To do this, let’s use an object to keep track of which effects need to be run for which props:</p>
<pre title="">const propsToEffects = {}
</pre>
<p>Next comes the crucial part! We need to make sure that our effects can <em>subscribe</em> to the right props. To do so, we’ll run the effect, note any <code>get</code> calls it makes, and create a mapping between the prop and the effect.</p>
<p>To break it down, remember our “dream code” is:</p>
<pre title="">createEffect(() =&gt; {
  state.sum = state.a + state.b
})
</pre>
<p>When this function runs, it calls two getters: <code>state.a</code> and <code>state.b</code>. These getters should trigger the reactive system to notice that the function relies on the two props.</p>
<p>To make this happen, we’ll start with a simple global to keep track of what the “current” effect is:</p>
<pre title="">let currentEffect
</pre>
<p>Then, the <code>createEffect</code> function will set this global before calling the function:</p>
<pre title="">function createEffect(effect) {
  currentEffect = effect
  effect()
  currentEffect = undefined
}
</pre>
<p>The important thing here is that the effect is <em>immediately</em> invoked, with the <code>currentEffect</code> being set globally in advance. This is how we can track whatever getters the effect might be calling.</p>
<p>Now, we can implement the <code>onGet</code> in our <code>Proxy</code>, which will set up the mapping between the global <code>currentEffect</code> and the property:</p>
<pre title="">function onGet(prop) {
  const effects = propsToEffects[prop] ?? 
      (propsToEffects[prop] = [])
  effects.push(currentEffect)
}
</pre>
<p>After this runs once, <code>propsToEffects</code> should look like this:</p>
<pre title="">{
  "a": [theEffect],
  "b": [theEffect]
}
</pre>
<p>…where <code>theEffect</code> is the “sum” function we want to run.</p>
<p>Next, our <code>onSet</code> should add any effects that need to be run to a <code>dirtyEffects</code> array:</p>
<pre title="">const dirtyEffects = []

function onSet(prop, value) {
  if (propsToEffects[prop]) {
    dirtyEffects.push(...propsToEffects[prop])
    // ...
  }
}
</pre>
<p>At this point, we have all the pieces in place for <code>flush</code> to call all the <code>dirtyEffects</code>:</p>
<pre title="">function flush() {
  while (dirtyEffects.length) {
    dirtyEffects.shift()()
  }
}
</pre>
<p>Putting it all together, we now have a fully functional reactivity system! You can play around with it yourself and try setting <code>state.a</code> and <code>state.b</code> in the DevTools console – the <code>state.sum</code> will update whenever either one changes.</p>

<p>Now, there are plenty of advanced cases that we’re <em>not</em> covering here:</p>
<ol>
<li>Using <code>try</code>/<code>catch</code> in case an effect throws an error</li>
<li>Avoiding running the same effect twice</li>
<li>Preventing infinite cycles</li>
<li>Subscribing effects to new props on subsequent runs (e.g. if certain getters are only called in an <code>if</code> block)</li>
</ol>
<p>However, this is more than enough for our toy example. Let’s move on to DOM rendering.</p>
<h2>Step 2: DOM rendering</h2>
<p>We now have a functional reactivity system, but it’s essentially “headless.” It can track changes and compute effects, but that’s about it.</p>
<p>At some point, though, our JavaScript framework needs to actually render some DOM to the screen. (That’s kind of the whole point.)</p>
<p>For this section, let’s forget about reactivity for a moment and imagine we’re just trying to build a function that can 1) build a DOM tree, and 2) update it efficiently.</p>
<p>Once again, let’s start off with some dream code:</p>
<pre title="">function render(state) {
  return html`
    &lt;div class="${state.color}"&gt;${state.text}&lt;/div&gt;
  `
}
</pre>
<p>As I mentioned, I’m using tagged template literals, ala Lit, because I found them to be a nice way to write HTML templates without needing a compiler. (We’ll see in a moment why we might actually <em>want</em> a compiler instead.)</p>
<p>We’re re-using our <code>state</code> object from before, this time with a <code>color</code> and <code>text</code> property. Maybe the state is something like:</p>
<pre title="">state.color = 'blue'
state.text = 'Blue!'
</pre>
<p>When we pass this <code>state</code> into <code>render</code>, it should return the DOM tree with the state applied:</p>
<pre title="">&lt;div class="blue"&gt;Blue!&lt;/div&gt;
</pre>
<p>Before we go any further, though, we need a quick primer on tagged template literals. Our <code>html</code> tag is just a function that receives two arguments: the <code>tokens</code> (array of static HTML strings) and <code>expressions</code> (the evaluated dynamic expressions):</p>
<pre title="">function html(tokens, ...expressions) {
}
</pre>
<p>In this case, the <code>tokens</code> are (whitespace removed):</p>
<pre title="">[
  "&lt;div class=\"",
  "\"&gt;",
  "&lt;/div&gt;"
]
</pre>
<p>And the <code>expressions</code> are:</p>
<pre title="">[
  "blue",
  "Blue!"
]
</pre>
<p>The <code>tokens</code> array will always be exactly 1 longer than the <code>expressions</code> array, so we can trivially zip them up together:</p>
<pre title="">const allTokens = tokens
    .map((token, i) =&gt; (expressions[i - 1] ?? '') + token)
</pre>
<p>This will give us an array of strings:</p>
<pre title="">[
  "&lt;div class=\"",
  "blue",
  "\"&gt;",
  "Blue!",
  "&lt;/div&gt;"
]
</pre>
<p>We can join these strings together to make our HTML:</p>
<pre title="">const htmlString = allTokens.join('')
</pre>
<p>And then we can use <code>innerHTML</code> to parse it into a <code>&lt;template&gt;</code>:</p>
<pre title="">function parseTemplate(htmlString) {
  const template = document.createElement('template')
  template.innerHTML = htmlString
  return template
}
</pre>
<p>This template contains our inert DOM (technically a <a href="https://developer.mozilla.org/en-US/docs/Web/API/DocumentFragment"><code>DocumentFragment</code></a>), which we can clone at will:</p>
<pre title="">const cloned = template.content.cloneNode(true)
</pre>
<p>Of course, parsing the full HTML whenever the <code>html</code> function is called would not be great for performance. Luckily, tagged template literals have a built-in feature that will help out a lot here.</p>
<p>For every unique usage of a tagged template literal, the <code>tokens</code> array is <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Template_literals#tagged_templates">always the same</a> whenever the function is called – in fact, it’s the exact same object!</p>
<p>For example, consider this case:</p>
<pre title="">function sayHello(name) {
  return html`&lt;div&gt;Hello ${name}&lt;/div&gt;`
}
</pre>
<p>Whenever <code>sayHello</code> is called, the <code>tokens</code> array will always be identical:</p>
<pre title="">[
  "&lt;div&gt;Hello ",
  "&lt;/div&gt;"
]
</pre>
<p>The only time <code>tokens</code> will be different is for completely different locations of the tagged template:</p>
<pre title="">html`&lt;div&gt;&lt;/div&gt;`
html`&lt;span&gt;&lt;/span&gt;` // Different from above
</pre>
<p>We can use this to our advantage by using a <code>WeakMap</code> to keep a mapping of the <code>tokens</code> array to the resulting <code>template</code>:</p>
<pre title="">const tokensToTemplate = new WeakMap()

function html(tokens, ...expressions) {
  let template = tokensToTemplate.get(tokens)
  if (!template) {
    // ...
    template = parseTemplate(htmlString)
    tokensToTemplate.set(tokens, template)
  }
  return template
}
</pre>
<p>This is kind of a mind-blowing concept, but the uniqueness of the <code>tokens</code> array essentially means that we can ensure that each call to <code>html`...`</code> only parses the HTML once.</p>
<p>Next, we just need a way to update the cloned DOM node with the <code>expressions</code> array (which is likely to be different every time, unlike <code>tokens</code>).</p>
<p>To keep things simple, let’s just replace the <code>expressions</code> array with a placeholder for each index:</p>
<pre title="">const stubs = expressions.map((_, i) =&gt; `__stub-${i}__`)
</pre>
<p>If we zip this up like before, it will create this HTML:</p>
<pre title="">&lt;div class="__stub-0__"&gt;
  __stub-1__
&lt;/div&gt;
</pre>
<p>We can write a simple string replacement function to replace the stubs:</p>
<pre title="">function replaceStubs (string) {
  return string.replaceAll(/__stub-(\d+)__/g, (_, i) =&gt; (
    expressions[i]
  ))
}
</pre>
<p>And now whenever the <code>html</code> function is called, we can clone the template and update the placeholders:</p>
<pre title="">const element = cloned.firstElementChild
for (const { name, value } of element.attributes) {
  element.setAttribute(name, replaceStubs(value))
}
element.textContent = replaceStubs(element.textContent)
</pre>

<p>Now, this is still not terribly efficient – notably, we are updating <code>textContent</code> and attributes that don’t necessarily need to be updated. But for our toy framework, this is good enough.</p>
<p>We can test it out by rendering with different <code>state</code>:</p>
<pre title="">document.body.appendChild(render({ color: 'blue', text: 'Blue!' }))
document.body.appendChild(render({ color: 'red', text: 'Red!' }))
</pre>
<p>This works!</p>

<h2>Step 3: combining reactivity and DOM rendering</h2>
<p>Since we already have a <code>createEffect</code> from the rendering system above, we can now combine the two to update the DOM based on the state:</p>
<pre title="">const container = document.getElementById('container')

createEffect(() =&gt; {
  const dom = render(state)
  if (container.firstElementChild) {
    container.firstElementChild.replaceWith(dom)
  } else {
    container.appendChild(dom)
  }
})
</pre>
<p>This actually works! We can combine this with the “sum” example from the reactivity section by merely creating another effect to set the <code>text</code>:</p>
<pre title="">createEffect(() =&gt; {
  state.text = `Sum is: ${state.sum}`
})
</pre>
<p>This renders “Sum is 3”:</p>

<p>You can play around with this toy example. If you set <code>state.a = 5</code>, then the text will automatically update to say “Sum is 7.”</p>
<h2>Next steps</h2>
<p>There are lots of improvements we could make to this system, especially the DOM rendering bit.</p>
<p>Most notably, we are missing a way to update content for elements inside a deep DOM tree, e.g.:</p>
<pre title="">&lt;div class="${color}"&gt;
  &lt;span&gt;${text}&lt;/span&gt;
&lt;/div&gt;
</pre>
<p>For this, we would need a way to uniquely identify every element inside of the template. There are lots of ways to do this:</p>
<ol>
<li>Lit, when parsing HTML, uses a system of <a href="https://github.com/lit/lit/blob/1af7991c27456c7e6073a3ee6f18f102c2adc026/packages/lit-html/src/lit-html.ts#L779-L857">regexes and character matching</a> to determine whether a placeholder is within an attribute or text content, plus the index of the target element (in depth-first <a href="https://developer.mozilla.org/en-US/docs/Web/API/TreeWalker"><code>TreeWalker</code></a> order).</li>
<li>Frameworks like Svelte and Solid have the luxury of parsing the entire HTML template during compilation, which provides the same information. They also generate code that calls <code>firstChild</code> and <code>nextSibling</code> to traverse the DOM to find the element to update.</li>
</ol>

<p>Whether we decided to do Lit-style client-side parsing or Svelte/Solid-style compile-time parsing, what we want is some kind of mapping like this:</p>
<pre title="">[
  {
    elementIndex: 0, // &lt;div&gt; above
    attributeName: 'class',
    stubIndex: 0 // index in expressions array
  },
  {
    elementIndex: 1 // &lt;span&gt; above
    textContent: true,
    stubIndex: 1 // index in expressions array
  }
]
</pre>
<p>These bindings would tell us exactly which elements need to be updated, which attribute (or <code>textContent</code>) needs to be set, and where to find the <code>expression</code> to replace the stub.</p>
<p>The next step would be to avoid cloning the template every time, and to just directly update the DOM based on the <code>expressions</code>. In other words, we not only want to parse once – we want to only clone and set up the bindings once. This would reduce each subsequent update to the bare minimum of <code>setAttribute</code> and <code>textContent</code> calls.</p>

<p>Another interesting pattern to implement would be iterations (or repeaters), which come with their own set of challenges, like reconciling lists between updates and handling “keys” for efficient replacement.</p>
<p>I’m tired, though, and this blog post has gone on long enough. So I leave the rest as an exercise to the reader!</p>
<h2>Conclusion</h2>
<p>So there you have it. In the span of one (lengthy) blog post, we’ve implemented our very own JavaScript framework. Feel free to use this as the foundation for your brand-new JavaScript framework, to release to the world and enrage the Hacker News crowd.</p>
<p>Personally I found this project very educational, which is partly why I did it in the first place. I was also looking to replace the current framework for <a href="https://github.com/nolanlawson/emoji-picker-element/">my emoji picker component</a> with a smaller, more custom-built solution. In the process, I managed to write <a href="https://github.com/nolanlawson/emoji-picker-element/pull/381">a tiny framework</a> that passes all the existing tests and is ~6kB smaller than the current implementation, which I’m pretty proud of.</p>
<p>In the future, I think it would be neat if browser APIs were full-featured enough to make it even easier to build a custom framework. For example, the <a href="https://github.com/WICG/webcomponents/blob/gh-pages/proposals/DOM-Parts.md">DOM Part API proposal</a> would take out a lot of the drudgery of the DOM parsing-and-replacement system we built above, while also opening the door to potential browser performance optimizations. I could also imagine (with some wild gesticulation) that an extension to <code>Proxy</code> could make it easier to build a full reactivity system without worrying about details like flushing, batching, or cycle detection.</p>
<p>If all those things were in place, then you could imagine effectively having a “Lit in the browser,” or at least a way to quickly build your own “Lit in the browser.” In the meantime, I hope that this small exercise helped to illustrate some of the things framework authors think about, and some of the machinery under the hood of your favorite JavaScript framework.</p>
<p><em>Thanks to <a href="https://pm.dartus.fr/">Pierre-Marie Dartus</a> for feedback on a draft of this post.</em></p>
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why does sleep become more elusive as we age? (148 pts)]]></title>
            <link>https://www.salon.com/2023/12/02/why-does-sleep-become-more-elusive-as-we-age-it-has-to-do-with-shifts-in-sleep-architecture/</link>
            <guid>38509956</guid>
            <pubDate>Sun, 03 Dec 2023 19:31:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.salon.com/2023/12/02/why-does-sleep-become-more-elusive-as-we-age-it-has-to-do-with-shifts-in-sleep-architecture/">https://www.salon.com/2023/12/02/why-does-sleep-become-more-elusive-as-we-age-it-has-to-do-with-shifts-in-sleep-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=38509956">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
								
																	
																
								<p>In his later life, my father-in-law routinely woke up for the day at 3 a.m. He'd become such an early bird that he morphed into a night owl, a man resigned to a post-retirement inability to clock in more than four or five hours of rest. I can recall taking his routines as a grim prophecy. And when a few years later I found myself struggling with brutal bouts of insomnia, I wondered if, along with laugh lines and macular degeneration, sleeplessness was an inevitable part of growing older for me, too.</p>

<p>There is a persistent folk wisdom that older people simply don't need as much sleep — an idea likely borne out of the idea that as our lifestyles ostensibly become less active, our requirements for the reparative benefits of rest diminish. As recently as 2008, a report in <a href="https://www.sciencedaily.com/releases/2008/07/080724123255.htm" target="_blank">Current Biology</a> found that in one experiment, older subjects got 1.5 hours less sleep on average than their younger counterparts. "The most parsimonious explanation for our results," researcher Elizabeth Klerman of Brigham and Women's Hospital &amp; Harvard Medical School said at the time, "is that older people need less sleep."</p>

<p>But what we <em>need</em> and what we actually <em>get </em>are two entirely different entities — and we are in the midst of a sleep shortage that's affecting Americans across all generational lines. The CDC notes that "<a href="https://www.cdc.gov/sleep/index.html#:~:text=A%20third%20of%20US%20adults,that%20threaten%20our%20nation's%20health." target="_blank">A third of US adults report that they usually get less than the recommended amount of sleep</a>." It's <a href="https://www.salon.com/2023/11/11/sleep-the-bedrock-of-public-health-is-eroding-this-is-how-experts-say-we-can-fix-it/" target="_blank">a crisis that can wreak havoc</a> on our physical and mental health, with sleep deprivation contributing to obesity, hypertension, diabetes, depression and stroke. And even accounting for fluctuations among different age populations, <a href="https://www.nhlbi.nih.gov/health/sleep/how-much-sleep" target="_blank">most adults need between 7 and 9 hours of sleep per night</a>. The key is just staying in a healthy range.&nbsp;</p>
<p>"A third of US adults report that they usually get less than the recommended amount of sleep."</p>
<p><a href="https://www.columbiapsychiatry.org/research-labs/sultan-lab-mental-health-informatics" target="_blank">Dr. Ryan Sultan</a>, a board-certified psychiatrist, therapist, researcher and professor at Columbia University, says that "As we age, the amount of sleep needed tends to decrease. Older adults may be well-rested and alert after 6 to 7 hours."</p>
<p>My late father-in-law may not have had much steam in him after dinnertime, but his days were as active and engaged as his solitary predawn hours. Sultan says it's just about paying attention to overall health patterns and any changes that feel off. "In my clinical experience," he says, "I have observed that older adults often face unique challenges, such as medical conditions or medications affecting sleep. Addressing these factors with a healthcare professional is crucial for developing a tailored approach to sleep improvement."</p>
<p>As Sultan puts it, "The concept of normal sleep does change as we age, and recognizing these shifts is essential for maintaining optimal health."</p>
<p>"Generally speaking, sleep ability declines as we age as the mechanisms that control sleep become less robust over time."</p>
<p>The real culprit to watch out for as we age isn't the amount of sleep, but quality of it. Older people have unique vulnerabilities around getting a deep, steady rest. A 2017 analysis in the journal <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5841578/" target="_blank">Sleep Medicine Clinics</a> explained how so-called "sleep architecture" can change with age, including "advanced sleep timing, shortened nocturnal sleep duration, increased frequency of daytime naps, increased number of nocturnal awakenings and time spent awake during the night, decreased slow wave sleep, and other changes."</p>
<p>Auckland sleep psychologist <a href="https://thebettersleepclinic.com/dan-ford-sleep-psychologist%C2%A0" target="_blank">Dan Ford, clinical director of the Better Sleep Clinic</a>, puts it simply, "Generally speaking, sleep ability declines as we age as the mechanisms that control sleep become less robust over time." But nothing is set in stone. He adds, "Healthy older adults do not necessarily show these changes in their sleep parameters."</p>
<p>Why do those gorgeous, lengthy sleeps of our younger years become so elusive as we age? There are a whole litany of reasons. <a href="https://www.salon.com/2022/11/13/dont-fear-the-hot-flash-menopause-isnt-a-disease-but-it-is-a-health-issue-we-need-to-talk-about/" target="_blank">There's menopause</a>, with its discomforts and night sweats. Bathroom issues can likewise keep a person of any gender up and down all night long. Changes in the urinary tract, along with other factors like bladder obstruction, make nocturia (frequent nighttime urination) <a href="https://pubmed.ncbi.nlm.nih.gov/10641954/#:~:text=In%20addition%2C%20aging%20is%20associated,nocturia%20as%20a%20prominent%20symptom." target="_blank">far more common </a>in adults over the age of 60.</p>
<p>There are other physical factors as well — the National Council on Aging estimates that "<a href="https://www.ncoa.org/article/sleep-apnea-in-older-adults-diagnosis-and-treatment-options" target="_blank">56% of people</a> age 65 and older have a high risk of developing obstructive sleep apnea." Our <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5272178/" target="_blank">circadian rhythms also change as we age</a>, edging us to what can make us feel like we're living in a different time zone from our family and friends. And then there are the mental health issues. Grief, loneliness, financial loss and other stressors can wreck a good night's rest, and the symptoms of <a href="https://www.cdc.gov/aging/depression/index.html#:~:text=How%20Many%20Older%20Adults%20are,11.5%25%20in%20older%20hospitalized%20patients." target="_blank">depression and anxiety often go undiagnosed</a>. A 2018 study on insomnia in the Journal of Clinical Sleep Medicine found that "<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5991956/" target="_blank">As many as 50% of older adults complain about difficulty initiating or maintaining sleep</a>."</p>
<hr>
<p><strong><em>Want more health and science stories in your inbox? Subscribe to Salon's weekly newsletter <a href="https://salon.us8.list-manage.com/subscribe?u=71cb3e8a6e9639c81023cd427&amp;id=5deda2aaa7">Lab Notes</a>.</em></strong></p>
<hr>
<p>So if you're noticing that your nights now typically involve periods of wakefulness, is playing a little catch up when possible during the day a good idea?</p>
<p>"Napping can be a helpful strategy for older adults," says Dr. Ryan Sultan, "but the timing and duration matter. Short naps of around 20 to 30 minutes can boost alertness without interfering with nighttime sleep. However, extended or late-afternoon naps might disrupt the sleep-wake cycle, making it harder to fall asleep at night." Mileage can vary even there, though — I have a friend in his late 50s who regularly konks out before making dinner. He calls it a "nappetizer."</p>
<p>For those who have a hard time resisting longer naps, <a href="https://www.emotionstherapycalgary.ca/psychologist-calgary-rod-mitchell" target="_blank">Rod Mitchell</a>, a Calgary psychologist with expertise in cognitive behavioral therapy for insomnia, recommends offsetting grogginess with a "coffee nap." He says, "Combine a small, controlled intake of caffeine (such as a half cup of coffee) followed by a short, 20-minute nap. This method can enhance the restorative effect of napping, with the caffeine kicking in just as you wake up, potentially offering a more refreshing experience."&nbsp;</p>
<p>However many candles may be on your own next birthday cake, we all need to prioritize adequate rest. We know that building healthy routines like regular bedtimes, avoiding too much caffeine and late-night doomscrolling or binge-watching and getting adequate physical activity are the best bet for a better night — even if it's all easier said than done. Our culture typically regards aging as a failure and sleep as for the weak. But the plain fact is that our bodies change over time. That doesn't mean that once you hit your AARP era,&nbsp; you suddenly can function just fine on 5 hours of sack time. Instead, if you want to feel younger, you just might actually need to sleep more.</p>
<div>

<ul>
<li><strong><a href="https://www.salon.com/2023/11/15/is-gen-zs-bed-rotting-trend-self-care-or-reckless-self-indulgence/" target="_blank">Is Gen Z's "bed rotting" trend self-care or reckless self-indulgence?</a></strong></li>
<li><strong><a href="https://www.salon.com/2023/11/11/sleep-the-bedrock-of-public-health-is-eroding-this-is-how-experts-say-we-can-fix-it/" target="_blank">Sleep, the bedrock of public health, is eroding. This is how experts say we can fix it</a></strong></li>
<li><strong><a href="https://www.salon.com/2023/11/08/is-blue-light-actually-harmful-to-your-sleep-why-the-science-isnt-so-clear-on-this-popular-belief/" target="_blank">Is blue light actually harmful to your sleep? Why the science isn't so clear on this popular belief</a></strong></li>
</ul>
</div>
							</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chasquid – SMTP server focused on simplicity (126 pts)]]></title>
            <link>https://blitiri.com.ar/p/chasquid/</link>
            <guid>38509678</guid>
            <pubDate>Sun, 03 Dec 2023 18:55:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blitiri.com.ar/p/chasquid/">https://blitiri.com.ar/p/chasquid/</a>, See on <a href="https://news.ycombinator.com/item?id=38509678">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><img src="https://blitiri.com.ar/p/chasquid/yaguarete.jpg" title="Yaguareté (panthera onca)" alt="Yaguareté (panthera onca) - From Wikipedia (MarcusObal and Kallerna)"></p>
<p><a href="https://blitiri.com.ar/p/chasquid">chasquid</a> is an SMTP (email) server with a
focus on simplicity, security, and ease of operation.</p>
<p>It sends and receives email as a typical
<a href="https://en.wikipedia.org/wiki/Message_transfer_agent">MTA</a> (for example, can
be used instead of <a href="http://www.postfix.org/">Postfix</a> or
<a href="https://exim.org/">Exim</a>), and it is designed mainly for individuals and
small groups.</p>
<p>It's written in <a href="https://golang.org/">Go</a>, and distributed under the
<a href="http://en.wikipedia.org/wiki/Apache_License">Apache license 2.0</a>.</p>
<p><a href="https://github.com/albertito/chasquid/actions"><img alt="Go tests" src="https://github.com/albertito/chasquid/actions/workflows/gotests.yml/badge.svg?branch=master"></a>
<a href="https://goreportcard.com/report/github.com/albertito/chasquid"><img alt="Go Report Card" src="https://goreportcard.com/badge/github.com/albertito/chasquid"></a>
<a href="https://blitiri.com.ar/p/chasquid/coverage.html"><img alt="Coverage" src="https://img.shields.io/badge/coverage-next-brightgreen.svg"></a><br>
<a href="https://blitiri.com.ar/p/chasquid/"><img alt="Docs" src="https://img.shields.io/badge/docs-reference-blue.svg"></a>
<a href="https://webchat.oftc.net/?channels=%23chasquid"><img alt="OFTC IRC" src="https://img.shields.io/badge/chat-oftc-blue.svg"></a></p>
<h2 id="features">Features</h2>
<ul>
<li>Easy<ul>
<li>Easy to configure.</li>
<li>Hard to mis-configure in ways that are harmful or insecure (e.g. no open
  relay, or clear-text authentication).</li>
<li><a href="https://blitiri.com.ar/p/chasquid/monitoring/">Monitoring</a> HTTP server, with exported variables and tracing to help
  debugging.</li>
<li>Integrated with <a href="https://blitiri.com.ar/p/chasquid/install/#debianubuntu">Debian</a>, <a href="https://blitiri.com.ar/p/chasquid/install/#debianubuntu">Ubuntu</a>, and <a href="https://blitiri.com.ar/p/chasquid/install/#arch">Arch</a>.</li>
<li>Supports using <a href="https://blitiri.com.ar/p/chasquid/dovecot/">Dovecot</a> for authentication.</li>
</ul>
</li>
<li>Useful<ul>
<li>Multiple/virtual domains, with per-domain users and aliases.</li>
<li>Suffix dropping (<code>user+something@domain</code> → <code>user@domain</code>).</li>
<li><a href="https://blitiri.com.ar/p/chasquid/hooks/">Hooks</a> for integration with greylisting, anti-virus, anti-spam, and
  DKIM/DMARC.</li>
<li>International usernames (<a href="https://en.wikipedia.org/wiki/Extended_SMTP#SMTPUTF8">SMTPUTF8</a>) and domain names (<a href="https://en.wikipedia.org/wiki/Internationalized_domain_name">IDNA</a>).</li>
</ul>
</li>
<li>Secure<ul>
<li><a href="https://blitiri.com.ar/p/chasquid/sec-levels/">Tracking</a> of per-domain TLS support, prevents connection downgrading.</li>
<li>Multiple TLS certificates.</li>
<li>Easy integration with <a href="https://letsencrypt.org/">Let's Encrypt</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/Sender_Policy_Framework">SPF</a> and <a href="https://tools.ietf.org/html/rfc8461">MTA-STS</a> checking.</li>
</ul>
</li>
</ul>
<h2 id="documentation">Documentation</h2>
<p>The <a href="https://blitiri.com.ar/p/chasquid/howto/">how-to guide</a> and the
<a href="https://blitiri.com.ar/p/chasquid/install/">installation guide</a> are the
best starting points on how to install, configure and run chasquid.</p>
<h2 id="source-code">Source code</h2>
<ul>
<li><a href="https://blitiri.com.ar/git/r/chasquid/">Browse the git repository</a> (mirrors:
  <a href="https://github.com/albertito/chasquid">GitHub</a>,
  <a href="https://gitlab.com/albertito/chasquid">GitLab</a>)</li>
<li><code>git clone https://blitiri.com.ar/repos/chasquid</code></li>
</ul>

<p>If you have any questions, comments or patches, please send them to the <a href="https://groups.google.com/forum/#!forum/chasquid">mailing
list</a>,
<code>chasquid@googlegroups.com</code>.<br>
To subscribe, send an email to <code>chasquid+subscribe@googlegroups.com</code>.</p>
<p>Security issues can be reported privately to <code>alb@blitiri.com.ar</code>.</p>
<p>Bug reports and pull requests on
<a href="https://github.com/albertito/chasquid">GitHub</a> are also welcome.</p>
<p>You can also reach out via IRC, <code>#chasquid</code> on <a href="https://oftc.net/">OFTC</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GDlog: A GPU-accelerated deductive engine (113 pts)]]></title>
            <link>https://arxiv.org/abs/2311.02206</link>
            <guid>38509255</guid>
            <pubDate>Sun, 03 Dec 2023 18:08:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2311.02206">https://arxiv.org/abs/2311.02206</a>, See on <a href="https://news.ycombinator.com/item?id=38509255">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2311.02206.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>Modern deductive database engines (e.g., LogicBlox and Soufflé) enable their users to write declarative queries which compute recursive deductions over extensional data, leaving their high-performance operationalization (query planning, semi-naïve evaluation, and parallelization) to the engine. Such engines form the backbone of modern high-throughput applications in static analysis, security auditing, social-media mining, and business analytics. State-of-the-art engines are built upon nested loop joins over explicit representations (e.g., BTrees and tries) and ubiquitously employ range indexing to accelerate iterated joins. In this work, we present GDlog: a GPU-based deductive analytics engine (implemented as a CUDA library) which achieves significant performance improvements (5--10x or more) versus prior systems. GDlog is powered by a novel range-indexed SIMD datastructure: the hash-indexed sorted array (HISA). We perform extensive evaluation on GDlog, comparing it against both CPU and GPU-based hash tables and Datalog engines, and using it to support a range of large-scale deductive queries including reachability, same generation, and context-sensitive program analysis. Our experiments show that GDlog achieves performance competitive with modern SIMD hash tables and beats prior work by an order of magnitude in runtime while offering more favorable memory footprint.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Yihao Sun [<a href="https://arxiv.org/show-email/0f48eaa6/2311.02206">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 3 Nov 2023 19:35:06 UTC (1,325 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Audio plugin for circuit-bent MP3 compression sounds (215 pts)]]></title>
            <link>https://wildergardenaudio.com/maim/</link>
            <guid>38509173</guid>
            <pubDate>Sun, 03 Dec 2023 18:01:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wildergardenaudio.com/maim/">https://wildergardenaudio.com/maim/</a>, See on <a href="https://news.ycombinator.com/item?id=38509173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <header>
        <h2><a href="https://wildergardenaudio.com/">Wildergarden Audio</a></h2>
        

    </header>
    <p><img src="https://wildergardenaudio.com/maim/static/images/maim-logo.svg" alt="MAIM">
        <img src="https://wildergardenaudio.com/maim/static/images/maim-logo-orange.svg" alt="MAIM">
    </p>
    <h2>MAIM Ain't an Implementation of MP3</h2>
    <p><img src="https://wildergardenaudio.com/maim/static/images/MaimGUI.png" alt="screenshot of MAIM GUI"></p><div>
            <p>MAIM is the plugin for you if you want the sound of MP3 compression. With heavily hacked real MP3
                encoders at its core, MAIM gives you the full gamut of digital distortion, from the realistic to the
                fantastical. Explore the bubbles and crunches of this unique form of digital distortion.</p>
            <ul>
                <li>MAIM features two real MP3 encoders, captured in the wild and painstakingly incorporated into a
                    real-time plugin.
                </li>
                <li>We've woven mad-science circuit bending into MAIM's MP3 encoders, to give you fine control over a
                    whole
                    palette of spectral distortions and face-melting glitches.
                </li>
                <li>All knobs can be smoothly dragged and automated, without pops or gaps in the sound.</li>
                <li>MAIM works across DAWs, on Mac (AU/VST3), Windows (VST3), and even Linux (VST3).</li>
                <li>MAIM is, and will always be, 100% free and open-source. If you are so inclined,
                    <a href="https://github.com/ArdenButterfield/Maim">check out the code</a>,
                    <a href="https://github.com/ArdenButterfield/Maim/blob/main/Docs/BUILDING.md">build MAIM
                        yourself</a>,
                    or add the next awesome feature.
                </li>
            </ul>
            <p>
                If you encounter any issues, or have an idea for something that would improve MAIM, please
                <a href="https://github.com/ArdenButterfield/Maim/issues">raise an issue</a> on the GitHub page.
            </p>
            <p>
                Maim took a long time to make. If you enjoy MAIM and want to see more plugins like it in the future,
                <a href="https://ko-fi.com/wildergardenaudio">tips</a> are always welcome.
            </p>
        </div>
    <div>
        <h2>Meet the Encoders</h2>
        <p>
            Why does MAIM have two MP3 encoders? An MP3 is an MP3, right? Not quite.
            Audio compression is as much an art as a science, and each encoder gives the track a slightly different
            tone.
        </p>
        
    </div>
    <div>
        <h2>The Sounds of MAIM</h2>
        <ul>
            <li>
                <h3>dry</h3>
                <p>just some normal drums... what will MAIM do?</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20dry.mp3">
                </audio>
            </li>
            <li>
                <h3>moderate mp3 distortion</h3>
                <p>that napster sound</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20light%20mp3%20distortion.mp3">
                </audio>
            </li>
            <li>
                <h3>muffled 8k</h3>
                <p>the lowest quality setting on the lame mp3 encoder... just 8000 bits per second!</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20muffled8k.mp3">
                </audio>
            </li>
            <li>
                <h3>blade</h3>
                <p>bubble bath for your music</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20bubblyBlade.mp3">
                </audio>
            </li>
            <li>
                <h3>eroded</h3>
                <p>a different kind of gate. memories of zoom meetings gone wrong</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20eroded.mp3">
                </audio>
            </li>
            <li>
                <h3>feedback</h3>
                <p>smeared and buzzy</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20smearedBuzzy.mp3">
                </audio>
            </li>
            <li>
                <h3>tubular</h3>
                <p>the math is hard to explain here, but imagine if a comb filter was worse</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20throughATube.mp3">
                </audio>
            </li>
            <li>
                <h3>whirled</h3>
                <p>it's a frequency shifter</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20spectralSpin.mp3">
                </audio>
            </li>
            <li>
                <h3>clunked up</h3>
                <p>all the wrong frequencies</p>
                <audio controls="">
                    <source src="https://wildergardenaudio.com/maim/static/audioExamples/maim%20crunk.mp3">
                </audio>
            </li>
        </ul>
    </div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Steel – An embeddable and extensible scheme dialect built in Rust (230 pts)]]></title>
            <link>https://github.com/mattwparas/steel</link>
            <guid>38508779</guid>
            <pubDate>Sun, 03 Dec 2023 17:24:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/mattwparas/steel">https://github.com/mattwparas/steel</a>, See on <a href="https://news.ycombinator.com/item?id=38508779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">Steel</h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/mattwparas/steel/blob/master/images/styled.png"><img width="150px" src="https://github.com/mattwparas/steel/raw/master/images/styled.png"></a>
</p>

<h2 tabindex="-1" dir="auto">Getting Started</h2>
<p dir="auto">This github repository contains a cli interpreter. To try it out on the online playground, go to the <a href="https://mattwparas.github.io/steel-playground/dev" rel="nofollow">Steel playground</a>. To get started using a repl with the crates, make sure you first have rust installed.</p>
<p dir="auto">Then, clone the repo and run the following command:</p>

<p dir="auto">This will launch a REPL instance that looks something like this:</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/mattwparas/steel/blob/master/images/repl.gif"><img src="https://github.com/mattwparas/steel/raw/master/images/repl.gif" width="100%" data-animated-image=""></a>
</p>
<h3 tabindex="-1" dir="auto">Packages</h3>
<p dir="auto">If you would like to install and use packages, please set the <code>STEEL_HOME</code> environment variable. This will be the location that packages get installed to. Steel currently does not assume any default.</p>
<h2 tabindex="-1" dir="auto">About</h2>
<p dir="auto"><code>Steel</code> is an embeddable scheme interpreter, with a standalone cli included as well. Inspired largely by Racket, the language seeks to be ergonomic scheme variant helpful for embedding in applications, or to be used on its own with high performance functions implemented in Rust. The language implementation itself contains a fairly powerful macro system based on the <code>syntax-rules</code> style and a bytecode virtual machine. At the moment, it is not explicitly compliant with any individual scheme specification.</p>
<blockquote>
<p dir="auto"><strong>Warning</strong>
The API is unstable with no guarantees, and may change at any time while pre 1.0. There are undoubtedly bugs that exist, and any major bug reports will be addressed quickly. That being said, I do use it as a daily driver for many scripting tasks myself.</p>
</blockquote>
<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Limited <code>syntax-rules</code> style macros are supported</li>
<li>Easy integration with Rust functions and structs</li>
<li>Easily call a script from rust or via a separate file</li>
<li>Efficient - common functions and data structures are optimized for performance (<code>map</code>, <code>filter</code>, etc)</li>
<li>Higher order Contracts</li>
<li>Built in immutable data structures include:
<ul dir="auto">
<li>lists</li>
<li>vectors</li>
<li>hashmaps</li>
<li>hashsets</li>
</ul>
</li>
</ul>
<h2 tabindex="-1" dir="auto">Contracts</h2>
<p dir="auto">Inspired by Racket's higher order contracts, <code>Steel</code> implements* higher order contracts to enable design by contract, made easy with a <code>define/contract</code> macro for easier ergonomics. Racket makes use of a concept known as <em>blame</em> which seeks to identify the violating party - <code>Steel</code> does not quite have fully fleshed out blame but that is a work in progress. Here are some examples:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Simple flat contracts
(define/contract (test x y)
    (->/c even? even? odd?)
    (+ x y 1))

(test 2 2) ;; => 5

(define/contract (test-violation x y)
    (->/c even? even? odd?)
    (+ x y 1))

(test-violation 1 2) ;; contract violation
"><pre><span><span>;</span>; Simple flat contracts</span>
(define/contract (test x y)
    (-&gt;/c <span>even?</span> <span>even?</span> odd?)
    (<span>+</span> x y <span>1</span>))

(test <span>2</span> <span>2</span>) <span><span>;</span>; =&gt; 5</span>

(define/contract (test-violation x y)
    (-&gt;/c <span>even?</span> <span>even?</span> odd?)
    (<span>+</span> x y <span>1</span>))

(test-violation <span>1</span> <span>2</span>) <span><span>;</span>; contract violation</span>
</pre></div>
<p dir="auto">Contracts are implemented as <em>values</em>, so they are bound to functions. This enables the use of contract checking on functions themselves since functions can be passed around:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Higher order contracts, check on application
(define/contract (higher-order func y)
    (->/c (->/c even? odd?) even? even?)
    (+ 1 (func y)))

(higher-order (lambda (x) (+ x 1)) 2) ;; => 4

(define/contract (higher-order-violation func y)
    (->/c (->/c even? odd?) even? even?)
    (+ 1 (func y)))

(higher-order-violation (lambda (x) (+ x 2)) 2) ;; contract violation"><pre><span><span>;</span>; Higher order contracts, check on application</span>
(define/contract (higher-order func y)
    (-&gt;/c (-&gt;/c <span>even?</span> odd?) <span>even?</span> even?)
    (<span>+</span> <span>1</span> (func y)))

(higher-order (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>)) <span>2</span>) <span><span>;</span>; =&gt; 4</span>

(define/contract (higher-order-violation func y)
    (-&gt;/c (-&gt;/c <span>even?</span> odd?) <span>even?</span> even?)
    (<span>+</span> <span>1</span> (func y)))

(higher-order-violation (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>2</span>)) <span>2</span>) <span><span>;</span>; contract violation</span></pre></div>
<p dir="auto">Contracts on functions do not get checked until they are applied, so a function returning a <em>contracted</em> function won't cause a violation until that function is actually used:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; More higher order contracts, get checked on application
(define/contract (output)
    (->/c (->/c string? int?))
    (lambda (x) 10))

(define/contract (accept func)
    (->/c (->/c string? int?) string?)
    &quot;cool cool cool&quot;)

(accept (output)) ;; => &quot;cool cool cool&quot;

;; different contracts on the argument
(define/contract (accept-violation func)
    (->/c (->/c string? string?) string?)
    (func &quot;applesauce&quot;)
    &quot;cool cool cool&quot;)

(accept-violation (output)) ;; contract violation

;; generates a function
(define/contract (generate-closure)
    (->/c (->/c string? int?))
    (lambda (x) 10))

;; calls generate-closure which should result in a contract violation
(define/contract (accept-violation)
    (->/c (->/c string? string?))
    (generate-closure))

((accept-violation) &quot;test&quot;) ;; contract violation"><pre><span><span>;</span>; More higher order contracts, get checked on application</span>
(define/contract (output)
    (-&gt;/c (-&gt;/c <span>string?</span> int?))
    (<span>lambda</span> (<span>x</span>) 10))

(define/contract (accept func)
    (-&gt;/c (-&gt;/c <span>string?</span> int?) string?)
    <span><span>"</span>cool cool cool<span>"</span></span>)

(accept (output)) <span><span>;</span>; =&gt; "cool cool cool"</span>

<span><span>;</span>; different contracts on the argument</span>
(define/contract (accept-violation func)
    (-&gt;/c (-&gt;/c <span>string?</span> string?) string?)
    (func <span><span>"</span>applesauce<span>"</span></span>)
    <span><span>"</span>cool cool cool<span>"</span></span>)

(accept-violation (output)) <span><span>;</span>; contract violation</span>

<span><span>;</span>; generates a function</span>
(define/contract (generate-closure)
    (-&gt;/c (-&gt;/c <span>string?</span> int?))
    (<span>lambda</span> (<span>x</span>) 10))

<span><span>;</span>; calls generate-closure which should result in a contract violation</span>
(define/contract (accept-violation)
    (-&gt;/c (-&gt;/c <span>string?</span> string?))
    (generate-closure))

((accept-violation) <span><span>"</span>test<span>"</span></span>) <span><span>;</span>; contract violation</span></pre></div>
<p dir="auto">Perhaps a more nuanced case:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(define/contract (output)
    (->/c (->/c string? int?))
    (lambda (x) 10.2))

(define/contract (accept)
    (->/c (->/c string? number?))
    (output))


((accept) &quot;test&quot;) ;; contract violation 10.2 satisfies number? but _not_ int?"><pre>(define/contract (output)
    (-&gt;/c (-&gt;/c <span>string?</span> int?))
    (<span>lambda</span> (<span>x</span>) 10.2))

(define/contract (accept)
    (-&gt;/c (-&gt;/c <span>string?</span> number?))
    (output))


((accept) <span><span>"</span>test<span>"</span></span>) <span><span>;</span>; contract violation 10.2 satisfies number? but _not_ int?</span></pre></div>
<p dir="auto">* Very much a work in progress</p>
<h2 tabindex="-1" dir="auto">Transducers</h2>
<p dir="auto">Inspired by clojure's transducers, <code>Steel</code> has a similar object that is somewhere half way in between transducers and iterators. Consider the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="
(mapping (lambda (x) (+ x 1))) ;; => <#iterator>
(filtering even?) ;; => <#iterator>
(taking 15) ;; => <#iterator>

(compose 
    (mapping add1)
    (filtering odd?)
    (taking 15)) ;; => <#iterator>"><pre>(mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span>
(filtering even?) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span>
(taking <span>15</span>) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span>

(compose 
    (mapping add1)
    (filtering odd?)
    (taking <span>15</span>)) <span><span>;</span>; =&gt; &lt;#iterator&gt;</span></pre></div>
<p dir="auto">Each of these expressions emit an <code>&lt;#iterator&gt;</code> object, which means they're compatible with  <code>transduce</code>. <code>transduce</code> takes a transducer (i.e. <code>&lt;#iterator&gt;</code>) and a collection that can be iterated (<code>list</code>, <code>vector</code>, <code>stream</code>, <code>hashset</code>, <code>hashmap</code>, <code>string</code>, <code>struct</code>) and applies the transducer.</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; Accepts lists
(transduce (list 1 2 3 4 5) (mapping (lambda (x) (+ x 1))) (into-list)) ;; => '(2 3 4 5 6)

;; Accepts vectors
(transduce (vector 1 2 3 4 5) (mapping (lambda (x) (+ x 1))) (into-vector)) ;; '#(2 3 4 5 6)

;; Even accepts streams!
(define (integers n)
    (stream-cons n (lambda () (integers (+ 1 n)))))

(transduce (integers 0) (taking 5) (into-list)) ;; => '(0 1 2 3 4)"><pre><span><span>;</span>; Accepts lists</span>
(transduce (<span>list</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span>) (mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) (into-list)) <span><span>;</span>; =&gt; '(2 3 4 5 6)</span>

<span><span>;</span>; Accepts vectors</span>
(transduce (vector <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span>) (mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) (into-vector)) <span><span>;</span>; '#(2 3 4 5 6)</span>

<span><span>;</span>; Even accepts streams!</span>
(<span>define</span> (<span>integers</span><span> n</span>)
    (stream-cons n (<span>lambda</span> () (integers (<span>+</span> <span>1</span> n)))))

(transduce (integers <span>0</span>) (taking <span>5</span>) (into-list)) <span><span>;</span>; =&gt; '(0 1 2 3 4)</span></pre></div>
<p dir="auto">Transduce accepts a reducer function as well. Above we used <code>into-list</code> and <code>into-vector</code>, but below we can use any arbitrary reducer:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; (-> transducer reducing-function initial-value iterable)
(transduce (list 0 1 2 3) (mapping (lambda (x) (+ x 1))) (into-reducer + 0)) ;; => 10"><pre><span><span>;</span>; (-&gt; transducer reducing-function initial-value iterable)</span>
(transduce (<span>list</span> <span>0</span> <span>1</span> <span>2</span> <span>3</span>) (mapping (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))) (into-reducer <span>+</span> <span>0</span>)) <span><span>;</span>; =&gt; 10</span></pre></div>
<p dir="auto">Compose just combines the iterator functions and lets us avoid intermediate allocation. The composition works left to right - it chains each value through the functions and then accumulates into the output type. See the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(define xf 
    (compose 
        (mapping add1)
        (filtering odd?)
        (taking 5)))

(transduce (range 0 100) xf (into-list)) ;; => '(1 3 5 7 9)"><pre>(<span>define</span> <span>xf</span> 
    (compose 
        (mapping add1)
        (filtering odd?)
        (taking <span>5</span>)))

(transduce (range <span>0</span> <span>100</span>) xf (into-list)) <span><span>;</span>; =&gt; '(1 3 5 7 9)</span></pre></div>
<h2 tabindex="-1" dir="auto">Syntax Choices</h2>
<p dir="auto"><code>Steel</code> is mildly opinionated in that there a few ways to define variables and functions. These choices are fairly arbitrary except for the shorthand function syntax, which I borrowed from Racket. <code>defn</code> and <code>fn</code> were really encouraged by me wanting to type less characters.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
;; All of the following are equivalent
(define (foo x) (+ x 1))
(define foo (lambda (x) (+ x 1)))
(defn (foo x) (+ x 1))
(defn foo (lambda (x) (+ x 1)))

;; All of the following are equivalent
(lambda (x) (+ x 1))
(λ (x) (+ x 1))
(fn (x) (+ x 1))"><pre><span><span>;</span>; All of the following are equivalent</span>
(<span>define</span> (<span>foo</span><span> x</span>) (<span>+</span> x <span>1</span>))
(<span>define</span> <span>foo</span> (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>)))
(defn (<span>foo</span> x) (<span>+</span> x <span>1</span>))
(defn <span>foo</span> (<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>)))

<span><span>;</span>; All of the following are equivalent</span>
(<span>lambda</span> (<span>x</span>) (<span>+</span> x <span>1</span>))
(λ (x) (<span>+</span> x <span>1</span>))
(fn (x) (<span>+</span> x <span>1</span>))</pre></div>
<h2 tabindex="-1" dir="auto">Modules</h2>
<p dir="auto">In order to support a growing codebase, Steel has module support for projects spanning multiple files. Steel files can <code>provide</code> values (with contracts attached) and <code>require</code> modules from other files:</p>
<div dir="auto" data-snippet-clipboard-copy-content=";; main.scm
(require &quot;provide.scm&quot;)

(even->odd 10)


;; provide.scm
(provide 
    (contract/out even->odd (->/c even? odd?))
    no-contract
    flat-value)

(define (even->odd x) 
    (+ x 1))

(define (accept-number x) (+ x 10))

(define (no-contract) &quot;cool cool cool&quot;)
(define flat-value 15)

(displayln &quot;Calling even->odd with some bad inputs but its okay&quot;)
(displayln (even->odd 1))"><pre><span><span>;</span>; main.scm</span>
(require <span><span>"</span>provide.scm<span>"</span></span>)

(even-&gt;odd <span>10</span>)


<span><span>;</span>; provide.scm</span>
(provide 
    (contract/out even-&gt;odd (-&gt;/c <span>even?</span> odd?))
    no-contract
    flat-value)

(<span>define</span> (<span>even-&gt;odd</span><span> x</span>) 
    (<span>+</span> x <span>1</span>))

(<span>define</span> (<span>accept-number</span><span> x</span>) (<span>+</span> x <span>10</span>))

(<span>define</span> (<span>no-contract</span>) "cool cool cool")
(<span>define</span> <span>flat-value</span> 15)

(displayln <span><span>"</span>Calling even-&gt;odd with some bad inputs but its okay<span>"</span></span>)
(displayln (even-&gt;odd <span>1</span>))</pre></div>
<p dir="auto">Here we can see if we were to run <code>main</code> that it would include the contents of <code>provide</code>, and only provided values would be accessible from <code>main</code>. The contract is attached at the contract boundary, so inside the <code>provide</code> module, you can violate the contract, but outside the module the contract will be applied.</p>
<p dir="auto">A few notes on modules:</p>
<ul dir="auto">
<li>Cyclical dependencies are not allowed</li>
<li>Modules will be only compiled once and used across multiple files. If <code>A</code> requires <code>B</code> and <code>C</code>, and <code>B</code> requires <code>C</code>, <code>C</code> will be compiled once and shared between <code>A</code> and <code>B</code>.</li>
<li>Modules will be recompiled when changed, and any dependent files will also be recompiled as necessary</li>
</ul>
<h2 tabindex="-1" dir="auto">Performance</h2>
<p dir="auto">Preliminary benchmarks show the following on my machine:</p>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Steel</th>
<th>Python</th>
</tr>
</thead>
<tbody>
<tr>
<td>(fib 28)</td>
<td>63.383ms</td>
<td>65.10 ms</td>
</tr>
<tr>
<td>(ack 3 3)</td>
<td>0.303 ms</td>
<td>0.195 ms</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Examples of embedding Rust values in the virtual machine</h2>
<p dir="auto">Rust values, types, and functions are easily embedded into Steel. Using the <code>register_fn</code> call, you can embed functions easily:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use steel_vm::engine::Engine;
use steel_vm::register_fn::RegisterFn;

fn external_function(arg1: usize, arg2: usize) -> usize {
    arg1 + arg2
}

fn option_function(arg1: Option<String>) -> Option<String> {
    arg1
}

fn result_function(arg1: Option<String>) -> Result<String, String> {
    if let Some(inner) = arg1 {
        Ok(inner)
    } else {
        Err(&quot;Got a none&quot;.to_string())
    }
}

pub fn main() {
    let mut vm = Engine::new();

    // Here we can register functions
    // Any function can accept parameters that implement `FromSteelVal` and
    // return values that implement `IntoSteelVal`
    vm.register_fn(&quot;external-function&quot;, external_function);

    // See the docs for more information about `FromSteelVal` and `IntoSteelVal`
    // but we can see even functions that accept/return Option<T> or Result<T,E>
    // can be registered
    vm.register_fn(&quot;option-function&quot;, option_function);

    // Result values will map directly to errors in the VM and bubble back up
    vm.register_fn(&quot;result-function&quot;, result_function);

    vm.run(
        r#&quot;
        (define foo (external-function 10 25))
        (define bar (option-function &quot;applesauce&quot;))
        (define baz (result-function &quot;bananas&quot;))
    &quot;#,
    )
    .unwrap();

    let foo = vm.extract::<usize>(&quot;foo&quot;).unwrap();
    println!(&quot;foo: {}&quot;, foo);
    assert_eq!(35, foo);

    // Can also extract a value by specifying the type on the variable
    let bar: String = vm.extract(&quot;bar&quot;).unwrap();
    println!(&quot;bar: {}&quot;, bar);
    assert_eq!(&quot;applesauce&quot;.to_string(), bar);

    let baz: String = vm.extract(&quot;baz&quot;).unwrap();
    println!(&quot;baz: {}&quot;, baz);
    assert_eq!(&quot;bananas&quot;.to_string(), baz);
}"><pre><span>use</span> steel_vm<span>::</span>engine<span>::</span><span>Engine</span><span>;</span>
<span>use</span> steel_vm<span>::</span>register_fn<span>::</span><span>RegisterFn</span><span>;</span>

<span>fn</span> <span>external_function</span><span>(</span><span>arg1</span><span>:</span> <span>usize</span><span>,</span> <span>arg2</span><span>:</span> <span>usize</span><span>)</span> -&gt; <span>usize</span> <span>{</span>
    arg1 + arg2
<span>}</span>

<span>fn</span> <span>option_function</span><span>(</span><span>arg1</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>)</span> -&gt; <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span> <span>{</span>
    arg1
<span>}</span>

<span>fn</span> <span>result_function</span><span>(</span><span>arg1</span><span>:</span> <span>Option</span><span>&lt;</span><span>String</span><span>&gt;</span><span>)</span> -&gt; <span>Result</span><span>&lt;</span><span>String</span><span>,</span> <span>String</span><span>&gt;</span> <span>{</span>
    <span>if</span> <span>let</span> <span>Some</span><span>(</span>inner<span>)</span> = arg1 <span>{</span>
        <span>Ok</span><span>(</span>inner<span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>Err</span><span>(</span><span>"Got a none"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> vm = <span>Engine</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    <span>// Here we can register functions</span>
    <span>// Any function can accept parameters that implement `FromSteelVal` and</span>
    <span>// return values that implement `IntoSteelVal`</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"external-function"</span><span>,</span> external_function<span>)</span><span>;</span>

    <span>// See the docs for more information about `FromSteelVal` and `IntoSteelVal`</span>
    <span>// but we can see even functions that accept/return Option&lt;T&gt; or Result&lt;T,E&gt;</span>
    <span>// can be registered</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"option-function"</span><span>,</span> option_function<span>)</span><span>;</span>

    <span>// Result values will map directly to errors in the VM and bubble back up</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"result-function"</span><span>,</span> result_function<span>)</span><span>;</span>

    vm<span>.</span><span>run</span><span>(</span>
        <span>r#"</span>
<span>        (define foo (external-function 10 25))</span>
<span>        (define bar (option-function "applesauce"))</span>
<span>        (define baz (result-function "bananas"))</span>
<span>    "#</span><span>,</span>
    <span>)</span>
    <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> foo = vm<span>.</span><span>extract</span><span>::</span><span>&lt;</span><span>usize</span><span>&gt;</span><span>(</span><span>"foo"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"foo: {}"</span>, foo<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>35</span>, foo<span>)</span><span>;</span>

    <span>// Can also extract a value by specifying the type on the variable</span>
    <span>let</span> bar<span>:</span> <span>String</span> = vm<span>.</span><span>extract</span><span>(</span><span>"bar"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"bar: {}"</span>, bar<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>"applesauce"</span>.to_string<span>(</span><span>)</span>, bar<span>)</span><span>;</span>

    <span>let</span> baz<span>:</span> <span>String</span> = vm<span>.</span><span>extract</span><span>(</span><span>"baz"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"baz: {}"</span>, baz<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>"bananas"</span>.to_string<span>(</span><span>)</span>, baz<span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">We can also embed structs themselves:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use steel_vm::engine::Engine;
use steel_vm::register_fn::RegisterFn;

use steel_derive::Steel;

// In order to register a type with Steel,
// it must implement Clone, Debug, and Steel
#[derive(Clone, Debug, Steel, PartialEq)]
pub struct ExternalStruct {
    foo: usize,
    bar: String,
    baz: f64,
}

impl ExternalStruct {
    pub fn new(foo: usize, bar: String, baz: f64) -> Self {
        ExternalStruct { foo, bar, baz }
    }

    // Embedding functions that take self by value
    pub fn method_by_value(self) -> usize {
        self.foo
    }

    pub fn method_by_reference(&amp;self) -> usize {
        self.foo
    }

    // Setters should update the value and return a new instance (functional set)
    pub fn set_foo(mut self, foo: usize) -> Self {
        self.foo = foo;
        self
    }
}

pub fn main() {
    let mut vm = Engine::new();

    // Registering a type gives access to a predicate for the type
    vm.register_type::<ExternalStruct>(&quot;ExternalStruct?&quot;);

    // Structs in steel typically have a constructor that is the name of the struct
    vm.register_fn(&quot;ExternalStruct&quot;, ExternalStruct::new);

    // register_fn can be chained
    vm.register_fn(&quot;method-by-value&quot;, ExternalStruct::method_by_value)
        .register_fn(&quot;method-by-reference&quot;, ExternalStruct::method_by_reference)
        .register_fn(&quot;set-foo&quot;, ExternalStruct::set_foo);

    let external_struct = ExternalStruct::new(1, &quot;foo&quot;.to_string(), 12.4);

    // Registering an external value is fallible if the conversion fails for some reason
    // For instance, registering an Err(T) is fallible. However, most implementation outside of manual
    // ones should not fail
    vm.register_external_value(&quot;external-struct&quot;, external_struct)
        .unwrap();

    let output = vm
        .run(
            r#&quot;
            (define new-external-struct (set-foo external-struct 100))
            (define get-output (method-by-value external-struct))
            (define second-new-external-struct (ExternalStruct 50 &quot;bananas&quot; 72.6))
            &quot;last-result&quot;
        &quot;#,
        )
        .unwrap();

    let new_external_struct = vm.extract::<ExternalStruct>(&quot;new-external-struct&quot;).unwrap();
    println!(&quot;new_external_struct: {:?}&quot;, new_external_struct);
    assert_eq!(
        ExternalStruct::new(100, &quot;foo&quot;.to_string(), 12.4),
        new_external_struct
    );

    // Can also extract a value by specifying the type on the variable
    let get_output: usize = vm.extract(&quot;get-output&quot;).unwrap();
    println!(&quot;get_output: {}&quot;, get_output);
    assert_eq!(1, get_output);

    let second_new_external_struct: ExternalStruct =
        vm.extract(&quot;second-new-external-struct&quot;).unwrap();
    println!(
        &quot;second_new_external_struct: {:?}&quot;,
        second_new_external_struct
    );
    assert_eq!(
        ExternalStruct::new(50, &quot;bananas&quot;.to_string(), 72.6),
        second_new_external_struct
    );

    // We also get the output of the VM as the value of every expression run
    // we can inspect the results just by printing like so
    println!(&quot;{:?}&quot;, output);
}"><pre><span>use</span> steel_vm<span>::</span>engine<span>::</span><span>Engine</span><span>;</span>
<span>use</span> steel_vm<span>::</span>register_fn<span>::</span><span>RegisterFn</span><span>;</span>

<span>use</span> steel_derive<span>::</span><span>Steel</span><span>;</span>

<span>// In order to register a type with Steel,</span>
<span>// it must implement Clone, Debug, and Steel</span>
<span>#<span>[</span>derive<span>(</span><span>Clone</span><span>,</span> <span>Debug</span><span>,</span> <span>Steel</span><span>,</span> <span>PartialEq</span><span>)</span><span>]</span></span>
<span>pub</span> <span>struct</span> <span>ExternalStruct</span> <span>{</span>
    <span>foo</span><span>:</span> <span>usize</span><span>,</span>
    <span>bar</span><span>:</span> <span>String</span><span>,</span>
    <span>baz</span><span>:</span> <span>f64</span><span>,</span>
<span>}</span>

<span>impl</span> <span>ExternalStruct</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>foo</span><span>:</span> <span>usize</span><span>,</span> <span>bar</span><span>:</span> <span>String</span><span>,</span> <span>baz</span><span>:</span> <span>f64</span><span>)</span> -&gt; <span>Self</span> <span>{</span>
        <span>ExternalStruct</span> <span>{</span> foo<span>,</span> bar<span>,</span> baz <span>}</span>
    <span>}</span>

    <span>// Embedding functions that take self by value</span>
    <span>pub</span> <span>fn</span> <span>method_by_value</span><span>(</span><span>self</span><span>)</span> -&gt; <span>usize</span> <span>{</span>
        <span>self</span><span>.</span><span>foo</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>method_by_reference</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> -&gt; <span>usize</span> <span>{</span>
        <span>self</span><span>.</span><span>foo</span>
    <span>}</span>

    <span>// Setters should update the value and return a new instance (functional set)</span>
    <span>pub</span> <span>fn</span> <span>set_foo</span><span>(</span><span>mut</span> <span>self</span><span>,</span> <span>foo</span><span>:</span> <span>usize</span><span>)</span> -&gt; <span>Self</span> <span>{</span>
        <span>self</span><span>.</span><span>foo</span> = foo<span>;</span>
        <span>self</span>
    <span>}</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> vm = <span>Engine</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>

    <span>// Registering a type gives access to a predicate for the type</span>
    vm<span>.</span><span>register_type</span><span>::</span><span>&lt;</span><span>ExternalStruct</span><span>&gt;</span><span>(</span><span>"ExternalStruct?"</span><span>)</span><span>;</span>

    <span>// Structs in steel typically have a constructor that is the name of the struct</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"ExternalStruct"</span><span>,</span> <span>ExternalStruct</span><span>::</span>new<span>)</span><span>;</span>

    <span>// register_fn can be chained</span>
    vm<span>.</span><span>register_fn</span><span>(</span><span>"method-by-value"</span><span>,</span> <span>ExternalStruct</span><span>::</span>method_by_value<span>)</span>
        <span>.</span><span>register_fn</span><span>(</span><span>"method-by-reference"</span><span>,</span> <span>ExternalStruct</span><span>::</span>method_by_reference<span>)</span>
        <span>.</span><span>register_fn</span><span>(</span><span>"set-foo"</span><span>,</span> <span>ExternalStruct</span><span>::</span>set_foo<span>)</span><span>;</span>

    <span>let</span> external_struct = <span>ExternalStruct</span><span>::</span><span>new</span><span>(</span><span>1</span><span>,</span> <span>"foo"</span><span>.</span><span>to_string</span><span>(</span><span>)</span><span>,</span> <span>12.4</span><span>)</span><span>;</span>

    <span>// Registering an external value is fallible if the conversion fails for some reason</span>
    <span>// For instance, registering an Err(T) is fallible. However, most implementation outside of manual</span>
    <span>// ones should not fail</span>
    vm<span>.</span><span>register_external_value</span><span>(</span><span>"external-struct"</span><span>,</span> external_struct<span>)</span>
        <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> output = vm
        <span>.</span><span>run</span><span>(</span>
            <span>r#"</span>
<span>            (define new-external-struct (set-foo external-struct 100))</span>
<span>            (define get-output (method-by-value external-struct))</span>
<span>            (define second-new-external-struct (ExternalStruct 50 "bananas" 72.6))</span>
<span>            "last-result"</span>
<span>        "#</span><span>,</span>
        <span>)</span>
        <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>

    <span>let</span> new_external_struct = vm<span>.</span><span>extract</span><span>::</span><span>&lt;</span><span>ExternalStruct</span><span>&gt;</span><span>(</span><span>"new-external-struct"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"new_external_struct: {:?}"</span>, new_external_struct<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span>
        <span>ExternalStruct</span>::new<span>(</span><span>100</span>, <span>"foo"</span>.to_string<span>(</span><span>)</span>, <span>12.4</span><span>)</span>,
        new_external_struct
    <span>)</span><span>;</span>

    <span>// Can also extract a value by specifying the type on the variable</span>
    <span>let</span> get_output<span>:</span> <span>usize</span> = vm<span>.</span><span>extract</span><span>(</span><span>"get-output"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span><span>"get_output: {}"</span>, get_output<span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span><span>1</span>, get_output<span>)</span><span>;</span>

    <span>let</span> second_new_external_struct<span>:</span> <span>ExternalStruct</span> =
        vm<span>.</span><span>extract</span><span>(</span><span>"second-new-external-struct"</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>println</span><span>!</span><span>(</span>
        <span>"second_new_external_struct: {:?}"</span>,
        second_new_external_struct
    <span>)</span><span>;</span>
    <span>assert_eq</span><span>!</span><span>(</span>
        <span>ExternalStruct</span>::new<span>(</span><span>50</span>, <span>"bananas"</span>.to_string<span>(</span><span>)</span>, <span>72.6</span><span>)</span>,
        second_new_external_struct
    <span>)</span><span>;</span>

    <span>// We also get the output of the VM as the value of every expression run</span>
    <span>// we can inspect the results just by printing like so</span>
    <span>println</span><span>!</span><span>(</span><span>"{:?}"</span>, output<span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">See the examples folder for more examples on embedding values and interacting with the outside world.</p>
<h2 tabindex="-1" dir="auto">License</h2>
<p dir="auto">Licensed under either of</p>
<ul dir="auto">
<li>Apache License, Version 2.0
(<a href="https://github.com/mattwparas/steel/blob/master/LICENSE-APACHE">LICENSE-APACHE</a> or <a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">http://www.apache.org/licenses/LICENSE-2.0</a>)</li>
<li>MIT license
(<a href="https://github.com/mattwparas/steel/blob/master/LICENSE-MIT">LICENSE-MIT</a> or <a href="http://opensource.org/licenses/MIT" rel="nofollow">http://opensource.org/licenses/MIT</a>)</li>
</ul>
<p dir="auto">at your option.</p>
<h2 tabindex="-1" dir="auto">Contribution</h2>
<p dir="auto">Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.</p>
<p dir="auto">See [CONTRIBUTING.md].</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Run 70B LLM Inference on a Single 4GB GPU with This New Technique (104 pts)]]></title>
            <link>https://ai.gopubby.com/unbelievable-run-70b-llm-inference-on-a-single-4gb-gpu-with-this-new-technique-93e2057c7eeb?gi=cbe7920f4cd2</link>
            <guid>38508571</guid>
            <pubDate>Sun, 03 Dec 2023 17:04:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.gopubby.com/unbelievable-run-70b-llm-inference-on-a-single-4gb-gpu-with-this-new-technique-93e2057c7eeb?gi=cbe7920f4cd2">https://ai.gopubby.com/unbelievable-run-70b-llm-inference-on-a-single-4gb-gpu-with-this-new-technique-93e2057c7eeb?gi=cbe7920f4cd2</a>, See on <a href="https://news.ycombinator.com/item?id=38508571">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a href="https://medium.com/@lyo.gavin?source=post_page-----93e2057c7eeb--------------------------------" rel="noopener follow"><div aria-hidden="false"><p><img alt="Gavin Li" src="https://miro.medium.com/v2/resize:fill:88:88/0*FeeK9pylAmmkY3_4." width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a><a href="https://ai.gopubby.com/?source=post_page-----93e2057c7eeb--------------------------------" rel="noopener  ugc nofollow"><div aria-hidden="false"><p><img alt="AI Advances" src="https://miro.medium.com/v2/resize:fill:48:48/1*R8zEd59FDf0l8Re94ImV0Q.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"></p></div></a></div><p id="29cb">Large language models require huge amounts of GPU memory. Is it possible to run inference on a single GPU? If so, what is the minimum GPU memory required?</p><figure></figure><p id="8f79">The 70B large language model has parameter size of 130GB. <strong>Just loading the model into the GPU requires 2 A100 GPUs with 100GB memory each.</strong></p><p id="a455">During inference, the entire input sequence also needs to be loaded into memory for complex “attention” calculations. The memory requirement of this attention mechanism scales quadratically with the input length. On top of the 130GB model size, a lot more memory is needed.</p><p id="9dfc">So what techniques can save so much memory and enable inference on a single 4GB GPU?</p><p id="6520">Note that here the memory optimization techniques <strong>do not require any model compression like quantization, distillation, pruning that would sacrifice model performance.</strong></p><p id="eb92">Today <strong>we will explain the key techniques for extreme memory optimization of large models.</strong></p><p id="4141">At the end of the article we also shared the open source library to achieve this with a few lines of codes!</p><p id="1d41"><strong>01</strong></p><p id="5fd8"><strong>Layer-wise Inference</strong></p><p id="1551">The most critical technique is layer-wise inference. This is essentially the basic <strong>divide and conquer approach</strong> in computer science.</p><p id="dfa2">Let’s first look at the architecture of large language models. Today’s large language models all adopt the Multi-head self-attention structure proposed in Google’s paper “Attention is all you need”. This is what people later call the Transformer structure.</p><figure></figure><p id="5125">The large language model first has an embedding projection layer. After that there are 80 completely identical transformer layers. Finally there is a normalization and fully connected layer to predict the token ID probabilities.</p><p id="d0ba">During inference, layers are executed sequentially. The output of the previous layer is the input to the next. Only one layer executes at a time.</p><p id="ffb5">Therefore, it is completely unnecessary to keep all layers in GPU memory. <strong>We can load whichever layer is needed from disk when executing that layer, do all the calculations, and then completely free the memory after.</strong></p><p id="806c">This way, the GPU memory required per layer is only about the parameter size of one transformer layer, 1/80 of the full model, around 1.6GB.</p><p id="4f88">In addition, some output caches are also stored in GPU memory, the largest being the KV cache to avoid repeated computations.</p><p id="0acd">A simple calculation, for the 70B model this KV cache size is about:</p><p id="acc9">2 * input_length * num_layers * num_heads * vector_dim * 4</p><p id="c6a2">With input length 100, this cache = 2 * 100 * 80 * 8 * 128 * 4 = 30MB GPU memory.</p><p id="9c69"><strong>According to our monitoring, the entire inference process uses less than 4GB GPU memory!</strong></p><p id="4a81"><strong>02</strong></p><p id="4670"><strong>Single Layer Optimization — Flash Attention</strong></p><p id="e109">Flash attention is perhaps one of the most important and critical optimizations in the development of large language models today.</p><p id="0d52">All the various large language models use essentially the same underlying code, with flash attention being the biggest improvement.</p><p id="b92c">The idea of flash attention optimization is not entirely novel though, we have to mention another paper “Self-attention Does Not Need O(n²) Memory”.</p><p id="8064">Originally self attention requires O(n²) memory (n being sequence length).</p><p id="4445">This paper proposes that we don’t actually need to keep the O(n²) intermediate results. We can compute them sequentially, continuously update one intermediate result and discard everything else. This reduces the memory complexity to O(logn).</p><p id="270e">Flash attention is similar in essence, with slightly higher memory complexity O(n), but <strong>flash attention deeply optimizes cuda memory access to achieve multi-fold speedups for inference and training.</strong></p><figure></figure><p id="e322">As the figure shows, originally self attention computes and stores O(n²) intermediate results. Flash attention splits the computation into many small blocks, computing block by block and reducing memory to the size of one block.</p><p id="4b9a"><strong>03</strong></p><p id="dea0"><strong>Model File Sharding</strong></p><p id="9963">The original model file is usually sharded into multiple chunks, typically 10GB each.</p><p id="68b5">Our execution processes layer by layer. Each layer is only 1.6GB. If we load based on the original 10GB shards, every layer execution will require reloading the entire 10GB file but only using 1.6GB.</p><p id="1562">This process wastes a lot of memory for loading and disk reading. Disk reading speed is actually the slowest bottleneck in the whole inference process, so we want to minimize it as much as possible.</p><p id="2eee">Therefore, we first <strong>pre-process the original HuggingFace model file and shard it by layers</strong>.</p><p id="a1e2">For storage we use safetensor technology (<a href="https://github.com/huggingface/safetensors" rel="noopener ugc nofollow" target="_blank">https://github.com/huggingface/safetensors</a>).</p><p id="4aa5"><strong>Safetensor ensures the storage format and in-memory format match closely, and uses memory mapping for loading to maximize speed.</strong></p><p id="717f"><strong>04</strong></p><p id="c9e1"><strong>Meta Device</strong></p><p id="387b">In implementation we use the meta device feature provided by HuggingFace Accelerate (<a href="https://huggingface.co/docs/accelerate/usage_guides/big_modeling" rel="noopener ugc nofollow" target="_blank">https://huggingface.co/docs/accelerate/usage\\_guides/big\\_modeling</a>).</p><p id="e92b">Meta device is a <strong>virtual device</strong> designed specifically for running ultra large models. <strong>When you load a model via meta device, the model data is not actually read in, only the code is loaded. Memory usage is 0.</strong></p><p id="d707">You can dynamically transfer parts of the model from meta device to a real device like CPU or GPU during execution. Only then is it actually loaded into memory.</p><p id="cbde">Using init_empty_weights() allows model loading via meta device.</p><pre><span id="5d87"><br>from accelerate import init_empty_weights<br>with init_empty_weights():<br>    my_model = ModelClass(...)</span></pre><p id="4366"><strong>05</strong></p><p id="b620"><strong>Open Source Library</strong></p><p id="9bb7">We open sourced all the code — AirLLM. Allows you to achieve this with a few lines of code.</p><p id="e76e"><strong>It can be found in the Anima github: </strong><a href="https://github.com/lyogavin/Anima/tree/main/air_llm" rel="noopener ugc nofollow" target="_blank">https://github.com/lyogavin/Anima/tree/main/air_llm</a><strong>.</strong></p><p id="cd8f">Usage is very simple. First install the package:</p><pre><span id="2ade">pip install airllm</span></pre><p id="7f41">Then layered inference can be performed like a normal Transformer model:</p><pre><span id="bcb9"><br>from airllm import AirLLMLlama2<p>MAX_LENGTH = 128<br># could use hugging face model repo id:<br>model = AirLLMLlama2("garage-bAInd/Platypus2-70B-instruct")</p><p># or use model's local path...<br>#model = AirLLMLlama2("/home/ubuntu/.cache/huggingface/hub/models--garage-bAInd--Platypus2-70B-instruct/snapshots/b585e74bcaae02e52665d9ac6d23f4d0dbc81a0f")</p><p>input_text = [<br>        'What is the capital of United States?',<br>    ]</p><p>input_tokens = model.tokenizer(input_text,<br>    return_tensors="pt", <br>    return_attention_mask=False, <br>    truncation=True, <br>    max_length=MAX_LENGTH, <br>    padding=True)</p><p>           generation_output = model.generate(<br>    input_tokens['input_ids'].cuda(), <br>    max_new_tokens=20,<br>    use_cache=True,<br>    return_dict_in_generate=True)</p><p>output = model.tokenizer.decode(generation_output.sequences[0])</p><p>print(output)</p></span></pre><p id="623c">We have tested this code on a 16GB Nvidia T4 GPU. The entire inference process <strong>uses less than 4GB GPU memory</strong>.</p><p id="0083">Note that lower end GPUs like T4 will be quite slow for inference. Not very suitable for interactive scenarios like chatbots. More suited for some offline data analytics like RAG, PDF analysis etc.</p><p id="d562">Currently only Llam2 based models are supported. <strong>Leave a comment if you need support for other models!</strong></p><p id="6e75"><strong>06</strong></p><p id="13e2"><strong>Can 70B Training Fit on a Single GPU?</strong></p><p id="dc8e">While inference can be optimized with layering, can training work similarly on a single GPU?</p><p id="01c4">Inference only needs the output of the previous layer when executing the next transformer layer, so layered execution with limited data is possible.</p><p id="b3d7"><strong>Training requires more data. The training process first computes the forward propagation to get the output of every layer and tensor. Then does backpropagation to compute the gradient of every tensor.</strong></p><p id="a8cd"><strong>Gradient calculation needs to save the results of previous forward layers, so layered execution does not reduce memory.</strong></p><p id="a2a5">There are some other techniques like gradient checkpointing that can achieve similar effects.</p><p id="d6a9"><strong>If you are interested in how gradient checkpointing can significantly reduce training memory requirements, leave a comment!</strong></p><p id="62e3"><strong>07</strong></p><p id="66c5">Our code references a lot from <a href="https://www.kaggle.com/simjeg" rel="noopener ugc nofollow" target="_blank">SIMJEG</a>’s implementation on Kaggle: <a href="https://www.kaggle.com/code/simjeg/platypus2-70b-with-wikipedia-rag/notebook" rel="noopener ugc nofollow" target="_blank">https://www.kaggle.com/code/simjeg/platypus2-70b-with-wikipedia-rag/notebook</a>. Shout out to the awesome Kaggle community for their contributions!</p><p id="d4e1"><strong>We will continue open sourcing the latest and most effective new methods and advances in AI, contributing to the open source community. Please follow us.</strong></p><figure></figure></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All the hominins made tools (133 pts)]]></title>
            <link>https://johnhawks.net/weblog/all-the-hominins-made-tools/</link>
            <guid>38508418</guid>
            <pubDate>Sun, 03 Dec 2023 16:49:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://johnhawks.net/weblog/all-the-hominins-made-tools/">https://johnhawks.net/weblog/all-the-hominins-made-tools/</a>, See on <a href="https://news.ycombinator.com/item?id=38508418">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
      


      <section>
        <p>The two inventors of the idea of natural selection had somewhat different viewpoints about how technology mattered to human origins. In an 1864 lecture, Alfred Russel Wallace observed that tools, weapons, and clothing all tend to remove humans from the direct action of natural selection on the form of the body. Wallace suggested that the physical features of the human body had become “fixed and permanent”. Instead, he offered, Man had been “kept in harmony with the slowly changing universe around him, by an advance in mind, rather than by a change in body.” </p><p>Charles Darwin also saw tools and weapons as highly important to human evolution. But where Wallace had suggested a major shift in natural selection away from bodies toward minds, Darwin emphasized the continuities that link humans and other primates. He discussed evidence of the use of stones by chimpanzees for cracking nuts, and mentioned that some American monkeys were easily trained to do the same. Darwin saw it as essential that people differ from other animals in degree, not in kind, and he considered this equally true for mental as for physical characteristics. For Darwin, this continuity of structure and behavior was a powerful argument that natural selection had crafted humans just as it had crafted other species. Where others imagined a gulf, Darwin invariably saw stepping stones.</p><p>This difference between Wallace and Darwin comes to mind when I look at the way that paleoanthropologists discuss evidence of tool use. Many researchers have considered stone and bone tools to be uniquely connected with the origin of our own genus, <em>Homo</em>. Like Wallace, they imagine a transition in our evolutionary trajectory: Once our ancestors began to rely more and more on technology, natural selection on the form of the body became less and less relevant. The evolution of toolmakers would be driven by natural selection on the mind. </p><p>But humans are far from unique in our use of technology. Our closest living relatives, chimpanzees and bonobos, are technical species that use a wide array of tools, mostly made from organic and perishable materials. Both bonobos and chimpanzees use tools as part of their social interactions with other individuals, and both species use tools sometimes to make themselves feel more comfortable. Chimpanzees additionally make and use a wide array of tools to help them get foods that are hard to process without tools, for example by cracking nuts, “fishing” for termites, or extracting honey from underground bee nests. Most chimpanzees do not use stone, but western chimpanzees use stones for nutcracking and a fascinating behavior known as “accumulative stone throwing”. Bonobos and chimpanzees have hands and wrists that are very different from humans, specialized for knuckle-walking on the ground and suspending below branches while climbing. These marked differences in anatomy do not impede chimpanzees or bonobos from manipulating objects, shaping them for a purpose, and using the resulting tools to accomplish their aims. </p><figure><img src="https://johnhawks.net/content/images/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg" alt="A chimpanzee blurred from motion in the action of throwing a stone at a tree" loading="lazy" width="1500" height="1170" srcset="https://johnhawks.net/content/images/size/w600/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg 600w, https://johnhawks.net/content/images/size/w1000/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg 1000w, https://johnhawks.net/content/images/2023/12/chimpanzee-stone-throwing-kuhl-2016.jpg 1500w" sizes="(min-width: 720px) 720px"><figcaption><span>Chimpanzee at Boé, Guinea-Bissau, throwing a large rock as part of the “accumulative stone throwing” behavior. Video still from Kühl and coworkers 2016.</span></figcaption></figure><p>Bonobos and chimpanzees help show how much variation in social learning of toolmaking can evolve between closely related species. Nearly all the differences between them are manifested in perishable materials, tools that would leave no trace after millions of years. Every indication from the anatomy of early hominins and their ecology points toward Darwin's insight that the technical behavior of nonhuman primates is continuous with behavior once manifested by human ancestors and early humans. </p><h3 id="many-species-made-early-stone-and-bone-tools">Many species made early stone and bone tools</h3><p>The earliest-known stone tools are from Lomekwi 3, Kenya, made around 3.3 million years ago and first described by Sonia Harmand and the West Turkana Archaeological Project in 2015. The toolmakers, whoever they were, lived a half million years before the earliest fossils that have been attributed to the genus <em>Homo. </em>The only fossil hominin identified from the Lomekwi area around this time is <em>Kenyanthropus platyops</em>. </p><figure><img src="https://johnhawks.net/content/images/2023/12/africa-sites-early-artifacts-2023.jpg" alt="Map of Africa with insets of the East African Rift System and Cradle of Humankind area of South Africa, with sites labeled" loading="lazy" width="1920" height="1080" srcset="https://johnhawks.net/content/images/size/w600/2023/12/africa-sites-early-artifacts-2023.jpg 600w, https://johnhawks.net/content/images/size/w1000/2023/12/africa-sites-early-artifacts-2023.jpg 1000w, https://johnhawks.net/content/images/size/w1600/2023/12/africa-sites-early-artifacts-2023.jpg 1600w, https://johnhawks.net/content/images/2023/12/africa-sites-early-artifacts-2023.jpg 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>Map of archaeological and fossil sites relevant to early associations of artifacts and fossil hominin remains. Most of these are included in the timeline below. Many other early archaeological sites exist that are not labeled here.</span></figcaption></figure><p>Fossils and artifacts are <strong>associated</strong> when both are found within the same sedimentary context, buried at around the same time in the same place. Few early archaeological sites have any hominin fossils. When a hominin fossil happens to be found at such a site, it is often only a single tooth or small fragment of bone. For example, a recent paper by Dylan Flicker and Alister Key lists ten archaeological sites with Oldowan artifacts that have been dated to the period between 2.6 million and 2.0 million years ago. Out of the ten sites, only five have any trace of hominin fossil remains, only one of the five has hominin fossils that are identifiable to the species level—in this case, <em>Paranthropus robustus</em> in Sterkfontein Member 5 East.</p><p>Earlier this year, Thomas Plummer and coworkers described the earliest association between stone artifacts and hominin fossils, from Nyayanga, Kenya. This site has now produced the oldest-known Oldowan archaeological material, between 3.03 million and 2.58 million years old. The two hominin fossils are a single isolated molar and a second tooth fragment. Both are similar to teeth of <em>Paranthropus</em>, although the teeth provide too little information to attribute them to a species. </p><p>In a recent article in <em>L'Anthropologie</em>, Sandrine Prat reviewed the record of association between stone tool evidence and fossil hominin remains, from the period between 3 million and 1.2 million years ago. The review included twenty-nine situations with artifacts and fossil hominin remains, all from Ethiopia, Kenya, or Tanzania. She also discusses sites in South Africa, while recognizing that the geological situations represented by these cave sites are not quite equivalent to the open air sedimentary deposits from the East African Rift System. </p><p>I plotted these sites all together here, adding a handful of data points from other situations that also fall within the same time range, such as Dmanisi, Republic of Georgia. I also added Lomekwi 3, despite the lack of direct association with hominin fossils, to show where later sites fit relative to these earliest known artifacts. </p><figure><img src="https://johnhawks.net/content/images/2023/11/timeline-early-stone-tool-associations-prat-2023.png" alt="Timeline of early tool evidence associated with hominin fossil material. The image shows that Paranthropus and Homo species are both associated with stone and bone tools. " loading="lazy" width="1920" height="1386" srcset="https://johnhawks.net/content/images/size/w600/2023/11/timeline-early-stone-tool-associations-prat-2023.png 600w, https://johnhawks.net/content/images/size/w1000/2023/11/timeline-early-stone-tool-associations-prat-2023.png 1000w, https://johnhawks.net/content/images/size/w1600/2023/11/timeline-early-stone-tool-associations-prat-2023.png 1600w, https://johnhawks.net/content/images/2023/11/timeline-early-stone-tool-associations-prat-2023.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The pattern is striking. <em>Paranthropus</em> and <em>Homo</em> species are both found in association with stone and bone artifacts throughout the period of their coexistence. The data provide no reason to suggest that either of these branches of hominins is more or less a toolmaker than the other. </p><p>Prat also discussed anatomical evidence from these species, particularly the form of the hand and wrist. All known hand and wrist fossils from <em>Australopithecus</em> and <em>Paranthropus</em> are consistent with the kinds of grips used in making and using stone tools. To be sure, there have been many scientific debates about the functional anatomy of hand and wrist fossils from these early hominins. But those debates have been about whether some features of the <em>Australopithecus</em> and <em>Paranthropus </em>hands may reflect a greater reliance on climbing than in <em>Homo</em>. All features of these hominin hands are consistent with fine motor control and manipulation of objects in ways consistent with tool use. That means there's no anatomical basis to say that <em>Paranthropus</em> or <em>Australopithecus</em> used tools less than <em>Homo</em>. That should be no surprise, considering the extent of tool use by chimpanzees and bonobos without the same ability to produce many of the grips used by humans.</p><h3 id="paranthropus-the-neglected-toolmaker"><em>Paranthropus: </em>the neglected toolmaker</h3><p><em>Paranthropus robustus</em> is the most common hominin represented in South African sites between 2.3 million and 1.0 million years ago. Nearly every context with fossils of <em>P. robustus</em> also has stone artifacts and bone tools. In the East African Rift System, <em>Paranthropus boisei</em> is the most common hominin species across the same range of time. Many sites with <em>P. boisei</em> also have stone artifacts, although the sedimentary exposures of the rift quite commonly have fossils that are found in isolation without other fossils or artifacts nearby. Only in the northeasternmost section of the Ethiopian Rift was <em>P. boisei</em> absent. </p><p>With this pattern of association of stone and bone artifacts with <em>Paranthropus,</em> it may seem challenging to explain why archaeologists long ignored this branch of hominins as potential tool using species. This bias can be tracked back to the 1950s, as John Robinson, C. K. Brain, and Revil Mason uncovered evidence of stone tools in the deposits of Sterkfontein. </p><figure><img src="https://johnhawks.net/content/images/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png" alt="Two Oldowan choppers, each pictured from two different directions" loading="lazy" width="2000" height="784" srcset="https://johnhawks.net/content/images/size/w600/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 600w, https://johnhawks.net/content/images/size/w1000/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 1000w, https://johnhawks.net/content/images/size/w1600/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 1600w, https://johnhawks.net/content/images/size/w2400/2023/12/sterkfontein-oldowan-artifacts-robinson-1957.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>Oldowan artifacts from Sterkfontein. Image from Robinson (1957)</span></figcaption></figure><p>Working under Robinson's direction, Brain and Mason opened an area of excavation at Sterkfontein that became known as the Extension Site. In the westernmost part of this area, the breccia contained many stone tools. In 1959, Robinson identified a bone tool from the site, marked by striations and polish on its tip. For twenty years, first Robert Broom and then John Robinson had found fossils of <em>Australopithecus africanus </em>at Sterkfontein. Was this species the toolmaker? </p><p>In early August of 1959, Mary Leakey excavated the first fossil skull of the species we know today as <em>Paranthropus boisei</em>, from level 22 of the FLK site at Olduvai Gorge. Louis and Mary Leakey had interpreted this level as a “living floor”, with abundant stone artifacts of the tradition they had named the Oldowan Industrial Complex. In his description of the skull, which he named <em>Zinjanthropus</em>, Louis emphasized its near-pristine preservation as a reason why this individual was different from the broken and fragmented animal bones at the site. <em>Zinjanthropus</em>, he argued, must be the maker of the tools. </p><p>Many anthropologists were happy to accept these hominins as makers of stone tools. For example, Sherwood Washburn discussed the <em>Zinjanthropus</em> discovery as confirming the discoveries by Robinson and Brain that seemed to associate <em>Australopithecus</em> with artifacts. He ridiculed the assertion by some other researchers that “no creature with so small a brain could have made tools”. Nevertheless, he wrote, the problem could only be solved by excavation. </p><blockquote>“An association in one site cannot settle the matter, and the situation is further complicated because several kinds of Australopithecus and Homo may have made tools. It is perfectly possible that different species of australopithecines and early Homo lived at the same time and <strong>all</strong> made tools.”—Sherwood Washburn</blockquote><p>One of the scientists with doubts was Robinson himself. His work made clear that the <em>Australopithecus</em> fossils from Sterkfontein were older than the Swartkrans breccia, which had fossils of <em>Paranthropus robustus</em> as well as a more humanlike form that Robinson and Robert Broom had called <em>Telanthropus capensis.</em> Robinson viewed <em>Telanthropus </em>as “an australopithecine that had attained euhominid status”—in other words, something that today we would recognize as early <em>Homo</em>. A few years later Robinson would accept <em>Telanthropus</em> as identical to <em>Homo erectus</em>, although today researchers see this as a heterogeneous group of fossils which may include some early <em>Homo</em> individuals but also some that belong to <em>P. robustus</em> or <em>Australopithecus sediba</em>. Brain had identified some quartzite artifacts in the Swartkrans breccia. As they continued to work the Sterkfontein deposits, it became clear that the artifact-bearing breccia was somewhere in the middle: later than most of the <em>Australopithecus</em> fossils from the site but earlier than Swartkrans. Still, even though the artifacts seemed to be later than most of the <em>Australopithecus</em> deposit, Robinson identified some <em>Australopithecus</em>-like fragments in the area where stone tools were found, and no other hominin remains. </p><p>Robinson admitted that it seemed logical to conclude that <em>Australopithecus</em> had made the tools. In fact, Robinson, Mason, and many others at the time accepted Raymond Dart's idea that the pattern of broken animal bones from the Makapan Limeworks site might represent an early use of bones as tools by <em>Australopithecus</em>. But Robinson considered the stone tools from Sterkfontein too advanced for the earlier species, and he noted that most of the <em>Australopithecus </em>fossils, from Sterkfontein, Taung, and Makapan, had come from contexts where no stone tools had yet been found. He thought that <em>Telanthropus</em> must surely have made the stone tools instead. The very absence of evidence became a centerpiece of his argument: </p><blockquote>“Perhaps the very fact that <em>Australopithecus</em> is common at Sterkfontein is an argument against it being a tool-maker, since in all other very early Stone Age sites remains of the tool manufacturer are extremely rare.”—John Robinson</blockquote><p>Today researchers have established that Robinson's West Pit included breccia that belongs to Member 5 West deposits, which include Oldowan artifacts and some bifaces, and likely postdates 2 million years ago. The earlier Oldowan Infill of Member 5 East is the earliest-known Oldowan assemblage from South Africa with a cosmogenic date assessment of 2.18&nbsp;±&nbsp;0.21&nbsp;Myr and currently includes only <em>Paranthropus</em> fossils. </p><p>The Olduvai Gorge picture changed markedly in 1960 with the discovery of the OH 7 mandible, partial cranium, and hand at the FLK-NN site. The OH 7 jaw was much more like <em>Australopithecus</em> than the <em>Zinjanthropus </em>skull had been, but its parietal bones suggested a larger brain size—ultimately Phillip Tobias would estimate it as 750 ml. As Mary and Louis Leakey continued to work, they found remains of more individuals with a similar dental pattern, different from <em>Zinjanthropus</em>. None of the other cranial remains reflected a brain as large as OH 7, but fossils like OH 16 and OH 13 were a bit larger in brain size than <em>Australopithecus</em> was. By 1964, Louis Leakey, Phillip Tobias, and John Napier were ready to recognize these as a transitional species between <em>Australopithecus</em> and <em>Homo erectus</em>: they named it <em>Homo habilis</em>. </p><p>Everything that Louis Leakey had said about <em>Zinjanthropus</em> being the Oldowan toolmaker, he now took back. </p><blockquote>“While it is possible that Zinjanthropus and Homo habilis both made stone tools, it is probable that the latter was the more advanced tool maker and that the Zinjanthropus skull represents an intruder (or a victim) on a Homo habilis living site.”—Louis Leakey, Phillip Tobias, and John Napier</blockquote><p><em>Homo habilis</em> was the favored hominin. <em>Zinjanthropus</em>, once vaunted as the toolmaker, was now roadkill. For many scientists, Leakey's backtracking was all they needed as proof that stone tools were the exclusive province of <em>Homo</em>. </p><p>It would take two decades for scientists to recognize the toolmaking potential of <em>Paranthropus</em>. The most important researcher behind this change was C. K. Brain. After more than twenty years working to understand the Swartkrans site, Brain had learned much about the associations of hominin fossils and their entry into the site. He found more bone tools, similar to the one noted by Robinson at Sterkfontein, and together with Pat Shipman quantified the wear that marked the tips of the tools as the possible result of digging in stony soil for underground bulbs. Later research by Lucinda Backwell and Francesco d'Errico further suggested that some of the bone artifacts had been used to puncture hard termite nests. Brain showed that <em>P. robustus</em> was the predominant hominin element in the Swartkrans assemblage, with <em>Homo</em> very rare within the deposits, yet artifacts were present throughout. The hand fossils also told a story. Analyzed by Randall Susman and reviewed by Brain, it was clear that the <em>Paranthropus</em> hand anatomy was fully capable of making and using tools. </p><blockquote>“The notion that&nbsp;toolmaking provided the&nbsp;adaptive wedge&nbsp;that separated&nbsp;the&nbsp;robust australopithecines&nbsp;from&nbsp;the gracile australopithecines and early&nbsp;<em>Homo</em> may&nbsp;be tenable&nbsp;no&nbsp;longer.”—C. K. Brain and coworkers</blockquote><h3 id="which-hominin-species-lacked-stone-or-bone-artifacts">Which hominin species lacked stone or bone artifacts?</h3><p>While today's data associating some archaeological materials with fossil hominin remains are much better than the past, they remain incomplete. Before 3 million years ago, the only known site with stone artifacts is Lomekwi 3. As discussed above, the hominin fossils from the Turkana Basin near that time have been classified as <em>Kenyanthropus platyops</em>. The more widespread <em>Australopithecus afarensis,</em> which lived much further north in the Afar triangle of Ethiopia, and further south at Kantis, Kenya, and Laetoli, Tanzania, may have been present in the Turkana Basin also. I don't think we can be sure which early species made these particular tools, nor would I bet that someone won't find even earlier artifacts. </p><p>At the very least, though, I think we must acknowledge that the use of stone artifacts was rare before 3 million years ago. Most hominins from this time, including species such as <em>Australopithecus anamensis</em> and <em>Australopithecus deyiremeda</em>, may not have used stone. That wouldn't surprise me at all: both bonobos and eastern and central chimpanzees show how extensive toolmaking can be without using stone as a raw material. But I don't think the record is strong enough to rule out stone tool use of the kind practiced by western chimpanzees, including the use of hammerstones for nutcracking and minimal transport of stone. It would be very challenging to test for this kind of behavior with the kinds of archaeological surveys that have been practical in fossil exposures from the Pliocene. </p><p>In addition to direct evidence from artifacts, there may be indirect evidence of stone tool use, such as cutmarks and puncture marks on the bones of prey animals. In 2010, Shannon McPherron and coworkers reported that 3.4-million-year-old animal bones from Dikika, Ethiopia, show cutmarks from stone tools, although they did not find the artifacts themselves. Some other researchers disputed this evidence, suggesting that crocodiles or other carnivores might have generated these marks. </p><p>A higher degree of acceptance has been given to claims of cutmarks and puncture marks on antelope and horse bones from 2.5 million years ago, at Bouri, Ethiopia. Some of these discoveries were near the BOU-VP-12 locality with fossil material of <em>Australopithecus garhi</em>. Other sites from this region, including Gona, Hadar, and Ledi-Geraru, do preserve stone artifacts from the same time or earlier, but without any associated hominin remains. Later, around 3.3 million years ago, stone tools from Hadar have been associated with a maxilla attributed to early <em>Homo</em>, but the first possible mandible of <em>Homo</em> from Ledi-Geraru is not from a locality with artifacts. </p><p><em>Australopithecus africanus</em> remains a challenging case. No stone tools have been found in contexts where <em>Au. africanus</em> fossils clearly occur, at Sterkfontein, Makapan Limeworks, or Taung. Recent work has shown that the Sterkfontein Member 4 fossils of <em>Au. africanus</em> may be older than 3.4 million years—therefore, older than any known artifacts anywhere. The Makapan and Taung sites themselves may be older than 2.8 million, and so it is possible that <em>Au. africanus</em> simply existed before stone tools were used in South Africa. Yet there remains some uncertainty. For one thing, some authors dispute the idea that Sterkfontein Member 4 is as early as 3.4 million years, preferring a date between 2.6 million and 2.1 million years ago. Another element of uncertainty comes from the StW 53 cranium, which I and many other scientists attribute to <em>Au. africanus</em>, and which has marks on its maxilla that some authors have argued are cutmarks from a stone artifact. Just as for <em>Paranthropus</em>, the anatomical evidence from the hand bones of <em>Au. africanus</em> suggests that this species had the fine precision grip and relied on hand postures that today's humans use for making and using tools. </p><figure><img src="https://johnhawks.net/content/images/2023/12/sediba-wrist-and-hand-johnhawks.jpg" alt="A view of the wrist anatomy of an articulated fossil hand" loading="lazy" width="1600" height="900" srcset="https://johnhawks.net/content/images/size/w600/2023/12/sediba-wrist-and-hand-johnhawks.jpg 600w, https://johnhawks.net/content/images/size/w1000/2023/12/sediba-wrist-and-hand-johnhawks.jpg 1000w, https://johnhawks.net/content/images/2023/12/sediba-wrist-and-hand-johnhawks.jpg 1600w" sizes="(min-width: 720px) 720px"><figcaption><span>Cast of the hand and wrist of MH2, </span><i><em>Australopithecus sediba</em></i><span>, from Malapa, South Africa. Photo: John Hawks</span></figcaption></figure><p>The notable late <em>Australopithecus</em> site is Malapa, with <em>Australopithecus sediba</em> at 1.977 million years ago. No artifacts have yet been reported from this locality. Still, recent work from Clément Zanolli and coworkers has shown that many dental and mandibular fossils from Swartkrans, Drimolen, and Sterkfontein Member 5 that were previously attributed to <em>Homo</em> may instead belong to <em>Paranthropus</em> or <em>Australopithecus</em>. It seems probable that many of these may be unrecognized <em>Au. sediba</em> individuals. Any of those would be associated with Oldowan artifacts and bone tools from these sites. </p><p>The well-known species of <em>Homo</em> that doesn't show up in the dataset on associations of artifacts and fossils is <em>Homo rudolfensis</em>. This is another case where only a handful of fossils are clearly associated with this species. It may be surprising, but I would argue that only four fossils might be strongly linked to <em>H. rudolfensis</em>: the KNM-ER 1470 cranium, KNM-ER 62000 subadult face, and two mandibular fossils—KNM-ER 60000 and KNM-ER 62003. None are from localities with archaeological material. There are other fossils that might conceivably belong to <em>H. rudolfensis</em>, but many of the ones that past anthropologists connected with this species, like the KNM-ER 1802 mandible or the UR 501 mandible from Uraha, Malawi, may be <em>Australopithecus</em> instead. </p><h3 id="toolmaking-ecology-across-species">Toolmaking ecology across species</h3><p>It's clear that associations of fossils and artifacts can go only so far. Robinson preferred the hypothesis that the most advanced hominin on the scene must have made any artifacts. Many researchers during the last 60 years have followed this point of view. But today's data allow us to test whether any fossil species is consistently associated with artifacts. After around 2.8 million years ago every fossil species is found with artifacts, with the few exceptions being those species that have been identified from only a single locality or—in the case of <em>H. rudolfensis</em>—a handful of localities. The two branches that are found most regularly with artifactual evidence, <em>Paranthropus</em> and <em>Homo</em>, are both represented at archaeological localities in equal measure; only <em>Paranthropus</em> is present at the earliest two Oldowan localities. </p><p>It is hard for me to improve on C. K. Brain's conclusions about tool use. By the Early Pleistocene, all hominins had the anatomical capability of making and using stone tools, and most of them did so. As in living bonobos and chimpanzees, tool use may have differed markedly between species and populations, depending upon their particular ecological situations. It was the uses of the tools that differentiated the hominins, not the capacity to use tools. </p><p>Yet maybe even this underestimates the commonalities across species. Stable isotopes and dental microwear suggest that <em>P. robustus</em> and early <em>Homo</em> in southern Africa were eating similar foods, despite what seem to be some important differences in dental morphology. If their ecologies were much the same, and their hand anatomies were much the same, it is hard to justify any assumption that they would have been different in their use of tools. </p><p>Going further, wherever both species existed they both would have encountered each other's trash. Each individual scattering stone across a landscape changed the potentialities for every other hominin. Each species existed within the ecology of the other. When one was rapping cobble on core, others heard them hundreds of meters away. They learned from each other. Their use of resources must often have converged. </p><p>Darwin wrote eloquently about the way that small steps in tool use would change the potentialities for “primeval” humans. </p><blockquote>“The Duke of Argyll&nbsp;remarks, that the fashioning of an implement for a special purpose is absolutely peculiar to man; and he considers that this forms an immeasurable gulf between him and the brutes. It is no doubt a very important distinction, but there appears to me much truth in Sir J. Lubbock's suggestion,&nbsp;that when primeval man first used flint-stones for any purpose, he would have accidentally splintered them, and would then have used the sharp fragments. From this step it would be a small one to intentionally break the flints, and not a very wide step to rudely fashion them.”—Charles Darwin</blockquote><p>Tool use does not make humans unique; it links us to our ancestors and relatives. Those links that remain are phylogenetic, but they were once living cultural links. It is true that recent humans have become reliant upon our tools in ways that early hominins would not have recognized. Before this time we lived in a world of transitions into and out of technical traditions. The steps across species in tool use were once small ones, interconnected actions that spanned differences in body size and form. </p><hr><p><em><strong>Notes:</strong> The current evidence of hand anatomy in various hominins is ably reviewed in several papers by Tracy Kivell, Matt Skinner, and many of their collaborators. The work by Cl</em>é<em>ment Zanolli and coworkers highlighting internal dental evidence for affinities of South African dental material is worth reading for its broader implications: we have little reliable information about the species identity of many isolated finds. I did not include in the references below all the works that underlie the dataset described by Sandrine Prat, or every paper related to the dating of sites discussed in the post. </em></p><p><em>I've only included a few words here about the cultural behavior of chimpanzees and bonobos. This is a rich area with deep importance for understanding early hominins, and hopefully I will be able to expand on this in an additional post. </em></p><p><em>There may be readers who suspect I am being unfair to Wallace in this comparison of views on technology. The differences between Wallace and Darwin on the extent that natural selection could explain human cultural abilities have been the subject of many historians of science, and two paragraphs inevitably oversimplify these differences. I think it's fair to say that Darwin and Wallace were concerned with different aspects of the human origins problem. </em></p><h3 id="references">References</h3><p>Brain, C. K., Churcher, C. S., Clark, J. D., Grine, F. F., Shipman, P., Susman, R. L., Turner, A. and Watson V. (1988). New evidence of early hominids, their culture and environment from the Swartkrans cave, South Africa.&nbsp;<em>South African Journal of Science</em>,&nbsp;<em>84</em>(10), 828.&nbsp;<a href="https://doi.org/10.10520/AJA00382353_6877?ref=johnhawks.net">https://doi.org/10.10520/AJA00382353_6877</a></p><p>Darwin, C. (1871).&nbsp;<em>The Descent of Man, and Selection in Relation to Sex</em>. John Murray.</p><p>Flicker, D., &amp; Key, A. (2023). Statistical assessment of the temporal and cultural relationship between the Lomekwian and Oldowan.&nbsp;<em>Journal of Archaeological Science: Reports</em>,&nbsp;<em>48</em>, 103834.&nbsp;<a href="https://doi.org/10.1016/j.jasrep.2023.103834?ref=johnhawks.net">https://doi.org/10.1016/j.jasrep.2023.103834</a></p><p>Harmand, S., Lewis, J. E., Feibel, C. S., Lepre, C. J., Prat, S., Lenoble, A., Boës, X., Quinn, R. L., Brenet, M., Arroyo, A., Taylor, N., Clément, S., Daver, G., Brugal, J.-P., Leakey, L., Mortlock, R. A., Wright, J. D., Lokorodi, S., Kirwa, C., … Roche, H. (2015). 3.3-million-year-old stone tools from Lomekwi 3, West Turkana, Kenya.&nbsp;<em>Nature</em>,&nbsp;<em>521</em>(7552), Article 7552.&nbsp;<a href="https://doi.org/10.1038/nature14464?ref=johnhawks.net">https://doi.org/10.1038/nature14464</a></p><p>Kivell, T. L., Baraki, N., Lockwood, V., Williams-Hatala, E. M., &amp; Wood, B. A. (2023). Form, function and evolution of the human hand.&nbsp;<em>American Journal of Biological Anthropology</em>,&nbsp;<em>181</em>(S76), 6–57.&nbsp;<a href="https://doi.org/10.1002/ajpa.24667?ref=johnhawks.net">https://doi.org/10.1002/ajpa.24667</a></p><p>Kühl, H. S., Kalan, A. K., Arandjelovic, M., Aubert, F., D’Auvergne, L., Goedmakers, A., Jones, S., Kehoe, L., Regnaut, S., Tickle, A., Ton, E., van Schijndel, J., Abwe, E. E., Angedakin, S., Agbor, A., Ayimisin, E. A., Bailey, E., Bessone, M., Bonnet, M., … Boesch, C. (2016). Chimpanzee accumulative stone throwing.&nbsp;<em>Scientific Reports</em>,&nbsp;<em>6</em>(1), Article 1.&nbsp;<a href="https://doi.org/10.1038/srep22219?ref=johnhawks.net">https://doi.org/10.1038/srep22219</a></p><p>Leakey, L. S. B. (1959). A New Fossil Skull From Olduvai.&nbsp;<em>Nature</em>,&nbsp;<em>184</em>(4685), Article 4685.&nbsp;<a href="https://doi.org/10.1038/184491a0?ref=johnhawks.net">https://doi.org/10.1038/184491a0</a></p><p>Leakey, L. S. B., Tobias, P. V., &amp; Napier, J. R. (1964). A New Species of The Genus Homo From Olduvai Gorge.&nbsp;<em>Nature</em>,&nbsp;<em>202</em>(4927), Article 4927.&nbsp;<a href="https://doi.org/10.1038/202007a0?ref=johnhawks.net">https://doi.org/10.1038/202007a0</a></p><p>McPherron, S. P., Alemseged, Z., Marean, C. W., Wynn, J. G., Reed, D., Geraads, D., Bobe, R., &amp; Béarat, H. A. (2010). Evidence for stone-tool-assisted consumption of animal tissues before 3.39 million years ago at Dikika, Ethiopia.&nbsp;<em>Nature</em>,&nbsp;<em>466</em>(7308), Article 7308.&nbsp;<a href="https://doi.org/10.1038/nature09248?ref=johnhawks.net">https://doi.org/10.1038/nature09248</a></p><p>Oakley, K. (1957). Tools Makyth Man.&nbsp;<em>Antiquity</em>,&nbsp;<em>31</em>(124), 199–209.&nbsp;<a href="https://doi.org/10.1017/S0003598X00028453?ref=johnhawks.net">https://doi.org/10.1017/S0003598X00028453</a></p><p>Plummer, T. W., Oliver, J. S., Finestone, E. M., Ditchfield, P. W., Bishop, L. C., Blumenthal, S. A., Lemorini, C., Caricola, I., Bailey, S. E., Herries, A. I. R., Parkinson, J. A., Whitfield, E., Hertel, F., Kinyanjui, R. N., Vincent, T. H., Li, Y., Louys, J., Frost, S. R., Braun, D. R., … Potts, R. (2023). Expanded geographic distribution and dietary strategies of the earliest Oldowan hominins and <em>Paranthropus</em>.&nbsp;<em>Science</em>,&nbsp;<em>379</em>(6632), 561–566.&nbsp;<a href="https://doi.org/10.1126/science.abo7452?ref=johnhawks.net">https://doi.org/10.1126/science.abo7452</a></p><p>Prat, S. (2023). Beyond the genus stereotype. Who were the first toolmarkers in Africa? Crossed views between archaeology and anatomy.&nbsp;<em>L’Anthropologie</em>,&nbsp;<em>127</em>(4), 103187.&nbsp;<a href="https://doi.org/10.1016/j.anthro.2023.103187?ref=johnhawks.net">https://doi.org/10.1016/j.anthro.2023.103187</a></p><p>Robinson, J. T. (1957). Occurrence of Stone Artefacts with Australopithecus at Sterkfontein: Part 1.&nbsp;<em>Nature</em>,&nbsp;<em>180</em>(4585), Article 4585.&nbsp;<a href="https://doi.org/10.1038/180521a0?ref=johnhawks.net">https://doi.org/10.1038/180521a0</a></p><p>Robinson, J. T., &amp; Mason, R. J. (1962). Australopithecines and Artefacts at Sterkfontein.&nbsp;<em>The South African Archaeological Bulletin</em>,&nbsp;<em>17</em>(66), 87–126.&nbsp;<a href="https://doi.org/10.2307/3886942?ref=johnhawks.net">https://doi.org/10.2307/3886942</a></p><p>Wallace, A. R. (1864). The Origin of Human Races and the Antiquity of Man Deduced from the Theory of “Natural Selection.”&nbsp;<em>Journal of the Anthropological Society of London</em>,&nbsp;<em>2</em>, clviii–clxxxvii.&nbsp;<a href="https://doi.org/10.2307/3025211?ref=johnhawks.net">https://doi.org/10.2307/3025211</a></p><p>Washburn, S. L. (1959). Speculations on the Interrelations of the History of Tools and Biological Evolution.&nbsp;<em>Human Biology</em>,&nbsp;<em>31</em>(1), 21–31. <a href="https://www.jstor.org/stable/41449226?ref=johnhawks.net">https://www.jstor.org/stable/41449226</a></p><p>Washburn, S. L. (1960). Tools and Human Evolution.&nbsp;<em>Scientific American</em>,&nbsp;<em>203</em>(3), 62–75.</p><p>Zanolli, C., Davies, T. W., Joannes-Boyau, R., Beaudet, A., Bruxelles, L., de Beer, F., Hoffman, J., Hublin, J.-J., Jakata, K., Kgasi, L., Kullmer, O., Macchiarelli, R., Pan, L., Schrenk, F., Santos, F., Stratford, D., Tawane, M., Thackeray, F., Xing, S., … Skinner, M. M. (2022). Dental data challenge the ubiquitous presence of Homo in the Cradle of Humankind.&nbsp;<em>Proceedings of the National Academy of Sciences</em>,&nbsp;<em>119</em>(28), e2111212119.&nbsp;<a href="https://doi.org/10.1073/pnas.2111212119?ref=johnhawks.net">https://doi.org/10.1073/pnas.2111212119</a></p>
      </section>

          <section>
            <a href="https://johnhawks.net/tag/technology/">technology</a><a href="https://johnhawks.net/tag/early-stone-age/">Early Stone Age</a><a href="https://johnhawks.net/tag/australopithecus-africanus/">Australopithecus africanus</a><a href="https://johnhawks.net/tag/australopithecus-sediba/">Australopithecus sediba</a><a href="https://johnhawks.net/tag/kenyanthropus-platyops/">Kenyanthropus platyops</a><a href="https://johnhawks.net/tag/homo-habilis/">Homo habilis</a><a href="https://johnhawks.net/tag/homo-rudolfensis/">Homo rudolfensis</a><a href="https://johnhawks.net/tag/homo-erectus/">Homo erectus</a><a href="https://johnhawks.net/tag/paranthropus-boisei/">Paranthropus boisei</a><a href="https://johnhawks.net/tag/paranthropus-robustus/">Paranthropus robustus</a>
          </section>

        
          <section>
    <p><img data-src="/content/images/size/w320/2022/02/skhul-headshot-john-hawks.jpg" alt="John Hawks" width="80" height="80" src="https://johnhawks.net/content/images/size/w320/2022/02/skhul-headshot-john-hawks.jpg"></p>

  <div>
    

      <p>I'm a paleoanthropologist exploring the world of ancient humans and our fossil relatives. </p>
  </div>
</section>
        
        <div>
                <h2>John Hawks Newsletter</h2>
                <p>Join the newsletter to receive the latest updates in your inbox.</p>
                
<form data-members-form="signup">
  <p><label for="subscribe-box-email">Your email address</label>
    
    
  </p>

  <p>Please check your inbox and click the link to confirm your subscription.</p>
  <p>Please enter a valid email address!</p>
  <p>An error occurred, please try again later.</p>
</form>              </div>

        
    </article>
  </div><div>
          <div>
  <div>
    <p><time datetime="2023-10-13">13 Oct 2023</time></p><p><span>Paid</span>
        <span>Members</span>
        <span>Public</span>
      </p>
  </div>

  <div>
    <h2>
      <a href="https://johnhawks.net/weblog/homo-erectus-keeps-getting-older/">Homo erectus keeps getting older</a>
    </h2>
    <p>New work from Melka Kunture, Ethiopia, shows the Garba IVE infant jaw is one of the oldest individuals of this longest-lasting hominin species.</p>
  </div>

    <div>
      <p><img alt="Lingual and buccal views of Garba IVE mandible fragment" data-srcset="
            /content/images/size/w730/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 612w,
            /content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 1462w" sizes="(min-width: 1280px) 153px, (min-width: 1040px) 12.27vw, (min-width: 640px) calc(22.37vw - 44px), calc(100vw - 32px)" data-src="/content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg" srcset="
            https://johnhawks.net/content/images/size/w730/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 612w,
            https://johnhawks.net/content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg 1462w" src="https://johnhawks.net/content/images/size/w1460/2023/10/garba-ive-lingual-buccal-photo-le-cabec-2021.jpg">
      </p>
    </div>
</div>          <div>
  <div>
    <p><time datetime="2023-09-20">20 Sep 2023</time></p><p><span>Paid</span>
        <span>Members</span>
        <span>Public</span>
      </p>
  </div>

  <div>
    <h2>
      <a href="https://johnhawks.net/weblog/guide-to-australopithecus-species/">Guide to Australopithecus species</a>
    </h2>
    <p>These ancient human relatives include the first species with evidence of upright walking and running like humans. They represent more than a third of our evolutionary history.</p>
  </div>

    <div>
      <p><img alt="Five fossil skulls in three-quarter view looking toward the right" data-srcset="
            /content/images/size/w730/2023/09/australopithecus-skulls-montage.jpg 612w,
            /content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg 1462w" sizes="(min-width: 1280px) 153px, (min-width: 1040px) 12.27vw, (min-width: 640px) calc(22.37vw - 44px), calc(100vw - 32px)" data-src="/content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg" srcset="
            https://johnhawks.net/content/images/size/w730/2023/09/australopithecus-skulls-montage.jpg 612w,
            https://johnhawks.net/content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg 1462w" src="https://johnhawks.net/content/images/size/w1460/2023/09/australopithecus-skulls-montage.jpg">
      </p>
    </div>
</div>          <div>
  <div>
    <p><time datetime="2023-09-03">3 Sep 2023</time></p><p><span>Paid</span>
        <span>Members</span>
        <span>Public</span>
      </p>
  </div>

  <div>
    <h2>
      <a href="https://johnhawks.net/weblog/real-story-myosin-jaw-muscles-ancient-brains/">The real story of myosin, jaw muscles, and ancient brains</a>
    </h2>
    <p>The provocative idea that our genus arose with a deactivated muscle gene turned out to be wrong.</p>
  </div>

    <div>
      <p><img alt="Bonobo and gorilla head and neck, showing ecorché muscles on the left side of each" data-srcset="
            /content/images/size/w730/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 612w,
            /content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 1462w" sizes="(min-width: 1280px) 153px, (min-width: 1040px) 12.27vw, (min-width: 640px) calc(22.37vw - 44px), calc(100vw - 32px)" data-src="/content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png" srcset="
            https://johnhawks.net/content/images/size/w730/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 612w,
            https://johnhawks.net/content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png 1462w" src="https://johnhawks.net/content/images/size/w1460/2023/08/bonobo-gorilla-head-muscles-visible-ape-data-left-oblique.png">
      </p>
    </div>
</div>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lobsters (245 pts)]]></title>
            <link>https://github.com/lobsters/lobsters</link>
            <guid>38508282</guid>
            <pubDate>Sun, 03 Dec 2023 16:34:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lobsters/lobsters">https://github.com/lobsters/lobsters</a>, See on <a href="https://news.ycombinator.com/item?id=38508282">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h3 tabindex="-1" dir="auto">Lobsters Rails Project <a target="_blank" rel="noopener noreferrer" href="https://github.com/lobsters/lobsters/actions/workflows/check.yml/badge.svg"><img src="https://github.com/lobsters/lobsters/actions/workflows/check.yml/badge.svg" alt="build status"></a></h3>
<p dir="auto">This is the
<a href="https://web.archive.org/web/20230213161624/https://old.reddit.com/r/rails/comments/6jz7tq/source_code_lobsters_a_hacker_news_clone_built/" rel="nofollow">quite sad</a>
source code to the
<a href="https://twitter.com/webshitweekly/status/1399935275057389571" rel="nofollow">ghost town</a> at
<a href="https://lobste.rs/" rel="nofollow">https://lobste.rs</a>.
It is a Rails codebase and uses a SQL (MariaDB in production) backend for the database.</p>
<p dir="auto">You are free to use this code to start your own <a href="https://github.com/lobsters/lobsters/wiki">sister site</a>
because the code is available under a <a href="https://github.com/lobsters/lobsters/blob/master/LICENSE">permissive license</a> (3-clause BSD).
We welcome bug reports and code contributions that help use improve <a href="https://lobste.rs/" rel="nofollow">lobste.rs</a>.
As a volunteer project we're reluctant to take on work that's not useful to our site, so please understand if we don't want to adopt your custom feature.</p>
<h4 tabindex="-1" dir="auto">Contributing bugfixes and new features</h4>
<p dir="auto">We'd love to have your help.
Please see the <a href="https://github.com/lobsters/lobsters/blob/master/CONTRIBUTING.md">CONTRIBUTING</a> file for details.
If you have questions, there is usually someone in <a href="https://lobste.rs/chat" rel="nofollow">our chat room</a> who's familiar with the code.</p>
<h4 tabindex="-1" dir="auto">Initial setup</h4>
<p dir="auto">Use the steps below for a local install or
<a href="https://github.com/lobsters/lobsters-ansible">lobsters-ansible</a> for our production deployment config.
There's an external project <a href="https://github.com/utensils/docker-lobsters">docker-lobsters</a> if you want to use Docker.</p>
<ul dir="auto">
<li>
<p dir="auto">Install the Ruby version specified in <a href="https://github.com/lobsters/lobsters/blob/master/.ruby-version">.ruby-version</a></p>
</li>
<li>
<p dir="auto">Checkout the lobsters git tree from Github</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:lobsters/lobsters.git
$ cd lobsters
lobsters$"><pre>$ git clone git@github.com:lobsters/lobsters.git
$ <span>cd</span> lobsters
lobsters$</pre></div>
</li>
<li>
<p dir="auto">Install Nodejs, needed (or other execjs) for uglifier</p>
<div dir="auto" data-snippet-clipboard-copy-content="Fedora: sudo yum install nodejs
Ubuntu: sudo apt-get install nodejs
OSX: brew install nodejs"><pre>Fedora: sudo yum install nodejs
Ubuntu: sudo apt-get install nodejs
OSX: brew install nodejs</pre></div>
</li>
<li>
<p dir="auto">Run Bundler to install/bundle gems needed by the project:</p>

<ul dir="auto">
<li>If when installing the <code>mysql2</code> gem on macOS, you see
<code>ld: library not found for -l-lpthread</code> in the output, see
<a href="https://stackoverflow.com/a/44790834/204052" rel="nofollow">this solution</a> for a fix.
You might also see <code>ld: library not found for -lssl</code> if you're using
macOS 10.4+ and Homebrew <code>openssl</code>, in which case see
<a href="https://stackoverflow.com/a/39628463/1042144" rel="nofollow">this solution</a>.</li>
</ul>
</li>
<li>
<p dir="auto">Create a MySQL (other DBs supported by ActiveRecord may work, only MySQL and
MariaDB have been tested) database, username, and password and put them in a
<code>config/database.yml</code> file.  You will also want a separate database for
running tests:</p>
<div dir="auto" data-snippet-clipboard-copy-content="development:
  adapter: mysql2
  encoding: utf8mb4
  reconnect: false
  database: lobsters_dev
  socket: /tmp/mysql.sock
  username: *dev_username*
  password: *dev_password*
  
test:
  adapter: mysql2
  encoding: utf8mb4
  reconnect: false
  database: lobsters_test
  socket: /tmp/mysql.sock
  username: *test_username*
  password: *test_password*"><pre><span>development</span>:
  <span>adapter</span>: <span>mysql2</span>
  <span>encoding</span>: <span>utf8mb4</span>
  <span>reconnect</span>: <span>false</span>
  <span>database</span>: <span>lobsters_dev</span>
  <span>socket</span>: <span>/tmp/mysql.sock</span>
  <span>username</span>: <span>*dev_username*</span>
  <span>password</span>: <span>*dev_password*</span>
  
<span>test</span>:
  <span>adapter</span>: <span>mysql2</span>
  <span>encoding</span>: <span>utf8mb4</span>
  <span>reconnect</span>: <span>false</span>
  <span>database</span>: <span>lobsters_test</span>
  <span>socket</span>: <span>/tmp/mysql.sock</span>
  <span>username</span>: <span>*test_username*</span>
  <span>password</span>: <span>*test_password*</span></pre></div>
</li>
<li>
<p dir="auto">Load the schema into the new database:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lobsters$ rails db:schema:load"><pre>lobsters$ rails db:schema:load</pre></div>
</li>
<li>
<p dir="auto">On your production server, copy <code>config/initializers/production.rb.sample</code>
to <code>config/initalizers/production.rb</code> and customize it with your site's
<code>domain</code> and <code>name</code>. (You don't need this on your dev machine).</p>
</li>
<li>
<p dir="auto">Seed the database to create an initial administrator user, the <code>inactive-user</code>, and at least one tag:</p>

</li>
<li>
<p dir="auto">On your personal computer, you can add some sample data and run the Rails server in development mode.
You should be able to login to <code>http://localhost:3000</code> with your new <code>test</code> user:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lobsters$ rails fake_data
lobsters$ rails server"><pre>lobsters$ rails fake_data
lobsters$ rails server</pre></div>
</li>
<li>
<p dir="auto">Deploying the site in production requires setting up a web server and running the app in production mode.
There are more tools and options available than we can describe; find a guide or an expert.
The lobsters-ansible repo has our config files to crib from. Some app-specific notes:</p>
</li>
<li>
<p dir="auto">Set up crontab or another scheduler to run regular jobs:</p>
<div data-snippet-clipboard-copy-content="*/5 * * * *  cd /path/to/lobsters &amp;&amp; env RAILS_ENV=production sh -c 'bundle exec ruby script/mail_new_activity; bundle exec ruby script/post_to_twitter; bundle exec ruby script/traffic_range'"><pre><code>*/5 * * * *  cd /path/to/lobsters &amp;&amp; env RAILS_ENV=production sh -c 'bundle exec ruby script/mail_new_activity; bundle exec ruby script/post_to_twitter; bundle exec ruby script/traffic_range'
</code></pre></div>
</li>
<li>
<p dir="auto">See <code>config/initializers/production.rb.sample</code> for GitHub/Twitter integration help.</p>
</li>
<li>
<p dir="auto">You probably want to use <a href="https://lobste.rs/s/dbm2d4" rel="nofollow">git-imerge</a> to pull in
changes from Lobsters to your site.</p>
</li>
</ul>
<h4 tabindex="-1" dir="auto">Administration</h4>
<p dir="auto">Basic moderation happens on-site, but most other administrative tasks require use of the rails console in production.
Administrators can create and edit tags at <code>/tags</code>.</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Watsonx: IBM's code assistant for turning COBOL into Java (112 pts)]]></title>
            <link>https://www.pcmag.com/articles/ibms-plan-to-update-cobol-with-watson</link>
            <guid>38508250</guid>
            <pubDate>Sun, 03 Dec 2023 16:31:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcmag.com/articles/ibms-plan-to-update-cobol-with-watson">https://www.pcmag.com/articles/ibms-plan-to-update-cobol-with-watson</a>, See on <a href="https://news.ycombinator.com/item?id=38508250">Hacker News</a></p>
Couldn't get https://www.pcmag.com/articles/ibms-plan-to-update-cobol-with-watson: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>