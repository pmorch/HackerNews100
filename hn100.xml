<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 07 Aug 2024 19:30:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Official proposal for Type Unions in C# (116 pts)]]></title>
            <link>https://github.com/dotnet/csharplang/blob/18a527bcc1f0bdaf542d8b9a189c50068615b439/proposals/TypeUnions.md</link>
            <guid>41183240</guid>
            <pubDate>Wed, 07 Aug 2024 17:02:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dotnet/csharplang/blob/18a527bcc1f0bdaf542d8b9a189c50068615b439/proposals/TypeUnions.md">https://github.com/dotnet/csharplang/blob/18a527bcc1f0bdaf542d8b9a189c50068615b439/proposals/TypeUnions.md</a>, See on <a href="https://news.ycombinator.com/item?id=41183240">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;packages&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;packages_link_product_navbar&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_product_navbar&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>

                  <li>
      
      
</li>

                  <li>
      
      <div>
                <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;white_papers_ebooks_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;white_papers_ebooks_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:dotnet/csharplang" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="FYIMrCnb55NrgkdfSEdBnMwrmiM2yxqYkwq__WK7JhFHqhYdLUaBhssmkbld-qO0f6g2OV43woq73K0UkZjWvA" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="dotnet/csharplang" data-current-org="dotnet" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=dotnet%2Fcsharplang" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/dotnet/csharplang/blob/18a527bcc1f0bdaf542d8b9a189c50068615b439/proposals/TypeUnions.md&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="069d1a30fab49cfd912b12ca207c4b569a1129407d0870735717e169b51a9c58" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tony Hawk's Pro Strcpy (161 pts)]]></title>
            <link>https://icode4.coffee/?p=954</link>
            <guid>41183115</guid>
            <pubDate>Wed, 07 Aug 2024 16:48:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://icode4.coffee/?p=954">https://icode4.coffee/?p=954</a>, See on <a href="https://news.ycombinator.com/item?id=41183115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
									
									
<figure><p>
<iframe title="Tony Hawk's Pro Strcpy" width="470" height="264" src="https://www.youtube.com/embed/Pjqw1Gwk0jg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Back in 2016 I really wanted to improve my exploit development skills and find some new bugs to hack the original Xbox. For many years people could download a hacked game save for games like 007 Agent Under Fire, Splinter Cell, or Mechassault and use it to hack their console. These game save hacks worked by exploiting trivial buffer overflows that would give the attacker code execution on the console and run unsigned code (code not authorized by Microsoft). From there you’d typically install some hacked OS files that would allow your console to run homebrew and pirated games. Being into computer security I knew all the academics of how exploit techniques like memory corruption and ROP worked but had no experience actually writing an exploit that used any of these techniques. I wasn’t going to try and write an exploit for a modern game console or PC without getting some elementary level experience under my belt first, which is why I turned to older gaming consoles.</p>



<p>Devices from the early-mid 2000s (or y2k devices as I like to call them) are a great platform for anyone wanting to learn more about how computer hardware works, exploit development, software development, etc. They have a low barrier to entry because they don’t have any of the security mitigations a more modern device will have and a lot of information on the inner workings have been thoroughly researched and documented. However, there’s still a lot of things yet to be discovered or learned about these consoles and any seasoned exploit developer can have a lot of fun treating these as “CTF” devices while in search of an easier way to hack the console.</p>



<h2>Part 1: Dropping in</h2>



<p>I started with the game save approach and began looking through the game saves I had from a backup of one of my consoles. The first game save I happen to open was for Tony Hawk’s Pro Skater 4. It was a custom park made with the “Create-A-Park” feature which was like a mini level editor players could use to create their own skate parks. Looking at the save file in a hex editor something immediately stuck out to me:</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/gap_name.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-955&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1902,&quot;targetHeight&quot;:361,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img fetchpriority="high" decoding="async" width="1902" height="361" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/gap_name.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/gap_name.png 1902w, https://icode4.coffee/wp-content/uploads/gap_name-300x57.png 300w, https://icode4.coffee/wp-content/uploads/gap_name-768x146.png 768w, https://icode4.coffee/wp-content/uploads/gap_name-1536x292.png 1536w" sizes="(max-width: 1902px) 100vw, 1902px"><figcaption>Hex view of the save file</figcaption></figure></div>


<p>The “Create-A-Park” feature allows you to create what’s known as a “gap”, which is a term in skateboarding used to describe an area between two platforms you jump over. THPS4 allows you to name the gap so when a player successfully clears the gap the name will appear in screen with a point value. It added additional depth to the feature back in the early 2000s when the idea of creating your own level as a feature of a console game was still pretty novel. But for me it meant I had a starting point for bug hunting. This custom string had a max length of 31 characters (+ a null terminator), and presumably this would be run through some sort of string copy function. If I was lucky it would be strcpy (opposed to something like strncpy) and I might be able to use it as a memory corruption primitive. </p>



<p>I crafted a malicious save file by changing the string to some really long repeating ‘0x41’ character sequence and copied it back to my Xbox. For testing I’d be using an already hacked Xbox console that had full debugging capabilities which would allow me to step through individual CPU instructions and investigate memory contents. Upon loading the game save the console crashed and looking at the CPU state I could see the instruction pointer was set to 0x41414141 which meant the gap name string was likely being copied to the stack using strcpy. After finding the address of where the strcpy was happening I opened it in IDA for easier analysis:</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/strcpy_call-1.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-959&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:640,&quot;targetHeight&quot;:283,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" width="640" height="283" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/strcpy_call-1.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/strcpy_call-1.png 640w, https://icode4.coffee/wp-content/uploads/strcpy_call-1-300x133.png 300w" sizes="(max-width: 640px) 100vw, 640px"></figure></div>


<p>The disassembly is a little hard to follow because the parameters for the inline strcpy call have been optimized but here’s the relevant pseudo code for the function that loads the save file data:</p>



<div id="urvanov-syntax-highlighter-66b3cb3c523eb582432218" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p></div>
				</td>
						<td><div><p><span>struct</span><span> </span><span>save_file_gap_data</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>char</span><span> </span><span>gap_name</span><span>[</span><span>32</span><span>]</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span><span>;</span></p><p><span>struct</span><span> </span><span>gap_description</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>char</span><span> </span><span>gap_name</span><span>[</span><span>32</span><span>]</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span><span>;</span></p><p><span>void</span><span> </span><span>read_park_file</span><span>(</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Loop through all the gaps in the park file.</span></p><p><span>	</span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>park_header</span><span>-&gt;</span><span>gap_count</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>gap_description </span><span>gapDesc</span><span>;</span></p><p><span>		</span><span>save_file_gap_data</span><span>*</span><span> </span><span>pGapData</span><span> </span><span>=</span><span> </span><span>(</span><span>save_file_gap_data</span><span>*</span><span>)</span><span>pParkDataPtr</span><span>;</span></p><p><span>		</span><span>.</span><span>.</span><span>.</span></p><p><span>		</span><span>// Copy the gap name locally.</span></p><p><span>		</span><span>strcpy</span><span>(</span><span>gapDesc</span><span>.</span><span>gap_name</span><span>,</span><span> </span><span>pGapData</span><span>-&gt;</span><span>gap_name</span><span>)</span><span>;</span></p><p><span>		</span><span>.</span><span>.</span><span>.</span></p><p><span>		</span><span>// Register the gap data parsed from the save file.</span></p><p><span>		</span><span>sub_EA520</span><span>(</span><span>&amp;</span><span>gapDesc</span><span>)</span><span>;</span></p><p><span>		</span><span>// Next gap.</span></p><p><span>		</span><span>pParkDataPtr</span><span> </span><span>+=</span><span> </span><span>sizeof</span><span>(</span><span>save_file_gap_data</span><span>)</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>As you can see the function loops through each gap in the save file and parses some information including the name which is copied to the gapDesc variable on the stack. There’s no bounds checking on the string so strcpy will continue to copy data until it reaches a null terminator. By overflowing the gap name string we can overwrite stack data including the return address for the function. This version of the game is conveniently compiled without stack cookies so we’re clear to trash as much data as we want. However, even once we control the return address not all memory is executable so we’ll need to do a little more work to get full code execution. </p>



<p>None of the gen 6 game consoles (Xbox, Playstation 2, Gamecube, Dreamcast) have any form of hardware data execution prevention (DEP) mitigations that would prevent regions of memory from being executable . However, Xbox does have some “soft DEP” that was used in later versions of the console and games but it can’t be applied to arbitrary regions of memory, it has to be a single contiguous region of memory. Basically, memory is only executable up to a certain address and everything thereafter is non-executable. This is achieved by changing the code segment selector address which defines the region of executable memory on the Pentium 3 processor. Later versions of the Xbox kernel will limit this region so not all memory is executable, but this really only prevents heap data from being executable and still leaves plenty of regions of RWX memory for us to use.</p>



<h2>Stick the landing</h2>



<p>The stack region and heap allocation containing the save file data are beyond the limit of the cs selector register, so we can’t execute code off either of these regions. However, all memory for the game executable including read-write data segments are in the executable region of memory, so all we need to do is find a way to copy some code to this area and we can execute it. This is where a ROP chain would prove useful but I actually found another way to achieve the same result that was a bit easier. </p>



<p>In addition to naming the gaps in the park file the game also lets you name the park itself. The park name string is stored in the header of the save file and the game must load this information after the player selects the save file so the name can be displayed in the UI. This header data is 136 bytes long and gets copied to a struct in the data segment of the executable which is in the executable region of memory. We can’t modify all of the header data as some fields need to be valid for the game to parse the file correctly. But there’s a small amount of data we can modify and it’s large enough to put a small memcpy stub there to copy our full payload to an executable region of memory and jump to it. Putting this all together we end up with the following:</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/thps4_memory_layout-1.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-1005&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1245,&quot;targetHeight&quot;:465,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1245" height="465" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/thps4_memory_layout-1.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/thps4_memory_layout-1.png 1245w, https://icode4.coffee/wp-content/uploads/thps4_memory_layout-1-300x112.png 300w, https://icode4.coffee/wp-content/uploads/thps4_memory_layout-1-768x287.png 768w" sizes="(max-width: 1245px) 100vw, 1245px"></figure></div>


<ol>
<li>After loading the save file but before the player presses “Start Game” the first 136 bytes of the save file are copied to the data segment of the game executable. This 136 bytes includes our shell code copy stub which will copy the full payload to an executable region of memory once we trigger the overflow.</li>



<li>After the player presses “Start Game” the save file will be loaded in full and our maliciously crafted gap name will be copied to the stack. The buffer is crafted specifically so that we overwrite the return address with the data segment address containing our shell code copy stub. </li>



<li>Once the park loading function returns it’ll jump to our shell code copy stub and copy a larger shell code payload from the save file buffer to some location in the game executable’s data segment that’s in the executable code region.</li>



<li>After copying the full payload the copy stub will jump to it giving us full arbitrary code execution.</li>
</ol>



<p>Now that we have full code execution on the console the next step is to disable signature enforcement and launch an unsigned executable, most likely one that could be used to further install softmod files on the console for a persistent hack. I’m not going to cover all the details of the security and OS on the Xbox or any other console mentioned in this post, but I will provide a brief overview of the steps used to patch the OS and launch additional unsigned code. I based this payload on the ones used in the existing softmod installer save files for 007 Agent Under Fire. The steps to patch out signature enforcement are as follows:</p>



<ol>
<li>Resolve the addresses of some kernel functions and data, the most notable being the address of the RSA public key used for signature validation of executable files.</li>



<li>Disable write protection in the machine state register and patch the RSA public key with the “habibi” key. </li>



<li>Launch a secondary executable file bundled in with the save game files, typically a softmod installer, though I used my classic “nyan cat” executable during all my testing. This executable must be signed with the habibi RSA key.</li>
</ol>



<details><summary>So what’s the “habibi” key?</summary>
<p>The habibi key pair is an RSA key that was generated by (presumably) the original Xbox Linux hacking group in the early 2000s. I haven’t been able to track down the entire back story to this key pair but this is what I’ve been able to conclude based on researching it. Rather than patching the RSA signature check out of the kernel which would allow for piracy the Xbox Linux group decided to instead replace the RSA public key with their own. This would allow them to sign their linux loader executable and run it on a console along with the game save hack but prevent people from using their game save to run pirated content (in theory). However, this didn’t really work since shortly after they released their exploit to run linux other hacking groups released additional exploit files to install a persistent hack on the console which completely removed the signature enforcement checks.</p>



<p>The more interesting thing about the habibi key is that the public key modulus only has a 4 byte difference compared to the Microsoft RSA public key. For reference the MS key is a 2048 bit RSA key. I’ve asked a few people how this might be possible and the answer I got is “if you change the exponent to something small like 3 you easily factor out a similar key”. This should require that the exponent of the public key is also patched to “3”. However, none of the shell code payloads that use the habibi key ever change the exponent used by the RSA signature verification routine. Presumably it’s still performing the validation using the exponent 65537 so I’m not entirely sure how this works. Perhaps someone more knowledgeable could shed some light on it.</p>
</details>



<p>So why use the habibi key instead of just patching the signature validation function to always return true? I initially wanted to do this but to make the exploit compatible with every kernel version released on the original Xbox would require I pattern match an instruction pattern with high probability for collisions, and I didn’t want to spend a bunch of time writing logic to decode instructions to additional validation of matches. Using the habibi key was easier because it only requires a 4 byte patch to memory I can easily find without pattern matching. </p>



<figure><video controls="" src="https://icode4.coffee/wp-content/uploads/thps4_xbox_exploit.mp4"></video></figure>



<p>With everything together I was able to load my hacked save file, get full code execution on the console, and run unsigned code. I was happy with the results but I wanted more so I looked at other iterations of the games in the Tony Hawk’s Pro Skater series to see how far back this bug went and how many versions of the game I could exploit with it.</p>



<h2>Variant analysis</h2>



<p>There’s a number of games in the Tony Hawk series and most of them have the Create-A-Park feature, so surely there’s more that are also exploitable. I worked backwards from THPS4 to see what the earliest version was that had the Create-A-Park feature and allowed you to use a custom name for gaps and found it was Tony Hawk’s Pro Skater 3. </p>



<h3>Tony Hawk’s Pro Skater 3</h3>



<p>I booted up THPS3 and created a custom park, fuzzed the gap name string and loaded the save again. However, this time the console didn’t crash when loading the save. I was able to spawn in and skate around, but as soon as I chose the “quit game” option the console crashed. Investigating the crash site revealed that the gap name string wasn’t being copied to the stack and was instead being copied to the heap. The overflow had overwritten some data in the next heap allocation and the console crashed when trying to free it. This piqued my interest because I was hoping to get experience with several different exploit techniques and not just rewriting the same strcpy bug several times over.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/thps3_cleanup_object_disassembly-1.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-965&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:802,&quot;targetHeight&quot;:400,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="802" height="400" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/thps3_cleanup_object_disassembly-1.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/thps3_cleanup_object_disassembly-1.png 802w, https://icode4.coffee/wp-content/uploads/thps3_cleanup_object_disassembly-1-300x150.png 300w, https://icode4.coffee/wp-content/uploads/thps3_cleanup_object_disassembly-1-768x383.png 768w" sizes="(max-width: 802px) 100vw, 802px"><figcaption>Disassembly for the THPS3 crash site</figcaption></figure></div>


<p>After investigating the crash some more I was able to determine that the game was using a custom memory allocator and by overflowing the gap name I was overwriting the allocation header for the next allocation in memory. When this next allocation was free’d the game would pull some pointers from the allocation header that lead to a vtable containing a function pointer for a cleanup routine.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/thps3_allocation_data.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-966&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1280,&quot;targetHeight&quot;:221,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1280" height="221" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/thps3_allocation_data.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/thps3_allocation_data.png 1280w, https://icode4.coffee/wp-content/uploads/thps3_allocation_data-300x52.png 300w, https://icode4.coffee/wp-content/uploads/thps3_allocation_data-768x133.png 768w" sizes="(max-width: 1280px) 100vw, 1280px"><figcaption>Heap allocation header data</figcaption></figure></div>


<p>This would be easy to exploit, however, unlike THPS4 this version of the game didn’t copy the header of the save file into the data segment, and the save file data was in non-executable heap memory. I’d need to find a way to get my shell code payload into executable memory and this was the perfect place to use a ROP chain. By overwriting the pAllocOwner pointer in the next allocation header I can control where the cleanup function pointer is loaded from. This can be set to the address of some instructions that would change the stack pointer to point to the malicious save data memory containing a ROP chain.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/thps3_exploit_memory.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-967&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1069,&quot;targetHeight&quot;:222,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="1069" height="222" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/thps3_exploit_memory.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/thps3_exploit_memory.png 1069w, https://icode4.coffee/wp-content/uploads/thps3_exploit_memory-300x62.png 300w, https://icode4.coffee/wp-content/uploads/thps3_exploit_memory-768x159.png 768w" sizes="(max-width: 1069px) 100vw, 1069px"><figcaption>Fake heap allocation header</figcaption></figure></div>


<p>The ROP chain only needed to be a few gadgets long to copy the full shell code payload into the executable region of memory and jump to it:</p>



<div id="urvanov-syntax-highlighter-66b3cb3c52401345060699" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p></div>
				</td>
						<td><div><p><span>; ROP gadget 0: 0x1BD19F -&gt; stack pivot</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;push</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>ecx</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; address of our fake heap allocation header</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>esp</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; esp is now set to the fake heap allocation header address</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>esi</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; esi now contains the address of the vtable</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;retn</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>0Ch</span></p><p><span>; ROP gadget 1: 0x45F69 -&gt; load memcpy parameters</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>esi</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; load the src address of the shell code</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>edi</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; load the data segment address for the shell code to be copied to</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>ecx</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; load the length of the shell code in dwords</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;retn</span></p><p><span>; ROP gadget 2: 0x19C4C1 -&gt; perform memcpy</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;rep</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>movsd</span><span>&nbsp;&nbsp; </span><span>; copy the shell code from the heap to the data segment</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>edi</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; load the data segment address for the shell code so we can jump to it</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>esi</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;retn</span></p><p><span>; ROP gadget 3: 0x1902DD -&gt; jump to the shell code</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;call</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>edi</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; jump to the shell code</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>.</span><span>.</span><span>.</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<p>This is actually the ROP chain pictured in my twitter profile banner (assuming I haven’t changed the picture since writing this post). The full payload was a generic “hack xbox kernel” payload I made for the THPS4 save exploit that would patch the RSA public key for executables to the habibi key and launch an unsigned executable. Putting everything together I had another save game exploit done, loading the hacked save file and then quitting the game would trigger the exploit and launch my nyan cat executable.</p>



<h3>Tony Hawk’s Underground 1 &amp; 2</h3>



<p>THUG started out with the same routine, create the park file, fuzz the gap name, and load the modified save. However, instead of getting some sort of crash for an access violation I received a full bug check and the following message in my debugger:</p>



<!-- Urvanov Syntax Highlighter v2.8.20 -->

		<div id="urvanov-syntax-highlighter-66b3cb3c5240c942196183" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>Buffer </span><span>overrun </span><span>detected</span><span>!</span></p><p><span>A</span><span> </span><span>buffer </span><span>overrun </span><span>has </span><span>been </span><span>detected </span><span>which </span><span>has </span><span>corrupted </span><span>the </span><span>program</span>'<span>s</span><span> </span><span>internal </span><span>state</span><span>.</span><span> </span><span>The </span><span>program </span><span>cannot </span><span>safely </span><span>continue</span><span> </span><span>execution </span><span>and</span><span> </span><span>must </span><span>now </span><span>be </span><span>terminated</span><span>.</span></p></div></td>
					</tr>
				</tbody></table>
			</div>
<!-- [Format Time: 0.0002 seconds] -->




<p>This means the game was compiled with stack cookies and my buffer overflow corrupted the cookie which caused the game to halt. Looking through the executable I found the save file loading function and confirmed the stack cookie check was there:</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/thug_stack_cookies.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-969&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:668,&quot;targetHeight&quot;:298,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="668" height="298" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/thug_stack_cookies.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/thug_stack_cookies.png 668w, https://icode4.coffee/wp-content/uploads/thug_stack_cookies-300x134.png 300w" sizes="(max-width: 668px) 100vw, 668px"></figure></div>


<p>A stack cookie is a random value generated when the executable first starts that gets placed on the stack of functions that perform certain copy operations to stack variables. The cookie sits before the return address (or immediately following the variable used in the copy operations) and before the function jumps to the return address it’ll check the stack cookie matches the expected value and if not it’ll throw an exception (or in this case bug check the console). This can thwart stack overflows as the only way to overwrite the return address requires you know the cookie value and include it as part of the overflow data (so it appears unmodified when validated). This was surprising to see but I wasn’t deterred and simply took this as another challenge. </p>



<p>I spent some time analyzing the function to see if there were any variables I could corrupt after the gap name buffer but before the stack cookie, and there were. However, these variables were useless from an exploitation perspective as they would immediately get overwritten by the game code after the gap name strcpy call. I looked further to see if there was any code I could use to cause an exception and possibly use SEH exploitation. Unfortunately there’s no way for me to cause an exception in the remaining code before the stack cookie check, and even if there was there’s no exception handler registered at this moment that would walk the SEH chain. After spending a bit of time brainstorming I decided to give up on this one and move on. </p>



<p>Checking Tony Hawk’s Underground 2 I saw the same thing: the game was compiled with stack cookies and there’s no variables on the stack I could use for exploitation purposes and there’s no way for me to leak the stack cookie value. I don’t wanna say these games can’t be used for exploitation as I know there are other strcpy bugs in the game that can be used for exploitation and are on the heap. But you definitely can’t use the gap name string in save files for exploitation on Xbox. Interestingly enough the Playstation 2 version, PC version, (and most likely the Gamecube version) are not compiled with stack cookies and can be exploited using the gap name string buffer.</p>



<h3>Tony Hawk’s American Wasteland</h3>



<p>Next up is Tony Hawk’s American wasteland, which I was expecting to not be expoitable after seeing THUG1 and 2 compiled with stack cookies. However, to my surprise THAW was not compiled with stack cookies and was vulnerable to the gap name string buffer overflow. The exploit is more or less identical to the one for THPS4 so I won’t bore you with redundant details.</p>



<h2>Part 2: Remote code execution</h2>



<p>Now that I had 3 new save game exploits for the Xbox on hand I wanted to go further. It’s 2016 and while finding a game that can be used for soft-modding the console with a save game hack is easy, finding the memory card you need to load the hacked save file is not. It’s also not common to find adapters that let you use a usb stick or other common storage device as a memory card on the console, and hacking up a controller is also not ideal. I wanted to try and find a new type of exploit with lower barrier to entry that didn’t require a memory card. The attack surface I had my eye on was the ability to play a multiplayer LAN game with a park made in the Create-A-Park editor. This meant that the game is sending the save file over the network and loading it on the client’s console, so it should be possible to craft a special save file that could be used over the network to hack the console of anyone who joins your match.</p>



<p>To start out I created a special setup for the host by modifying the game executable to fix the strcpy bug which would prevent the host from hacking themself. I also added a new code segment to the executable so that I’d have plenty of space for any additional functions I’d need to write. Next I setup a network match between my “host” and another console using a hacked save file that would just change the LED color to orange to signal the payload ran. Unlike loading the save locally, loading it over the network doesn’t copy the save file header data to the data segment which breaks the shell code copy stub, but that’s not a big issue because we can use a ROP chain similar to the THPS3 exploit to perform the shell code copy.</p>



<p>After crafting the save file and setting up a network game I had the client console join expecting it to receive the park file, get compromised, and change the console’s LED color. However, what actually happened is that the client connected to the host and spawned the player in, allowing them to skate around. Not only did the payload not run but we didn’t even trigger the buffer overflow. This was odd so I did some poking around in the memory of the client console and saw that the memory containing the park file sent by the host did not match my exploit file. I could see some of the exploit data in memory but the gap name been trashed and null terminated… </p>



<p>To figure out what was going on I placed some memory breakpoints on the memory containing the park file data on the host and waited for them to get hit. What I found was that the host would load the park file, then re-save it in memory, and send that to the client. In the process it would trash the exploit data which prevented it from running on the client console. Not entirely sure why it did this but I was able to just NOP the function call out and then everything worked as expected. The client would receive the hacked park file, get compromised, and change the LED color.</p>



<p>The next obstacle was figuring out how to obtain the secondary payload executable on the client side. When running the save exploit locally the secondary payload is bundled into the folder for the game save. However, running the exploit over the network the client won’t have access to this file so I’d have to come up with a way for them to obtain it. Initially I tossed around ideas like loading it off a burned CD but I didn’t want people to have to burn a disc as less and less people have CD burners nowadays. I also considered loading the executable from a local network address which would only require the client run a python script on a computer on the same network as the console. However, the Xbox winsock implementation uses secure socket connections by default which meant that my python script would have to recreate all the Xbox security stuff on top of the IP frames, and I didn’t want to do all that. </p>



<p>I decided to try and find the game’s net code and see if I could use it to send the executable to the client using some sort of “out of band” messages on the already established connection. I figured this might require quite a bit of shell code to do so I started by doing more research on the park save file to see how much space I had to work with. If it turned out I didn’t have enough space in the park file for all the shell coded needed then I’d be wasting time.</p>



<h2>What happens if I google this?</h2>



<p>I started searching the internet to see if anyone else had explored the park save files and if there might be some notes or something I could use as preliminary research material. After a few google searches I wasn’t able to find anything useful. So I played a game I like to call “what happens if I google this?”. Any time I’m reverse engineering something and come across a magic number or debug string I’ll put it into google and see what comes up. Over the years I’ve found a number of really interesting things such as the exact source file for the obscure encryption algorithm used in Call of Duty Black Ops, Microsoft patents with C-structs and developer comments describing how some encryption key ROM chips worked, and this time I’d hit one of my best finds. In the function that loads the park file there’s a reference to the string “Sk4Ed_Dead”. I put this string into google to see what would pop up, hoping that I’d find some sort of forum post referencing it. What I found instead was a GitHub repository called “thug”:</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/thug_github.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-973&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:914,&quot;targetHeight&quot;:227,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="914" height="227" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/thug_github.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/thug_github.png 914w, https://icode4.coffee/wp-content/uploads/thug_github-300x75.png 300w, https://icode4.coffee/wp-content/uploads/thug_github-768x191.png 768w" sizes="(max-width: 914px) 100vw, 914px"></figure></div>


<p>I thought that maybe this was some sort of homebrew tool for modding the game, but as I started to explore the repository I quickly realized that this was actually the source code for the entire game of Tony Hawk’s Underground. Someone had dumped it onto the internet in the form of this GitHub repository. This was an incredible find, even if it wasn’t for THPS4 the code base should be similar enough that I could use it to figure out how the game’s networking code worked and write the hooks I need to send the secondary payload to the client. You might be thinking, but wait, isn’t that cheating? And sure I guess you could say that, but in my opinion everything is fair in exploitation. My goal was to hack the console at all costs, I didn’t care about having a “clean room” exploit implementation. I already had RCE working and knew with a bit of work I could have the payload transfer using the connection established with the host. The only difference having this source code makes is how long it’ll take me to find the net code functions I need, from a few days down to a few hours. But now my goal has slightly changed.</p>



<details><summary>Rather than just get the exploit working over the network I wanted to make it as robust as I could.</summary>
<p>I wanted to make an exploit that would silently get RCE on the console of anyone who joined my match, hack their console to run unsigned code, and silently transfer another executable to their console while they played the game. Nowadays with RCE being a common attack vector this doesn’t sound that crazy. But imagine it’s ~2005 and a hack like this came to light, how crazy would it be to see headlines talking about hackers remotely hacking Xbox gaming consoles through online play, with the exploit being so seamless that the victim has no idea it happened until it’s too late. So I decided to switch from console hacker to threat actor and see how much fun I could have with this.</p>
</details>



<p>I cloned the repo and began looking through the code base. I was able to find the park file loading code and saw the exact line of code with the strcpy bug. Curious if this code was for the final version of the game I spent an hour or so recreating the Visual Studio project files for it and after fixing a few compiler errors I was able to successfully compile the code and run it with assets from the final version of the game. The code didn’t appear to be final but very very close to it. I spent some time looking through the network code and got an understanding of how messages were sent back and forth from host &lt;–&gt; client. After that I tracked down the relevant functions and variables for THPS4 in IDA and had everything I needed to start writing the hooks.</p>



<h2>Restoring execution</h2>



<p>Now that I decided to make this exploit as robust as possible I’d need to find a way to restore execution back to the game while the secondary payload transferred. This would require some changes to the ROP chain to save the old stack pointer before performing the stack pivot, and then restoring it later on after the shell code finishes executing.</p>



<div id="urvanov-syntax-highlighter-66b3cb3c52414024029532" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p></div>
				</td>
						<td><div><p><span>; Gadget 0 - save old stack pointer</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;push</span><span>&nbsp;&nbsp;</span><span>esp</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;and</span><span>&nbsp;&nbsp; </span><span>al</span><span>,</span><span> </span><span>8</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;mov</span><span>&nbsp;&nbsp; </span><span>[</span><span>ecx</span><span>]</span><span>,</span><span> </span><span>edx</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp; </span><span>esi</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; esi now contains the old stack pointer</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;retn</span><span>&nbsp;&nbsp;</span><span>4</span></p><p><span>; Gadget 1 - stack pivot</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp; </span><span>esp</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; Change esp to point to our ROP gadget data</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;ret</span></p><p><span>; Gadget 2 - get address to save stack pointer to</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp; </span><span>eax</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; Hack_OldStackPointer</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;ret</span></p><p><span>; Gadget 3 - save old stack pointer for later</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;mov</span><span>&nbsp;&nbsp; </span><span>[</span><span>eax</span><span>]</span><span>,</span><span> </span><span>esi</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>; Save old stack pointer</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp; </span><span>esi</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;ret</span></p><p><span>; Gadget 4 - load destination address for shell code copy</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp; </span><span>ecx</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; ShellCodeCopyDstAddress</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;ret</span></p><p><span>; Gadget 5 - load source address for shell code copy</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp; </span><span>eax</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; shell_code_start</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;ret</span></p><p><span>; Gadget 6 - copy shell code to executable memory</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>edx</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span>; size of shell code / 4</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;sub</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>ecx</span><span>,</span><span> </span><span>eax</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;push</span><span>&nbsp;&nbsp;&nbsp;&nbsp;</span><span>esi</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;loc_1117E4</span><span>:</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>esi</span><span>,</span><span> </span><span>[</span><span>eax</span><span>]</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mov</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>[</span><span>ecx</span><span>+</span><span>eax</span><span>]</span><span>,</span><span> </span><span>esi</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; add</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>eax</span><span>,</span><span> </span><span>4</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; dec</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>edx</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; jnz</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>short</span><span> </span><span>loc</span><span>_</span>1117<span>E</span>4</p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;pop</span><span>&nbsp;&nbsp;&nbsp;&nbsp; </span><span>esi</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;retn</span><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span><span>; Jump to our shell code</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<h2>Asynchronous file transfer</h2>



<p>The game’s networking system works by registering a set of message handler functions and corresponding message IDs, when the game receives a message it’ll call the handler function for the message ID received. By registering some unused message IDs I can setup some simple file transfer messages to send the secondary payload to the client. I came up with some simple message exchanges that look like this:</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/rce_file_transfer.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-978&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:990,&quot;targetHeight&quot;:644,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="990" height="644" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/rce_file_transfer.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/rce_file_transfer.png 990w, https://icode4.coffee/wp-content/uploads/rce_file_transfer-300x195.png 300w, https://icode4.coffee/wp-content/uploads/rce_file_transfer-768x500.png 768w" sizes="(max-width: 990px) 100vw, 990px"></figure></div>


<ol>
<li>When the client connects to the host they’ll start the file transfer with a MSG_ID_PAYLOAD_REQUEST message to the host.</li>



<li>The host will respond with a MSG_ID_PAYLOAD_DATA message that contains a sub message ID and associated value. The possible sub message IDs are:
<ul>
<li>PAYLOAD_MSG_ID_START: the value is the size of the secondary payload.</li>



<li>PAYLOAD_MSG_ID_DATA: when sent from the client to the host the value is the offset of the next block of data to send, when sent from host to client the value is the size of the payload data attached.</li>



<li>PAYLOAD_MSG_ID_END: indicates this is the last chunk of data for the secondary payload (file transfer complete).</li>
</ul>
</li>



<li>Once the client receives the PAYLOAD_MSG_ID_END message the file transfer is complete.</li>
</ol>



<p>After coding up the file transfer message handlers for both the host and client and working out the bugs I could finally see the debug spew that my payload was transferring to the client. I waited anxiously for the transfer to complete, but rather than it completing successfully my client console crashed trying to dereference a null pointer.</p>



<h2>A memory leak 15 years in the making</h2>



<p>Upon investigating further I found that a memory allocator for network data was returning NULL and causing a the null pointer dereference. I started looking through the source code for the net code and I could see exactly where the buffers for my network messages should be getting free’d. It didn’t make sense that the game was out of memory. I eventually found some debug prints left in the game that I enabled to get a print out of memory statistics if a memory allocation fails. Looking at the output I could see the memory pool for “networking” had 0 free bytes. But this didn’t make sense, I could see exactly where the buffers for the network messages should be getting free’d. I even found the matching function call in the disassembly of the THPS4 game executable to confirm it wasn’t something that only existed in the THUG code. After spending a few hours looking back and forth trying to figure out what the issue was I happened to hover over a particular line of the THUG source code. A Visual Studio intellisense tooltip popped up and what it showed made me immediately realize what the issue was.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/global_delete_operator-1.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-985&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:474,&quot;targetHeight&quot;:116,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="474" height="116" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/global_delete_operator-1.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/global_delete_operator-1.png 474w, https://icode4.coffee/wp-content/uploads/global_delete_operator-1-300x73.png 300w, https://icode4.coffee/wp-content/uploads/global_delete_operator-1-470x116.png 470w" sizes="(max-width: 474px) 100vw, 474px"></figure></div>


<p>If you’re not familiar with Visual Studio (or more so MSVC) or the new/delete operators for C++ then this tooltip probably doesn’t mean anything to you. But for those familiar you may already see the issue. This tooltip is showing the signature for the delete operator and it doesn’t match the signature for the standard Microsoft C++ runtime delete operator. This signature is for a custom delete operator, which means the game developers overloaded the global new and delete operators so that any calls using new or delete would route to their routines. Remember in the Tony Hawk’s Pro Skater 3 section I said the game developers were using a custom memory allocator? Well this is the “new and improved” version of it. I looked at the source for the delete operator function and immediately realized the mistake the developers had made. For legal reasons I’m not going to show the real source code but I’ve written a pseudo code-esq version of the code that contains the issue. Put your C++ skills to the test and see if you can spot the issue:</p>



<div id="urvanov-syntax-highlighter-66b3cb3c52420824772016" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					<div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p><p>7</p><p>8</p><p>9</p><p>10</p><p>11</p><p>12</p><p>13</p><p>14</p><p>15</p><p>16</p><p>17</p><p>18</p><p>19</p><p>20</p><p>21</p><p>22</p><p>23</p><p>24</p><p>25</p><p>26</p><p>27</p><p>28</p><p>29</p><p>30</p><p>31</p><p>32</p><p>33</p><p>34</p><p>35</p><p>36</p><p>37</p><p>38</p><p>39</p><p>40</p><p>41</p><p>42</p><p>43</p><p>44</p><p>45</p><p>46</p><p>47</p><p>48</p><p>49</p><p>50</p><p>51</p><p>52</p><p>53</p><p>54</p><p>55</p><p>56</p></div>
				</td>
						<td><div><p><span>inline</span><span> </span><span>void</span><span> </span><span>operator</span><span> </span><span>delete</span><span>(</span><span>void</span><span>*</span><span> </span><span>pAddr</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>alloc_header</span><span>*</span><span> </span><span>p_header</span><span> </span><span>=</span><span> </span><span>get_alloc_header</span><span>(</span><span>pAddr</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Mark the region as free.</span></p><p><span>	</span><span>p_header</span><span>-&gt;</span><span>data_size</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span></p><p><span>	</span><span>p_header</span><span>-&gt;</span><span>id</span><span> </span><span>=</span><span> </span><span>ALLOC_DEAD</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p><p><span>class</span><span> </span><span>stream_desc</span></p><p><span>{</span></p><p><span>	</span><span>char</span><span>*</span><span> </span><span>p_data</span><span>;</span><span>		</span><span>// Buffer holding message data</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>~</span><span>stream_desc</span><span>(</span><span>)</span></p><p><span>	</span><span>{</span></p><p><span>		</span><span>delete</span><span>[</span><span>]</span><span> </span><span>p_data</span><span>;</span></p><p><span>	</span><span>}</span></p><p><span>}</span><span>;</span></p><p><span>class</span><span> </span><span>stream_link</span></p><p><span>{</span></p><p><span>	</span><span>stream_desc</span><span>*</span><span> </span><span>p_desc</span><span>;</span></p><p><span>}</span><span>;</span></p><p><span>int</span><span> </span><span>handle_stream_message</span><span>(</span><span>.</span><span>.</span><span>.</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>stream_link</span><span>*</span><span> </span><span>p_link</span><span> </span><span>=</span><span> </span><span>.</span><span>.</span><span>.</span><span>;</span></p><p><span>	</span><span>stream_desc</span><span>*</span><span> </span><span>p_desc</span><span> </span><span>=</span><span> </span><span>p_link</span><span>-&gt;</span><span>p_desc</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Copy message data to the descriptor object.</span></p><p><span>	</span><span>p_desc</span><span>-&gt;</span><span>p_data</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>char</span><span>[</span><span>.</span><span>.</span><span>.</span><span>]</span><span>;</span></p><p><span>	</span><span>memcpy</span><span>(</span><span>p_desc</span><span>-&gt;</span><span>p_data</span><span>,</span><span> </span><span>.</span><span>.</span><span>.</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Dispatch the message handler to process the message data.</span></p><p><span>	</span><span>dispatch_message</span><span>(</span><span>p_desc</span><span>)</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Cleanup temporary resources.</span></p><p><span>	</span><span>delete </span><span>p_desc</span><span>;</span></p><p><span>	</span><span>delete </span><span>p_link</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>







<p>The problem lies in the custom delete operator. When you call delete on a C++ class pointer the standard runtime implementation will invoke the destructor for the class, in this case <code>~stream_desc()</code> would be invoked and p_data would be free’d. However, the custom delete operator written by the developers does not invoke the destructor for the object being deleted, meaning <code>~stream_desc()</code> isn’t going to be called and p_data won’t be free’d. This memory will be leaked and this happens for every message I send with payload data until the memory pool for networking data is exhausted and the next allocation request returns NULL. This memory leak has existed for years and it would normally never be an issue unless you sat in a multiplayer game long enough for the network pool to be exhausted (or, you know, decided to send some exploit files through the game’s net code…).</p>



<details><summary>It’s always the custom memory allocator…</summary>
<p>I’ve mentioned this in several of my blog posts but it was very common in older games for developers to write their own memory allocators. Often times the built-in memory allocators for gaming consoles were slow or even buggy and developers opted to write their own. However, often times the custom memory allocators would also be a source of bugs, just not ones that would manifest in the same way as when using the built-in memory allocators.</p>
</details>



<p>Not to worry though, because we can fix this by simply hooking the client code and free’ing the <code>p_desc-&gt;p_data</code> buffer. Yes, as part of this exploit I’m going to hot patch a 15 year old bug in the game so I can hack the client’s console. The fix is very simple, I just hooked the <code>handle_stream_message</code> function and called the correct free function for the <code>p_data</code> buffer. I know the correct fix is to invoke the destructor for the class pointer, but this code has existed this way for 15 years now and I don’t know what side effects might occur if I suddenly start invoking the destructors for objects that were never called before. Here’s the pseudo code for the fix:</p>



<div id="urvanov-syntax-highlighter-66b3cb3c52428495356358" data-settings=" minimize scroll-mouseover">
				<table>
					<tbody><tr>
				<td data-settings="show">
					
				</td>
						<td><div><p><span>int</span><span> </span><span>handle_stream_message</span><span>(</span><span>.</span><span>.</span><span>.</span><span>)</span></p><p><span>{</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>	</span><span>// Cleanup temporary resources.</span></p><p><span>	</span><span>mem_delete</span><span>(</span><span>g_memory_manager</span><span>,</span><span> </span><span>p_desc</span><span>-&gt;</span><span>p_data</span><span>)</span><span>;</span></p><p><span>	</span><span>delete </span><span>p_desc</span><span>;</span></p><p><span>	</span><span>delete </span><span>p_link</span><span>;</span></p><p><span>	</span><span>.</span><span>.</span><span>.</span></p><p><span>}</span></p></div></td>
					</tr>
				</tbody></table>
			</div>



<h2>The final result</h2>



<p>With the memory leak hot patch code in place I booted up the host and client console, let the client connect to the match and waited for the payload transfer to finish. The hot patch worked, the file transfer completed successfully and the client ran my nyan-cat executable. I now had full RCE and asynchronous file transfer to the client all while they continued to play the game. I ran one last test using a tunneling app to remotely hack a friends console who lived across the country. After a few minutes of setting everything up I waited for the file transfer to complete and boom, his console booted the nyan-cat executable.</p>



<p>Here’s a recap of all the steps required to perform this exploit from start to finish:</p>



<ol>
<li>The client connects to the malicious host console and receives the “Hack Xbox” park file over the network.</li>



<li>The client parses the park file which triggers the buffer overflow bug and overwrites the return address on the stack to kick off the ROP chain.</li>



<li>The ROP chain will copy the full shell code payload into an executable section of memory and jump to it.</li>



<li>The shell code will do the following before restoring execution back to the game and spawning the player in the match: 
<ul>
<li>Register new network message handlers for my custom message IDs to facilitate the file transfer in the background. </li>



<li>Hot patch the memory leak bug in the net code.</li>



<li>Send a MSG_ID_PAYLOAD_REQUEST message to the host console to initiate the file transfer.</li>
</ul>
</li>



<li>While the player skates around in-game the host will send an executable file to the client that gets saved locally on the client’s HDD.</li>



<li>Once the file transfer is completed the shell code will patch the client’s kernel to use the habibi key and boot the secondary executable that was sent.</li>
</ol>



<p>The entire process is so seamlessly smooth that without changing the LED color an unsuspecting player would have no idea anything was going on until their console suddenly booted another application. If I was a real threat actor I could easily get persistent code execution on the console and do whatever I want, snoop around the person’s network, create a botnet, or just brick their console entirely. Luckily I’m just here to try and prove my skills as a console hacker. With this exploit completed I was just pretty satisfied and felt I had achieved my original goals. However, with everything I achieved I was still doing all of this on a console that doesn’t have DEP or any real security mitigations that would make this exploit difficult. So it was time to move on to another target, one I had wanted to find a new exploit on for a long time…</p>



<h2>Part 3: The first Xbox 360 software-only exploit</h2>



<p>I’ve spent many years reverse engineering the software on the Xbox 360 in hopes I might one day find a bug that could be used to hack the console on newer kernel versions. The Xbox 360 hypervisor is probably the most secure piece of code Microsoft has ever written. There’s only ever been 1 software bug found in it that I largely suspect was due to a compiler bug and not the result of a developer making changes to the hypervisor code. That bug existed in the system call handler and was only present in the 4548 version kernel, which has not been usable since early in the console’s lifecycle. While I have found a few bugs in the Xbox 360 hypervisor I have not found any that are exploitable or could be chained together to get code execution. </p>



<p>I checked the version of Tony Hawk’s American Wasteland for Xbox 360 and confirmed it was vulnerable to the gap name buffer overflow attack. I really wanted to exploit the console on a kernel version newer than 4548 (even obtaining a console that can boot this kernel version is difficult in modern times) but without a new hypervisor bug that hope was dead in the water. However, there was one thing I could do with the Tony Hawk strcpy bug and that was develop the first software only exploit for the console, even if it only worked on the 4548 version kernel.</p>



<details><summary>Lets take a step back to 2006 for a moment…</summary>
<p>The Xbox 360 has recently been released and the Xbox hacking community is in full swing trying to hack the console. Very little is known about the inner workings of the console due to all executable code being encrypted. This means hackers didn’t have the ability to reverse engineer any code to try and find bugs or learn about how the console software worked. However, December 2006 an exploit would be revealed at 23C3 that showed the game King Kong being used to boot linux. Shortly after the first decrypted hypervisor and kernel image would appear on the internet for people to start reverse engineering, and eventually tools would be developed to decrypt all code that could be found on the console or on game discs. I remember reading a lot of misconceptions that the Xbox 360 hypervisor would prevent buffer overflow attacks and that the console wouldn’t be able to be hacked using game save exploits like the original Xbox was. This however, was incorrect, the Xbox 360 hypervisor doesn’t do anything that prevents stack buffer overflows.</p>



<p>Later on the details of the King Kong hack would be disclosed for anyone to use. It worked by modifying the shader files the game used to perform some arbitrary writes to kernel memory that would kick off a ROP chain and exploit the system call handler bug. This required you opened the console and flash modified firmware to the dvd drive in order to play the modified King Kong disc you would need to create (the shader files are on disc). I always wondered if there was another entry point that could have been used instead of having to open the console and modify the dvd drive (which ultimately led to an unstoppable wave of piracy in the years to come). And there was: using a game save bug to kick off the ROP chain. </p>



<p>However, this is also a “chicken and egg” situation as the game save files are RSA signed using a key pair that is unique to your console. Every Xbox 360 console has a “key store” that contains a number of cryptographic keys used by the console, one of which is used to sign game saves. This prevents people from modifying save files unless you have the RSA private key from a console’s key store, any console’s key store. How does a save file signed with my console’s private RSA key successfully validate on another Xbox 360 console? Because the RSA public key is embedded into the save file header, allowing another console to use it to validate the integrity of the save file. This public key is actually signed by another RSA key pair that only Microsoft has, so you can’t just put any public key in the save file header and have it validate. But as long as you had the decrypted key store for any Xbox 360 console you could resign a modified save file for use on anyone else’s console. This would require you first hack the console in order to get the decrypted key store, and you might be wondering how the first group of hackers were able to find the system call handler bug in the first place if all executable code is encrypted?</p>



<p>The crux of all Xbox 360 hacking started with hackers obtain Xbox 360 development consoles. These are special consoles used by developers to make and debug games. Once hackers were able to obtain these consoles (or more importantly, the SDK used along side these consoles) it would reveal a ton of information on how to decrypt executable code allowing them to start reverse engineering the boot chain, hypervisor, and game code, and eventually hack the console. Had these developer consoles and software not leaked the console most likely would have never been hacked as all executable code was encrypted (even when in RAM) from an external point of view. No ability to inspect code = no ability to find bugs.</p>
</details>



<h2>The system call handler bug</h2>



<p>I’m not gonna go into great detail about the overall security architecture of the Xbox 360 as there’s way too much to cover that’s not relevant to this post. But I will provide an overview of the system call handler bug as understanding that is essential to understanding the exploit payload.</p>



<p>The Xbox 360 has two main modes of execution: hypervisor real mode which is the most privileged mode and kernel mode which is less privileged and where the rest of the OS and games run. The CPU will use 64-bit physical addresses when in real mode and 32-bit virtual addresses when in kernel mode. The hypervisor doesn’t actually provide any virtualization functionality that you’d expect when you hear the word “hypervisor”. It’s more akin to a micro-kernel or “security supervisor” as it facilitates all security related operations on the console (such as code integrity validation) and assignment of executable memory. There’s no way to run any code on the console without it going through the hypervisor to be validated and have the memory pages marked as executable. </p>



<p>The CPU also has a cryptography unit on-die that sits next to the L2 cache and is responsible for encrypting and hashing memory. This prevents an attacker from sniffing or modifying RAM externally but also helps to thwart certain types of memory corruption bugs. When in kernel mode you can only see the cipher text of the hypervisor pages as they’re encrypted + hashed and not mapped in a way that would allow successful decryption of the memory from kernel mode. Trying to overwrite the cipher text from kernel mode will cause the hashing checks to fail and accessing that memory from real mode (hypervisor context) will trigger an exception and halt the console. Basically, you can’t read or write hypervisor memory from kernel mode or the console will halt.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/xbox_360_address-2.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-995&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:900,&quot;targetHeight&quot;:326,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="900" height="326" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/xbox_360_address-2.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/xbox_360_address-2.png 900w, https://icode4.coffee/wp-content/uploads/xbox_360_address-2-300x109.png 300w, https://icode4.coffee/wp-content/uploads/xbox_360_address-2-768x278.png 768w" sizes="(max-width: 900px) 100vw, 900px"><figcaption>Real mode address breakdown</figcaption></figure></div>


<p>When in real mode the upper 32-bits of a physical address are used by the crypto unit to control encryption and hashing of data (I’ll refer to them as the “protection bits”). There’s a special address mask, <code>0x80000000.00000000</code>, that can be applied to a 64-bit physical address that performs a memory access while ignoring encryption and hashing. This can be used to read or write memory in a non-protected way as validation of the memory is skipped. Any place kernel mode can provide a physical memory address to the hypervisor it’s imperative that the upper 32 bits are cleared to ensure that kernel mode code can’t provide the protection bits or else it could be used to read/write protected memory.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/system_call_handler_normal.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-998&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:563,&quot;targetHeight&quot;:222,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="563" height="222" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/system_call_handler_normal.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/system_call_handler_normal.png 563w, https://icode4.coffee/wp-content/uploads/system_call_handler_normal-300x118.png 300w" sizes="(max-width: 563px) 100vw, 563px"><figcaption>Normal system call handler instructions</figcaption></figure></div>


<p>Looking at the normal implementation of the system call handler we can see how it’s supposed to work. Register r0 contains the system call ordinal provided by kernel mode. The slwi (shift left word immediate) instruction will shift the system call ordinal left by 2 (multiplying it by 4) and discard the upper 32 bits of the result (truncating the 64 bit result to 32 bits). This offset is used to index into the system call function table to get the function address for the specified system call ordinal. Since the ordinal has to be between 0 and the highest system call ordinal it’s not possible to get offset to point anywhere except within the system call function table.</p>


<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/icode4.coffee\/wp-content\/uploads\/system_call_handler_4548.png&quot;,&quot;figureClassNames&quot;:&quot;aligncenter size-full&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-1000&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:565,&quot;targetHeight&quot;:147,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="565" height="147" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" src="https://icode4.coffee/wp-content/uploads/system_call_handler_4548.png" alt="" srcset="https://icode4.coffee/wp-content/uploads/system_call_handler_4548.png 565w, https://icode4.coffee/wp-content/uploads/system_call_handler_4548-300x78.png 300w" sizes="(max-width: 565px) 100vw, 565px"><figcaption>System call handler instructions for 4548</figcaption></figure></div>


<p>Looking at the implementation of the system call handler on 4548 we can see there’s a slightly different instruction pattern, the slwi instruction has been replaced with sldi (shift left double immediate). This instruction operates on 64 bits, not 32, which means we can control the upper 32 bits of r0 which will get used when indexing the system call function table. Now I did say that the system call ordinal will be checked to make sure it’s within [0, max ordinal), but that comparison operates on the lower 32 bits of r0. The upper 32 bits will not be considered for the comparison. So by setting r0 to a value such as <code>0x20000000.0000003F</code> it will pass the ordinal range check and produce an offset of <code>0x80000000.000000FC</code> which will allow us to access unprotected memory (ignoring encryption and hashing) when indexing the system call function table.</p>



<details><summary>I highly suspect that this change was due to a compiler bug…</summary>
<p>The system call handler routine would be one of the first pieces of code written for the hypervisor as it’s a CPU exception vector and required for kernel mode code to run. By the time the console launched this code would have been well matured and there wouldn’t be any reason to change it, especially a few updates into the console’s lifecycle. Having worked at Microsoft for 7 years I can recount 3 occasions where we received an MSRC bug report for some bug that cropped up in the Windows kernel. Upon investigating the causes it was determined that recent compiler work had cause certain instruction patterns emitted by the compiler to change, and the new instruction patterns led to security bugs in kernel code. I highly suspect that this is the case for the 4548 system call handler bug as well. I don’t think there’s any reason for this code to have been changed by a developer especially in a way that would change how this array is indexed.</p>
</details>



<p>So how can this be exploited? From kernel mode we have a view of encrypted hypervisor memory and we can overwrite it. Normally this would cause the console to halt the next time the hypervisor tried to read that memory, but because we can get the system call handler to read a function pointer while controlling the upper 32 bits of the address we can set the upper most bit so a read ignoring encryption and hashing is performed. This will let the hypervisor read the value we overwrote and not fault. We can set the function pointer to point to a convenient instruction sequence that’ll get us code execution and by executing a system call with a maliciously crafted ordinal we can get the hypervisor to jump to our code. Here’s the steps required to exploit this bug:</p>



<ol>
<li>Load some shell code into memory and get the physical address of the allocation.</li>



<li>Change a kernel memory manager variable that controls the 64kb page mappings. This will expose the encrypted view of hypervisor memory into an address range we can write to.</li>



<li>Overwrite a system call function pointer in the encrypted view of hypervisor memory to point to the address of a convenient instruction sequence. For this we choose the instruction sequence <code>mtctr r4; bctr</code> which will jump to the address contained in r4 which we have full control over going into the system call handler.</li>



<li>Set r0 to contain the ordinal of the system call function pointer we overwrote in step 2 and set the upper 32 bits such that shifting them left by 2 will set the upper most bit in the register, ex: <code><code>0x20000000.0000003F</code></code>. Set r4 such that it contains the physical address of our shell code OR’d with the <code>0x80000000.00000000</code> mask (our shell code sits in unprotected memory).</li>



<li>Execute the system call instruction which will switch into real mode and let the hypervisor dispatch the system call. It’ll perform a 32-bit comparison on the malicious system call ordinal and a 64-bit shift to calculate the array offset which will read the function pointer we overwrote without faulting. The hypervisor will jump to this address and execute the <code>mtctr r4; bctr</code> instruction sequence and jump to our shell code in unprotected memory. When in real mode the page protections are ignored so the hypervisor won’t fault trying to execute non-executable memory.</li>
</ol>



<p>So how can we do this using the strcpy bug in Tony Hawk’s American Wasteland?</p>



<h2>Collect E X P L O I T while maintaining a ROP chain</h2>



<p>To build the ROP chain I modified the (now archived) <a href="https://github.com/iphelix/ida-sploiter" data-type="link" data-id="https://github.com/iphelix/ida-sploiter">Ida-Sploiter</a> IDA plugin to add support for PowerPC architecture. This plugin would help me find ROP gadgets based on given search criteria for specific instructions or registers being used. The entire exploit took 24 ROP gadgets to perform and achieve full hypervisor code execution where I then patch out the code integrity checks and launch a secondary executable bundled in with the game save. I’m not going to detail the ROP chain here as it’s really long and boring (I’ve also thoroughly documented it on the GitHub repository), but I’ll provide a brief overview of all the steps for the full exploit:</p>



<ol>
<li>Using the strcpy bug we overflow the gap name buffer on the stack and overwrite the return address to point to the first ROP gadget.</li>



<li>The first ROP gadget changes the stack pointer to point to the ROP chain data contained in the save game buffer in memory.</li>



<li>Call MmAllocatePhysicalMemoryEx to allocate a block of physical memory for our hypervisor shell code.</li>



<li>Call memcpy and copy the hypervisor shell code into the buffer allocated in step 3.</li>



<li>Call MmGetPhysicalAddress to get the physical address of our shell code buffer (this is what we pass to the hypervisor) and save it for later.</li>



<li>Change the kernel memory manager variable that controls the 64kb page mappings to map in the encrypted view of hypervisor memory for write access.</li>



<li>Overwrite the hypervisor system call function address in the encrypted memory view to point to the <code>mtctr r4; bctr</code> instruction sequence.</li>



<li>Execute the syscall instruction using the malicious system call ordinal and physical address of our hypervisor shell code obtained in step 5.</li>



<li>The hypervisor will load the function pointer we overwrote in step 7, execute the <code>mtctr r4; bctr</code> instruction sequence and jump to our hypervisor shell code.</li>



<li>Now we have full hypervisor code exec. I change the LED color to signal the exploit was successful, then patch out the RSA signature checks on executable files and return from the system call interrupt.</li>



<li>We’re back in the ROP chain in kernel mode. Next we map a folder on the HDD that contains the secondary payload by calling ObCreateSymbolicLink.</li>



<li>Finally we call XLaunchNewImage and launch our unsigned secondary payload.</li>
</ol>



<figure><video controls="" src="https://icode4.coffee/wp-content/uploads/thaw_xbox360_exploit.mov"></video></figure>



<p>And there you have it, the first software only exploit for the Xbox 360. It’s kind of ironic that this worked out almost exactly the same as the save game exploits for the original Xbox: performing a stack buffer overflow from a strcpy call on data contained in a save game file you can copy to your console using a memory card. You can use the strcpy bug to get ROP execution on any Xbox 360 OS version, but you’ll only be able to get full hypervisor code execution on the 4548 kernel version. If a new hypervisor bug is discovered this can easily be paired with it to work on newer kernel versions. I still have some hope that there might be an exploitable bug that would get you hypervisor code execution on a new kernel version. But I highly suspect it would be some kind of CPU or MMU bug rather than a bug in the hypervisor code. </p>



<h2>Part 3: Hack the planet</h2>



<p>Fast forward to present day (2024) and I finally got around to cleaning up and releasing all these Tony Hawk exploits. However, since I’m most likely retiring from game console hacking after this I wanted to drop an absolute banger of a release so I ported the exploit to some other game consoles that are vulnerable to it. This bug exists in 5 different iterations of the Tony Hawk video game series across numerous game consoles and handhelds. No one is safe from Tony Hawk’s Pro Strcpy. Since you’re probably tired of me talking about the same strcpy bug over and over I’m only going to provide some brief details of which games for which platforms I ported the exploit to and how it may or may not make hacking those consoles easier.</p>



<h2>Playstation 2</h2>



<p>I ported the Tony Hawk Pro Skater 4 network RCE exploit to the Playstation 2 version of the game. Using PCSX2 (or another console) you only need the THPS4 disc and you can hack your console over the network. The exploit will send uLaunchElf over the network and launch it when the transfer completes, from there you can load the FreeMcBoot/FreeHDBoot installer off some other media (like a usb stick). I originally wanted to just send the FreeMcBoot installer but it’s not a single file and the PS2 doesn’t have any persistent storage attached to it by default (unlike Xbox with the built-in HDD). </p>



<p>The save game exploits are not useful on the PS2 because if you have a way to copy files to a memory card you can just install FreeMcBoot and be done. I don’t know if this network exploit will make it any easier to hack the console since you can already buy a FreeMcBoot memory card off Amazon for $15 USD with next day prime shipping or just use FreeHDBoot on a phat console with the network adapter. So I think it’s safe to say anyone who wants to hack their PS2 most likely will not need this exploit. Oh well, hack the planet.</p>



<h2>GameCube</h2>



<p>I ported the Tony Hawk Pro Skater 4 save game exploit to the GameCube version of the game, but did not port the network RCE or any other version of the save game exploits. What I didn’t realize going into this was that it’s non-trivial to copy files to the GameCube memory card and that people have been buying memory cards with pre-hacked save files on them off of Ebay for upwards of $50 USD. This is honestly pretty lame and I tried to think of another way to lower the barrier to entry for this console but the GameCube versions of the Tony Hawk games don’t have network support so even if you bought the network adapter (which apparently no one has because only like 4 games supported it) you wouldn’t be able to use the network exploit anyway. It looks like there’s already plenty of game save exploits available for the console, and since there isn’t a persistent software hack for the console most people end up going with a modchip anyway. Oh well, hack the planet.</p>



<h2>Windows</h2>



<p>I created a game save exploit for THUG PRO, the community patch for Tony Hawk’s Underground, and I even reported the bug to them 7 years ago but they weren’t interested in fixing it at the time. Since the exploit doesn’t provide any value to Windows I opted not to release it (it wasn’t full stack anyway) but I would like to provide a word of warning to anyone playing any of the Tony Hawk games on PC. They all have the same strcpy bug in them, they’re all exploitable, and that’s not the only strcpy bug that can be exploited over network play either. I highly recommend playing those games while forcing ASLR on the executable, and don’t ever run them as Administrator.</p>



<h2>Conclusion</h2>



<p>So there you have it, who would have thought one strcpy bug could be used to hack so many different platforms and even achieve RCE on some of them? Bugs aside the Tony Hawk skateboarding games were some of my favorite growing up. Those games are what got me into skateboarding and provided years of entertainment. Neversoft was one of my favorite game studios and a place I would’ve loved to work at. There’s some behind the scenes footage of a bunch of Neversoft developers who were probably in their late 20s-early 30s and had never stepped on a skateboard before have a contest to see who could do a kickflip off a big wooden conference table at the studio. I remember thinking that was the coolest thing I had ever seen and wanted to work there ever since. Unfortunately they shut down but at least the legacy of the Tony Hawk video game series will live on as some of the greatest games of the 2000s and the best way to hack your old gaming consoles 😉</p>



<p>Full source code and patched game save files are available on my <a href="https://github.com/grimdoomer/TonyHawksProStrcpy">GitHub</a>.</p>
									
																		
								</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Official Puppeteer Support for Firefox (141 pts)]]></title>
            <link>https://hacks.mozilla.org/2024/08/puppeteer-support-for-firefox/</link>
            <guid>41182847</guid>
            <pubDate>Wed, 07 Aug 2024 16:19:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hacks.mozilla.org/2024/08/puppeteer-support-for-firefox/">https://hacks.mozilla.org/2024/08/puppeteer-support-for-firefox/</a>, See on <a href="https://news.ycombinator.com/item?id=41182847">Hacker News</a></p>
<div id="readability-page-1" class="page"><article role="article">
    
<p>We’re pleased to announce that, as of version 23, the <a href="https://pptr.dev/">Puppeteer</a> browser automation library now has first-class support for Firefox. This means that it’s now easy to write automation and perform end-to-end testing using Puppeteer, and run against both Chrome and Firefox.</p>
<h2>How to Use Puppeteer With Firefox</h2>
<p>To get started, simply set the product to “<code>firefox</code>” when starting Puppeteer:</p>
<pre><code>import puppeteer from "puppeteer";

const browser = await puppeteer.launch({
  browser: "firefox"
});

const page = await browser.newPage();
// ...
await browser.close();</code></pre>
<p>As with Chrome, Puppeteer is able to download and launch the latest stable version of Firefox, so running against either browser should offer the same developer experience that Puppeteer users have come to expect.</p>
<p>Whilst the features offered by Puppeteer won’t be a surprise, bringing support to multiple browsers has been a significant undertaking. The Firefox support is not based on a Firefox-specific automation protocol, but on WebDriver BiDi, a cross browser protocol that’s undergoing standardization at the W3C, and currently has implementation in both Gecko and Chromium. This use of a cross-browser protocol should make it much easier to support many different browsers going forward.</p>
<p>Later in this post we’ll dive into some of the more technical background behind WebDriver BiDi. But first we’d like to call out how today’s announcement is a great demonstration of how productive collaboration can advance the state of the art on the web. Developing a new browser automation protocol is a lot of work, and great thanks goes to the Puppeteer team and the other members of the W3C Browser Testing and Tools Working Group, for all their efforts in getting us to this point.</p>
<p>You can also check out the Puppeteer team’s<a href="https://developer.chrome.com/blog/firefox-support-in-puppeteer-with-webdriver-bidi"> post</a> about making WebDriver BiDi production ready.</p>
<h2>Key Features</h2>
<p>For long-time Puppeteer users, the features available are familiar. However for people in other automation and testing ecosystems — particularly those that until recently relied entirely on HTTP-based WebDriver — this section outlines some of the new functionality that WebDriver BiDi makes possible to implement in a cross-browser manner.</p>
<h3>Capturing of Log Messages</h3>
<p>A common requirement when testing web apps is to ensure that there are no unexpected errors reported to the console. This is also a case where an event-based protocol shines, since it avoids the need to poll the browser for new log messages.</p>
<pre><code>import puppeteer from "puppeteer";

const browser = await puppeteer.launch({
  browser: "firefox"
});

const page = await browser.newPage();
page.on('console', msg =&gt; {
  console.log(`[console] ${msg.type()}: ${msg.text()}`);
});

await page.evaluate(() =&gt; console.debug('Some Info'));
await browser.close();</code></pre>
<p>Output:</p>
<pre>[console] debug: Some Info</pre>
<h3>Device Emulation</h3>
<p>Often when testing a reactive layout it’s useful to be able to ensure that the layout works well at multiple screen dimensions, and device pixel ratios. This can be done by using a real mobile browser, either on a device, or on an emulator. However for simplicity it can be useful to perform the testing on a desktop set up to mimic the viewport of a mobile device. The example below shows loading a page with Firefox configured to emulate the viewport size and device pixel ratio of a Pixel 5 phone.</p>
<pre><code>import puppeteer from "puppeteer";

const device = puppeteer.KnownDevices["Pixel 5"];

const browser = await puppeteer.launch({
  browser: "firefox"
});

const page = await browser.newPage();
await page.emulate(device);

const viewport = page.viewport();

console.log(
  `[emulate] Pixel 5: ${viewport.width}x${viewport.height}` +
  ` (dpr=${viewport.deviceScaleFactor}, mobile=${viewport.isMobile})`
);

await page.goto("https://www.mozilla.org");
await browser.close();
</code></pre>
<p>Output:</p>
<pre>[emulate] Pixel 5: 393x851 (dpr=3, mobile=true)</pre>
<h3>Network Interception</h3>
<p>A common requirement for testing is to be able to track and intercept network requests. Interception is especially useful for avoiding requests to third party services during tests, and providing mock response data. It can also be used to handle HTTP authentication dialogs, and override parts of the request and response, for example adding or removing headers. In the example below we use network request interception to block all requests to web fonts on a page, which might be useful to ensure that these fonts failing to load doesn’t break the site layout.</p>
<pre><code>import puppeteer from "puppeteer";

const browser = await puppeteer.launch({
  browser: 'firefox'
});

const page = await browser.newPage();
await page.setRequestInterception(true);

page.on("request", request =&gt; {
  if (request.url().includes(".woff2")) {
    // Block requests to custom user fonts.
    console.log(`[intercept] Request aborted: ${request.url()}`);
    request.abort();
  } else {
    request.continue();
  }
});

const response = await page.goto("https://support.mozilla.org");
console.log(
  `[navigate] status=${response.status()} url=${response.url()}`
);
await browser.close();</code></pre>
<p>Output:</p>
<pre>[intercept] Request aborted: https://assets-prod.sumo.prod.webservices.mozgcp.net/static/Inter-Bold.3717db0be15085ac.woff2
[navigate] status=200 url=https://support.mozilla.org/en-US/
</pre>
<h3>Preload Scripts</h3>
<p>Often automation tooling wants to provide custom functionality that can be implemented in JavaScript. Whilst WebDriver has always allowed injecting scripts, it wasn’t possible to ensure that an injected script was always run before the page started loading, making it impossible to avoid races between the page scripts and the injected script.</p>
<p>WebDriver BiDi provides “preload” scripts which can be run before a page is loaded. It also provides a means to emit custom events from scripts. This can be used, for example, to avoid polling for expected elements, but instead using a mutation observer that fires as soon as the element is available. In the example below we wait for the &lt;title&gt; element to appear on the page, and log its contents.</p>
<pre><code>import puppeteer from "puppeteer";

const browser = await puppeteer.launch({
  browser: 'firefox',
});

const page = await browser.newPage();

const gotMessage = new Promise(resolve =&gt;
  page.exposeFunction("sendMessage", async message =&gt; {
    console.log(`[script] Message from pre-load script: ${message}`);
    resolve();
  })
);

await page.evaluateOnNewDocument(() =&gt; {
  const observer = new MutationObserver(mutationList =&gt; {
    for (const mutation of mutationList) {
      if (mutation.type === "childList") {
        for (const node of mutation.addedNodes) {
          if (node.tagName === "TITLE") {
            sendMessage(node.textContent);
          }
        }
      }
    };
  });

  observer.observe(document.documentElement, {
    subtree: true,
    childList: true,
  });
});

await page.goto("https://support.mozilla.org");
await gotMessage;
await browser.close();</code></pre>
<p>Output:</p>
<pre>[script] Message from pre-load script: Mozilla Support</pre>
<h2>Technical Background</h2>
<p>Until recently people wishing to automate browsers had two main choices:</p>
<ul>
<li aria-level="1">Use the W3C <a href="https://w3c.github.io/webdriver/">WebDriver</a> API, which was based on earlier work by the Selenium project.</li>
<li aria-level="1">Use a browser-specific API for talking to each supported browser such as <a href="https://chromedevtools.github.io/devtools-protocol/">Chrome DevTools Protocol</a> (CDP) for Chromium-based browsers, or Firefox’s <a href="https://firefox-source-docs.mozilla.org/devtools/backend/protocol.html">Remote Debugging Protocol</a> (RDP) for Gecko-based browsers.</li>
</ul>
<p>Unfortunately both of those options come with significant tradeoffs. The “classic” WebDriver API is HTTP-based, and its model involves automation sending a command to the browser and waiting for a response. That works well for automation scenarios where you load a page and then verify, for example, that some element is displayed, but the inability to get events ­— e.g. console logs — back from the browser, or run multiple commands concurrently, makes the API a poor fit for more advanced use cases.</p>
<p>By contrast, browser-specific APIs have generally been designed around supporting the complex use cases of in-browser devtools. This has given them a feature set far in advance of what’s possible using WebDriver, as they need to support use cases such as recording console logs, or network requests.</p>
<p>Therefore, browser automation clients have been forced to make the choice between supporting many browsers using a single protocol and providing a limited feature set, or providing a richer feature set but having to implement multiple protocols to provide functionality separately for each supported browser. This obviously increased the cost and complexity of creating great cross-browser automation, which isn’t a good situation, especially when developers <a href="https://mdn.dev/archives/insights/reports/mdn-web-testing-report-2021.html">commonly cite</a> cross-browser testing as one the main pain points in developing for the web.</p>
<p>Long time developers might notice the analogy here to the situation with editors before the development of <a href="https://microsoft.github.io/language-server-protocol/">Language Server Protocol</a> (LSP). At that time each text editor or IDE had to implement bespoke support for each different programming language. That made it hard to get support for a new language into all the tools that developers were using. The advent of LSP changed that by providing a common protocol that could be supported by any combination of editor and programming language. For a new programming language like TypeScript to be supported across all editors it no longer needs to get them to add support one-by-one; it only needs to provide an LSP server and it will automatically be supported across any LSP-supporting editor. The advent of this common protocol has also enabled things that were hard to imagine before. For example specific libraries like Tailwind getting their own <a href="https://www.npmjs.com/package/@tailwindcss/language-server">LSP implementation</a> to enable bespoke editor functionality.</p>
<p>So to improve cross-browser automation we’ve taken a similar approach: developing <a href="https://w3c.github.io/webdriver-bidi/">WebDriver BiDi</a>, which brings the automation featureset previously limited to browser-specific protocols to a standardized protocol that can be implemented by any browser and used by any automation tooling in any programming language.</p>
<p>At Mozilla we see this strategy of standardizing protocols in order to remove barriers to entry, allow a diverse ecosystem of interoperable implementations to flourish, and enable users to choose those best suited to their needs as a key part of our manifesto and <a href="https://www.mozilla.org/en-US/about/webvision/full/#openness">web vision</a>.</p>
<p>For more details about the design of WebDriver BiDi and how it relates to classic WebDriver, please see our <a href="https://hacks.mozilla.org/2020/12/cross-browser-testing-part-1-web-app-testing-today/">earlier</a> <a href="https://hacks.mozilla.org/2021/01/improving-cross-browser-testing-part-2-new-automation-features-in-firefox-nightly/">posts</a>.</p>
<h2>Removing experimental CDP support in Firefox</h2>
<p>As part of our early work on improving cross-browser testing, we shipped a partial implementation of CDP, limited to a few commands and events needed to support testing use cases. This was previously the basis of experimental support for Firefox in Puppeteer. However, once it became clear that this was not the way forward for cross-browser automation, effort on this was stopped. As a result it is unmaintained and doesn’t work with modern Firefox features such as site isolation. Therefore support is <a href="https://fxdx.dev/deprecating-cdp-support-in-firefox-embracing-the-future-with-webdriver-bidi/">scheduled to be removed</a> at the end of 2024.</p>
<p>If you are currently using CDP with Firefox, and don’t know how to transition to WebDriver BiDi, please reach out using one of the <a href="#contact-us">channels listed at the bottom of this post</a>, and we will discuss your requirements.</p>
<h2>What’s Next?</h2>
<p>Although Firefox is now officially supported in Puppeteer, and has enough functionality to cover many automation and testing scenarios, there are still some APIs that remain unsupported. These broadly fall into three categories (consult the <a href="https://pptr.dev/webdriver-bidi">Puppeteer documentation</a> for a full list):</p>
<ul>
<li aria-level="1">Highly CDP-specific APIs, notably those in the <a href="https://pptr.dev/api/puppeteer.cdpsession">CDPSession</a> module. These are unlikely to be supported directly, but specific use cases that currently require these APIs could be candidates for standardization.</li>
<li aria-level="1">APIs which require further standards work. For example <a href="https://pptr.dev/api/puppeteer.accessibility.snapshot">page.accessibility.snapshot</a> returns a dump of the Chromium accessibility tree. However because there’s currently no standardized description of what that tree should look like this is hard to make work in a cross-browser way. There are also cases which are much more straightforward, as they only require work on the WebDriver BiDi spec itself; for example <a href="https://pptr.dev/api/puppeteer.page.setgeolocation">page.setGeolocation</a>.</li>
<li aria-level="1">APIs which have a standard but are not yet implemented, for example the ability to execute scripts in workers required for commands like <a href="https://pptr.dev/api/puppeteer.webworker.evaluate">WebWorker.evaluate</a>.</li>
</ul>
<p>We expect to fill these gaps going forward. To help prioritize, we’re interested in your feedback: Please try running your Puppeteer tests in Firefox! If you’re unable to get them in Firefox because of a bug or missing feature, please let us know using one of the methods below so that we can take it into account when planning our future standards and implementation work:</p>

    <section>
                                
                      <p>Software engineer focused on maintaining a healthy open web. Web-platform-tests core team member.</p>
                                <p><a href="https://hacks.mozilla.org/author/jgrahammozilla-com/">More articles by James Graham…</a></p>
                  
                                <p><a href="https://hacks.mozilla.org/author/hskupinmozilla-com/">More articles by Henrik Skupin…</a></p>
                  
                                <p><a href="https://hacks.mozilla.org/author/jdescottesmozilla-com/">More articles by Julian Descottes…</a></p>
                  
                                <p><a href="https://hacks.mozilla.org/author/aborovovamozilla-com/">More articles by Alexandra Borovova…</a></p>
                  </section>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gear Acquisition Syndrome (110 pts)]]></title>
            <link>https://library.oapen.org/handle/20.500.12657/48282</link>
            <guid>41181871</guid>
            <pubDate>Wed, 07 Aug 2024 14:32:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://library.oapen.org/handle/20.500.12657/48282">https://library.oapen.org/handle/20.500.12657/48282</a>, See on <a href="https://news.ycombinator.com/item?id=41181871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h5>Abstract</h5>
<p>"Gear Acquisition Syndrome, also known as GAS, is commonly understood as the musicians’ unrelenting urge to buy and own instruments and equipment as an anticipated catalyst of creative energy and bringer of happiness. For many musicians, it involves the unavoidable compulsion to spend money one does not have on gear perhaps not even needed. The urge is directed by the belief that acquiring another instrument will make one a better player.
This book pioneers research into the complex phenomenon named GAS from a variety of disciplines, including popular music studies and music technology, cultural and leisure studies, consumption research, sociology, psychology and psychiatry. The newly created theoretical framework and empirical studies of online communities and offline music stores allow the study to consider musical, social and personal motives, which influence the way musicians think about and deal with equipment. As is shown, GAS encompasses a variety of practices and psychological processes. In an often life-long endeavour, upgrading the rig is accompanied by musical learning processes in popular music."</p>
</div><div>
<h5>Keywords</h5><p>Gear Acquisition Syndrome, GAS, THEORY, musician, popular music studies, music technology, consumption research</p></div><div>
<h5>ISBN</h5><p>9781862181847, 9781862181847</p></div><div>
<h5>Publication date and place</h5><p>Huddersfield, 2021</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AMD Ryzen 5 9600X and Ryzen 7 9700X Offer Excellent Linux Performance (109 pts)]]></title>
            <link>https://www.phoronix.com/review/ryzen-9600x-9700x</link>
            <guid>41180976</guid>
            <pubDate>Wed, 07 Aug 2024 13:01:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.phoronix.com/review/ryzen-9600x-9700x">https://www.phoronix.com/review/ryzen-9600x-9700x</a>, See on <a href="https://news.ycombinator.com/item?id=41180976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p>This could quite well be my simplest review in the past twenty years of Phoronix. The AMD Ryzen 9000 series starting with the Ryzen 5 9600X and Ryzen 7 9700X launching tomorrow are some truly great desktop processors. The generational uplift is very compelling, even in single-threaded Linux workloads shooting ahead of Intel's 14th Gen Core competition, across nearly 400 benchmarks these new Zen 5 desktop CPUs impress, and these new Zen 5 desktop processors are priced competitively. I was already loving the Ryzen 7000 series performance on Linux with its AVX-512 implementation and performing so well across hundreds of different Linux workloads but now with the AMD Ryzen 9000 series, AMD is hitting it out of the ball park. That paired with the issues Intel is currently experiencing for the Intel Core 13th/14th Gen CPUs and the ~400 benchmark results makes this a home run for AMD on the desktop side with only some minor Linux caveats.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_1_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_1_med" alt="AMD Ryzen 5 9600X and Ryzen 7 9700X retail packages"></a></p>
<p>The past two weeks I have been eagerly running many benchmarks of AMD <a href="https://www.phoronix.com/search/Zen+5">Zen 5</a> on Linux with Strix Point via the <a href="https://www.phoronix.com/review/amd-ryzen-ai-9-365">Ryzen AI 9 365</a> and <a href="https://www.phoronix.com/review/amd-ryzen-ai-9-hx-370">Ryzen AI 9 HX 370</a> with great results. That was fun, but now with Zen 5 desktop processors in hand, the benchmarking has been wild. Ahead of tomorrow's Ryzen 5 9600X and Ryzen 7 9700X availability, the review embargo on these processors lifts today. It's not until next week for the Ryzen 9 9900X and Ryzen 9 9950X availability and review embargo lift.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_2_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_2_med" alt="AMD Ryzen Zen 5 bottom"></a></p>
<p>Given there were already the prior embargo lifts on the <a href="https://www.phoronix.com/review/amd-zen5-ryzen-9000">AMD Zen 5 client products</a> and <a href="https://www.phoronix.com/review/amd-zen-5-core">Zen 5 architecture details</a>, today's review is squarely focused on the Ryzen 5 9600X and Ryzen 7 9700X products.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_4_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_4_med" alt="AMD Ryzen 5 9600X"></a></p>
<p>The Ryzen 5 9600X as a reminder is a 6-core / 12-thread Zen 5 processor with 3.9GHz base clock and 5.4GHz boost clock while having a 32MB L3 cache and a 65 Watt TDP rating. This processor is launching tomorrow at $279 USD... While the prior gen Ryzen 5 7600X today retails for around $200~220, back when it launched that Zen 4 6-core part was priced at $299 USD. So seeing the Ryzen 5 9600X launch less at $279 is rather competitive. The Intel Core i5 14600K competition meanwhile is priced at $299~339 USD as of writing.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_3_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_3_med" alt="AMD Ryzen 7 9700X"></a></p>
<p>The Ryzen 7 9700X meanwhile is the 8-core / 16-thread Zen 5 desktop processor with a 3.8GHz base frequency, maximum boost clock of 5.5GHz, 32MB L3 cache, and a 65 Watt TDP. The Ryzen 7 9700X is launching at a suggested price of $359 USD. This too is priced very well considering the prior gen Ryzen 7 7700X launched at $399 USD and the Intel Core i7 14700K competition is priced at $399~419 USD.</p>
<p><a href="https://www.phoronix.com/image-viewer.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_5_lrg" target="_blank"><img src="https://www.phoronix.net/image.php?id=amd-ryzen-5-9600x-ryzen-7-9700x&amp;image=amd_ryzen9600x9700x_5_med" alt="AMD Ryzen 7 9700X processor"></a></p>
<p>With the pricing covered, that leaves the two other main areas for the Phoronix focus: the Linux support and the performance.</p>
<p>When it comes to the Linux support for the Ryzen 9000 series, you should be in good shape with modern Linux distributions. With the Ryzen 9000 series working with existing AM5 motherboards after BIOS upgrade, there isn't any new platform kinks to really worry about or other Linux compatibility problems there. As I've shown in my several AMD Ryzen AI 300 series articles, the Zen 5 core support is in order. With the Ryzen 9000 series it's also simpler than with Strix Point given that there is the older cut-down RDNA2 integrated graphics if using the integrated graphics/display on the desktop CPUs and these are all full Zen 5 cores without any mix of Zen 5 and 5C.</p>
<p>All of the core support for the Ryzen 9000 series is good for end-users running the Ryzen 9000 series on modern distributions like Ubuntu 24.04 LTS, Fedora 40, Arch Linux, etc. There are a few caveats to note. First, while not relevant to most of you, if planning to use any RAPL/PowerCap sysfs monitoring the CPU power consumption that sadly isn't yet mainlined for Zen 5... Rather silly, but <a href="https://lore.kernel.org/linux-pm/20240719101234.50827-1-Dhananjay.Ugwekar@amd.com/">a one line patch is needed</a> that hasn't yet been upstreamed to add Family 1Ah to the PowerCap RAPL driver. It's sad that this one-liner wasn't merged months ago especially with the new Family ID for Zen 5 being known for months. But without this one line patch, you won't be able to enjoy any energy reporting for the CPU... Thus for my benchmarking of the Ryzen 9000 series I had to patch my kernel build. If you are on Linux 6.9+, you'll also need <a href="https://lore.kernel.org/linux-pm/20240730044917.4680-1-Dhananjay.Ugwekar@amd.com/T/#m7a59207d34b40a54971193b75d36c14dafee7824">this patch</a> to fix the AMD RAPL package energy counter scope. But again this isn't a feature used by the masses and for my purposes only ever of interest during benchmarking for power consumption monitoring and performance-per-Watt measurements. But frustrating nevertheless that the one line patch wasn't upstreamed months ago as part of the rest of the Zen 5 code but seemingly overlooked.</p>
<p>The other minor blemish for the AMD Zen 5 support is on the compiler side. <a href="https://www.phoronix.com/news/AMD-Zen-5-Znver5-Merged-GCC14">AMD did get the Znver5 target added for GCC 14.1 stable</a> that released back in April. Though it would have been even better if the support actually was out last year for GCC 13 given the annual release cadence and the likes of Ubuntu 24.04 LTS using GCC 13, not GCC 14. Intel typically does the better job here of trying to get their ISA enablement and new CPU targets added into the open-source compilers well ahead of release to avoid timing/alignment issues like this. But getting the Znver5 target into GCC 14 is at least better than sometimes where there hasn't been the support in a released compiler at launch day. But... Znver5 isn't yet in the LLVM/Clang compiler codebase. As of writing there is no Znver5 support upstreamed into the LLVM/Clang compiler. That's disappointing months after the GCC support was upstreamed. There is an imminent timing issue there as well with <a href="https://www.phoronix.com/news/LLVM-Clang-19-Feature-Freeze">LLVM Clang 19 releasing in September</a> and no Znver5 support yet. We'll see if it gets added and back-ported to the v19 release branch in the coming weeks or not.</p>
<p>So there still are some AMD Linux enablement quirks where they could improve upon for seeing better software support on launch-day, but for those not worrying about RAPL/PowerCap energy monitoring or spinning tuned-out binaries catered to Zen 5, the Linux support overall is in great shape for the Ryzen 9000 series.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I've spent nearly 5y on a web app that creates 3D apartments (302 pts)]]></title>
            <link>https://roometron.com</link>
            <guid>41180504</guid>
            <pubDate>Wed, 07 Aug 2024 12:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://roometron.com">https://roometron.com</a>, See on <a href="https://news.ycombinator.com/item?id=41180504">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="mainContainer"><h3><span>ROO</span><span>M</span><span>ETRON</span></h3><div><h2><span>WE TRANSFORM&nbsp;</span><br><span>Floor&nbsp;</span> <span>PLANS</span></h2><h2><strong>Boost up your</strong> real estate <strong>marketing</strong><br>with eye-catching 3D visuals</h2></div></div><div id="aboutUsMobile"><h2>Roometron transforms floor plans into virtual 3D spaces</h2><p>We bring an amazing opportunity to <strong>enhance the visibility of your real estate projects</strong> and stand out among the others within any budget</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: BudgetFlow – Budget planning using interactive Sankey diagrams (151 pts)]]></title>
            <link>https://www.budgetflow.cc/</link>
            <guid>41180441</guid>
            <pubDate>Wed, 07 Aug 2024 11:56:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.budgetflow.cc/">https://www.budgetflow.cc/</a>, See on <a href="https://news.ycombinator.com/item?id=41180441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page_content">
	<!-- <header>
		<h1>BudgetFlow: Visual Budget Management Made Easy</h1>
		<nav>
			<ul>
				<li><a href="">Home</a></li>
				<li><a href="">Features</a></li>
				<li><a href="">How It Works</a></li>
				<li><a href="">Pricing</a></li>
				<li><a href="">Blog</a></li>
			</ul>
		</nav>
	</header>
	-->
	
<!----------------------------------------------------------------------------->




<ui-container>
	<div id="top_bar">
	



		<div>

			<ui-button clear="" hx-get="/" hx-push-url="true" hx-select="#page_content" hx-target="#page_content" hx-swap="outerHTML">
				<img src="https://www.budgetflow.cc/static/images/logo6.png" alt="Logo">
			</ui-button>

			
		</div>

		

		<p id="align-right">
			
				<ui-button href="/register">
					Register
				</ui-button>
			
		</p>


</div>


</ui-container>


<ui-container>
	
	<p>
		Welcome to BudgetFlow, an app for managing your budget visually and interactively using flow charts.
		The website is currently in beta so feedback is highly appreciated.
	</p>
</ui-container>


<ui-container>
	<div>
		<div>
			<h5>Create Budgets</h5>
			<p>Create budgets and visualize them as sankey diagrams.</p>
		</div>
		<div>
			<h5>Smart Pockets</h5>
			<p>Pockets can automatically send excess cash to another pocket or take missing cash from another pocket.</p>
		</div>
		<div>
			<h5>Shared Budgets</h5>
			<p>Share budgets with other users like your roommates or partner. Collaborate on the budget together, and link it with your own budgets.</p>
		</div>
	</div>
</ui-container>






<!----------------------------------------------------------------------------->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uber tests its payment systems in production (156 pts)]]></title>
            <link>https://news.alvaroduran.com/p/cringey-but-true-how-uber-tests-payments</link>
            <guid>41178959</guid>
            <pubDate>Wed, 07 Aug 2024 07:16:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.alvaroduran.com/p/cringey-but-true-how-uber-tests-payments">https://news.alvaroduran.com/p/cringey-but-true-how-uber-tests-payments</a>, See on <a href="https://news.ycombinator.com/item?id=41178959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>You are wasting most of the time you spend testing.</p><p>And I get it. You’d rather test things in staging, because it gives you a sense of control. Most engineers even cringe at the idea of testing in production. But I think that's because they think it’s either/or. It’s not.</p><p>You can test before deployment as much as you’d like. And then, you can test in production as much as you can. The trick is when to switch.&nbsp;</p><p><strong>You aren’t testing in production early enough.</strong></p><p>That’s why what Uber does is so intriguing.</p><p>But first, why is testing in production even necessary? Can’t we just try to write code as correctly as we can inside a no-stakes environment, rather than risking real money and real impact on real users?</p><p><span>You could. But </span><strong>if you’re doing your job right, you’ll quickly run out of bugs</strong><span> to find in such an environment. The easy ones. If you haven’t already.</span></p><p>Look, the systems you maintain, that most of us maintain, have been around for a few years. Some, even decades. That is because software is not like other machines. Most machines, in time, rot and decay. But software is just information: if it’s correct, it stays that way. Hardware does need replacement, but the correct software that runs on it keeps running.</p><p>Software, if you’re doing your job right, gets better over time.</p><p>What an amazing machine.</p><p><span>You probably call those systems </span><em>legacy</em><span> with disdain, because software gets more difficult to maintain over time. But there’s a reason legacy software is scary to change. We want it to keep doing what it's currently doing.</span></p><p><span>Hate it all you want, but </span><strong>legacy software works, even when it’s a mess</strong><span>.</span></p><p>There’s pretty much one way to produce high quality software. Use it, and fix all the bugs you can find in it. In time, the easy bugs are gone.&nbsp;</p><p>Unlike the human body, old software is so healthy. If that’s the only way to produce high quality software, the only illnesses you’re going to find are the exotic ones.</p><p><span>Payment systems are an extreme version of this. Moving money has always been </span><strong>the most obvious business use case for computers</strong><span>. And so, money software has been around for a long time.</span></p><p>That’s the kind of software that Uber, or any other merchant, has to deal with. What I find fascinating is that Uber is doing it in a way that makes many engineers cringe.</p><p><strong>Uber tests its payment systems in production</strong><span>. And in this article, I’m going to tell you how they do it, and why it’s a great idea.</span></p><p><span>I’m </span><a href="https://www.linkedin.com/in/alvaroduranbarata/" rel="">Alvaro Duran</a><span>, and this is </span><em>The Payments Engineer Playbook</em><span>. Scroll for five minutes on Youtube and you’ll find tons of tutorials that show you payment system designs that’ll help you pass interviews. But there’s not much that teaches you how to build this critical software for real users and real money.</span></p><p>The reason I know this is because I’ve built and maintained systems that handle close to 100,000 payments a day. And I’ve been able to see all types of interesting conversations about what works and what doesn't for payment systems behind closed doors.</p><p>These conversations are what inspired this newsletter.</p><p><span>In </span><em>The Payments Engineer Playbook</em><span>, we investigate the technology that transfers money. And we do that by cutting off one sliver of it and extract tactics from it.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg" width="1456" height="998" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:998,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;A Tour of Uber's New San Francisco Office - Officelovin&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="A Tour of Uber's New San Francisco Office - Officelovin" title="A Tour of Uber's New San Francisco Office - Officelovin" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa77d5215-a5c5-4b71-b783-57e26c261a9f_1600x1097.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Uber offices in San Francisco</figcaption></figure></div><p>If you don’t want to test payments in production, your only choice is to use a staging environment.</p><p>And what do you have to do to set up a good one? Two things.</p><p>First, you have to copy all production data. It’s expensive, and a reckless breach in privacy and security, but it’s doable. And second, you must emulate all user activity. Staging must become a believable version of your production systems.</p><p><span>That reminds me of a </span><a href="https://en.wikipedia.org/wiki/Potemkin_village" rel="">Potemkin village</a><span>.</span></p><p><span>Staging environments are not as useful as you think they are. </span><strong>It is unrealistic to try to erect sophisticated replicas of the real world</strong><span>. Your tests will only be as good as your ability to do the job completely.</span></p><p><span>I really like </span><a href="https://www.youtube.com/watch?v=DfAwKS1NShs" rel="">how Charity Majors put it</a><span>: “</span><strong>staging is just a glorified laptop</strong><span>”. Only production is production.</span></p><p><span>In fact, payment providers only do so much in their sandbox environments. As soon as you start digging deeper, </span><strong>you’ll notice a big gap between how sandbox behaves and all the surprises that production has for you</strong><span>.</span></p><p>But the lesson isn’t to demand better sandbox applications from your provider. They’re not going to comply, because it just doesn’t make a business difference to them.</p><p><span>Instead, the lesson should be this: </span><strong>to test your payment systems in sandbox for an amount of time that’s reasonable</strong><span>. And not a second more.</span></p><p>That’s how Uber does it.</p><p>Uber has outgrown the idea that defects can be completely solved at staging.</p><p>Rather than stressing out over a perfect release, Uber has put in place tools to detect production failures as early as possible, and to roll back to a known safe state quickly and easily.</p><p><span>These tools correspond to </span><strong>three key concepts</strong><span>: To roll out against business metrics, to carefully select a first rollout region, and to make these rollouts progressively.</span></p><p><span>Before he started </span><a href="https://newsletter.pragmaticengineer.com/" rel="">The Pragmatic Engineer</a><span>, Gergely Orosz worked as an engineer manager at Uber Money. In 2018, he gave a talk on </span><a href="https://www.youtube.com/watch?v=yooCE5B0SRA" rel="">how Uber rolled out new payment methods</a><span>.</span></p><p><span>For Orosz, </span><strong>building and rolling out a new payment method are two sides of the same coin</strong><span>.</span></p><p>Sandbox testing is something you do early on, because it speeds up development. But as soon as you can, you move into real payments with real cards.</p><p>And for that, the right debugging tools are critical.</p><p>Orosz mentions Uber’s internal tools, Cerberus and Deputy, which are responsible for two important tasks when testing in production</p><ul><li><p>Making requests to real systems in a transparent way</p></li><li><p>Channeling the responses into your own laptop</p></li></ul><p>But to me, the most important point of his talk is this:</p><p>For Uber, every deployment is an experiment</p><p>What Orosz means is that Uber recognizes that nobody really knows how any deployment is really going to turn out. Every time out there is a guess, and your job is to make it an educated one.</p><p>Therefore, every deployment is a hypothesis on how certain business metrics will look like from the moment it goes live.</p><p><span>Which metrics to measure, and which monitors to put in place to do that varies from company to company. But </span><strong>a payment method that doesn’t help your company earn more or spend less is a wasted effort</strong><span>.</span></p><blockquote><p>I’m not going to name names but some large successful unicorns in this city still deploy all their Java WAR files to production at once. At once. And they have a reputation for going down a bunch. I have no idea why.</p><p><span>— Charity Majors, </span><a href="https://www.youtube.com/watch?v=DfAwKS1NShs" rel="">Engineering Large Systems When You're Not Google Or Facebook</a></p></blockquote><p>Brazilians always get the new stuff from Facebook first.</p><p>This is by design. One of the corollaries of “every deployment is an experiment” is that you should mitigate any potential problems by exposing it to the smallest, but significant, subset of users possible. Only when you don’t see anything wrong, you expose it to more users.</p><p><span>The first experiment region is how you do that in the beginning. </span><strong>A way to contain the impact of a potential screw up</strong><span>.</span></p><p>When Uber rolled out GooglePay, they decided to focus their monitoring on Portugal.</p><p>It was a country</p><ul><li><p><strong>Small, but not tiny</strong><span>: Rolling out incrementally to 100% of the country’s traffic would be a significant number already</span></p></li><li><p><strong>In a close time region</strong><span> to where the team was based (Amsterdam): This made live monitoring so much convenient for them.</span></p></li><li><p><strong>With representative users</strong><span>: Most Portuguese pay on Uber through the Authorize flow, just like pretty much everyone globally.</span></p></li><li><p><strong>Where the provider’s dependencies are minimized</strong><span>: In Portugal, the old Android Pay had close to no penetration.</span></p></li></ul><p>Selecting a first experiment region can do wonders if you accept payments globally.</p><p>Done well, canary deployments make rollbacks more frequent, not less.</p><p>Like canaries in a coalmine, deploying to a subset of users is meant to be done frequently. You assume that the moment something doesn’t look good, you will pull back fast.</p><p><span>No deployment strategy is going to make each individual deployment safer. </span><strong>What canary deployments give you is the opportunity to trade SEV-1 outages for a few SEV-3 and SEV-4</strong><span>.</span></p><p>And guess what? That’s exactly what happened to Uber when they were rolling out GooglePay. Numbers didn’t add up in the beginning!</p><p>Rolling out cautiously in Portugal was a smart decision. It surfaced bugs in Google Pay.</p><blockquote><p>Our uncollected rate was huge. And we first just said “all right, are we stupid? Are we missing something here?” But no, everything seemed fine. Seemed like no mistakes.</p><p>So we searched it all with Google. First, we rolled back and we talked with Google. And, you know, It turns out there were some issues on their end, and there were some issues on our end, and we certainly fixed it. But it took quite a while.</p><p><span>— Gergely Orosz, </span><a href="https://www.youtube.com/watch?v=yooCE5B0SRA" rel="">Payments Integration at Uber: A Case Study</a></p></blockquote><p>How on Earth are you going to find bugs in GooglePay from a staging environment?</p><p>You can’t. You just can’t.</p><p><span>And that’s what’s fascinating to me. On the one hand, you’ve got engineers who take every precaution possible </span><em>before rolling out</em><span> because payments are something you should never break.</span></p><p><span>And on the other hand, you’ve got companies like Uber, who take every precaution possible </span><em>after rolling out</em><span> because they understand that </span><strong>the game is resiliency</strong><span>, not never failing at anything.</span></p><p><span>That’s the lesson that I’m taking away from how Uber does things. </span><strong>Testing before production is fine, but returns diminish sharply</strong><span>.</span></p><p>At some point, you’re better off checking your work against real users, and real money.</p><p>This reminds me of algorithmic trading. You can develop a strategy that performs great with backtest data, in a no stakes environment. But the real test is the real thing with real stakes. Nothing else compares to it.</p><p>You should think of deployments as experiments. Only production is production. Anything else is a prelude.</p><p><span>All right, that’s it for this article of </span><em>The Payments Engineer Playbook</em><span>. See you next week.</span></p><p><strong>PS</strong><span>: Before you go, I have to be completely honest with you: this article and </span><a href="https://news.alvaroduran.com/p/stripe-made-the-obvious-choice-when" rel="">the one on Stripe</a><span> took A LOT of work. I’m not sure if I’m going to keep making these kind of articles anymore.</span></p><p>I need to know from you.</p><p>Are these articles useful? Then, you can do two things.</p><p>First, I want you to leave a comment, no matter if it’s negative or positive. Either way, I want you to let me know: do you want me to keep making these articles?</p><p>It’s a lot of work, but I’ll keep doing it if I know it’s making an impact on you. Otherwise, these ideas will stay private inside of my team.</p><p>The second thing I need from you is to tell a colleague. If you’re reading this, you probably work with someone who builds payments for a living. And you’ve been reading this newsletter long enough to tell if it’s going to be useful for them too.</p><p>And if you got this article from a colleague, do me a favor and subscribe. It’s a flex to be a reader of a well-known publication before it was cool.</p><p>I bet that’s how it feels to be a VC who led a series A on a startup at IPO day.</p><p><span>Make a bet on </span><em>The Payments Engineer Playbook</em><span>. I’ll see you around.</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[70% of new NPM packages in last 6 months were spam (211 pts)]]></title>
            <link>https://blog.phylum.io/the-great-npm-garbage-patch/</link>
            <guid>41178258</guid>
            <pubDate>Wed, 07 Aug 2024 04:31:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.phylum.io/the-great-npm-garbage-patch/">https://blog.phylum.io/the-great-npm-garbage-patch/</a>, See on <a href="https://news.ycombinator.com/item?id=41178258">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
<!--kg-card-begin: html-->
    
<a href="https://www.phylum.io/black-hat-2024">
        <p><img src="https://www.blackhat.com/images/page-graphics-usa-15/logos/bh_logo_black_onwhite.png"></p>
        <p>Headed to Black Hat USA? Come talk to us in Start-Up City at SC203!</p>
    </a>
<!--kg-card-end: html-->
<p>In April of this year, the Phylum Research Team revealed the <a href="https://blog.phylum.io/digital-detritus-unintended-consequences-of-open-source-sustainability-platforms/" rel="noopener noreferrer">proliferation of spam packages in npm</a> associated with the Tea protocol, a decentralized initiative that promises to compensate software developers in cryptocurrency for their open-source contributions. Last month, we published our <a href="https://blog.phylum.io/q2-2024-evolution-of-software-supply-chain-security-report/" rel="noopener noreferrer">quarterly research report</a>, which estimated that approximately one out of every four packages published to npm in Q2 were associated with Tea, virtually all of which had no redeeming quality aside from gaming the protocol to inflate a software developer’s contribution artificially. With new research from a fresh perspective, our team can now report that the volume of these packages is likely larger than our initial estimates. Like the island of discarded plastic twice the size of Texas floating in the North Pacific Ocean, npm has accrued an astonishing amount of spam packages over the past six months. Join us as we take a fresh look at the pollution in this open-source ecosystem.</p><p>As detailed in <a href="https://blog.phylum.io/digital-detritus-unintended-consequences-of-open-source-sustainability-platforms/">our previous blog</a>, the Tea protocol perversely incentivizes software developers to exaggerate their contribution to open-source development. Using a modified PageRank called teaRank, software developers are rewarded based on their “Proof of Contribution”. As the early SEO spammers figured out how to game PageRank for their benefit, history repeats itself, and a few software developers have spammed open-source repositories with absurd amounts of worthless packages.</p><p>npm, the largest open-source ecosystem, has suffered the worst from this pollution from various actors. Some of the hallmarks of these spam packages are <a href="https://www.npmjs.com/package/mdanattagdaysrh?activeTab=code">gibberish package names</a>, packages named with <a href="https://www.npmjs.com/package/interesting-moccasin-pike?activeTab=code">random combinations of words</a> from a list, implausible <a href="https://www.npmjs.com/package/rusttool080059?activeTab=dependencies">lists of dependent packages</a>, a <a href="https://www.npmjs.com/package/random-job-selector?activeTab=dependents">dubious number of dependent packages</a>, and in this morass of transitive dependencies, the ubiquitous <code>tea.yaml</code> file that ultimately <a href="https://www.npmjs.com/package/hoadandi-27">identifies the code owner</a>. When Phylum first started investigating this situation in February, we were continually amazed at the sheer volume of packages that could be published, clearly due to automation. So, we turned our attention to trying to understand the full scope of this spam problem.</p><p>For a baseline, at the start of 2024, the total number of packages ingested into Phylum daily from npm was about 1,500 each business day and about half that on the weekends. Starting in February of 2024, Phylum began to notice a steady increase in npm package publications from a few thousand to tens of thousands. The high water mark of this increase occurred on 8 April 2024, with over 48,000 packages published to npm. This explosion of packages led us to our first discovery of the <a href="https://blog.phylum.io/digital-detritus-unintended-consequences-of-open-source-sustainability-platforms/">perverse incentives</a> of the Tea protocol.</p><p>Last month, in preparation for our quarterly report, we took a random sample from all npm packages published in Q2, and we manually triaged 1600 packages. If a package contained markers of Tea protocol abuse, as noted above, we marked it as spam. With these, we found a 95% confidence interval for the estimate of the percentage of spam packages in npm in Q2 between 21.25% and 25.5%, or in other words, over 500,000 spam packages.</p><p>Upon further reflection, we considered that many npm projects have nightly builds or alpha, beta, and canary versions. So, these legitimate packages that enjoy a robust development cycle might dilute the size of the true impact of spam. What if we restricted our search to new packages? Packages that have never been seen before in npm?</p><p>We widened our search in our npm data back to February, when we saw the first Tea protocol spam, and then removed all the packages that had at least one version published prior. This left us over 890,000 new, never-before-seen packages between February 2024 and the present. From this set, we took a random sample of 900 packages and applied the same criteria as before. From this new perspective, our 95% confidence interval for the estimate of Tea protocol spam in new packages over the past six months jumped to between 68.66% and 74.67%, or somewhere between 613,000 and 667,000 packages.</p><p>In other words, among all new packages published to npm in the past six months, about five out of every seven packages are Tea spam.</p><p>Followers of this blog know that most of our content focuses on exposing active malicious attacks against open-source software developers. In the spirit of full disclosure, Phylum has yet to discover evidence that these packages contain or lead to the usual kind of malice that we regularly report. But, as a general observation, this pollution is a kind of malice, and there are several dangerous avenues that this could turn into.</p><p>First, unlike malicious typosquatting campaigns, in which an unsuspecting developer might accidentally install <code>reaxt</code> instead of <code>react</code>, it is not at all likely that a developer would make the same mistake with, for example, <a href="https://www.npmjs.com/package/quasar-fig-0e1t?activeTab=dependencies">quasar-fig-0e1t</a>. However, a package like <a href="https://www.npmjs.com/package/web3-cover?activeTab=dependencies">web3-cover</a> is more plausible, where the developer would also get the 170 dependents along with the complete transitive dependency tree for each of those.</p><p>Next, because the AI hype train is at full steam, we must point out the obvious. AI models that are trained on these packages will almost certainly skew the outputs in unintended directions. These packages are ultimately garbage, and the mantra of “garbage in, garbage out” holds true.</p><p>Finally, these large-scale spam campaigns hinder the open-source package registry’s ability to reason through the safety of all packages in an ecosystem, despite the fact that no reasonable person would ever endeavor to install one of these spam packages. They raise the noise floor and create an environment in which an adversary could surreptitiously hide actual maliciousness.</p><p>Let’s start by taking a look at the following package, <a href="https://www.npmjs.com/package/sournoise" rel="noopener noreferrer">sournoise</a>. The npmjs website lists a single dependency on axios.</p><figure><img src="https://blog.phylum.io/content/images/2024/08/Screenshot-2024-08-05-at-17.55.22.png" alt="npmjs.org showing axios as a dependency of sournoise" loading="lazy" width="2000" height="1152" srcset="https://blog.phylum.io/content/images/size/w600/2024/08/Screenshot-2024-08-05-at-17.55.22.png 600w, https://blog.phylum.io/content/images/size/w1000/2024/08/Screenshot-2024-08-05-at-17.55.22.png 1000w, https://blog.phylum.io/content/images/size/w1600/2024/08/Screenshot-2024-08-05-at-17.55.22.png 1600w, https://blog.phylum.io/content/images/2024/08/Screenshot-2024-08-05-at-17.55.22.png 2000w" sizes="(min-width: 720px) 720px"><figcaption><span>npmjs.org showing </span><code spellcheck="false"><span>axios</span></code><span> as a dependency of </span><code spellcheck="false"><span>sournoise</span></code></figcaption></figure><p>There is not a lot happening here. The package does not contain code, and according to npm, the only dependency is on the extremely popular Axios package. Is this package safe to install?</p><p>The <code>package.json</code> tells a different story.</p><figure><pre><code>{
  "name": "sournoise",
  "version": "1.0.1",
  "description": "",
  "main": "index.js",
  "scripts": {
    "test": "echo \"Error: no test specified\" &amp;&amp; exit 1"
  },
  "author": "",
  "license": "ISC",
  "dependencies": {
    "axios": "https://registry.npmjs.org/@putrifransiska/kwonthol36/-/kwonthol36-1.1.4.tgz"
  }
}</code></pre><figcaption><p><code spellcheck="false"><span>package.json</span></code><span> for </span><code spellcheck="false"><span>sournoise</span></code><span> shouting the spurious </span><code spellcheck="false"><span>axios</span></code><span> dependency</span></p></figcaption></figure><p>Contrary to what npm states, this package actually depends on one of our aforementioned spam packages. This is a by-product of how npm handles and displays dependencies to users on its website. There is no clear linkage to <code>@putrifransiska/kwonthol36</code>, <code>axios</code> lists <code>sournoise</code> as a dependent.</p><p>To say that you’d never install one of these spam packages is to ignore the complexity of the supply chain: transitive dependencies can pull in packages that the developer neither wants nor expects to receive.</p><p>Open-source software ecosystem pollution is a problem for everyone. The Tea protocol project is <a href="https://tea.xyz/blog/proof-of-contribution" rel="noopener noreferrer">taking steps to remediate this problem.</a> It would be unfair to legitimate participants in the Tea protocol to have their remuneration reduced because others are scamming the system. Also, npm has begun to take down <a href="https://github.com/advisories?query=type%3Amalware+zitterorg" rel="noopener noreferrer">some of these spammers</a>, but the take-down rate does not match the new publication rate. And this problem is not limited to npm alone. For example, <a href="https://packages.ecosyste.ms/api/v1/registries/rubygems.org/maintainers/188987/packages" rel="noopener noreferrer">this user</a> published nearly 1800 spam packages on Rubygems in late February and early March 2024. Phylum is actively researching this area, and we will continue to seek new ways to detect this spam as these actors adapt their tactics.</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Private Life: On James Baldwin (103 pts)]]></title>
            <link>https://www.theparisreview.org/blog/2024/08/02/the-private-life-on-james-baldwin/</link>
            <guid>41177831</guid>
            <pubDate>Wed, 07 Aug 2024 02:58:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theparisreview.org/blog/2024/08/02/the-private-life-on-james-baldwin/">https://www.theparisreview.org/blog/2024/08/02/the-private-life-on-james-baldwin/</a>, See on <a href="https://news.ycombinator.com/item?id=41177831">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		

<p>In his review of James Baldwin’s third novel, <em>Another Country</em>, Lionel Trilling asked: “How, in the extravagant publicness in which Mr. Baldwin lives, is he to find the inwardness which we take to be the condition of truth in the writer?”</p>
<p>But Baldwin’s sense of inwardness had been nourished as much as it had been damaged by the excitement and danger that came from what was public and urgent. <em>Go Tell It on the Mountain</em> and <em>Giovanni’s Room</em> dramatized the conflict between a longing for a private life, even a spiritual life, and the ways in which history and politics intrude most insidiously into the very rooms we try hardest to shut them out of.</p>
<p>Baldwin had, early in his career, elements of what T. S. Eliot attributed to Henry James, “a mind so fine that it could not be penetrated by an idea.” The rest of the time, however, he did not have this luxury, as public events pressed in on his imagination.<span id="more-168156"></span></p>
<p>Baldwin’s imagination remained passionately connected to the destiny of his country. He lacked the guile and watchfulness that might have tempted him to keep clear of what was happening in America; the ruthlessness he had displayed in going to live in Paris and publishing <em>Giovanni’s Room</em> was no use to him later as the battle for civil rights grew more fraught. It was inevitable that someone with Baldwin’s curiosity and moral seriousness would want to become involved, and inevitable that someone with his sensitivity and temperament would find what was happening all-absorbing.</p>
<p>Baldwin’s influence arose from his books and his speeches, and from the tone he developed in essays and television appearances, a tone that took its bearings from his own experience in the pulpit. Instead of demanding reform or legislation, Baldwin grew more interested in the soul’s dark, intimate spaces and the importance of the personal and the private.</p>
<p>In 1959, in reply to a question about whether the fifties as a decade “makes special demands on you as a writer,” Baldwin adopted his best style, lofty and idealistic and candid, while remaining sharp, direct, and challenging: “But finally for me the difficulty is to remain in touch with the private life. The private life, his own and that of others, is the writer’s subject—his key and ours to his achievement.”</p>
<p>Baldwin was interested in the hidden and dramatic areas in his own being, and was prepared as a writer to explore difficult truths about his own private life. In his fiction, he had to battle for the right of his protagonists to choose or influence their destinies. He knew about guilt and rage and bitter privacies in a way that few of his white novelist contemporaries did. And this was not simply because he was Black and homosexual; the difference arose from the very nature of his talent, from the texture of his sensibility. “All art,” he wrote, “is a kind of confession, more or less oblique. All artists, if they are to survive, are forced, at last, to tell the whole story, to vomit the anguish up.”</p>
<p>Baldwin understood the singular importance of the novel, because he saw the dilemma his country faced as essentially an interior one, as his fellow citizens suffered from a poison that began in the individual spirit and then made its way into politics. And his political writing remains as intense and vivid as his fiction, because he believed that social reform could not occur through legislation alone but required a reimagining of the private realm. Thus, for Baldwin, an examination of the individual soul as dramatized in fiction had immense power.</p>
<p>***</p>
<p>Baldwin’s reputation as a novelist and essayist rests mainly on the work he did in the decade before 1963, a decade in which he was passionately industrious. The year 1963 seems to have been a watershed for him. He wrote hardly any fiction in that year. It was a time in which “the condition of truth” could not be achieved by solitude or by silence or by slow work on a novel.</p>
<p>Baldwin began the year by going on a lecture tour for the Congress of Racial Equality, known as <small>CORE</small>. In the first few days of January, he met James Meredith, the first Black student to enroll at the University of Mississippi despite being denied admission by the state’s governor. Meredith noted how quiet Baldwin was, but he was also amused by Baldwin’s version of the dance known as the twist.</p>
<p>Also in January of 1963, Baldwin met Medgar Evers. They began to travel together in Mississippi, investigating the murder of a Black man and visiting the sort of churches that Baldwin’s stepfather, the model for the Gabriel of <em>Go Tell It on the Mountain</em>, would have preached in.</p>
<p>When Baldwin returned to New York, where he lived in a two-room walkup on West Eighteenth Street, he became involved, with Lorraine Hansberry and others, in various protests. He also had a busy social life. His biographer David Leeming writes: “He still had the ‘poor boy’s’ fascination with the rich and famous … and they were just as fascinated by him. He found it difficult to refuse their frequent invitations. In short, the work was not getting done.”</p>
<p>In the spring of 1963, to find peace, Baldwin traveled to Turkey, which had become one of his havens.</p>
<p>In May 1963, back in the U.S., Baldwin spoke in nine cities on the West Coast over ten days, earning around five hundred dollars a speech, all of which went to <small>CORE</small>. In that month, his face appeared on the cover of the mainstream magazine <em>Time</em>. Three days later, when a friend gave a party for him at a restaurant in Haight-Ashbury, “literally hundreds of people struggled at the windows … to get a glimpse of him,” Leeming reports.</p>
<p>Two days later, Baldwin was in Connecticut, and then, on two hours’ sleep, he went to New York for a meeting with Attorney General Robert Kennedy. On May 12, Baldwin had wired Kennedy, blaming the federal government for failing to protect nonviolent protestors who had been beaten by police in Birmingham, Alabama. Now, on May 24, Baldwin and other activists, including Hansberry, Lena Horne, and Harry Belafonte, met Robert Kennedy at his home. The meeting went nowhere. Its main result was to increase the FBI’s interest in Baldwin.</p>
<p>In this same year—1963—as Baldwin made speeches, attended meetings, and stayed up late, he had many plans for work, including a book on the FBI. James Campbell writes in his biography: “Baldwin never produced his threatened work on the FBI, but he had, as usual, a multitude of other plans in mind, including the slave novel—now retitled ‘Tomorrow Brought Us Rain’—a screen treatment of <em>Another Country</em>, a musical version of <em>Othello</em>, a play called ‘The 121st Day of Sodom,’ which [Ingmar] Bergman intended to produce in Stockholm, and a text for a book of photographs by … Richard Avedon.”</p>
<p>Baldwin worked on the Avedon text after the assassination of Medgar Evers on June 12, 1963. It has all the hallmarks of his best writing: the high tone taken from the Bible, from the sermon, from Henry James, and from a set of beliefs that belonged fundamentally to Baldwin himself and gave him his signature voice: “For nothing is fixed, forever and forever, it is not fixed; the earth is always shifting, the light is always changing, the sea does not cease to grind down rock. Generations do not cease to be born, and we are responsible to them because we are the only witnesses they have.”</p>
<p>In August, Baldwin flew some members of his family to Puerto Rico to celebrate his birthday. Then he went to Paris, where he led five hundred people in a protest to the U.S. embassy, returning to the U.S. in time for the March on Washington at the end of the month. In September he went to Selma to work on voter registration. The following month he went to Canada. In December, he traveled to Africa to celebrate the independence of Kenya.</p>
<p>When Baldwin was asked how and where he had written his play <em>Blues for Mr. Charlie</em>, he replied: “On pads in planes, trains, gas stations—all sorts of places. With a pen or a pencil. … This is a <em>hand-written</em> play.” It was the only writing he completed in 1963.</p>
<p>***</p>
<p>Part of James Baldwin’s fame arose from his skill as a television performer. On camera, he used clear, well-made sentences. At times, he spoke like a trained orator, channeling his views into sharp wit, fresh insight, irony, with impressive verbal command. What he displayed was an intelligence that could quickly become grounded and combative and political once the television lights were on.</p>
<p>In some early appearances such as one on <em>The Dick Cavett Show</em> with the Yale philosopher Paul Weiss, Baldwin’s arguments were too complex for the short time he had been allotted. Because his delivery was slightly halting—he was articulate in bursts—he was too easy to interrupt, and he was always at his best when he could speak without interruption. It was as though he was sometimes too thoughtful for television.</p>
<p>This, of course, also gave him an edge. It meant that he was not mimicking politicians or TV regulars. He sought to challenge, and to set about thinking aloud. There were moments when he loved a simple question so that the answer could be ruminative and complicated. He used a context such as a talk show to state the most difficult truths in a style that belonged to the sermon or the seminar more naturally than the television studio.</p>
<p>He knew how to slow down, so that the camera lingered on his face as he prepared himself to say something difficult. He had a way, when he was about to offer an opinion that might seem extreme or unpalatable to his host or his audience, to hesitate, to let the camera see him thinking, and then to return to fluency.</p>
<p>At times, Baldwin’s manner in television interviews and in public debates could be scathing and indignant. But he could also be calm and self-possessed. In a 1963 debate in Florida, for example, even though his fellow panelists were hostile, Baldwin remained polite. He was ready to talk about the private life, the creation of the self, in a way that no one could argue with, since he himself had set the tone and the terms. He was also ready to make clear that the lives of white people, too, had been maimed by segregation. But what was most notable is how he moved his face towards the light, how he spoke with authority, and how at home he seemed to be in a television studio.</p>
<p>There were times when Baldwin appeared like a method actor playing out the part of thoughtfulness, working out as the camera rolled how a man considering things carefully might appear.</p>
<p>While he could be provocative, he was also measured. He exuded a sort of melancholy wisdom. At times, he managed to sound optimistic, especially in a panel discussion in August 1963, at the time of the March on Washington, when he was in the company of Harry Belafonte, Marlon Brando, Sidney Poitier, and Charlton Heston.</p>
<p>When Lionel Trilling wrote of the “extravagant publicness in which Mr. Baldwin lives” and wondered how Baldwin might find “the inwardness which we take to be the condition of truth in the writer,” Trilling was still in a world where it was presumed that writers should be quiet and stay home. And Trilling was not alone in believing that Baldwin was destroying his talent by going on television, writing articles, giving speeches, and being distracted by whatever was happening on the street.</p>
<p>But Baldwin belongs to a group of writers, born in the twenties and early thirties, who wrote both fiction and essays with a similar zeal and ambition; they did not see nonfiction as a lesser form or reporting as a lesser task. It was not easy to make a judgment on whether they were mainly novelists or, more likely, essayists who happened to write fiction. Also, it was often hard to make a judgment on what constituted their best work.</p>
<p>For example: Norman Mailer’s <em>The </em><em>Armies of the Night</em> and his <em>Miami and the Siege of Chicago</em>, both works of imaginative and original political reporting, may equal his best novel, <em>The Executioner’s Song</em>. So, too, V. S. Naipaul’s long essay on the dictatorship in Argentina, “The Return of Eva Perón,” and his autobiographical essay <em>Finding the Center</em> may match in power his novels <em>A House for Mr. Biswas</em> and <em>The Enigma of Arrival</em>. Joan Didion’s <em>Slouching Towards Bethlehem</em> and <em>The White Album</em> may be better than her novels <em>A Book of Common Prayer</em> and <em>Democracy</em>.</p>
<p>These writers—Baldwin, Mailer, Naipaul, Didion—traveled, took an interest in life, and accepted commissions from editors. And all four understood that if writing is a display of personality, then their literary personality was, no matter what form they used, lavish enough to blur the distinction between reportage and high literary fiction.</p>
<p>But there were also times when all four of them took on too much; their interest in a subject was sometimes not equaled by their account of it. Baldwin’s book on the child murders that occurred between 1979 and 1981 in Atlanta, <em>The </em><em>Evidence of Things Not Seen</em>, is slack and rambling; Mailer’s <em>Advertisements for Myself</em> and <em>Marilyn: A Biography</em> are not quite readable now, their egotism bloated and out of control; Naipaul’s travel books often present someone too mean and irascible, more interested in showing off his own crankiness than in exploring the world outside. And Joan Didion’s book <em>Salvador</em> might have been helped by more research.</p>
<p>What is fascinating about Baldwin’s occasional journalism and speechmaking is how uneven it is, and how rapidly this can give way to insights and sharp analysis and then a glorious, sweeping, seemingly effortless final set of statements and assertions.</p>
<p>While he worked fast on these stray pieces for magazines, Baldwin refused to settle for a simplified version of his own oppression. Instead, he combined irony and urgency in the same thought, seeking a manner that took its bearings from somewhere high above us, perhaps even from his own unique access to the word of the Lord.</p>
<p>“In a very real sense,” he wrote, “the Negro problem has become anachronistic; we ourselves are the only problem, it is our hearts only that we must search.”</p>
<p>In “As Much Truth as One Can Bear,” a <em>New York Times Book Review</em> article from January 14, 1962, when others might have been concerned about the police or about housing, Baldwin wrote about private loneliness as though it were the most pressing problem facing Americans: “The loneliness of those cities described in [the work of John] Dos Passos is greater now than it has ever been before; and these cities are more dangerous now than they were before, and their citizens are yet more unloved … The trouble is deeper than we wished to think: the trouble is in us.”</p>
<p>Sometimes, in his journalism and in his speeches, Baldwin was amusing himself. He took words such as <em>equality</em> or <em>identity</em> and concepts such as whiteness and examined them with a mixture of mischief and a sort of Swiftian contempt.</p>
<p>For example, in an address to Harlem teachers in October 1963, he sought to explode the myth of the original, heroic, white settlers in America: “What happened was that some people left Europe because they couldn’t stay there any longer and had to go some place else to make it. That’s all. They were hungry, they were poor, they were convicts. Those who were making it in England, for example, did not get on the <em>Mayflower</em>.”</p>
<p>In an essay called “The White Problem,” published in 1964, Baldwin wrote scornfully about the vast difference between the white and black American celebrities. He wrote, “Doris Day and Gary Cooper: two of the most grotesque appeals to innocence the world has ever seen. And the other, subterranean, indispensable, and denied, can be summed up, let us say, in the tone and in the face of Ray Charles. And there never has been in this country any genuine confrontation between these two levels of experience.”</p>
<p>He sought to elevate what was complex, multifarious, intricate. In 1966, he wrote: “Much of the American confusion, if not most of it, is a direct result of the American effort to avoid dealing with the Negro as a man.”</p>
<p>Since he had it in for easy and fixed categories, he was bound eventually to become eloquent about how his society dealt with the idea of men and masculinity.</p>
<p>In the early sixties, Baldwin spoke in an interview with <em>Mademoiselle</em> magazine about sexuality in his customarily challenging tone: “American males are the only people I’ve ever encountered in the world who are willing to go on the needle before they go to bed with each other.”</p>
<p>While early in his career Baldwin did not speak directly about his own sexuality, others were ready to offer hints and innuendos. A 1963 <em>Time</em> magazine profile, for example, described Baldwin as a “nervous, slight, almost fragile figure, filled with frets and fears. He is effeminate in manner, drinks considerably, smokes cigarettes in chains.”</p>
<p>When Lionel Trilling worried about Baldwin’s “extravagant publicness,” the implications of the word <em>extravagant</em> would not have been lost on many readers. And when Norman Mailer wrote of Baldwin that “even the best of his paragraphs are sprayed with perfume,” he would not have been easily misunderstood. Also, the extensive FBI file on James Baldwin includes the sentence: “It has been heard that Baldwin may be a homosexual and he appeared as if he may be one.”</p>
<p>Baldwin, in his own writings, was often careful. He liked complex connections, strange distinctions, ambiguous implications. Thus, even in a time when gay identity was becoming easier to denote or define, Baldwin resisted the very concept of gay and straight, even male and female, insisting in an essay in 1985 that “Each of us, helplessly and forever, contains the other—male in female, female in male, white in black and black in white. We are part of each other. Many of my countrymen appear to find this fact exceedingly inconvenient and even unfair, and so, very often, do I. But none of us can do anything about it.”</p>
<p>Religious elements in the civil rights movement were suspicious of both Baldwin and Bayard Rustin, a prominent organizer and activist who was close to Martin Luther King Jr. While King was not personally bothered by Rustin’s homosexuality, some of his colleagues were. One of them suggested that Baldwin and Bayard “were better qualified to lead a homosexual movement than a civil rights movement.” Baldwin’s homosexuality may have been one of the reasons why he was not invited to speak at the March on Washington in 1963.</p>
<p>But these were minor irritations compared to what happened when Baldwin’s fellow activists began to absorb fully the implications not only of<span>&nbsp;</span><em>Giovanni’s Room</em><span>&nbsp;</span>but also of<span>&nbsp;</span><em>Another Country</em>. This third novel, published in 1962, became a bestseller. Its Black hero, Rufus, in the words of the Black Panther leader Eldridge Cleaver, was depicted as, “a pathetic wretch who indulged in the white man’s pastime of committing suicide, who let a white bisexual homosexual [<em>sic</em>] fuck him in the ass, and who took a Southern Jezebel for his woman.”</p>
<p>Cleaver, in his book<span>&nbsp;</span><em>Soul on Ice</em>, published in 1968, wrote, “It seems that many Negro homosexuals … are outraged and frustrated because in their sickness they are unable to have a baby by a white man. … Homosexuality is a sickness, just as are baby-rape or wanting to become the head of General Motors.” Later, in an interview with<span>&nbsp;</span><em>The</em><span>&nbsp;</span><em>Paris Review</em><span>&nbsp;</span>in 1984, Baldwin said “My real difficulty with Cleaver, sadly, was visited on me by the kids who were following him, while he was calling me a faggot and the rest of it.”</p>
<p>It would have been easy then for Baldwin to have gone into exile, disillusioned and sad, to have written his memoirs and become nostalgic about the glory days of the civil rights movement. Indeed, he was planning to write a book about the murdered leaders Medgar Evers, Malcolm X, and Martin Luther King.</p>
<p>But this is not what happened. As the sixties went on, Baldwin became energized and excited by the Black Panthers, whose leaders he first met in San Francisco late in 1967. The three leaders—Huey Newton, Bobby Seale, and (despite their antipathies) Eldridge Cleaver—were, David Leeming writes, “as far as Baldwin was concerned, the future of the civil rights movement. … Baldwin admired the radicals; he saw them as part of the larger ‘project’ of which the old civil rights movement had been only a stage.” Baldwin wrote a preface to one of Seale’s books and supported Newton when, soon after their first meeting, he was arrested and imprisoned.</p>
<p>He also became more militant in his television interviews. For example, in an interview with Dick Cavett aired on June 16, 1969, he said: “If we were white, if we were Irish, if we were Jewish, if we were Poles, if we had in fact, in your mind, a frame of reference, our heroes would be your heroes too. Martin would be a hero for you and not be a threat, Malcolm X might still be alive. Everyone is very proud of brave little Israel, a state against which I have nothing—I don’t want to be misinterpreted, I am not an anti-Semite. But, you know, when the Israelis pick up guns, or the Poles or the Irish or any white man in the world says, ‘Give me liberty or give me death,’ the entire white world applauds. When a black man says exactly the same thing, word for word, he is judged a criminal and treated like one and everything possible is done to make an example of [him] so there won’t be any more like him.”</p>
<p>***</p>
<p>Two weeks before he died, the poet W. B. Yeats wrote a poem called “Cuchulain Comforted,” which began with a series of statements free of metaphor. The poem was written in terza rima, a form that was new for Yeats. Unusually, this poem did not need many drafts. It seems to have come to him easily, as if naturally. In earlier Yeats poems and plays, Cuchulain, a figure from Irish mythology, had appeared as the implacable, solitary, and violent hero, prepared for solo combat, free of fear. Now he has “six mortal wounds” and is attended by figures, Shrouds, who encourage him to join them in the act of sewing rather than fighting. They let him know that they themselves are not among the heroic dead but are “Convicted cowards all by kindred slain // Or driven from home and left to die in fear.”</p>
<p>Thus, at the very end of his life, Yeats created an image that seemed the very opposite of what had often given vigor to his own imagination. His heroic figure has now been gentled; his fierce and solitary warrior has joined others in the act of sewing; instead of the company of brave men, Cuchulain seems content to rest finally among cowards.</p>
<p>This poem is not a culminating statement for Yeats, but a contradictory one; it is not a crowning version of a familiar poetic form, but an experiment in a form—terza rima—associated most with Dante. Instead of attempting to sum up, it is as though Yeats wished to release fresh energy by repudiating, by beginning again, by offering his hero a set of images alien to him, which served all the more to make the hero more unsettled, more ambiguous.</p>
<p>How fascinating to see a writer abandon bold self-assertion and, however briefly, find a tone that is compassionate and genial and tender.</p>
<p>There was, however, no such moment in Baldwin. From the beginning, he displayed his own vulnerability, his own softness, sometimes as a weapon but mostly as a way of transforming an argument so that it was not a contest to be won but rather a question to be reframed—to be moved from the narrow confines of the public realm back towards the unsettled (and unbounded) space of the self, the questing, uneasy spirit.</p>

<p><em>Adapted from</em> <a href="https://brandeisuniversitypress.com/title/on-james-baldwin/">On James Baldwin</a> by Colm Tóibín, <em>now available from Brandeis University Press.</em></p>

<p><em>Colm Tóibín’s most recent book is </em>The Magician<em>. He was interviewed by Belinda McKeon in <a href="https://www.theparisreview.org/interviews/7955/the-art-of-fiction-no-256-colm-toibin" target="_blank" rel="noopener">issue no. 242</a>&nbsp;of&nbsp;</em>The Paris Review<em><i>.</i></em></p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jeremy Rowley resigns from DigiCert due to mass-revocation incident (123 pts)]]></title>
            <link>https://bugzilla.mozilla.org/show_bug.cgi?id=1910322</link>
            <guid>41177161</guid>
            <pubDate>Wed, 07 Aug 2024 00:54:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1910322">https://bugzilla.mozilla.org/show_bug.cgi?id=1910322</a>, See on <a href="https://news.ycombinator.com/item?id=41177161">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="wrapper">

 


<main id="bugzilla-body" tabindex="-1">



<div id="main-inner">













<div id="module-categories">
        <p><span id="field-value-component">
      <div>
        <p><span id="component-name" tabindex="0" role="button" aria-haspopup="menu" aria-controls="component-info">CA Certificate Compliance
          
        </span></p>
      </div>
        </span>
    </p></div>





































<meta name="firefox-versions" content="{&quot;FIREFOX_AURORA&quot;:&quot;&quot;,&quot;FIREFOX_DEVEDITION&quot;:&quot;130.0b1&quot;,&quot;FIREFOX_ESR&quot;:&quot;115.14.0esr&quot;,&quot;FIREFOX_ESR_NEXT&quot;:&quot;128.1.0esr&quot;,&quot;FIREFOX_NIGHTLY&quot;:&quot;131.0a1&quot;,&quot;LAST_MERGE_DATE&quot;:&quot;2024-08-05&quot;,&quot;LAST_RELEASE_DATE&quot;:&quot;2024-08-06&quot;,&quot;LAST_SOFTFREEZE_DATE&quot;:&quot;2024-08-01&quot;,&quot;LAST_STRINGFREEZE_DATE&quot;:&quot;2024-08-02&quot;,&quot;LATEST_FIREFOX_DEVEL_VERSION&quot;:&quot;130.0b1&quot;,&quot;LATEST_FIREFOX_OLDER_VERSION&quot;:&quot;3.6.28&quot;,&quot;LATEST_FIREFOX_RELEASED_DEVEL_VERSION&quot;:&quot;130.0b1&quot;,&quot;LATEST_FIREFOX_VERSION&quot;:&quot;129.0&quot;,&quot;NEXT_MERGE_DATE&quot;:&quot;2024-09-02&quot;,&quot;NEXT_RELEASE_DATE&quot;:&quot;2024-09-03&quot;,&quot;NEXT_SOFTFREEZE_DATE&quot;:&quot;2024-08-29&quot;,&quot;NEXT_STRINGFREEZE_DATE&quot;:&quot;2024-08-30&quot;}">



<div id="c0" data-comment-id="17044133" data-ismarkdown="true"><p>User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36</p>
<p>Steps to reproduce:</p>
<p>We received a certificate problem report that indicated DigiCert might have an issue with our implementation of method 7 – DNS-based validation. We have been investigating the issue and discovered a path that could allow mis-issuance. We are still investigating the root cause and gathering a report on the certificates impacted. We will file a full report of our findings when we have the information.</p>
<p>For background, DigiCert supports multiple DNS-related verification processes:<br>
a)	Adding a random value or request token to a TXT record,<br>
b)	Adding a random value to a CNAME pointed to by _dcv.[domain] or another subdomain starting with a prefix as agreed upon with the subscriber,<br>
c)	Adding a random value or request token to a TXT record of a domain that is followed via CNAME,<br>
d)	Adding the random value with an underscore prefix to the CNAME as the sub domain of an authorization domain name,<br>
e)	Adding the random value to a CAA record, and<br>
f)	Adding the random value to a TXT record of a subdomain that includes a prefixed underscore.</p>
<p>Spot checks performed on each of the methods above showed accurate validation information, but we initiated a thorough code review on July 27th to confirm. This review found a potential issue under (d) on our current system.</p>
<p>The code review found one path where a certificate could issue when the random value was used as the host in a CNAME resource record without first pre-appending an underscore. Our preliminary investigation shows that the code that should have appended an underscore as a prefix to a random value when using the CNAME method was not working properly. The code worked in our original monolithic system but was not implemented properly when we moved to our micro-services systems. In some cases, underscores might not have been appended to random values used for CNAME verification where the random value was used as a sub domain.</p>
<p>We also found that the bug in the code was inadvertently remediated when engineering completed a user-experience enhancement project that collapsed multiple random value generation microservices into a single service. This service began including an underscore prefix before each random value, regardless of which validation method the user chose. This project allows DigiCert to simplify the random value generation process. This also reduced customer support calls related to the manual addition of underscore prefix, fixed a bug in our certificate management platform’s display of validation status, and inadvertently ensured that every CNAME-based verification included an underscore prefix to each random value.</p>
<p>We verified that after the UX modification certificate issuance is not possible without proper CNAME verification and reviewed recent issuance to confirm that certificates are not issuing without including an underscore as part of the random value.</p>
<p>The 24-hour revocation rule applies in this circumstance as the issue impacts domain validation. We are currently investigating the root cause and gathering a list of impacted certificate serial numbers. We will post this information in the full bug report along with a complete list of impacted certificates. The revocation process will begin as soon as we’ve identified the impacted serial numbers. We do not expect to have a delayed revocation in regard to this issue.</p>
</div><div id="a68164_661011"><p>Assignee: nobody → jeremy.rowley</p><p>Status: UNCONFIRMED → ASSIGNED</p><p>Type: defect → task</p><p>Ever confirmed: true</p><p>Whiteboard: [ca-compliance]</p></div><div id="c1" data-comment-id="17048384" data-ismarkdown="true"><p>Thank you for this report, Jeremy, and for the responsiveness exhibited by DigiCert. We’ve been getting inbound requests from various sources for guidance about this incident.</p>
<p>As you know, DigiCert, as a publicly trusted CA, has to comply with the CA/Browser Forum Baseline Requirements, which are written as a collaboration between CAs and Browsers, including DigiCert.</p>
<p>The Chrome Root Program does not have the authority to grant exceptions to the CA/Browser Forum TLS Baseline Requirements. However, we do recognize other programs include exceptions for delayed revocations in some exceptional circumstances.</p>
<p>As detailed in our <a href="https://www.chromium.org/Home/chromium-security/root-ca-policy/" rel="nofollow">policy</a>, we evaluate all incidents on a case-by-case basis and work to identify ecosystem-wide risk or potential improvements that can help prevent future incidents. The Chrome Root Program continuously points to the factors significant to our program when evaluating incidents which include (but are not limited to):</p>
<ul>
<li>a demonstration of understanding of the root causes of an incident,</li>
<li>a substantive commitment and timeline to changes that clearly and persuasively address the root cause,</li>
<li>past history by the Chrome Root Program Participant in its incident handling and its follow through on commitments, and,</li>
<li>the severity of the security impact of the incident.</li>
</ul>
<p>When evaluating an incident response, the Chrome Root Program’s primary concern is ensuring that Browsers, other CA Owners, users, and website developers have the necessary information to identify improvements, and that the Chrome Root Program Participant is responsive to addressing identified issues. Outside egregious cases (e.g., abject security failures), we do not make trust decisions on individual incidents, and always consider the wider context.</p>
<p>We note the ongoing <a href="https://groups.google.com/a/mozilla.org/g/dev-security-policy/c/-WC72Oa5DTI/m/ri0OF9v7AQAJ?utm_medium=email&amp;utm_source=footer" rel="nofollow">discussions</a> in community forums that seek to minimize impact for revocation activities, and will be looking for opportunities to strike the right balance between the security of the Web PKI and ecosystem considerations.</p>
</div><div id="c2" data-comment-id="17048396" data-ismarkdown="true"><p>I will note that currently there seems to be confusion on DigiCert's internal list of impacted certificates and how they are displayed to subscribers. I have heard directly from parties of email-validated certificates being impacted, so there is a high likelihood of an overbroad initial revocation.</p>
<p>While this is preferable to a partial revocation list, it would explain the high volume of customer outreach at present. There is also an additional complication of resellers not providing the revocation information to their subscribers. Please consider this internally as you analyze the situation and prepare a report.</p>
</div><div id="c3" data-comment-id="17048468" data-ismarkdown="true"><p>We wanted to update the community on the status of this issue. A full incident report is forthcoming. We have identified 83,267 certs impacting 6,807 subscribers. We are planning to begin revoking within the 24-hour time window. Some of these customers have been able to reissue their certificates. Unfortunately, many other customers operating critical infrastructure, vital telecommunications networks, cloud services, and healthcare industries are not in a position to be revoked without critical service interruptions. While we have deployed automation with several willing customers, the reality is that many large organizations cannot reissue and deploy new certificates everywhere in time. We note that other customers have also initiated legal action against us to block revocation.</p>
<p>We have been working around the clock with customers and remain committed to adhering to the BRs. We are aware of and are participating in the active industry discussion happening about the applicability of revocation timelines given the widespread impact and the relative severity of incidents. Our response to this incident to date reflects our commitment to comply with the BRs.  We also note that browsers have mentioned that delayed revocation might still be acceptable under “exceptional circumstances.” However, given no clear definition of what would constitute an exception circumstance, we are seeking root store feedback as soon as possible, as we are standing ready to begin revocations within the timeline.</p>
</div><div id="c4" data-comment-id="17048484" data-ismarkdown="true"><p>The 24 hour timer starts when the issue is notified to the CA, or when it is identified without a third-party report. I fear that DigiCert are acting under the impression that the timer begins when the final certificate list is generated, or when subscribers are informed?</p>
<p>I will not reiterate the discussion held in <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1896053">#1896053</a>, but will note it is pertinent to this incident as well.</p>
</div><div id="c5"><p>For clarity, we expect customers will have all impacted certs remediated at 120 hours after we had serial numbers. For those ready sooner, we'll begin revocations.</p></div><div id="c6" data-comment-id="17048594" data-ismarkdown="true"><p>Can we have some more clarity on certificate count, please?<br>
"approximately 0.4% of the applicable domain validations we have in effect" - from your website and LinkedIn CEO post.</p>
<p>Can you confirm what 'applicable domain validations we have in effect' means, please?<br>
0.4% of all domain validations? 0.4% of all DNS-based? 0.4% of the specific method of DNS validations?</p>
<p>"We note that other customers have also initiated legal action against us to block revocation."<br>
Action with no legal basis, if the customers have agreed to your terms &amp; conditions and subscriber agreements, correct?<br>
How can legal action have merit when clearly stated in your legal documentation and industry guidelines?</p>
<p>If there are customers attempting to bypass these guidelines through legal means affecting all internet relying parties, they should be named.</p>
<p>"Unfortunately, many other customers operating critical infrastructure, vital telecommunications networks, cloud services, and healthcare industries are not in a position to be revoked without critical service interruptions. "<br>
Very specific details are needed. Customer names, certificate information, and explicit details as to why they cannot replace.</p>
<p>The suggestion from your own colleague:<br>
"For organizations that can’t, we would have transparent information about the existence of the issue, the nature of the problem, and the severity (feasible timeline). "<br>
"And furthermore, it would be better if these disclosures came directly from the subscribers, because they are the only ones in a position to know the ground truth.  Subscribers could be held publicly accountable for the accuracy and reasonableness of their determination and need."</p>
<p>...seems to imply this should be possible, no? Why not start now and lead by example?</p>
<p>"The 24-hour revocation rule applies in this circumstance as the issue impacts domain validation. "<br>
How are we now already talking about 120 revocation periods?</p>
</div><div id="c7"><p>Digicert, please note that if there is a delayed revocation happening to file a preliminary incident for that ASAP as the questions regarding this incident and why there’s a delay are going to be different. Also, we’re already seeing questions about the delayed revocation pop up.</p><div><p>Flags: needinfo?(jeremy.rowley)</p></div></div><div id="c8" data-comment-id="17048773" data-ismarkdown="true"><p>To answer everyone’s question:</p>
<blockquote>
<p>I will note that currently there seems to be confusion on DigiCert's internal list of impacted certificates and how they are displayed to subscribers. I have heard directly from parties of email-validated certificates being impacted, so there is a high likelihood of an overbroad initial revocation.</p>
</blockquote>
<p>The confusion is around mixed certificates where one domain was verified using a non-impacted method and another was verified using CNAME without an underscore. The data does overcount but only because some underscores were included in random values. We cannot distinguish between those that that had underscores and those that did not within the OEM system and are therefore revoking all of them.</p>
<blockquote>
<p>While this is preferable to a partial revocation list, it would explain the high volume of customer outreach at present. There is also an additional complication of resellers not providing the revocation information to their subscribers. Please consider this internally as you analyze the situation and prepare a report.</p>
</blockquote>
<p>The total number of impacted certificates is 83,267. The primary source of confusion is the 24-hour notice that was done by email. We added an in-console message to alert users about the revocation but communicating this information in a short period of time outside of email proved difficult.</p>
<blockquote>
<p>Can you confirm what 'applicable domain validations we have in effect' means, please?<br>
0.4% of all domain validations? 0.4% of all DNS-based? 0.4% of the specific method of DNS validations?</p>
</blockquote>
<p>Yes – DigiCert has one main validation system for high volume issuance (CDNs and Cloud providers specifically) and one for lower volume. The reason for the separation is the amount of control a user wants over their certificate process. 0.4% is the total over just OEM (the lower volume issuing system). We confirmed that the CNAME method in this higher volume issuance system worked correctly.</p>
<blockquote>
<p>Action with no legal basis, if the customers have agreed to your terms &amp; conditions and subscriber agreements, correct?  How can legal action have merit when clearly stated in your legal documentation and industry guidelines?</p>
</blockquote>
<p>Temporary Restraining Orders (TROs) are designed to be temporary while the facts are figured out. Courts routinely grant these to prevent material harm. TROs are legally binding. We did receive a TRO in connection with this revocation.</p>
<blockquote>
<p>If there are customers attempting to bypass these guidelines through legal means affecting all internet relying parties, they should be named.</p>
</blockquote>
<p>I will need to work my legal counsel to see if we can name them. I have no idea what’s allowed in these circumstances.</p>
<blockquote>
<p>"Unfortunately, many other customers operating critical infrastructure, vital telecommunications networks, cloud services, and healthcare industries are not in a position to be revoked without critical service interruptions. "  Very specific details are needed. Customer names, certificate information, and explicit details as to why they cannot replace.</p>
</blockquote>
<p>This will be coming in the delayed revocation bug.</p>
<blockquote>
<p>The suggestion from your own colleague:  "For organizations that can’t, we would have transparent information about the existence of the issue, the nature of the problem, and the severity (feasible timeline). "  "And furthermore, it would be better if these disclosures came directly from the subscribers, because they are the only ones in a position to know the ground truth. Subscribers could be held publicly accountable for the accuracy and reasonableness of their determination and need." ...seems to imply this should be possible, no? Why not start now and lead by example?</p>
</blockquote>
<p>Yes. I would love for them to jump in on Bugzilla. I think that information would be very beneficial to the community.</p>
<blockquote>
<p>How are we now already talking about 120 revocation periods?</p>
</blockquote>
<p>That’s long-tail in the timeframe cited in discussions when all certificates can be revoked.  We will not be granting that timeline, but we need to untangle the mass revocation process before we can revoke the certificates that are not exceptional circumstances. We will provide a burn-down on the delayed revocation bug.</p>
<blockquote>
<p>Digicert, please note that if there is a delayed revocation happening to file a preliminary incident for that ASAP as the questions regarding this incident and why there’s a delay are going to be different. Also, we’re already seeing questions about the delayed revocation pop up.</p>
</blockquote>
<p>We will be filing a preliminary delayed revocation bug today and are working on a draft.  Our systems were prepared to execute the entire revocation before 24-hour mark.</p>
</div><div id="c10" data-comment-id="17049050" data-ismarkdown="true"><p><a href="https://www.digicert.com/support/certificate-revocation-incident" rel="nofollow">DigiCert's public communication</a> about this incident (which has been quoted in <a href="https://www.bleepingcomputer.com/news/security/digicert-mass-revoking-tls-certificates-due-to-domain-validation-bug/" rel="nofollow">at least one news report</a>) gets the security impact of the noncompliance completely wrong:</p>
<blockquote>
<p>The underscore prefix ensures that the random value cannot collide with an actual domain name that uses the same random value. While the odds of that happening are practically negligible, the validation is still deemed as non-compliant if it does not include the underscore prefix.</p>
</blockquote>
<blockquote>
<p>Failing to include the underscore is considered a security risk because there is potential for a collision between an actual domain and the subdomain used for verification. Although the chance of a collision is extremely low because the random value has at least 150 bits of entropy, there is still a chance. Because there is a finite chance of collision, revocation is strictly required per CABF rules.</p>
</blockquote>
<p>The actual reason for the underscore is so that services which allow users to create DNS records at subdomains (e.g. dynamic DNS services) can block users from registering subdomains starting with an underscore and be safe from unwanted certificate issuance. It serves the same purpose that <code>/.well-known</code> does for Agreed-Upon Change To Website, and that admin/administrator/webmaster/hostmaster/postmaster do for Constructed Email to Domain Contact.  By using DNS records without underscores, DigiCert has violated a security-critical assumption that these services have made.</p>
<p><strong>Therefore, this is truly a security-critical incident</strong>, as there is a real risk (not a negligible 2^-150 risk as implied by DigiCert) that this flaw could have been exploited to get unauthorized certificates. <strong>Revocation of the improperly validated certificates is security-critical.</strong></p>
<p>It's troubling that DigiCert is no longer treating this with the urgency required by the Baseline Requirements.</p>
<p>It's also troubling that DigiCert has disseminated misinformation to the public that minimizes the security impact of the noncompliance.</p>
</div><div id="c11">

  <p>I had to split this into two parts as the size is too big for one file.</p></div><div id="c12">

  <p>I had to split this into two files</p></div><div id="c14"><p>Can we have a column with a human-readable attribute (such as the Common Name) in the CSV, so that not everyone has to open thousands of URLs by themselves on crt.sh?</p></div><div id="c15" data-comment-id="17050696" data-ismarkdown="true"><p>Has DigiCert confirmed whether this vulnerability has been exploited against major service providers that permit the creation of custom subdomains?</p>
<p>For instance, No-IP (<a href="https://www.noip.com/" rel="nofollow">https://www.noip.com</a>) allows the creation of arbitrary labels under their domains like ddns.net, enabling users to easily create subdomains such as <code>&lt;some_arbitrary_string&gt;.ddns.net</code> and map them as CNAMEs to any target.</p>
<p>In this scenario, this bug could have allowed an attacker to obtain a valid TLS certificate for <code>ddns.net</code>.</p>
</div><div id="c16" data-comment-id="17050963" data-ismarkdown="true"><p>In the provided CSV's by DigiCert there are 83_267 unique serials and 166_397 crt.sh links (137 have <code>#N/A</code> in the precert column).<br>
Please note that crt.sh is Precertificates heavy for DigiCert (see <a href="https://crt.sh/cert-populations?group=RootOwner" rel="nofollow">https://crt.sh/cert-populations?group=RootOwner</a>).<br>
I did a lookup of all serials and based on 84 batch requests to crt.sh between 2024-07-31T20:06:00Z and 2024-07-31T21:06:00Z this was the result:</p>
<table>
<thead>
<tr>
<th>Precertificate</th>
<th>Leaf certificate</th>
<th>Count</th>
<th>Percentage</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>-</td>
<td>0</td>
<td>137</td>
<td>0.16%</td>
<td>These all have <code>#N/A</code> in precert column</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>2_105</td>
<td>2.53%</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>71_732</td>
<td>86.15%</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>9_293</td>
<td>11.16%</td>
<td></td>
</tr>
</tbody>
</table>
<p>These are the match numbers based on the serial and sha256 fingerprint combination. Only 13.69% of the Leaf certificates are found, while 97.31% of Precertificates are found. Because of these numbers, it's not strange that the 137 certificates without Precertificates cannot be found.</p>
<p>All 92_423 can be found in this bzip2 compressed attachment in tab-separated values format.<br>
These are certificates for 172_047 unique domains, of which 20_702 are wildcard and 71 IP Addresses (63 IPv4 and 8 IPv6).</p>
</div><div id="c17"><div id="ct-17" data-comment-id="17051649" data-ismarkdown="true"><h2>Incident Report</h2>
<h3>Summary</h3>
<p>DigiCert verified domains using a random value in a CNAME without an underscore prefixed to the random value; the impact is limited to issuers utilizing DigiCert's OEM validation system. Validation paths through CertCentral and CIS, DigiCert’s high volume issuance engine for cloud providers, validated domains correctly and are unaffected.</p>
<h3>Impact</h3>
<p>83,267 valid certificates were issued based on this method. A list of active impacted certificates is attached as a CSV file to this bug report. We are revoking all certificates in the database listed as using CNAME-based DNS validation that are currently valid and issued before the date of the fix. This likely overcounts the number of certificates without an underscore, but the system controls in OEM did not adequately store information about whether an underscore was present.</p>
<h3>Timeline</h3>
<p>Executive Summary</p>
<p>DigiCert is continuously deploying changes to its RA system to consolidate and improve workflows. DigiCert deployed a change to its RA system to consolidate domain validation flows to reuse random values across multiple methods. This exposed the fact that one path through the system did not include the underscore when using CNAME verification. The issue was fixed with the consolidation but not found until a third party reported the issue. The root causes were siloing between engineering and compliance, a failure to take CPRs seriously if they did not include serial numbers, and a lack of engineering rigor.</p>
<p>Background</p>
<p>In 2019, DigiCert started creating a services-oriented architecture to extract all validation from the monolithic code. This plan separated the system into three components made up of different services: a front-end portal for customers (called CertCentral), two domain validation systems (CIS for high issuance and OEM for lower volume issuance), one org validation system, and a CA. CIS and OEM share some but not all services. In 2019, DNS CNAME was added to the services-oriented system. Both the monolithic system and service-oriented system ran in parallel while we measured performance and work flows to ensure 1:1 parity. The monolithic code included a function in the front-end that added an underscore if the customer requested a certificate for CNAME validation. The backend system did not check for the underscore, just the random value, and the underscore was not mandatory for any certificate issued through OEM.</p>
<p>Starting May 3, 2024, engineering initiated a project to consolidate and containerize domain validation to prepare for Multi-Perspective Validation (MPV). The goal was to execute on a directive from leadership made in January to open source our domain validation system for the community to use and deploy as needed to facilitate MPV from different global vantage points. This project also finalized the 2019 project by removing paths through our systems that are rarely used, cleaning up code, and consolidating similar processes. One of these processes consolidated the various method 7 steps to a single path. The last few months have been spent heavily on revising our validation system, which lead to confusion about what changes occurred and how the system worked.  The design goal behind these changes (per engineering) was to support a very large customer request from 2023 that wanted to pull all DNS records at each authorization domain name and check a single random value across CNAME, TXT, or CAA resource records. The following timeline discusses all relevant changes to the random value processing code and relevant to this incident.</p>
<p>All times are UTC</p>
<p>Dec 15, 2023 – Engineering architected a plan to consolidate domain methods into a streamlined process that included reusing the same random values across different methods, including non-DNS based methods as needed. This included a plan for making random value generation work uniformly regardless of method. This plan was part of a larger project and customer-requested project for a cloud provider where we wanted to be able to deploy our validation system easily to different regions. Part of this plan is to consolidate to one random value generation service that works with every validation workflow.</p>
<p>Jan 30, 2024 at 2:24 – Engineering created a plan to consolidate workflows into a single validation flow when random values are used. The project is scheduled for Q1 by leadership.</p>
<p>April 16, 2024 at 21:59 – Engineering makes a change to fix a display issue in CertCentral if a validation is originally requested using one method but later completed with another method.</p>
<p>May 1, 2024 at 21:34 – Engineering discusses how to update the DCV methods to use the same random values across domains if the domains are related. Random values being tied to specific validation types is identified as a blocker.</p>
<p>May 17, 2024 at 16:47 – Random value consolidation work starts with fixes to response codes that are causing issues in the API and UX.</p>
<p>May 18, 2024 – JIRA discussion on how to consolidate the user experience for file auth and DNS methods.</p>
<p>May 21, 2024 at 16:00 – During the weekly staff meeting, the team presents the RA consolidation architecture and plan to consolidate the random value process across methods. Compliance is not involved in the architecture design meetings.</p>
<p>May 29, 2024 at 17:00 – Sprint planning meeting to discuss operational changes required for consolidation.</p>
<p>May 29, 2024 at 23:18 – Modification of DCV checking strategy in preparation for consolidation of random value checking to a single process.</p>
<p>May 30, 2024 – Sprint where random value service change is planned begins.</p>
<p>June 4, 2024 at 16:12 – Globalsign sends a Digicert employee a personal email with a question on CNAME-based verification.</p>
<p>June 6, 2024 at 23:53 – Engineering deployed a change that consolidated random values to a single system that uses an underscore across all systems whether they require one or not. There were 7 processes that used a random value (File auth dynamic, File auth static, CNAME token, CNAME RND, TXT, DNS Token, CAA) processes subject to the plan. Although there is some overlap between CIS and OEM with these methods, each system had partially unique workflows that required consolidation. Random values are tied to the process and cannot be reused across methods. The underscore path was chosen as the consolidation because engineering understood that the random value was required in some cases but not others. There is no engineering documentation on which methods were understood as needing an underscore. Compliance was not consulted about this consolidation. After the deployment, random values can be used across different validation methods but random values without underscores cease functioning in the system. Engineering does not provide notice of change as the change is considered technical debt and non-customer impacting.</p>
<p>June 7, 2024 at 19:16 – I received the Globalsign email as the forwarding (on June 6) was missed due to multiple travel schedules. I investigated and found that certificates without an underscore could not issue. I thought the question was about documentation and requested more information from Globalsign. I spot checked random values in CIS and CC and found them included.</p>
<p>June 10, 2024 at 13:00, Globalsign confirmed that they could not issue, but that validation showed as complete.  I ask engineering to fix the UX bug associated with random values (based on the email from Globalsign). Engineering was not consulted on the Globalsign email nor brought into the investigation.  This is where a mistake was made as I should have investigated further on whether something changed.</p>
<p>June 11, 2024 at 11:24 – Engineering deployed a fix based on the UX request. Engineering also modified the random value format. These modifications were based on the Globalsign email but were not considered a compliance change. Engineering does not provide notice of change as customers are not expected to rely on the format of random values.</p>
<p>June 13, 2024 at 6:44 – Engineering merged code to remove DCV methods (ones that relied on the deprecated random value components) that were redundant and no longer necessary. Compliance was not consulted on this change. Notices are not made about the deprecation per DigiCert standard procedure (as no impact was expected).</p>
<p>June 18, 2024 – Our engineering team fixes another UX bug related to random values where the random value displayed to the customer is not the same as expected in the backend. Engineering fixes but does not provide notice of the change.</p>
<p>July 3, 2024 at 20:43 – Our support team received a certificate problem report from a researcher through <a href="mailto:revoke@digicert.com" rel="nofollow">revoke@digicert.com</a>. The researcher asked whether they needed to revoke their certificates that did not include an underscore as part of the random value. The question was not about CNAME-based verification, just random values in general.</p>
<p>July 4, 2024 at 11:24 - Our support team responded that engineering had made a UX change to show accurate random values in the console and requested serial numbers to investigate further. This support email was not escalated.</p>
<p>July 7, 2024 at 23:56 - The researcher asked for clarification on the random value change. The support team responded with information about the validation process and the underscore change that occurred on June 7.</p>
<p>July 9, 2024 at 23:41 – The researcher asked about our documentation that did not specify that an underscore was required in front of the random value. DigiCert support responded that the change was a trivial change to fix the UX to update the console. Support escalated to industry standards, who informed a browser representative about the questions and asked how to address the issue as we were unaware of an issue and could not get a serial number from the researcher. The standards team met to review the validation process and did not find an issue with respect to DNS records. The review included a demonstration of the CNAME process but showed the random value in the CNAME as retrieved from the base domain, not the authorization domain (e.g., - foo.example.com CNAME {_rnd}.dcv.digicert.com), and from an authorization domain with an underscore prefix (eg – [_rnd].domain.com CNAME dcv.digicert.com). No compliance issues were detected.</p>
<p>July 14, 2024 at 21:28 – The researcher responded to the request for serials stating that certificates on CertCentral are impacted and asked for clarification on what happened. No serial numbers are provided.</p>
<p>July 15, 2024 at 15:01 – Support again requests serial numbers and reiterates that the change was a user experience change that consolidated random values between various methods and internal workflows. </p>
<p>July 15, 2024 at 21:49 - The researcher responded asking for more information on what Digicert investigated but did not provide serial numbers.</p>
<p>July 16, 2024 at 15:40 – Support decides this is an industry standards or compliance question and escalates to me to answer.</p>
<p>July 17, 2024 at 16:33 - I ask questions about what’s going on to clarify exactly what the researcher is finding given the previous investigation and demo provided. Engineering is not consulted on the issue.</p>
<p>July 17, 2024 at 23:20 – The researcher resends a list of questions.</p>
<p>July 18, 2024 at 14:50 – Engineering deploys code to consolidate file auth and DNS methods into single process.</p>
<p>July 18, 2024 at 21:21 – I again tried to clarify the scope of issues as there’s confusion around why the researcher thinks that adding an underscore in front of all random values is a compliance issue. The CNAME aspect of the question is missed as random values are investigated across the methods.</p>
<p>July 18, 2024 at 23:16 - The researcher replied that they were upset that notice of the change was not sent to customers and that they were not getting the answers needed. Note that the researcher is correct that notice was not sent to customers. This is not an issue as notices are not typically sent for changes that are expected to have negligible impact. DigiCert’s CI/CD pipeline deploys changes daily and the review process only sends notices for material changes. The researcher claims the change was to comply with the Baseline Requirements. Spot checks were again performed on domain validation and found that the sampled certificates complied with the Baseline Requirements. Spot checks include verification of CNAME validation, TXT validation, and other types of validation that included random values as it’s still unclear whether CNAME is the issue.  The spot checks were primarily new certificates that had been issued after the consolidation change.</p>
<p>July 20, 2024 at 03:48 - I responded that the change should have been trivial as customers should not care about the contents of a random value and asked for more details. As DigiCert splits method 7 into 6 paths, there was ambiguity about which path might have an issue.</p>
<p>July 22, 2024 at 17:07– The researcher claimed a customer integration was broken (provides a link to the github pull where another third party commented on noticing the change with the addition of the underscore) because of the change made to the random value, citing a change to our onion process. This was not considered an issue because onions are not expected to have underscore characters but could have them at the start. Onions were not considered when evaluating the end-user impact of the change.</p>
<p>July 22, 2024 at 22:00 – I reply that I am unaware of an outage and ask for clarification of the outage so I can investigate. An outage was discovered with onion certs where the length of the random value changed.</p>
<p>July 24, 2024 at 22:42 – The researcher stated that they have serial numbers and this was a test to see if DigiCert would acknowledge that there was an issue with domain validation. DigiCert had not detected a mis-issuance, but we gave the other browsers notice that there was a potential issue and informed them that we were investigating. One browser rep offered to assist with understanding the ask from the researcher.</p>
<p>July 25, 2024 at 18:23 – I introduced the individual to the browser rep on the continuing email thread to help identify the issue.</p>
<p>July 26, 2024 at 09:33 - The browser rep helped establish a list of questions that narrow the scope and describe the issue.</p>
<p>July 27, 2024 at 07:36 – DigiCert began code reviews of DNS methods using random values and their paths through its validation system. This review was done on the code version that existed before the random value consolidation project. Engineering found a possible path on its service system that allowed certificates to issue without an underscore prefix using CNAME validation where the host is the random value. An underscore was required for all other subdomains (i.e., - _dcv.domain.com CNAME [rnd].dcv.digicert.com).  This issue is the method from our preliminary report.</p>
<p>July 28, 2024 at 03:56 – DigiCert engineering reported back the root cause and found that the service-oriented system had several paths through the system for random number generation. One of those (OEM) did not add the underscore. Consolidating the random value generator remediated the issue by ensuring that all paths included an underscore at the start of the random value, even if an underscore was not required.</p>
<p>July 29. 2024 at 02:17– DigiCert filed the preliminary incident report.</p>
<p>July 29, 2024 at 22:36 – DigiCert identified impacted certificates and sends notice about revocation.</p>
<p>July 30, 2024 at 2:10-12:56 – DigiCert informed the root stores on the impact of revocation. Based on the discussion, DigiCert decides these are exceptional circumstances.</p>
<p>July 30, 2024 at 19:01– The court granted the TRO prohibiting revocation. <a href="https://www.courtlistener.com/docket/68995396/alegeus-technologies-llc-v-digicert/" rel="nofollow">https://www.courtlistener.com/docket/68995396/alegeus-technologies-llc-v-digicert/</a>.</p>
<p>July 30, 2024 at 23:12 – DigiCert filed a delayed revocation bug.</p>
<h3>Root Cause Analysis</h3>
<p>In August 2019, we began modernizing our domain and organization validation systems towards a service-oriented architecture with a goal of improving performance and simplifying workflows. Legacy code in CertCentral (our TLS certificate management portal) automatically added an underscore prefix to random values if a customer selected CNAME-based verification. Our new architecture redirected all validation through separate services instead of the legacy monolithic code structure. The code adding an underscore prefix was removed from CertCentral and added to some paths in the updated system. The underscore prefix addition was not separated into a distinct service. One path through the updated system did not automatically add the underscore nor check to see if the random value had a pre-appended underscore.</p>
<p>We recently found the omission of an automatic underscore prefix was not caught during the cross-functional team reviews that occurred before deployment of the updated system. While we had regression testing in place, those tests failed to alert us to the change in functionality because the regression tests were scoped to workflows and functionality instead of the content/structure of the random value. Other paths through the system either added underscores automatically or required customers to manually add the random value before verification completed. Unfortunately, no reviews were done to compare the legacy random value implementations with the random value implementations in the new system. Had we conducted those evaluations, we would have learned earlier that the system was not automatically adding the underscore prefix to the random value.</p>
<p>On June 11, 2024, engineering completed a user-experience project that collapsed multiple random value generation microservices into a single service. This service began including an underscore prefix before each random value, regardless of which validation method the user intended to use. This project allows DigiCert to ignore the random value generation process when verifying a domain and only check whether a random value appears in an authorization domain name. This deployment also reduced customer support calls related to the manual addition of underscore characters, fixed a bug in CertCentral’s display of validation status, and inadvertently ensured that every CNAME-based verification included an underscore prefix to each random value. As before, we did not compare this UX change against the underscore flow in the legacy system.</p>
<p>Several weeks ago, a researcher contacted our problem report alias over email asking about random values used in validation. Although the reporter did not provide serial numbers for any certificates, DigiCert conducted a preliminary investigation. This initial investigation did not uncover any issues with random value generation or validation. After the reporter requested answers to their repeated questions without providing any certificate serial numbers, DigiCert sought guidance from external CABF participants, who suggested DigiCert conduct an additional review. Upon further review, DigiCert discovered an issue regarding the underscore prefix for random values. DigiCert then initiated this incident management process.</p>
<h3>Lessons Learned</h3>
<p>First, we need to have a compliance sign-off process in engineering. Engineering is expected to read and understand the standards. We also have a process for questions from engineering. However, there was not a sign-off process before RA or CA deployments, nor were compliance people included in the planning process.</p>
<p>Second, this would have been better handled if we’d moved the emails immediately from our certificate problem notification process to MDSP. The back and forth wasted valuable time and led to confusion on both the issue and process. The certificate problem reporting process is equipped to best handle reported serial numbers. Anything that is not a serial number needs to leave that queue as quickly as possible and move to MDSP.</p>
<p>Third, this incident and the last one made the fact our teams are badly siloed very apparent. Although we reorganized the compliance team to try and facilitate broader investigations, there is little communication between compliance and engineering. Had engineering sent the change to compliance for review, compliance would have known this was a critical change. Had compliance discussed the issue with engineering, the issue would have been caught in June. Compliance right now is verifying post change instead of pre-change, which is causing serious issues. Amit initiated a project to shift compliance left in the dev process during the last issue and we’ve made significant progress even though additional steps are needed. We will be adding additional remediation actions to this JIRA as we discuss internally how to ensure more technical and thorough compliance reviews that are a partnership with engineering.</p>
<h4>What went well</h4>
<p>We were ready to revoke at the 24-hour mark and could process that number of revocations in about 1.5 hours. The DigiCert team was aligned on the plan to revoke at the 24-hour mark, even if that plan was interrupted by additional information on the impact of the revocation.</p>
<p>We were able to organize on the weekend to investigate the issue.</p>
<p>We deployed code after the last bug that permitted customers to see whether they were impacted by the issue which helped with notification.</p>
<p>We notified browser representatives early.</p>
<h4>What didn't go well</h4>
<ul>
<li>
<p>We were unable to revoke all certificates within the 24-hour timeframe and unable to quickly detangle the customer list of those that had exceptional circumstances vs. those that did not.</p>
</li>
<li>
<p>We never received an actionable certificate problem report. One problematic certificate would have simplified the scope. We rely too heavily on a serial for a certificate problem report and should have treated the allegation more seriously, despite not having any evidence of an issue.</p>
</li>
<li>
<p>Getting personal emails is not a good way to kickoff an investigation. Those are easily missed and were not investigated as they did not constitute a certificate problem report.</p>
</li>
<li>
<p>We did not understand the original email about the issue and believed the issue was about the random value generator.</p>
</li>
<li>
<p>We should have moved the discussion to the public earlier.</p>
</li>
<li>
<p>The 24-hour turn-around for certificate problem reports meant our responses were less ideal and didn’t have the research necessary to accurately answer the questions.</p>
</li>
<li>
<p>Our testing needs to focus as much on compliance checks as it does on customer workflow checks.</p>
</li>
<li>
<p>Notices of system changes should always be sent out, regardless of size or complexity but especially if the changes have any relevance to baseline requirements.</p>
</li>
</ul>
<p>The ultimate root cause ended up being me. I have led the compliance team for the past several years. The fact this went unnoticed in our many reviews during that time shows that we need a different approach to both our internal investigations and compliance controls. I also dropped the ball on the certificate problem report by failing to escalate the issue to engineering and give it the proper attention it deserved. Although I did some investigation, I failed to treat the allegations with sufficient seriousness based on what could have been wrong. I assumed I knew the systems and what was happening in them rather than deeply investigating the report. Finally, I didn’t do enough to eliminate the silos between compliance and engineering. We’ve done a lot to rectify those silos, including a complete reorganization in the compliance function. Unfortunately, those changes were too late to rectify the problem.</p>
<p>I apologize to the community and our customers for the events and circumstances that led to this incident. This incident made me realize that I am no longer the person for this role. As such, after consulting with Amit (CEO), we have agreed that the path forward is for me to tender my resignation at the company. I will definitely miss the community, browsers, and public interactions as the PKI ecosystem has been my home and life for such a long time.</p>
<p>Going forward, Amit has asked Tim Hollebeek to lead a task force to implement thorough technical compliance controls (that go above and beyond pkilint) and provide oversight to our engineering team and processes to ensure strict compliance. Tim has 25+ years of computer security experience and was a security architect before joining DigiCert. He is chair of several IETF working groups, has been involved with the CA/B forum for 10 years and is a leader in our industry. I have no doubt that with Tim’s background and Amit’s oversight, he and our other compliance and engineering colleagues will do what’s needed to ensure the rigor the community and our customers expect from DigiCert.</p>
<h4>Where we got lucky</h4>
<p>We patched the system without knowing it. That patch ultimately ended up exposing the issue, which lead to a researcher reporting the problem.</p>
<p>The number of certificates was relatively small compared to the overall scope (2.8% of the non-ACME DNS-based validations through OEM).</p>
<h3>Action Items</h3>
<p>Modify the certificate problem report process to create a Bugzilla discussion for all non-compromised certificate serial numbers. The current process is to wait until an issue is confirmed. Although this will result in more “Invalid” bugs filed, the extra transparency will be valuable. – In progress</p>
<p>Consolidation of random value generators. - Done </p>
<p>Ensure all random values are prefixed with an underscore. – Done</p>
<p>Ensure compliance is part of each architecture review meeting and has the technical expertise to provide solutions. Compliance now has the ability to access architecture meetings but the technical expertise is lacking. – In Progress; eta August 15.</p>
<p>Remove the ability of Product teams to self-identify changes that require a formal compliance review. All changes in the CA and RA systems require a compliance review. Compliance team members will be included in early stakeholder reviews with the RA sprint teams and will determine changes that require formal review. – In Progress; eta August 15.</p>
<p>Add all applicable tests (not just entropy and functionality) for random value content/structure in the context of all validation flows. – In Progress; eta August 15.</p>
<p>Complete review of DCV methods with Industry Standards Development team. – In Progress; eta of August 10th</p>
<p>Eliminate all infrequently used processes and funnel all users though a single flow for each method. – In Progress, eta of Nov 1</p>
<p>Open Source DCV system for community review – In Progress; eta of December 1.</p>
</div><div><p>Flags: <span>needinfo?(jeremy.rowley)</span></p></div></div><div id="c18" data-comment-id="17051714" data-ismarkdown="true"><p>Hello,</p>
<p>This is Tim.</p>
<p>We failed to live up to your expectations. Obviously, it is going to take a bit of time for me to get up to speed, but we're going to be doing things differently going forward. We have some amazing people here at DigiCert, and they've done some amazing things, but they don't always work together internally as well as they need to. And since literally the entire planet is relying on them, that's not acceptable and is going to change.</p>
<p>Right now, we're working hard to get all of these certificates replaced as soon as possible, but as you can see from the actions above, we take this very seriously, and have already initiated a variety of efforts to make sure our critical processes are as technically excellent and correct as you deserve them to be.</p>
<p>Thank you.</p>
<p>-Tim</p>
</div><div id="c19" data-comment-id="17051920" data-ismarkdown="true"><p>Thank you for the incident report. This is quite detailed and really allows the reader to understand the full timeline and how this mistake was introduced. I have two passing thoughts here:</p>
<p>First:</p>
<blockquote>
<p>The 24-hour turn-around for certificate problem reports meant our responses were less ideal and didn’t have the research necessary to accurately answer the questions.</p>
</blockquote>
<p>From my understanding, it is acceptable to say "We're going to be doing a deep look into this, and we'll update you again in 24 hours." to get more time to do a deeper analysis. I do not think the 24 hour time for CPRs explicitly say that you have to have it full done and complete by 24 hours. Just that you have to have <em>some</em> response by 24 hours, and that response could be a good-faith representation that you're looking further into it.</p>
<p>Maybe the community can correct my understanding here.</p>
<p>Second:</p>
<p>If I'm understanding this correctly, the security impact of this incident could be quite significant if an attacker knew about this flaw. Will there be an action item to go check DCVs since this bug was introduced in production to check for anomalies of DCVs? For example looking at the logs of DNS queries where the domain being queried didn't start with an <code>_</code> and seeing if there are anomalies in any of those issuance patterns?</p>
<p>I'd be interested if the community has any thoughts on how best a search like that can be executed.</p>
</div><div id="c20" data-comment-id="17051989" data-ismarkdown="true"><p>(Speaking personally, not on behalf of my employer.)</p>
<p>Thank you for this detailed and well-written incident report. The timeline is very clear and interesting, and I think the points about siloing between various compliance-critical departments within the same organization are very valuable insights that should be taken to heart by all CAs. The remediation items listed are clear, actionable, and make sense to me.</p>
<p>I believe strongly in <a href="https://sre.google/sre-book/postmortem-culture/" rel="nofollow">blameless postmortem culture</a>. Incidents like this are not the result of individual actions, but of years of systemic failures that have allowed incorrect actions to be taken. I believe this applies at all levels, from newly-hired line engineers to CISOs. Even when leadership changes do need to occur, I believe they should not be precipitated by -- nor announced as part of -- individual incidents. Doing so harms our industry, and sends the wrong message especially to junior employees.</p>
<p>Jeremy, if this resignation is your own idea, done for your own health and well-being, then I hope you know that the rest of this community does not hold you personally responsible or blame you for this incident. We wish you the best. If this resignation is at the prompting of DigiCert leadership, then I hope they recognize that this move reflects poorly upon them.</p>
<p>Thanks again for the report, and I sincerely look forward to reviewing DigiCert's open-source DCV system!</p>
</div><div id="c21" data-comment-id="17051995" data-ismarkdown="true"><p>(In reply to Aaron Gable from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1910322#c20" title="ASSIGNED - DigiCert: Random value in CNAME without underscore prefix">comment #20</a>)</p>
<blockquote>
<p>(Speaking personally, not on behalf of my employer.)</p>
<p>Thank you for this detailed and well-written incident report. The timeline is very clear and interesting, and I think the points about siloing between various compliance-critical departments within the same organization are very valuable insights that should be taken to heart by all CAs. The remediation items listed are clear, actionable, and make sense to me.</p>
<p>I believe strongly in <a href="https://sre.google/sre-book/postmortem-culture/" rel="nofollow">blameless postmortem culture</a>. Incidents like this are not the result of individual actions, but of years of systemic failures that have allowed incorrect actions to be taken. I believe this applies at all levels, from newly-hired line engineers to CISOs. Even when leadership changes do need to occur, I believe they should not be precipitated by -- nor announced as part of -- individual incidents. Doing so harms our industry, and sends the wrong message especially to junior employees.</p>
<p>Jeremy, if this resignation is your own idea, done for your own health and well-being, then I hope you know that the rest of this community does not hold you personally responsible or blame you for this incident. We wish you the best. If this resignation is at the prompting of DigiCert leadership, then I hope they recognize that this move reflects poorly upon them.</p>
<p>Thanks again for the report, and I sincerely look forward to reviewing DigiCert's open-source DCV system!</p>
</blockquote>
<p>Thank you for saying this Aaron. I have similar feelings and didn’t really know what’s an appropriate way to put it into a comment.</p>
<p>I’d even go as far as saying I would like the CCADB incident response template specifically prohibiting these types of mentions in incident reports.</p>
<p>Personnel changes are not and have never been expected or appreciated as part of an incident response.</p>
</div><div id="c22"><p>Why? I think they are an important part of accountability. I decided to step down because of the incident. That's part of the incident report and something that should be disclosed. Knowing what changes are happening is part of transparency and ensuring accountability within the organization.</p></div><div id="c23" data-comment-id="17051998" data-ismarkdown="true"><p>(In reply to Jeremy Rowley from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1910322#c22" title="ASSIGNED - DigiCert: Random value in CNAME without underscore prefix">comment #22</a>)</p>
<blockquote>
<p>Why? I think they are an important part of accountability. I decided to step down because of the incident. That's part of the incident report and something that should be disclosed. Knowing what changes are happening is part of transparency and ensuring accountability within the organization.</p>
</blockquote>
<p>One reason: it can set inadvertently make it an expectation for other CAs to think they need to make personnel changes when an incident happens. It has a chilling effect for incident reporting even if that’s not the intention.</p>
</div><div id="c24" data-comment-id="17052062" data-ismarkdown="true"><p>(In reply to Jeremy Rowley from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1910322#c22" title="ASSIGNED - DigiCert: Random value in CNAME without underscore prefix">comment #22</a>)</p>
<blockquote>
<p>Why? I think they are an important part of accountability. I decided to step down because of the incident. That's part of the incident report and something that should be disclosed. Knowing what changes are happening is part of transparency and ensuring accountability within the organization.</p>
</blockquote>
<p>Aaron laid out the <em>why</em> in his comment:</p>
<blockquote>
<p>Incidents like this are not the result of individual actions, but of years of systemic failures that have allowed incorrect actions to be taken. I believe this applies at all levels, from newly-hired line engineers to CISOs.</p>
</blockquote>
<p>Additionally, the lesson many people learn from shouldering blame, or from seeing blame shouldered, is to hide/bury mistakes instead of learning to uncover ways to make the mistakes easier to spot, earlier, and with more thorough understanding.</p>
<p>And I'd like to echo again Aaron's statement:</p>
<blockquote>
<p>if this is your own idea, done for your own health and well-being, then I hope you know that the rest of this community does not hold you personally responsible or blame you for this incident. We wish you the best.</p>
</blockquote>
<p>Hundreds of other humans helping to run the PKI ecosystem upon which the current Web is built have a lot to learn from these reports; a lot to learn about improving the systems, policies and procedures that keep it going. We will all be digging into the technical details of the report and finding items that can help us improve - but learning to shoulder blame is not constructive in that regard.</p>
</div><div id="c25" data-comment-id="17052248" data-ismarkdown="true"><p>(In reply to Aaron Gable from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1910322#c20" title="ASSIGNED - DigiCert: Random value in CNAME without underscore prefix">comment #20</a>)</p>
<blockquote>
<p>(Speaking personally, not on behalf of my employer.)</p>
<p>Thank you for this detailed and well-written incident report. The timeline is very clear and interesting, and I think the points about siloing between various compliance-critical departments within the same organization are very valuable insights that should be taken to heart by all CAs. The remediation items listed are clear, actionable, and make sense to me.</p>
<p>I believe strongly in <a href="https://sre.google/sre-book/postmortem-culture/" rel="nofollow">blameless postmortem culture</a>. Incidents like this are not the result of individual actions, but of years of systemic failures that have allowed incorrect actions to be taken. I believe this applies at all levels, from newly-hired line engineers to CISOs. Even when leadership changes do need to occur, I believe they should not be precipitated by -- nor announced as part of -- individual incidents. Doing so harms our industry, and sends the wrong message especially to junior employees.</p>
<p>Jeremy, if this resignation is your own idea, done for your own health and well-being, then I hope you know that the rest of this community does not hold you personally responsible or blame you for this incident. We wish you the best. If this resignation is at the prompting of DigiCert leadership, then I hope they recognize that this move reflects poorly upon them.</p>
<p>Thanks again for the report, and I sincerely look forward to reviewing DigiCert's open-source DCV system!</p>
</blockquote>
<p>Aaron you took every sentiment I was going to say privately and repeated them better than I could. I don't see a single piece of this incident that is a result of an individual failing, but a lack of support in getting them help. Jeremy I know you've made comments in the past that reflect you taking issues personally, but I see that more as you caring about doing your job properly. We need more people across the industry who care, so please reconsider. I see no one externally who thinks you were at all a problem throughout this, <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1896053">or in prior incidents</a>.</p>
<p>Back to this incident: At least one organization has reached out regarding a certificate that is a single wildcard SAN that was email-verified but is in the revocation group, so I don't think the mixed-verification scenario explains the full story. Now unfortunately I can't name names, but I was being serious in prior comments. I realize the irony here when one unknown researcher was wasting everyone's time with an actual security incident and not providing serials - but that's where we are. I'd rather there be an overbroad search, but this will be why some subscribers are upset.</p>
<p>With regards to when the clock starts until we get stronger recommendations from CAB/F or Root Programs I am aiming to get CAs to be clearer on their methodology in incident reports. This makes it easier for people to review later, and reach a consensus across incidents.</p>
<p>I strongly appreciate there being an actual realistic time for revocation mentioned at 1.5h, rather than boldly claiming it can be done immediately. I am hesitant on the security of the CNAME underscore method itself, but if it is recognized in the industry then I don't see it relevant to this incident itself. I do think it is leaning too much on overlapping RFCs as a security property, but it is what it is.</p>
</div><div id="c26" data-comment-id="17052610" data-ismarkdown="true"><p>(In reply to Jeremy Rowley from <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1910322#c22" title="ASSIGNED - DigiCert: Random value in CNAME without underscore prefix">comment #22</a>)</p>
<blockquote>
<p>Why? I think they are an important part of accountability. I decided to step down because of the incident. That's part of the incident report and something that should be disclosed. Knowing what changes are happening is part of transparency and ensuring accountability within the organization.</p>
</blockquote>
<p>I wrote my thoughts about your decision to resign privately, and won’t restate them all here (roughly: oh god, what a blow to the web), but I want to respond to this point.</p>
<p>“Accountability” is not about punishment or scorekeeping or setting an example <em>pour encourager les autres</em>. It is about having appropriate attention paid to the things that caused a problem to occur, by making that reflection and transparency the responsibility of the person who was placed to observe those things and best understand how they happened. That reflection and transparency is <strong>only</strong> valuable to the extent that it changes the future handling of related situations. I know that in your place I would be watching the director’s commentary of <em>Looper</em> over and over to see if I could pull off time travel even <em>just once</em>, but alas that’s not one of the choices available. What matters now is what happens to the web, to DigiCert’s operations, and to Jeremy Rowley as a person and community member.</p>
<p>When DigiCert has another incident (and while I have tremendous faith in Tim, it will happen), I would rather that they have Jeremy Rowley with his wisdom and scar tissue around to guide their response and subsequent improvement. When another CA has a crisis related to domain validation, I want their panicked CISO to be able to reach out to Jeremy Rowley for help, and to see that these crises can be used as powerful tools for change. And, more personally, when DigiCert has rolled out its changes and demonstrated that is exactly the company that we need in such a critical role on the web, I want Jeremy Rowley to get the highest of fives at the after party. DigiCert and its customers and the web already have to pay the cost of this incident, and it would be so much better if we could also benefit maximally from what you’ve learned (so so painfully) along the way.</p>
<p>Of course, I have no right whatsoever to tell you that you can’t resign, Jeremy, or that you “shouldn’t” feel as you do. While I very much share Aaron’s love of blameless postmortem, I know that I can be caustic in these forums when I’m frustrated or disappointed; I hope that hasn’t contributed to you feeling that you should be punished or exiled. If this is your exit, please know that you will be missed.</p>
</div><div id="c27" data-comment-id="17053047" data-ismarkdown="true"><p>I have over 24 years of experience in the DNS (Domain Name System) space. I founded and developed DNS Made Easy in 2002 and have managed DNS Made Easy and Constellix since their inception. Initially, we handled DDNS (Dynamic DNS) entries for millions of hostnames before transitioning to the authoritative DNS space, focusing on the SMB and enterprise market. Over the past 24 years, I have been responsible for serving hundreds of millions of hostnames across millions of domains. For full transparency, DNS Made Easy and Constellix were acquired by DigiCert in May of 2022.</p>
<p>The current DNS-related issue centers on the ability for someone to create a CNAME (Canonical Name) record without being the domain owner. Historically, some services have allowed this due to the challenges of domain ownership at the time.</p>
<p>From a DNS perspective, it is crucial to understand that this issue arises from services that permit third parties to create hostnames within their domain names as a service or value to their customers. This is common among DDNS (dynamic DNS) providers, who typically allow users to map a name to a dynamic IP address, thus enabling the creation of A or AAAA records (IPv4 and IPv6 addresses, respectively). Most DDNS providers are not part of this conversation since they do not permit CNAME record creation by third parties.</p>
<p>However, a subset of DDNS providers do allow CNAME record creation for vanity reasons. Although the practice has diminished over the years, it still exists among a few companies. Within this group, the potential problem is further divided into those allowing CNAME records with hostnames starting with an underscore and those that do not. Providers allowing underscores inherently assume the risk of certificate creation for their root domain and are not part of this discussion. This risk can be mitigated with a properly secured domain using specific CAA (Certification Authority Authorization) records, but that is another conversation entirely.</p>
<p>Additionally, many providers do not allow the creation of CNAME records with hostnames of at least 32 characters, which further narrows the potentially affected group. After thoroughly investigating and testing notable DDNS services, it appears that No-IP allows CNAME record creation. While free accounts on their platform are limited to 19 characters, paid users can create longer CNAME records that would have allowed the 32 characters necessary for the CNAME validation.</p>
<p>Following discussions with the No-IP executive team and conducting an internal search, we were able to determine that none of these domains were affected by having a root certificate or a wildcard certificate created. Therefore, I can confidently say that none of the potentially affected domains were impacted. Based on a DNS-level understanding of this situation, no certificates were wrongfully or maliciously created.</p>
<p>Please note that all DDNS providers that allow the creation of A, AAAA, or CNAME records automatically permit certificates for individual hostnames since you can create certificates for them at any time. With any DDNS (or CNAME) provider, you have always been able to perform an "HTTP-01 challenge" to request a certificate for your individual hostname. The issue was whether you could create a certificate for other host names in the domain.</p>
<p>This overview is presented purely from a DNS perspective. I am not implying that the security policies of the appropriate agencies should not be followed. My goal is to assess the likelihood of such an occurrence and cross-reference this with known domains, finding zero collisions. From a DNS standpoint, I believe there is virtually a 0% chance that a domain certificate was wrongfully created.</p>
</div><div id="c28"><div id="ct-28" data-comment-id="17053081" data-ismarkdown="true"><p>First off, my peers at Sectigo and I want to echo others in applauding Jeremy for his contribution to this community and the WebPKI.  Thank you for being an esteemed colleague and a friend.</p>
<p>Now, on to this TRO.  I see that the TRO was filed on July 30, 2024.  As of posting time it’s August 2.  I can’t find any motion to dissolve on Pacer.</p>
<p><strong>Question 1</strong>:  Did you file a motion to dissolve?  Can you post it here?</p>
<p>The BRs require</p>
<blockquote>
<p>An acknowledgment and acceptance that the CA is entitled to revoke the certificate immediately if the Applicant were to violate the terms of the Subscriber Agreement or Terms of Use or if revocation is required by the CA’s CP, CPS, or these Baseline Requirements.</p>
</blockquote>
<p><strong>Question 2</strong>:  Can you share the specific wording in your agreement with Alegeus that meets or was intended to meet this requirement?  This may be illuminating in understanding how to protect CAs from this kind of offense in the future.</p>
</div><div><p>Flags: needinfo?(tim.hollebeek)</p></div></div><div id="c29"><div id="ct-29" data-comment-id="17053732" data-ismarkdown="true"><p>On Saturday, August 3, 2024, 20:47 UTC, DigiCert completed the revocation of the 83,267 certificates affected by this bug, without exception. This was a large, coordinated effort across many organizations to get all certificates revoked within 5 days.  We’re very thankful to everyone for working with us on such a short timescale to make sure all impacted certificates could be revoked while minimizing impact to critical infrastructure and services. Faced with incidents of similar scale, many other CAs have simply let the affected certificates expire naturally. We originally planned to revoke all of these certificates within 24 hours, but a few legal and critical infrastructure related concerns, as well as the scale of the number of organizations we were dealing with, caused us to take a few more days to get everything resolved and revoked safely. Those concerns have now all been dealt with.</p>
<p>Obviously, the best outcome would have been for the validation method to have been implemented correctly, so improving the rigor of our approval processes and continuing to tighten up our technical controls is where we will be concentrating most of our efforts going forward. It’s unfortunate that this bug was exposed as a side-effect of us simplifying and coalescing our validation systems; we intend to provide more details going forward about our new, simpler validation architecture, and we even intend to open-source it so that we can benefit from community examination of the implementations.</p>
<p>We’ve had our DNS experts looking closely at whether any certificates were improperly issued due to this bug and have found no evidence that any of these certificates were issued to anyone other than the intended recipients. We’ve examined the list of affected domains and compared them to the theoretical attacks that have been suggested and found in most cases the suggested actions cannot be carried out successfully, and there’s no evidence anyone even attempted to do so. If people have additional scenarios or evidence that needs to be investigated, we can do so.</p>
<p>Questions have also been asked about whether any S/MIME certificates are affected by this validation bug, since the S/MIME Baseline Requirements include the TLS Baseline Requirement validation methods by reference, and Mozilla Policy has long required domain validation prior to the issuance of S/MIME certificates. We have investigated and found 1,308 S/MIME certificates which were based on flawed validations using this same method, and we will be revoking those as well. A list of affected serial numbers is attached.</p>
</div><div><p>Flags: <span>needinfo?(tim.hollebeek)</span></p></div></div>







<dialog id="att-overlay" aria-labelledby="att-overlay-title" data-attachment-count="4">
  
</dialog>

</div> 
</main> 
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Medieval (785 pts)]]></title>
            <link>https://teenage.engineering/products/ep-1320</link>
            <guid>41176831</guid>
            <pubDate>Tue, 06 Aug 2024 23:57:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://teenage.engineering/products/ep-1320">https://teenage.engineering/products/ep-1320</a>, See on <a href="https://news.ycombinator.com/item?id=41176831">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[MNT Pocket Reform first impressions and hardware (129 pts)]]></title>
            <link>https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/</link>
            <guid>41176817</guid>
            <pubDate>Tue, 06 Aug 2024 23:56:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/">https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/</a>, See on <a href="https://news.ycombinator.com/item?id=41176817">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		
<p>A couple of weeks ago I received something I’ve been eagerly expecting from a <a href="https://www.crowdsupply.com/mnt/pocket-reform" data-type="link" data-id="https://www.crowdsupply.com/mnt/pocket-reform">Crowd Supply crowd funding campaign</a>.</p>



<p><a href="https://mntre.com/about.html" data-type="link" data-id="https://mntre.com/about.html">MNT</a> have been making devices that aim to be “open source, accessible and modular” for a number of years. I didn’t get their original Reform laptop, but I’ve seen those around at events like FOSDEM and I’ve been following the team’s progress with interest. When the Pocket Reform was announced I was immediately intrigued – a smaller form factor, 7 inch full Linux system with open hardware that is easily portable.</p>







<p>I went for the Hyper edition, which came with a beautiful Piñatex sleeve, SSD, and printed manual. Purple, of course, because I want to be <a href="https://joinmastodon.org/branding" data-type="link" data-id="https://joinmastodon.org/branding">on brand</a> 🤓 and, also because I love it!</p>



<p>I posted a very brief <a href="https://makertube.net/w/fmCffr2EwC3kDE9fS4RycA" data-type="link" data-id="https://makertube.net/w/fmCffr2EwC3kDE9fS4RycA">unboxing video</a>. I’ve now had a couple of weeks to occasionally tinker, and I’ve been putting off writing about it all in part because there’s a lot of things to dig into! </p>



<p>One of the things I like, surprisingly, is the chunkiness of the machine. It is really well constructed, solid, and feels great. Fits in a small cross-body bag or satchel. It’s less than half the size of a 14 inch MacBook Pro – you can more than fit two of them side by side on top of the Mac – but it is about 3 times thicker – and that’s OK, because, it is in service of making the innards very accessible and user serviceable. It comes with a complete manual and schematic, which is something I’ve not had in a computer since the 8-bit machines of my youth! The top half contains the mainboard and display (all the ports are in the top half), and the bottom contains the battery cells and mechanical keyboard. The upper panel has a copper layer and acts as a large heatsink for the processor module.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/andypiper.co.uk\/2024\/08\/06\/mnt-pocket-reform-first-impressions\/&quot;}">
<figure><img loading="lazy" decoding="async" width="400" height="533" data-attachment-id="4691" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/img_3364/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 15 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1721388805&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.2200000286119&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_3364" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?fit=400%2C533&amp;ssl=1" tabindex="0" role="button" data-id="4691" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364.jpg?resize=400%2C533&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=400%2C533&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=113%2C150&amp;ssl=1 113w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?resize=1088%2C1451&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?w=1478&amp;ssl=1 1478w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3364-rotated.jpg?w=2217&amp;ssl=1 2217w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>



<figure><img loading="lazy" decoding="async" width="400" height="300" data-attachment-id="4689" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/img_3368/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 15 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1721388929&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.2200000286119&quot;,&quot;iso&quot;:&quot;80&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_3368" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?fit=400%2C300&amp;ssl=1" tabindex="0" role="button" data-id="4689" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-400x300.jpg?resize=400%2C300&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=150%2C113&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?resize=1088%2C816&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?w=1478&amp;ssl=1 1478w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3368-rotated.jpg?w=2217&amp;ssl=1 2217w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>



<figure><img loading="lazy" decoding="async" width="400" height="533" data-attachment-id="4688" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/img_3366/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?fit=3024%2C4032&amp;ssl=1" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 15 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1721388818&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.2200000286119&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.01&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_3366" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?fit=225%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?fit=400%2C533&amp;ssl=1" tabindex="0" role="button" data-id="4688" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366.jpg?resize=400%2C533&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=400%2C533&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=113%2C150&amp;ssl=1 113w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=1152%2C1536&amp;ssl=1 1152w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=1536%2C2048&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=900%2C1200&amp;ssl=1 900w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=600%2C800&amp;ssl=1 600w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=450%2C600&amp;ssl=1 450w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=300%2C400&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=150%2C200&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=1200%2C1600&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?resize=1088%2C1451&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?w=1478&amp;ssl=1 1478w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3366-rotated.jpg?w=2217&amp;ssl=1 2217w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>



<figure><img loading="lazy" decoding="async" width="739" height="554" data-attachment-id="4690" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/img_3486/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 15 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1722516372&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.2200000286119&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.027777777777778&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_3486" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?fit=400%2C300&amp;ssl=1" tabindex="0" role="button" data-id="4690" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=739%2C554&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?w=4032&amp;ssl=1 4032w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=150%2C113&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?resize=1088%2C816&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?w=1478&amp;ssl=1 1478w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3486.jpg?w=2217&amp;ssl=1 2217w" sizes="(max-width: 739px) 100vw, 739px" data-recalc-dims="1"></figure>
</figure>



<p>The keyboard is ortholinear, which means it is a direct grid layout rather than offset row-by-row. It’s the first time I’ve used this format, which – along with the smaller keycaps – has made it a little challenging to learn, but I’m doing pretty well now. The trackball is nice and responsive. The backlit keys are easy to adjust.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/andypiper.co.uk\/2024\/08\/06\/mnt-pocket-reform-first-impressions\/&quot;}">
<figure><img loading="lazy" decoding="async" width="400" height="300" data-attachment-id="4686" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/img_3357/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 15 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1721306672&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.2200000286119&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.02&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_3357" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?fit=400%2C300&amp;ssl=1" tabindex="0" role="button" data-id="4686" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357-400x300.jpg?resize=400%2C300&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=150%2C113&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?resize=1088%2C816&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?w=1478&amp;ssl=1 1478w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3357.jpg?w=2217&amp;ssl=1 2217w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>



<figure><img loading="lazy" decoding="async" width="400" height="300" data-attachment-id="4685" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/img_3363/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?fit=4032%2C3024&amp;ssl=1" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 15 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1721332855&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;2.2200000286119&quot;,&quot;iso&quot;:&quot;1600&quot;,&quot;shutter_speed&quot;:&quot;0.026315789473684&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="IMG_3363" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?fit=400%2C300&amp;ssl=1" tabindex="0" role="button" data-id="4685" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-400x300.jpg?resize=400%2C300&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=150%2C113&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=1536%2C1152&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=2048%2C1536&amp;ssl=1 2048w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=600%2C450&amp;ssl=1 600w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?resize=1088%2C816&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?w=1478&amp;ssl=1 1478w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/IMG_3363-rotated.jpg?w=2217&amp;ssl=1 2217w" sizes="(max-width: 400px) 100vw, 400px" data-recalc-dims="1"></figure>
</figure>



<p>The screen is excellent – bright, and sharp. Actually I think the screen is probably the aspect that has impressed me most so far.</p>



<p>In terms of ports and connectivity – I’ve yet to hook up to an additional screen via the micro-HDMI connector, but I’ve used the USB-C connections (one of which is used to charge / power the machine), and the micro SD slot. The industrial iX connector for ethernet is likely a good choice for the target niche, and certainly does give more space on the motherboard than an RJ45 socket would… but I’ve yet to put my hands on a passive adapter to enable me to plug in to a wired connection, so it’s currently not as useful to me.</p>



<p>There’s a lot more to talk about, primarily (but not exclusively) on the software side, and also around hardware enablement. Out-of-the-box the Pocket Reform runs Debian unstable from MMC, with some customisations to provide a nice getting started wizard. It is important to point out that this is a machine for hackers and tinkerers – although it works very nicely, it’s not all fully baked in places – for example, the firmware for the system controller (a Raspberry Pi RP2040 chip) is being tweaked and tested, and I’ve already tested one update to that which improved the charging behaviour. </p>



<p>The other day <a href="https://andypiper.co.uk/2024/08/03/messing-with-a-messy-nvme/" data-type="post" data-id="4615">I posted about some issues with an NVMe SSD</a> – that, unfortunately, was on this machine. I actually think there was a physical hardware issue with the drive, as I’ve now replaced it with a higher-performance NVMe and things are moving along nicely (while the problematic SSD continues to report errors when accessed in an adapter over USB). I also managed to temporarily brick the machine by corrupting the uboot in flash, and needed to rig it up with Dupont wires on headers and access the machine from another via USB to get back to where I wanted to be. Very Open Source! 😎 but, I’m comfortable with this, and knew what I was purchasing. The forums and IRC have proven to be useful so far and I’m enjoying learning as well as hopefully (!?) helping the MNT team via my feedback and bug reports. I have a huge amount of respect for what they have built, their ethos, and their commitment to making this as open hardware as they can.</p>



<p>I should be receiving a modem / WWAN card for the second internal expansion slot shortly. I’ve been both learning the Sway desktop environment and also working out how best to organise my setup, so there will be more to cover in future. I particularly want to play more with the onboard I2C, and other hardware opportunities, as well – for example, potentially swapping in a Raspberry Pi CM4 if that <a href="https://mntre.com/modularity.html" data-type="link" data-id="https://mntre.com/modularity.html">becomes a modular option in the future</a>.</p>



<figure><img loading="lazy" decoding="async" width="739" height="462" data-attachment-id="4701" data-permalink="https://andypiper.co.uk/2024/08/06/mnt-pocket-reform-first-impressions/screenshot-2024-08-06-15-49-30/" data-orig-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?fit=1920%2C1200&amp;ssl=1" data-orig-size="1920,1200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2024-08-06-15-49-30" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?fit=400%2C250&amp;ssl=1" tabindex="0" role="button" src="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=739%2C462&amp;ssl=1" alt="" srcset="https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?w=1920&amp;ssl=1 1920w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=300%2C188&amp;ssl=1 300w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=400%2C250&amp;ssl=1 400w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=150%2C94&amp;ssl=1 150w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=768%2C480&amp;ssl=1 768w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=1536%2C960&amp;ssl=1 1536w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=1200%2C750&amp;ssl=1 1200w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?resize=1088%2C680&amp;ssl=1 1088w, https://i0.wp.com/andypiper.co.uk/wp-content/uploads/2024/08/screenshot-2024-08-06-15-49-30.png?w=1478&amp;ssl=1 1478w" sizes="(max-width: 739px) 100vw, 739px" data-recalc-dims="1"></figure>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How French Drains Work (355 pts)]]></title>
            <link>https://practical.engineering/blog/2024/8/6/how-french-drains-work</link>
            <guid>41176461</guid>
            <pubDate>Tue, 06 Aug 2024 23:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://practical.engineering/blog/2024/8/6/how-french-drains-work">https://practical.engineering/blog/2024/8/6/how-french-drains-work</a>, See on <a href="https://news.ycombinator.com/item?id=41176461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="item-66b23daa88ea931bc7bcff1f" data-layout-label="Post Body" data-type="item" data-updated-on="1722957457318">
  <p><em>[Note that this article is a transcript of the video embedded above.]</em></p><p>In February of 2017, one of the largest spillways in the world, the one at Oroville Dam in northern California, was severely damaged during releases from heavy rain. You might remember this. I made a video about it, and then another one about the impressive feat of rebuilding the structure. In the forensic report following the incident, one of the contributing causes identified in the failure was the drainage system below the spillway. Rather than being installed below the concrete, each drain protruded into it, reducing the thickness of the concrete and making it more prone to cracking. But why do you need drains below a spillway in the first place? Put simply: water doesn’t just flow on the surface of earth. It also flows through the soil and rock below it. Water that gets underneath a structure creates pressure that can lift and move it. That’s especially true when the water is flowing. Dam Engineers deal with the challenge in two ways: make concrete structures like spillways massive (so gravity holds them in place) and use drains to relieve that pressure, giving the water a way out.</p><p>Even though we depend on it to live, water is the enemy of all kinds of structures. Pressure is far from the only problem it causes. Most of us have come face to face with it in some way or other. Water causes some soils to expand and contract. It freezes, promotes rot, erodes, and corrodes, wreaking all kinds of havoc on the things we build. On the surface, water is relatively easy to manage through channels and curbs and slopes. Below the ground, things get much more challenging. Subsurface drainage is a really interesting challenge, and it applies to everything from simple landscaping at your house to the biggest structures on Earth, and there are a lot of things that can go wrong if they’re not designed correctly. I’m Grady, and this is Practical Engineering. Today, we’re talking about French Drains.</p><p>The idea of a subsurface drain is really pretty simple. And I built a model here in the garage to show you how they work. This is just an acrylic box with a hole at the bottom. I filled the box with sand to simulate soil. And I left a small area of gravel in front of the hole. A few strategically-placed dye tablets will help with the visualization. When I turn on the rainfall simulator, watch what happens. Water percolating into the subsurface continues flowing within the sand. It moves toward the gravel, eventually flowing into the holes between the stones and out of the model. (Don’t pay attention to those dye traces on the left. Turns out there was a small leak in the box that was acting as a… secondary outlet to my drain). When the rain is over, the subsurface water continues to flow until the soil is mostly dries out.</p><p>This is a very simple model of what’s often referred to as a French drain. It’s not from France but named after an American farmer, lawyer, politician, and inventor Henry French whose 1846 book on Farm Drainage cataloged and described many of the practices being used around the world. Funny enough, he was explicit that he didn’t invent these drains, claiming “no great praise of originality in what is here offered to the public.” Still, I have to admit, after reading his book, I understand why he became the namesake of the drains he made famous. The man had a way with words:</p><p>“The art of removing superfluous water from land must be as ancient as the art of cultivation; and from the time when Noah and his family anxiously watched the subsiding of the waters into their appropriate channels to the present, men must have felt the ill effects of too much water, and adopted means, more or less effective, to remove it.” </p><p>Well before we worried about draining subsurface water to protect buildings and structures, farmers were doing it in one way or another to keep their fields from sogginess that affects the growth of crops and bogs down agricultural equipment. In fact, “tile drain” is another common term for subsurface drains because clay tiles were used to hold the drains open. And there are plenty of fields still drained using clay tiles today. But French pointed out that rocks sometimes work just as well:</p><p>“Providence has so liberally supplied the greater part of New England with stones, that it seems to the most inexperienced person to be a work of supererogation, almost, to manufacture tiles or any other draining material for our farms.”</p><p>He was mostly right, and gravel-filled trenches are used all over the place for simple and non-critical applications. The problem with rocks is that they clog up. You can kind of see how sand migrated into the spaces between the gravel in my demo. Since it’s sand, it’s not really a problem, but if this were a finer-grained soil, it would eventually reduce the drain’s ability to transport water, slowing down the drainage process. Tiles provided the benefit of holding open a clear space for water to flow. Over time, perforated or slotted pipes began to replace tiles for use in drains. You’ve probably seen these before; there are a hundred different styles and materials. Rather than flowing in through the joints between the tiles, the water just comes into the holes in the pipe. But which way should the holes face? Turns out it’s a debate as old as pipes themselves among engineers and contractors, and there are strong opinions on both sides.</p><p>If the holes are on the top, water has to fill the gravel to the top of the pipe before it can get in and be carried away. If the holes are on the bottom, the flow path isn’t smooth, so the water flows slower and is less likely to wash away any soil or debris that gets inside. From my research, it seems like most of the manufacturers recommend holes down so the gravel envelope doesn’t have to be completely saturated before water can enter the pipe. I think, in practice, it’s really not too important, and actually, a lot of perforated pipes you can buy for drainage have holes all the way around so you don’t even have to think about it. That’s the best kind of decision, in my book. But, if it seems counterintuitive to you to orient the holes downward, I can demonstrate it in my model.</p><p>With a pipe in the middle of the gravel layer, I can turn on the rain again. Just like before, water makes its way through the soil toward the drain, and eventually out of the model. Let’s watch that sped up. When the rain is off, the soil continues draining out until it’s no longer saturated. Hopefully it’s clear how beneficial this is. Without that drain, water will eventually dry out of the soil by flowing away or evaporating over time. But getting it out quickly, with a drain, gives it less opportunity to apply pressure to basement walls, freeze against a structure creating long-term movement, swell the soils, or cause rot and corrosion. </p><p>I’m using sand in my model to speed up these simulations, so this envelope of small gravel with a pipe inside is working pretty well to keep the soil in place. But, somewhat inconveniently, most places we want to drain aren’t overlain by playground sand. They have finer-grained soils, including silt and clay. These small stones are holding back the sand, but tinier particles would just flow right through the cracks. That can lead to erosion over time as water dislodges and carries soil particles away through the drain. Watch what happens when I try my French Drain model with large stones between the sand and the outlet. You can see the turbid water coming through the drain, indicating that soil particles are making their way out. And if you watch closely on the right side, you can see where they’re coming from. Eventually, enough sand washes through the rocks to create a sinkhole, and the rest of the water bursts through. Made a HECK of a mess (pardon my French drain). I’ve talked about internal erosion and sinkholes in a previous video, so check that one out if you want more details. This erosion can also result in clogging if the soil particles move into the gravel and pipe. In fact, clogging is the biggest problem with subsurface drains, so properly designed ones usually have some kind of filter.</p><p>The design you’re probably most familiar with if you’ve seen or installed a french drain yourself uses geotextile fabric. These are permeable sheets that have a wide variety of applications: separating different layers of soil or rock, protecting against erosion, adding reinforcement to backfill, and filtering soil particles out of flowing water. A typical french drain design uses geotextile fabric around the gravel envelope to keep the fines from migrating in. It’s sometimes known as a pipe-within-a-pipe. But geotextile has some limitations. It’s easy to damage during installation. It’s pretty much impossible to repair or replace once it’s in place. And it also gets clogged up. It’s just a thin mesh of fibers, after all, so once soil particles get stuck, they can quickly lead to a decrease in permeability and efficiency. But there is another option for filtration, and it’s most commonly used on dams.</p><p>It is hard to overstate the importance of properly filtered drains for dams. If you don’t believe me, take it from the Federal Emergency Management Agency in their 360-page report, Filters for Embankment Dams: Best Practices for Design and Construction. If that’s not enough, try the Bureau of Reclamation in their 400-page report, Drainage for Dams and Associated Structures. A civil engineer could spend an entire career just thinking about subsurface drains, and for good reason. Lots of high-profile dam failures have directly resulted from a lack of drains or ones that weren’t designed well, including the Oroville Spillway incident I mentioned. For embankment dams that are built from compacted soil, any movement of those soil particles can spell demise. And if you think about all the ways that water is terrible for structures, you can imagine how hard it is to design a structure whose literal job is to hold it back. That’s why they use filters of a different design. You can see it in bold right here in this FEMA status report: “It’s the policy of the National Dam Safety Review Board that geotextiles should not be used in locations that are critical to the safety of the dam.”</p><p>Instead, they use sand. Just like the gravel in my demonstration lets the water through while holding back the sand particles, sand can hold back smaller particles of silt and clay, acting as a filter. But it’s a little more complicated than that. Every soil consists of a variety of sizes of particles. I can show that pretty easily, again using sand as an example. I have a collection of sieves with different sizes of holes, each one finer than the one above. I put my sand in at the top. Then give it a little shake (a little razzle-dazzle). And when I open it back up, the sand is all sorted out. If you weigh out the fraction that got caught in each sieve and plot that on a graph, you get something like this: a grain size distribution curve, also called the soil’s gradation. Soils can have a wide variety of gradations. And it’s super important to understand in this case, because before you can design a filter, you have to know what you’re trying to filter out. Once you know the base soil’s grain size distribution, there are a number of engineering methods to find a material that will both allow water to flow while still holding the soil back. And in a lot of cases, that just happens to end up being some variation on the sand we’re used to using in concrete and sandboxes and demonstrations about french drains.</p><p>Actually, for dams, you often can get either the filtration you need or the capacity to let water through, but not both in the same material. So lots of dams use two-stage filters. The first stage filters the base soil material. The second stage filters the first stage, but lets water flow more freely. And then, you put a perforated pipe in the middle to get the water out of the drain as quickly as possible. So they look basically identical to the demonstration I built: sand, then gravel, then pipe.</p><p>As for dealing with the water once it’s out of the ground, there are really just two options. The easiest is to simply release it by gravity to the surface at some low point. But if you don’t have a low point on the surface nearby, the other alternative is to pump it. If you have a basement at your house, there’s a good chance you have a sump, which is just a low spot for drainage to collect, and if you have a sump, it’s a REALLY GOOD idea to have a sump pump, to move that water out and somewhere outside your house.</p><p>Of course, there’s a lot more to this. Dams have all kinds of drainage features depending on their design. Concrete dams often include a gallery or tunnel with vertical drains into the foundation. Embankment dams often feature a large internal drain called a chimney filter to keep water moving through cracks or pores from carrying soil along with it. And it’s not just dams. Plenty of structures, like retaining walls, rely on good subsurface drainage for protection against all the bad things that water does, not to mention their widespread use in agriculture. There are lots of interesting designs and maybe even more proprietary products on the market all trying to accomplish those two main tasks: get the water out without getting the soil out too. In the end, it’s all the same engineering whether you’re trying to protect a multi-million dollar structure or just keep your basement dry. I think Mr. French put it best: </p><p>“Indeed, the importance of this subject of drainage, seems all at once to have found universal acknowledgement throughout our country, not only from agriculturists, but from philosophers and men of general science.”</p><p>I don’t think anyone could reasonably call me a philosopher, but I do love drains, and I hope you agree that, from dams to fields to foundations of houses, they are pretty important.</p><p>French drains are one of those topics that be hard to sell in a pitch meeting, right? No studio executive would be like, “Yes, this is a million dollar idea!” But the thing I love about this channel is that it’s created a passionate community around seemingly mundane things like subsurface drains. TV used to be like that too: something for everyone. I loved the old History and Discovery channel shows. Now it’s all converged into reality shows and reruns, and I’ve found that pretty much everything I watch these days is done by passionate independent producers. If you feel the same way, I have a recommendation for you: The Getaway by my friend Sam at Wendover Productions.</p><p>It’s a gameshow with a hilarious premise, which is that all of the contestants (who are all big YouTubers, by the way) are snitches, but each one thinks they’re the only one. And it just leads to all these very funny situations where everyone is trying to secretly sabotage the contests. Plus the behind-the-scene cuts to the producers trying to keep all the confusion under control are wonderful. It’s such a great twist on a game show, and it’s one of those creative experiments that only works because it’s independently produced. The chaos of it is what makes it great, and that’s why it’s only available on Nebula.</p><p>I talk about Nebula a lot. It’s a streaming service built by and for independent creators, and it’s growing super fast. After the major overhaul of the home page, making it easier to find new stuff to love, we’ve leaned into producing really good original content, like The Getaway; basically allowing your favorite creators to make bigger budget videos without the fear of having it flop on YouTube’s algorithm. That means you get more creative, interesting, and thoughtful videos. My videos go live on Nebula before they come out here, and right now, a subscription is 40% off at the link in the description.</p><p>Plus if you already have a subscription, now you gift one to a friend. We have annual gift cards now. Give someone you love a year’s worth of thoughtful videos, podcasts, and classes from their favorite creators. It’s 40 percent off either way at nebula.tv/practicalengineering for yourself or gift.nebula.tv/practical-engineering for a friend. Thank you for watching, and let me know what you think!</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please do not attempt to simplify this code (439 pts)]]></title>
            <link>https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/controller/volume/persistentvolume/pv_controller.go</link>
            <guid>41175586</guid>
            <pubDate>Tue, 06 Aug 2024 21:30:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/controller/volume/persistentvolume/pv_controller.go">https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/controller/volume/persistentvolume/pv_controller.go</a>, See on <a href="https://news.ycombinator.com/item?id=41175586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;packages&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;packages_link_product_navbar&quot;}" href="https://github.com/features/packages">
      
      <div>
        <p>Packages</p><p>
        Host and manage packages
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;security_link_product_navbar&quot;}" href="https://github.com/features/security">
      
      <div>
        <p>Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>

                  <li>
      
      
</li>

                  <li>
      
      <div>
                <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;white_papers_ebooks_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;white_papers_ebooks_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      White papers, Ebooks, Webinars

    
</a></li>

                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

            </ul>
          </div>
</li>


                <li>
      
      <div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

            </ul>
          </div>
          <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

            </ul>
          </div>
          
      </div>
</li>


                <li>
      
      <div>
            <ul>
                <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

            </ul>
          </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:kubernetes/kubernetes" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="W_9cKzaBVObLcYkHVY1kdRD3QgD_wUef8TmL0FqYy_xAdRqYXFUsiy7qKKOH7Eb7r1RW2bhvQDzWlnETi1vSKw" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="kubernetes/kubernetes" data-current-org="kubernetes" data-current-owner="" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>

            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&amp;source=header-repo&amp;source_repo=kubernetes%2Fkubernetes" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/kubernetes/kubernetes/blob/60c4c2b2521fb454ce69dee737e3eb91a25e0535/pkg/controller/volume/persistentvolume/pv_controller.go&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="564c48d6a3754f7a40049ef9e46bb8cca7808a986c548ee089aa5a617b2f103f" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>/blob/show;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>
        </p></div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Carvings at Gobekli Tepe may be oldest calendar (141 pts)]]></title>
            <link>https://www.tandfonline.com/doi/full/10.1080/1751696X.2024.2373876#abstract</link>
            <guid>41174979</guid>
            <pubDate>Tue, 06 Aug 2024 20:30:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tandfonline.com/doi/full/10.1080/1751696X.2024.2373876#abstract">https://www.tandfonline.com/doi/full/10.1080/1751696X.2024.2373876#abstract</a>, See on <a href="https://news.ycombinator.com/item?id=41174979">Hacker News</a></p>
Couldn't get https://www.tandfonline.com/doi/full/10.1080/1751696X.2024.2373876#abstract: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[How to let go: Jake's life ends as his daughter's begins (110 pts)]]></title>
            <link>https://jakeseliger.com/2024/08/06/how-to-let-go-one-life-ends-while-another-begins/</link>
            <guid>41174621</guid>
            <pubDate>Tue, 06 Aug 2024 19:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jakeseliger.com/2024/08/06/how-to-let-go-one-life-ends-while-another-begins/">https://jakeseliger.com/2024/08/06/how-to-let-go-one-life-ends-while-another-begins/</a>, See on <a href="https://news.ycombinator.com/item?id=41174621">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<form action="https://subscribe.wordpress.com" method="post" accept-charset="utf-8" data-blog="221111" data-post_access_level="everybody" id="subscribe-blog">
				<p>Enter your email address to subscribe to this blog and receive notifications of new posts by email.</p>
				<p id="subscribe-email">
					<label id="subscribe-field-label" for="subscribe-field">
						Email Address:					</label>

									</p>

				
			</form>
							<p>
					Join 3,726 other subscribers				</p>
						</div></div>]]></description>
        </item>
    </channel>
</rss>