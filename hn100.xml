<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 22 Aug 2024 14:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[No "Hello", No "Quick Call", and No Meetings Without an Agenda (199 pts)]]></title>
            <link>https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/</link>
            <guid>41318408</guid>
            <pubDate>Thu, 22 Aug 2024 09:46:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/">https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/</a>, See on <a href="https://news.ycombinator.com/item?id=41318408">Hacker News</a></p>
Couldn't get https://switowski.com/blog/no-hello-no-quick-call-no-agendaless-meetings/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[What is an SBAT and why does everyone suddenly care (143 pts)]]></title>
            <link>https://mjg59.dreamwidth.org/70348.html</link>
            <guid>41318222</guid>
            <pubDate>Thu, 22 Aug 2024 09:11:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mjg59.dreamwidth.org/70348.html">https://mjg59.dreamwidth.org/70348.html</a>, See on <a href="https://news.ycombinator.com/item?id=41318222">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Short version: <a href="https://github.com/rhboot/shim/blob/main/SBAT.md">Secure Boot Advanced Targeting</a> and if that's enough for you you can skip the rest you're welcome.</p><p>Long version: When UEFI Secure Boot was specified, everyone involved was, well, a touch naive. The basic security model of Secure Boot is that all the code that ends up running in a kernel-level privileged environment should be validated before execution - the firmware verifies the bootloader, the bootloader verifies the kernel, the kernel verifies any additional runtime loaded kernel code, and now we have a trusted environment to impose any other security policy we want. Obviously people might screw up, but the spec included a way to revoke any signed components that turned out not to be trustworthy: simply add the hash of the untrustworthy code to a variable, and then refuse to load anything with that hash even if it's signed with a trusted key.</p><p>Unfortunately, as it turns out, scale. Every Linux distribution that works in the Secure Boot ecosystem generates their own bootloader binaries, and each of them has a different hash. If there's a vulnerability identified in the source code for said bootloader, there's a large number of different binaries that need to be revoked. And, well, the storage available to store the variable containing all these hashes is limited. There's simply not enough space to add a new set of hashes every time it turns out that grub (a bootloader initially written for a simpler time when there was no boot security and which has several separate image parsers and also a font parser and look you know where this is going) has another mechanism for a hostile actor to cause it to execute arbitrary code, so another solution was needed.</p><p>And that solution is SBAT. The general concept behind SBAT is pretty straightforward. Every important component in the boot chain declares a security generation that's incorporated into the signed binary. When a vulnerability is identified and fixed, that generation is incremented. An update can then be pushed that defines a minimum generation - boot components will look at the next item in the chain, compare its name and generation number to the ones stored in a firmware variable, and decide whether or not to execute it based on that. Instead of having to revoke a large number of individual hashes, it becomes possible to push one update that simply says "Any version of grub with a security generation below this number is considered untrustworthy".</p><p>So why is this suddenly relevant? SBAT was developed collaboratively between the Linux community and Microsoft, and Microsoft chose to push a Windows update that told systems not to trust versions of grub with a security generation below a certain level. This was because those versions of grub had genuine security vulnerabilities that would allow an attacker to compromise the Windows secure boot chain, and we've seen real world examples of malware wanting to do that (<a href="https://media.defense.gov/2023/Jun/22/2003245723/-1/-1/0/CSI_BlackLotus_Mitigation_Guide.PDF">Black Lotus</a> did so using a vulnerability in the Windows bootloader, but a vulnerability in grub would be just as viable for this). Viewed purely from a security perspective, this was a legitimate thing to want to do.</p><p>(An aside: the "Something has gone seriously wrong" message that's associated with people having a bad time as a result of this update? That's a message from <a href="https://github.com/rhboot/shim/">shim</a>, not any Microsoft code. Shim pays attention to SBAT updates in order to avoid violating the security assumptions made by other bootloaders on the system, so even though it was Microsoft that pushed the SBAT update, it's the Linux bootloader that refuses to run old versions of grub as a result. This is absolutely working as intended)</p><p>The problem we've ended up in is that several Linux distributions had not shipped versions of grub with a newer security generation, and so those versions of grub are assumed to be insecure (it's worth noting that grub is signed by individual distributions, not Microsoft, so there's no externally introduced lag here). Microsoft's stated intention was that Windows Update would only apply the SBAT update to systems that were Windows-only, and any dual-boot setups would instead be left vulnerable to attack until the installed distro updated its grub and shipped an SBAT update itself. Unfortunately, as is now obvious, that didn't work as intended and at least some dual-boot setups applied the update and that distribution's Shim refused to boot that distribution's grub.</p><p>What's the summary? Microsoft (understandably) didn't want it to be possible to attack Windows by using a vulnerable version of grub that could be tricked into executing arbitrary code and then introduce a bootkit into the Windows kernel during boot. Microsoft did this by pushing a Windows Update that updated the SBAT variable to indicate that known-vulnerable versions of grub shouldn't be allowed to boot on those systems. The distribution-provided Shim first-stage bootloader read this variable, read the SBAT section from the installed copy of grub, realised these conflicted, and refused to boot grub with the "Something has gone seriously wrong" message. This update was not supposed to apply to dual-boot systems, but did anyway. Basically:</p><p>1) Microsoft applied an update to systems where that update shouldn't have been applied<br>2) Some Linux distros failed to update their grub code and SBAT security generation when exploitable security vulnerabilities were identified in grub</p><p>The outcome is that some people can't boot their systems. I think there's plenty of blame here. Microsoft should have done more testing to ensure that dual-boot setups could be identified accurately. But also distributions shipping signed bootloaders should make sure that they're updating those and updating the security generation to match, because otherwise they're shipping a vector that can be used to attack other operating systems and that's kind of a violation of the social contract around all of this.</p><p>It's unfortunate that the victims here are largely end users faced with a system that suddenly refuses to boot the OS they want to boot. That should never happen. I don't think asking arbitrary end users whether they want secure boot updates is likely to result in good outcomes, and while I vaguely tend towards UEFI Secure Boot not being something that benefits most end users it's also a thing you really don't want to discover you want after the fact so I have sympathy for it being default on, so I do sympathise with Microsoft's choices here, other than the failed attempt to avoid the update on dual boot systems.</p><p>Anyway. I was extremely involved in the implementation of this for Linux back in 2012 and wrote the first prototype of Shim (which is now a massively better bootloader maintained by a wider set of people and that I haven't touched in years), so if you want to blame an individual please do feel free to blame me. This is something that shouldn't have happened, and unless you're either Microsoft or a Linux distribution it's not your fault. I'm sorry.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SwiftUI for Mac 2024 (112 pts)]]></title>
            <link>https://troz.net/post/2024/swiftui-mac-2024/</link>
            <guid>41318000</guid>
            <pubDate>Thu, 22 Aug 2024 08:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://troz.net/post/2024/swiftui-mac-2024/">https://troz.net/post/2024/swiftui-mac-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=41318000">Hacker News</a></p>
Couldn't get https://troz.net/post/2024/swiftui-mac-2024/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Mourning and moving on: rituals for leaving a career (2014) (134 pts)]]></title>
            <link>https://franceshocutt.com/2014/09/10/on-mourning-and-moving-on-rituals-for-leaving-a-career/</link>
            <guid>41317280</guid>
            <pubDate>Thu, 22 Aug 2024 06:03:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://franceshocutt.com/2014/09/10/on-mourning-and-moving-on-rituals-for-leaving-a-career/">https://franceshocutt.com/2014/09/10/on-mourning-and-moving-on-rituals-for-leaving-a-career/</a>, See on <a href="https://news.ycombinator.com/item?id=41317280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><a href="http://modelviewculture.com/pieces/i-didn-t-want-to-lean-out">I decided to leave what had been a promising career in organic chemistry</a> about a year ago. Deciding to leave my program, and then to leave the field entirely, was one of the hardest decisions I have made. I had more resources than many in my position: savings and financial support, enough work experience to feel confident that I was making a realistic decision, and supportive friends and mentors. Still, that decision meant that I lost my plans, my confidence in my career trajectory, and my identity as a practicing scientist.</p>
<p>One of my biggest losses was a clear(ish) path forward. In chemistry, and particularly in academia, your mentors and your observations help you form a mental career map of sorts. Undergrad (graduation) leads to a bench job or graduate school (the latter may be much like that bench job, but with worse management and less compensation); the bench job leads to a dead end (in Big Pharma, at least), an “alternate career path”, or to graduate school. Graduate school traditionally leads to academia, industry, or work at national labs (or that “alternate career path”). Academia has the postdoc-to-postdoc-to-tenure track path; “industry” covers a lot of territory, but there is an expectation of moving either laterally or vertically within and between various companies (<a href="http://chemjobber.blogspot.com/">assuming there are jobs</a>); and similarly, there are opportunities for career progress and moving up the ladder in national labs. None of these are easy paths, of course, but I was surrounded by the institutional knowledge that they were possible.</p>
<p>When I left, I left the territory that my maps covered. That same institutional knowledge whispered that leaving a program is failing; that “alternate career paths” are well and good for those who couldn’t hack it on the “normal” paths; that a master’s degree is an admission of inferiority, not a proud acheivement. I had never judged my friends and partners who had left their own programs and changed fields, but it was somehow different when it was me.</p>
<p>Humans aren’t very good with change. We create meaning around the stress and soften transitions with rituals and rites of passage. Each of the change-points on the map I described would have been marked with a ritual: graduations, heading to happy hour after quals, the <a href="http://www.mcsweeneys.net/articles/faq-the-snake-fight-portion-of-your-thesis-defense">ritual challenge</a> of the <a href="http://xkcd.com/1403/">thesis defense</a> and the addition of “Dr.” to one’s full name, a handshake and congratulations on a raise or promotion, ordering business cards with a new title, heading to lunch with coworkers when a new coworker arrives or when one leaves for grad school, going through the arcane and labryinthine process of setting up accounts and office space at a new institution. We go through rituals to enter a program, and the process of graduate school itself is arguably a rite of passage that culminates in a final challenge, renaming, and shared food and drink. There is nothing to smooth the process of choosing to leave.</p>
<p>When I made my final decision to leave, I could feel what I was losing and that I needed to mourn. My grandmother had died at the beginning of the year, so grief, and irreversible change were already on my mind. My family grieved by coming together to share food, drink, stories, and ritual. None of those elements need to be restricted to mourning a death. I wanted the support of my community for this loss as well. </p>
<p>I invited my friends to a wake of sorts. No one ended up coming in mourning wear, but a dear friend brought me funeral lilies with a sheepish expression and that set the tone for the evening. We ate, we drank, and we chatted. Eventually I talked a bit about the choice I’d made, why I’d invited them, and my hopes for my future. My friends shared their hopes, reassurances, and anger on my behalf and their own wishes. I led a series of toasts and curses for what I’d been through and what I wished were different. I acknowledged what I had gotten from that part of my life. I cried for what I’d experienced and what I’d lost.</p>
<p>Those of us who leave the paths “everyone” knows are no less brave and resourceful than those who follow them. I’ve posted the invitation I sent out for the “wake” I held below the cut. If you think that anything I’ve shared here might help you navigate your own changes, please take whatever is helpful, change it to fit you, and pass it on. We can map and mark our new paths together.</p>
<p><span id="more-140"></span><br>
Greetings, all:</p>
<p>You are formally invited to</p>
<p>A WAKE</p>
<p>for</p>
<p>THE RESEARCH SCIENCE CAREER</p>
<p>of</p>
<p>FRANCES HOCUTT</p>
<p>FRIDAY from 7 PM to MIDNIGHT</p>
<p>I have decided to permanently leave the UW chemistry department and,<br>
most likely, the field of organic chemistry. This is a significant<br>
personal loss. I have been interested in and good at organic chemistry<br>
for the last decade and had been planning to use those skills in a<br>
research career to figure out more about the world and change it for<br>
the better with SCIENCE! I have finally decided that the culture of<br>
the field is too toxic for me to want to continue and I have chosen to<br>
leave to pursue other interests.</p>
<p>You are all invited to help me mourn this loss, to celebrate the good<br>
things I’ll be taking forward from it, and to look ahead at where I’m<br>
going next. I will provide: delicious coconut lentil curry with rice,<br>
caramel sauce and chocolate ganache to put on things, and a few<br>
beverages (alcoholic and not). Please bring some combination of: food,<br>
board games, delightful music, projects to work on, more delicious<br>
beverages, things to put caramel on, and your awesome selves. Kids are<br>
welcome but please be aware there are cats and my house is not<br>
kid-proofed. Please do not bring foods with peanuts or tree nuts in<br>
them.</p>
<p>I ask that those of you currently connected to the chemistry<br>
department keep this information private. I am still trying to work<br>
some things out with the department and would prefer to handle<br>
informing people there myself.</p>
<p>Please do RSVP so I can get a rough head-count, but feel free to show<br>
up at any time during the evening. Dressing in your personal version<br>
of mourning wear, the more over-the-top the better, is highly<br>
encouraged but not required.</p>
<p>Frances</p>

			
			
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Celebrating 6 years since Valve announced Steam Play Proton for Linux (285 pts)]]></title>
            <link>https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/</link>
            <guid>41316999</guid>
            <pubDate>Thu, 22 Aug 2024 05:05:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/">https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=41316999">Hacker News</a></p>
Couldn't get https://www.gamingonlinux.com/2024/08/celebrating-6-years-since-valve-announced-steam-play-proton-for-linux/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Designing my own watch (2020) (186 pts)]]></title>
            <link>https://willem.com/blog/2020-11-30_designing-my-own-watch/</link>
            <guid>41316598</guid>
            <pubDate>Thu, 22 Aug 2024 03:41:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://willem.com/blog/2020-11-30_designing-my-own-watch/">https://willem.com/blog/2020-11-30_designing-my-own-watch/</a>, See on <a href="https://news.ycombinator.com/item?id=41316598">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="content">
	
	<h2 itemprop="subheading">Timeless timepiece, both functional and comfortable</h2>
	
	<p>Last month a very special package arrived from Switzerland, containing my custom made wrist watch. I decided to sell all my big brand watches and have them replaced by something unique, tailored to my personal preferences. This is the story of my watch.</p>

	<a name="continue" id="continue"></a>
	<h3>Watches</h3><p>There is something magical in these miniature machines that sit on peoples' wrists: watches. They are technical marvels that often are much more than mere tools to tell time. </p><p>Some are status symbols, some are pieces of art, some are fitness tools and others are digital companions. But most of all, a watch is something truly personal: you wear it on<i> your</i> body. With smartphones and computers everywhere, nobody really needs a watch to tell time. Wearing a watch is a deliberate choice, one I like to carefully consider.</p><a name="Some of my watches over the years" title="Some of my watches over the years" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_3000px.png"><figure><img alt="Some of my watches over the years" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_500px.png" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_500px.png 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_640px.png 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_720px.png 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_750px.png 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_960px.png 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1000px.png 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1080px.png 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1125px.png 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1440px.png 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1536px.png 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_1920px.png 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_00_Some-of-my-watches-over-the-years_3000px.png 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Some of my watches over the years</figcaption></figure></a><p>Over the years I have worn many different watches and each of them has its own story and reason. Yet none of them felt like a perfect fit<i> for me</i>. </p><p>You'll be surprised how hard it is to<i> precisely</i> define what you<i> really</i> want. I took my time (pun intended) to distill a list of features that would define<i> my perfect watch</i>:</p><ul><li><b>analogue display:</b> like the natural passing of time I like the hands of a watch to sweep by as time progresses</li><li><b>simple:</b> devoid of any unnecessary distractions I like my watch to be (visually) focussed on its function</li><li><b>autonomous:</b> in line with how I value my own independence, I like my watch to be capable of running all by itself, without the need to charge or wind it manually</li><li><b>waterproof:</b> as I don't fear rain while <a href="https://willem.com/blog/bike/" title="riding my bike" target="_blank">riding my bike</a> and as I do like to swim, my watch should be capable of dealing with water, too!</li><li><b>day and night:</b> with a young kid, the distinction between night and day becomes fuzzy every now and then.., any bearing the watch can provide in total darkness is welcome!</li><li><b>timeless:</b> in a world where <a href="https://willem.com/blog/2018-01-08_lessons-from-a-takeaway-plastic-bag/" title="things become obsolete rapidly" target="_blank">things become obsolete rapidly</a>, I love to think of my watch as something more timeless, like a piece of art</li><li><b>inconspicuous:</b> I wear my watch for myself, I don't want it to attract any unnecessary attention</li><li><b>honest:</b> it should be true to the nature of the material, I don't like to hide things behind layers of superficial markup</li></ul><h3>ochs und junior</h3><p>Then I stumbled upon <a href="https://www.ochsundjunior.swiss/" title="ochs und junior" target="_blank">ochs und junior</a>, a small watch company from Switzerland. Founded in 2006 by Ludwig Oechslin, <a href="https://www.instagram.com/beatweinmann/" title="Beat Weinmann" target="_blank">Beat Weinmann</a> and Kurt König, they undertook an intense construction and design process to create their watches. While the company is in a <a href="https://www.ochsundjunior.swiss/news/" title="state of transformation" target="_blank">state of transformation</a> at the moment, they're still producing the watches that earned them their reputation.</p><a name="Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend" title="Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_3000px.jpg"><figure><img alt="Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_01_Ludwig-Oechslin-is-obsessed-with-reducing-the-number-of-parts-he-is-described-as-a-living-legend_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Ludwig Oechslin is obsessed with reducing the number of parts - he is described as a living legend</figcaption></figure></a><p>Their wrist watches use fewer parts to deliver mechanical complications, displaying other things than just the time. The watches are designed by <a href="https://en.wikipedia.org/wiki/Ludwig_Oechslin" title="Ludwig Oechslin" target="_blank">Ludwig Oechslin</a>, a renowned, recognised and awarded watchmaker, inventor and designer. He got widely known for his restoration of the astronomical clock in the Vatican Library, known as the Farnese Clock, and for the time he spent as Director of the International Museum of Horology in La Chaux-de-Fonds, Switzerland. He is obsessed with reducing the number of parts because simpler mechanics are more reliable and easier to manufacture and service.</p><p>This focus on removing unnecessary complexity is something that I totally value. It is something that I try to attain in everything I do, design and work with. Like my <a href="https://willem.com/blog/2020-03-25_designing-and-implementing-a-micro-payment-system/" title="coffee button" target="_blank">coffee button</a> or my <a href="https://willem.com/blog/2020-04-30_minimalistic-road-bike-with-gates-carbon-drive/" title="road bike" target="_blank">road bike</a>. I knew immediately that this was the company that would be able to build my watch.</p><p>After contacting the company, we had several phone calls and email exchanges to discuss my ideas. Over the years they have made some very spectacular examples, yet I wanted to stay true to my wish list. When the sky is the limit, it's hard to stay on the ground - yet that's what I tried to do when creating this  understated piece of art.</p><a name="Timeless timepiece: an annual calendar watch, custom made to my specifications" title="Timeless timepiece: an annual calendar watch, custom made to my specifications" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_3000px.jpg"><figure><img alt="Timeless timepiece: an annual calendar watch, custom made to my specifications" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_02_Timeless-timepiece-an-annual-calendar-watch-custom-made-to-my-specifications_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Timeless timepiece: an annual calendar watch, custom made to my specifications</figcaption></figure></a><p>My watch is made from titanium (which is light and durable), it's small (36MM diameter), it's waterproof (with a screw-down crown), the hands are luminous (visible in the dark), it has an automatic movement (not requiring batteries or manual winding) and its colours are true to the material (no painted surfaces).</p><p>The watch is a so-called "annual calendar", which means it can show the correct date with only one manual adjustment per year (during February). An annual calendar "knows" the difference between short and longer months. In haute horlogerie this is a higher end complication, sometimes requiring more than hundredth additional parts. Thanks to Oechslin's brilliant design, this watch only uses only 3 additional parts!</p><a name="The annual calendar complication using just 3 additional parts" title="The annual calendar complication using just 3 additional parts" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_3000px.jpg"><figure><img alt="The annual calendar complication using just 3 additional parts" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_03_The-annual-calendar-complication-using-just-3-additional-parts_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The annual calendar complication using just 3 additional parts</figcaption></figure></a><a name="How to read the time, month, date and weekday" title="How to read the time, month, date and weekday" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_3000px.jpg"><figure><img alt="How to read the time, month, date and weekday" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_04_How-to-read-the-time-month-date-and-weekday_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>How to read the time, month, date and weekday</figcaption></figure></a><p>As an hidden luxury (it is only noticeable by the wearer), the watch is made lighter by milling away any excess material. While some people prefer a certain heft to communicate (material) value, I appreciate lightweightness as it improves comfort (especially when you're active). </p><a name="Milling away material to make the watch lighter" title="Milling away material to make the watch lighter" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_3000px.jpg"><figure><img alt="Milling away material to make the watch lighter" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_05_Milling-away-material-to-make-the-watch-lighter_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Milling away material to make the watch lighter</figcaption></figure></a><a name="Before (left) and after (right) milling away material" title="Before (left) and after (right) milling away material" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_3000px.jpg"><figure><img alt="Before (left) and after (right) milling away material" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_06_Before-left-and-after-right-milling-away-material_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Before (left) and after (right) milling away material</figcaption></figure></a><p>During the design process I remained in contact with the company. Every now and then I received images from the workshop, keeping me in the loop as things progressed. </p><a name="The 3D model of my watch case" title="The 3D model of my watch case" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_3000px.jpg"><figure><img alt="The 3D model of my watch case" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_07_The-3D-model-of-my-watch-case_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The 3D model of my watch case</figcaption></figure></a><a name="The super luminova makes the watch clearly readable in darkness" title="The super luminova makes the watch clearly readable in darkness" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_3000px.jpg"><figure><img alt="The super luminova makes the watch clearly readable in darkness" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_08_The-super-luminova-makes-the-watch-clearly-readable-in-darkness_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The super luminova makes the watch clearly readable in darkness</figcaption></figure></a><a name="While the subtile contrast allows my watch to fly under the radar during the day " title="While the subtile contrast allows my watch to fly under the radar during the day " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_3000px.jpg"><figure><img alt="While the subtile contrast allows my watch to fly under the radar during the day " src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_09_While-the-subtile-contrast-allows-my-watch-to-fly-under-the-radar-during-the-day_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>While the subtile contrast allows my watch to fly under the radar during the day </figcaption></figure></a><a name="The " maestro"="" himself="" working="" on="" my="" watch="" -="" this="" feels="" like="" i="" have="" picture="" of="" rembrandt="" painting="" very="" own="" nachtwatch!="" "="" title="The " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_3000px.jpg"><figure><img alt="The " maestro"="" himself="" working="" on="" my="" watch="" -="" this="" feels="" like="" i="" have="" picture="" of="" rembrandt="" painting="" very="" own="" nachtwatch!="" "="" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_10_The-maestro-himself-working-on-my-watch-this-feels-like-I-have-picture-of-Rembrandt-painting-my-very_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The "maestro" himself working on my watch - this feels like I have picture of Rembrandt painting my very own Nachtwatch! </figcaption></figure></a><a name="Before leaving Switzerland the watch is tested and calibrated to make sure it is working well" title="Before leaving Switzerland the watch is tested and calibrated to make sure it is working well" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_3000px.jpg"><figure><img alt="Before leaving Switzerland the watch is tested and calibrated to make sure it is working well" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_11_Before-leaving-Switzerland-the-watch-is-tested-and-calibrated-to-make-sure-it-is-working-well_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Before leaving Switzerland the watch is tested and calibrated to make sure it is working well</figcaption></figure></a><h3>Delivery day!</h3><p>After waiting patiently for a few months, I received my watch per mail last month. Normally you're welcome to pick it up in person, but due to all the COVID-19 restrictions I opted for parcel delivery. If you hate paying (import) tax you might want to reconsider this... the Dutch customs' office wanted their part of my piggy bank before releasing my package for import. </p><a name="My son offered an helping hand while importing his future heirloom piece" title="My son offered an helping hand while importing his future heirloom piece" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_3000px.jpg"><figure><img alt="My son offered an helping hand while importing his future heirloom piece" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_12_My-son-offered-an-helping-hand-while-importing-his-future-heirloom-piece_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>My son offered an helping hand while importing his future heirloom piece</figcaption></figure></a><a name="It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this" title="It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_3000px.jpg"><figure><img alt="It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_13_It-s-all-about-the-product-no-money-or-energy-is-wasted-on-superflous-boxes-or-booklets-I-love-this_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>It's all about the product, no money or energy is wasted on superflous boxes or booklets - I love this</figcaption></figure></a><a name="Like a kid in the candy store - happy me!" title="Like a kid in the candy store - happy me!" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_3000px.jpg"><figure><img alt="Like a kid in the candy store - happy me!" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_14_Like-a-kid-in-the-candy-store-happy-me_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Like a kid in the candy store - happy me!</figcaption></figure></a><a name="The natural colours work well with light" title="The natural colours work well with light" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_3000px.jpg"><figure><img alt="The natural colours work well with light" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_15_The-natural-colours-work-well-with-light_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The natural colours work well with light</figcaption></figure></a><a name="The sturgeon leather strap is waterproof by nature" title="The sturgeon leather strap is waterproof by nature" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_3000px.jpg"><figure><img alt="The sturgeon leather strap is waterproof by nature" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_16_The-sturgeon-leather-strap-is-waterproof-by-nature_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The sturgeon leather strap is waterproof by nature</figcaption></figure></a><a name="The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)" title="The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_3000px.jpg"><figure><img alt="The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_17_The-case-is-milled-with-extreme-precision-making-it-unnecessary-to-hide-mistakes-by-polishing-as-the_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The case is milled with extreme precision, making it unnecessary to hide mistakes by polishing (as there aren't any!)</figcaption></figure></a><a name="The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm" title="The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_3000px.jpg"><figure><img alt="The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_18_The-curved-case-design-is-very-comfortable-on-the-wrist-as-there-are-no-sharp-edges-sticking-in-your_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The curved case design is very comfortable on the wrist, as there are no sharp edges sticking in your arm</figcaption></figure></a><a name="The dial is spectacular in an " under="" the="" radar="" way"="" -="" there="" is="" an="" incredible="" depth="" that="" hard="" to="" capture="" in="" a="" photo="" (i="" tried="" anyway!)"="" title="The dial is spectacular in an " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_3000px.jpg"><figure><img alt="The dial is spectacular in an " under="" the="" radar="" way"="" -="" there="" is="" an="" incredible="" depth="" that="" hard="" to="" capture="" in="" a="" photo="" (i="" tried="" anyway!)"="" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_19_The-dial-is-spectacular-in-an-under-the-radar-way-there-is-an-incredible-depth-that-is-hard-to-captu_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The dial is spectacular in an "under the radar way" - there is an incredible depth that is hard to capture in a photo (I tried anyway!)</figcaption></figure></a><a name="The 36MM size is perfect on my wrist" title="The 36MM size is perfect on my wrist" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_3000px.jpg"><figure><img alt="The 36MM size is perfect on my wrist" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_20_The-36MM-size-is-perfect-on-my-wrist_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The 36MM size is perfect on my wrist</figcaption></figure></a><a name="Changing the strap is easy and transforms the watch - because the watch itself is rather neutral" title="Changing the strap is easy and transforms the watch - because the watch itself is rather neutral" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_3000px.jpg"><figure><img alt="Changing the strap is easy and transforms the watch - because the watch itself is rather neutral" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_21_Changing-the-strap-is-easy-and-transforms-the-watch-because-the-watch-itself-is-rather-neutral_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Changing the strap is easy and transforms the watch - because the watch itself is rather neutral</figcaption></figure></a><a name="The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!" title="The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_3000px.jpg"><figure><img alt="The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_22_The-black-fabric-strap-features-a-Kevlar-core-making-it-extremely-durable-and-strong-perfect-when-ri_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The black fabric strap features a Kevlar core making it extremely durable and strong - perfect when riding your bike!</figcaption></figure></a><a name="The carbon buckle hardly adds any weight" title="The carbon buckle hardly adds any weight" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_3000px.jpg"><figure><img alt="The carbon buckle hardly adds any weight" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_23_The-carbon-buckle-hardly-adds-any-weight_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>The carbon buckle hardly adds any weight</figcaption></figure></a><a name="Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap" title="Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_3000px.jpg"><figure><img alt="Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_24_Different-colours-have-different-effects-on-the-watch-here-you-see-it-with-a-tan-coloured-fabric-str_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Different colours have different effects on the watch - here you see it with a 'tan'-coloured fabric strap</figcaption></figure></a><a name="In line with the " light"-case="" of="" my="" watch,="" the="" buckle="" this="" strap="" is="" milled="" to="" remove="" any="" unneeded="" weight"="" title="In line with the " href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_3000px.jpg"><figure><img alt="In line with the " light"-case="" of="" my="" watch,="" the="" buckle="" this="" strap="" is="" milled="" to="" remove="" any="" unneeded="" weight"="" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_25_In-line-with-the-LIGHT-case-of-my-watch-the-buckle-of-this-strap-is-milled-to-remove-any-unneeded-we_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>In line with the "LIGHT"-case of my watch, the buckle of this strap is milled to remove any unneeded weight</figcaption></figure></a><h3>Conclusion</h3><p>While there are many reasons to choose a watch, I wanted my watch to be perfect<i> for me</i>. In a fast moving world where things get replaced rapidly by newer fads, spending time and money on a timeless timepiece felt right.</p><p>Don't be afraid to make decisions for yourself. Wear the watch you want to wear. If it doesn't exists, don't panic. Thanks to the wonders of our connected world, you can find people that will help you!</p><a name="Wear the watch you want - if it doesn't exist you can create it!" title="Wear the watch you want - if it doesn't exist you can create it!" href="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_3000px.jpg"><figure><img alt="Wear the watch you want - if it doesn't exist you can create it!" src="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_500px.jpg" srcset="https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_500px.jpg 500w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_640px.jpg 640w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_720px.jpg 720w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_750px.jpg 750w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_960px.jpg 960w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1000px.jpg 1000w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1080px.jpg 1080w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1125px.jpg 1125w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1440px.jpg 1440w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1536px.jpg 1536w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_1920px.jpg 1920w,
		https://willem.com/blog/2020-11-30_designing-my-own-watch/images/i_26_Wear-the-watch-you-want-if-it-doesn-t-exist-you-can-create-it_3000px.jpg 3000w" sizes="(max-width: 1000px) 100vw, 960px"><figcaption>Wear the watch you want - if it doesn't exist you can create it!</figcaption></figure></a>

	

	

<div id="support">
	<h2>Did you enjoy this post?</h2>
	<p>If you found this content useful, <br>consider showing your appreciation<br>
   		by buying me a coffee ❤️😋: </p>
	

</div> 



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A 20-part deep dive into how linkers work (2008) (153 pts)]]></title>
            <link>https://lwn.net/Articles/276782/</link>
            <guid>41316342</guid>
            <pubDate>Thu, 22 Aug 2024 02:47:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/276782/">https://lwn.net/Articles/276782/</a>, See on <a href="https://news.ycombinator.com/item?id=41316342">Hacker News</a></p>
Couldn't get https://lwn.net/Articles/276782/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bum Farto (106 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Bum_Farto</link>
            <guid>41316067</guid>
            <pubDate>Thu, 22 Aug 2024 02:05:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Bum_Farto">https://en.wikipedia.org/wiki/Bum_Farto</a>, See on <a href="https://news.ycombinator.com/item?id=41316067">Hacker News</a></p>
Couldn't get https://en.wikipedia.org/wiki/Bum_Farto: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[SIMD Matters: Graph Coloring (125 pts)]]></title>
            <link>https://box2d.org/posts/2024/08/simd-matters/</link>
            <guid>41315359</guid>
            <pubDate>Wed, 21 Aug 2024 23:55:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://box2d.org/posts/2024/08/simd-matters/">https://box2d.org/posts/2024/08/simd-matters/</a>, See on <a href="https://news.ycombinator.com/item?id=41315359">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            

            

            <div>
                <h2 id="simd-in-game-development">SIMD in game development</h2>
<p>Often in game development we talk about <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a>. It is the holy grail of CPU performance, often out of reach. The conventional wisdom is that it is difficult to achieve real gains from SIMD.</p>
<p>It is tempting to build a math library around SIMD hoping to get some performance gains. However, it often has no proven benefit. It just feels good to be using something we know <em>can</em> improve performance. But sometimes SIMD can get in the way.</p>
<p>For example, game play programmers often do a lot of piecemeal vector math. They are not chopping 8 carrots at once. Instead they are trying to get a movement ability to work well on the player. Like swinging on a rope or swimming in water. These require vector math, but this code cannot be gathered into SIMD instructions in a meaningful way. We cannot force a game to have 8 players swinging on a rope at the same time.</p>
<p>Game physics is often similar. The user wants to create or destroy a single body. The ray casts are issued from the game separately and point in different directions.</p>
<p>Even if there are many similar things being computed, it can be difficult to gather these objects and push them through some algorithm simultaneously. For example, in game physics one of the most expensive computations is computing the contact forces between colliding bodies. When there are many bodies there can be a huge number of contact points.</p>
<p>This large pyramid has 5050 bodies and a whopping 14950 contact pairs, each with two contact points. Each contact point has a non-penetration force and a friction force. That is 59800 forces to be computed! Further these forces need to be computed several times per time step as part of the <em>Soft Step</em> solver. Read more <a href="https://box2d.org/posts/2024/02/solver2d/">here</a>.</p>
<p><img src="https://box2d.org/images/large_pyramid_benchmark.png" alt="Large Pyramid"><em>A pyramid of 5050 bodies</em></p>
<p>Another problem is that each constraint operates on different bodies. So even if constraints are organized contiguously in an array for faster iteration, the bodies need to be randomly accessed. This random access is the ultimately the bottleneck in game physics.</p>
<h2 id="graph-coloring">Graph coloring</h2>
<p>For Box2D version 3.0 I decided to finally try using SIMD as it is <strong>meant to be used</strong> for solving contacts. Making contacts solve faster could yield large performance gains so I decided it would be worth the effort.</p>
<p>But how can I gather 4 or 8 contact pairs to be solved simultaneously? The key is <a href="https://en.wikipedia.org/wiki/Graph_coloring">graph coloring</a>. The idea is to have a handful of colors to be assigned to all the contact constraints. For example, suppose I have 6 colors and I want to assign all the contacts to one of those 6 colors. Contact constraints act upon two bodies at a time. With graph coloring the restriction is that within a single color a body can only appear once or not at all.</p>
<p>This small pyramid shows an example of graph coloring. Each contact constraint has two contact points with the same color. There are four colors: red, orange, yellow, and green. If you look at a color, such as orange, you can see that it only touches a box once per contact point pair. This is the magic of graph coloring and enables me to solve multiple contact constraints simultaneously without a <a href="https://en.wikipedia.org/wiki/Race_condition">race condition</a>.</p>
<p><img src="https://box2d.org/images/graph_color_small.png" alt="Graph Coloring"><em>Graph coloring of a small pyramid</em></p>
<p>Graph coloring can scale to very large scenarios. The image below shows the graph coloring of the contact points on the large pyramid. You can see in the text the number of contact constraints per color.</p>
<ul>
<li>color 1 : 2524</li>
<li>color 2 : 2508</li>
<li>color 3 : 2465</li>
<li>color 4 : 2376</li>
<li>color 5 : 2286</li>
<li>color 6 : 2107</li>
<li>color 7 : 652</li>
<li>color 8 : 32</li>
</ul>
<p><img src="https://box2d.org/images/graph_color.png" alt="Large Pyramid Graph Coloring"><em>Graph coloring of the large pyramid</em></p>
<p>These colors group together constraints that can be solved simultaneously using SIMD. For example, color 1 has 2524 contact constraints. Each of these constraints is between two bodies. The graph coloring ensures that none of the same bodies appear more than once in all 2524 contact constraints. This means all 2524 constraints can be solved simultaneously.</p>
<p>But isn’t graph coloring very complex and slow? Contacts come and go all the time in rigid body simulation. Do I need to recompute the graph colors every time a contact is added or removed?</p>
<p>First of all, there is a lot of intimidating <a href="https://en.wikipedia.org/wiki/Four_color_theorem">theory</a> around graph coloring and it seems at first that some complex algorithms must be applied to do graph color properly. This is not true at all! A simple <a href="https://en.wikipedia.org/wiki/Greedy_algorithm">greedy algorithm</a> is sufficient for game physics.</p>
<p>Box2D maintains a <a href="https://en.wikipedia.org/wiki/Bit_array">bitsets</a> for each graph color. Each bit corresponds to a body index. When a contact constraint is created, the graph color bitsets are examined. The constraint is assigned to the first color with a bitset that doesn’t have either body bit set to 1. Once the constraint is assigned to a color, those two body bits are set to 1. This is a very fast operation.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>b2AddContactToGraph</span>(b2ConstraintGraph<span>*</span> graph, b2Contact<span>*</span> contact)
</span></span><span><span>{
</span></span><span><span>    <span>int</span> indexA <span>=</span> contact<span>-&gt;</span>bodyIndexA;
</span></span><span><span>    <span>int</span> indexB <span>=</span> contact<span>-&gt;</span>bodyIndexB;
</span></span><span><span>
</span></span><span><span>    <span>for</span> (<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> graph<span>-&gt;</span>colorCount; <span>++</span>i)
</span></span><span><span>    {
</span></span><span><span>        b2GraphColor<span>*</span> color <span>=</span> graph<span>-&gt;</span>color <span>+</span> i;
</span></span><span><span>        <span>if</span> (<span>b2GetBit</span>(color<span>-&gt;</span>bodySet, indexA))
</span></span><span><span>        {
</span></span><span><span>            <span>// advance to next color
</span></span></span><span><span><span></span>            <span>continue</span>;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>if</span> (<span>b2GetBit</span>(color<span>-&gt;</span>bodySet, indexB))
</span></span><span><span>        {
</span></span><span><span>            <span>// advance to next color
</span></span></span><span><span><span></span>            <span>continue</span>;
</span></span><span><span>        }
</span></span><span><span>
</span></span><span><span>        <span>// available color found!
</span></span></span><span><span><span></span>        <span>b2SetBit</span>(color<span>-&gt;</span>bodySet, indexA);
</span></span><span><span>        <span>b2SetBit</span>(color<span>-&gt;</span>bodySet, indexB);
</span></span><span><span>
</span></span><span><span>        contact<span>-&gt;</span>colorIndex <span>=</span> i;
</span></span><span><span>    }
</span></span><span><span>}
</span></span></code></pre></div><p>Even though bitsets are fast, it would be better not to redo the graph coloring every time step. So Box2D persists the graph coloring across time steps. When a contact constraint is created the color is determined and the body bits are turned on. When a constraint is removed the corresponding two body bits are cleared.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>void</span> <span>b2RemoveContactFromGraph</span>(b2ConstraintGraph<span>*</span> graph, b2Contact<span>*</span> contact)
</span></span><span><span>{
</span></span><span><span>    <span>int</span> indexA <span>=</span> contact<span>-&gt;</span>bodyIndexA;
</span></span><span><span>    <span>int</span> indexB <span>=</span> contact<span>-&gt;</span>bodyIndexB;
</span></span><span><span>
</span></span><span><span>    b2GraphColor<span>*</span> color <span>=</span> graph<span>-&gt;</span>color <span>+</span> contact<span>-&gt;</span>colorIndex;
</span></span><span><span>    <span>b2ClearBit</span>(color<span>-&gt;</span>bodySet, contact<span>-&gt;</span>bodyIndexA);
</span></span><span><span>    <span>b2ClearBit</span>(color<span>-&gt;</span>bodySet, contact<span>-&gt;</span>bodyIndexB);
</span></span><span><span>    contact<span>-&gt;</span>colorIndex <span>=</span> B2_NULL_INDEX;
</span></span><span><span>}
</span></span></code></pre></div><p>There are a couple more details. When bodies go to sleep they are removed from the graph coloring and when they wake they are added back according to the constraints that connect them. Also static bodies are never set in the bitsets because static bodies are not modified by the contact solver. This reduces the number of colors needed.</p>
<h2 id="going-wide">Going WIDE</h2>
<p>So now that I have 2524 contact constraints I can solve simultaneously, how do I do that? Well there are no SIMD units that are 2524 floats wide. So I break these into 4 or 8 constraint blocks (SSE2/Neon or AVX2). These <em>wide</em> constraints can be solved like a single scalar constraint. The math looks almost identical.</p>
<p>There is some delicate plumbing needed to make this happen. In particular, I need to gather 4 or 8 pairs of bodies for each wide constraint. I gather the body velocities and put them in <em>wide</em> floats (4 or 8 floats).</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>// wide float
</span></span></span><span><span><span></span><span>typedef</span> b2FloatW <span>__m128</span>;
</span></span><span><span>
</span></span><span><span><span>// wide vector
</span></span></span><span><span><span></span><span>struct</span> b2Vec2W
</span></span><span><span>{
</span></span><span><span>    b2FloatW X;
</span></span><span><span>    b2FloatW Y;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>// wide body
</span></span></span><span><span><span></span><span>struct</span> b2BodyW
</span></span><span><span>{
</span></span><span><span>    b2Vec2W linearVelocity;
</span></span><span><span>    b2FloatW angularVelocity;
</span></span><span><span>};
</span></span></code></pre></div><p>I grab 4 or 8 bodies and stuff their velocities into a single <em>wide</em> body. Then the wide constraint operates on wide bodies and all the math looks similar to scalar math. For example, the wide dot product is just two multiplications and one addition, doing 4 or 8 dot products simultaneously.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>// wide dot product
</span></span></span><span><span><span></span>b2FloatW <span>b2DotW</span>(b2Vec2W a, b2Vec2W b)
</span></span><span><span>{
</span></span><span><span>    <span>return</span> <span>b2AddW</span>(<span>b2MulW</span>(a.X, b.X), <span>b2MulW</span>(a.Y, b.Y));
</span></span><span><span>}
</span></span></code></pre></div><p>This is the way SIMD is <strong>meant to be used</strong>. But there is sure a lot of setup work to make this possible!</p>
<p>After the wide constraint is solved, the wide body velocities are <em>scattered</em> to the individual scalar bodies. These <a href="https://en.wikipedia.org/wiki/Gather/scatter_(vector_addressing)">gather/scatter</a> operations are needed to make this all work. Each instruction set SSE2/Neon/AVX2 has custom instructions that help with this. None of it is super intuitive but it is well documented not too difficult to setup.</p>
<h2 id="does-it-matter">Does it matter?</h2>
<p>I did all this work to enable SIMD processing. Did it help? Box2D has a benchmarking console application to help answer this question. I implemented SSE2, Neon, and AVX SIMD instruction sets in the Box2D contact solver. I also implemented a <strong>scalar</strong> reference implementation. I have 5 benchmarks scenarios that push Box2D in various ways. See the benchmark results <a href="https://box2d.org/files/benchmark_results.html">here</a>.</p>
<p>I ran these benchmarks on an AMD 7950X (AVX2, SSE2, scalar) and an Apple M2 (Neon).</p>
<p><img src="https://box2d.org/images/large_pyramid_results.png" alt="Large Pyramid Results"><em>Large pyramid benchmark results</em></p>
<p>The joint grid benchmark doesn’t use SIMD instructions at all, so you can ignore that one. But the other ones all stress the contact solver.</p>
<p>The large pyramid benchmark with 4 workers has the following numbers:</p>
<ul>
<li>AVX2 : 1117 fps = 0.90 ms</li>
<li>Neon : 1058 fps = 0.95 ms</li>
<li>SSE2 : 982 fps = 1.02 ms</li>
<li>scalar (AMD): 524 fps = 1.91 ms</li>
<li>scalar (M2): 679 fps = 1.47 ms</li>
</ul>
<p>From this I draw the following conclusions:</p>
<ol>
<li>SSE2 is about 2x faster than scalar</li>
<li>AVX2 is about 14% faster than SSE2</li>
<li>The Apple M2 smokes!</li>
</ol>
<p>Another consideration is that all collision is done with scalar math. So more gains could be made if I figure out how to use SIMD for collision as well.</p>
<p>The bottom line is that making good use of SIMD can be a lot of work but it is worth the effort because it can make games run significantly faster and handle more rigid bodies.</p>
<h2 id="what-about-compiler-vectorization">What about compiler vectorization?</h2>
<p>An interesting side result from this experiment relates to compiler vectorization. In my scalar reference implementation I defined the wide float as a structure of 4 floats.</p>
<div><pre tabindex="0"><code data-lang="c"><span><span><span>// wide float for reference scalar implementation
</span></span></span><span><span><span></span><span>struct</span> b2FloatW { <span>float</span> x, y, z, w };
</span></span></code></pre></div><p>I also implemented all the wide math functions to work with this. It seems that I have arranged all the data perfectly for the compiler to use <a href="https://en.wikipedia.org/wiki/Automatic_vectorization">automatic vectorization</a>. But it seems this doesn’t really happen to a sufficient degree to compete with my hand written SSE2. This is a bit ironic because on x64 all math <strong>is</strong> SIMD math, it is just inefficient SIMD math.</p>
<h2 id="references">References</h2>
<p><a href="https://www.bepuentertainment.com/">Bepu Physics</a> uses graph coloring and SIMD. While I had known about this technique for some time, the high performance of Bepu has inspired me.</p>
<p><a href="http://web.eecs.umich.edu/~msmelyan/papers/physsim_onmanycore_itj.pdf">High-Performance Physical Simulations on Next-Generation Architecture with Many Cores</a>. This is the earliest reference I know of that suggests using graph coloring to speed up rigid body physics calculations.</p>
<p>Graph coloring is used in many areas of simulation. For example, it is very useful for <a href="https://gamma.cs.unc.edu/CDCD/main.pdf">cloth simulation</a>. The nice thing about cloth simulation is that typically the graph coloring can be pre-computed.</p>
<h2 id="update">Update</h2>
<ul>
<li>added milliseconds to comparison</li>
<li>added M2 scalar results</li>
</ul>

            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I'm Tired of Fixing Customers' AI Generated Code (367 pts)]]></title>
            <link>https://medium.com/@thetateman/im-tired-of-fixing-customers-ai-generated-code-94816bde4ceb</link>
            <guid>41315138</guid>
            <pubDate>Wed, 21 Aug 2024 23:16:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://medium.com/@thetateman/im-tired-of-fixing-customers-ai-generated-code-94816bde4ceb">https://medium.com/@thetateman/im-tired-of-fixing-customers-ai-generated-code-94816bde4ceb</a>, See on <a href="https://news.ycombinator.com/item?id=41315138">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://medium.com/@thetateman?source=post_page-----94816bde4ceb--------------------------------"><div aria-hidden="false"><p><img alt="Tate Smith" src="https://miro.medium.com/v2/resize:fill:88:88/1*i8DvUi3xBFiTI_jQDk3MYg.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="30f3">(Not an anti-AI post — Copilot is great, I use it all the time.)</p><p id="cc58">Early this year I built some cryptocurrency trading and data gathering tools for personal use and to get more experience in Rust programming. While asking questions in various groupchats, it didn’t take too long to see that lots of other people were demanding similar tools — and would be willing to pay for them. Pretty soon after that realization, I had some API endpoints set up where people could access the data for free and submit trades for a small commission.</p><p id="3136">I started getting a few customers, a very cool experience since this was the first time people were paying for software I built myself! I started a Telegram channel for feature announcements and support, which worked well at first. But, as my customer base slowly grew, support began taking up more and more of my time. I know this is the case for any SAAS startup, so the increasing support burden was hardly a surprise, and, after all, more customers is a good problem to have! What became irritating was not the quantity, but the quality of the support requests I was receiving.</p><p id="ad0b">My API is just a few well documented endpoints. If you can figure out how to send a POST request using any programming language, you should have no problem using it. But that seems to be too high a bar for the new generation of prompt-engineer coders. Since opening my support channel, I have fielded many a “Help! My trading bot is not working!!” support request. More often than not, I will be sent customer code that is mostly fine, but has some error that should be glaringly obvious to anyone who has read the documentation and has some programming ability. Often this takes the form of trying to access an endpoint that does not exist, or read a property off the API response that does not exist. After probing a bit more, my suspicions are usually confirmed — ChatGPT hallucinated that endpoint or property, and the customer I’m talking to has little to no programming knowledge. If they are just trying to build a simple script I’ll help them out, and fix the hallucinations — it’s not much effort and creates a potentially paying customer. Often, though, the customer is envisioning a more complex application, and I just have to tell them, “Sorry, you’re going to have to hire a professional developer for this.” The worst is when a request starts out simple — I help them fix one hallucination — but then that customer wants to build more complex logic, and somehow I’ve set the expectation that I will provide unlimited free support forever. I’ve gotten a number of angry messages from customers who essentially want me to build their whole app for free.</p><p id="2841">I’m sure these challenges sound familiar to anyone who has run support for a SAAS business, but AI programming tools have exacerbated the problem. Helping a customer solve challenges is often super rewarding, but only when I can remove roadblocks for customers who can do most of the work themselves. When customers offload software engineering to AI because they don’t have the capability themselves, they still need to find a developer to fix the bugs that AI creates. I don’t want to be that developer!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euphemisms are best changed frequently (2016) (111 pts)]]></title>
            <link>https://aeon.co/essays/euphemisms-are-like-underwear-best-changed-frequently</link>
            <guid>41315126</guid>
            <pubDate>Wed, 21 Aug 2024 23:14:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aeon.co/essays/euphemisms-are-like-underwear-best-changed-frequently">https://aeon.co/essays/euphemisms-are-like-underwear-best-changed-frequently</a>, See on <a href="https://news.ycombinator.com/item?id=41315126">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>What we would today call <em>cash assistance for the differently abled</em> could in a different era permissibly have been called <em>welfare for cripples</em>. The terms <em>welfare</em> and <em>crippled</em> sound somewhere between loaded and abusive today, and yet once were considered civil by educated, sensitive people. There actually was an organisation called the International Society for the Welfare of Cripples established in 1922.</p>
<p>However, in 1960 it was retitled the International Society for the Rehabilitation of the Disabled. As appropriate as that seems from our vantage point, it demonstrated a general tendency towards which we often roll our eyes. ‘Okay, what are we supposed to call it now?’ we sometimes think, as terms considered proper for a group or phenomenon seem to change every generation or so. The implication is that we find this rolling terminology a bit much – why can’t the names of things just stay put? On <em>disabled</em>, for example, what was wrong with <em>handicapped</em>, and why must we now move on to <em>differently abled</em>? Isn’t all of this kind of like Puff Daddy to P Diddy?</p>
<p>No, actually. What the cognitive psychologist and linguist Steven Pinker has artfully termed ‘the euphemism treadmill’ is not a tic or a stunt. It is an inevitable and, more to the point, healthy process, necessary in view of the eternal gulf between language and opinion. We think of euphemisms as one-time events, where one prissily coins a way of saying something that detracts from something unpleasant about it. That serves perfectly well as a definition of what euphemism is, but misses the point that euphemism tends to require regular renewal. This is because thought changes more slowly than we can change the words for it, and has a way of catching up with our new coinages. Since that is likely eternal, we must accept that we’ll change our terms just like we change our underwear, as a part of linguistic life in a civilised society.</p>
<p><span>T</span>he reason for this rolling semantic renewal is that the meanings of words are, in actual usage, messier than their dictionary definitions, cast in the tidy eternity of print, might make them seem. We store words in our brains amid webs of association, with experiences, impressions and other words. As a result, a word is always redolent of various associations, metaphorical extensions, beyond its core meaning.</p>
<p>For example, <em>generous</em> once meant noble, with no connection to sharing. It’s what William Shakespeare meant when he used the term. So when Edmund in <em>King Lear</em> defends himself against dismissal as low-born by insisting that</p>
<blockquote>… my dimensions are as well compact,<br>My mind as generous, and my shape as true,<br>As honest madam’s issue</blockquote>
<p>it can throw us a bit, making us wonder how a mind can be generous, and we find it a bit curious that someone would defend himself against a charge of bastardy by pointing out his magnanimity. However, in earlier societies, the noble person was often responsible for a degree of charity to the ordinary population, such that magnanimity was a trait associated with nobility. Over time, especially as formal nobility itself had ever less importance (think of the fate of the Crawleys in <em>Downton Abbey</em>), the meaning of <em>magnanimity</em> changed from a resonance of <em>generous</em> to the meaning it has today.</p>
<p>A word, then, is like a bell tone, with a central pitch seasoned by overtones. As the tone fades away, the overtones can hang in the air. Words are similar, with opinion, assumption and, more to the point, bias as equivalents to the overtones. <em>Crippled</em> began as a sympathetic term. However, a sad reality of human society is that there are negative associations and even dismissal harboured against those with disabilities. Thus <em>crippled</em> became accreted with those overtones, so to speak, to the point that <em>handicapped</em> was fashioned as a replacement term free from such baggage.</p>
<p>what a warm, charitable word <em>welfare</em> is at its core, and how much static and bile we must peel away to hear it that way again</p>
<p>However, because humans stayed human, it was impossible that <em>handicapped</em> would not, over time, become accreted with similar gunk. Enter <em>disabled</em>, which is now long-lived enough that many process it, too, as harbouring shades of abuse, which conditions a replacement such as <em>differently abled</em>. Notably, the International Society for the Rehabilitation of the Disabled later changed its name again to Rehabilitation, International; today, the organisation prefers to be known simply as ‘RI’, bypassing the inconvenience of actual words altogether. The story has been similar for <em>retarded</em> being replaced by <em>cognitively impaired</em>; for <em>welfare</em>, which today is more often referred to as <em>cash assistance</em>; or by the faceless initials of programmes disbursing it, such as TANF (Temporary Assistance for Needy Families).</p>
<p>Opinion can permeate a euphemism to such an extent that it becomes difficult to conceive of how it once sounded. <em>Welfare</em> was a replacement for what was once commonly referred to as <em>home relief</em>. The empathy in that term was soon blunted by associations with the people granted relief, such that older generations will recall <em>home relief</em> practically uttered as a negative epithet by the 1950s and ’60s. Meanwhile, reflect on what a warm, charitable word <em>welfare</em> is at its core, and how much static and bile we must peel away to hear it that way again. Similar is <em>affirmative action</em>: a term that 50 years ago resounded with a clean, stalwart clang of high-minded social justice now sounds freighted, sour, vague and tired to many on both sides of the political spectrum. <em>Racial preferences</em> was an attempt at a replacement – and note its similar fate.</p>
<p>As a lad decades ago, I worked briefly in the production of a magazine about <em>family planning</em>. Unfamiliar with the terminology, I spent months in this job before fully understanding that <em>family planning</em> referred to contraception, not just people musing over when they ‘planned’ to have children. Why the obliqueness? Because <em>family planning</em> was a replacement euphemism for <em>birth control</em>, coined in 1914 by the US contraception activist Margaret Sanger. Note that <em>birth control</em> was in itself as elliptical and abstract a terminology as <em>family planning.</em> Yet today, <em>birth control</em> summons the concrete image of a contraceptive pill or other device. It was inevitable that this would become the case for <em>birth control</em> given the controversy over its use.</p>
<p>This sheds light on the linguist George Lakoff’s briefly acclaimed proposal during the George W Bush administration that Democrats could regain influence by changing the terms for things reviled by Republicans. Taxes could be <em>membership fees</em>; trial lawyers could be <em>public protection attorneys</em>. As fresh as this idea seemed, it could have only worked temporarily, as the history of words such as <em>welfare</em> demonstrates. The nature of language and humanity is such that, after about 20 years, those criticising taxation rates would have come to process and discuss ‘membership fees’ with the same contempt with which they once discussed ‘taxes’, just as it has got to the point that <em>custodian</em> now has roughly the same feel as <em>janitor</em>, for which it emerged as a euphemism in the 1940s. <em>Custodian</em> makes one think not of ‘custody’ but of a mop.</p>
<p><span>T</span>hought will always catch up with the word. Make no mistake, the thoughts can be ones that many would consider welcome. A hundred years ago, in industry, <em>efficiency</em> was associated with the ‘scientific management’ theories of Frederick Taylor, the US mechanical engineer and one of the first management consultants, in search of the maximum output from factory labourers. However, as this kind of efficiency often led to the need for fewer workers, a question arose as to whom the efficiency was intended most to benefit.</p>
<p>Today, <em>efficiency</em> carries a faintly minatory air, in contrast to its first neutral, and then glamorous, feel as the 20th century got underway. <em>Downsizing</em>, an attempt to euphemise the dismissal of workers for the purposes of the bottom line, rapidly lost any impartial connotation it was crafted to purvey. In the mid-20th century, <em>urban renewal</em> was a term of art for what on the ground displaced millions of Americans, often from low-income but stable neighbourhoods deemed ‘slums’ and razed down. Today, that reality has been aired amply and publicly, such that <em>urban renewal</em> calls to mind a bulldozer mowing down innocent people’s homes. Notably, there seems to be no replacement term for <em>urban renewal</em>, partly because the policies of urban czars such as New York’s city planner Robert Moses have been so thoroughly repudiated that public officials no longer espouse any similar doctrine. Ultimately, words alone cannot do this: <em>urban renewal</em> itself began as a euphemism for the more direct <em>slum clearance</em>, but the practice only burgeoned for decades thereafter. It took thought changing to truly transform.</p>
<p>‘Innovation’ has been fashionable for long enough among corporate and political types that it has taken on their hucksterish associations</p>
<p>The euphemism treadmill, then, is neither just a form of bureaucratese, nor of identity politics. It is a symptom of the fact that, however much we would like it to be otherwise, it’s easier to change language than to change thought. Moreover, the euphemism treadmill is neither new nor does it churn faster than it once did. When you ask someone <em>Where’s the men’s?,</em> you are using a replacement for the <em>restroom</em> that can summon a vision of a certain undersanitised room in the back of a Wendy’s fast-food restaurant. Yet the very idea of it being a ‘rest’ room began as an exquisite attempt to wave away miasmic associations after <em>bathroom</em> ceased to do the job any better than had <em>toilet</em> or <em>lavatory</em>, deflecting attention to grooming and cleansing over what else happens in the room. Historically, <em>lavatory</em> is first attested in 1864, <em>restroom</em> followed hot on its heels a few decades later, at the turn of the 20th century, and then <em>men’s room</em> came into fashion in the 1920s.</p>
<p>This means that, in a linguistically mature society, we should expect that the terms we introduce to help us kick off new ways of thinking will require periodic replacement, like tyres. In our moment, <em>special-needs student</em> would appear about due for a swap-out. Meanwhile, the term <em>innovation</em> has been fashionable for just long enough among corporate and political types that it has taken on their hucksterish associations. <em>Invention</em>, for their purposes, would be better, although by about 2035 we can assume that this word too will sound, from the mouths of that era’s managers and mayors, equally fulsome.</p>
<p>Reality persists. It’s language we have control over – at least, for a while.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Play will no longer pay to discover vulnerabilities in Android apps (115 pts)]]></title>
            <link>https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/</link>
            <guid>41315068</guid>
            <pubDate>Wed, 21 Aug 2024 23:06:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/">https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/</a>, See on <a href="https://news.ycombinator.com/item?id=41315068">Hacker News</a></p>
Couldn't get https://www.androidauthority.com/google-play-security-reward-program-winding-down-3472376/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bioaccumulation of Microplastics in Decedent Human Brains (127 pts)]]></title>
            <link>https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/</link>
            <guid>41314674</guid>
            <pubDate>Wed, 21 Aug 2024 22:07:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/</a>, See on <a href="https://news.ycombinator.com/item?id=41314674">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
    <article>
        <section>
         
    <ul>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/journals/">Journal List</a>
                </li>
            
                <li>
                    <a href="https://www.ncbi.nlm.nih.gov/pmc/?term=%22Res%20Sq%22[jour]">Research Square</a>
                </li>
            
                <li aria-current="page">
                    PMC11100893
                </li>
            
    </ul>
 

        </section>
        
  

        
        <div id="mc" role="document"><!--main-content--><div data-jigconfig="smoothScroll: false, allHeadingLevels: ['h2'], headingExclude: ':hidden,.nomenu'"><div><div><p>Version 1. <span id="pmcmata">Res Sq.</span> Preprint. 2024 May 6.</p></div><div><p><a href="https://pubmed.ncbi.nlm.nih.gov/?term=Campen%20M%5BAuthor%5D" co-rid="_co_idm140287073396832" co-class="co-affbox">Matthew Campen</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Nihart%20A%5BAuthor%5D" co-rid="_co_idm140287138113648" co-class="co-affbox">Alexander Nihart</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Garcia%20M%5BAuthor%5D" co-rid="_co_idm140287070400336" co-class="co-affbox">Marcus Garcia</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Liu%20R%5BAuthor%5D" co-rid="_co_idm140287070521552" co-class="co-affbox">Rui Liu</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Olewine%20M%5BAuthor%5D" co-rid="_co_idm140287072016768" co-class="co-affbox">Marian Olewine</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Castillo%20E%5BAuthor%5D" co-rid="_co_idm140287077058752" co-class="co-affbox">Eliseo Castillo</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Bleske%20B%5BAuthor%5D" co-rid="_co_idm140287077057152" co-class="co-affbox">Barry Bleske</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Scott%20J%5BAuthor%5D" co-rid="_co_idm140287077087232" co-class="co-affbox">Justin Scott</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Howard%20T%5BAuthor%5D" co-rid="_co_idm140287073604784" co-class="co-affbox">Tamara Howard</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Gonzalez-Estrella%20J%5BAuthor%5D" co-rid="_co_idm140287075701440" co-class="co-affbox">Jorge Gonzalez-Estrella</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Adolphi%20N%5BAuthor%5D" co-rid="_co_idm140287079550448" co-class="co-affbox">Natalie Adolphi</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Gallego%20D%5BAuthor%5D" co-rid="_co_idm140287078865264" co-class="co-affbox">Daniel Gallego</a>, and  <a href="https://pubmed.ncbi.nlm.nih.gov/?term=Hayek%20EE%5BAuthor%5D" co-rid="_co_idm140287148974224" co-class="co-affbox">Eliane El Hayek</a></p></div></div><div id="ABS1" lang="en"><h2 id="ABS1title">Abstract</h2><!--article-meta--><p id="P1">Rising global concentrations of environmental micro- and nanoplastics (MNPs) drive concerns for human exposure and health outcomes. Applying pyrolysis gas chromatography-mass spectrometry (Py-GC/MS) methods to isolate and quantify MNPs from human samples, we compared MNP accumulation in kidneys, livers, and brains. Autopsy samples from the Office of the Medical Investigator in Albuquerque, NM, collected in 2016 and in 2024, were digested for Py-GC/MS analysis of 12 polymers. Brains exhibited higher concentrations of MNPs than liver or kidney samples. All organs exhibited significant increases from 2016 to 2024. Polyethylene was the predominant polymer; the relative proportion of polyethylene MNPs was greater in brain samples than in liver or kidney. Transmission electron microscopy verified the nanoscale nature of isolated particles, which largely appeared to be aged, shard-like plastics remnants across a wide range of sizes. Results demonstrate that MNPs are selectively accumulated into the human brain and concentrations are rising over time.</p><p><strong>Keywords: </strong><span>Polymer, neuronal, autopsy, liver, kidney, nanoplastics</span></p></div><div id="body-a.f"><p id="P2">The ubiquitous presence of plastics, especially polymer-derived particulates ranging from 500 micrometers in diameter down to 1 nanometer, defined as micro- and nanoplastics (MNP), is a defining feature of the Anthropocene epoch<sup><a href="#R1" rid="R1">1</a></sup>. The extent to which microplastics cause harm or toxicity is unclear, although recent studies associated MNP presence in carotid atheromas with increased inflammation and risk of future adverse cardiovascular events<sup><a href="#R2" rid="R2">2</a>,<a href="#R3" rid="R3">3</a></sup>. In controlled exposure studies, MNPs clearly enhance or drive toxic outcomes<sup><a href="#R4" rid="R4">4</a>–<a href="#R6" rid="R6">6</a></sup>. The mantra of the field of toxicology – “dose makes the poison” (Paracelsus) – renders such discoveries as easily anticipated; what is not clearly understood is the internal dose in humans.</p><p id="P3">To date, several studies have utilized visualization and spectroscopic methods to identify and count particulates in organs such as the lungs, intestine<sup><a href="#R7" rid="R7">7</a></sup>, and placenta<sup><a href="#R8" rid="R8">8</a></sup>. These methods are often limited to larger (&gt;1–5μm) particulates, thus nanoplastics are excluded from the quantitation. As a novel approach, pyrolysis gas chromatography-mass spectrometry (Py-GC/MS) has been applied to blood<sup><a href="#R9" rid="R9">9</a></sup>, placentas<sup><a href="#R10" rid="R10">10</a></sup> and recently major blood vessels<sup><a href="#R2" rid="R2">2</a>,<a href="#R3" rid="R3">3</a></sup> in a manner that appears more cumulative and quantitative, and less biased than visual identification methods. Py-GC/MS data between labs has been comparable, providing confidence in this method for human tissue analysis<sup><a href="#R2" rid="R2">2</a>,<a href="#R9" rid="R9">9</a>,<a href="#R10" rid="R10">10</a></sup>. We applied Py-GC/MS to assess the relative distribution of MNPs in major organ systems from human decedent livers, kidneys, and brains.</p></div><div id="S1"><h2 id="S1title">METHODS</h2><div id="S2"><h3 id="S2title">Human Tissue Samples:</h3><p id="P4">We obtained de-identified, post-mortem human liver, kidney, and brain (frontal cortex) samples, retrospectively, in cooperation with and approval from the University of New Mexico Office of the Medical Investigator (OMI) in Albuquerque, New Mexico, under the guidance of a trained forensic pathologist (DFG) who selected consistent regions from all organs. Samples were available from 2016 and 2024; the same collection protocol was used for 2016 and 2024. Small pieces of representative organs (3 to 5 cm<sup><a href="#R2" rid="R2">2</a></sup>) are routinely collected at autopsy and placed in a small container with 10% formalin. Limited demographic data was available due to the conditions of specimen approval. In the 2016 samples, 17 samples were from males and 10 were from females. In 2024, 13 samples were from males and 11 were from females. The mean (and standard deviation) age of 2016 decedents was 50.0 (±11.4) years and 52.3 (±16.8) years for the 2024 decedents.</p></div><div id="S3"><h3 id="S3title">Py-GC/MS Detection of Polymer Solids:</h3><p id="P5">Formalin-fixed tissue samples (approximately 500mg) were digested with 10% potassium hydroxide for 3d at 40°C with intermittent manual mixing to ensure even and thorough digestion. Fully digested samples were then ultracentrifuged at 100,000g × 4h to generate a pellet enriched in solid materials resistant to such digestion, principally polymer-based solids<sup><a href="#R10" rid="R10">10</a></sup>. A 1–2 mg portion of the resulting pellet was then analyzed by single-shot Py-GC/MS and compared to a microplastics-CaCO<sub>3</sub> standard containing 12 specific polymers: Polyethylene (PE), Polyvinyl chloride (PVC), Nylon 66 (N66), Styrene-butadiene (SBR), Acrylonitrile Butadiene Styrene (ABS), Polyethylene terephthalate (PET), Nylon 6 (N6), Poly(methyl methacrylate) (PMMA), Polyurethane (PU), Polycarbonate (PC), Polypropylene (PP), Polystyrene (PS). Polymer spectra were identified via the F-Search MPs v2.1 software (Frontier Labs). Resulting data were normalized to original sample weight to render a mass concentration (μg/g).</p></div><div id="S4"><h3 id="S4title">Data Analysis:</h3><p id="P6">Statistical analysis was performed using GraphPad Prism v10.0.03. Details of statistical analysis are provided in the data supplement.</p></div></div><div id="S5"><h2 id="S5title">RESULTS and DISCUSSION</h2><p id="P7">Py-GC/MS has proven to be an informative and reliable method to determine plastics concentrations in liquid and solid tissue samples, with ample assurance of accuracy, quality, and rigor<sup><a href="#R2" rid="R2">2</a>,<a href="#R3" rid="R3">3</a>,<a href="#R9" rid="R9">9</a>,<a href="#R10" rid="R10">10</a></sup>. Decedent liver and kidney MNP concentrations were similar, with means of 465 and 666 μg/g, respectively, from 2024 samples (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1A</span></a>). These were higher than previously published data for human placentas (126 μg/g)<sup><a href="#R10" rid="R10">10</a></sup>, but comparable to testes (329 μg/g)<sup><a href="#R11" rid="R11">11</a></sup>. Liver samples had significantly higher concentrations in 2024 than in 2016 samples (145 μg/g; p&lt;0.001). The brain samples, all derived from the frontal cortex, revealed substantially higher concentrations than liver or kidney, at 3,057 μg/g in 2016 samples and 4,806 μg/g (0.48%, by weight) in 2024 samples, ranging as high as 8,861 μg/g. Five brain samples from 2016 (highlighted in orange, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1A</span></a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>​</span><span>B</span></a>) were analyzed independently by colleagues at Oklahoma State University, and those values were consistent with our findings.</p><!--fig ft0--><!--fig mode=article f1--><div id="F1" co-legend-rid="lgnd_F1"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div data-largeobj="" data-largeobj-link-rid="largeobj_idm140287073274816"><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=11100893_nihpp-rs4345687v1-f0001.jpg" target="tileshopwindow" rel="noopener"><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is nihpp-rs4345687v1-f0001.jpg" title="Click on image to zoom" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/bin/nihpp-rs4345687v1-f0001.jpg"></a></div><div id="lgnd_F1"><!--caption a7--><p id="P17">Overview of total MNP concentrations from all decedent samples from liver, kidney, and brain. <strong>A.</strong> All data shown, with the bar representing arithmetic mean value and the standard deviation. Orange colored symbols in the 2016 brain samples were analyzed independently at Oklahoma State University. Asterisks indicate significant differences temporal changes (from 2016 to 2024) using a nonparametric t-test (Mann Whitney). Brain concentrations were also significantly higher than liver and kidney, by ANOVA. <strong>B.</strong> Using only polyethylene data, similar trends were noted, although the kidney concentrations did not increase in the 2024 samples. <strong>C.</strong> Overall distribution of 12 different polymers suggests a greater accumulation of polyethylene in the brain relative to liver or kidney. Polyethylene (PE), Polyvinyl chloride (PVC), Nylon 66 (N66), Styrene-butadiene (SBR), Acrylonitrile Butadiene Styrene (ABS), Polyethylene terephthalate (PET), Nylon 6 (N6), Poly(methyl methacrylate) (PMMA), Polyurethane (PU), Polycarbonate (PC), Polypropylene (PP), Polystyrene (PS). <strong>D.</strong> Distribution trends for PE across each organ and collection date, including 5 additional samples (on the right) from the 2016 brain collections that were analysed by Attenuated Total Reflectance-Fourier-transform infrared spectroscopy (FTIR).</p></div></div><p id="P8">A non-parametric analysis of variance (Kruskal-Wallis) confirmed that MNP concentrations in brains were significantly greater than all other tissues (P&lt;0.0001). Furthermore, from 2016 to 2024, there was a significant increase in MNP concentrations in both livers and brains. The predominant polymer found in all tissues was polyethylene, which independently displayed similarly increasing trends from 2016 to 2024 in the liver and brain (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1B</span></a>). The proportion of polyethylene in the brain (74%) appeared significantly greater relative to other polymers in comparison to the liver and kidney (44–57%), although kidney samples from 2024 also had increased relative PE (71%; <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1C</span></a>,<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>​</span><span>D</span></a>). This was also confirmed with ATR-FTIR spectroscopic analysis from 5 brain samples (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F1/" target="figure" rid-figpopup="F1" rid-ob="ob-F1" co-legend-rid="lgnd_F1"><span>Figure 1D</span></a>).</p><p id="P9">Because we suspected that much of the MNPs measured were actually in the nanoscale range, transmission electron microscopy (TEM) was conducted on the dispersed pellets obtained from kidney, liver, and brain (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2" co-legend-rid="lgnd_F2"><span>Figure 2</span></a>; see methods supplement). While TEM does not provide spectroscopic identification to confirm particulate composition, we observed common shapes and sizes among the numerous samples and tissue types. Notably, there were innumerable particulates with shard-like appearance, often less than 200 nm in length. Currently, MNP uptake and distribution pathways are incompletely understood; this new appreciation of the size and shape aids in our appreciation of potential mechanisms. Importantly, these observations bring into question the relevance of the many recent studies utilizing polystyrene microspheres<sup><a href="#R4" rid="R4">4</a>,<a href="#R12" rid="R12">12</a></sup>, as polystyrene was infrequently detected in human tissues and MNPs were rarely spherical.</p><!--fig ft0--><!--fig mode=article f1--><div id="F2" co-legend-rid="lgnd_F2"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/figure/F2/" target="figure" rid-figpopup="F2" rid-ob="ob-F2"><!--fig/graphic|fig/alternatives/graphic mode="anchored" m1--></a><div data-largeobj="" data-largeobj-link-rid="largeobj_idm140287077828624"><a href="https://www.ncbi.nlm.nih.gov/core/lw/2.0/html/tileshop_pmc/tileshop_pmc_inline.html?title=Click%20on%20image%20to%20zoom&amp;p=PMC3&amp;id=11100893_nihpp-rs4345687v1-f0002.jpg" target="tileshopwindow" rel="noopener"><img loading="lazy" alt="An external file that holds a picture, illustration, etc.
Object name is nihpp-rs4345687v1-f0002.jpg" title="Click on image to zoom" src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11100893/bin/nihpp-rs4345687v1-f0002.jpg"></a></div><div id="lgnd_F2"><!--caption a7--><p id="P18">Example TEM images of solid nanoparticulates derived from kidney (left), liver (center), and brain (right) samples. While TEM does not permit spectroscopic identification of particulate molecular composition, the bulk of particulates that were predominantly polymer as assessed by ATR-FTIR appear to be of these sizes and shapes. Shard-like appearances, with dimensions ranging from micrometer to nanometer sizes, suggest an aged, friable polymer composition.</p></div></div><p id="P10">The concentrations in liver and kidney were not as high (relative to brains) as we would have suspected, as these are “front line” organs for xenobiotic uptake and clearance. That said, the lipophilic nature of plastics may make them easily handled by the liver, which has a major role in uptake and repackaging of dietary triglycerides and cholesterol. A recent study found higher MNP numbers in the cirrhotic liver compared to the healthy liver; whether the microplastics promote disease or are simply accumulating along with intracellular fats has not been elucidated<sup><a href="#R13" rid="R13">13</a></sup>.</p><p id="P11">Following this logic, the human brain has the second highest lipid content in the body, with only adipose tissue being higher; brain MNP concentrations are comparable to recently published Py-GC/MS data from carotid plaques, which are also a lipid depot<sup><a href="#R3" rid="R3">3</a></sup>. Furthermore, the brain receives a high blood flow, approximately 25–30% of the cardiac output, and has a tremendous metabolism. The blood-brain barrier poses a notorious challenge. However, modeling of transfer across cellular membranes suggests the uptake is dependent on the association of particulates with cholesterol and, furthermore, that particles &lt;1μm rapidly traversed the blood-brain barrier within 2h of ingestion in mice<sup><a href="#R14" rid="R14">14</a></sup>. Longer-term gavage studies similarly found that larger (5 μm) polystyrene microspheres could access the brain and promote metabolomic alterations<sup><a href="#R15" rid="R15">15</a></sup>. Lastly, clearance rates from the brain are unknown for polymer particulates. The lack of correlation with the decedent age suggests that an equilibrium occurs and may depend on genetic, dietary, and lifestyle factors that ultimately contribute to the wide between-subject variability in MNP concentrations. In zebrafish exposed to constant concentrations, nanoplastics uptake increased to a stable plateau and cleared after exposure<sup><a href="#R16" rid="R16">16</a></sup>; however, the maximal concentrations were increased proportionately with higher exposure concentrations. While the time course for kinetics is assuredly longer in humans, we postulate that the exponentially increasing environmental concentrations of MNPs<sup><a href="#R1" rid="R1">1</a>,<a href="#R17" rid="R17">17</a></sup> will analogously increase internal maximal concentrations, which is corroborated by our finding that total plastics mass concentration in brains increased over 50% in the past 8 years.</p></div><div id="S6"><h2 id="S6title">LIMITATIONS</h2><p id="P12">The present data are derived from novel analytical chemistry methods that have yet to be widely adopted and refined. Several quality control steps ensure that external contaminants are not incorporated into the sample calculations, including KOH blank samples and measurement of the polymer composition of all plastic tubes and pipette tips that are essential in the digestion and measurement process. Notably, given the consistent nature of handling and processing across varying organ samples (<em>i.e</em>., brain, liver, kidney), the dramatic, selective accumulation of MNPs in the brain cannot be dismissed as an artefact of contamination. Furthermore, the far longer duration of samples in plastic stock jars from 2016 (84–96 months) compared to those samples from 2024 (1–3 months) and the significantly lower plastics content in 2016 samples suggests that contamination from fresh plastics is not a concern to the conclusions from these data.</p><p id="P13">Both laboratories (UNM and OSU) observed a within-sample coefficient of variation of approximately 25%. This does not alter the conclusions regarding the temporal trends of selective accumulation in brains, given the magnitude of those effects. However, we believe several steps may be valuable to improve the precision of Py-GC/MS output, which in turn should improve assessment of health outcomes for future studies. There may be value in limiting assessments to the nanoscale range, which could incorporate longer ultracentrifugation times as well as a filtration of &gt;1 μm particulates. Ambient air particulate matter research provides some justification that “smaller is worse”, which led to the transition from air quality standards based on particles &lt;10 μm in diameter to those &lt;2.5 μm, which aligned more closely with health outcomes<sup><a href="#R18" rid="R18">18</a></sup>. Additionally, the Py-GC/MS method is limited to small sample weights (~1–2mg), which presents challenges for sampling and weighing accuracy when even small portions of tissue (~500 mg) generate large polymer-containing pellets; however, larger sample sizes may not be feasible due to the rapid combustion required for this approach. Lastly, by obtaining only a single sample from each organ for each subject, distribution heterogeneity within tissues remains uncharacterized.</p></div><div id="S7"><h2 id="S7title">CONCLUSIONS</h2><p id="P14">MNP concentrations in decedent brain samples ranged from 7-to-30 times the concentrations seen in livers or kidneys. With independent confirmation from another laboratory and visual evidence from FTIR and TEM approaches, we have high confidence that MNPs selectively accumulate in the brain, with the majority being nanometer-scale, shard-like particulates. However, linking MNP concentration data to health outcomes in larger cohorts will require refinements to the technique, more complex study designs, and larger cohorts. The parallels between the present data showing an increasing trend in MNP concentrations in the brain with exponentially rising environmental presence of microplastics<sup><a href="#R19" rid="R19">19</a>–<a href="#R21" rid="R21">21</a></sup> and increasing global rates of age-corrected Alzheimer’s disease and related dementia<sup><a href="#R22" rid="R22">22</a>–<a href="#R25" rid="R25">25</a></sup>, given the potential role of anionic nanoplastics in protein aggregation<sup><a href="#R26" rid="R26">26</a></sup>, add urgency to understanding the impacts of MNP on human health.</p></div><div id="S8"><h2 id="S8title">Funding/Support:</h2><p id="P15">This research was funded by NIH P20 GM130422 (MJC), R01 ES032037 (EFC), R01 ES014639 (MJC), K12 GM088021 (MAG), P50 MD015706 (EEH), P30ES032755 (BB), and R15 ES034901 (JGE).</p></div><div id="fn-group-a.g.b"><h2 id="fn-group-a.g.btitle">Footnotes</h2><!--back/fn-group--><div><p id="P16"><strong>Statement of Interests:</strong> The authors declare no conflicts of interest with the content of this manuscript.</p></div></div><div id="article-aaff-info"><h2 id="article-aaff-infotitle">Contributor Information</h2><p><span>Matthew Campen, </span><span id="A1"> University of New Mexico.</span></p><p><span>Alexander Nihart, </span><span id="A2"> University of New Mexico.</span></p><p><span>Marcus Garcia, </span><span id="A3"> University of New Mexico.</span></p><p><span>Rui Liu, </span><span id="A4"> University of New Mexico.</span></p><p><span>Marian Olewine, </span><span id="A5"> University of New Mexico.</span></p><p><span>Eliseo Castillo, </span><span id="A6"> University of New Mexico.</span></p><p><span>Barry Bleske, </span><span id="A7"> University of New Mexico.</span></p><p><span>Justin Scott, </span><span id="A8"> Oklahoma State University.</span></p><p><span>Tamara Howard, </span><span id="A9"> University of New Mexico Health Sciences Center.</span></p><p><span>Jorge Gonzalez-Estrella, </span><span id="A10"> Oklahoma State University.</span></p><p><span>Natalie Adolphi, </span><span id="A11"> New Mexico Office of the Medical Investigator.</span></p><p><span>Daniel Gallego, </span><span id="A12"> New Mexico Office of the Medical Investigator.</span></p><p><span>Eliane El Hayek, </span><span id="A13"> University of New Mexico.</span></p></div><div id="ref-list-a.g.c"><h2 id="ref-list-a.g.ctitle">REFERENCES</h2><div id="reference-list"><p>1. <span>Stubbins A., Law K. L., Munoz S. E., Bianchi T. S. &amp; Zhu L.
<span>Plastics in the Earth system</span>. <span>Science</span>
<span>373</span>, 51–55, doi: 10.1126/science.abb0354 (2021).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/34210876" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1126%2Fscience.abb0354" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Science&amp;title=Plastics+in+the+Earth+system&amp;author=A.+Stubbins&amp;author=K.+L.+Law&amp;author=S.+E.+Munoz&amp;author=T.+S.+Bianchi&amp;author=L.+Zhu&amp;volume=373&amp;publication_year=2021&amp;pages=51-55&amp;pmid=34210876&amp;doi=10.1126/science.abb0354&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>2. <span>Liu S.
et al. 
<span>Microplastics in three types of human arteries detected by pyrolysis-gas chromatography/mass spectrometry (Py-GC/MS)</span>. <span>J Hazard Mater</span>
<span>469</span>, 133855, doi: 10.1016/j.jhazmat.2024.133855 (2024).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/38428296" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jhazmat.2024.133855" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hazard+Mater&amp;title=Microplastics+in+three+types+of+human+arteries+detected+by+pyrolysis-gas+chromatography/mass+spectrometry+(Py-GC/MS)&amp;author=S.+Liu&amp;volume=469&amp;publication_year=2024&amp;pages=133855&amp;pmid=38428296&amp;doi=10.1016/j.jhazmat.2024.133855&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>3. <span>Marfella R.
et al. 
<span>Microplastics and Nanoplastics in Atheromas and Cardiovascular Events</span>. <span>N Engl J Med</span>
<span>390</span>, 900–910, doi: 10.1056/NEJMoa2309822 (2024).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11009876/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38446676" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1056%2FNEJMoa2309822" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Microplastics+and+Nanoplastics+in+Atheromas+and+Cardiovascular+Events&amp;author=R.+Marfella&amp;volume=390&amp;publication_year=2024&amp;pages=900-910&amp;pmid=38446676&amp;doi=10.1056/NEJMoa2309822&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>4. <span>El Hayek E.
et al. 
<span>Photoaging of polystyrene microspheres causes oxidative alterations to surface physicochemistry and enhances airway epithelial toxicity</span>. <span>Toxicol Sci</span>
<span>193</span>, 90–102, doi: 10.1093/toxsci/kfad023 (2023).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10176241/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/36881996" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1093%2Ftoxsci%2Fkfad023" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Toxicol+Sci&amp;title=Photoaging+of+polystyrene+microspheres+causes+oxidative+alterations+to+surface+physicochemistry+and+enhances+airway+epithelial+toxicity&amp;author=E.+El+Hayek&amp;volume=193&amp;publication_year=2023&amp;pages=90-102&amp;pmid=36881996&amp;doi=10.1093/toxsci/kfad023&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>5. <span>Dong C. D.
et al. 
<span>Polystyrene microplastic particles: In vitro pulmonary toxicity assessment</span>. <span>J Hazard Mater</span>
<span>385</span>, 121575, doi: 10.1016/j.jhazmat.2019.121575 (2020).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/31727530" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jhazmat.2019.121575" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hazard+Mater&amp;title=Polystyrene+microplastic+particles:+In+vitro+pulmonary+toxicity+assessment&amp;author=C.+D.+Dong&amp;volume=385&amp;publication_year=2020&amp;pages=121575&amp;pmid=31727530&amp;doi=10.1016/j.jhazmat.2019.121575&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>6. <span>Dibbon K. C.
et al. 
<span>Polystyrene micro- and nanoplastics cause placental dysfunction in mice1</span>. <span>Biol Reprod</span>, doi: 10.1093/biolre/ioad126 (2023). [<a href="https://pubmed.ncbi.nlm.nih.gov/37724921" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1093%2Fbiolre%2Fioad126" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Biol+Reprod&amp;title=Polystyrene+micro-+and+nanoplastics+cause+placental+dysfunction+in+mice1&amp;author=K.+C.+Dibbon&amp;publication_year=2023&amp;doi=10.1093/biolre/ioad126&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>7. <span>Zhu L.
et al. 
<span>Tissue accumulation of microplastics and potential health risks in human</span>. <span>Sci Total Environ</span>
<span>915</span>, 170004, doi: 10.1016/j.scitotenv.2024.170004 (2024).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/38220018" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.scitotenv.2024.170004" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Total+Environ&amp;title=Tissue+accumulation+of+microplastics+and+potential+health+risks+in+human&amp;author=L.+Zhu&amp;volume=915&amp;publication_year=2024&amp;pages=170004&amp;pmid=38220018&amp;doi=10.1016/j.scitotenv.2024.170004&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>8. <span>Ragusa A.
et al. 
<span>Plasticenta: First evidence of microplastics in human placenta</span>. <span>Environ Int</span>
<span>146</span>, 106274, doi: 10.1016/j.envint.2020.106274 (2021).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/33395930" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.envint.2020.106274" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Environ+Int&amp;title=Plasticenta:+First+evidence+of+microplastics+in+human+placenta&amp;author=A.+Ragusa&amp;volume=146&amp;publication_year=2021&amp;pages=106274&amp;pmid=33395930&amp;doi=10.1016/j.envint.2020.106274&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>9. <span>Leslie H. A.
et al. 
<span>Discovery and quantification of plastic particle pollution in human blood</span>. <span>Environ Int</span>
<span>163</span>, 107199, doi: 10.1016/j.envint.2022.107199 (2022).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/35367073" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.envint.2022.107199" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Environ+Int&amp;title=Discovery+and+quantification+of+plastic+particle+pollution+in+human+blood&amp;author=H.+A.+Leslie&amp;volume=163&amp;publication_year=2022&amp;pages=107199&amp;pmid=35367073&amp;doi=10.1016/j.envint.2022.107199&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>10. <span>Garcia M. A.
et al. 
<span>Quantitation and identification of microplastics accumulation in human placental specimens using pyrolysis gas chromatography mass spectrometry</span>. <span>Toxicol Sci</span>, doi: 10.1093/toxsci/kfae021 (2024). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11057519/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38366932" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1093%2Ftoxsci%2Fkfae021" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Toxicol+Sci&amp;title=Quantitation+and+identification+of+microplastics+accumulation+in+human+placental+specimens+using+pyrolysis+gas+chromatography+mass+spectrometry&amp;author=M.+A.+Garcia&amp;publication_year=2024&amp;doi=10.1093/toxsci/kfae021&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>11. <span>Hu C.
et al. 
<span>Unveiling the Hidden Threat: Microplastic Presence in Dog and Human Testis and Its Potential Association with Sperm Count</span>. <span>Toxicol Sci</span> (2024). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11285152/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38745431" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Toxicol+Sci&amp;title=Unveiling+the+Hidden+Threat:+Microplastic+Presence+in+Dog+and+Human+Testis+and+Its+Potential+Association+with+Sperm+Count&amp;author=C.+Hu&amp;publication_year=2024&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>12. <span>Garcia M. M.
et al. 
<span>In Vivo Tissue Distribution of Polystyrene or Mixed Polymer Microspheres and Metabolomic Analysis after Oral Exposure in Mice</span>. <span>Environ Health Perspect</span>
<span>132</span>, 47005, doi: 10.1289/EHP13435 (2024).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11005960/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38598326" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1289%2FEHP13435" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Environ+Health+Perspect&amp;title=In+Vivo+Tissue+Distribution+of+Polystyrene+or+Mixed+Polymer+Microspheres+and+Metabolomic+Analysis+after+Oral+Exposure+in+Mice&amp;author=M.+M.+Garcia&amp;volume=132&amp;publication_year=2024&amp;pages=47005&amp;pmid=38598326&amp;doi=10.1289/EHP13435&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>13. <span>Horvatits T.
et al. 
<span>Microplastics detected in cirrhotic liver tissue</span>. <span>EBioMedicine</span>
<span>82</span>, 104147, doi: 10.1016/j.ebiom.2022.104147 (2022).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9386716/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/35835713" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.ebiom.2022.104147" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=EBioMedicine&amp;title=Microplastics+detected+in+cirrhotic+liver+tissue&amp;author=T.+Horvatits&amp;volume=82&amp;publication_year=2022&amp;pages=104147&amp;pmid=35835713&amp;doi=10.1016/j.ebiom.2022.104147&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>14. <span>Kopatz V.
et al. 
<span>Micro- and Nanoplastics Breach the Blood-Brain Barrier (BBB): Biomolecular Corona’s Role Revealed</span>. <span>Nanomaterials (Basel)</span>
<span>13</span>, doi: 10.3390/nano13081404 (2023). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10141840/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/37110989" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.3390%2Fnano13081404" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Nanomaterials+(Basel)&amp;title=Micro-+and+Nanoplastics+Breach+the+Blood-Brain+Barrier+(BBB):+Biomolecular+Corona%E2%80%99s+Role+Revealed&amp;author=V.+Kopatz&amp;volume=13&amp;publication_year=2023&amp;doi=10.3390/nano13081404&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>15. <span>Garcia M. M.
et al. 
<span>In Vivo Tissue Distribution of Microplastics and Systemic Metabolomic Alterations After Gastrointestinal Exposure</span>. <span>bioRxiv</span>, doi: 10.1101/2023.06.02.542598 (2023). [<a href="https://doi.org/10.1101%2F2023.06.02.542598" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=bioRxiv&amp;title=In+Vivo+Tissue+Distribution+of+Microplastics+and+Systemic+Metabolomic+Alterations+After+Gastrointestinal+Exposure&amp;author=M.+M.+Garcia&amp;publication_year=2023&amp;doi=10.1101/2023.06.02.542598&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>16. <span>Habumugisha T., Zhang Z., Fang C., Yan C. &amp; Zhang X.
<span>Uptake, bioaccumulation, biodistribution and depuration of polystyrene nanoplastics in zebrafish (Danio rerio)</span>. <span>Sci Total Environ</span>
<span>893</span>, 164840, doi: 10.1016/j.scitotenv.2023.164840 (2023).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/37321508" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.scitotenv.2023.164840" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Total+Environ&amp;title=Uptake,+bioaccumulation,+biodistribution+and+depuration+of+polystyrene+nanoplastics+in+zebrafish+(Danio+rerio)&amp;author=T.+Habumugisha&amp;author=Z.+Zhang&amp;author=C.+Fang&amp;author=C.+Yan&amp;author=X.+Zhang&amp;volume=893&amp;publication_year=2023&amp;pages=164840&amp;pmid=37321508&amp;doi=10.1016/j.scitotenv.2023.164840&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>17. <span>Landrigan P. J.
<span>Plastics, Fossil Carbon, and the Heart</span>. <span>N Engl J Med</span>
<span>390</span>, 948–950, doi: 10.1056/NEJMe2400683 (2024).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/38446681" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1056%2FNEJMe2400683" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=Plastics,+Fossil+Carbon,+and+the+Heart&amp;author=P.+J.+Landrigan&amp;volume=390&amp;publication_year=2024&amp;pages=948-950&amp;pmid=38446681&amp;doi=10.1056/NEJMe2400683&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>18. <span>Dockery D. W.
et al. 
<span>An association between air pollution and mortality in six U.S. cities</span>. <span>N Engl J Med</span>
<span>329</span>, 1753–1759, doi: 10.1056/NEJM199312093292401 (1993).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/8179653" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1056%2FNEJM199312093292401" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=N+Engl+J+Med&amp;title=An+association+between+air+pollution+and+mortality+in+six+U.S.+cities&amp;author=D.+W.+Dockery&amp;volume=329&amp;publication_year=1993&amp;pages=1753-1759&amp;pmid=8179653&amp;doi=10.1056/NEJM199312093292401&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>19. <span>Wang C. H., Zhao J. &amp; Xing B. S.
<span>Environmental source, fate, and toxicity of microplastics</span>. <span>J Hazard Mater</span>
<span>407</span>, doi:ARTN 124357 10.1016/j.jhazmat.2020.124357 (2021). [<a href="https://pubmed.ncbi.nlm.nih.gov/33158648" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1016%2Fj.jhazmat.2020.124357" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Hazard+Mater&amp;title=Environmental+source,+fate,+and+toxicity+of+microplastics&amp;author=C.+H.+Wang&amp;author=J.+Zhao&amp;author=B.+S.+Xing&amp;volume=407&amp;publication_year=2021&amp;doi=10.1016/j.jhazmat.2020.124357&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>20. <span>Geyer R., Jambeck J. R. &amp; Law K. L.
<span>Production, use, and fate of all plastics ever made</span>. <span>Sci Adv</span>
<span>3</span>, doi:ARTN e1700782 10.1126/sciadv.1700782 (2017). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5517107/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28776036" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1126%2Fsciadv.1700782" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Adv&amp;title=Production,+use,+and+fate+of+all+plastics+ever+made&amp;author=R.+Geyer&amp;author=J.+R.+Jambeck&amp;author=K.+L.+Law&amp;volume=3&amp;publication_year=2017&amp;doi=10.1126/sciadv.1700782&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>21. <span>Landrigan P. J.
et al. 
<span>The Minderoo-Monaco Commission on Plastics and Human Health</span>. <span>Ann Glob Health</span>
<span>89</span>, 23, doi: 10.5334/aogh.4056 (2023).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10038118/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/36969097" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.5334%2Faogh.4056" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Ann+Glob+Health&amp;title=The+Minderoo-Monaco+Commission+on+Plastics+and+Human+Health&amp;author=P.+J.+Landrigan&amp;volume=89&amp;publication_year=2023&amp;pages=23&amp;pmid=36969097&amp;doi=10.5334/aogh.4056&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>22. <span>van Bussel E. F.
et al. 
<span>Dementia incidence trend over 1992–2014 in the Netherlands: Analysis of primary care data</span>. <span>PLoS Med</span>
<span>14</span>, e1002235, doi: 10.1371/journal.pmed.1002235 (2017).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5340347/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/28267788" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1371%2Fjournal.pmed.1002235" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=PLoS+Med&amp;title=Dementia+incidence+trend+over+1992%E2%80%932014+in+the+Netherlands:+Analysis+of+primary+care+data&amp;author=E.+F.+van+Bussel&amp;volume=14&amp;publication_year=2017&amp;pages=e1002235&amp;pmid=28267788&amp;doi=10.1371/journal.pmed.1002235&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>23. <span>Collaborators G. U. N. D.
et al. 
<span>Burden of Neurological Disorders Across the US From 1990–2017: A Global Burden of Disease Study</span>. <span>JAMA Neurol</span>
<span>78</span>, 165–176, doi: 10.1001/jamaneurol.2020.4152 (2021).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7607495/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/33136137" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1001%2Fjamaneurol.2020.4152" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=JAMA+Neurol&amp;title=Burden+of+Neurological+Disorders+Across+the+US+From+1990%E2%80%932017:+A+Global+Burden+of+Disease+Study&amp;author=G.+U.+N.+D.+Collaborators&amp;volume=78&amp;publication_year=2021&amp;pages=165-176&amp;pmid=33136137&amp;doi=10.1001/jamaneurol.2020.4152&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>24. <span>Huang Y., Li Y., Pan H. &amp; Han L.
<span>Global, regional, and national burden of neurological disorders in 204 countries and territories worldwide</span>. <span>J Glob Health</span>
<span>13</span>, 04160, doi: 10.7189/jogh.13.04160 (2023).
 <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10685084/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/38018250" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.7189%2Fjogh.13.04160" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=J+Glob+Health&amp;title=Global,+regional,+and+national+burden+of+neurological+disorders+in+204+countries+and+territories+worldwide&amp;author=Y.+Huang&amp;author=Y.+Li&amp;author=H.+Pan&amp;author=L.+Han&amp;volume=13&amp;publication_year=2023&amp;pages=04160&amp;pmid=38018250&amp;doi=10.7189/jogh.13.04160&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>25. <span>Zhu Z., Zheng Z., Zhou C., Cao L. &amp; Zhao G.
<span>Trends in Prevalence and Disability-Adjusted Life-Years of Alzheimer’s Disease and Other Dementias in China from 1990 to 2019</span>. <span>Neuroepidemiology</span>
<span>57</span>, 206–217, doi: 10.1159/000530593 (2023).
 [<a href="https://pubmed.ncbi.nlm.nih.gov/37231950" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1159%2F000530593" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Neuroepidemiology&amp;title=Trends+in+Prevalence+and+Disability-Adjusted+Life-Years+of+Alzheimer%E2%80%99s+Disease+and+Other+Dementias+in+China+from+1990+to+2019&amp;author=Z.+Zhu&amp;author=Z.+Zheng&amp;author=C.+Zhou&amp;author=L.+Cao&amp;author=G.+Zhao&amp;volume=57&amp;publication_year=2023&amp;pages=206-217&amp;pmid=37231950&amp;doi=10.1159/000530593&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p><p>26. <span>Liu Z.
et al. 
<span>Anionic nanoplastic contaminants promote Parkinson’s disease-associated alpha-synuclein aggregation</span>. <span>Sci Adv</span> 9, eadi8716, doi: 10.1126/sciadv.adi8716 (2023). <span>[<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10656074/">PMC free article</a>]</span> [<a href="https://pubmed.ncbi.nlm.nih.gov/37976362" ref="reftype=pubmed&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Entrez%7CPubMed%7CRecord">PubMed</a>] [<a href="https://doi.org/10.1126%2Fsciadv.adi8716" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CCrosslink%7CDOI">CrossRef</a>] <span>[<a href="https://scholar.google.com/scholar_lookup?journal=Sci+Adv&amp;title=Anionic+nanoplastic+contaminants+promote+Parkinson%E2%80%99s+disease-associated+alpha-synuclein+aggregation&amp;author=Z.+Liu&amp;publication_year=2023&amp;doi=10.1126/sciadv.adi8716&amp;" target="_blank" rel="noopener noreferrer" ref="reftype=other&amp;article-id=11100893&amp;issue-id=462566&amp;journal-id=3885&amp;FROM=Article%7CCitationRef&amp;TO=Content%20Provider%7CLink%7CGoogle%20Scholar">Google Scholar</a>]</span></span></p></div></div></div><!--post-content--><div><hr><p>Articles from <span>Research Square</span> are provided here courtesy of <strong>American Journal Experts</strong></p><hr></div></div>
    </article>
    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Crypto 'pig butchering' scam wrecks bank, sends ex-CEO to prison for 24 years (103 pts)]]></title>
            <link>https://www.cnbc.com/2024/08/21/cryptocurrency-shan-hanes-pig-butchering-scam.html</link>
            <guid>41314542</guid>
            <pubDate>Wed, 21 Aug 2024 21:52:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/08/21/cryptocurrency-shan-hanes-pig-butchering-scam.html">https://www.cnbc.com/2024/08/21/cryptocurrency-shan-hanes-pig-butchering-scam.html</a>, See on <a href="https://news.ycombinator.com/item?id=41314542">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The former CEO of a small <a href="https://kansasreflector.com/2023/08/11/huge-scam-in-rural-kansas-town-fells-fourth-u-s-bank-in-2023/" target="_blank">Kansas bank</a> was sentenced to more than 24 years in <a href="https://www.justice.gov/usao-ks/pr/former-ceo-failed-bank-sentenced-prison" target="_blank">prison</a> for looting the bank of $47 million — which he sent to <a href="https://www.cnbc.com/2021/11/16/us-selling-seized-cryptocurrency-in-bitconnect-fraud-case.html">cryptocurrency</a> wallets controlled by scammers who had duped him in a "<a href="https://www.fincen.gov/news/news-releases/fincen-issues-alert-prevalent-virtual-currency-investment-scam-commonly-known" target="_blank">pig butchering</a>" scheme that appealed to his greed, <a href="https://www.cnbc.com/2024/05/14/trump-aide-steve-bannon-prosecutors-ask-judge-to-lift-jail-stay.html">federal prosecutors</a> said.</p><p>The massive embezzlement by ex-CEO <a href="https://storage.courtlistener.com/recap/gov.uscourts.ksd.151122/gov.uscourts.ksd.151122.1.0.pdf" target="_blank">Shan Hanes</a> in a series of wire transfers over just eight weeks last year led to the collapse and <a href="https://www.fdic.gov/news/press-releases/2023/pr23058.html" target="_blank">FDIC</a> takeover of <a href="https://oig.federalreserve.gov/reports/board-material-loss-review-heartland-tri-state-bank-feb2024.pdf" target="_blank">Heartland Tri-State Bank</a> in Elkhart, one of only five U.S. banks that <a href="https://oig.federalreserve.gov/releases/news-statement-heartland-ceo-sentence-aug2024.htm" target="_blank">failed</a> in 2023.</p><p>Hanes, 53, also swindled funds from a local <a href="https://www.cnbc.com/2020/01/24/new-orleans-saints-helped-catholic-church-on-clergy-sex-abuse-pr.html">church</a> and investment club — and a daughter's college savings account — to transfer money, purportedly to buy cryptocurrency as the scammers insisted they needed more funds to unlock the supposed returns on his investments, according to records from <a href="https://ksd.uscourts.gov/wichita" target="_blank">U.S. District Court in Wichita</a>, Kansas.</p><p>But Hanes never realized any profit, and lost all of the money he stole, as a result of the scam.</p><p>Judge John Broomes on Monday sentenced Hanes to 293 months in prison — 29 months more than what prosecutors requested after he pleaded guilty in May to a single count of embezzlement by a bank officer.</p><p>During the sentencing hearing, "I called his actions 'pure evil,' " said Brian Mitchell, who for years was Hanes' next-door neighbor in Elkhart, a town of 2,000 or so people in southwestern Kansas, north of the Oklahoma panhandle.</p><p>Mitchell, whose farm and movie theater chain businesses banked at Heartland Tri-State, said there were around 30 shareholders in the bank who attended Hanes' sentencing, more than a year after their stock value was wiped out in the failure.</p><p>"There were people who lost 70, 80% of their retirement" as a result of Hanes' actions, Mitchell told CNBC on Wednesday in a phone interview.</p><p>One local woman is "struggling to afford a nursing home" for her 93-year-old mother, while another woman "can't retire" now because of the crime, Mitchell said.</p><p>Mitchell, who was not a shareholder but who belonged to the investment club victimized by the CEO, said Hanes showed little, if any, remorse for his actions, despite hearing victims tell the judge about the effects of his crime.</p><p>"Shan was facing the judge, and he just looked over his left shoulder for a second, and didn't make eye contact, and said, 'Sorry,' " Mitchell recalled, describing the scene in the courtroom.</p><p>"And that was it."</p><p>But Hanes had a look of "absolute shock" on his face when Broomes imposed the stiff sentence and ordered the former bank chief taken into custody immediately, Mitchell said.</p><p>Mitchell said that for years he considered Hanes a "good guy," who like other people in Elkhart pitched in to help others in the small community when they needed help, and preached at his local church. Hanes also testified several times before Congress about community banking.</p><p>But prosecutors and bank regulators said that Hanes, who has three daughters with his school teacher wife, began stealing after being targeted in a pig-butchering scheme in late 2022.</p><p>That scheme was described in a court filing as "a scammer convincing a victim (a pig) to invest in supposedly legitimate virtual currency investment opportunities and then steals the victim's money — butchering the pig."</p><p>Hanes, who had served on the board of the American Bankers Association, and been chairman of the Kansas Bankers Association, in December 2022 began making transactions to buy cryptocurrency, which "appeared to be precipitated by communication with an unidentified co-conspirator on the electronic messaging app 'WhatsApp,' " prosecutors wrote in a court filing.</p><p>"To date, the true identity of the co-conspirator, or conspirators, remain unknown," the filing notes.</p><p>Hanes initially used personal funds to buy crypto, but in early 20233&nbsp;he stole $40,000 from Elkhart&nbsp;Church of Christ and $10,000 from the Santa Fe Investment Club, according to prosecutors and a defense filing.</p><p>He also used $60,000 taken from a daughter's college fund, and nearly $1 million in stock from the Elkhart Financial Corporation, his lawyer said in a filing.</p><p>In May 2023, he began to make wire transfers from Heartland Tri-State Bank to accounts controlled by scammers, at first with a $5,000 transfer.</p><p>Two weeks later, on May 30, Hanes wired $1.5 million and a day after that, he sent another transfer of the same amount the following day, filings show.</p><p>Three days later he directed two wire transfers totaling $6.7 million to be sent by the bank to the crypto wallet, and a whopping $10 million less than two weeks later, and another $3.3 million days afterward.</p><p>Hanes told bank employees to execute the wire transfers, and "made many misrepresentations to various people" to get access to the funds so they could be transferred, prosecutors wrote. Heartland Tri-State employees circumvented the bank's own wire policy and daily limits to approve Hanes' wire transfers, according to a report by the Office of the Inspector General of the Board of Governors of the Federal Reserve System.</p><p>"We believe that the CEO's dominant role in the bank and prominent role in the community contributed to a reluctance on the part of Heartland employees to question or report the alleged fraudulent activities earlier," that report said.</p><p>Prosecutors wrote that the series of 11 wire transfers from Hanes to the scammer "illustrate a common pattern" in pig-butchering schemes.</p><p>"First, there is an initial 'investment' followed by another transaction required to secure or guarantee those funds," prosecutors wrote. "Further 'investments' may be made, but always require another need for funds, to guarantee or unfreeze the earlier transfers. This pattern is clearly represented in the defendant's embezzlement."</p><p>Mitchell confirmed that to CNBC, saying that he got a call from Hanes at 7:40 a.m. on July 5, 2023.</p><p>"He said, 'Brian, 'I need your help, and you're the only guy who can help me,' " Mitchell recounted.</p><p>Mitchell, who had survived prostate cancer two decades ago, said he thought Hanes was calling him to say that he had the same type of cancer.</p><p>But when Mitchell showed up at Heartland Tri-State to meet Hanes, before the bank had officially opened to customers that morning, the CEO told him something much different — and stranger.</p><p>"The first thing he says is, 'Brian, I need to borrow $12 million for ten days, and I'll give you $1 million for loaning it to me,' " Mitchell recalled. "I'm sitting there and I said, am I in a bank in Elkhart, Kansas, or in an alley with a loan shark in Chicago."</p><p>When he asked Hanes what he wanted the money for, Hanes "pulls out his phone and acts like he's logging in and he shows me this account that has $40 million, $42 million," Mitchell said. "He said, 'Brian, I've got this money and it's in cryptocurrency, and I need $12 million to help verify the funds.' "</p><p>Hanes then hold him he had been in touch with a banker in Denver named "Jim" and "another guy in Oklahoma" and they had invested in crypto held in Coinbase accounts, where they had made a lot of money, Mitchell said.</p><p>"I told him, 'You're in a scam, dude. You're in a scam,' " Mitchell said. "I stopped him and said, 'Is this bank money you're playing with?' And he said, 'No, Brian.' "</p><p>Hanes kept telling him he needed the $12 million to "activate" the funds he had already transferred to the crypto account, which he said was in Hong Kong, Mitchell recalled.</p><p>"I said, 'Get on a plane, go to Hong Kong, hire an interpreter, and go get a bank check' " for the funds supposedly held there, Mitchell said. "Then I said, 'I'm not going to loan you the money.' I said, 'You're in a scam, walk away.'"</p><p>But later that same day, after Mitchell rebuffed his entreaties, Hanes had bank employees wire $8 million to the scammers' accounts, prosecutors said in a court filing.</p><p>Two days after that, Hanes had employees wire the scammers another $4.4 million.</p><p>In the meantime, Mitchell, who was unaware of those transfers during that period, said that after meeting with the CEO he was worried that Hanes would get access to customers' deposits at the bank and transfer the $12 million that he had asked for.</p><p>"We kept checking our lines of credit," Mitchell said.</p><p>"The next week, I was in the bank, and one of the employees caught me, she just looked so stressed," Mitchell said. The woman told him that Hanes had wired money out of the bank.</p><p>"I said, 'Don't say another word to me... I've got to talk to a board member,'" Mitchell said.</p><p>"And I talked to a board member that night, and he went to talk to an attorney that night," Mitchell recalled.</p><p>Hanes was fired within days.</p><p>About two weeks later, on July 28, 2023, Heartland Tri-State was closed by the Kansas Office of the State Bank Commissioner was taken over by the Federal Deposit Insurance Corp.</p><p>Shareholders were wiped out, but depositors did not lose any money, as Dream First Bank, National Association, of Syracuse, Kansas, assumed all deposits.</p><p>Heartland Tri-State had nearly $140 million in total assets and $130 million in total deposits as of the prior March.</p><p>Word quickly spread that a scam had led to the bank's failure, but Hanes' involvement in it did not come to light for months.</p><p>Hanes remained uncharged until last February when federal prosecutors accused him of embezzlement. He was separately charged in Morton County, Kansas, state court in a 28-count complaint related to looting the bank.</p><p>Hanes was under house arrest until his sentencing in federal court this week.</p><p>"I talked to him last month when he was out mowing his yard," Mitchell said.</p><p>Hanes, who had traveled at one point to Perth, Australia while being scammed to try to recover the funds he transferred, told Mitchell that he believed there had been a way to recover the money up to the point he was arrested.</p></div><div id="RegularArticle-RelatedContent-1"><h2>Read more CNBC politics coverage</h2><div><ul><li><a href="https://www.cnbc.com/2024/08/21/biden-dnc-harris-democrats-future-speeches.html">Biden gets few mentions from Democrats eager to turn the page at DNC day 2</a></li><li><a href="https://www.cnbc.com/2024/08/21/obama-says-america-is-ready-for-a-new-chapter-with-harris-walz.html">Obama says 'America is ready for a new chapter' with Harris, Walz</a></li><li><a href="https://www.cnbc.com/2024/08/20/arizona-montana-abortion-rights-constitutional-measures-on-ballots.html">Arizona, Montana put abortion rights constitutional measures on November ballots</a></li><li><a href="https://www.cnbc.com/2024/08/20/rfk-jr-campaign-trump-alliance-shanahan.html">RFK Jr. campaign eyes joining forces with Trump, running mate Shanahan says</a></li></ul></div></div><div><p>"He said ... 'If I just had another two months I could get the money back,'" Mitchell recalled.</p><p>Mitchell said that at Hanes' sentencing, Judge Broomes asked Hanes several questions about his actions, but, "He didn't really have any good answers."</p><p>Broomes later looked at the victims in the courtroom's gallery before announcing Hanes' sentence.</p><p>"He said ... 'I want you to forgive Shan. I know that he's hurt you, I know this, but I want you to move on, and I want you to find some joy in your life. Let me discipline him,'" Mitchell recalled.</p><p>Broomes also told Hanes that although several people had noted how intelligent the former CEO was, "If you were that intelligent you would have stopped this," Mitchell recounted.</p><p>Hanes' lawyer John Stang, who did not respond to a request for comment, in a sentencing submission wrote, "Mr. Hanes made some very bad choices after being caught up in an extremely well-run<br>cryptocurrency scam."</p><p>"He was the pig that was butchered," Stang wrote. "Mr. Hanes's vulnerability to the Pig Butcher scheme caused him to make some very bad decisions, for which he is truly sorry for causing damage to the bank and loss to the Stockholders."</p><p>Kansas U.S. Attorney Kate Brubacher, in a statement, said, "Hanes' greed knew no bounds. He trespassed his professional obligations, his personal relationships, and federal law."</p><p>"Not only did Shan Hanes betray Heartland Bank and its investors, but his illegal schemes also jeopardized confidence in financial institutions," Brubacher said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do low-level optimizations matter? Faster quicksort with cmov (2020) (140 pts)]]></title>
            <link>http://cantrip.org/sortfast.html</link>
            <guid>41314039</guid>
            <pubDate>Wed, 21 Aug 2024 20:42:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://cantrip.org/sortfast.html">http://cantrip.org/sortfast.html</a>, See on <a href="https://news.ycombinator.com/item?id=41314039">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

   <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   <meta name="viewport" content="width=device-width, user-scalable=no">
   <title></title>



<h3 id="do-low-level-optimizations-matter">Do Low-level Optimizations Matter?</h3>
<p><em>by Nathan Myers, ncm at cantrip dot org, 2020-01-09</em></p>
<p>Collectively, we have been thinking about sorting for longer than we have had computers. There is still an active literature <a href="#fn1" id="fnref1"><sup>1</sup></a>,<a href="#fn2" id="fnref2"><sup>2</sup></a>,<a href="#fn3" id="fnref3"><sup>3</sup></a>. We are taught that how the counts of comparisons and swaps vary with problem size is what matters: as problems get bigger, order dominates, and anything else is buried in the noise. We learn that the best in-place sorts run in time around <em>kN lg2(N)</em>, and a better sort algorithm has a smaller <em>k</em>, or is better-behaved for chosen input.</p>
<p>We ought to be able to sort pretty fast, by now, using a Standard Library sort. Sorting is real work: if you need it to go faster, you probably need to spend more on hardware. You can’t cheat on that.</p>
<p>Or can you? The classic sorting research was conducted on machines from many generations ago. While today’s are made to seem similar from the outside, inside they are very, very different. Do we still understand what affects sorting speed today? Maybe the rules have changed.</p>
<h3 id="laboratory">Laboratory</h3>
<p>Trying out ideas with Standard Library sort implementations can be tricky; as they have been tuned, they have become complicated. Results can be confusing. We need a laboratory: simple sorts, and simple data<a href="#fn4" id="fnref4"><sup>4</sup></a>. So, let us begin with a file of a hundred-million totally random integers:</p>
<pre><code>  $ dd if=/dev/urandom count=100 bs=4000000 of=1e8ints</code></pre>
<p>This is objectively the worst case, containing the greatest possible entropy; but also the best case, hiding no surprises. We can map this file into our process, and the OS will copy it from the file buffer cache, the work showing up as <code>sys</code> time. All the rest of the run time is spent on nothing but sorting.</p>
<p>Next, we need a baseline, using <code>std::sort</code>, for reference:</p>
<pre><code>  #include &lt;sys/mman.h&gt;
  #include &lt;fcntl.h&gt;
  #include &lt;algorithm&gt;

  static const int size = 100'000'000;

  int main(int, char**) {
    int fd = ::open("1e8ints", O_RDONLY);
    int perms = PROT_READ|PROT_WRITE;
    int flags = MAP_PRIVATE|MAP_POPULATE|MAP_NORESERVE;
    auto* a = (int*) ::mmap(
      nullptr, size * sizeof(int), perms, flags, fd, 0);

    std::sort(a, a + size);

    return a[0] == a[size - 1];
  }</code></pre>
<p>The <code>return</code> statement keeps the compiler from optimizing away the whole program. Trying it<a href="#fn5" id="fnref5"><sup>5</sup></a>:</p>
<pre><code>  $ g++ -O3 -march=native sort_base.cc &amp;&amp; time ./a.out

  real  0m7.365
  user  0m7.257
  sys   0m0.108s</code></pre>
<p>We see about <code>73ns</code> per element. <em>lg2(1e8)</em> is about 27, making <em>k</em> a bit less than <code>3ns</code>. Each time <code>std::sort</code> looks at an element, it spends, on average, <code>3ns</code>, presumably on shuffling it from memory to cache to register to ALU, and maybe back to cache and to memory. This happens 27 times before the element ends up where it belongs. (Nobody said, in school, that <em>k</em> has a unit, but for our purposes, it’s nanoseconds.)</p>
<h4 id="reality-check">Reality Check</h4>
<p>Just for a reality check, let’s plug in a radix sort. It is an unfair comparison, on several axes, but it suggests a hard upper bound on the kind of improvement we can reasonably hope for. This function distributes elements to one of 256 buckets, and then copies them back, in stable bucket order, and again for the next byte.</p>
<pre><code>  #include &lt;vector&gt;
  #include &lt;cstring&gt;

  void sort_radix256(unsigned* begin, unsigned* end) {
    std::vector&lt;int&gt; buckets[256];
    for (auto&amp; v : buckets) v.reserve((end - begin)/128);
    for (int byte = 0; byte != sizeof(unsigned); ++byte) {
      for (unsigned* p = begin; p != end; ++p) {
        buckets[*p &amp; 0xff].push_back((*p &gt;&gt; 8) | (*p &lt;&lt; 24));
      }
      unsigned* p = begin;
      for (auto&amp; v : buckets) {
        std::memcpy(p, v.data(), v.size() * sizeof(unsigned));
        p += v.size();
        v.clear();
  } } }

  - auto* a = (int*) ::mmap(
  + auto* a = (unsigned*) ::mmap(

  - std::sort(a, a + size);
  + sort_radix256(a, a + size);

  real  0m1.193s
  user  0m0.985s
  sys   0m0.208s</code></pre>
<p>We see the OS spending extra time initializing memory (two thirds of it to zeroes), because radix sorting is not done in place. The rest of the time is spent copying the input to buckets and back, four passes in all, <code>2.5ns</code> per element per pass. When you can use it, and for big enough N, radix sort always wins, because it’s O(N): in this case, 4N. Notably, the sequence of instructions is almost the same, no matter what the values of the elements are. All that varies is which bucket each element goes into.</p>
<p>This radix sort would be easy to make even faster. Instead, let us make one that is slower, but that shares important qualities with in-place sorts. Instead of 256 buckets, this will use just two. The first pass picks a bucket according to the low bit, the next pass uses the next bit, and on around.</p>
<pre><code>  void sort_radix2(unsigned* begin, unsigned* end) {
    std::vector&lt;unsigned&gt; a_buckets[2];
    for (auto&amp; v : a_buckets) v.reserve((end - begin)/3);
    int i = 0;
    for (; i &lt; (end - begin) / 2; ++i) a_buckets[0].push_back(begin[i]);
    for (; i &lt; (end - begin); ++i) a_buckets[1].push_back(begin[i]);

    std::vector&lt;unsigned&gt; b_buckets[2];
    for (auto&amp; v : b_buckets) v.reserve((end - begin)/3);

    for (int bit = 0; bit != 8 * sizeof(unsigned); ++bit) {
      for (int j = 0; j != 2; ++j) {
        for (unsigned v : a_buckets[j]) {
          b_buckets[v &amp; 0x1].push_back((v &gt;&gt; 1) | (v &lt;&lt; 31));
        }
      }
      std::swap(a_buckets[0], b_buckets[0]), b_buckets[0].clear();
      std::swap(a_buckets[1], b_buckets[1]), b_buckets[1].clear();
    }

    for (auto bucket : a_buckets)
      for (unsigned v : bucket) *begin++ = v;
  }

  - sort_radix256(a, a + size);
  + sort_radix2(a, a + size);

  real  0m4.759s
  user  0m4.543s
  sys   0m0.216s
</code></pre>
<p>It’s slower, because it examines each element 32 times. It’s not <em>N lg2(N)</em>, but <em>32N</em>. This <code>4.5s</code> is remarkably close to our <code>std::sort</code> baseline, <code>7.3s</code>. Maybe we can think of the difference between <code>4.5s</code> and our baseline as what we pay for the generality of <code>std::sort</code>? <em>32N</em> is not far from <em>27N</em>. Should we take <code>4.5s</code> <code>*</code> <em>27/32</em> <em>=</em> <code>3.8s</code> as an ultimate stretch goal?</p>
<h4 id="starting-point-quicksort">Starting Point: <code>quicksort</code></h4>
<p>Let’s see how well we can do with a regular sorting algorithm. Start by pasting in a bog-standard quicksort<a href="#fn6" id="fnref6"><sup>6</sup></a>:</p>
<pre><code>  int* partition(int* begin, int* end) {
    int pivot = end[-1];
    int* left = begin;
    for (int* right = begin; right &lt; end - 1; ++right) {
      if (*right &lt;= pivot) {
        int tmp = *left; *left = *right, *right = tmp;
        ++left;
      }
    }
    int tmp = *left; *left = end[-1], end[-1] = tmp;
    return left;
  }

  void quicksort(int* begin, int* end) {
    while (end - begin &gt; 1) {
      int* mid = partition(begin, end);
      quicksort(begin, mid);
      begin = mid + 1;
  } }

  - auto* a = (unsigned*) ::mmap(
  + auto* a = (int*) ::mmap(

  - radix_sort2(a, a + size);
  + quicksort(a, a + size);

  real  0m8.309s
  user  0m8.193s
  sys   0m0.116s</code></pre>
<p>This is really not bad. The <code>std::sort</code> in the standard library, at <code>7.3s</code>, is a lot more code than we see here, but it has to perform well on tricky cases we won’t be testing.</p>
<h4 id="what-is-new">What Is New?</h4>
<p>What is different in modern CPUs from the machines the algorithms we use were originally tuned for? Well, lots. Today they have up to a half-billion transistors per core, not just the thousands originally used to execute a notably similar instruction set. (Imagine, in each generation, being asked to find a way to use another million, ten million, hundred million! more transistors, to get better benchmark times.)</p>
<p>We have many more caches, registers, instruction decoders, and functional units–barrel shifters, multipliers, ALUs<a href="#fn7" id="fnref7"><sup>7</sup></a>. There’s even a little just-in-time compiler, <em>in hardware</em>, to translate complex-instruction sequences into simpler ones, with its own peephole optimizer, and a cache of its output. A small-enough loop can execute entirely from that cache.</p>
<p>One thing wholly new is the <em>branch predictor</em><a href="#fn8" id="fnref8"><sup>8</sup></a>. Technically, it’s another cache, one that accumulates a history of which way was chosen on each of the last M conditional branch points encountered during execution. (The number M is secret.) Branch prediction matters because of something else that’s wholly new: <em>speculative execution</em><a href="#fn9" id="fnref9"><sup>9</sup></a>.</p>
<p>When regular execution needs to stop and wait on a result, speculative execution can run on ahead, stuffing pipelines with work from upcoming loop iterations. Because the values needed to decide which way a conditional branch will go haven’t been computed yet, it has to <em>guess</em>, based on the pattern of what has happened before at that instruction address. When the branch predictor guesses wrong, a lot of work may need to be discarded, but whenever it guesses right, that work has already been done when regular execution gets there.</p>
<p>These days, often, most of the work gets done speculatively, so it is vitally important to guess right. Branch predictors have become astonishingly good at discovering patterns in our code, and guessing right. Nowadays, they use a neural net to identify such patterns; the branch prediction cache holds sets of coefficients for the neural net.</p>
<p>Branching on random data, though, is the worst case for any branch predictor, no matter how smart, because it can never find more regularity than the data has. Here, it guesses wrong half the time, and work is done and then discarded. The pipelines never fill, and functional units sit idle.</p>
<h4 id="adaptation">Adaptation</h4>
<p>If we want to better adapt our algorithm to the way a modern CPU works, we need to protect speculative execution against randomness in our data. Our only available course is to eliminate conditional branches that depend on that data.</p>
<p>So, let’s see what our conditional branches are doing. In this quicksort, there are only three conditional branches.</p>
<p>The first check, at the top of <code>quicksort</code> itself:</p>
<pre><code>    while (end - begin &gt; 1) {</code></pre>
<p>detects when recursion has bottomed out. It evaluates to <code>true</code> half the time, on a complicated schedule, but it is evaluated only about N times, and hardly depends on the input.</p>
<p>The second:</p>
<pre><code>    for (int* right = begin; right &lt; end - 1; ++right) {</code></pre>
<p>controls the loop in <code>partition</code> that walks through a subrange of the input. It runs about <em>N lg2(N)</em> times, but usually it’s taken. It, too, doesn’t depend much on input values. It gets hard to predict only when <code>begin</code> is very close to <code>end</code>, a small multiple of N times.</p>
<p>The third conditional branch:</p>
<pre><code>      if (*right &lt;= pivot) {</code></pre>
<p>happens <em>N lg2(N)</em> times, too, but it depends directly on the values of elements in the input, <em>every time</em>. To prevent missed branch predictions, we must find a way to avoid that branch. We need identically the same sequence of instructions executed in the true <em>and</em> the false case–and just have <em>nothing change</em>, in the false case.</p>
<p>The portable way to do this is to turn the result of the comparison into a regular value, and then do ordinary arithmetic with it. Sometimes, we can use the boolean value itself, as is. Perhaps the simplest possible example is:</p>
<pre><code>  if (a &lt; b) ++i;</code></pre>
<p>which can always be transformed, via conversion to <code>int</code>, to:</p>
<pre><code>  i += (a &lt; b);</code></pre>
<p>A more general method is to convert the boolean value into a mask value, of all zeroes or all ones. Then we can use bitwise operations to produce different results for the all-zeroes and the all-ones cases. For a slightly more complicated example, here we add up two seconds/nanoseconds pairs:</p>
<pre><code>  secs = secs1 + secs2, nsecs = nsecs1 + nsecs2;
  if (nsecs &gt;= 1'000'000'000) {
    ++secs, nsecs -= 1'000'000'000;
  }</code></pre>
<p>This transforms to:</p>
<pre><code>  secs = secs1 + secs2, nsecs = nsecs1 + nsecs2;
  int carry = (nsecs &gt;= 1'000'000'000);
  secs += carry, nsecs -= ((-carry) &amp; 1'000'000'000);</code></pre>
<p>With a carry, <code>(-carry)</code> is 111…111, and it subtracts a billion; with no carry, <code>(-carry)</code> is zero, and it subtracts zero.</p>
<h4 id="a-new-primitive-swap_if">A New Primitive, <code>swap_if</code></h4>
<p>How can we use this method in our sort? First, let us make a <code>swap_if</code>:</p>
<pre><code>  inline bool swap_if(bool c, int&amp; a, int&amp; b) {
    int ta = a, mask = -c;  // false -&gt; 0, true -&gt; 111..111
    a = (b &amp; mask) | (ta &amp; ~mask);
    b = (ta &amp; mask) | (b &amp; ~mask);
    return c;
  }</code></pre>
<p>In our <code>partition</code> function, then, we can transform</p>
<pre><code>    if (*right &lt;= pivot) {
      int tmp = *left; *left = *right, *right = tmp;
      ++left;
    }</code></pre>
<p>into just</p>
<pre><code>    left += swap_if(*right &lt;= pivot, *left, *right);</code></pre>
<p>This expands to more code, and all of it runs on every iteration, not just half of them, as before. But now, there is no branch to predict, or to mis-predict. It is just straight-line code.</p>
<p>Trying it:</p>
<pre><code>  $ g++ -O3 -march=native sort_swap_if.cc &amp;&amp; time ./a.out

  real  0m5.792s
  user  0m5.679s
  sys   0m0.112s</code></pre>
<p>This is excellent! <code>5.7s</code> is 1.44x better than before, and 1.29x as fast as <code>std::sort</code>.</p>
<p>Another way to make a value control what happens is indexing. (We have already seen an example of this, in the second radix sort presented above.) The boolean value is used as an array index:</p>
<pre><code>    int v[2] = { a, b };
    b = v[1-c], a = v[c];

  real  0m4.576s
  user  0m4.459s
  sys   0m0.116s</code></pre>
<p>Even better! This is 1.84x as fast as the naïve quicksort, even though the values have to take a detour through L1 cache so they can have addresses. This version is easily generalized to types that are not just a machine word:</p>
<pre><code>  template &lt;typename T&gt;
  bool swap_if(bool c, T&amp; a, T&amp; b) {
    T v[2] = { std::move(a), std::move(b) };
    b = std::move(v[1-c]), a = std::move(v[c]);
    return c;
  }</code></pre>
<p>When <code>T</code> is <code>int</code>, compilers generate identical code for the template version,</p>
<p>For completeness, there is also:</p>
<pre><code>    uint64_t both = (uint64_t(uint32_t(a)) &lt;&lt; 32) | uint32_t(b);
    int shift = c * 32;
    both = (both &lt;&lt; shift) | (both &gt;&gt; (64 - shift));
    a = int(uint32_t(both &amp; 0xffffffff)), b = int(both &gt;&gt; 32);</code></pre>
<p>The line with the shifts turns into a single “rotate” instruction. But this is not faster than the indexed version: it runs in <code>4.8s</code>.</p>
<h4 id="cmov-considered-disturbing"><code>cmov</code> Considered Disturbing</h4>
<p>How does the first, “and-and-or”, version do on Clang:</p>
<pre><code>  $ clang++ -O3 -march=native sort_swap_if.cc &amp;&amp; time ./a.out

  real  0m3.551s
  user  0m3.430s
  sys   0m0.120s</code></pre>
<p><em>HOLY CRAP! <code>3.4s</code>? What just happened?</em></p>
<p>Weren’t we just guessing that <code>3.8s</code> was as fast as we should ever hope to get? This is 2.4x as fast as quicksort, and more than 2x as fast as <code>std::sort</code>! This raises <em>so many</em> questions.</p>
<p>First, why the big difference between G++ and Clang? A quick detour through Godbolt<a href="#fn10" id="fnref10"><sup>10</sup></a> reveals what is going on. G++ actually generated the four “<code>and</code>”, and two “<code>or</code>” instructions seen in <code>swap_if</code>. But Clang’s optimizer recognized what we were trying to do with the masks, and replaced it all with a pair of simple <code>cmov</code>, conditional-move, instructions. (On top of that, it unrolled the loop in <code>partition</code>.)</p>
<p>What is the <code>cmov</code> instruction? It has been in ARM forever. Back in 2000, AMD included <code>cmov</code> in its 64-bit x86 ISA extensions. Then, Intel had to adopt them when Itanium flopped.</p>
<p><code>cmov</code> just copies a value from one place to another–register to register, register to memory, memory to register–but <em>only if</em> a condition-code flag has been set, such as by a recent comparison instruction. Since <code>cmov</code> replaces a conditional branch, the result of the comparison doesn’t need to be predicted. The execution unit doesn’t know <em>which</em> value it will end up with, but it knows where it will be, and can schedule copying that out to cache, and eventually memory, and run on ahead, without discarding anything.</p>
<p>Why doesn’t G++ generate <code>cmov</code> instructions? Older releases did, in fact, often enough to generate bug reports<a href="#fn11" id="fnref11"><sup>11</sup></a>. It turned out that, any time a subsequent loop iteration depends on the result, and the branch would have been predicted correctly, <code>cmov</code> may be slower than a branch, sometimes <em>much</em> slower. <code>cmov</code> can stall speculation all by itself.</p>
<p>The latest designs from Intel and AMD are said to avoid the <code>cmov</code> pipeline stall, often, but Gcc has not caught up with them yet.</p>
<p>For more on <code>cmov</code> and pessimization in G++, follow links in <a href="#fn12" id="fnref12"><sup>12</sup></a>.</p>
<p>In this case, though, nothing later depends on the result–it just gets stored, and the loop moves on–so this is a poster-child case for using <code>cmov</code>.</p>
<p>Clang, it turns out, can turn a simpler definition of <code>swap_if</code> into <code>cmov</code> instructions:</p>
<pre><code>    int ta = a, tb = b;
    a = c ? tb : ta;
    b = c ? ta : tb;</code></pre>
<p>But for this, G++ just generates a badly-predicted branch. I have not discovered a way to persuade G++ to produce <code>cmov</code> instructions (not even in old releases, and not even with the new <code>__builtin_expect_with_probability</code> intrinsic, probability 0.5). Even “profile-guided optimization” doesn’t help. (In the Linux kernel, wherever a <code>cmov</code> is needed, a macro expands directly to assembly code.) Looking into G++, it appears that it refuses to emit a <code>cmov</code> if anything else follows it in the “basic block”, even if what follows ought to be another <code>cmov</code> <a href="#fn13" id="fnref13"><sup>13</sup></a>.</p>
<h4 id="faster-than-pessimized-radix-sort">Faster Than (Pessimized) Radix Sort?</h4>
<p>Another big question: how could the Clanged version be even faster than our target time? This might come back to <code>cmov</code>, again. Radix sort always performs the same number of copy operations. So, also, do our first three versions of <code>swap_if</code>, as compiled by G++. But with <code>cmov</code>, only <em>half</em> of the swap operations end up needing to copy the pair of words out to L1 cache<a href="#fn14" id="fnref14"><sup>14</sup></a>,<a href="#fn15" id="fnref15"><sup>15</sup></a>, and thereby, perhaps, delay reading the next pair from it. There may be other reasons: radix sort sweeps majestically, sequentially through the whole sequence, relying on the prefetcher to keep ahead of it, while quicksort spends much of its time noodling around with values in L1 cache.</p>
<p>In the original quicksort, <em>k</em> was almost <code>3ns</code>, but now it is just <code>1.3ns</code>. More than <em>half</em> of the time we thought was being spent on honest computation was wasted, sitting stalled on branch mis-predictions! Who knows how much is still wasted? (Actually, the CPU knows: it keeps a count of how many of various cache misses happened, and you can read those out, given some care, with <code>perf</code><a href="#fn16" id="fnref16"><sup>16</sup></a>.)</p>
<h4 id="next">Next</h4>
<p>What can we do with what we’ve discovered? Sure, we can make our own programs faster, particularly if we are using Clang. But it would be better if we could make all programs faster.</p>
<p>We could propose a new library function, <code>std::swap_if</code>. Then, implementers could ensure it uses <code>cmov</code> for machine-word types (including pointers and floating-point values, and even small objects like <code>std::string_view</code>), and use it in their sorting and partitioning code. We could use it in our own programs, too. But for it to do much good, we would need to get it into a Standard, and then persuade many people to change a lot of code.</p>
<p>The experience with Clang’s optimizer hints at an alternative: Why can’t compilers recognize the sequence we did, and perform their own transformation?</p>
<p>This would be way better; just recompile, and all code gets faster, some a <em>lot</em> faster, with no need to rewrite any of it. The <code>std::sort</code> implementions in libstdc++ and libc++ are quite a bit more complicated than our toy quicksort, but maybe a compiler could spot places to transform that look unpromising to us.</p>
<p>Getting this optimization into compilers depends on those few who can add a new optimization to G++’s or Clang’s code generator taking time away from other optimization work. Doesn’t a 2x improvement over current <code>std::sort</code> automatically deserve that kind of attention? But it might not be so easy: too often, <code>cmov</code> is <em>slower</em>. The optimizer doesn’t just need to recognize when it <em>could</em> substitute <code>cmov</code> for a branch, it needs to decide whether it <em>should</em>.</p>
<p>While the optimizer knows whether anything depends on the result, it doesn’t know whether the input would have patterns that the branch predictor could tease out. Such an optimization would need a great deal of testing to ensure it doesn’t pessimize (too much) code.</p>
<p>Still, Clang, at least, seems to be all-in on plugging in <code>cmov</code> where it seems to make sense. It just needs to learn to recognize the conditionally-swapping and the conditionally-incrementing cases. It should be able to compose those into the transformation used here, and thence to <code>cmov</code>.</p>
<h4 id="conclusion">Conclusion</h4>
<p>What can we conclude from this discovery? Before we conclude anything, we should remind ourselves of its limitations. The tests run were on completely random data. Truly random data seldom occurs in real life. If there is a pattern in the data, the branch predictor might be able to find and exploit it. Shouldn’t it get that chance, sometimes?</p>
<p>Furthermore, the idea was tested on only the simplest possible elements, where both comparing and swapping were as cheap as they ever can be. While sorting word-sized objects is still an important use case, real sorting problems often have very different time budgets. We never changed the number or kind of comparisons performed, but the first big improvements doubled the number of copies; then the final improvement halved them again. A copy is a quarter or a third of a swap, but a dramatic change in their number had comparatively little effect on run time.</p>
<p>For many object types, the self-moves seen in the simplest, conditional-expression <code>swap_if</code> version are not permitted. For a production library, we might need to specialize on whether self-moves are allowed.</p>
<p>Our deep takeaway might be that counting comparisons and swaps ignores what are, today, the actually expensive operations: cache misses, of all kinds. Despite the millions of transistors devoted to the task, caches miss, sometimes systematically. Any time the number of misses, of all kinds, is not directly proportional to the number of operations counted, an analysis may produce the wrong answer, and lead us to bad choices.</p>
<p>But a lesson for the working programmer might be that, sometimes, you know the problem better than the compiler or cache systems, and measuring can lead you to simple code changes<a href="#fn17" id="fnref17"><sup>17</sup></a> that avoid costly misses, with sometimes dramatic results.</p>
<h4 id="recommendations">Recommendations</h4>
<p>Do these results suggest improvements to our Standard Library?</p>
<p>In C++, a factor of two in performance matters. We need two versions of each of the Standard sort, partition, binary search, merge, and heap algorithms that constitute nearly half of <code>&lt;algorithm&gt;</code><a href="#fn18" id="fnref18"><sup>18</sup></a>: one set that shields the branch predictor, and a second set that exposes the branch predictor to any patterns it can tease out. But this does <em>not</em> mean we need that many new named library functions! Instead, we can bind the choice to an optional property of the comparison predicate. The default should be to shield the branch predictor, at least for small types, because the consequence of failing to protect it can be so severe.</p>
<p>A branchless <code>std::swap_if</code> would be good to have in the Standard Library<a href="#fn19" id="fnref19"><sup>19</sup></a>, even after optimizers learn to generate it themselves, because optimizers are sometimes too cautious. We should consider carefully, also, whether <code>std::count_if</code> merits attention.</p>
<h4 id="more-to-come">More to Come</h4>
<p>Is that everything? Just the one weird trick?</p>
<p>No! This was <em>just one example</em>. Modern CPU chips are packed to the rafters with dodgy gimcracks. They have pre-fetchers, micro-op caches with micro-op fusion, register renaming, a shadow return-address stack, pipelines everywhere, atomic interlocks, translation lookaside buffers, hugepages, vector units. Caches collude with one another over private buses.</p>
<p>It all makes many programs go faster than they have any business going, but not necessarily <em>your</em> program. A better algorithm is no longer enough to get top performance; your program needs to join in the dance of the million-transistor accelerators. Anybody who insists C is close to the machine is, at best, deluded.</p>
<p>Can the dance of the gimcracks drive <em>k</em> south of one nanosecond? Stay tuned<a href="#fn20" id="fnref20"><sup>20</sup></a>.</p>
<p>Finally: If you control a budget, and depend on the performance of software, it might be a good use of that budget to help improve compilers and standard libraries in the ways suggested.</p>
<p><em>The author thanks Andrei Alexandrescu for a most thorough and helpful review of an early, and very different, draft of this article.</em></p>
<section>
<hr>
<ol>
<li id="fn1"><p><a href="https://arxiv.org/abs/1811.01259">https://arxiv.org/abs/1811.01259</a><a href="#fnref1">↩</a></p></li>
<li id="fn2"><p><a href="https://arxiv.org/abs/1810.12047">https://arxiv.org/abs/1810.12047</a><a href="#fnref2">↩</a></p></li>
<li id="fn3"><p><a href="https://arxiv.org/abs/1604.06697">https://arxiv.org/abs/1604.06697</a><a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="https://gitlab.com/ncmncm/sortfast/">https://gitlab.com/ncmncm/sortfast/</a><a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>Programs were run an an i7-7820X SkylakeX.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>I call this bog-standard, but the quicksorts most easily found online are always oddly pessimized, both more complicated <em>and</em> slower. This one uses the “Lomuto partition”, which is simpler than Hoare’s.)<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p><a href="https://www.agner.org/optimize/microarchitecture.pdf">https://www.agner.org/optimize/microarchitecture.pdf</a><a href="#fnref7">↩</a></p></li>
<li id="fn8"><p><a href="https://danluu/branch-prediction/">https://danluu/branch-prediction/</a><a href="#fnref8">↩</a></p></li>
<li id="fn9"><p><a href="https://en.wikipedia.org/wiki/Speculative_execution">https://en.wikipedia.org/wiki/Speculative_execution</a><a href="#fnref9">↩</a></p></li>
<li id="fn10"><p><a href="https://godbolt.org/z/k4iZAB">https://godbolt.org/z/k4iZAB</a><a href="#fnref10">↩</a></p></li>
<li id="fn11"><p><a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56309">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=56309</a><a href="#fnref11">↩</a></p></li>
<li id="fn12"><p><a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=85559">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=85559</a><a href="#fnref12">↩</a></p></li>
<li id="fn13"><p><a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=93165">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=93165</a><a href="#fnref13">↩</a></p></li>
<li id="fn14"><p><a href="https://gist.github.com/jboner/2841832">https://gist.github.com/jboner/2841832</a><a href="#fnref14">↩</a></p></li>
<li id="fn15"><p><a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.957">https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.957</a><a href="#fnref15">↩</a></p></li>
<li id="fn16"><p><a href="http://www.brendangregg.com/perf.html">http://www.brendangregg.com/perf.html</a><a href="#fnref16">↩</a></p></li>
<li id="fn17"><p><a href="https://www.agner.org/optimize/optimizing_cpp.pdf">https://www.agner.org/optimize/optimizing_cpp.pdf</a><a href="#fnref17">↩</a></p></li>
<li id="fn18"><p><a href="https://en.cppreference.com/w/cpp/algorithm">https://en.cppreference.com/w/cpp/algorithm</a><a href="#fnref18">↩</a></p></li>
<li id="fn19"><p><a href="https://cantrip.org/swap_if.pdf">https://cantrip.org/swap_if.pdf</a><a href="#fnref19">↩</a></p></li>
<li id="fn20"><p>Little optimization pun there.<a href="#fnref20">↩</a></p></li>
</ol>
</section>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euclid's Proof that √2 is Irrational (145 pts)]]></title>
            <link>https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html</link>
            <guid>41314031</guid>
            <pubDate>Wed, 21 Aug 2024 20:39:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html">https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html</a>, See on <a href="https://news.ycombinator.com/item?id=41314031">Hacker News</a></p>
Couldn't get https://www.mathsisfun.com/numbers/euclid-square-root-2-irrational.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[US hospital told family their daughter had checked out when in fact she'd died (355 pts)]]></title>
            <link>https://www.theguardian.com/us-news/article/2024/aug/21/sacramento-hospital-patient-death-checked-out</link>
            <guid>41313740</guid>
            <pubDate>Wed, 21 Aug 2024 20:07:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/us-news/article/2024/aug/21/sacramento-hospital-patient-death-checked-out">https://www.theguardian.com/us-news/article/2024/aug/21/sacramento-hospital-patient-death-checked-out</a>, See on <a href="https://news.ycombinator.com/item?id=41313740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Jessie Peterson’s family spent a year searching for her after they were told that she had checked herself out of a <a href="https://www.theguardian.com/us-news/california" data-link-name="in body link" data-component="auto-linked-tag">California</a> hospital against medical advice – before they learned that she had been dead all along.</p><p>The 31-year-old died in the care of Mercy San Juan medical center in Sacramento in April 2023. The hospital shipped her body to a storage facility and did not inform her mother and sisters. The family only learned her fate the following April after months of trying to find her, according to a civil lawsuit against the hospital.</p><p>In the lawsuit, filed earlier this month, the family described the hospital’s conduct as “malicious and outrageous” and accused the facility of negligence, the negligent handling of a corpse and negligent infliction of emotional distress.</p><p>“Mercy San Juan hospital failed in its most fundamental duty to notify Jessie’s family of her death,” the lawsuit states. “Mercy San Juan stored<strong> </strong>Jessie in an off-site warehouse morgue and she was left to decompose for nearly a year while her family relentlessly inquired about her whereabouts.”</p><p>Peterson, whom her family described in the lawsuit as “loving and energetic”, had type 1 diabetes. She was experiencing a diabetic episode when she was admitted to Mercy San Juan on 6 April 2023. Her mother, Ginger Congi, stated that Peterson had called her two days later asking for a ride because she would be leaving the hospital, according to the lawsuit.</p><p>Congi was later told that Peterson had left the hospital against medical advice, and her medical records indicate she was discharged on 8 April. After her sudden disappearance, the family spent months “relentlessly” searching for her, posting flyers, speaking with unhoused residents in the area, and contacting police and the coroner’s office, according to the lawsuit.</p><p>On 12 April 2024, more than a year after Peterson was last seen, the Sacramento county detective’s office informed the family that she had been found dead at Mercy San Juan, the suit states. According to her death certificate, which was completed in April 2024, Peterson died of cardiopulmonary arrest at age 31.</p><figure id="4fa9fbba-5a61-436c-a35b-3aac46440d98" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Outside of building." src="https://i.guim.co.uk/img/media/40cc543f18f79dd497ebea63faf0894d5fa95c2e/0_405_6016_3611/master/6016.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.10355718085106" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Mercy medical center.</span> Photograph: Chris Allan/Alamy</figcaption></figure><p>Peterson’s sister went to the coroner’s office seeking her remains, but a worker told her that the office did not have Peterson’s body and directed her to contact the hospital. Mercy San Juan was not responsive to efforts to contact them, according to the lawsuit, and a mortuary eventually informed Congi that Peterson’s body had been found in one of the hospital’s off-site storage facilities.</p><p>Her body was so decomposed the family could not obtain her fingerprints or hold an open casket funeral, and an autopsy that could have indicated whether there had been medical malpractice associated with her death was “rendered impossible”, according to the lawsuit.</p><p>“Defendants’ failure to issue a timely certificate of death, failure to notify Jessie’s next of kin, failure to allow an autopsy, and mishandling of Jessie’s remains [was] negligent, careless, and heartless,” the lawsuit states. “Defendants violated their own promise of dignity and respect for the people in their care. Defendants’ conduct is so egregious and malicious to shock the conscious and punitive damages should be awarded.”</p><p>The family is seeking more than $5m in damages, as well as “five times the jury’s award of actual damages to punish defendants for their outrageous and inexcusable negligence” and attorneys’ fees.</p><p>Dignity Health, which operates Mercy San Juan, said in a statement: “We extend our deepest sympathies to the family during this difficult time. We are unable to comment on pending litigation.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Breaking down a record-setting day on the Texas grid (194 pts)]]></title>
            <link>https://blog.gridstatus.io/a-record-setting-day-in-ercot/</link>
            <guid>41313290</guid>
            <pubDate>Wed, 21 Aug 2024 19:18:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.gridstatus.io/a-record-setting-day-in-ercot/">https://blog.gridstatus.io/a-record-setting-day-in-ercot/</a>, See on <a href="https://news.ycombinator.com/item?id=41313290">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        

            <p>Market highlights and explanations from a day of records in ERCOT.</p>

        


    </div><section>
        <p>On August 20th, 2024, The Electric Reliability Council of Texas (<a href="https://www.gridstatus.io/live/ercot?ref=blog.gridstatus.io" rel="noreferrer">ERCOT</a>) saw records for demand, solar generation, net load, and battery discharge alongside <a href="https://www.gridstatus.io/map?t=1724201100&amp;node=CALAVER_JTD2&amp;zoom=6.50&amp;center=-98.32030%2C29.80972&amp;ref=blog.gridstatus.io" rel="noreferrer">prices near the cap</a>; a prime example of how operations in the market are evolving.</p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024.png 960w" sizes="(min-width: 720px) 720px"></figure><h2 id="solar-and-demand-were-high-throughout-the-day">Solar and Demand Were High Throughout the Day</h2><p>Solar generation was high all day, keeping prices under control even through the record-setting peak load. However, as solar ramped down and the proportion low marginal cost resources on the grid was reduced and prices began to take off.</p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--1--1.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024--1--1.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--1--1.png 960w" sizes="(min-width: 720px) 720px"></figure><p>As the resource mix has evolved, high prices correlate more to high net load rather than gross load. Net load is demand that must be met by resources with a higher marginal cost. Because load remained high as the sun set ERCOT began to call on more resources with fuel costs and higher O&amp;M components, eventually reaching the upper echelon of energy prices from peaking units. </p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--2-.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024--2-.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--2-.png 960w" sizes="(min-width: 720px) 720px"></figure><h2 id="batteries-and-prices-hit-their-peaks">Batteries and Prices Hit Their Peaks</h2><p>Shattering the previous record, battery discharge peaked 20% higher than the previous record, which was set only the day before. The fulsome deployment of ECRS contributed to juicing battery discharge above and beyond the previous peak. </p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--3-.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024--3-.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--3-.png 960w" sizes="(min-width: 720px) 720px"></figure><p>The Hub average fifteen-minute settlement point price (SPP) nearly reached the $5,000 bid cap. ERCOT’s ORDC also contributed to sustained high prices. The ORDC adders were a major contributor to price action in 2021 and 2022, but were greatly reduced in 2023 and have been largely absent so far in 2024 due to changes in the ancillary services market and how ERCOT handles tight situations.</p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--4-.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024--4-.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--4-.png 960w" sizes="(min-width: 720px) 720px"></figure><h2 id="tight-on-capacity-without-conservation">Tight on Capacity Without Conservation</h2><p>Physical Responsive Capacity (PRC) and capacity available to SCED within 5 minutes declined significantly despite 2,000 MW of extra capacity released from ECRS. </p><p>Despite the demand, prices, and ancillary deployments, ERCOT didn't issue a general call for conservation, indicating its operators were confident that the grid had sufficient resources to make it through the net load peak.</p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--7-.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024--7-.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--7-.png 960w" sizes="(min-width: 720px) 720px"></figure><p>Yesterday set a number of <a href="https://www.gridstatus.io/records/ercot?ref=blog.gridstatus.io" rel="noreferrer">records</a> at or near the top of the ERCOT leaderboards. While we may not see another load record this summer, solar generation could still set new peaks and an unexpected grid event at any time could trigger another coordinated response from batteries.</p><figure><img src="https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--6-.png" alt="" loading="lazy" width="960" height="540" srcset="https://blog.gridstatus.io/content/images/size/w600/2024/08/ERCOT-Recap-8.19-8.20.2024--6-.png 600w, https://blog.gridstatus.io/content/images/2024/08/ERCOT-Recap-8.19-8.20.2024--6-.png 960w" sizes="(min-width: 720px) 720px"></figure>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Linux desktop market share climbs to 4.45% (329 pts)]]></title>
            <link>https://ostechnix.com/linux-market-share-july-2024-report/</link>
            <guid>41312883</guid>
            <pubDate>Wed, 21 Aug 2024 18:32:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ostechnix.com/linux-market-share-july-2024-report/">https://ostechnix.com/linux-market-share-july-2024-report/</a>, See on <a href="https://news.ycombinator.com/item?id=41312883">Hacker News</a></p>
Couldn't get https://ostechnix.com/linux-market-share-july-2024-report/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Turnstyle – An esoteric, graphical functional language (116 pts)]]></title>
            <link>https://jaspervdj.be/posts/2024-08-21-turnstyle.html</link>
            <guid>41312521</guid>
            <pubDate>Wed, 21 Aug 2024 17:49:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jaspervdj.be/posts/2024-08-21-turnstyle.html">https://jaspervdj.be/posts/2024-08-21-turnstyle.html</a>, See on <a href="https://news.ycombinator.com/item?id=41312521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
    
<p>
    An esoteric, graphical functional language<br>
    Published on August 21, 2024 under the tag <a title="All pages tagged 'haskell'." href="https://jaspervdj.be/tags/haskell.html">haskell</a>
</p>

<p>I am delighted and horrified to announce a new graphical programming language
called <a href="https://jaspervdj.be/turnstyle/">Turnstyle</a>. You can see an example below (click to run).</p>

<p><img src="https://jaspervdj.be/images/2024-08-21-turnstyle-loop.svg"></p>
<hr>
<p>In the time leading up to <a href="https://zfoh.ch/zurihac2024">ZuriHac 2024</a> earlier this year, I had been thinking
about <a href="https://www.dangermouse.net/esoteric/piet.html">Piet</a> a little. We ended up working on something else during the
Hackathon, but this was still in the back of my mind.</p>
<p>Some parts of Piets design are utter genius (using areas for number literals,
using hue/lightness as cycles). There are also things I don’t like, such as the
limited amount of colors, the difficulty reusing code, and the lack of a
way to extend it with new primitive operations. I suspect these are part of the
reason nobody has yet tried to write, say, an RDBMS or a web browser in Piet.</p>
<p>Given the amount of attention going to programming languages in the functional
programming community, I was quite surprised nobody had ever tried to do a
functional variant of it (as far as I could find).</p>
<p>I wanted to create something based on Lambda Calculus. It forms a nice basis
for a minimal specification, and I knew that while code would still be somewhat
frustrating to write, there is the comforting thought of being able to reuse
almost everything once it’s written.</p>
<figure>
<img src="https://jaspervdj.be/images/2024-08-21-turnstyle-cheatsheet.svg" alt="Cheatsheet for the specification">

</figure>
<p>After playing around with different designs this is what I landed on. The
guiding principle was to search for a specification that was as simple as
possible, while still covering lambda calculus extended with primitives that,
you know, allow you to interact with computers.</p>
<p>One interesting aspect that I discovered (not invented) is that it’s actually
somewhat more expressive than Lambda Calculus, since you can build Abstract
Syntax Graphs (rather than just Trees). This is illustrated in the loop example
above, which recurses without the need for a fixed-point combinator.</p>
<p>For the full specification and more examples take a look at the <a href="https://jaspervdj.be/turnstyle/">Turnstyle
website</a> and feel free to play around with the sources on <a href="https://github.com/jaspervdj/turnstyle/">GitHub</a>.</p>
<p>Thanks to <a href="https://mazzo.li/">Francesco Mazzoli</a> for useful feedback on the
specification and website.</p>




    

    
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kill the Newsletter: Convert email newsletters into Atom feeds (103 pts)]]></title>
            <link>https://kill-the-newsletter.com/</link>
            <guid>41312259</guid>
            <pubDate>Wed, 21 Aug 2024 17:15:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kill-the-newsletter.com/">https://kill-the-newsletter.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41312259">Hacker News</a></p>
<div id="readability-page-1" class="page"><div key="/" css="evihcnjzizuqad">
          <div>
            
            <p css="ctcpaefngdseol">
              <small>Convert email newsletters into Atom feeds</small>
            </p>
          </div>
          
          
          <p>
            <small>
              <a href="https://leafac.com/">By Leandro Facchinetti</a>&nbsp;|
              <a href="https://github.com/leafac/kill-the-newsletter">Source</a>&nbsp;|
              <a href="mailto:kill-the-newsletter@leafac.com">Report Issue</a>&nbsp;|
              <a href="https://patreon.com/leafac">Patreon</a>&nbsp;·
              <a href="https://paypal.me/LeandroFacchinettiEU">PayPal</a>&nbsp;·
              <a href="https://github.com/sponsors/leafac">GitHub Sponsors</a>
            </small>
          </p>
          <hr>
          <div>
            <h2>How does Kill the Newsletter! work?</h2>
            <p>
              Create a feed with the form above and Kill the Newsletter!
              provides you with an email address and an Atom feed. Emails that
              are received at that address are turned into entries in that feed.
              Sign up to a newsletter with that address and use your feed reader
              to subscribe to that feed.
            </p>
          </div>
          <div>
            <h2>How do I confirm my newsletter subscription?</h2>
            <p>
              In most cases when you subscribe to a newsletter the newsletter
              publisher sends you an email with a confirmation link. Kill the
              Newsletter! converts that email into a feed entry as usual, so it
              appears in your feed reader and you may follow the confirmation
              link from there. Some newsletter publishers want you to reply to
              an email using the address that subscribed to the newsletter.
              Unfortunately Kill the Newsletter! doesn’t support this scenario,
              but you may contact the newsletter publisher and ask them to
              verify you manually. As a workaround, some people have had success
              with signing up for the newsletter using their regular email
              address and setting up a filter to forward the emails to Kill the
              Newsletter!
            </p>
          </div>
          <div>
            <h2>
              Why can’t I subscribe to a newsletter with my Kill the Newsletter!
              email?
            </h2>
            <p>
              Some newsletter publishers block Kill the Newsletter!. You may
              contact them to explain why using Kill the Newsletter! is
              important to you and ask them to reconsider their decision, but
              ultimately it’s their content and their choice of who has access
              to it and by what means. As a workaround, some people have had
              success with signing up for the newsletter using their regular
              email address and setting up a filter to forward the emails to
              Kill the Newsletter!
            </p>
          </div>
          <div>
            <h2>How do I share a Kill the Newsletter! feed?</h2>
            <p>
              You don’t. The feed includes the identifier for the email address
              and anyone who has access to it may unsubscribe you from your
              newsletters, send you spam, and so forth. Instead of sharing a
              feed, you may share Kill the Newsletter! itself and let people
              create their own Kill the Newsletter! feeds. Kill the Newsletter!
              has been designed this way because it plays better with newsletter
              publishers, who may, for example, get statistics on the number of
              subscribers who use Kill the Newsletter!. Note that Kill the
              Newsletter! itself doesn’t track users in any way.
            </p>
          </div>
          <div>
            <h2>Why are old entries disappearing?</h2>
            <p>
              When Kill the Newsletter! receives an email it may delete old
              entries to keep the feed under a size limit, because some feed
              readers don’t support feeds that are too big.
            </p>
          </div>
          <div>
            <h2>Why isn’t my feed updating?</h2>
            <p>
              Send an email to the address that corresponds to your Kill the
              Newsletter! feed and wait a few minutes. If the email shows up on
              your feed reader, then the issue must be with the newsletter
              publisher and you should contact them. Otherwise, please
              <a href="mailto:kill-the-newsletter@leafac.com">report the issue us</a>.
            </p>
          </div>
          <div>
            <h2>How do I delete my Kill the Newsletter! feed?</h2>
            <p>
              At the end of each feed entry there’s a link to manage the Kill
              the Newsletter! feed settings, including deleting it.
            </p>
          </div>
          <div>
            <h2>
              I’m a newsletter publisher and I saw some people subscribing with
              Kill the Newsletter!. What is this?
            </h2>
            <p>
              Think of Kill the Newsletter! as an email provider like Gmail, but
              the emails get delivered through Atom feeds for people who prefer
              to read with feed readers instead of email. Also, consider
              providing your content through an Atom feed—your readers will
              appreciate it.
            </p>
          </div>
        
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Midjourney web experience is now open to everyone (293 pts)]]></title>
            <link>https://www.midjourney.com/</link>
            <guid>41312225</guid>
            <pubDate>Wed, 21 Aug 2024 17:11:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.midjourney.com/">https://www.midjourney.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41312225">Hacker News</a></p>
Couldn't get https://www.midjourney.com/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Code review antipatterns (119 pts)]]></title>
            <link>https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/code-review-antipatterns/</link>
            <guid>41312084</guid>
            <pubDate>Wed, 21 Aug 2024 16:55:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/code-review-antipatterns/">https://www.chiark.greenend.org.uk/~sgtatham/quasiblog/code-review-antipatterns/</a>, See on <a href="https://news.ycombinator.com/item?id=41312084">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <p>[Simon Tatham, 2024-08-21]</p>
    <ul>
      <li>
        <a href="#intro">Introduction</a>
      </li>
      <li>
        <a href="#antipatterns">The antipatterns</a>
        <ul>
          <li>
            <a href="#round-trips">The Death of a Thousand Round Trips</a>
          </li>
          <li>
            <a href="#ransom-note">The Ransom Note</a>
          </li>
          <li>
            <a href="#double-team">The Double Team</a>
          </li>
          <li>
            <a href="#guessing-game">The Guessing Game</a>
          </li>
          <li>
            <a href="#priority-inversion">The Priority Inversion</a>
          </li>
          <li>
            <a href="#late-design">The Late-Breaking Design Review</a>
          </li>
          <li>
            <a href="#catch-22">The Catch-22</a>
          </li>
          <li>
            <a href="#flip-flop">The Flip Flop</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="#the-point">But seriously, folks …</a>
        <ul>
          <li>
            <a href="#authority">Authority</a>
          </li>
          <li>
            <a href="#types">Gatekeeping code review</a>
          </li>
        </ul>
      </li>
      <li>
        <a href="#disclaimer">Disclaimer</a>
      </li>
    </ul>
    <h2 id="intro">Introduction</h2>
    <p>Code review seems like a great idea, right? Two developers
      looking at the same code means two chances to spot problems; it
      spreads understanding of the way the project is evolving; the
      reviewer can learn useful tricks from reading the author’s code
      in detail, or spot opportunities to teach the author a useful
      trick that they didn’t know already.</p>
    <p>But that’s only for ‘light side’ code reviewers, who use it to
      try to improve the code base and the developers’ collective
      skills. Code review can also be a powerful tool for totally
      different purposes. When a code reviewer turns to the dark side,
      they have a huge choice of ways to obstruct or delay
      improvements to the code, to annoy patch authors or discourage
      them completely, or to pursue other goals of their own.</p>
    <p>If you’ve only recently turned to the dark side, you might not
      have thought of all the possibilities yet. So here’s a list of
      code-review antipatterns, for the dark-side code reviewer who’s
      running out of ideas.</p>
    <h2 id="antipatterns">The antipatterns</h2>

    <h3 id="round-trips">The Death of a Thousand Round Trips</h3>
    <p>You start reading the code. As soon as you see a nitpick, you
      add a review comment pointing it out. Then you stop reading.</p>
    <p>The developer conscientiously fixes your nitpick, and submits a
      revised patch.</p>
    <p>You start reading that version. You spot another nitpick,
      independent of the first. You <em>could</em> perfectly well have
      mentioned it the first time, but you didn’t, because you didn’t
      get that far. So you point that out – and stop reading
      again.</p>
    <p>And so on. Iterate until the developer loses hope.</p>
    <p>If you’re in a very different time zone from the developer, you
      get a natural 24-hour round-trip time, so that the patch evolves
      as slowly as possible. If you’re in a nearby time zone, or the
      same one, then to delay the patch properly, you’ll have to
      arrange to be busy with several other things, so you have a good
      excuse for it taking you a day or two to get round to looking at
      each new version.</p>
    <p>Resist the temptation to make any remarks like ‘This is
      looking much better now.’ If you hint that you’re getting closer
      to being satisfied, you’ll give them reason to keep trying!</p>

    <h3 id="ransom-note">The Ransom Note</h3>
    <p>This particular patch seems <em>especially</em> important to
      the developer who submitted it. (Maybe they said that outright,
      as part of their argument trying to persuade you to take the
      patch. Or maybe you just read between the lines.)</p>
    <p>But this patch isn’t especially vital to you – so you’re in a
      position of power! Now you can hold the change they need hostage
      until they do lots of extra tangentially related work, which
      doesn’t really need to be in the same commit, but which is
      important to <em>you</em>.</p>
    <p>‘If you ever want to see your beloved patch again …’</p>

    <h3 id="double-team">The Double Team</h3>
    <p>One patch. Two reviewers.</p>
    <p>Every time one of you demands a change, the developer
      obediently makes it – and now the other one can complain
      instead!</p>
    <p>Keep taking turns to make incompatible demands. But always
      direct your comments at the developer. Avoid arguing directly
      with <em>each other</em> on the review thread, and don’t
      acknowledge any suggestion from the patch author that the two of
      you should talk to each other and come to a consensus about what
      the patch is supposed to look like.</p>
    <p>See how many times you can ping-pong the developer back and
      forth before they give up.</p>
    <p>(In a real emergency, if you can’t find an accomplice, you can
      try contradicting <em>your own</em> previous review comments.
      But normally someone will notice. It works better with two
      reviewers.)</p>

    <h3 id="guessing-game">The Guessing Game</h3>
    <p>There’s a problem, and lots of different possible ways to
      solve it. A developer has picked one solution and submitted a
      patch.</p>
    <p>Criticise that <em>particular</em> solution, on some grounds
      that don’t relate to whether or not it solves the problem. Keep
      your criticism vague and woolly: violation of an obscure design
      principle, perhaps, or incompatibility with some vapourware plan
      for future development in the same area. Make the criticism as
      irrelevant as possible to the thing they were really trying to
      achieve.</p>
    <p>If you make it vague enough, the developer won’t be able to
      think of any way to adapt their existing patch that they’re
      confident will address your criticisms. Their best bet is to
      choose a totally <em>different</em> solution to the original
      problem, and try implementing that instead.</p>
    <p>So now you can smack that one down too, in just as unhelpful a
      way!</p>
    <p>Don’t let the developer trap you into any conversation like
      ‘ok, how do you think this problem <em>should</em> be solved?’,
      or give any hint at a solution you’d be happy with. Sooner or
      later, they’ll lose the will to keep guessing.</p>

    <h3 id="priority-inversion">The Priority Inversion</h3>
    <p>In your first code review passes, pick small and simple nits.
      Variable names are a bit unclear; comments have typos in.</p>
    <p>Wait for the developer to fix those, and <em>then</em> drop
      your bombshell: there’s a much more fundamental problem with the
      patch, that needs a chunk of it to be completely rewritten –
      which means throwing away a lot of the nitpick fixes you’ve
      already made the developer do in that part of the patch.</p>
    <p>Nothing says ‘your work is not wanted, and your time is not
      valued’ better than making someone do a lot of work and then
      making them throw it away. This might be enough to make the
      developer give up, all by itself.</p>

    <h3 id="late-design">The Late-Breaking Design Review</h3>
    <p>An enormously complicated piece of work has been ongoing for
      weeks or months, in lots of separate patches. Half the work is
      already committed.</p>
    <p>You personally don’t agree with the design of the entire piece
      of work, but you weren’t consulted in the original discussions.
      Or maybe you were, but you were on the losing side of the
      debate.</p>
    <p>But now you’ve been asked to review a minor but important thing
      in the middle of it, like an easy fix for a bug that’s blocking
      lots of developers. This is your opportunity!</p>
    <p>Demand justification for the entire design of the work so far.
      If the developer doesn’t know the answers, because they’re just
      working on one small part of the overall job, then shrug –
      that’s not your problem, and you’re not hitting the ‘Approve’
      button until you’re satisfied.</p>
    <p>If you’re really lucky, perhaps you can even manipulate this
      developer into undoing some of the already-done work, by giving
      a plausible excuse why it’s necessary. Carefully avoid letting
      them know where to find the design discussions that contradict
      you.</p>

    <h3 id="catch-22">The Catch-22</h3>
    <p>If there’s one big patch, then it’s too hard to read! Demand it
      be split up into self-contained sub-pieces.</p>
    <p>On the other hand, if there are lots of little patches, then
      some of them make no sense on their own! So insist that they be
      glued back together.</p>
    <p>With any large enough piece of work you can surely find a
      reason to make <em>one</em> of those complaints; it’s just a
      matter of deciding which.</p>
    <p>It doesn’t have to be ‘number of patches in the pull request’.
      You can do this one with any kind of tradeoff that seems
      relevant in the particular case. For example, if the code is
      written legibly, it probably has unacceptably poor performance –
      or if it’s well optimised, it’s unreadable and hard to
      maintain.</p>

    <h3 id="flip-flop">The Flip Flop</h3>
    <p>There’s a type of change that people commonly make to the same
      part of the code, like adding an extra thing to a list. You’ve
      reviewed several of these changes before. Another one has just
      come along: the author has looked at the prior changes,
      carefully followed the existing pattern, and chosen you as a
      code reviewer because you’re clearly used to this area.</p>
    <p>Keep everybody on their toes by suddenly objecting to an aspect
      of the change that you’ve never had a problem with before.
      Following the existing pattern just isn’t good enough! The
      author ought to have anticipated that you’ve recently changed
      your mind about what this type of change should look like.</p>
    <p>What if the author points out your inconsistency, by showing
      the previous three identical changes where you didn’t raise this
      objection?</p>
    <p>Then you say ‘You’re right, those should be changed too.’ Be
      careful not to take any personal responsibility
      – <em>you’re</em> not volunteering to change all the existing
      cases. If you’re really lucky the developer will interpret this
      as instructions to change the existing cases themself, and then
      you’ve saved yourself a lot of effort.</p>

    <h2 id="the-point">But seriously, folks …</h2>
    <p>Up to here, this article has been a joke.</p>
    <p>(I’d hope I don’t even have to say that at all, but I’m
      sure <em>somebody</em> would have misunderstood otherwise.)</p>
    <p>I’m not <em>really</em> intending to encourage code reviewers
      to be annoying and obstructive. And I’m not even really
      suggesting that code reviewers <em>do</em> do all these bad
      things, at least on purpose, at least most of the time. Most of
      the descriptions above are exaggerations of what the reviewer
      really does. Or not even that: just an exaggeration of what
      it <em>feels</em> like, when you’re the frustrated patch
      submitter, and your patch has been stuck in review for weeks,
      and doesn’t feel as if it’s getting any closer.</p>
    <p>I really mean: <em>don’t</em> do these things! Try to minimise
      round trips, rather than maximising them. Ask for important
      rewrites (if needed) <em>before</em> picking all the trivial
      nits. When you criticise the patch, make constructive
      suggestions about what version of it you <em>would</em> accept.
      If you have opinions about the code base as a whole, raise them
      with all the developers in a general discussion, rather than
      being petty with the one developer whose patch you’re assigned
      to review. And if you do any of these things <em>by
      accident</em>, have some self-awareness about it: notice that
      you’ve made the developer’s life extra difficult by mistake,
      apologise, and try to compensate by being extra helpful. (Maybe
      even help to improve the actual code, either by writing your own
      revised version of this patch, or doing extra polishing in a
      followup patch of your own.)</p>
    
    <p>But if there’s a serious point to make here, I think it’s this.
      When one developer becomes the code reviewer for another one’s
      patch, that relationship creates temporary <em>authority</em>.
      The reviewer has the power to prevent that particular patch
      being committed, even if they don’t have any kind of authority
      over the patch submitter the rest of the time.</p>
    <p>With authority comes responsibility. You’re supposed to use the
      authority only for its intended purpose, and only as much as
      necessary. In this case, that’s to make the patch as good as
      possible, according to whatever definition of ‘good’ the
      development team as a whole has agreed on.</p>
    <p>So most of these antipatterns (or the milder behaviours that
      they’re caricaturing) are <em>abuses of authority</em>. The
      reviewer is using that temporary power over another developer as
      leverage to pursue some other personal agenda, perhaps
      independent of the goodness of the patch, or perhaps actively
      opposed to it.</p>
    <p>The personal agenda in question varies between these
      antipatterns. It could be some unrelated piece of work the
      reviewer is in favour of; it could be personal stylistic
      preferences that the reviewer hasn’t been able to get the rest
      of the team to adopt; it could be laziness, taking advantage of
      the opportunity to write a one-line description of what you want
      and let someone else do the hard work; it could just be plain
      resistance to change, or perhaps even a personal dislike of the
      patch submitter.</p>
    <p>And that dislike might be quite justifiable, if the patch
      submitter has done any of these bad behaviours when it was
      last <em>their</em> turn to be the code reviewer! That’s another
      reason you should use the code reviewer’s authority sparingly.
      If developers manage to get locked into a cycle of revenge
      against each other, your software project is doomed.</p>
    <h3 id="types">Gatekeeping code review</h3>
    <p>Up to this point, I’ve been focused on <em>peer</em> code
      review. The code reviewer and the patch submitter are
      colleagues; neither is in charge of the other; neither has the
      final say over the code base in general. That’s why the
      authority you get in a code review is <em>temporary</em>:
      tomorrow, after this patch lands, you won’t have it any more.
      The day after that, it might be the other way round.</p>
    <p>Also, in peer review situations, the code reviewer and the
      author are supposed to have basically the same goal. If there’s
      any serious disagreement about what features should go into the
      code at all, or how polished something needs to be before
      approval, or what the acceptable coding style is, it’s supposed
      to be dealt with outside the context of the code review.</p>
    <p>But in other kinds of code review situation, that’s not quite
      the way it works. In particular, if an outsider to your software
      project sends you an unsolicited patch, that’s very different.</p>
    <p>(This scenario usually comes up in free software, since anyone
      in the world can modify your source code, and some of them will
      try sending the changes back to you. But it can happen in other
      situations too – inside a company developing proprietary code, a
      developer in one team might try their luck sending a patch to
      another team’s project, if they particularly want a feature or
      fix that the other team hasn’t found effort for.)</p>
    <p>In this situation, there’s a much bigger chance that the
      receiver of the patch will be unwilling to accept it at all,
      either because they don’t think that change should be made in
      the first place, or they disagree completely with the way it was
      done. And in this case, that’s <em>not</em> an abuse of the
      temporary authority granted by being a peer reviewer: it’s a
      legitimate exercise of the <em>permanent</em> authority of being
      the person or team in charge of the project. It’s my software
      project – I get to decide what direction it goes in.</p>
    <p>When the code reviewer is in this ‘gatekeeping’ role, it’s not
      always wrong to criticise the patch on the grounds that it
      violates an existing general design principle or requirement
      (<a href="#guessing-game">The Guessing Game</a>), without
      suggesting how the same problem could be solved better. Maybe I
      don’t <em>know</em> how that problem could be solved in a way
      that’s consistent with the requirement. In fact, maybe that’s
      precisely the hard part, and the only reason why I haven’t
      already made the same change myself!</p>
    <p>But even in a gatekeeping context, it’s rude to deploy ‘The
      Guessing Game’ <em>without explaining</em>. When I do this, I
      generally try to explain how the developer has overlooked the
      hard part, and if I don’t know the answer myself, I’ll say so.</p>
    <p>And, of course, there’s still no excuse
      for <em>passive-aggressive</em> obstructiveness
      like <a href="#round-trips">The Death of a Thousand Round
      Trips</a>. If you genuinely don’t want the patch in the code at
      all, and you’re in a gatekeeping role with the legitimate
      authority to make that decision, you can <em>say so</em> in
      words, so the submitter doesn’t waste any more time on it!</p>
    <h2 id="disclaimer">Disclaimer</h2>
    <p>I’ve been collecting notes towards this article for many years,
      from code reviews I’ve participated in (on <em>both</em> sides),
      code reviews I’ve observed between others, and code reviews I’ve
      only heard about in conversation.</p>
    <p>So it’s not aimed at any specific person who’s reviewed my code
      recently!</p>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make Firefox Private Again (232 pts)]]></title>
            <link>https://make-firefox-private-again.com/</link>
            <guid>41311479</guid>
            <pubDate>Wed, 21 Aug 2024 15:57:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://make-firefox-private-again.com/">https://make-firefox-private-again.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41311479">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Mimalloc Cigarette: Losing one week of my life catching a memory leak (Rust) (126 pts)]]></title>
            <link>https://pwy.io/posts/mimalloc-cigarette/</link>
            <guid>41311071</guid>
            <pubDate>Wed, 21 Aug 2024 15:09:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pwy.io/posts/mimalloc-cigarette/">https://pwy.io/posts/mimalloc-cigarette/</a>, See on <a href="https://news.ycombinator.com/item?id=41311071">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post">
        

        <p>
          One of applications at my work has always been RAM-bound - it's a
          pricing engine that basically loads tons of hotels, builds some
          in-memory indices and then allows you to issue queries like
          <i>find me the cheapest hotel in berlin, pronto</i>.
        </p>

        <p>
          A pricing engine's main purpose is to price <s>engines</s> hotels, but
          in order to do that effectively, there's a lot of "meta work"
          involved, like:
        </p>

        <ul>
          <li>Where do we load the data from, how do we do it?</li>
          <li>Do we load the entire dataset or just some parts of it?</li>
          <li>
            Should we precalculate prices in order to speed-up the most popular
            queries?
          </li>
        </ul>

        <p>
          Such an engine poses an interesting technical challenge, even greater
          so when one day it starts OOMing on production, even though the entire
          dataset should fit in the memory multiple times...
        </p>

        <h2 id="hello-world"><a href="#hello-world"> Hello, World! </a></h2>

        <p>Simplifying <s>a bit</s> a lot, what we're dealing with is:</p>

        

        <div>
          <pre><span></span><span>struct</span> <span>State</span><span> </span><span>{</span>
<span>    </span><span>hotels</span>: <span>Vec</span><span>&lt;</span><span>Hotel</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>struct</span> <span>Hotel</span><span> </span><span>{</span>
<span>    </span><span>prices</span>: <span>Vec</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>,</span>
<span>}</span>

<span>// ---</span>

<span>impl</span><span> </span><span>State</span><span> </span><span>{</span>
<span>    </span><span>fn</span> <span>new</span><span>()</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span>
<span>        </span><span>Self</span><span> </span><span>{</span>
<span>            </span><span>hotels</span>: <span>load_hotels</span><span>().</span><span>collect</span><span>(),</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>

<span>    </span><span>fn</span> <span>refresh</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>for</span><span> </span><span>(</span><span>id</span><span>,</span><span> </span><span>hotel</span><span>)</span><span> </span><span>in</span><span> </span><span>load_hotels</span><span>().</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>            </span><span>self</span><span>.</span><span>hotels</span><span>[</span><span>id</span><span>]</span><span> </span><span>=</span><span> </span><span>hotel</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>

<span>fn</span> <span>load_hotels</span><span>()</span><span> </span>-&gt; <span>impl</span><span> </span><span>Iterator</span><span>&lt;</span><span>Item</span><span> </span><span>=</span><span> </span><span>Hotel</span><span>&gt;</span><span> </span><span>{</span>
<span>    </span><span>(</span><span>0</span><span>..</span><span>1_000</span><span>).</span><span>map</span><span>(</span><span>|</span><span>_</span><span>|</span><span> </span><span>Hotel</span><span> </span><span>{</span>
<span>        </span><span>prices</span>: <span>(</span><span>0</span><span>..</span><span>1_000_000</span><span>).</span><span>map</span><span>(</span><span>|</span><span>n</span><span>|</span><span> </span><span>n</span><span> </span><span>as</span><span> </span><span>f32</span><span>).</span><span>collect</span><span>(),</span>
<span>    </span><span>})</span>
<span>}</span>

<span>// ---</span>

<span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>state</span><span> </span><span>=</span><span> </span><span>Arc</span>::<span>new</span><span>(</span><span>RwLock</span>::<span>new</span><span>(</span><span>State</span>::<span>new</span><span>()));</span>

<span>    </span><span>// Spawn a separate thread responsible for checking which hotels have</span>
<span>    </span><span>// changed and need to be refreshed etc.</span>
<span>    </span><span>thread</span>::<span>spawn</span><span>({</span>
<span>        </span><span>let</span><span> </span><span>state</span><span> </span><span>=</span><span> </span><span>Arc</span>::<span>clone</span><span>(</span><span>&amp;</span><span>state</span><span>);</span>

<span>        </span><span>move</span><span> </span><span>||</span><span> </span><span>loop</span><span> </span><span>{</span>
<span>            </span><span>thread</span>::<span>sleep</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>5</span><span>));</span>
<span>            </span><span>state</span><span>.</span><span>write</span><span>().</span><span>unwrap</span><span>().</span><span>refresh</span><span>();</span>
<span>        </span><span>}</span>
<span>    </span><span>});</span>

<span>    </span><span>// Now in reality we start a Rocket server here, but for practical</span>
<span>    </span><span>// purposes stalling the main thread will be sufficient.</span>
<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>thread</span>::<span>sleep</span><span>(</span><span>Duration</span>::<span>from_secs</span><span>(</span><span>1</span><span>));</span>
<span>    </span><span>}</span>
<span>}</span>
</pre>
        </div>

        <p>
          Of course IRL there's <kbd>ArcSwap</kbd> instead of <kbd>RwLock</kbd>,
          every hotel contains much more information (like taxes, discounts or
          supplements) etc., but we've got a reasonably good approximation here.
        </p>

        <p>
          Now, what if I told you that this code has <i>totally</i> different
          memory characteristics depending on which allocator you use?
        </p>

        <h2 id="practical-reasons">
          <a href="#practical-reasons"> Practical Reasons </a>
        </h2>

        <p>
          Memory allocator is the piece of software invoked whenever your
          program needs to get hands on extra memory, like when you're calling
          <kbd>Box::new()</kbd>. And memory allocation is quite a complex topic,
          with different solutions offering different trade-offs.
        </p>

        <p>
          Say, when implementing a firmware you might pick an allocator that
          works slower, because its implementation is just simpler and doesn't
          occupy much space in the final binary.
        </p>

        <p>
          (some would argue that embeddeed programs shouldn't allocate, yadda
          yadda, but you get the idea -- replace <i>firmware</i> with
          <i>wasm</i> and you end up with the same problem.)
        </p>

        <p>
          <a href="https://github.com/microsoft/mimalloc">mimalloc</a> is an
          allocator that fights tooth and nail for performance - and while most
          applications don't have to worry about allocation performance, in our
          case internal benchmarks have proven it gives us extra 10% for free;
          when your response times have to be within milliseconds, this matters.
        </p>

        <p>But there's a catch.</p>

        <h2 id="desenchantee"><a href="#desenchantee"> Désenchantée </a></h2>

        <p>
          That program from before, on my x86_64 Linux machine it allocates
          around 4 GB of memory and it remains on this level through the
          refreshing.
        </p>

        <p>
          This makes sense, right? We're using lazy iterators, replacing stuff
          in place one-by-one, there's no reason we'd need more RAM.
        </p>

        <p>But if you use mimalloc:</p>

        <div>
          <pre><span></span><span>use</span><span> </span><span>mimalloc</span>::<span>MiMalloc</span><span>;</span>

<span>#[global_allocator]</span>
<span>static</span><span> </span><span>GLOBAL</span>: <span>MiMalloc</span><span> </span><span>=</span><span> </span><span>MiMalloc</span><span>;</span>
</pre>
        </div>

        <p>
          ... the program will first allocate 4 GB and then allocate
          <i>extra</i> 4 GB during the refreshing, oh noes!
        </p>

        <p>
          Getting to this point already took three days of my life - believe me
          or not, when faced with 200k lines of Arc-ridden Rust code that
          <i>seems</i> to generate a memory leak, one's first thought is not
          "let's try with different allocator", but rather "probably something's
          holding onto an Arc for too long".
        </p>

        <p>
          And so I've valgrind-ed. I've perf-ed. I've analyzed assembly. I've
          headbanged and I've cried.
        </p>

        <p>No more.</p>

        <p>
          From now on I'm always assuming it's someone else's fault - it's the
          allocator, it's the compiler, it's that crate Mike pulled last night.
          WHY DO YOU HATE ME MIKE, WHY ARE YOU PULLING RANDOM CRATES TO MY PURE
          <span>~~~tv noise~~~</span>
        </p>

        <h2 id="remede"><a href="#remede"> Remède </a></h2>

        <p>
          Allocators have different characteristics for a reason - they do some
          things differently between each other. What do you think mimalloc does
          that could account for this behavior?
        </p>

        <p>
          Let me give you two hints, two pieces of code that solve the problem,
          but feel cursed:
        </p>

        <div>
          <pre><span></span><span>// Approach 1:</span>
<span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>state</span><span> </span><span>=</span><span> </span><span>thread</span>::<span>spawn</span><span>(</span><span>||</span><span> </span><span>{</span>
<span>        </span><span>Arc</span>::<span>new</span><span>(</span><span>RwLock</span>::<span>new</span><span>(</span><span>State</span>::<span>new</span><span>()))</span>
<span>    </span><span>}).</span><span>join</span><span>().</span><span>unwrap</span><span>();</span>

<span>    </span><span>/* ... */</span>
<span>}</span>

<span>// Approach 2:</span>
<span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>/* ... */</span>

<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>Box</span>::<span>new</span><span>(</span><span>1234</span><span>);</span>
<span>    </span><span>}</span>
<span>}</span>
</pre>
        </div>

        <p>Any ideas? Last chance to win a plushie polar bear!</p>

        <p>
          Alright then, the issue is that mimalloc assumes that
          <b>every thread allocates every now and then</b>.
        </p>

        <p>
          Every now and then during <kbd>malloc()</kbd> mimalloc performs some
          internal bookkeeping, so when a thread goes to sleep (say, because it
          delegates handling HTTP requests into a separate thread pool...), this
          bookkeeping doesn't happen (for that particular thread).
        </p>

        <p>
          The most nasty edge case that can happen here, and the one that we've
          stumbled upon, is when your thread allocates a lot of data, then
          launches other threads to work on that data, and then goes to sleep.
          As other threads work on memory and override stuff, Rust destructors
          <i>are</i> launched properly, but the underlying memory blocks simply
          get marked as "to be released".
        </p>

        <p>
          Under normal conditions, these blocks get processed a moment later,
          during a call to <kbd>malloc()</kbd> on the thread that created them -
          but if that thread is asleep, those blocks never become available
          again (unless the thread dies, of course).
        </p>

        <p>
          To be sure, the problem is not that the memory is not returned to the
          kernel - that's alright. It's that unless this bookkeeping happens,
          mimalloc can't even use the memory <i>for itself</i> - all this free
          estate just lays there, dormant:
        </p>

        <ul>
          <li>
            <a href="https://github.com/microsoft/mimalloc/issues/537">https://github.com/microsoft/mimalloc/issues/537</a>
          </li>
          <li>
            <a href="https://github.com/microsoft/mimalloc/issues/214">https://github.com/microsoft/mimalloc/issues/214</a>
          </li>
        </ul>

        <p>
          Anyway, the solution we went with was to keep all refreshing on the
          same thread - when program starts, we spawn a dedicated
          refreshing-thread and use channels to let it know to do its thing.
        </p>

        <p>
          So yeah, that was fun; and health-wise probably more like seven
          cigarettes.
        </p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mathematicians prove Hawking wrong about the most extreme black holes (107 pts)]]></title>
            <link>https://www.quantamagazine.org/mathematicians-prove-hawking-wrong-about-extremal-black-holes-20240821/</link>
            <guid>41310865</guid>
            <pubDate>Wed, 21 Aug 2024 14:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/mathematicians-prove-hawking-wrong-about-extremal-black-holes-20240821/">https://www.quantamagazine.org/mathematicians-prove-hawking-wrong-about-extremal-black-holes-20240821/</a>, See on <a href="https://news.ycombinator.com/item?id=41310865">Hacker News</a></p>
Couldn't get https://www.quantamagazine.org/mathematicians-prove-hawking-wrong-about-extremal-black-holes-20240821/: Error: timeout of 10000ms exceeded]]></description>
        </item>
    </channel>
</rss>