<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 04 May 2024 16:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A love letter to bicycle maintenance and repair (194 pts)]]></title>
            <link>https://tegowerk.eu/posts/bicycle-repair/</link>
            <guid>40255209</guid>
            <pubDate>Sat, 04 May 2024 05:50:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tegowerk.eu/posts/bicycle-repair/">https://tegowerk.eu/posts/bicycle-repair/</a>, See on <a href="https://news.ycombinator.com/item?id=40255209">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>It was the 28th of June, 2020; the perfect summer day. I remember it distinctly because of two important events that took place on that day. The first was the unfortunate discovery that I am highly sensitive to the venomous hairs of the <a href="https://en.wikipedia.org/wiki/Oak_processionary">Oak processionary</a> caterpillar. If you’ve never wished you could use a cheese grater to remove the skin off your arms and legs just to be rid of the itching, then you can’t really understand how I felt for two whole weeks that summer.</p><p>The second thing that happened on that 28th of June was the seemingly inconsequential purchase of two secondhand bicycles. My wife and I drove out to a local park to test ride a couple of ’90s-era Trek 970 bikes that a guy had restored in his garage. We didn’t know a thing about bicycles, but we liked what we saw; the bikes worked great and felt very nice to ride around the park–the fact that I also happened to ride through a floating cloud of Oak-processionary hairs would only become apparent the next day.</p><p>So we took our new old bikes home, and we started riding them around. We got into bicycle touring too around that time, and that’s worth an entire future post on its own for the joy it’s brought us, but for now I’d like to get back on track. See, I kept thinking about the guy we bought the bikes from. I don’t know if he did this as a hobby, side business, or what, but I became increasingly fascinated by the idea of fixing up and restoring old bicycles. As I said, at that time I didn’t know a thing about bikes; I couldn’t even change a brake cable, but I’d always wanted to pick up a hobby that would take me away from the computer, something that would get my hards dirty at the same time, so why not give this a try?</p><p>Back then I still had my previous bike too, gathering dust and cobwebs somewhere in the basement. It was a Cube Aim that I’d had for at least a decade and had practically never serviced. It worked like crap, but I suspected most of it was just lack of maintenance and proper adjustment. In fact, it was in a lot of ways a nicer bike than the one I’d just bought. So I set a goal for myself: I would take the bike apart, down to the last bolt; I would clean everything up, change whatever parts were broken, and put it back together again. After all, how hard could it be?</p><p>At its core, a bike is a very simple, very old machine. The basic operating principles have remained virtually unchanged since the first <a href="https://en.wikipedia.org/wiki/Safety_bicycle">“safety bicycle”</a> of the late 19th century: you push on the pedals to rotate a crank arm; a chain transfers the power to the rear sprockets; the sprockets turn the rear wheel. That’s it, that’s all there is to it; a wonderfully simple device that is nonetheless the single <a href="https://en.wikipedia.org/wiki/Bicycle_performance#Energy_efficiency">most energy-efficient</a> mode of transportation humanity has come up with.</p><p>Of course, modern bikes are a lot more complicated than that: inflatable tires; the freewheel; derailleurs; suspension; hydraulic disk brakes; electric motors and electronic gear shifting. Every major technological advancement has brought with it increased safety, ease of use, and performance, at the cost of adding extra layers of complexity on top of the basic initial machine. It’s increasingly rare now for people to know how to repair their own bicycles, and bicycle mechanics themselves have more and more skills to learn if they want to keep on top of the fast changes in their field.</p><p>Which brings me back to my modest Cube. I grossly underestimated just how complex a task I’d set for myself, of course, but at the same time I also underestimated just how much I would love doing it. I had never considered myself mechanically inclined; my dad didn’t teach me much, and by that time I hadn’t yet truly internalized something that has since become one of my main mantras in life: <a href="https://www.youtube.com/watch?v=K4J_QfiGRRc">what one man can do, another can do</a> (by the way, if you haven’t watched <a href="https://www.imdb.com/title/tt0119051/">The Edge</a> yet, you really should). Thankfully, we live in glorious informational times that our forefathers didn’t even dream of. A trove of knowledge of incalculable value is available at the fingertips of every self-learner, and bicycle repair is no exception. YouTube channels like <a href="https://www.youtube.com/channel/UCzaZ1sPWEuZN-I8_XT6AH8g">Park Tool</a> or <a href="https://www.youtube.com/channel/UCaAK2FaxQ2xiBbAUVZsvDYQ">RJ The Bike Guy</a> provide a visual, hands-on learning experience that is comparable to the tragically fading practice of apprenticeship. Internet forums like <a href="http://reddit.com/r/bikewrench">/r/bikewrench</a> give one the ability to pick the brains of real-life professional mechanics (although, just like every other subreddit, it does have its idiots that one needs to learn to steer clear of), and no list of bike repair resources could be complete without mentioning <em>the Bible</em>, the website of the late <a href="https://www.sheldonbrown.com/">Sheldon Brown</a>. May he rest in peace.</p><p>Eventually, I finished the project. It didn’t go smoothly at all. On more than one occasion I realized I was missing some vital tool, or some tiny part that I hadn’t even known existed until I suddenly needed it–like <a href="https://tegowerk.eu/img/2022-02-04-repair/EfCKYf2.jpg">cable ferrules</a>, or a <a href="https://tegowerk.eu/img/2022-02-04-repair/UqbJC1q.png">star nut</a>–and without which the whole project ground to a halt. Nevertheless, the bike progressed, then finally it was done, and from that moment on I knew I was hooked. I’ve been working as a web developer since 2006. Coding has always been my great passion. I have literally lost count of the number of apps and projects I worked on for the past sixteen years. But let me tell you something: not a single launch has given me the same high, has been as memorable or as character-defining as rebuilding that cheap bicycle in 2020; I simply had to have more of it.</p><p>Almost two years have passed since then. I’ve rebuilt almost twenty more bikes in that time. I’ve learned to reliably <a href="https://www.wheelpro.co.uk/wheelbuilding/book.php">build wheels</a>, and I’ve become the go-to guy for bike repair in my circle of friends–and even for some folks who I didn’t even know before. There isn’t a single bicycle repair task that scares me anymore. I’ve gone from not being able to change a brake cable, to bravely <a href="https://tegowerk.eu/posts/sram-automatix/">taking apart complex components</a> or <a href="https://tegowerk.eu/posts/drop-bar-shifter-tutorial/">hacking them</a> for use-cases that they weren’t designed for. We have since sold the bikes we bought back in 2020, and both my wife and I are now riding bikes that I’ve built from scratch. The pride I feel when we go out on a ride cannot be overstated, and I love biking now more than I ever did as a result.</p><p>I realize this may sound overblown, but the changes this hobby has wrought in me go beyond just teaching me a fun and useful skill. Learning to fix bicycles has changed my outlook on manual labor, on the nature of work, and ultimately on life itself:</p><h3 id="thinking-versus-doing">Thinking versus doing</h3><p>Looking back, I realize I had a terribly naive perspective on manual labor. I lived with the misconception–drilled into me since childhood–that work can be neatly split into two categories: knowledge work and manual work; that there are those who think, and those who do, and by extension (and it greatly shames me to admit this) that there is a clear difference in value between the two.</p><p>I have since realized that the line that separates thinking from doing doesn’t actually exist; instead, the two are facets of the same coin, and neither can exist in isolation. This came to me when I noticed that there is just as much thinking going into solving a bike repair problem as there is in solving a bug in my code (and, incidentally, the same high when I finally crack it). I later ended up reading <a href="https://www.goodreads.com/book/show/6261332-shop-class-as-soulcraft">Shop Class as Soulcraft: An Inquiry Into the Value of Work</a>, by Matthew B. Crawford; it was an eye-opening read that eloquently put into words a concept I had merely sniffed the edges of. I highly recommend you give it a read.</p><h3 id="what-one-man-can-do-another-can-do">What one man can do, another can do</h3><p>I touched on this a bit earlier in the text. I have a lot more courage now in tackling all sorts of repairs around the house, not just on bikes. This is because I now know that I have the capacity to learn the necessary skills, but more importantly, it’s because I’ve learned to look at objects and <em>see them</em>. Something has shifted inside me, and it has altered my perception of the world. Before, I used to look at an object and only see it on the surface; I saw the function it performed and nothing more. Now I see the bolts, the screws, the cables, the hinges, the motors, and I know that each one of those can be fixed or replaced independently of the object as a whole. Maybe this has always been obvious to you, but as I’ve already said, I didn’t learn much of this stuff growing up; it’s a failing I put on my shoulders and the shoulders of my father both, and it’s something I’m only truly making up for now, in the fourth decade of my life. Better late than never.</p><h3 id="tangibility-of-objects-and-people">Tangibility, of objects and people</h3><p>At work I build websites. Well, that’s not strictly true. I build web apps, I write unit tests, I manage databases, I architect and set up the cloud infrastucture, I set up continuous integration and continuous delivery pipelines, and sometimes I even help my colleagues fix the Docker setup on their machines. My daily conversations are peppered with such acronyms as PHP, TDD, CI, CD, K8s, SQL, JSON, AWS, GCP, CF, SSH, SSL, and on and on and on.</p><p>If you’re not an IT person, most of these words won’t mean anything to you, and therein lies my next point. Conceptually, it’s easier for humans to relate to occupations that produce something you can point a finger at. The further removed a person is from the results of their own work, the greater the disconnect they feel, and the greater the chance they’ll conclude they’re working in a <a href="https://en.wikipedia.org/wiki/Bullshit_job">bullshit job</a>.</p><p>Now, I don’t actually believe I’m working a bullshit job. I don’t really believe they exist. I believe jobs provide value even when the value is not immediately, tangibly apparent. But I do believe in the disconnect that makes people feel this way, and I do believe that’s a distinct hallmark of the modern service-oriented industries. You’ll never hear a baker say their job is bullshit.</p><p>And it’s not just the tangible aspect of the work itself, either. The same can be said of the people who ultimately benefit from the work. Websites that I’ve built are being used right now by hundreds of thousands of people, yet for some reason I still feel I’m making a greater impact when I see a person ride away on a bike I’ve just repaired for them. It’s senseless, yet there it is.</p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nintendo blitzes GitHub with over 8k emulator-related DMCA takedowns (207 pts)]]></title>
            <link>https://www.engadget.com/nintendo-blitzes-github-with-over-8000-emulator-related-dmca-takedowns-200021877.html</link>
            <guid>40254602</guid>
            <pubDate>Sat, 04 May 2024 03:37:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.engadget.com/nintendo-blitzes-github-with-over-8000-emulator-related-dmca-takedowns-200021877.html">https://www.engadget.com/nintendo-blitzes-github-with-over-8000-emulator-related-dmca-takedowns-200021877.html</a>, See on <a href="https://news.ycombinator.com/item?id=40254602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main"><div id="module-moreStories" data-wf-sticky-offset="130px   10px" data-wf-sticky-position="" data-wf-sticky-target="#adsStream" data-wf-trigger-percentage=""><ul><li></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/1gUFCX8h7IVNhH2Gi._Bgg--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2024-05/d9f08690-0974-11ef-bd8f-8eb0887821c4" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="dd2d602a-2c2f-4e26-95cf-e8aa604a3a44" href="https://www.engadget.com/redfalls-two-dlc-heroes-are-still-mia-a-year-later-180838827.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:3;ct:story;g:dd2d602a-2c2f-4e26-95cf-e8aa604a3a44" data-hosted-type="HOSTED">Redfall’s two DLC heroes are still MIA a year later</a></h4><p>Microsoft may want to be more careful about leaving a trail of broken promises when games don’t go as planned. A year after Redfall landed with a thud, players are still waiting for the advertised post-launch DLC they already paid for.</p></div></div></li><li></li><li></li><li></li><li></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/7aEQ.4fdWuMUUrnwA97sAw--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2023-09/a4fc4790-5749-11ee-8fb2-b86b1385cef0" alt=""></p></div></li><li></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/_TvVDHp9inz_19yiMJ93Lg--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2024-04/f97e0620-f8e1-11ee-b6c6-1e329bded0bb" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="779f199a-c821-4fb1-9321-0fe080c20b4d" href="https://www.engadget.com/best-tech-upgrades-laptops-tablets-headphones-smartphones-monitors-bags-for-graduates-150049903.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:12;ct:story;g:779f199a-c821-4fb1-9321-0fe080c20b4d" data-hosted-type="HOSTED">The best gifts to upgrade your grad’s tech setup</a></h4><p>College grads are probably using the same tech they started out with four years ago. Here are the best gadgets you can get them to upgrade their kit, including laptops, headphones, monitors and more.</p></div></div></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/jXbFa1iT1I43q580qMv7LA--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2021-12/7e185d50-5a8c-11ec-97de-17cd16d432dd" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="90f488a8-a981-4d8d-ad71-e507477d020b" href="https://www.engadget.com/the-morning-after-pelotons-grim-post-pandemic-reality-111518934.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:14;ct:story;g:90f488a8-a981-4d8d-ad71-e507477d020b" data-hosted-type="HOSTED">The Morning After: Peloton's grim post-pandemic reality</a></h4><p>The biggest news stories this morning: 
Huawei has been secretly funding research in America after being blacklisted, The best noise-canceling earbuds, Olivia Rodrigo, Drake and other Universal artists return to TikTok.</p></div></div></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/FGRSzt3Sm8ws6w4klf1wYA--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2024-04/1b3e6980-fb4e-11ee-a1db-b3af8fdba41a" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="a649d9d6-10c3-35af-94c2-dfe91925156a" href="https://www.engadget.com/best-password-manager-134639599.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:16;ct:story;g:a649d9d6-10c3-35af-94c2-dfe91925156a" data-hosted-type="HOSTED">The best password manager for 2024</a></h4><p>Remembering dozens of passwords can be difficult for anyone. These are the best password managers you can use to keep your information safe and secure.</p></div></div></li><li></li><li></li><li></li><li><div><p><img src="https://s.yimg.com/cv/apiv2/default/20190501/placeholder.gif" data-wf-src="https://s.yimg.com/uu/api/res/1.2/MdPqMZ1Zp5TMGVrtHJQd2A--~B/Zmk9c3RyaW07aD0yODg7dz01MTQ7YXBwaWQ9eXRhY2h5b24-/https://s.yimg.com/os/creatr-uploaded-images/2024-05/e8ff96c0-08b2-11ef-bbfe-5d492495948d" alt=""></p><div><p><span>Engadget</span></p><h4><a data-uuid="5a90c300-7585-4546-a1fc-c9ad59966021" href="https://www.engadget.com/audible-is-testing-a-cheaper-plan-in-australia-191347871.html" data-ylk="elm:hdln;itc:0;pos:1;sec:strm;subsec:moreforyou;cpos:20;ct:story;g:5a90c300-7585-4546-a1fc-c9ad59966021" data-hosted-type="HOSTED">Audible is testing a cheaper plan in Australia</a></h4><p>Audible is testing a cheaper subscription tier in Australia that sounds like an answer to Spotify’s audiobook push. The service’s new Standard plan gives you one free title per month, but your credits don’t roll over.</p></div></div></li></ul></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I joined landlord groups to persuade them to be better people to their tenants (151 pts)]]></title>
            <link>https://www.thisisalot.com/unhinged-opinions/i-joined-a-bunch-of-landlord-groups-to-subtly-manipulate-them-into-being-better-people/118/</link>
            <guid>40254573</guid>
            <pubDate>Sat, 04 May 2024 03:30:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thisisalot.com/unhinged-opinions/i-joined-a-bunch-of-landlord-groups-to-subtly-manipulate-them-into-being-better-people/118/">https://www.thisisalot.com/unhinged-opinions/i-joined-a-bunch-of-landlord-groups-to-subtly-manipulate-them-into-being-better-people/118/</a>, See on <a href="https://news.ycombinator.com/item?id=40254573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>It’s actually kinda working</h2>



<div><p>So, about a year ago I joined a bunch of a landlord groups on Facebook and Nextdoor. I’ve worked diligently to manipulate them into taking pro-tenant actions, and it actually has kind of worked? Here’s the general strategy:</p><figure><img title="noun-landlord-111368 » This is a lot" decoding="async" width="512" height="512" src="https://www.thisisalot.com/wp-content/uploads/2024/04/noun-landlord-111368.png" alt="" srcset="https://www.thisisalot.com/wp-content/uploads/2024/04/noun-landlord-111368.png 512w, https://www.thisisalot.com/wp-content/uploads/2024/04/noun-landlord-111368-300x300.png 300w, https://www.thisisalot.com/wp-content/uploads/2024/04/noun-landlord-111368-150x150.png 150w" sizes="(max-width: 512px) 100vw, 512px"></figure></div>







<ol>
<li>Make some posts detailing how I run my “businesss”<sup data-fn="6a55418c-f453-4de4-a1a6-4282352192ef"><a id="6a55418c-f453-4de4-a1a6-4282352192ef-link" href="#6a55418c-f453-4de4-a1a6-4282352192ef">1</a></sup> and ask a few questions.</li>



<li>Establish credibility by earning their trust by posting helpful information. </li>



<li>Politely suggest taking actions that unequivocally benefit the tenant by dressing them up as beneficial to the landlord.  </li>
</ol>



<p>These three steps, of which order matters a lot, have given me a few wins I’d like to share with y’all. </p>



<h2>Establishing your credentials by lying </h2>



<p>Landlords won’t listen to tenants. In the same way that Republicans won’t seriously engage with Democrats and <em>vice versa</em>. The two roles are viewed as kind of adversarial, so going directly into trying to change their behavior is not a  going proposition. </p>



<p>However, <em>all</em> humans listen to people that they think are like themselves. Naturally, we place more weight on people with whom we have a common reference point. This shared reference binds us together, and its through those ties that bind you can persuade effectively. So, the first move was to convince them that I am in fact a landlord<sup data-fn="d458854b-cbc0-43c7-a9c3-cc614f72f476"><a href="#d458854b-cbc0-43c7-a9c3-cc614f72f476" id="d458854b-cbc0-43c7-a9c3-cc614f72f476-link">2</a></sup>.</p>



<p>So, when the question was posed “do you own a property?” when I applied to join the group, I chose a random 2-flat at the other end of my street and said “yes”. </p>



<h2>Asking Questions to get your name out there</h2>



<p>When I was still new in the groups, I asked some questions about common landlord issues to win cheap interactions. The exposure of seeing my name in the group and interacting with a few of them was the actual goal. People are much more easily influenced by familiar faces than complete strangers, unless they are paying them (e.g. consultants). Tragically, no one paid me to go on this campaign. </p>



<figure><img title="GreaseDownDrain » This is a lot" decoding="async" width="707" height="234" src="https://www.thisisalot.com/wp-content/uploads/2024/04/GreaseDownDrain.png" alt="" srcset="https://www.thisisalot.com/wp-content/uploads/2024/04/GreaseDownDrain.png 707w, https://www.thisisalot.com/wp-content/uploads/2024/04/GreaseDownDrain-300x99.png 300w" sizes="(max-width: 707px) 100vw, 707px"><figcaption>literally every landlord probably has</figcaption></figure>



<p>A week or two of a few questions sprinkled-in is really all that’s needed. Maybe a total of two questions per group. Bonus points in the questions are about common sources of frustration/anger for landlords. People interact more with content that angers them, and our goal is just to get some interactions. </p>



<h2>Creating friendly-informative content to establish credibility and gain favor of the landlords</h2>



<p>The next phase was a campaign of friendly, helpful, and more importantly strictly factual posts to establish credibility. I spent some time reading the comments of other posts in the group, so I could tailor each post to whatever common misconceptions were being repeated. The more people who could learn something new from my posts, the better. </p>



<figure><img title="LLCs » This is a lot" loading="lazy" decoding="async" width="697" height="340" src="https://www.thisisalot.com/wp-content/uploads/2024/04/LLCs.png" alt="" srcset="https://www.thisisalot.com/wp-content/uploads/2024/04/LLCs.png 697w, https://www.thisisalot.com/wp-content/uploads/2024/04/LLCs-300x146.png 300w" sizes="(max-width: 697px) 100vw, 697px"></figure>



<p>Notice, there’s not much room to comment from the content of the post. That’s by design. I’m not trying to start a discussion or an argument here. I want people to read the post, smash the like button, and feel a little more informed. Notice the increase in reactions from our beginning questions. The goal is to slowly but steadily build-up reactions and discussions. Don’t come in with too much controversy. </p>



<h2>Cashing in the social currency</h2>



<p>Then it was time to take the offensive. After reading many posts of landlords asking if they can <em>pre-file</em> eviction paperwork (they can’t) to general posts complaining about tenants <em>cooking in their own apartment</em>, I was ready. </p>



<figure><img title="landlords » This is a lot" loading="lazy" decoding="async" width="702" height="703" src="https://www.thisisalot.com/wp-content/uploads/2024/04/landlords.png" alt="" srcset="https://www.thisisalot.com/wp-content/uploads/2024/04/landlords.png 702w, https://www.thisisalot.com/wp-content/uploads/2024/04/landlords-300x300.png 300w, https://www.thisisalot.com/wp-content/uploads/2024/04/landlords-150x150.png 150w" sizes="(max-width: 702px) 100vw, 702px"><figcaption>they paid the $1000</figcaption></figure>



<p>I had to resist my urge to respond with “<strong>I THINK THE FUCK NOT</strong>“. Instead, I calmly laid out an alternative in which this landlord looks like the hero, instead of someone who seriously just asked if they can <em>pre-file</em> an eviction. Ridiculous. However, the appeal to ego worked. Somewhere, some tenant got a $1,000 check. <strong>Mission accomplished</strong>.</p>







<figure><blockquote><p>It ain’t much but it’s honest work. </p></blockquote></figure>


<ol><li id="6a55418c-f453-4de4-a1a6-4282352192ef">There is no business. I don’t own any real estate.  <a href="#6a55418c-f453-4de4-a1a6-4282352192ef-link" aria-label="Jump to footnote reference 1">↩︎</a></li><li id="d458854b-cbc0-43c7-a9c3-cc614f72f476">Once again, I am not a landlord. <a href="#d458854b-cbc0-43c7-a9c3-cc614f72f476-link" aria-label="Jump to footnote reference 2">↩︎</a></li></ol>


<div>
			<p><img src="https://secure.gravatar.com/avatar/aea30111d3f88654af35064c2dac662b?s=300&amp;d=blank&amp;r=g" alt="author avatar">
		</p>
			<div><p>
			
			Luke A man on a crusade against apathy.

I created this website on April Fool’s Day 2024, after noticing the sharp uptick in garbage writing on the internet. My day job is as a data something. I also do consulting work for small-business’ trying to modernize their data situations and make a buck off them. I write a lot about technology, economics, my own antics, and opinions.&nbsp;

If my writing has entertained, informed, aggravated, or made you reconsider anything, then I consider this blog a fantastic success.
							</p>
				
					</div>
</div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Insects and other animals have consciousness (109 pts)]]></title>
            <link>https://nautil.us/insects-and-other-animals-have-consciousness-571584/</link>
            <guid>40254054</guid>
            <pubDate>Sat, 04 May 2024 01:25:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/insects-and-other-animals-have-consciousness-571584/">https://nautil.us/insects-and-other-animals-have-consciousness-571584/</a>, See on <a href="https://news.ycombinator.com/item?id=40254054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><span>I</span>n 2022, researchers at the Bee Sensory and Behavioral Ecology Lab at Queen Mary University of London observed bumblebees doing something remarkable: The diminutive, fuzzy creatures were engaging in activity that&nbsp;<a href="https://doi.org/10.1016/j.anbehav.2022.08.013" target="_blank" rel="noreferrer noopener">could only be described as play</a>. Given small wooden balls, the bees pushed them around and rotated them. The behavior had no obvious connection to mating or survival, nor was it rewarded by the scientists. It was, apparently, just for fun.</p><p>The study on playful bees is part of a body of research that a group of prominent scholars of animal minds cited last month, buttressing&nbsp;<a href="http://www.nydeclaration.com/" target="_blank" rel="noreferrer noopener">a new declaration</a>&nbsp;that extends scientific support for consciousness to a wider suite of animals than has been formally acknowledged before. For decades, there’s been a broad agreement among scientists that animals similar to us—the great apes, for example—have conscious experience, even if their consciousness differs from our own. In recent years, however, researchers have begun to acknowledge that consciousness may also be widespread among animals that are very different from us, including invertebrates with completely different and far simpler nervous systems.</p>

<blockquote>
<p>We have much more in common with other animals than we do with things like ChatGPT.</p>
</blockquote><p>The new declaration, signed by biologists and philosophers, formally embraces that view. It reads, in part: “The empirical evidence indicates at least a realistic possibility of conscious experience in all vertebrates (including all reptiles, amphibians, and fishes) and many invertebrates (including, at minimum, cephalopod mollusks, decapod crustaceans, and insects).” Inspired by recent research findings that describe complex cognitive behaviors in these and other animals, the document represents a new consensus and suggests that researchers may have overestimated the degree of neural complexity required for consciousness.</p>
<p>The four-paragraph New York Declaration on Animal Consciousness was unveiled on April 19, at a one-day conference called “<a href="https://forum.effectivealtruism.org/events/ptbAnN83QHwazPJ6a/the-emerging-science-of-animal-consciousness" target="_blank" rel="noreferrer noopener">The Emerging Science of Animal Consciousness</a>” held at New York University. Spearheaded by the philosopher and cognitive scientist&nbsp;<a href="https://profiles.laps.yorku.ca/profiles/andrewsk/" target="_blank" rel="noreferrer noopener">Kristin Andrews</a>&nbsp;of York University in Ontario, the philosopher and environmental scientist&nbsp;<a href="https://as.nyu.edu/faculty/jeff-sebo.html" target="_blank" rel="noreferrer noopener">Jeff Sebo</a>&nbsp;of New York University, and the philosopher&nbsp;<a href="https://www.lse.ac.uk/cpnss/people/jonathan-birch" target="_blank" rel="noreferrer noopener">Jonathan Birch</a>&nbsp;of the London School of Economics and Political Science, the declaration has so far been signed by more than 100 researchers, including the psychologists&nbsp;<a href="https://www.psychol.cam.ac.uk/people/nsc22%40cam.ac.uk" target="_blank" rel="noreferrer noopener">Nicola Clayton</a>&nbsp;and&nbsp;<a href="https://www.bu.edu/psych/profile/irene-pepperberg/" target="_blank" rel="noreferrer noopener">Irene Pepperberg</a>, the neuroscientists&nbsp;<a href="https://www.anilseth.com/" target="_blank" rel="noreferrer noopener">Anil Seth</a>&nbsp;and&nbsp;<a href="https://alleninstitute.org/person/christof-koch/" target="_blank" rel="noreferrer noopener">Christof Koch</a>, the zoologist&nbsp;<a href="http://chittkalab.sbcs.qmul.ac.uk/Lars.html" target="_blank" rel="noreferrer noopener">Lars Chittka</a>, and the philosophers&nbsp;<a href="https://consc.net/" target="_blank" rel="noreferrer noopener">David Chalmers</a>&nbsp;and&nbsp;<a href="https://petergodfreysmith.com/" target="_blank" rel="noreferrer noopener">Peter Godfrey-Smith</a>.</p><p>The declaration focuses on the most basic kind of consciousness, known as phenomenal consciousness. Roughly put, if a creature has phenomenal consciousness, then it is “like something” to be that creature—an idea enunciated by the philosopher Thomas Nagel in his influential 1974 essay, “<a href="https://www.sas.upenn.edu/~cavitch/pdf-library/Nagel_Bat.pdf" target="_blank" rel="noreferrer noopener">What is it like to be a bat?</a>” Even if a creature is very different from us, Nagel wrote, “fundamentally an organism has conscious mental states if and only if there is something that it is like to&nbsp;<em>be</em>&nbsp;that organism. … We may call this the subjective character of experience.” If a creature is phenomenally conscious, it has the capacity to experience feelings such as pain or pleasure or hunger, but not necessarily more complex mental states such as self-awareness.</p><p>“I hope the declaration [draws] greater attention to the issues of nonhuman consciousness, and to the ethical challenges that accompany the possibility of conscious experiences far beyond the human,” wrote Seth, a neuroscientist at the University of Sussex, in an email. “I hope it sparks discussion, informs policy and practice in animal welfare, and galvanizes an understanding and appreciation that we have much more in common with other animals than we do with things like ChatGPT.”</p><p><strong>A Growing Awareness</strong></p>
<p>The declaration began to take shape last fall, following conversations between Sebo, Andrews, and Birch. “The three of us were talking about how much has happened over the past 10 years, the past 15 years, in the science of animal consciousness,” Sebo recalled. We now know, for example, that&nbsp;<a href="https://doi.org/10.1016/j.isci.2021.102229" target="_blank" rel="noreferrer noopener">octopuses feel pain</a>&nbsp;and&nbsp;<a href="https://doi.org/10.1038/s41598-020-62335-x" target="_blank" rel="noreferrer noopener">cuttlefish remember details</a>&nbsp;of specific past events. Studies in fish have found that&nbsp;<a aria-label=" (opens in a new tab)" href="https://www.quantamagazine.org/a-self-aware-fish-raises-doubts-about-a-cognitive-test-20181212/" target="_blank" rel="noreferrer noopener">cleaner wrasse appear to pass</a>&nbsp;a version of the “mirror test,” which indicates a degree of self-recognition, and that&nbsp;<a href="https://doi.org/10.3389/fvets.2022.1062420" target="_blank" rel="noreferrer noopener">zebra fish show signs of curiosity</a>. In the insect world,&nbsp;<a href="https://doi.org/10.1016/j.anbehav.2022.08.013" target="_blank" rel="noreferrer noopener">bees show apparent play behavior</a>, while&nbsp;<a href="https://doi.org/10.7554/eLife.88198.2" target="_blank" rel="noreferrer noopener"><em>Drosophila</em>&nbsp;fruit flies have distinct sleep patterns</a>&nbsp;influenced by their social environment. Meanwhile,&nbsp;<a href="https://doi.org/10.1038/srep39935" target="_blank" rel="noreferrer noopener">crayfish display anxiety-like states</a>—and those states can be altered by anti-anxiety drugs.</p><figure><img width="800" height="342" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Falk_Hero.png?auto=compress&amp;fit=scale&amp;fm=png&amp;h=438&amp;ixlib=php-3.3.1&amp;w=1024&amp;wpsize=large" srcset="https://assets.nautil.us/sites/3/nautilus/Falk_Hero.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/Falk_Hero.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Falk_Hero.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>INQUIRING MINDS:</strong> After reflecting on recent research into diverse animal minds, Jeff Sebo, Kristin Andrews, and Jonathan Birch (from left) decided to organize scientists and philosophers to sign a declaration that extends consciousness to more animals. <em>Credit: From left: Kate Reeder; Ben Wulf; Maria Moore/LSE.</em></figcaption></figure><p>These and other signs of conscious states in animals that had long been considered less than conscious excited and challenged biologists, cognitive scientists, and philosophers of mind. “A lot of people have now accepted for a while that, for example, mammals and birds are either conscious or very likely to be conscious, but less attention has been paid to other vertebrate and especially invertebrate taxa,” Sebo said. In conversations and at meetings, experts largely agreed that these animals must have consciousness. However, this newly formed consensus wasn’t being communicated to the wider public, including other scientists and policymakers. So the three researchers decided to draft a clear, concise statement and circulate it among their colleagues for endorsement. The declaration is not meant to be comprehensive but rather “to point to where we think the field is now and where the field is headed,” Sebo said.</p><p>The new declaration updates the most recent effort to establish scientific consensus on animal consciousness. In 2012, researchers published the&nbsp;<a href="http://fcmconference.org/img/CambridgeDeclarationOnConsciousness.pdf" target="_blank" rel="noreferrer noopener">Cambridge Declaration on Consciousness</a>, which said that an array of nonhuman animals, including but not limited to mammals and birds, have “the capacity to exhibit intentional behaviors” and that “humans are not unique in possessing the neurological substrates that generate consciousness.”</p>
<p>The new declaration expands the scope of its predecessor and is also worded more carefully, Seth wrote. “It doesn’t try to do science by diktat, but rather emphasizes what we should take seriously regarding animal consciousness and the relevant ethics given the evidence and theories that we have.” He wrote that he is “not in favor of avalanches of open letters and the like,” but that he ultimately “came to the conclusion that this declaration was very much worth supporting.”</p><blockquote>
<p>It’s not enough for people to prevent animals in captivity from experiencing bodily pain and discomfort.</p>
</blockquote><p>Godfrey-Smith, a philosopher of science at the University of Sydney who has worked extensively with octopuses, believes that the complex behaviors those creatures exhibit—including problem-solving, tool use, and play behavior—can only be interpreted as indicators of consciousness. “They’ve got this attentive engagement with things, with us and with novel objects that makes it very hard not to think that there’s quite a lot going on inside them,” he said. He noted that recent papers looking at pain and dreamlike states in octopuses and cuttlefish “point in the same direction … toward experience as being a real part of their lives.”</p><p>While many of the animals mentioned in the declaration have brains and nervous systems that are very different from those of humans, the researchers say that this needn’t be a barrier to consciousness. For example, a bee’s brain contains only about a million neurons, compared to some 86 billion in the case of humans. But each of those bee neurons may be as structurally complex as an oak tree. The network of connections they form is also incredibly dense, with each neuron contacting perhaps 10,000 or 100,000 others. The nervous system of an octopus, by contrast, is complex in other ways. Its organization is highly distributed rather than centralized; a severed arm can exhibit many of the behaviors of the intact animal.</p>
<figure><img width="800" height="496" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Falk_breaker.png?auto=compress&amp;fit=scale&amp;fm=png&amp;h=635&amp;ixlib=php-3.3.1&amp;w=1024&amp;wpsize=large" srcset="https://assets.nautil.us/sites/3/nautilus/Falk_breaker.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/Falk_breaker.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Falk_breaker.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>ANIMAL AWARENESS:</strong> Recent research on animal minds—including those of crayfish, octopuses, snakes, and fish—suggests that consciousness “can exist in a [neural] architecture that looks completely alien” to ours, Peter Godfrey-Smith said. <em>Credit: Clockwise from top left: Svetlana123/iStock; Colin Marshal/Biosphoto/Science Source; MATTHIASRABBIONE/iStock; Jim Maley/iStock.</em></figcaption></figure><p>The upshot, Andrews said, is that “we might not need nearly as much equipment as we thought we did” to achieve consciousness. She noted, for example, that even a cerebral cortex—the outer layer of the mammalian brain, which is believed to play a role in attention, perception, memory, and other key aspects of consciousness—may not be necessary for the simpler phenomenal consciousness targeted in the declaration.</p><p>“There was a big debate about whether fish are conscious, and a lot of that had to do with them lacking the brain structures that we see in mammals,” she said. “But when you look at birds and reptiles and amphibians, they have very different brain structures and different evolutionary pressures—and yet some of those brain structures, we’re finding, are doing the same kind of work that a cerebral cortex does in humans.”</p><p>Godfrey-Smith agreed, noting that behaviors indicative of consciousness “can exist in an architecture that looks completely alien to vertebrate or human architecture.”</p>
<p><strong>Mindful Relations</strong></p><p>While the declaration has implications for the treatment of animals, and especially for the prevention of animal suffering, Sebo noted that the focus should go beyond pain. It’s not enough for people to prevent animals in captivity from experiencing bodily pain and discomfort, he said. “We also have to provide them with the kinds of enrichment and opportunities that allow them to express their instincts and explore their environments and engage in social systems and otherwise be the kinds of complex agents they are.”</p><p>But the consequences of bestowing the label of “conscious” onto a wider array of animals—particularly animals whose interests we are not used to considering—are not straightforward. For example, our relationship with insects may be “inevitably a somewhat antagonistic one,” Godfrey-Smith said. Some pests eat crops, and mosquitoes can carry diseases. “The idea that we could just sort of make peace with the mosquitoes—it’s a very different thought than the idea that we could make peace with fish and octopuses,” he said.</p><p>Similarly, little attention is given to the well-being of insects such as<em>&nbsp;Drosophila</em>, which are widely used in biology research. “We think about the welfare of livestock and of mice in research, but we never think about the welfare of the insects,” said&nbsp;<a href="https://hosting.med.upenn.edu/hearing/team/" target="_blank" rel="noreferrer noopener">Matilda Gibbons</a>, who researches the neural basis of consciousness at the University of Pennsylvania and has signed the declaration.</p>
<p>While scientific bodies have created some standards for the treatment of lab mice, it’s not clear if today’s declaration will lead to new standards for the treatment of insects. But new scientific findings do sometimes spark new policies. Britain, for example,&nbsp;<a href="https://www.lse.ac.uk/News/Latest-news-from-LSE/2021/k-November-21/Octopuses-crabs-and-lobsters-welfare-protection" target="_blank" rel="noreferrer noopener">enacted legislation</a>&nbsp;to increase protection for octopuses, crabs, and lobsters after a London School of Economics&nbsp;<a href="https://www.lse.ac.uk/business/consulting/reports/review-of-the-evidence-of-sentiences-in-cephalopod-molluscs-and-decapod-crustaceans" target="_blank" rel="noreferrer noopener">report</a>&nbsp;indicated that those animals can experience pain, distress, or harm.</p><p>While the declaration makes no mention of artificial intelligence, the issue of possible AI consciousness has been on the minds of animal-consciousness researchers. “Current AI systems are very unlikely to be conscious,” Sebo said. However, what he’s learned about animal minds “does give me pause and makes me want to approach the topic with caution and humility.”</p><p>Andrews hopes that the declaration will spark more research into animals that have often been overlooked, a move that has the potential to further expand our awareness of the scope of consciousness in the animal world. “All these nematode worms and fruit flies that are in almost every university—study consciousness in them,” she said. “You already have them. Somebody in your lab is going to need a project. Make that project a consciousness project. Imagine that!”</p><p><em>This article was&nbsp;<a aria-label=" (opens in a new tab)" href="https://www.quantamagazine.org/insects-and-other-animals-have-consciousness-experts-declare-20240419/" target="_blank" rel="noreferrer noopener">originally published</a>&nbsp;on the</em>&nbsp;&nbsp;<a href="https://www.quantamagazine.org/abstractions/" target="_blank" rel="noreferrer noopener">Quanta Abstractions</a><em>&nbsp;blog.&nbsp;</em></p>
<p><em>Lead image: What’s going on in the mind of a bee? There’s “a realistic possibility” of consciousness, according to a new declaration. Credit: Tran The Ngoc/Shutterstock.</em></p> <ul>
<li>
<div>
<h6>
Dan Falk </h6>
<p>
Posted on May 3, 2024 </p>
</div>
<p>
Dan Falk (@danfalk) is a science journalist and broadcaster based in Toronto. His books include <i>The Science of Shakespeare</i> and <i>In Search of Time</i>. </p>
</li>
</ul>
<div>
<p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
<h4>Get the Nautilus newsletter</h4>
<p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
</div>

</div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I never stopped learning from Daniel Dennett (107 pts)]]></title>
            <link>https://nautil.us/i-never-stopped-learning-from-daniel-dennett-569904/</link>
            <guid>40254047</guid>
            <pubDate>Sat, 04 May 2024 01:23:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/i-never-stopped-learning-from-daniel-dennett-569904/">https://nautil.us/i-never-stopped-learning-from-daniel-dennett-569904/</a>, See on <a href="https://news.ycombinator.com/item?id=40254047">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><span>T</span>hey say, never meet your heroes. Daniel Dennett, who was exceptional in so many ways, and who died last month, was for me an exception to this rule, too.</p><p>Like so many, I was first inspired by Dennett on reading one of his many bestsellers: <a aria-label=" (opens in a new tab)" href="https://www.hachettebookgroup.com/titles/daniel-c-dennett/consciousness-explained/9780316439480/?lens=little-brown" target="_blank" rel="noreferrer noopener"><em>Consciousness Explained</em></a>. It was 1991 and I was a fresh undergraduate with a powerful but undirected interest in consciousness. I had no idea how to go about studying it, or how to think about it. I was studying physics at Cambridge and had just plowed my way through Roger Penrose’s <a aria-label=" (opens in a new tab)" href="https://global.oup.com/academic/product/the-emperors-new-mind-9780198784920?cc=us&amp;lang=en&amp;" target="_blank" rel="noreferrer noopener"><em>The Emperor’s New Mind</em></a>, which had left me confused and despondent. Dennett’s book, with its presumptuous but oh-so-appealing title, was both a tease and a salve. I devoured it.</p>

<p>I didn’t agree with, or follow, everything. But I learned so much from his clear, witty writing, and from his famous “<a aria-label=" (opens in a new tab)" href="https://wwnorton.com/books/Intuition-Pumps-And-Other-Tools-for-Thinking/" target="_blank" rel="noreferrer noopener">intuition pump</a>” thought experiments. I was left with the strong impression that consciousness, if not explained, was explainable, and I now had a north star to steer by.</p><blockquote>
<p>Learning from him could sometimes feel like looking straight at the sun.</p>
</blockquote>
<p>Years passed. I thought I might meet him when he examined the doctoral thesis of a friend of mine who was studying with me at the University of Sussex, but it turned out they met over Skype. I would hear stories about him from one of my mentors at the University of Sussex and one of Dennett’s great friends, the philosopher Maggie Boden. These were tales of philosophical bust-ups, of sailing adventures, and of a voracious and seemingly unbounded intellectual appetite. The impression was of someone larger-than-life, who delighted in engaging with the world rather than preaching from an ivory tower. I read every book he wrote, and many of his papers. But the man himself remained remote.</p><p>I finally met Dennett in 2016. I’d recently joined a group of researchers at the <a aria-label=" (opens in a new tab)" href="https://cifar.ca/research-programs/brain-mind-consciousness/" target="_blank" rel="noreferrer noopener">Brain, Mind, and Consciousness Program</a> of the Canadian Institute for Advanced Research, where Dennett had served as a long-time advisor. I remember feeling nervous when approaching him in the hotel bar before one of our meetings to say hello for the first time, but I needn’t have worried. Dennett was as approachable and avuncular in person as he was esteemed and revered in academia. Which is <em>very</em>. I don’t remember what we talked about then, but in the conversations and email exchanges that followed over the years he unfailingly exuded kindness, intellectual generosity, and perspicuity. He would tell you exactly what he thought, and he had the ability to do so in a way that made you feel improved, rather than dumb for making some stupid mistake.</p><p>Two examples stand out. The first is from seven years ago. I was in Vancouver, about to give a <a href="https://www.ted.com/talks/anil_seth_your_brain_hallucinates_your_conscious_reality?language=en" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">TED talk</a>, and I was terrified. There were hundreds of influential people watching in person, and thousands more online. The next 16 minutes could be transformational or a total flop. But of all the people there whose opinions might matter, the one person I really didn’t want to disappoint was Dan Dennett.</p><p>Afterward, amid the high-fiving and catharsis, I noticed a short tweet from Dennett.</p>
<figure><img width="800" height="231" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/TgDmwTgL-Seth_BREAKER.png?auto=compress&amp;fit=scale&amp;fm=png&amp;h=296&amp;ixlib=php-3.3.1&amp;w=1024&amp;wpsize=large" srcset="https://assets.nautil.us/sites/3/nautilus/TgDmwTgL-Seth_BREAKER.png?q=65&amp;auto=format&amp;w=1600 800w,https://assets.nautil.us/sites/3/nautilus/TgDmwTgL-Seth_BREAKER.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/TgDmwTgL-Seth_BREAKER.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"></figure><p>“Almost perfect but not quite.” This combination of generosity and gentle criticism was typical. And he was right. In my talk I’d made the mistake of using the phrase “inner movie” to describe the multisensory immersive nature of conscious experience. But an inner movie implies an inner movie-watcher, a Cartesian homunculus of exactly the sort that Dennett—and I—wanted to expunge. This wasn’t a technicality. It was a give-away that I hadn’t really internalized the insight.</p><p>The second example was from a pandemic year. I was finalizing the first draft of my book <a href="https://www.penguinrandomhouse.com/books/566315/being-you-by-anil-seth/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener"><em>Being You</em></a> and, with some hesitation, I’d asked Dan if he’d be willing to consider writing a blurb for the cover. He declined, disarmingly—explaining that he’d decided some time back not to do any more blurbs, and if he changed his mind for me he’d risk upsetting many of his colleagues and friends he’d already said no to. But to my amazement he offered something much more valuable. He said he would set the draft as the reading for his next course at Tufts University, and then we could have two or three long Zoom sessions going through each chapter in detail with him and his class of talented students. It still astounds me that he took the time to do this, but he did, and the discussions we had in these sessions improved the book no end.</p><figure><img width="800" height="569" alt="In Body Image" src="https://assets.nautil.us/sites/3/nautilus/Seth_BREAKER-2.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1" srcset="https://assets.nautil.us/sites/3/nautilus/Seth_BREAKER-2.png?auto=compress&amp;fm=png&amp;ixlib=php-3.3.1 800w,https://assets.nautil.us/sites/3/nautilus/Seth_BREAKER-2.png?q=65&amp;auto=format&amp;w=1200 600w,https://assets.nautil.us/sites/3/nautilus/Seth_BREAKER-2.png?q=65&amp;auto=format&amp;w=800 400w" loading="lazy"><figcaption><strong>THE GENTLE GIANT: </strong>Anil Seth with his personal hero Daniel Dennett. Seth was struck by Dennett’s combination of kindness, intellectual generosity, and perspicuity—his talent for gentle criticism that made one feel improved rather than chastened. <em>Photo courtesy of Anil Seth.</em></figcaption></figure>
<p>I never stopped learning from Dennett. I found myself coming round to his way of thinking on many things: <a aria-label=" (opens in a new tab)" href="https://www.simonandschuster.com/books/Darwins-Dangerous-Idea/Daniel-C-Dennett/9780684824710" target="_blank" rel="noreferrer noopener">the centrality of evolution</a> for understanding the mind, <a aria-label=" (opens in a new tab)" href="https://mitpress.mit.edu/9780262540421/elbow-room/" target="_blank" rel="noreferrer noopener">how to think about free will</a> (though in 2021 we found ourselves on opposite sides of <a href="https://www.youtube.com/watch?v=MA4tGpJPc8Q" target="_blank" aria-label="a debate (opens in a new tab)" rel="noreferrer noopener">a debate</a> on the topic), and of course the absence of—or any need for—an inner observer, homunculus, or theater in the brain where everything “comes together.” But learning from him could sometimes feel like looking straight at the sun. I had to look away, to approach things sidelong, sparking the worry that I’d never fully grasp the weight of his arguments.</p><p>Dennett was often described as a philosophical “<a aria-label=" (opens in a new tab)" href="https://keithfrankish.github.io/articles/Frankish_Illusionism%20as%20a%20theory%20of%20consciousness_eprint.pdf" target="_blank" rel="noreferrer noopener">illusionist</a>,” a position sometimes caricatured as saying that consciousness doesn’t exist. (A criticism of his 1991 book was that it should’ve been called <em>Consciousness Explained Away</em>.) But illusionism doesn’t, in fact, say this. On one reading, it says we are mistaken to think that the relationship between consciousness and physical, biological processes in the brain is a big mystery—the mystery that fellow philosopher David Chalmers calls the “<a href="https://nautil.us/whats-so-hard-about-understanding-consciousness-238421/" target="_blank" aria-label=" (opens in a new tab)" rel="noreferrer noopener">hard problem</a>” of consciousness. On another reading, which I’m more sympathetic to, it says that consciousness exists, but it might not be what we think it is—in the same way that the color red exists, but is not what we might think it is—there is no redness out there in the world nor is there a red “figment” in the mind, to borrow another of Dennett’s delightful terms.</p><p>I always looked forward to discussing these ideas with Dennett, and to chatting about them with my colleagues and friends, all of us trying to figure out what Dennett might really be thinking. One dimension of the sense of loss I now feel is that these discussions will become historical, a matter of interpretation and exegesis, rather than the living, vital process they so recently were.</p><p>In his later years, Dennett was fond of riffing on Chalmers’ hard problem with what he called the “hard question”: Once some (mental) content reaches consciousness, “then what happens?” This was his way of sending up the many theories that propose that conscious experience might somehow arise out of, or emerge from, this-or-that aspect of brain activity. Neurons fire in synchrony? Or with a certain form of complexity? <em>And then what happens? </em>In his diagnosis, the struggles of consciousness science lay in the systematic failure to properly ask, and answer, this question.</p>
<p>Daniel Clement Dennett was a gentle giant of the intellectual world. I, along with many others, will miss him deeply. He leaves an unmatched legacy in his books and papers, in how he brought philosophy and science together, and in the legions of students and researchers he taught and inspired. He was, I will assume, a materialist to the end. And in dying, perhaps Dan put his materialist beliefs to the ultimate test. And then what happens? <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p><p><em>Lead image: Master1305 / Shutterstock</em></p> <ul>
<li>
<div>
<h6>
Anil Seth </h6>
<p>
Posted on May 2, 2024 </p>
</div>
<p>
Anil Seth is Professor of Cognitive and Computational Neuroscience and Director of the Centre for Consciousness Science at the University of Sussex. He is also Co-Director of the Canadian Institute for Advanced Research Program on Brain, Mind, and Consciousness, and author of the bestselling book <i>Being You—A New Science of Consciousness.</i> </p>
</li>
</ul>
<div>
<p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
<h4>Get the Nautilus newsletter</h4>
<p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
</div>

</div> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Bloom – A shadcn like UI library for Elixir and Phoenix (141 pts)]]></title>
            <link>https://bloom-ui.fly.dev/</link>
            <guid>40253774</guid>
            <pubDate>Sat, 04 May 2024 00:23:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bloom-ui.fly.dev/">https://bloom-ui.fly.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=40253774">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <div>
  <div>
    <h2>
    <img src="https://bloom-ui.fly.dev/images/bloom-73d514c8254d4d96629ebf3f805cd78f.png?vsn=d">
    <span>
  Bloom
</span>
    </h2>
  </div>
  <p>
    
      The opinionated, open-source extension to Phoenix Core Components.<br>
      Install a copy of each component using the mix command in seconds.<br>
      Yours to edit and customise.
    
  </p>
  
</div>

  <section>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 128 128">
      <linearGradient id="elixir-original-a" gradientUnits="userSpaceOnUse" x1="835.592" y1="-36.546" x2="821.211" y2="553.414" gradientTransform="matrix(.1297 0 0 .2 -46.03 17.198)">
        <stop offset="0" stop-color="#d9d8dc"></stop><stop offset="1" stop-color="#fff" stop-opacity=".385"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-a)" d="M64.4.5C36.7 13.9 1.9 83.4 30.9 113.9c26.8 33.5 85.4 1.3 68.4-40.5-21.5-36-35-37.9-34.9-72.9z"></path>
      <linearGradient id="elixir-original-b" gradientUnits="userSpaceOnUse" x1="942.357" y1="-40.593" x2="824.692" y2="472.243" gradientTransform="matrix(.1142 0 0 .2271 -47.053 17.229)">
        <stop offset="0" stop-color="#8d67af" stop-opacity=".672"></stop><stop offset="1" stop-color="#9f8daf"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-b)" d="M64.4.2C36.8 13.6 1.9 82.9 31 113.5c10.7 12.4 28 16.5 37.7 9.1 26.4-18.8 7.4-53.1 10.4-78.5C68.1 33.9 64.2 11.3 64.4.2z"></path>
      <linearGradient id="elixir-original-c" gradientUnits="userSpaceOnUse" x1="924.646" y1="120.513" x2="924.646" y2="505.851" gradientTransform="matrix(.1227 0 0 .2115 -46.493 17.206)">
        <stop offset="0" stop-color="#26053d" stop-opacity=".762"></stop><stop offset="1" stop-color="#b7b4b4" stop-opacity=".278"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-c)" d="M56.7 4.3c-22.3 15.9-28.2 75-24.1 94.2 8.2 48.1 75.2 28.3 69.6-16.5-6-29.2-48.8-39.2-45.5-77.7z"></path>
      <linearGradient id="elixir-original-d" gradientUnits="userSpaceOnUse" x1="428.034" y1="198.448" x2="607.325" y2="559.255" gradientTransform="matrix(.1848 0 0 .1404 -42.394 17.138)">
        <stop offset="0" stop-color="#91739f" stop-opacity=".46"></stop><stop offset="1" stop-color="#32054f" stop-opacity=".54"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-d)" d="M78.8 49.8c10.4 13.4 12.7 22.6 6.8 27.9-27.7 19.4-61.3 7.4-54-37.3C22.1 63 4.5 96.8 43.3 101.6c20.8 3.6 54 2 58.9-16.1-.2-15.9-10.8-22.9-23.4-35.7z"></path>
      <linearGradient id="elixir-original-e" gradientUnits="userSpaceOnUse" x1="907.895" y1="540.636" x2="590.242" y2="201.281" gradientTransform="matrix(.1418 0 0 .1829 -45.23 17.18)">
        <stop offset="0" stop-color="#463d49" stop-opacity=".331"></stop><stop offset="1" stop-color="#340a50" stop-opacity=".821"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-e)" d="M38.1 36.4c-2.9 21.2 35.1 77.9 58.3 71-17.7 35.6-56.9-21.2-64-41.7 1.5-11 2.2-16.4 5.7-29.3z"></path>
      <linearGradient id="elixir-original-f" gradientUnits="userSpaceOnUse" x1="1102.297" y1="100.542" x2="1008.071" y2="431.648" gradientTransform="matrix(.106 0 0 .2448 -47.595 17.242)">
        <stop offset="0" stop-color="#715383" stop-opacity=".145"></stop><stop offset="1" stop-color="#f4f4f4" stop-opacity=".234"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-f)" d="M60.4 49.7c.8 7.9 3.9 20.5 0 28.8S38.7 102 43.6 115.3c11.4 24.8 37.1-4.4 36.9-19 1.1-11.8-6.6-38.7-1.8-52.5L76.5 41l-13.6-4c-2.2 3.2-3 7.5-2.5 12.7z"></path>
      <linearGradient id="elixir-original-g" gradientUnits="userSpaceOnUse" x1="1354.664" y1="140.06" x2="1059.233" y2="84.466" gradientTransform="matrix(.09173 0 0 .2828 -48.536 17.28)">
        <stop offset="0" stop-color="#a5a1a8" stop-opacity=".356"></stop><stop offset="1" stop-color="#370c50" stop-opacity=".582"></stop>
      </linearGradient>
      <path fill-rule="evenodd" clip-rule="evenodd" fill="url(#elixir-original-g)" d="M65.3 10.8C36 27.4 48 53.4 49.3 81.6l19.1-55.4c-1.4-5.7-2.3-9.5-3.1-15.4z"></path><path fill-rule="evenodd" clip-rule="evenodd" fill="#330A4C" fill-opacity=".316" d="M68.3 26.1c-14.8 11.7-14.1 31.3-18.6 54 8.1-21.3 4.1-38.2 18.6-54z"></path><path fill-rule="evenodd" clip-rule="evenodd" fill="#FFF" d="M45.8 119.7c8 1.1 12.1 2.2 12.5 3 .3 4.2-11.1 1.2-12.5-3z"></path><path fill-rule="evenodd" clip-rule="evenodd" fill="#EDEDED" fill-opacity=".603" d="M49.8 10.8c-6.9 7.7-14.4 21.8-18.2 29.7-1 6.5-.5 15.7.6 23.5.9-18.2 7.5-39.2 17.6-53.2z"></path>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 128 128">
      <path fill="#fd4f00" d="m48.067 81.275-1.006-.183c-7.145-1.329-11.66-5.65-13.797-12.447-1.337-4.237 1.087-7.355 5.53-7.56 3.637-.17 6.129 1.922 8.33 4.355 2.839 3.135 5.44 6.486 8.228 9.67 4.014 4.583 8.744 7.534 15.215 6.623 5.801-.816 10.86-3.144 15.258-6.977.661-.576 1.387-1.079 2.085-1.615l-.44-.518c-3.694 1.15-7.46 1.533-11.31 1.34-5.823-.292-11.373-1.51-16.338-4.706-4.531-2.918-7.873-6.828-9.46-12.05-1.283-4.22 1.34-7.171 5.715-6.561 1.727.242 3.181 1.02 4.489 2.122 1.062.9 2.083 1.85 3.167 2.722 5.104 4.102 12.235 4.33 18.71-.124-10.648-.048-17.893-5.907-24.256-13.33-2.49-2.905-4.921-5.861-7.464-8.722-4.919-5.533-10.375-10.407-17.844-12.072-9.548-2.122-18.762-.732-27.606 3.316-1.763.807-3.456 1.748-5.273 3.26.9 0 1.39.01 1.88 0 4.46-.117 7.802 1.864 10.212 5.512 1.754 2.655 2.58 5.657 3.21 8.745.935 4.584.45 9.255.991 13.861 1.387 11.837 7.437 20.097 18.701 24.327 4.132 1.552 8.368 2.068 13.072 1.01zm-28.471-54c-1.779.448-3.201-.27-4.666-1.753 2.51-.625 4.724-.868 7.103-.963-.195 1.546-1.107 2.38-2.435 2.716zm58.332 69.126c-.155-1.141-1.13-1.643-1.896-2.238-3.384-2.636-7.345-3.57-11.543-3.646-2.506-.047-4.986-.233-7.347-1.112-1.084-.4-2.298-.92-2.268-2.318.027-1.422 1.263-1.823 2.388-2.159.92-.272 1.87-.45 2.917-.695-2.661-1.706-5.261-1.941-8.726-.547-5.456 2.19-10.833 1.932-16.27-.03-3.07-1.11-5.795-2.85-8.63-4.39l-.078.055a5.395 5.395 0 0 0 .072-.054c-.07-.213-.195-.219-.359-.098l.222.195c2.351 3.855 5.53 6.957 9.121 9.608 6.914 5.103 14.465 8.148 23.302 6.798a121.601 121.601 0 0 1 8.608-1.008c3.61-.292 7.047.726 10.487 1.639zm-16.66-55.31c-.192-.138-.376-.484-.767-.126 3.181 4.302 7.264 7.47 12.182 9.466 7.936 3.221 15.991 3.773 24.23.93 6.397-2.206 10.995-.051 13.384 6.16.346-7.209-3.896-12.462-10.65-13.49-3.8-.58-7.31.68-10.867 1.713-9.905 2.872-19.112 1.455-27.513-4.653zm49.367 28.116c1.29.107 2.582.224 3.872.337-2.916-2.56-6.47-2.765-10.067-2.56-5.473.31-9.417 3.47-13.014 7.24-3.17 3.326-6.034 7.055-10.76 8.392.08.142.1.214.122.214.636.009 1.272.038 1.907.009 6.868-.31 13.338-1.759 18.483-6.744 1.622-1.568 3.07-3.311 4.636-4.94 1.306-1.36 2.887-2.113 4.821-1.95zm-15.954-8.512c-5.125.449-9.576 2.568-13.757 5.364-3.22 2.15-6.66 3.168-10.529 2.497-.68-.12-1.366-.208-2.049-.31l-.023.284c.246.128.483.275.738.378.645.255 1.28.562 1.95.72 7.442 1.77 14.568.864 20.991-3.286 4.049-2.616 8.24-3.112 12.783-2.436.46.07.917.151 1.378.196.426.04.872.463 1.449.005-3.971-2.869-8.25-3.82-12.931-3.412zM76.366 43.298c2.688.093 5.364-.26 8.177-1.93-.825.072-1.172.072-1.508.138-3.875.772-7.351-.073-10.45-2.521-1.135-.898-2.29-1.775-3.442-2.656-4.563-3.488-9.797-4.656-15.52-4.556.091.28.1.474.198.574 6.229 6.297 13.435 10.637 22.545 10.95zm45.07 32.319c-3.853-3.823-9.026-4.314-13.812-.979 3.168.141 5.546 1.152 7.474 3.15a23.695 23.695 0 0 0 2.155 2.015c2.917 2.352 7.858 2.465 10.747.282-3.392-1.323-3.392-1.323-6.563-4.468zm-38.384 29.272c-3.386-6.306-9.079-7.728-15.657-7.305a17.62 17.62 0 0 1 5.426 2.534c1.532 1.068 2.82 2.388 4.09 3.745 2.514 2.685 6.44 4.33 9.043 3.774-1.195-.751-2.257-1.547-2.902-2.748zm31.516-35.215c0-.042.001-.081.004-.124l-.01.011.01-.01-.065-.008.038.032.022.097zM78.114 96.55a13.871 13.871 0 0 0-.132-.076.232.232 0 0 0 .027.079c.01.015.07 0 .106-.003zm-.132-.076-.015-.061-.015.018.015-.018-.04-.01.01.046.043.025z"></path>
    </svg>
    <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 54 33">
      <g clip-path="url(#prefix__clip0)">
        <path fill="#38bdf8" fill-rule="evenodd" d="M27 0c-7.2 0-11.7 3.6-13.5 10.8 2.7-3.6 5.85-4.95 9.45-4.05 2.054.513 3.522 2.004 5.147 3.653C30.744 13.09 33.808 16.2 40.5 16.2c7.2 0 11.7-3.6 13.5-10.8-2.7 3.6-5.85 4.95-9.45 4.05-2.054-.513-3.522-2.004-5.147-3.653C36.756 3.11 33.692 0 27 0zM13.5 16.2C6.3 16.2 1.8 19.8 0 27c2.7-3.6 5.85-4.95 9.45-4.05 2.054.514 3.522 2.004 5.147 3.653C17.244 29.29 20.308 32.4 27 32.4c7.2 0 11.7-3.6 13.5-10.8-2.7 3.6-5.85 4.95-9.45 4.05-2.054-.513-3.522-2.004-5.147-3.653C23.256 19.31 20.192 16.2 13.5 16.2z" clip-rule="evenodd"></path>
      </g>
      <defs>
        <clipPath id="prefix__clip0"><path fill="#fff" d="M0 0h54v32.4H0z"></path></clipPath>
      </defs>
    </svg>
  </section>

  <h2>
    <span>
  
      Use in seconds
    
</span>
    <p>
      Install the dependency, use the mix task, customise, use.
    </p>
  </h2>

  <div>
    <div>
  
  <pre before="$">    
      defp deps do
      [
      {:bloom, "~&gt; 0.0.7"},
      ]
      end
    
  </pre>
</div>
    <div>
  
  <pre before="$">    
      mix bloom.install code_snippet
    
  </pre>
</div>
  </div>

  <h2>
    <span>
  
      Avatars! Avatars!
    
</span>
    <p>
      From dicebear.fm (or your own images)
    </p>
  </h2>

  

  <h2>
    <span>
  
      Look, a bento grid Phoenix Component!
    
</span>
    <p>
      For showing off features, or just for fun.
    </p>
  </h2>

  

  <h2>
    <span>
  
      Marquee &amp; Card Components
    
</span>
    <p>
      Think social proof, showing company logos, and more.
    </p>
  </h2>
  

  <section>
    <h2>
      <span>
  
        Missing a component you want? This is Open Source!
      
</span>
    </h2>
    <a href="https://github.com/chrisgreg/bloom/issues">
      
    </a>
  </section>

  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft ties executive pay to security after multiple failures and breaches (173 pts)]]></title>
            <link>https://arstechnica.com/information-technology/2024/05/microsoft-ties-executive-pay-to-security-following-multiple-failures-and-breaches/</link>
            <guid>40252619</guid>
            <pubDate>Fri, 03 May 2024 21:32:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/information-technology/2024/05/microsoft-ties-executive-pay-to-security-following-multiple-failures-and-breaches/">https://arstechnica.com/information-technology/2024/05/microsoft-ties-executive-pay-to-security-following-multiple-failures-and-breaches/</a>, See on <a href="https://news.ycombinator.com/item?id=40252619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h4>
      lock it down    —
</h4>
            
            <h2 itemprop="description">Microsoft has been criticized for "preventable" failures and poor communication.</h2>
                    </div><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2021/08/Screen-Shot-2021-08-30-at-11.34.41-PM-800x450.jpg" alt="A PC running Windows 11.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2021/08/Screen-Shot-2021-08-30-at-11.34.41-PM.jpg" data-height="1080" data-width="1920">Enlarge</a> <span>/</span> A PC running Windows 11.</p></figcaption>  </figure>

  




<!-- cache hit 113:single/related:83dd7b5ab0a42e9dbe06fd03bce9523f --><!-- empty -->
<p>It's been a bad couple of years for Microsoft's security and privacy efforts. <a href="https://arstechnica.com/information-technology/2022/10/microsoft-under-fire-for-response-to-leak-of-2-4tb-of-sensitive-customer-data/">Misconfigured endpoints</a>, <a href="https://arstechnica.com/security/2023/08/a-renegade-certificate-is-removed-from-windows-then-it-returns-confusion-ensues/">rogue security certificates</a>, and weak passwords have all caused or risked the exposure of sensitive data, and Microsoft has been criticized by security researchers, <a href="https://arstechnica.com/security/2023/07/us-senator-blasts-microsoft-for-negligent-cybersecurity-practices/">US lawmakers</a>, and <a href="https://arstechnica.com/security/2023/08/microsoft-cloud-security-blasted-for-its-culture-of-toxic-obfuscation/">regulatory agencies</a> for how it has responded to and disclosed these threats.</p>

<p>The most high-profile of these breaches involved a China-based hacking group named Storm-0558, which breached Microsoft's Azure service and collected data for over a month in mid-2023 before being discovered and driven out. After <a href="https://arstechnica.com/security/2023/07/microsoft-takes-pains-to-obscure-role-in-0-days-that-caused-email-breach/">months of ambiguity</a>, Microsoft disclosed that a series of security failures gave Storm-0558 access to an engineer's account, which allowed Storm-0558 to collect data from 25 of Microsoft's Azure customers, including US federal agencies.</p>
<p>In January, <a href="https://arstechnica.com/security/2024/01/microsoft-network-breached-through-password-spraying-by-russian-state-hackers/">Microsoft disclosed that it had been breached again</a>, this time by Russian state-sponsored hacking group Midnight Blizzard. The group was able "to compromise a legacy non-production test tenant account" to gain access to Microsoft's systems for "as long as two months."</p>
<p>All of this culminated in a report (<a href="https://www.cisa.gov/sites/default/files/2024-04/CSRB_Review_of_the_Summer_2023_MEO_Intrusion_Final_508c.pdf">PDF</a>) from the US Cyber Safety Review Board, which <a href="https://arstechnica.com/information-technology/2024/04/microsoft-blamed-for-a-cascade-of-security-failures-in-exchange-breach-report/">castigated</a> Microsoft for its "inadequate" security culture, its "inaccurate public statements," and its response to "preventable" security breaches.</p>
<p>To attempt to turn things around, Microsoft announced something it called the "<a href="https://blogs.microsoft.com/on-the-issues/2023/11/02/secure-future-initiative-sfi-cybersecurity-cyberattacks/">Secure Future Initiative</a>" in November 2023. As part of that initiative, Microsoft today <a href="https://www.microsoft.com/en-us/security/blog/2024/05/03/security-above-all-else-expanding-microsofts-secure-future-initiative/">announced</a> a series of plans and changes to its security practices, including a few changes that have already been made.</p>
<p>"We are making security our top priority at Microsoft, above all else—over all other features," wrote Microsoft Security Executive Vice President Charlie Bell. "We’re expanding the scope of SFI, integrating the recent recommendations from the CSRB as well as our learnings from Midnight Blizzard to ensure that our cybersecurity approach remains robust and adaptive to the evolving threat landscape."</p>                                            
                                                        
<p>As part of these changes, Microsoft will also make its Senior Leadership Team's pay partially dependent on whether the company is "meeting our security plans and milestones," though Bell didn't specify how much executive pay would be dependent on meeting those security goals.</p>
<p>Microsoft's post describes three security principles ("secure by design," "secure by default," and "secure operations") and six "security pillars" meant to address different weaknesses in Microsoft's systems and development practices. The company says it plans to secure 100 percent of all its user accounts with "securely managed, phishing-resistant multifactor authentication," enforce least-privilege access across all applications and user accounts, improve network monitoring and isolation, and retain all system security logs for at least two years, among other promises. Microsoft is also planning to put new deputy Chief Information Security Officers on different engineering teams to track their progress and report back to the executive team and board of directors.</p>
<p>As for concrete fixes that Microsoft has already implemented, Bell writes that Microsoft has "implemented automatic enforcement of multifactor authentication by default across more than 1 million Microsoft Entra ID tenants within Microsoft," removed 730,000 old and/or insecure apps "to date across production and corporate tenants," expanded its security logging, and adopted the <a href="https://msrc.microsoft.com/blog/2024/04/toward-greater-transparency-adopting-the-cwe-standard-for-microsoft-cves/">Common Weakness Enumeration (CWE) standard</a> for its security disclosures.</p>
<p>In addition to Bell's public security promises, The Verge has <a href="https://www.theverge.com/24148033/satya-nadella-microsoft-security-memo">obtained and published an internal memo</a> from Microsoft CEO Satya Nadella that re-emphasizes the company's publicly stated commitment to security. Nadella also says that improving security should be prioritized over adding new features, something that may affect the <a href="https://arstechnica.com/gadgets/2022/09/microsoft-commits-to-updating-windows-11-once-per-year-and-also-all-the-time/">constant stream of tweaks and changes</a> that Microsoft releases for Windows 11 and other software.</p>
<p>"The recent findings by the Department of Homeland Security’s Cyber Safety Review Board (CSRB) regarding the Storm-0558 cyberattack, from summer 2023, underscore the severity of the threats facing our company and our customers, as well as our responsibility to defend against these increasingly sophisticated threat actors," writes Nadella. "If you’re faced with the tradeoff between security and another priority, your answer is clear: <strong>Do security</strong>. In some cases, this will mean prioritizing security above other things we do, such as releasing new features or providing ongoing support for legacy systems."</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I built a free in-browser Llama 3 chatbot powered by WebGPU (386 pts)]]></title>
            <link>https://github.com/abi/secret-llama</link>
            <guid>40252569</guid>
            <pubDate>Fri, 03 May 2024 21:26:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/abi/secret-llama">https://github.com/abi/secret-llama</a>, See on <a href="https://news.ycombinator.com/item?id=40252569">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Secret Llama</h2><a id="user-content-secret-llama" aria-label="Permalink: Secret Llama" href="#secret-llama"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/23818/327878509-0bf43a95-4fe5-4c53-87bc-b558e5c4968f.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQ4MDI3MDcsIm5iZiI6MTcxNDgwMjQwNywicGF0aCI6Ii8yMzgxOC8zMjc4Nzg1MDktMGJmNDNhOTUtNGZlNS00YzUzLTg3YmMtYjU1OGU1YzQ5NjhmLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA0VDA2MDAwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA0ZWYxY2ZlZGI3ZTM0ODM4NjYwODdkNjNkYzg3MmY5OTUwMzM4Zjg5ZGY1OTRhMTgxNmY2Y2QwY2NlMGIzNzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.10o5We7TbisVX426sTof1VRDdjCAb1G7usrfMPhqq6Q"><img src="https://private-user-images.githubusercontent.com/23818/327878509-0bf43a95-4fe5-4c53-87bc-b558e5c4968f.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQ4MDI3MDcsIm5iZiI6MTcxNDgwMjQwNywicGF0aCI6Ii8yMzgxOC8zMjc4Nzg1MDktMGJmNDNhOTUtNGZlNS00YzUzLTg3YmMtYjU1OGU1YzQ5NjhmLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA0VDA2MDAwN1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA0ZWYxY2ZlZGI3ZTM0ODM4NjYwODdkNjNkYzg3MmY5OTUwMzM4Zjg5ZGY1OTRhMTgxNmY2Y2QwY2NlMGIzNzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.10o5We7TbisVX426sTof1VRDdjCAb1G7usrfMPhqq6Q" alt="secret llama" data-animated-image=""></a></p>
<p dir="auto">Entirely-in-browser, fully private LLM chatbot supporting Llama 3, Mistral and other open source models.</p>
<ul dir="auto">
<li>Fully private = No conversation data ever leaves your computer</li>
<li>Runs in the browser = No server needed and no install needed!</li>
<li>Works offline</li>
<li>Easy-to-use interface on par with ChatGPT, but for open source LLMs</li>
</ul>
<p dir="auto">Big thanks to the inference engine provided by <a href="https://github.com/mlc-ai/web-llm">webllm</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">System Requirements</h2><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<p dir="auto">To run this, you need a modern browser with support for WebGPU. According to <a href="https://caniuse.com/?search=WebGPU" rel="nofollow">caniuse</a>, WebGPU is supported on:</p>
<ul dir="auto">
<li>Google Chrome</li>
<li>Microsoft Edge</li>
</ul>
<p dir="auto">It's also available in Firefox, but it needs to be enabled manually through the dom.webgpu.enabled flag. Safari on MacOS also has experimental support for WebGPU which can be enabled through the WebGPU experimental feature.</p>
<p dir="auto">In addition to WebGPU support, various models might have specific RAM requirements.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Try it out</h2><a id="user-content-try-it-out" aria-label="Permalink: Try it out" href="#try-it-out"></a></p>
<p dir="auto">You can <a href="https://secretllama.com/" rel="nofollow">try it here</a>.</p>
<p dir="auto">To compile the React code yourself, download the repo and then, run</p>
<div data-snippet-clipboard-copy-content="yarn
yarn build-and-preview"><pre><code>yarn
yarn build-and-preview
</code></pre></div>
<p dir="auto">If you're looking to make changes, run the development environment with live reload:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Supported models</h2><a id="user-content-supported-models" aria-label="Permalink: Supported models" href="#supported-models"></a></p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Model Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>TinyLlama-1.1B-Chat-v0.4-q4f32_1-1k</td>
<td>600MB</td>
</tr>
<tr>
<td>Llama-3-8B-Instruct-q4f16_1 ⭐</td>
<td>4.3GB</td>
</tr>
<tr>
<td>Phi1.5-q4f16_1-1k</td>
<td>1.2GB</td>
</tr>
<tr>
<td>Mistral-7B-Instruct-v0.2-q4f16_1 ⭐</td>
<td>4GB</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Looking for contributors</h2><a id="user-content-looking-for-contributors" aria-label="Permalink: Looking for contributors" href="#looking-for-contributors"></a></p>
<p dir="auto">We would love contributions to improve the interface, support more models, speed up initial model loading time and fix bugs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Other Projects</h2><a id="user-content-other-projects" aria-label="Permalink: Other Projects" href="#other-projects"></a></p>
<p dir="auto">Check out <a href="https://github.com/abi/screenshot-to-code">screenshot to code</a> and <a href="https://picoapps.xyz/" rel="nofollow">Pico - AI-powered app builder</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Applying Forced Arbitration - opt-out before it is too late! (173 pts)]]></title>
            <link>https://bsky.app/profile/silverwuffamute.bsky.social/post/3kqbd476nvk2i</link>
            <guid>40252525</guid>
            <pubDate>Fri, 03 May 2024 21:20:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.app/profile/silverwuffamute.bsky.social/post/3kqbd476nvk2i">https://bsky.app/profile/silverwuffamute.bsky.social/post/3kqbd476nvk2i</a>, See on <a href="https://news.ycombinator.com/item?id=40252525">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Physics of Karate (2021) (115 pts)]]></title>
            <link>https://daily.jstor.org/the-physics-of-karate/</link>
            <guid>40251317</guid>
            <pubDate>Fri, 03 May 2024 19:25:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daily.jstor.org/the-physics-of-karate/">https://daily.jstor.org/the-physics-of-karate/</a>, See on <a href="https://news.ycombinator.com/item?id=40251317">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>
								The <span></span> icon indicates free access to the linked research on JSTOR.
							</p>
							<p>In the late 1970s, a team of karate-loving physicists decided to perform an experiment inspired by their collective passion for martial arts. The group was made up of physicist Michael Feld, a brown belt who liked to illustrate the physics of karate via <a href="https://www.youtube.com/watch?v=REcj-zaG4Lc">live demonstrations to his classes at the Massachusetts Institute of Technology</a>; Ronald McNair, <a href="https://greensboro.com/news/local_news/30-things-you-should-know-about-astronaut-ronald-mcnair/article_35a46ea7-b52b-5be5-91ec-6d02a023dfe4.html">future astronaut and fifth-degree black belt</a>; and undergraduate Stephen Wilk.</p><p><a href="https://bit.ly/30jM88p"><img decoding="async" src="https://daily.jstor.org/wp-content/uploads/2024/03/jstor_daily_patreon_membership_hat_800.jpg" alt="JSTOR Daily Membership Ad" width="800" height="196"><img src="https://daily.jstor.org/wp-content/uploads/2024/03/jstor_daily_patreon_membership_hat_mobile_800.jpg" alt="JSTOR Daily Membership Ad"></a></p>
<p>“<a href="https://www.jstor.org/stable/24965179?mag=the-physics-of-karate">The picture of a karate expert breaking stout slabs of wood and concrete with his bare hand is a familiar one</a>,” begins a 1979 paper by Feld, McNair, and Wilk. The trio wanted to know: How can a bare hand demolish a solid block of wood or concrete without injury? What’s the trick?</p>
		
		
<p>As it turns out, there’s no trick—the perfect karate strike is nothing more than a precise application of Newton’s laws.</p>
<p>Feld, McNair, and Wilk placed wood and concrete in a hydraulic press to determine the amount of stress (force) needed to crack the underside of the objects. A wood plank can bend by about one centimeter before it breaks, which requires a force of 500 <a href="https://en.wikipedia.org/wiki/Newton_(unit)">newtons</a>. Concrete blocks only need to be deflected one millimeter before breaking, but since the material is less bendable than wood, that displacement requires 2,500 to 3,000 newtons. And because some energy is lost upon collision, the fist needs to exert <i>even more</i> force than that in order to actually break the blocks.</p>
<p>Thankfully, the human hand is capable of generating a very high degree of force in a very short period of time. The impact from a typical strike lasts only about five milliseconds. Through a combination of theory and experiment, the team discovered that within this brief flash of time, “the hand of the karateka, or practitioner of karate, can…exert a force of more than 3,000 newtons, a wallop of 675 pounds.” The team’s model indicates that the hand must reach a speed of 6.1 meters per second to break wood and 10.6 meters per second to break concrete. “Such speeds agree with our observation that beginners can break wood but not concrete,” they write. “A hand velocity of 6.1 meters per second is within range of the beginner, but a velocity of 10.6 meters per second calls for training and practice.”</p>

	<div>
		<h4>Weekly Newsletter</h4>
		


	</div>
	
<p>Feld and McNair were able to show off their martial arts skills during the investigation. Both were photographed striking a pile of wood planks at 120 frames per second. This allowed them to measure the displacement, velocity, and acceleration of different parts of the fist. These photos showed that the fist compresses and distorts “to such an extent that it scarcely behaves like a solid object.”</p>
<p>The obvious follow-up question: “How is it that the hand of the karateka is not shattered by the force of the karate strike?” Here, it’s anatomy to the rescue: Human bone is five times stiffer than concrete and fifty times harder to break (successfully karate-chopping a femur would take more than 25,000 newtons’ worth of force). The bones in the hand are easily able to absorb the stress of the impact. Of course, it’s technique, not strength, that provides the real power. A successful strike needs to hit the board precisely in the center. With enough training, karate represents the human body at its maximum, the group writes, and “The precision demanded…makes karate not only an excellent physical discipline but also a mental one.”</p>
<hr>
<p><a href="https://bit.ly/30jM88p">Support JSTOR Daily! Join our new membership program on Patreon today.</a></p>
													</div><div><p><img src="https://daily.jstor.org/wp-content/uploads/2018/02/jstor-logo@2x.png" alt="JSTOR logo" width="65" height="90">
		</p>
		<div>
			<h2>Resources</h2>
			<p>
				JSTOR is a digital library for scholars, researchers, and students. JSTOR Daily readers can access the original research behind our articles for free on JSTOR.			</p>

								<div>
						
												<p>
							By: Michael S. Feld, Ronald E. McNair and Stephen R. Wilk						</p>
													<p>
							Scientific American, Vol. 240, No. 4 (April 1979), pp. 150-161						</p>
						<p>
							Scientific American, a division of Nature America, Inc.						</p>
					</div>
					
		</div>
	</div><div>
		<h4>Get Our Newsletter</h4>
		


	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: BandMatch – "Tinder" but for finding musicians to create bands/collab (398 pts)]]></title>
            <link>https://bandmatch.app</link>
            <guid>40250557</guid>
            <pubDate>Fri, 03 May 2024 18:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bandmatch.app">https://bandmatch.app</a>, See on <a href="https://news.ycombinator.com/item?id=40250557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>Discover nearby musicians so that you can start a band or collaborate on projects.</p>
<p>Find upcoming concerts near you so you don't miss your favorite artists when they are in town.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SATO: Stable Text-to-Motion Framework (103 pts)]]></title>
            <link>https://sato-team.github.io/Stable-Text-to-Motion-Framework/</link>
            <guid>40250525</guid>
            <pubDate>Fri, 03 May 2024 18:07:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sato-team.github.io/Stable-Text-to-Motion-Framework/">https://sato-team.github.io/Stable-Text-to-Motion-Framework/</a>, See on <a href="https://news.ycombinator.com/item?id=40250525">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><span>Attention Stability.</span> For the original text input, we can easily observe the model's
        attention vector for the text. This attention vector reflects the model's attentional ranking of the text,
        indicating the importance of each word to the text encoder's prediction. We hope a stable attention vector
        maintains a consistent ranking even after perturbations.</p>
      <p><span>Prediction Robustness.</span> Even with stable attention, we still cannot achieve stable
        results due to the change in text embeddings when facing perturbations, even with similar attention vectors.
        This requires us to impose further restrictions on the model's predictions. Specifically, in the face of
        perturbations, the model's prediction should remain consistent with the original distribution, meaning the
        model's output should be robust to perturbations.</p>
      <p><span>Balancing Accuracy and Robustness Trade-off.</span> Accuracy and robustness are naturally in
        a trade-off relationship. Our objective is to bolster stability while minimizing the decline in model accuracy,
        thereby mitigating catastrophic errors arising from input perturbations. Consequently, we require a mechanism to
        uphold the model's performance concerning the original input.</p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How hard can generating 1024-bit primes be? (222 pts)]]></title>
            <link>https://glitchcomet.com/articles/1024-bit-primes/</link>
            <guid>40250519</guid>
            <pubDate>Fri, 03 May 2024 18:06:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://glitchcomet.com/articles/1024-bit-primes/">https://glitchcomet.com/articles/1024-bit-primes/</a>, See on <a href="https://news.ycombinator.com/item?id=40250519">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        <header>
            <p>
                <time datetime="2023-01-12">
                    January 12, 2023
                    
                </time>
            </p>
            <hr>
            
        </header>
        <p>Prime numbers are fascinating!</p>
<p>On the one hand they are easy to explain, they are just numbers that have no factors other than one and themselves, but on the other hand they contain endless complexity. They show up in numerous places, ranging from mathematical concepts and conjectures to interesting looking visualizations and cryptography, underpinning many internet standards and security protocols we use everyday.</p>
<p>Despite my fascination with primes I never really explored them in detail. So, I thought I would challenge myself, and what better way to explore primes than to use my interest in coding to generate prime numbers!</p>
<h2>The Challenge</h2>
<div><p>But what kind of prime should I generate? Finding the one billionth prime is too easy, and getting on the <a href="https://primes.utm.edu/largest.html">leaderboard</a> of the <a href="https://en.wikipedia.org/wiki/Largest_known_prime_number">largest known primes</a> is way beyond what I think I can achieve in my first attempt. Combining primes with my interest in cryptography I came up with this -</p><p>

<strong><em>Generate primes that are capable of generating keys for the RSA Algorithm</em></strong></p><p>

As of the writing of this article a good length for RSA keys is <a href="https://en.wikipedia.org/wiki/Key_size#Asymmetric_algorithm_key_lengths">2048 bits</a>. RSA keys are generated by the multiplication of two primes, so to get a 2048-bit key we need two roughly 1024-bit sized primes. That narrows down the challenge to <strong><em>generate 1024-bit primes</em></strong> and now you know why that's the size in the title.</p></div>
<div>
    <p>In addition to the challenge, I also set up some rules for myself:</p>
<ul>
<li>The code has to be written from scratch - otherwise you could just <code>openssl prime -generate -bits 1024</code> and be done! "from scratch" here just means no external dependencies.  </li>
<li>No fancy external hardware or cloud - so you can't just throw additional computing power at the problem. I will use my laptop with an AMD Ryzen 7 CPU and 16gb RAM.  </li>
<li>Generate the primes in "reasonable" time - deliberately left vague so that I optimize a little but not get caught in a over-optimization spiral.  </li>
</ul>
</div>

<p>For the language I picked Rust, mainly because I happened to be learning it recently and this challenge looked like it would be good practice. I feel Rust is low level enough to play around with deeper concepts while being high level enough that the code snippets are relatively easy to understand. I won't be using any of the more complex features of rust because I am not familiar with them yet.</p>
<p>With all that out of the way, let's get started!</p>
<h2>16 bits, the easy bit!</h2>
<p>My plan is to slowly build up to 1024 bits, so I started at 16 bits as a bit of a warm up. In theory, the process to generate any N-bit primes is easy - </p>
<div><pre><span></span><code><span>while</span><span> </span><span>true</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>number</span><span> </span><span>=</span><span> </span><span>&lt;&lt;</span><span>random</span><span> </span><span>N</span><span>-</span><span>bit</span><span> </span><span>integer</span><span>&gt;&gt;</span>
<span>    </span><span>if</span><span> </span><span>is_prime</span><span>(</span><span>number</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>break</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<p>Just keep generating new random N-bit numbers until one that passes the primality test is found. Even before I can tackle primality tests though I have my first hurdle, where do I get my random numbers from? Rust has an excellent crate (aka library/package) called <a href="https://docs.rs/rand/latest/rand/">rand</a> that can almost be considered part of the standard library. But before I break my "no dependencies" rule right at the start I thought I should at least try to do it myself. </p>
<p>I remember hearing about <code>/dev/urandom</code> from somewhere, and upon further research it turns out this would fit my use case perfectly. The Linux kernel has a built-in <em>Cryptographically Secure Pseudo Random Number Generator</em> (CSPRNG) which can be accessed by reading from the pseudo device file <code>/dev/urandom</code>. It collects 
<span><span>e</span><span>n</span><span>t</span><span>r</span><span>o</span><span>p</span><span>y</span></span>
 from the user's environment and uses it to periodically seed a deterministic stream cipher called <a href="https://en.wikipedia.org/wiki/Salsa20#ChaCha20_adoption">ChaCha20</a> (fun name!), which can then generate some "true" random bits. I was hesitant to use this at first but <a href="https://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/">a certain article</a> convinced me otherwise.</p>
<p>This is the implementation I came up with - </p>
<div><pre><span></span><code><span>// rng.rs</span>
<span>use</span><span> </span><span>std</span>::<span>fs</span>::<span>File</span><span>;</span>
<span>use</span><span> </span><span>std</span>::<span>io</span>::<span>Read</span><span>;</span>

<span>fn</span> <span>insert_random_bytes</span><span>(</span><span>mut</span><span> </span><span>bytes</span>: <span>&amp;</span><span>mut</span><span>[</span><span>u8</span><span>])</span><span> </span>-&gt; <span>std</span>::<span>io</span>::<span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span><span> </span><span>{</span>
<span>    </span><span>File</span>::<span>open</span><span>(</span><span>"/dev/urandom"</span><span>)</span><span>?</span><span>.</span><span>read_exact</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>bytes</span><span>)</span><span>?</span><span>;</span>
<span>    </span><span>Ok</span><span>(())</span>
<span>}</span>

<span>fn</span> <span>u16</span><span>()</span><span> </span>-&gt; <span>u16</span> <span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>bytes</span><span> </span><span>=</span><span> </span><span>[</span><span>0</span><span>u8</span><span>;</span><span> </span><span>2</span><span>];</span>
<span>    </span><span>insert_random_bytes</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>bytes</span><span>).</span><span>expect</span><span>(</span><span>"Cannot access /dev/urandom"</span><span>);</span>
<span>    </span><span>u16</span>::<span>from_le_bytes</span><span>(</span><span>bytes</span><span>)</span>
<span>}</span>
</code></pre></div>

<p>Note: expressions without a semicolon placed at the end of rust functions act as the function's return value.</p>
<p><code>insert_random_bytes()</code> takes in a mutable array of bytes as input and fills it with the output from <code>/dev/urandom</code>. The <code>u16()</code> function creates a buffer of 2 bytes (16 bits), fills the buffer with random bits and then creates a <code>u16</code> integer from those bits, with <code>u16</code> in rust representing an unsigned 16-bit integer. <code>u16()</code> is then used like this - </p>
<div><pre><span></span><code><span>fn</span> <span>run</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>println!</span><span>(</span><span>"random no - {}"</span><span>,</span><span> </span><span>rng</span>::<span>u16</span><span>()</span><span> </span><span>|</span><span> </span><span>0b1000000000000001</span><span>);</span>
<span>}</span>
</code></pre></div>

<p>The random number returned is OR-ed with <code>0b1000000000000001</code> to set its first and last bit to <code>1</code>. The last bit set to 1 makes it an odd number and the first bit set to 1 ensures that it is a sufficiently large number which covers the entire range of bits I need. </p>
<p>Here's it generating a few 16-bit random numbers -</p>
<div><pre><span></span><code>random no - 36111
random no - 52205
random no - 45689
random no - 33631
</code></pre></div>

<p>Now that I have my very own random number generator let's quickly finish out 16-bit primes. First, a fancy enum to store our results - </p>
<div><pre><span></span><code><span>enum</span> <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>Prime</span><span>,</span>
<span>    </span><span>Composite</span><span>,</span>
<span>}</span>
</code></pre></div>

<p>Then, a basic primality test called <a href="https://en.wikipedia.org/wiki/Trial_division">trial division</a> to check if a number is prime. It loops from <code>3</code> to <code>sqrt(num)</code> and checks if any of them is a factor of <code>num</code> - </p>
<div><pre><span></span><code><span>fn</span> <span>trial_division_simple</span><span>(</span><span>n</span>: <span>u16</span><span>)</span><span> </span>-&gt; <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>root_n</span><span> </span><span>=</span><span> </span><span>(</span><span>n</span><span> </span><span>as</span><span> </span><span>f64</span><span>).</span><span>sqrt</span><span>()</span><span> </span><span>as</span><span> </span><span>u16</span><span>;</span>
<span>    </span><span>for</span><span> </span><span>x</span><span> </span><span>in</span><span> </span><span>3</span><span>..</span><span>root_n</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>n</span><span> </span><span>%</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>    </span><span>PrimeResult</span>::<span>Prime</span>
<span>}</span>
</code></pre></div>

<p>And a basic loop to finish it off - </p>
<div><pre><span></span><code><span>fn</span> <span>run</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u16</span><span>()</span><span> </span><span>|</span><span> </span><span>0b1000000000000001</span><span>;</span>
<span>        </span><span>if</span><span> </span><span>trial_division_simple</span><span>(</span><span>num</span><span>)</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>Prime</span><span> </span><span>{</span>
<span>            </span><span>println!</span><span>(</span><span>"Prime found: {num}"</span><span>);</span>
<span>            </span><span>break</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<div><pre><span></span><code>➜ time cargo run --release 
Prime found: 44809
cargo run --release  0.03s user 0.01s system 99% cpu 0.038 total
</code></pre></div>

<p>This works nicely and on average takes ~40ms to generate 16-bit primes. To confirm that my primes are actually prime, I am using a cool online tester written in WebAssembly (<a href="https://www.alpertron.com.ar/ECM.HTM">hosted here</a>) along with this OpenSSL command - <code>openssl prime &lt;number&gt;</code>.</p>
<p>With this, we have refreshed some basic concepts and warm up is done. Now it's time to move on to the next step!</p>
<h2>64 bits, 4 times the bits!</h2>
<p>After 16 bits I jumped straight to 64-bit numbers. 64-bit architecture is common nowadays on most modern hardware and with 64 bits we are well into the 20 digit numbers range (for context, 1 trillion is 13 digits). Would the simple trial division algorithm be able to handle such large numbers?</p>
<div><pre><span></span><code>➜ time cargo run --release 
Prime found: 14288847644715868907
cargo run --release  30.27s user 0.02s system 99% cpu 30.294 total
</code></pre></div>

<p>It does, kinda. 30 seconds to generate a 64-bit prime does not look great but this is not trial division's full potential. In this section, I will try to push it to its limits.</p>
<p>First, here's a more optimized version of trial division - </p>
<div><pre><span></span><code><span>fn</span> <span>trial_division</span><span>(</span><span>n</span>: <span>u64</span><span>,</span><span> </span><span>start</span>: <span>u64</span><span>)</span><span> </span>-&gt; <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>// assumption: n &gt; 3 and start &gt; 3</span>
<span>    </span><span>let</span><span> </span><span>root_n</span><span> </span><span>=</span><span> </span><span>(</span><span>n</span><span> </span><span>as</span><span> </span><span>f64</span><span>).</span><span>sqrt</span><span>()</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>
<span>    </span><span>for</span><span> </span><span>x</span><span> </span><span>in</span><span> </span><span>(</span><span>start</span><span>..</span><span>(</span><span>root_n</span><span> </span><span>+</span><span> </span><span>1</span><span>)).</span><span>step_by</span><span>(</span><span>6</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>n</span><span> </span><span>%</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>||</span><span> </span><span>n</span><span> </span><span>%</span><span> </span><span>(</span><span>x</span><span> </span><span>+</span><span> </span><span>2</span><span>)</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>    </span><span>PrimeResult</span>::<span>Prime</span>
<span>}</span>
</code></pre></div>

<div>
    <p>Changes:</p>
<ul>
<li>It also accepts a <code>start</code> parameter for where to start the loop from.</li>
<li>The loop steps forward by 6 instead of 1.</li>
<li>Check <code>n % (x + 2) == 0</code> in addition to <code>n % x == 0</code>.</li>
</ul>
</div>

<p>Basically, it only considers factors between <code>start</code> and <code>sqrt(n)</code> that are of the form 6k+1, to quote <a href="https://en.wikipedia.org/wiki/Primality_test#Simple_methods">Wikipedia</a> - </p>
<blockquote>
<p>This is because all integers can be expressed as (6k+i), where i = −1, 0, 1, 2, 3, or 4. Note that 2 divides (6k+0), (6k+2), and (6k+4) and 3 divides (6k+3). So, a more efficient method is to test whether n is divisible by 2 or 3, then to check through all numbers of the form 6k±1 ≤ √n. This is 3 times faster than testing all numbers up to √n. </p>
</blockquote>
<p>Next, a function to generate a list of small primes using this improved trial division - </p>
<div><pre><span></span><code><span>fn</span> <span>generate_small_primes</span><span>&lt;</span><span>const</span><span> </span><span>N</span>: <span>usize</span><span>&gt;</span><span>()</span><span> </span>-&gt; <span>[</span><span>u64</span><span>;</span><span> </span><span>N</span><span>]</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>primes</span>: <span>[</span><span>u64</span><span>;</span><span> </span><span>N</span><span>]</span><span> </span><span>=</span><span> </span><span>[</span><span>0</span><span>;</span><span> </span><span>N</span><span>];</span>
<span>    </span><span>primes</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>2</span><span>;</span>
<span>    </span><span>primes</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>3</span><span>;</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>n</span>: <span>u64</span> <span>=</span><span> </span><span>3</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>nth</span>: <span>u64</span> <span>=</span><span> </span><span>2</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>i</span>: <span>usize</span> <span>=</span><span> </span><span>2</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>limit</span><span> </span><span>=</span><span> </span><span>N</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>

<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>n</span><span> </span><span>+=</span><span> </span><span>2</span><span>;</span>
<span>        </span><span>if</span><span> </span><span>trial_division</span><span>(</span><span>n</span><span>,</span><span> </span><span>5</span><span>)</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>Prime</span><span> </span><span>{</span>
<span>            </span><span>primes</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>n</span><span>;</span>
<span>            </span><span>i</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>            </span><span>nth</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>            </span><span>if</span><span> </span><span>nth</span><span> </span><span>==</span><span> </span><span>limit</span><span> </span><span>{</span>
<span>                </span><span>return</span><span> </span><span>primes</span>
<span>            </span><span>}</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<p>Add another possible state to our result - </p>
<div><pre><span></span><code><span>enum</span> <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>Prime</span><span>,</span>
<span>    </span><span>Composite</span><span>,</span>
<span>    </span><span>Unknown</span><span>,</span><span>   </span><span>// &lt;----- new</span>
<span>}</span>
</code></pre></div>

<p>And then use the list of small primes to do a pre-check for easily divisible numbers before reverting to trial division -</p>
<div><pre><span></span><code><span>fn</span> <span>primes_64bit</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>N</span>: <span>usize</span> <span>=</span><span> </span><span>10000</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>start</span><span> </span><span>=</span><span> </span><span>(</span><span>N</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>primes</span><span> </span><span>=</span><span> </span><span>utils</span>::<span>generate_small_primes</span>::<span>&lt;</span><span>N</span><span>&gt;</span><span>();</span>

<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u64</span><span>()</span><span> </span><span>|</span><span> </span><span>0x8000000000000001</span><span>u64</span><span>;</span>
<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>PrimeResult</span>::<span>Unknown</span><span>;</span>

<span>        </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>N</span><span> </span><span>{</span>
<span>            </span><span>if</span><span> </span><span>num</span><span> </span><span>%</span><span> </span><span>primes</span><span>[</span><span>i</span><span>]</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span>
<span>                </span><span>result</span><span> </span><span>=</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>                </span><span>break</span><span>;</span>
<span>            </span><span>}</span>
<span>        </span><span>}</span>

<span>        </span><span>if</span><span> </span><span>result</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>Unknown</span><span> </span><span>{</span>
<span>            </span><span>result</span><span> </span><span>=</span><span> </span><span>algos</span>::<span>trial_division</span><span>(</span><span>num</span><span>,</span><span> </span><span>start</span><span>)</span>
<span>        </span><span>}</span>

<span>        </span><span>if</span><span> </span><span>result</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>Prime</span><span> </span><span>{</span>
<span>            </span><span>println!</span><span>(</span><span>"Prime found: {num}"</span><span>);</span>
<span>            </span><span>break</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<p>After all that work, here's the result -</p>
<div><pre><span></span><code>➜ time cargo run --release 
Prime found: 12589778476493955313
cargo run --release  6.40s user 0.01s system 99% cpu 6.414 total
</code></pre></div>

<p>That's a nice improvement from the 30 seconds it took previously. There's still some optimization potential left on the table, but if it takes 6 seconds for just 64-bit numbers then it's clear that this cannot scale to 1024-bit numbers.</p>
<p>With this, we have to leave behind the safe cozy lands of deterministic algorithms and enter the realm of uncertainty with probabilistic algorithms!</p>
<h2>128 bits, with a bit of a twist!</h2>
<p>This is where things start to get interesting. At first, I found the concept of probabilistic primality tests strange and tried to look for deterministic algorithms that could handle huge numbers. I did find two - <a href="https://en.wikipedia.org/wiki/Adleman%E2%80%93Pomerance%E2%80%93Rumely_primality_test">APR-CL</a> and <a href="https://en.wikipedia.org/wiki/Elliptic_curve_primality">ECPP</a>. Both of these are so mathematically complex that I could not make sense of their research papers at all, and there isn't much accessible information about them on the internet for someone like me who is bad at math. </p>
<p>After taking a look at discussions online, OpenSSL's <a href="https://github.com/openssl/openssl/blob/master/crypto/bn/bn_prime.c">source code</a> and recommendations by <a href="https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf">NIST</a>, I realized that almost everyone including RSA uses probabilistic algorithms. The catch is that if implemented properly, these algorithms have an extremely low error rate which is negligible. From this point on all algorithms that show up will not "prove" that a number is prime, but will say that it is a "probable prime" with a certain accuracy. The first of these algorithms I explored was <em>Fermat's Little Theorem</em>.</p>
<h3>Fermat's Little Theorem</h3>
<p>This <a href="https://en.wikipedia.org//wiki/Fermat's_little_theorem">theorem</a> by Fermat states: If <span>p</span> is prime and <span>a</span> is any integer not divisible by <span>p</span>, then the number <span>a<sup>p-1</sup></span> is divisible by <span>p</span>. The same thing can be expressed in modular arithmetic as:</p>
<p><span>
a<sup>p-1</sup> = 1 (mod p)
</span></p>
<p>We can pick different values for <span>a</span> where <span>a &lt; p</span>, so by definition <span>a</span> would not be divisible by <span>p</span>, and in theory plugging those values into this relation would tell us whether <span>p</span> is prime or not. </p>
<p>All we have to do is implement this relation in code, beginning with <span>a<sup>p-1</sup></span> and <span>a = 2</span> -</p>
<div><pre><span></span><code><span>fn</span> <span>run</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u128</span><span>()</span><span> </span><span>|</span><span> </span><span>0x80000000000000000000000000000001</span><span>u128</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>base</span><span> </span><span>=</span><span> </span><span>2</span><span>u128</span><span>;</span>
<span>    </span><span>println!</span><span>(</span><span>"{}"</span><span>,</span><span> </span><span>base</span><span>.</span><span>pow</span><span>(</span><span>num</span><span> </span><span>-</span><span> </span><span>1</span><span>);</span>
<span>}</span>
</code></pre></div>

<div><pre><span></span><code>➜ cargo run
...
error[E0308]: mismatched types
   --&gt; src/lib.rs:71:29
    |
71  |     println!("{}", base.pow(num - 1);
    |                         --- ^^^^^^^ expected `u32`, found `u128`
    |                         |
    |                         arguments to this function are incorrect
</code></pre></div>

<p>It took me a minute to realize that this was not an error on my part. The <code>pow()</code> function intentionally takes in a u32, as raising u128 to any higher power would already overflow the u128! Fortunately, our relation above is in modular arithmetic which means we can take the modulus at each step instead of at the end keeping the result less than u128.</p>
<p>basically,</p>
<p><span>
a × b (mod m) = [ a (mod m) × b (mod m) ]  (mod m)
</span></p>
<p>and so -</p>
<p><span>
a<sup>p-1</sup> (mod p) = ((((a × a (mod p)) × a (mod p)) × a (mod p)) × ...... p - 1 times )
</span></p>
<p>The algorithm to implement this is called <em>modular exponentiation</em>. I implemented it by directly following the <a href="https://en.wikipedia.org/wiki/Modular_exponentiation#Pseudocode">pseudocode from Wikipedia</a>, using the version that implements "exponentiation by squaring" for a more efficient algorithm.</p>
<p>Here goes attempt #2 -</p>
<div><pre><span></span><code><span>fn</span> <span>run</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u128</span><span>()</span><span> </span><span>|</span><span> </span><span>0x80000000000000000000000000000001</span><span>u128</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>base</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u128_range</span><span>(</span><span>2</span><span>,</span><span> </span><span>num</span><span> </span><span>-</span><span> </span><span>1</span><span>);</span>
<span>    </span><span>println!</span><span>(</span><span>"{}"</span><span>,</span><span> </span><span>mod_exp</span><span>(</span><span>base</span><span>,</span><span> </span><span>num</span><span> </span><span>-</span><span> </span><span>1</span><span>,</span><span> </span><span>num</span><span>));</span>
<span>}</span>
</code></pre></div>

<div><pre><span></span><code>➜ cargo run                 
...
thread 'main' panicked at 'attempt to multiply with overflow', src/utils.rs:38:16
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
</code></pre></div>

<p>Oh well.</p>
<p>Another thing I didn't realize is that even the multiplication of two u128 can easily become too large for a u128 to store. Defeated for now, I decided to move ahead by storing only 64-bit numbers inside the u128s. Roughly speaking the most amount of space needed for multiplication of two N-bit numbers is 2N, hence the decision to store 64-bit numbers inside u128. This idea of allocating twice the amount of bits needed will show up later too. Interestingly, the previous 64-bit step with trial division had no multiplications which is why it did not run into this issue.</p>
<p>Adding another possible state to the enum - </p>
<div><pre><span></span><code><span>enum</span> <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>Prime</span><span>,</span>
<span>    </span><span>Composite</span><span>,</span>
<span>    </span><span>Unknown</span><span>,</span>
<span>    </span><span>ProbablePrime</span><span>,</span><span>   </span><span>// &lt;----- new</span>
<span>}</span>
</code></pre></div>

<p>And here's the Fermat test implementation. It just runs the equation <code>k</code> times with random bases -</p>
<div><pre><span></span><code><span>fn</span> <span>fermat_test</span><span>(</span><span>num</span>: <span>u128</span><span>,</span><span> </span><span>k</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>k</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>base</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u128_range</span><span>(</span><span>2</span><span>,</span><span> </span><span>num</span><span> </span><span>-</span><span> </span><span>1</span><span>);</span>
<span>        </span><span>if</span><span> </span><span>mod_exp</span><span>(</span><span>base</span><span>,</span><span> </span><span>num</span><span> </span><span>-</span><span> </span><span>1</span><span>,</span><span> </span><span>num</span><span>)</span><span> </span><span>!=</span><span> </span><span>1</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>    </span><span>PrimeResult</span>::<span>ProbablePrime</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>An interesting implementation detail here, the function <code>rng::u128_range()</code> implies that it uniformly selects a random u128 from between <code>2</code> and <code>num - 1</code> but I found it more practical to directly return a random number that's a few bytes shorter than <code>num</code>. This greatly simplifies the logic while still giving us a mostly random sufficiently large number between <code>2</code> and <code>num - 1</code>. Moving forward this trick will be used whenever random values from a range are needed.</p>
<p>Here's the full test! - </p>
<div><pre><span></span><code><span>fn</span> <span>primes_128bit</span><span>()</span><span> </span>-&gt; <span>u128</span> <span>{</span>
<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>(</span><span>rng</span>::<span>u64</span><span>()</span><span> </span><span>|</span><span> </span><span>0x8000000000000001</span><span>u64</span><span>)</span><span> </span><span>as</span><span> </span><span>u128</span><span>;</span>
<span>        </span><span>if</span><span> </span><span>fermat_test</span><span>(</span><span>num</span><span>,</span><span> </span><span>10</span><span>)</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>ProbablePrime</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>num</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<div><pre><span></span><code>➜ time cargo run --release 
Prime found: 9944209443870115157
cargo run --release  0.03s user 0.01s system 99% cpu 0.033 total
</code></pre></div>

<p>That's quite a bit faster than the ~6sec runs we were getting previously for 64 bits, but the fact that it uses a "probable prime" result might already tell you there's a catch. The flaw in Fermat's Little Theorem is - "pseudoprimes". The relation defined by Fermat's Little Theorem is true for all primes but is also additionally true for some composites. If the RNG generates one of these special composites, the code would say it is prime even when its not. These composites, also called "Fermat Pseudoprimes", are rare but still numerous enough that we cannot rely on the accuracy of Fermat's test.</p>
<h3>Miller-Rabin Primality Test</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test">Miller-Rabin</a> test is an improved probabilistic primality test that works on the same principles as Fermat's test, but is much stronger and more practical to use due to a few key differences. For one, in this test no composite number is a strong pseudoprime for all bases at the same time in contrast to Fermat's where such composites exist (called the Carmichael numbers). Miller-Rabin also has a substantially better error rate that can be called "insignificant" in most cases. In fact when looking around for what other people use, like OpenSSL's <a href="https://github.com/openssl/openssl/blob/master/crypto/bn/bn_prime.c">source code</a> and recommendations by <a href="https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.186-4.pdf">NIST</a> mentioned at the start, many sources recommend or are already using Miller-Rabin!</p>
<p>The math behind Miller-Rabin is not that important for implementing the algorithm itself, but nevertheless I will try to summarize what I understood. Feel free to skip it and jump directly to the code.</p>
<p>The relation we looked at in Fermat's test was:  </p>
<p><span>a<sup>n-1</sup> = 1 (mod n)</span>,&nbsp; if <span>n</span> is prime &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (1)</p>
<div>
    <p>A more general form of <span>a<sup>n-1</sup></span> can be written as <span>a<sup>2<sup>s</sup> × d</sup></span>, where:</p>
<ul>
<li><span>d</span> = An odd number left after factoring out all powers of 2 from <span>n</span>.  </li>
<li><span>s</span> = The power of 2 as the factor of <span>n</span>.  </li>
</ul>
</div>

<p>which implies:  </p>
<p><span>n - 1 = 2<sup>s</sup> × d</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (2)</p>
<div>
    <p>Combining (1) and (2), we can say <span>n</span> is a strong probable prime if one of these conditions is true:</p>
<ul>
<li><span>a<sup>d</sup> = 1 (mod n)</span>.</li>
<li><span>a<sup>2<sup>r</sup> × d</sup> = n - 1 (mod n)</span> for some <span>0 &lt;= r &lt; s</span>.</li>
</ul>
</div>

<p>Note: <span>n - 1 (mod n)</span> is equivalent to <span>-1 (mod n)</span>. It is left in the expanded form as I am working with unsigned ints and don't have a way to represent -1.</p>
<p>Essentially, instead of doing a single test on <span>a<sup>n-1</sup></span> it is doing multiple tests - starting with <span>a<sup>2<sup>0</sup> × d</sup></span> which is <span>a<sup>d</sup></span>, then <span>a<sup>2<sup>1</sup> × d</sup></span>, <span>a<sup>2<sup>2</sup> × d</sup></span>, <span>a<sup>2<sup>3</sup> × d</sup></span> and so on until it reaches <span>n</span> at <span>a<sup>2<sup>s</sup> × d</sup></span>.</p>
<p>Here's my implementation, derived by combining the above math with the basic <a href="https://en.wikipedia.org/wiki/Miller%E2%80%93Rabin_primality_test#Miller%E2%80%93Rabin_test">pseudocode</a> described on Wikipedia - </p>
<div><pre><span></span><code><span>fn</span> <span>miller_rabin_test</span><span>(</span><span>n</span>: <span>u128</span><span>,</span><span> </span><span>k</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>d</span><span> </span><span>=</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>1</span><span>;</span>
<span>    </span><span>while</span><span> </span><span>d</span><span> </span><span>%</span><span> </span><span>2</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span>
<span>        </span><span>d</span><span> </span><span>=</span><span> </span><span>d</span><span> </span><span>/</span><span> </span><span>2</span><span>;</span>
<span>        </span><span>s</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>'</span><span>main_loop</span>: <span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>k</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>base</span><span> </span><span>=</span><span> </span><span>rng</span>::<span>u128_range</span><span>(</span><span>2</span><span>,</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>2</span><span>);</span>

<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>utils</span>::<span>mod_exp</span><span>(</span><span>base</span><span>,</span><span> </span><span>d</span><span>,</span><span> </span><span>n</span><span>);</span>
<span>        </span><span>if</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>1</span><span> </span><span>||</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>{</span><span> </span><span>continue</span><span> </span><span>'main_loop</span><span>;</span><span> </span><span>}</span>

<span>        </span><span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>(</span><span>s</span><span> </span><span>-</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span>
<span>            </span><span>x</span><span> </span><span>=</span><span> </span><span>utils</span>::<span>mod_exp</span><span>(</span><span>x</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>n</span><span>);</span>
<span>            </span><span>if</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>{</span><span> </span><span>continue</span><span> </span><span>'main_loop</span><span>;</span><span> </span><span>}</span>
<span>        </span><span>}</span>

<span>        </span><span>return</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>PrimeResult</span>::<span>ProbablePrime</span>
<span>}</span>
</code></pre></div>

<p>The first while loop factors out powers of 2, converting <span>n-1</span> to <span>2<sup>s</sup> × d</span>. Then "main_loop" does all the tests mentioned above, squaring <code>x</code> (raising power by 2) and testing until it reaches <span>2<sup>s-1</sup></span>.</p>
<p>And, the usual loop to find primes - </p>
<div><pre><span></span><code><span>fn</span> <span>primes_128bit</span><span>()</span><span> </span>-&gt; <span>u128</span> <span>{</span>
<span>    </span><span>loop</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>(</span><span>rng</span>::<span>u64</span><span>()</span><span> </span><span>|</span><span> </span><span>0x8000000000000001</span><span>u64</span><span>)</span><span> </span><span>as</span><span> </span><span>u128</span><span>;</span>
<span>        </span><span>if</span><span> </span><span>miller_rabin_test</span><span>(</span><span>num</span><span>,</span><span> </span><span>10</span><span>)</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>ProbablePrime</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>num</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<div><pre><span></span><code>➜ time cargo run --release 
Prime found: 15333511742700010117
cargo run --release  0.03s user 0.01s system 99% cpu 0.042 total
</code></pre></div>

<p>It is as fast as Fermat's test but what about the "probable prime" thing here? Miller-Rabin's worst case error is bound to <span>4<sup>-k</sup></span>, but for large values of <span>n</span>, the error on average is much smaller like <span>8<sup>-k</sup></span>. What's the chance that a Miller-Rabin test with <span>k = 10</span> returns a composite?</p>
<div><pre><span></span><code>➜ python3 -c "print(f'chance of error = {8 ** -10 :.15f}%')"
chance of error = 0.000000000931323%
</code></pre></div>

<p>That is good enough for me :). For context that probability is exactly the same as the probability of getting all heads in 30 consecutive coin tosses (<span>2<sup>-30</sup></span>). In real cryptographic use you have to be a bit more cautious though in how the random bases are picked and <a href="https://www.youtube.com/watch?v=OohldLXyVpc">assume adversarial conditions</a>.</p>
<p>Finally, we have a way to generate random numbers and we have a primality test that is fast and efficient enough to work on big numbers. The only things missing are the big numbers themselves, so let's venture even deeper...</p>
<h2>1024 bits, A bit of a detour?</h2>
<p>At this point it is obvious that we cannot go further than 64 bits by just using rust's built-in integer datatypes. What we need is a "bigint", or an implementation of <a href="https://en.wikipedia.org/wiki/Arbitrary-precision_arithmetic">arbitrary precision arithmetic</a> usually called "bigint" or "bignum" in most languages. The sensible thing to do would be to import a bigint crate for rust and be done, but I am the one who gave myself the constraint of no external dependencies so I am going to follow it.</p>
<p>I guess it's time to build a BigInt :P</p>
<p>"Build a BigInt" is not the answer to "how to generate big primes?", but there won't be any big primes (or composites for that matter) without a BigInt behind them, so we are going to take a bit of a detour and figure out how BigInt works.</p>
<h3>Attempt #1 - BigInt as digits</h3>
<p>After a quick skim of the Wikipedia page for arbitrary precision arithmetic and a brief research session, I found out there are a few ways to go about this. The easiest method was to store all the digits of your big number in an array and so that's what I tried for attempt #1.</p>
<p>At first it starts out really simple. The number is represented as just a list of digits, so implementing addition and multiplication is also easy and I copied the basic pen and paper methods that we learn in middle school into code. Once I reached division I realized that this is not going to be that simple, and after a few failed attempts I gave up. If you want a challenge, pause and try to think how you might implement the pen and paper long division algorithm in code.</p>
<h3>Attempt #2 - BigInt as binary</h3>
<p>After my failed attempt #1, I thought - why not store the numbers in binary? Or more specifically, why not store the number as a list of 0s and 1s? And so began my second attempt.</p>
<p>This was my very simple BigInt, just an array of bool values - </p>
<div><pre><span></span><code><span>const</span><span> </span><span>N</span>: <span>usize</span> <span>=</span><span> </span><span>2048</span><span>;</span>

<span>struct</span> <span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>bits</span>: <span>[</span><span>bool</span><span>;</span><span> </span><span>N</span><span>]</span>
<span>}</span>
</code></pre></div>

<p>The actual size is 2048 instead of 1024 because as we saw earlier multiplying two N-bit numbers needs at most 2N bits of space.</p>
<p>Next we need some arithmetic. I still remember a few fragments of my <em>logic and microprocessor</em> class from university so what I did was basically implement a <a href="https://en.wikipedia.org/wiki/Adder_(electronics)#Full_adder">Full Adder</a> in code to handle addition and subtraction. This is what addition looked like - </p>
<div><pre><span></span><code><span>fn</span> <span>bigint_add</span><span>(</span><span>own</span>: <span>&amp;</span><span>[</span><span>bool</span><span>],</span><span> </span><span>other</span>: <span>&amp;</span><span>[</span><span>bool</span><span>])</span><span> </span>-&gt; <span>[</span><span>bool</span><span>;</span><span> </span><span>N</span><span>]</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>bits</span><span> </span><span>=</span><span> </span><span>[</span><span>false</span><span>;</span><span> </span><span>N</span><span>];</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>carry</span><span> </span><span>=</span><span> </span><span>false</span><span>;</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>i</span><span>,</span><span> </span><span>(</span><span>d1</span><span>,</span><span> </span><span>d2</span><span>))</span><span> </span><span>in</span><span> </span><span>own</span><span>.</span><span>iter</span><span>().</span><span>zip</span><span>(</span><span>other</span><span>.</span><span>iter</span><span>()).</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>bits</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>d1</span><span> </span><span>^</span><span> </span><span>d2</span><span> </span><span>^</span><span> </span><span>carry</span><span>;</span>
<span>        </span><span>carry</span><span> </span><span>=</span><span> </span><span>(</span><span>d1</span><span> </span><span>&amp;</span><span> </span><span>d2</span><span>)</span><span> </span><span>|</span><span> </span><span>(</span><span>carry</span><span> </span><span>&amp;</span><span> </span><span>(</span><span>d1</span><span> </span><span>^</span><span> </span><span>d2</span><span>));</span>
<span>    </span><span>}</span>

<span>    </span><span>if</span><span> </span><span>carry</span><span> </span><span>{</span><span> </span><span>panic!</span><span>(</span><span>"Attempt to add with overflow"</span><span>);</span><span> </span><span>}</span>
<span>    </span><span>bits</span>
<span>}</span>


<span>impl</span><span> </span><span>Add</span><span> </span><span>for</span><span> </span><span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>type</span> <span>Output</span><span> </span><span>=</span><span> </span><span>Self</span><span>;</span>
<span>    </span><span>fn</span> <span>add</span><span>(</span><span>self</span><span>,</span><span> </span><span>other</span>: <span>Self</span><span>)</span><span> </span>-&gt; <span>Self</span><span> </span><span>{</span>
<span>        </span><span>Self</span><span> </span><span>{</span><span> </span><span>bits</span>: <span>bigint_add</span><span>(</span><span>&amp;</span><span>self</span><span>.</span><span>bits</span><span>,</span><span> </span><span>&amp;</span><span>other</span><span>.</span><span>bits</span><span>)</span><span> </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>

<span>impl</span><span> </span><span>AddAssign</span><span> </span><span>for</span><span> </span><span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>fn</span> <span>add_assign</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>self</span><span>,</span><span> </span><span>other</span>: <span>Self</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>self</span><span>.</span><span>bits</span><span> </span><span>=</span><span> </span><span>bigint_add</span><span>(</span><span>&amp;</span><span>self</span><span>.</span><span>bits</span><span>,</span><span> </span><span>&amp;</span><span>other</span><span>.</span><span>bits</span><span>);</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<p>Note: Here I am using the <code>Add</code> and <code>AddAssign</code> traits from rust to override the <code>+</code> and <code>+=</code> operators for my BigInt type and will do the same for all other operators too.</p>
<p>Next I implemented the shift left (<code>&lt;&lt;</code>) and shift right (<code>&gt;&gt;</code>) operators. These just shift the entire list of bits left or right by the given amount, throwing away any overflow.</p>
<div><pre><span></span><code><span>fn</span> <span>bigint_shl</span><span>(</span><span>own</span>: <span>&amp;</span><span>[</span><span>bool</span><span>],</span><span> </span><span>amount</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>[</span><span>bool</span><span>;</span><span> </span><span>N</span><span>]</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>bits</span><span> </span><span>=</span><span> </span><span>[</span><span>false</span><span>;</span><span> </span><span>N</span><span>];</span>
<span>    </span><span>if</span><span> </span><span>amount</span><span> </span><span>&gt;</span><span> </span><span>N</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>bits</span><span>;</span><span> </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>amount</span><span>;</span>
<span>    </span><span>for</span><span> </span><span>bit</span><span> </span><span>in</span><span> </span><span>own</span><span>.</span><span>iter</span><span>().</span><span>take</span><span>(</span><span>N</span><span> </span><span>-</span><span> </span><span>amount</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>bits</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>*</span><span>bit</span><span>;</span>
<span>        </span><span>i</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>bits</span>
<span>}</span>

<span>fn</span> <span>bigint_shr</span><span>(</span><span>own</span>: <span>&amp;</span><span>[</span><span>bool</span><span>],</span><span> </span><span>amount</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>[</span><span>bool</span><span>;</span><span> </span><span>N</span><span>]</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>bits</span><span> </span><span>=</span><span> </span><span>[</span><span>false</span><span>;</span><span> </span><span>N</span><span>];</span>
<span>    </span><span>if</span><span> </span><span>amount</span><span> </span><span>&gt;</span><span> </span><span>N</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>bits</span><span>;</span><span> </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>for</span><span> </span><span>bit</span><span> </span><span>in</span><span> </span><span>own</span><span>.</span><span>iter</span><span>().</span><span>skip</span><span>(</span><span>amount</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>bits</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>*</span><span>bit</span><span>;</span>
<span>        </span><span>i</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>bits</span>
<span>}</span>
</code></pre></div>

<p>Onward to multiplication. A really good thing about working in binary is that multiplication becomes very easy. Binary can only be 0 or 1, so no matter how long a number is, the only two results of its multiplication with a bit can be either 0 or itself. This reduces the classic multiplication algorithm to a much simpler one called "<a href="https://users.utcluj.ro/~baruch/book_ssce/SSCE-Shift-Mult.pdf">shift-and-add</a>" and now it can use the newly implemented "shift" and "add" -</p>
<div><pre><span></span><code><span>fn</span> <span>bigint_mul</span><span>(</span><span>own</span>: <span>&amp;</span><span>[</span><span>bool</span><span>],</span><span> </span><span>other</span>: <span>&amp;</span><span>[</span><span>bool</span><span>])</span><span> </span>-&gt; <span>[</span><span>bool</span><span>;</span><span> </span><span>N</span><span>]</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>n1</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>own</span><span>);</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>current</span><span>;</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>shift</span><span>,</span><span> </span><span>d2</span><span>)</span><span> </span><span>in</span><span> </span><span>other</span><span>.</span><span>iter</span><span>().</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>!</span><span>(</span><span>*</span><span>d2</span><span>)</span><span> </span><span>{</span><span> </span><span>continue</span><span>;</span><span> </span><span>}</span>

<span>        </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>(</span><span>N</span><span> </span><span>-</span><span> </span><span>shift</span><span>)</span><span>..</span><span>N</span><span> </span><span>{</span>
<span>            </span><span>if</span><span> </span><span>own</span><span>[</span><span>i</span><span>]</span><span> </span><span>{</span><span> </span><span>panic!</span><span>(</span><span>"Attempt to multiply with overflow"</span><span>);</span><span> </span><span>}</span>
<span>        </span><span>}</span>

<span>        </span><span>current</span><span> </span><span>=</span><span> </span><span>n1</span><span> </span><span>&lt;&lt;</span><span> </span><span>shift</span><span>;</span>
<span>        </span><span>result</span><span> </span><span>+=</span><span> </span><span>current</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>result</span><span>.</span><span>bits</span>
<span>}</span>
</code></pre></div>

<p>Finally we arrive at division, and the reason why I decided to go with binary, because <a href="https://users.utcluj.ro/~baruch/book_ssce/SSCE-Basic-Division.pdf">binary long division</a> also simplifies the problem quite a lot. Unlike long division with 0-9 digits, the digits of the quotient can only be 1 or 0 in binary which means the intermediate subtractions use either the divisor or 0. This is similar to the "shift-and-add" algorithm above and can be implemented with just <a href="https://courses.cs.vt.edu/~cs1104/BuildingBlocks/divide.030.html">"shift" and "sub"</a> -  </p>
<div><pre><span></span><code><span>fn</span> <span>bigint_div</span><span>(</span><span>own_bits</span>: <span>&amp;</span><span>[</span><span>bool</span><span>],</span><span> </span><span>other_bits</span>: <span>&amp;</span><span>[</span><span>bool</span><span>])</span><span> </span>-&gt; <span>([</span><span>bool</span><span>;</span><span> </span><span>N</span><span>],</span><span> </span><span>[</span><span>bool</span><span>;</span><span> </span><span>N</span><span>])</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>quotient</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>dividend</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>own_bits</span><span>);</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>remainder</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>divisor</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>other_bits</span><span>);</span>

<span>    </span><span>if</span><span> </span><span>divisor</span><span> </span><span>==</span><span> </span><span>BigInt</span>::<span>zero</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>panic!</span><span>(</span><span>"Attempt to divide by zero"</span><span>);</span>
<span>    </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>no_of_bits</span><span> </span><span>=</span><span> </span><span>N</span><span>;</span>
<span>    </span><span>while</span><span> </span><span>!</span><span>dividend</span><span>.</span><span>bits</span><span>[</span><span>N</span><span> </span><span>-</span><span> </span><span>1</span><span>]</span><span> </span><span>{</span>
<span>        </span><span>dividend</span><span> </span><span>&lt;&lt;=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>no_of_bits</span><span> </span><span>-=</span><span> </span><span>1</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>no_of_bits</span><span> </span><span>{</span>
<span>        </span><span>remainder</span><span> </span><span>&lt;&lt;=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>remainder</span><span>.</span><span>bits</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>dividend</span><span>.</span><span>bits</span><span>[</span><span>N</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>-</span><span> </span><span>i</span><span>];</span>

<span>        </span><span>quotient</span><span> </span><span>&lt;&lt;=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>if</span><span> </span><span>remainder</span><span> </span><span>&gt;=</span><span> </span><span>divisor</span><span> </span><span>{</span>
<span>            </span><span>remainder</span><span> </span><span>-=</span><span> </span><span>divisor</span><span>;</span>
<span>            </span><span>quotient</span><span>.</span><span>bits</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>true</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>

<span>    </span><span>(</span><span>quotient</span><span>.</span><span>bits</span><span>,</span><span> </span><span>remainder</span><span>.</span><span>bits</span><span>)</span>
<span>}</span>
</code></pre></div>

<p>After doing some testing to confirm the arithmetic works as expected I switched over all <code>u128</code>s in <code>miller_rabin_test()</code> and <code>mod_exp()</code> over to my BigInt, changed the RNG to fill 1024 bits, and ran the code. It didn't finish in a few minutes and it was getting late at night, so I left it running and went to sleep. The next day I woke up to this - </p>
<div><pre><span></span><code>➜ time cargo run --release
Prime found: 1100001101000111101111110011001111000010011111010110100010101011111110100010001100001101110101100100100110011110101100001000110010100011100101001010100110010110001101110111001110100110000001010111100000110111100010010010100110101011101010100101000100111110000001100000000011101111010100100101001111111100010010000110101010101000101010000011011110111101100011000010111011010000110101100111001101011000000001000100011001011100100000011110011011000000101000010001010001010010001101111100110001000011100110111100000010100000011101011100101101110100010111110000110000010111110000110101001110100100110101011101100111000100010110101001101110100111100010000000110000001001011100100100101001110100101100110110001001101110010100011011011110111100010011111011101010100010111010110101101010011110010111100100110111010111100101111111110010100101010111100111010001010101011100001000100101001111110101100101011100100001101111000100000001111100001001001010100101101111010000101001111111010110111111011101010100111011100111100001010101011101
cargo run --release  1959.67s user 0.09s system 99% cpu 32:44.90 total
</code></pre></div>

<p>Or expressed in base-10 - </p>
<div><pre><span></span><code>137130462909417371581865483489043797725909059024661411704723085022816692663284008207826785132470756353352621332808019668785759110990576815741502628035997147255459016128105305451010585699069674494217365521467940783164171729442866016775055913991624626502191730619275815532321664270492537447637102633611801007453
</code></pre></div>

<p>This is the first 1024-bit prime number I found! I have solved the challenge! </p>
<p>But there was just one small issue - the runtime counter showed that it took ~30mins to find that prime. Although technically I have solved the challenge and also understood how to do it, taking 30 minutes per prime is not what I would call "reasonable time" especially when OpenSSL takes 30ms to do the same thing! The "reasonable time" limitation was part of the constraints because I want to learn both the skill of making it work and making it efficient :).</p>
<h3>Attempt #3 - BigInt as bytes</h3>
<p>The binary implementation I came up with in attempt #2 was immensely valuable. Not only did it give me my first 1024-bit prime, it was also an implementation that was proven to work correctly and I can test any further changes against it. This helped a lot with speeding up my experimentation and gave me the confidence to try some of the more difficult things.</p>
<p>When I started looking into why binary was so slow, the first thing I found was that in an array of <code>bool</code>, each <code>bool</code> would occupy a byte in memory  and not a single bit as I thought it might. This <a href="https://stackoverflow.com/a/48882542">stackoverflow answer</a> has the reasons why. This meant my <code>bool</code> array of size 2048 was not using 2048 bits of memory as I had assumed, but 2048 <em>bytes</em>! That's 2kb of memory just to store a single number. My binary implementation was probably spending almost all of its time waiting to read or write numbers from RAM due to L1 cache misses. I did not know at the time how to actually test this, but I thought let's try a more memory efficient version anyway and see if it improves things.</p>
<p>The natural path to follow would then be, why not store the bits as <em>byte sized chunks</em> instead of individual bits in a list. It could store all 2048 bits in an array of 256 bytes. Surprisingly, addition/subtraction and multiplication worked with this new format without any major changes to the algorithms. Instead of adding bit by bit and using an extra bit as carry, it would now add byte by byte using an extra byte as carry. I switched multiplication from "shift-and-add" back to the pen and paper algorithm I initially had for digits, but using bytes in place of 0-9 digits, and it worked without any modifications too. For division I added a few extra lines of code to treat the list of byte chunks as a single list of bits and the rest remained unchanged. </p>
<p>With all these improvements, I got my second 1024-bit prime at 4min 43sec. Nice improvement over the original binary, but still not enough.</p>
<h3>Attempt #4 - BigInt as u64 chunks</h3>
<p>While doing more research on arbitrary precision arithmetic trying to find other ways to optimize I made an interesting discovery. There is a reason why my arithmetic algorithms in attempt #3 worked directly with bytes instead of bits. What I had unknowingly implemented was a digit based BigInt similar to what I tried in attempt #1, but using "high radix" digits. Attempt #1 used base-10 digits, 0 to 9, what us humans are comfortable with, but a computer can work in any base you want it to use. You've probably heard of base-16 (or hexadecimal) where the digits are 0-9 and A-F, or even base-64 which consists of all alphanumeric characters as the digits. My code from attempt #3 was effectively using base-255, with each byte acting as a single "digit". </p>
<p>For example, here's the same number expressed in different bases -</p>
<div><pre><span></span><code>base-10:    3,095,627                          (7 digits)
base-16:    2F3C4B                             (6 digits)
base-64:    LzxL                               (4 digits)
base-255:   00101111 00111100 01001011         (3 digits)
</code></pre></div>

<p>(If you are wondering how I got the base-255 version, it is literally the binary representation of 3,095,627 split into 3 bytes.)</p>
<p>The funny thing is, I had read about this multiple times and dismissed it each time as being "too complex a concept for me to understand", but after implementing it accidentally it finally clicked in my mind. Once I understood it the next logical thing to realize was that there's no reason for it to be limited to byte sized digits and I can push it as far as it would go.</p>
<p>So here's what my latest BigInt looks like -</p>
<div><pre><span></span><code><span>const</span><span> </span><span>N</span>: <span>usize</span> <span>=</span><span> </span><span>2048</span><span> </span><span>/</span><span> </span><span>64</span><span>;</span>

<span>struct</span> <span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>chunks</span>: <span>[</span><span>u64</span><span>;</span><span> </span><span>N</span><span>]</span>
<span>}</span>
</code></pre></div>

<p>It uses a array of 32 u64 chunks to store upto 2048 bits. As usual it goes to twice the size we need so it has enough room to store the multiplication result of 2 BigInts. Similarly, the highest it can go for each individual "digit" is u64 as it would need to use a u128 to store the multiplication result of two individual "digits". The rest of the code remained mostly unchanged from attempt #3 with a few small changes, like changing the carry variable to u64 instead of a byte. At this point, the BigInt is using base-(2<sup>64</sup>-1) or base-18446744073709551615 (🤯) and it only needs 16 "digits" to represent a number that uses 309 digits in base-10!</p>
<p>This now takes roughly 60-90 seconds to generate 1024-bit primes, which is a vast improvement over binary but still not fast enough.</p>
<h3>Attempt #5 - BigInt as u64 chunks, but better</h3>
<p>At this point I decided to run some simple benchmarks to try to find out what was slowing us down. Here's the results:</p>
<table>
<thead>
<tr>
<th></th>
<th>binary</th>
<th>u64 chunks</th>
</tr>
</thead>
<tbody>
<tr>
<td>a + b and a - b</td>
<td>5537.35ns</td>
<td>123.57ns</td>
</tr>
<tr>
<td>a * b</td>
<td>1292283.14ns</td>
<td>842.32ns</td>
</tr>
<tr>
<td>a / b and a % b</td>
<td>733446.76ns</td>
<td>44440.12ns</td>
</tr>
<tr>
<td>a &lt;&lt; b and a &gt;&gt; b</td>
<td>276.85ns</td>
<td>140.88ns</td>
</tr>
<tr>
<td>a &lt; b and a &gt; b</td>
<td>2506.02ns</td>
<td>58.91ns</td>
</tr>
</tbody>
</table>
<p>(All times average of 1000 runs measured in nanoseconds)</p>

<p>This shows the significant progress made since binary, and rest of attempt #5 is going to be a list of things I did to make it even faster.</p>
<h4>Division</h4>
<p>The biggest thing that jumps out from the benchmarks is: division. Even though everything else has improved a lot, division is still using the same algorithm that it used in binary, still doing long division a single bit at a time. I have always seen people complain about division being slow, now I know why. Division really is a harder problem to solve compared to addition or multiplication.</p>
<p>I saw multiple articles and sources pointing to a book - <em><a href="https://archive.org/details/handbookofapplie0000mene">Handbook of Applied Cryptography</a></em> when looking for better algorithms. I found it on the Internet Archive, made an account, and borrowed it for 14 days. This is what I found on page 598:</p>
<p><img src="https://glitchcomet.com/articles/1024-bit-primes/page_598.png"></p>
<p>Page 598, <em>Handbook of Applied Cryptography</em></p>

<p>On the one hand it's talking about "radix b representation" and by now I had done enough to understand that it was referencing the same "high radix digits" concept I had discovered earlier. On the other hand I understood nothing else at all and the book doesn't make it any easier as it didn't include any text explaining this algorithm. After staring at this page for 3 days straight and numerous failed attempts, I managed to write a working implementation. What I understood is that it is doing long division on base-N numbers, using the first 3 "digits" of the dividend and the first 2 "digits" of the divisor to estimate the current quotient "digit" in a loop until it finds the correct value, but I am not comfortable enough with <a href="https://mathsanew.com/articles/implementing_large_integers_division.pdf">the math behind it</a> yet to explain it here. I have also heard that a very similar algorithm appears in <em><a href="https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming">The Art of Computer Programming</a></em>, but there was no easy way to quickly refer it other than buying a copy, which I would get around to doing eventually.</p>
<p>Spending the effort to figure this out did pay off though, it saves about 40,000ns (40μs) <strong><em>per division</em></strong>, and there are quite a lot of division and modulus operations that happen for a single run of Miller-Rabin and 1000s of Miller-Rabin runs before a prime is found. An additional optimization I did was to check if the divisor is a single "digit" (a single u64 chunk) and then directly do long division using u128 to catch any overflows. This skips the costly algorithm entirely and is another one of those cases that frequently appear in Miller-Rabin.</p>
<div><pre><span></span><code><span>fn</span> <span>bigint_div</span><span>(</span><span>mut</span><span> </span><span>dividend</span>: <span>BigInt</span><span>,</span><span> </span><span>mut</span><span> </span><span>divisor</span>: <span>BigInt</span><span>)</span><span> </span>-&gt; <span>(</span><span>BigInt</span><span>,</span><span> </span><span>BigInt</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>if</span><span> </span><span>divisor</span><span>.</span><span>is_zero</span><span>()</span><span> </span><span>{</span><span> </span><span>panic!</span><span>(</span><span>"Attempt to divide by zero"</span><span>);</span><span> </span><span>}</span>
<span>    </span><span>if</span><span> </span><span>dividend</span><span> </span><span>&lt;</span><span> </span><span>divisor</span><span> </span><span>{</span><span> </span><span>return</span><span> </span><span>(</span><span>BigInt</span>::<span>zero</span><span>(),</span><span> </span><span>dividend</span><span>)</span><span> </span><span>}</span>

<span>    </span><span>// x = dividend</span>
<span>    </span><span>// y = divisor</span>
<span>    </span><span>// b = 64 (size of a "digit")</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>quotient</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>lambda</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>

<span>    </span><span>let</span><span> </span><span>t</span><span> </span><span>=</span><span> </span><span>divisor</span><span>.</span><span>size</span><span>();</span>

<span>    </span><span>if</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span>]</span><span> </span><span>&lt;</span><span> </span><span>u64</span>::<span>MAX</span><span> </span><span>/</span><span> </span><span>2</span><span> </span><span>{</span>
<span>        </span><span>while</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span>]</span><span> </span><span>&lt;&lt;</span><span> </span><span>lambda</span><span> </span><span>&lt;</span><span> </span><span>u64</span>::<span>MAX</span><span> </span><span>/</span><span> </span><span>2</span><span> </span><span>{</span>
<span>            </span><span>lambda</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>}</span>
<span>        </span><span>divisor</span><span> </span><span>&lt;&lt;=</span><span> </span><span>lambda</span><span>;</span>
<span>        </span><span>dividend</span><span> </span><span>&lt;&lt;=</span><span> </span><span>lambda</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>n</span><span> </span><span>=</span><span> </span><span>dividend</span><span>.</span><span>size</span><span>();</span>

<span>    </span><span>// if y has only 1 "digit", then do long division directly</span>
<span>    </span><span>if</span><span> </span><span>t</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>divisor_digit</span><span> </span><span>=</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>]</span><span> </span><span>as</span><span> </span><span>u128</span><span>;</span>
<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>remainder</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>current</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>

<span>        </span><span>for</span><span> </span><span>(</span><span>i</span><span>,</span><span> </span><span>chunk</span><span>)</span><span> </span><span>in</span><span> </span><span>dividend</span><span>.</span><span>chunks</span><span>.</span><span>iter</span><span>().</span><span>enumerate</span><span>().</span><span>rev</span><span>().</span><span>skip</span><span>(</span><span>N</span><span> </span><span>-</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span>
<span>            </span><span>current</span><span> </span><span>=</span><span> </span><span>(</span><span>remainder</span><span> </span><span>&lt;&lt;</span><span> </span><span>64</span><span>)</span><span> </span><span>+</span><span> </span><span>*</span><span>chunk</span><span> </span><span>as</span><span> </span><span>u128</span><span>;</span>
<span>            </span><span>quotient</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>(</span><span>current</span><span> </span><span>/</span><span> </span><span>divisor_digit</span><span>)</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>
<span>            </span><span>remainder</span><span> </span><span>=</span><span> </span><span>current</span><span> </span><span>%</span><span> </span><span>divisor_digit</span><span>;</span>
<span>        </span><span>}</span>
<span>        </span><span>return</span><span> </span><span>(</span><span>quotient</span><span>,</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>remainder</span><span> </span><span>&gt;&gt;</span><span> </span><span>lambda</span><span>));</span>
<span>    </span><span>}</span>

<span>    </span><span>// step 2, align and then subtract y from x until x &gt;= aligned</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>aligned</span><span> </span><span>=</span><span> </span><span>divisor</span><span>.</span><span>clone</span><span>();</span>
<span>    </span><span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>(</span><span>n</span><span> </span><span>-</span><span> </span><span>t</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>aligned</span><span> </span><span>&lt;&lt;=</span><span> </span><span>64</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>while</span><span> </span><span>dividend</span><span> </span><span>&gt;=</span><span> </span><span>aligned</span><span> </span><span>{</span>
<span>        </span><span>quotient</span><span>.</span><span>chunks</span><span>[</span><span>n</span><span> </span><span>-</span><span> </span><span>t</span><span>]</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>dividend</span><span> </span><span>-=</span><span> </span><span>aligned</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>one</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>1</span><span>);</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>x_3digit</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>y_2digit</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>q_u128</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>q_digit</span><span>;</span>

<span>    </span><span>// step 3</span>
<span>    </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>((</span><span>t</span><span> </span><span>+</span><span> </span><span>1</span><span>)</span><span>..=</span><span>n</span><span>).</span><span>rev</span><span>()</span><span> </span><span>{</span>

<span>        </span><span>q_digit</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>

<span>        </span><span>// step 3.1</span>
<span>        </span><span>if</span><span> </span><span>dividend</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span>]</span><span> </span><span>==</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span>]</span><span> </span><span>{</span>
<span>            </span><span>q_digit</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>u64</span>::<span>MAX</span><span> </span><span>-</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span>
<span>            </span><span>q_u128</span><span> </span><span>=</span><span> </span><span>(</span><span>dividend</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span>]</span><span> </span><span>as</span><span> </span><span>u128</span><span>)</span><span> </span><span>&lt;&lt;</span><span> </span><span>64</span><span>;</span>
<span>            </span><span>q_u128</span><span> </span><span>+=</span><span> </span><span>dividend</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>-</span><span> </span><span>1</span><span>]</span><span> </span><span>as</span><span> </span><span>u128</span><span>;</span>
<span>            </span><span>q_digit</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>q_u128</span><span> </span><span>/</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span>]</span><span> </span><span>as</span><span> </span><span>u128</span><span>);</span>
<span>        </span><span>}</span>

<span>        </span><span>// precalc 3digit x and 2digit y</span>
<span>        </span><span>x_3digit</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>        </span><span>x_3digit</span><span>.</span><span>chunks</span><span>[</span><span>2</span><span>]</span><span> </span><span>=</span><span> </span><span>dividend</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span>];</span>
<span>        </span><span>x_3digit</span><span>.</span><span>chunks</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>dividend</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>-</span><span> </span><span>1</span><span>];</span>
<span>        </span><span>x_3digit</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>dividend</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>-</span><span> </span><span>2</span><span>];</span>

<span>        </span><span>y_2digit</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>        </span><span>y_2digit</span><span>.</span><span>chunks</span><span>[</span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span>];</span>
<span>        </span><span>y_2digit</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>divisor</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span> </span><span>-</span><span> </span><span>1</span><span>];</span>

<span>        </span><span>// step 3.2</span>
<span>        </span><span>while</span><span> </span><span>q_digit</span><span> </span><span>*</span><span> </span><span>y_2digit</span><span> </span><span>&gt;</span><span> </span><span>x_3digit</span><span> </span><span>{</span>
<span>            </span><span>q_digit</span><span> </span><span>-=</span><span> </span><span>one</span><span>;</span>
<span>        </span><span>}</span>

<span>        </span><span>// move quotient "digit" from temp bigint to its place in quotient</span>
<span>        </span><span>quotient</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>-</span><span> </span><span>t</span><span> </span><span>-</span><span> </span><span>1</span><span>]</span><span> </span><span>=</span><span> </span><span>q_digit</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>];</span>

<span>        </span><span>// precalc shifted y</span>
<span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>y_shifted</span><span> </span><span>=</span><span> </span><span>divisor</span><span>.</span><span>clone</span><span>();</span>
<span>        </span><span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>(</span><span>i</span><span> </span><span>-</span><span> </span><span>t</span><span> </span><span>-</span><span> </span><span>1</span><span>)</span><span> </span><span>{</span>
<span>            </span><span>y_shifted</span><span> </span><span>&lt;&lt;=</span><span> </span><span>64</span><span>;</span>
<span>        </span><span>}</span>

<span>        </span><span>// step 3.3 and 3.4</span>
<span>        </span><span>if</span><span> </span><span>dividend</span><span> </span><span>&gt;=</span><span> </span><span>q_digit</span><span> </span><span>*</span><span> </span><span>y_shifted</span><span> </span><span>{</span>
<span>            </span><span>dividend</span><span> </span><span>-=</span><span> </span><span>q_digit</span><span> </span><span>*</span><span> </span><span>y_shifted</span><span>;</span>
<span>        </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span>
<span>            </span><span>dividend</span><span> </span><span>+=</span><span> </span><span>y_shifted</span><span>;</span>
<span>            </span><span>dividend</span><span> </span><span>-=</span><span> </span><span>q_digit</span><span> </span><span>*</span><span> </span><span>y_shifted</span><span>;</span>
<span>            </span><span>quotient</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>-</span><span> </span><span>t</span><span> </span><span>-</span><span> </span><span>1</span><span>]</span><span> </span><span>-=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>

<span>    </span><span>// rewind shifts by lambda to get actual remainder</span>
<span>    </span><span>dividend</span><span> </span><span>&gt;&gt;=</span><span> </span><span>lambda</span><span>;</span>

<span>    </span><span>(</span><span>quotient</span><span>,</span><span> </span><span>dividend</span><span>)</span>
<span>}</span>
</code></pre></div>

<h4>Multiplication</h4>
<p>Next I looked at multiplication, the second biggest thing in the benchmarks. I had implemented essentially the same algorithm as the book, so no gains there. Rearranging the loop calculations cleverly to eliminate an extra BigInt I was using to store the intermediate results gave a 2x improvement to runtime. </p>
<p>Since I had already added a function to calculate the size (number of occupied chunks) for division, I used the same function here to only run the loops for non-zero chunks and also added extra checks to skip loop iteration if one of the chunks is zero. Although this adds complexity and branching inside the loops, it still helps improve performance as most of the time BigInt is supposed to store 1024 bits or less and thus be half empty. This gave another 2x improvement.</p>
<p>I could have gone to the <a href="https://mathsanew.com/articles/implementing_large_integers_multiplication.pdf">Karatsuba</a> algorithm or even <a href="https://gmplib.org/manual/Multiplication-Algorithms">fast Fourier transforms (FFT)</a> which theoretically would give even better performance, but actually implementing it for a BigInt that I am building myself was too complex and my current multiplication was now fast enough that I did not pursue this path.</p>
<div><pre><span></span><code><span>fn</span> <span>bigint_mul</span><span>(</span><span>own</span>: <span>BigInt</span><span>,</span><span> </span><span>other</span>: <span>BigInt</span><span>)</span><span> </span>-&gt; <span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>intermediate</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>carry</span><span>;</span>

<span>    </span><span>let</span><span> </span><span>t</span><span> </span><span>=</span><span> </span><span>own</span><span>.</span><span>size</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>n</span><span> </span><span>=</span><span> </span><span>other</span><span>.</span><span>size</span><span>();</span>
<span>    </span><span>if</span><span> </span><span>t</span><span> </span><span>+</span><span> </span><span>n</span><span> </span><span>+</span><span> </span><span>1</span><span> </span><span>&gt;=</span><span> </span><span>N</span><span> </span><span>{</span><span> </span><span>panic!</span><span>(</span><span>"Attempt to multiply with overflow"</span><span>);</span><span> </span><span>}</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>j</span><span>,</span><span> </span><span>chunk2</span><span>)</span><span> </span><span>in</span><span> </span><span>other</span><span>.</span><span>chunks</span><span>.</span><span>iter</span><span>().</span><span>take</span><span>(</span><span>n</span><span> </span><span>+</span><span> </span><span>1</span><span>).</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>*</span><span>chunk2</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span><span> </span><span>continue</span><span>;</span><span> </span><span>}</span>
<span>        </span><span>carry</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>

<span>        </span><span>for</span><span> </span><span>(</span><span>i</span><span>,</span><span> </span><span>chunk1</span><span>)</span><span> </span><span>in</span><span> </span><span>own</span><span>.</span><span>chunks</span><span>.</span><span>iter</span><span>().</span><span>take</span><span>(</span><span>t</span><span> </span><span>+</span><span> </span><span>1</span><span>).</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>            </span><span>if</span><span> </span><span>*</span><span>chunk1</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>&amp;&amp;</span><span> </span><span>carry</span><span> </span><span>==</span><span> </span><span>0</span><span> </span><span>{</span><span> </span><span>continue</span><span>;</span><span> </span><span>}</span>

<span>            </span><span>intermediate</span><span> </span><span>=</span><span> </span><span>((</span><span>*</span><span>chunk1</span><span> </span><span>as</span><span> </span><span>u128</span><span>)</span><span> </span><span>*</span><span> </span><span>(</span><span>*</span><span>chunk2</span><span> </span><span>as</span><span> </span><span>u128</span><span>))</span><span> </span><span>+</span><span> </span><span>carry</span><span>;</span>
<span>            </span><span>intermediate</span><span> </span><span>+=</span><span> </span><span>result</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>+</span><span> </span><span>j</span><span>]</span><span> </span><span>as</span><span> </span><span>u128</span><span>;</span>
<span>            </span><span>result</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span> </span><span>+</span><span> </span><span>j</span><span>]</span><span> </span><span>=</span><span> </span><span>intermediate</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>
<span>            </span><span>carry</span><span> </span><span>=</span><span> </span><span>intermediate</span><span> </span><span>&gt;&gt;</span><span> </span><span>64</span><span>;</span>
<span>        </span><span>}</span>
<span>        </span><span>result</span><span>.</span><span>chunks</span><span>[</span><span>t</span><span> </span><span>+</span><span> </span><span>j</span><span> </span><span>+</span><span> </span><span>1</span><span>]</span><span> </span><span>+=</span><span> </span><span>carry</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>result</span>
<span>}</span>
</code></pre></div>

<h4>Addition and Subtraction</h4>
<p>These are already super fast, I was surprised to see even my custom implementation already runs relatively close to the time it takes rust to add two native u128. I tried a few things but (as expected) I was not as clever as the compiler and whatever magic it does under the hood.</p>
<div><pre><span></span><code><span>fn</span> <span>bigint_add</span><span>(</span><span>own</span>: <span>BigInt</span><span>,</span><span> </span><span>other</span>: <span>BigInt</span><span>)</span><span> </span>-&gt; <span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>sum</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>carry</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>sum_overflow</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>carry_overflow</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>result</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>

<span>    </span><span>let</span><span> </span><span>own_iter</span><span> </span><span>=</span><span> </span><span>own</span><span>.</span><span>chunks</span><span>.</span><span>iter</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>other_iter</span><span> </span><span>=</span><span> </span><span>other</span><span>.</span><span>chunks</span><span>.</span><span>iter</span><span>();</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>i</span><span>,</span><span> </span><span>(</span><span>chunk1</span><span>,</span><span> </span><span>chunk2</span><span>))</span><span> </span><span>in</span><span> </span><span>own_iter</span><span>.</span><span>zip</span><span>(</span><span>other_iter</span><span>).</span><span>enumerate</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>(</span><span>sum</span><span>,</span><span> </span><span>sum_overflow</span><span>)</span><span> </span><span>=</span><span> </span><span>chunk1</span><span>.</span><span>overflowing_add</span><span>(</span><span>*</span><span>chunk2</span><span>);</span>
<span>        </span><span>(</span><span>sum</span><span>,</span><span> </span><span>carry_overflow</span><span>)</span><span> </span><span>=</span><span> </span><span>sum</span><span>.</span><span>overflowing_add</span><span>(</span><span>carry</span><span>);</span>
<span>        </span><span>result</span><span>.</span><span>chunks</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>sum</span><span>;</span>
<span>        </span><span>carry</span><span> </span><span>=</span><span> </span><span>sum_overflow</span><span> </span><span>as</span><span> </span><span>u64</span><span> </span><span>+</span><span> </span><span>carry_overflow</span><span> </span><span>as</span><span> </span><span>u64</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>if</span><span> </span><span>carry</span><span> </span><span>!=</span><span> </span><span>0</span><span> </span><span>{</span><span> </span><span>panic!</span><span>(</span><span>"Attempt to add with overflow"</span><span>);</span><span> </span><span>}</span>
<span>    </span><span>result</span>
<span>}</span>
</code></pre></div>

<h4>Miller-Rabin</h4>
<p>There were a bunch of optimizations that I found I could do in my implementation of Miller-Rabin. Here's what it looked like initially -</p>
<div><pre><span></span><code><span> 1</span><span>fn</span> <span>miller_rabin_test</span><span>(</span><span>n</span>: <span>BigInt</span><span>,</span><span> </span><span>k</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>PrimeResult</span><span> </span><span>{</span>
<span> 2</span><span>    </span><span>let</span><span> </span><span>zero</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span> 3</span><span>    </span><span>let</span><span> </span><span>one</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>1</span><span>);</span>
<span> 4</span><span>    </span><span>let</span><span> </span><span>two</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>2</span><span>);</span>
<span> 5</span>
<span> 6</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>zero</span><span>;</span>
<span> 7</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>d</span><span> </span><span>=</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>one</span><span>;</span>
<span> 8</span><span>    </span><span>while</span><span> </span><span>d</span><span> </span><span>%</span><span> </span><span>two</span><span> </span><span>==</span><span> </span><span>zero</span><span> </span><span>{</span>
<span> 9</span><span>        </span><span>d</span><span> </span><span>=</span><span> </span><span>d</span><span> </span><span>/</span><span> </span><span>two</span><span>;</span>
<span>10</span><span>        </span><span>s</span><span> </span><span>+=</span><span> </span><span>one</span><span>;</span>
<span>11</span><span>    </span><span>}</span>
<span>12</span>
<span>13</span><span>    </span><span>'</span><span>main_loop</span>: <span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>k</span><span> </span><span>{</span>
<span>14</span><span>        </span><span>let</span><span> </span><span>base</span><span> </span><span>=</span><span> </span><span>&lt;&lt;</span><span>rng</span><span> </span><span>omitted</span><span>&gt;&gt;</span><span>;</span>
<span>15</span><span>        </span><span>let</span><span> </span><span>mut</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>mod_exp</span><span>(</span><span>base</span><span>,</span><span> </span><span>d</span><span>,</span><span> </span><span>n</span><span>);</span>
<span>16</span><span>        </span><span>if</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>one</span><span> </span><span>||</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>one</span><span> </span><span>{</span><span> </span><span>continue</span><span> </span><span>'main_loop</span><span>;</span><span> </span><span>}</span>
<span>17</span>
<span>18</span><span>        </span><span>while</span><span> </span><span>s</span><span> </span><span>&gt;</span><span> </span><span>zero</span><span> </span><span>{</span>
<span>19</span><span>            </span><span>x</span><span> </span><span>=</span><span> </span><span>mod_exp</span><span>(</span><span>x</span><span>,</span><span> </span><span>two</span><span>,</span><span> </span><span>n</span><span>);</span>
<span>20</span><span>            </span><span>if</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>n</span><span> </span><span>-</span><span> </span><span>one</span><span> </span><span>{</span><span> </span><span>continue</span><span> </span><span>'main_loop</span><span>;</span><span> </span><span>}</span>
<span>21</span><span>            </span><span>s</span><span> </span><span>-=</span><span> </span><span>one</span><span>;</span>
<span>22</span><span>        </span><span>}</span>
<span>23</span><span>        </span><span>return</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>24</span><span>    </span><span>}</span>
<span>25</span>
<span>26</span><span>    </span><span>PrimeResult</span>::<span>ProbablePrime</span>
<span>27</span><span>}</span>
</code></pre></div>

<div>
    <p>And here some of the major optimizations I did:</p>
<ul>
<li>The <code>mod_exp()</code> call on line 19 is no longer required as BigInt has enough memory to do <code>x = (x * x) % n</code> directly.</li>
<li>On line 15 <code>mod_exp()</code> was replaced by an simplified inline version which saved a lot of function call overhead.</li>
<li>The BigInt representation of "2" on line 4 was created just to do the even check on line 8. I wrote a simple <code>num.is_even()</code> function that only needs to check if the last bit is <code>0</code> or <code>1</code>, and so removed a bunch of extra costly divisions and an extra BigInt allocation.</li>
<li>Similarly, the division on line 9 can be replaced with a <code>d &gt;&gt;= 1</code> shift operation. In this case replacing another bunch of costly divisions with shifts is actually very beneficial compared to native code where this change is usually not worth it.</li>
<li>There are a lot of <code>+= one</code> and <code>-= one</code> (where <code>one</code> is BigInt representation of "1"), I added special <code>num.increase()</code> and <code>num.decrease()</code> which for almost all cases would just do a u64 addition/subtraction on the last "digit", and only go to the full BigInt addition/subtraction if the last "digit" was either <code>0</code> or <code>u64::max</code>, meaning the rare cases where it actually needs the BigInt to handle the overflow from adding or subtracting 1.</li>
</ul>
</div>

<p>All of these and other changes not listed above individually account for just microseconds or even nanoseconds of advantage, but when they are run multiple times inside a loop inside thousands of Miller-Rabin tests it all adds up to a nice improvement in runtime. At least that is what I thought before I benchmarked them, and <code>is_even()</code> plus <code>d &gt;&gt;=1</code> easily outclass everything else give a whopping 70,000ns advantage <em>each</em>! Here's the final improved Miller-Rabin - </p>
<div><pre><span></span><code><span>fn</span> <span>miller_rabin_test</span><span>(</span><span>n</span>: <span>BigInt</span><span>,</span><span> </span><span>k</span>: <span>usize</span><span>)</span><span> </span>-&gt; <span>PrimeResult</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>zero</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>one</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>1</span><span>);</span>
<span>    </span><span>let</span><span> </span><span>n_minus_1</span><span> </span><span>=</span><span> </span><span>n</span><span>.</span><span>decrease</span><span>();</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>d</span><span> </span><span>=</span><span> </span><span>n_minus_1</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>s</span><span> </span><span>=</span><span> </span><span>zero</span><span>;</span>
<span>    </span><span>while</span><span> </span><span>d</span><span>.</span><span>is_even</span><span>()</span><span> </span><span>{</span>
<span>        </span><span>d</span><span> </span><span>&gt;&gt;=</span><span> </span><span>1</span><span>;</span>
<span>        </span><span>s</span><span> </span><span>=</span><span> </span><span>s</span><span>.</span><span>increase</span><span>();</span>
<span>    </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>bytes</span><span> </span><span>=</span><span> </span><span>[</span><span>0</span><span>;</span><span> </span><span>(</span><span>1024</span><span> </span><span>/</span><span> </span><span>16</span><span>)];</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>x</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>base</span><span>;</span>
<span>    </span><span>'</span><span>main_loop</span>: <span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>k</span><span> </span><span>{</span>
<span>        </span><span>rng</span>::<span>insert_random_bytes</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>bytes</span><span>).</span><span>unwrap</span><span>();</span>
<span>        </span><span>base</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>bytes</span><span>.</span><span>as_slice</span><span>());</span>

<span>        </span><span>x</span><span> </span><span>=</span><span> </span><span>one</span><span>;</span>
<span>        </span><span>while</span><span> </span><span>!</span><span>d</span><span>.</span><span>is_zero</span><span>()</span><span> </span><span>{</span>
<span>            </span><span>if</span><span> </span><span>!</span><span>d</span><span>.</span><span>is_even</span><span>()</span><span> </span><span>{</span><span> </span><span>x</span><span> </span><span>=</span><span> </span><span>(</span><span>x</span><span> </span><span>*</span><span> </span><span>base</span><span>)</span><span> </span><span>%</span><span> </span><span>n</span><span>;</span><span> </span><span>}</span>
<span>            </span><span>d</span><span> </span><span>=</span><span> </span><span>d</span><span> </span><span>&gt;&gt;</span><span> </span><span>1</span><span>;</span>
<span>            </span><span>base</span><span> </span><span>=</span><span> </span><span>(</span><span>base</span><span> </span><span>*</span><span> </span><span>base</span><span>)</span><span> </span><span>%</span><span> </span><span>n</span><span>;</span>
<span>        </span><span>}</span>
<span>        </span><span>if</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>one</span><span> </span><span>||</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>n_minus_1</span><span> </span><span>{</span><span> </span><span>continue</span><span> </span><span>'main_loop</span><span>;</span><span> </span><span>}</span>

<span>        </span><span>while</span><span> </span><span>!</span><span>s</span><span>.</span><span>is_zero</span><span>()</span><span> </span><span>{</span>
<span>            </span><span>x</span><span> </span><span>=</span><span> </span><span>(</span><span>x</span><span> </span><span>*</span><span> </span><span>x</span><span>)</span><span> </span><span>%</span><span> </span><span>n</span><span>;</span>
<span>            </span><span>if</span><span> </span><span>x</span><span> </span><span>==</span><span> </span><span>n_minus_1</span><span> </span><span>{</span><span> </span><span>continue</span><span> </span><span>'main_loop</span><span>;</span><span> </span><span>}</span>
<span>            </span><span>s</span><span> </span><span>=</span><span> </span><span>s</span><span>.</span><span>decrease</span><span>();</span>
<span>        </span><span>}</span>

<span>        </span><span>return</span><span> </span><span>PrimeResult</span>::<span>Composite</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>PrimeResult</span>::<span>ProbablePrime</span>
<span>}</span>
</code></pre></div>

<h4>Primality testing logic</h4>
<p>I modified the logic for testing primes with changes inspired by step 2 (64-bit primes) to add an additional trial division check at the start, using a precomputed list of the first 5000 small primes. This was infeasible for the majority of the time I was working on BigInt as trial division uses a lot of divisions, which were extremely slow. The trick to make it work is that all first 5000 small primes are small enough that they fit inside a single "digit" (a single u64 chunk). This means all divisions inside trial division would fall into the special case I just added, where it can perform the entire division using long division and u128 and skip the costly BigInt division algorithm. The same trial division function can also be used to generate the initial list of the first 5000 small primes. Optimizing trial division at step 2 did have some use after all! </p>
<p>Another change to the logic is that instead of reading <code>/dev/urandom</code> for each iteration of the loop and generating a new random number to test, it just adds 2 to the first random number to get the next candidate. Since the last bit is modified to be <code>1</code> we know it's an odd number, which means adding 2 would take it to the next odd number. This can be further optimized by adding a dedicated function <code>num.increase_by_2()</code> which like <code>num.increase()</code> will only do the full BigInt addition for the overflow case, and otherwise would just do a u64 addition. </p>
<p>And finally, this is one of those problems that can be called "<a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a>" because there is no shared memory and no need to have any synchronization between threads. Instead of asking one CPU thread to find primes why not ask all 16 CPU threads and the fastest one wins!</p>
<p><span>- - -</span></p>
<p>Here are the same benchmarks after these optimizations:</p>
<table>
<thead>
<tr>
<th></th>
<th>binary</th>
<th>u64 chunks</th>
<th>u64 chunks but better</th>
</tr>
</thead>
<tbody>
<tr>
<td>a + b and a - b</td>
<td>5537.35ns</td>
<td>123.57ns</td>
<td>123.62ns</td>
</tr>
<tr>
<td>a * b</td>
<td>1292283.14ns</td>
<td>842.32ns</td>
<td>295.04ns</td>
</tr>
<tr>
<td>a / b and a % b</td>
<td>733446.76ns</td>
<td>44440.12ns</td>
<td>831.77ns</td>
</tr>
<tr>
<td>a &lt;&lt; b and a &gt;&gt; b</td>
<td>276.85ns</td>
<td>140.88ns</td>
<td>126.04ns</td>
</tr>
<tr>
<td>a &lt; b and a &gt; b</td>
<td>2506.02ns</td>
<td>58.91ns</td>
<td>58.50ns</td>
</tr>
<tr>
<td>a / 2 (or a &lt;&lt; 1)</td>
<td>2638289.48ns</td>
<td>75121.58ns</td>
<td>60.89ns</td>
</tr>
<tr>
<td>a % 2 == 0 (or a.is_even())</td>
<td>2447553.14ns</td>
<td>78400.87ns</td>
<td>21.65ns</td>
</tr>
<tr>
<td>a - 1 (or a.decrease())</td>
<td>6179.48ns</td>
<td>103.15ns</td>
<td>67.54ns</td>
</tr>
</tbody>
</table>
<p>(All times average of 1000 runs measured in nanoseconds)</p>

<h2>1024 bits, quite a bit faster!</h2>
<p>Finally, we arrive at the conclusion to this very long article. Let's combine everything together into a function to generate 1024-bit primes - </p>
<div><pre><span></span><code><span>fn</span> <span>primes_1024bit</span><span>()</span><span> </span>-&gt; <span>BigInt</span><span> </span><span>{</span>
<span>    </span><span>const</span><span> </span><span>P</span>: <span>usize</span> <span>=</span><span> </span><span>1000</span><span>;</span>
<span>    </span><span>let</span><span> </span><span>primes</span><span> </span><span>=</span><span> </span><span>utils</span>::<span>generate_small_primes</span>::<span>&lt;</span><span>P</span><span>&gt;</span><span>();</span>

<span>    </span><span>let</span><span> </span><span>zero</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>small_prime</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>zero</span><span>();</span>

<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>bytes</span><span> </span><span>=</span><span> </span><span>[</span><span>0</span><span>u8</span><span>;</span><span> </span><span>1024</span><span> </span><span>/</span><span> </span><span>8</span><span>];</span>
<span>    </span><span>rng</span>::<span>insert_random_bytes</span><span>(</span><span>&amp;</span><span>mut</span><span> </span><span>bytes</span><span>).</span><span>expect</span><span>(</span><span>"Cannot access /dev/urandom"</span><span>);</span>
<span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>num</span><span> </span><span>=</span><span> </span><span>BigInt</span>::<span>from</span><span>(</span><span>bytes</span><span>.</span><span>as_slice</span><span>())</span>

<span>    </span><span>num</span><span>.</span><span>chunks</span><span>[(</span><span>1024</span><span> </span><span>/</span><span> </span><span>64</span><span>)</span><span> </span><span>-</span><span> </span><span>1</span><span>]</span><span> </span><span>|=</span><span> </span><span>0x8000000000000000</span><span>u64</span><span>;</span>
<span>    </span><span>num</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>]</span><span> </span><span>|=</span><span> </span><span>1</span><span>;</span>

<span>    </span><span>'</span><span>prime_loop</span>: <span>loop</span><span> </span><span>{</span>
<span>        </span><span>num</span><span> </span><span>=</span><span> </span><span>num</span><span>.</span><span>increase_by_2</span><span>();</span>

<span>        </span><span>for</span><span> </span><span>i</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>P</span><span> </span><span>{</span>
<span>            </span><span>small_prime</span><span>.</span><span>chunks</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>primes</span><span>[</span><span>i</span><span>];</span>
<span>            </span><span>if</span><span> </span><span>num</span><span> </span><span>%</span><span> </span><span>small_prime</span><span> </span><span>==</span><span> </span><span>zero</span><span> </span><span>{</span>
<span>                </span><span>continue</span><span> </span><span>'prime_loop</span><span>;</span>
<span>            </span><span>}</span>
<span>        </span><span>}</span>

<span>        </span><span>if</span><span> </span><span>miller_rabin_test</span><span>(</span><span>num</span><span>,</span><span> </span><span>10</span><span>)</span><span> </span><span>==</span><span> </span><span>PrimeResult</span>::<span>ProbablePrime</span><span> </span><span>{</span>
<span>            </span><span>return</span><span> </span><span>num</span><span>;</span>
<span>        </span><span>}</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>

<p>Call the above function in parallel threads - </p>
<div><pre><span></span><code><span>fn</span> <span>run</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>let</span><span> </span><span>(</span><span>tx</span><span>,</span><span> </span><span>rx</span><span>)</span><span> </span><span>=</span><span> </span><span>std</span>::<span>sync</span>::<span>mpsc</span>::<span>channel</span><span>();</span>

<span>    </span><span>for</span><span> </span><span>_</span><span> </span><span>in</span><span> </span><span>0</span><span>..</span><span>16</span><span> </span><span>{</span>
<span>        </span><span>let</span><span> </span><span>thread_tx</span><span> </span><span>=</span><span> </span><span>tx</span><span>.</span><span>clone</span><span>();</span>
<span>        </span><span>std</span>::<span>thread</span>::<span>spawn</span><span>(</span><span>move</span><span> </span><span>||</span><span> </span><span>{</span>
<span>            </span><span>thread_tx</span><span>.</span><span>send</span><span>(</span><span>primes_1024bit</span><span>()).</span><span>unwrap</span><span>();</span>
<span>        </span><span>});</span>
<span>    </span><span>}</span>

<span>    </span><span>let</span><span> </span><span>prime</span><span> </span><span>=</span><span> </span><span>rx</span><span>.</span><span>recv</span><span>().</span><span>unwrap</span><span>();</span>
<span>    </span><span>prime</span><span>.</span><span>print_decimal</span><span>();</span>
<span>}</span>
</code></pre></div>

<p>And here are the results! - </p>
<div><pre><span></span><code>➜ time cargo run --release
133639768604208228777408136159783586754136713880762782100572086187859339703910900715674773943439684405153138260262492990850200027881950953138966616704637409705491165541761840874200485820151419486204300434469857557841532664407934654743999891926036532834796558113864177048787433702650711105375897281079281724197
cargo run --release  0.58s user 0.01s system 690% cpu 0.086 total
</code></pre></div>

<p><br>
I can finally say - 
<span><span>c</span><span>h</span><span>a</span><span>l</span><span>l</span><span>e</span><span>n</span><span>g</span><span>e</span><span>&nbsp;</span><span>s</span><span>o</span><span>l</span><span>v</span><span>e</span><span>d</span><span>!</span></span></p>
<p><br>
It takes on average 40ms to find a 1024-bit prime. Individual calls to <code>prime_1024bit()</code> can range from as low as ~8ms to high ~800ms due to randomness, but parallel execution and picking the fastest one smoothens that out. Here's the average runtime from 100 runs - </p>
<div><pre><span></span><code>➜ perf stat -r100 ./target/release/primes

--- outputs omitted ---

Performance counter stats for './target/release/primes' (100 runs):

    --- other stats omitted ---

    0.04109 +- 0.00307 seconds time elapsed  ( +-  7.48% )
</code></pre></div>

<p><br>
In the end, I am really happy that I gave myself this challenge. It forced me out of my comfort zone and pushed me to learn so many new things, both about programming and how to tackle new topics and do research. There are still tons of things and ideas left on my todo list for improvements I can make and things I could have done better, but I have to save at least some energy for my next project :D.</p>
<p><br>
The full code and repository can be found here - <a href="https://github.com/prdx23/1024-bit-primes">github</a>.<br>
It goes without saying that probably none of this is actually cryptographically secure, but that was never the point anyway.</p>
<p><br>
Discuss on hackernews - <a href="https://news.ycombinator.com/item?id=40250519">https://news.ycombinator.com/item?id=40250519</a>  </p>
<p>

Thanks for reading!</p>
<p>

<span>
<em>Tried to find big primes</em><br>
<em>Multiply overflowed</em><br>
<em>Had to build BigInt</em><br>
</span></p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Evidence of price-fixing in the oil industry? (239 pts)]]></title>
            <link>https://www.thebignewsletter.com/p/an-oil-price-fixing-conspiracy-caused</link>
            <guid>40250226</guid>
            <pubDate>Fri, 03 May 2024 17:39:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebignewsletter.com/p/an-oil-price-fixing-conspiracy-caused">https://www.thebignewsletter.com/p/an-oil-price-fixing-conspiracy-caused</a>, See on <a href="https://news.ycombinator.com/item?id=40250226">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><em><span>Welcome to BIG, a newsletter on the politics of monopoly power. If you’d like to sign up to receive issues over email, you can do so </span><a href="https://mattstoller.substack.com/subscribe" rel="">here</a><span>.</span></em></p><p>I’m at the Google antitrust closing arguments, and I’ll have some thoughts on that soon. But today’s piece is about some bombshell evidence that just came out on a giant post-Covid conspiracy in the oil industry. And I do mean giant, because there’s now evidence that price-fixingp in the oil industry alone may single-handedly be responsible for a little over a quarter of the total inflationary increase in 2021.</p><p>Let’s dive in.</p><p><span>Last Sunday, I wrote </span><a href="https://www.thebignewsletter.com/p/monopoly-round-up-inflation-re-accelerating" rel="">a piece</a><span> alleging that U.S. shale oil producers colluded with the Saudi government from 2021-2023 to drive up gas prices. That essay was based on some reporting I had done, as well as a </span><a href="https://www.dropbox.com/scl/fi/6kg5nqpr3uxakc41bmywz/pm-53123561_complaint.pdf?rlkey=lvmfvw5cjz67kwu2hc1rbk8q8&amp;dl=0" rel="">complaint</a><span> from a savvy Kansas City class action law firm, </span><a href="https://sharplawllp.com/" rel="">Sharp Law</a><span>, with special expertise in oil. The theory was that American producers, after a bitter price war from 2014-2016, got tired of competing on price with the Organization of Petroleum Exporting Countries, or the OPEC oil cartel, and at some point from 2017-2021, decided to join the cartel and cut supply to the market. This action had the affect of raising oil prices, costing oil consumers something on the order of $200 billion a year.</span></p><p><span>Yesterday, the Federal Trade Commission </span><a href="https://www.ftc.gov/news-events/news/press-releases/2024/05/ftc-order-bans-former-pioneer-ceo-exxon-board-seat-exxon-pioneer-deal" rel="">released evidence</a><span> confirming that collusion played a serious role in hiking oil prices at that time. Pioneer Natural Resources CEO Scott Sheffield, a leader in the fracking field, “exchanged hundreds of text messages with OPEC representatives and officials discussing crude oil market dynamics, pricing and output.” Sheffield was explicit about his goal, saying that “if Texas leads the way, maybe we can get OPEC to cut production. Maybe Saudi and Russia will follow. That was our plan,” he said, adding: “I was using the tactics of OPEC+ to get a bigger OPEC+ done.” He talked to shareholders, publicly threatened rivals, and ultimately achieved output cuts across the industry regardless of price. “Even if oil gets to $200/barrel,” he said, “the independent producers are going to be disciplined.”</span></p><p>By 2021, as the economy roared back from Covid, the independents had joined OPEC. “I don’t think the world can rely much on US shale,” Sheffield said. “It’s really under OPEC control.” </p><p><span>There’s more about Sheffield in the FTC complaint, though </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2410004exxonpioneercomplaintredacted.pdf" rel="">a lot is redacted</a><span>. Investment data bears out what the FTC found, with lower production despite variations in price.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png" width="765" height="415" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:415,&quot;width&quot;:765,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F702b677d-8b2b-458b-925c-66b1edeef5d0_765x415.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>How much did this conspiracy cost the consumer? “We produced too much oil and competed with OPEC,” Sheffield </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2410004exxonpioneercomplaintredacted.pdf" rel="">said</a><span> in 2023. “We actually lowered the price by $20 to $30 per barrel over the past 10 years to the detriment of losing our entire investor base.” </span></p><p><span>Since the U.S. consumes</span><a href="https://www.eia.gov/tools/faqs/faq.php?id=33&amp;t=6#:~:text=EIA%20uses%20product%20supplied%20to,7.3%20billion%20barrels%20of%20petroleum." rel=""> 7 billion barrels of oil</a><span> annually, the amount saved by shale oil drillers during their price war with OPEC was $140 billion to $210 billion a year. Once that price war ended, presumably so did the savings. The cost itself is likely a lot higher because pulling shale off the market when demand spiked probably caused prices to increase by much more than $20-30 a barrel. Anyway, we’re talking $500-1000 dollars of extra cost per year to Americans through direct and indirect effects of this conspiracy. This cost shows up most obviously in the form of more expensive gas, but higher oil prices increase the price of everything right down to potato chips because of gas being a primary cost in distribution of goods and services. For a family of four, that’s two to four thousand dollars a year in higher costs.</span></p><p><span>With these kinds of numbers, it’s likely this conspiracy had macro-economic impacts. In late 2021, I </span><a href="https://www.thebignewsletter.com/p/corporate-profits-drive-60-of-inflation" rel="">noticed</a><span> that the increase in corporate profits in aggregate was responsible for 60% of inflationary increases, using this chart and doing a bunch of rough calculations that have since mostly been borne out. The jump in profits in 2021 was about $730 billion, or $2,100 per person.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png" width="962" height="439" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:439,&quot;width&quot;:962,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7f9c6117-63ef-4aa6-ba3b-de788f9a999c_962x439.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>How do you aggregate just the oil industry? Well, it’s pretty clear that in 2021 and 2022, the industry </span><a href="https://www.americanprogress.org/article/these-top-5-oil-companies-just-raked-in-35-billion-while-americans-pay-more-at-the-pump/" rel="">did</a><span> fantastically well, with the “the top 25 companies [making] more than </span><a href="https://www.accountable.us/news/report-oil-giants-post-eye-popping-205-billion-record-profits/" rel="">$205 billion</a><span> in profits in 2021,” and an “even more astounding” amount in 2022. Of course, not all profits are due to price-fixing, but $205 billion is just the top 25, not the whole industry. And profits got much much better the next year.</span></p><p>So let’s layer on a rough guess of a $200 billion increase in profits in 2021 that Scott Sheffield implies, which is 27% of the total corporate profit increase that year. That’s a pretty astounding amount, more than a quarter of the total inflationary increase being a result purely of a price-fixing scheme.</p><p><span>In 2021-2022, many populists questioned whether oil companies were engaging in a conspiracy, which triggered intense pushback from economists like Larry Summers that market power as a cause of inflation is a </span><a href="https://www.axios.com/2022/05/24/summers-opens-new-front-on-inflation" rel="">silly theory</a><span>, and that we needed a recession and cuts to government spending to bring down prices. Remember this comment?</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png" width="1070" height="502" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:502,&quot;width&quot;:1070,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:115876,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46c25994-0fef-45a2-a9e5-eb70b9e59b9d_1070x502.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>As it turned out, populists were right about corporate profits as a factor in inflation. And now we can see that it’s price-fixing in the specific </span><em>sector </em><span>of oil companies that kept prices high. </span></p><p><span>Ok, so now let’s talk about why the government uncovered this conspiracy, and what is likely to happen. The context for this investigation was the FTC looking into the </span><a href="https://www.houstonchronicle.com/business/energy/article/exxon-pioneer-buyout-shale-texas-18419313.php" rel="">$60 billion Exxon-Pioneer merger</a><span>. And while the FTC did let the merger through, they conditioned it on Exxon disallowing Sheffield from serving on the board of the combined firm or having a role as an advisor after it acquires his company. It’s a pretty aggressive punishment for an executive, to essentially bar him from the corporation he helped build. The industry, especially in the executive suite, is </span><a href="https://www.bloomberg.com/news/articles/2024-05-02/ftc-s-surprise-attack-on-us-oil-icon-rattles-shale-sector" rel="">apparently shaken</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png" width="785" height="559" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:559,&quot;width&quot;:785,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:252971,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4fc81093-35f0-4cdf-b507-93ca1609b5cd_785x559.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Still, the FTC allowed the Exxon-Pioneer merger through, probably because the case would be brought in Texas, the industry is generally supportive of oil mergers, and it’s hard to argue to a judge that a merger would grant market power over the price of oil when the witnesses in the industry don’t support a challenge. The conduct the FTC found is a conspiracy that violates price-fixing law, and the commission should be bringing a charge on that basis, not necessarily based on merger law. Plaintiff lawyers are </span><em>already </em><a href="https://www.dropbox.com/scl/fi/6kg5nqpr3uxakc41bmywz/pm-53123561_complaint.pdf?rlkey=lvmfvw5cjz67kwu2hc1rbk8q8&amp;dl=0" rel="">bringing</a><span> price-fixing claims here, and the FTC action just made that case far more likely to draw blood. </span></p><p><span>There’s also the politics, as these oil mergers are highly contested and partisan. Democrats are skeptical of “Big Oil,” while the Republican coalition is built around fossil fuel firms, Wall Street private equity who finance it, and Saudi wealth that benefits from expensive oil. Late last year, 21 Senate Democrats asked the FTC to challenge this spate of oil and gas mergers. Then, a few month ago, 37 Senate Republicans, led by Texas Senator Ted Cruz, </span><a href="https://www.capito.senate.gov/imo/media/doc/03-27-2024_commerce_ftc_oil_and_gas_mergers_letter.pdf" rel="">sent a letter</a><span> demanding the FTC stay out of the industry’s merger spree, as that merger spree would, in their view, raise production. </span></p><p><span>Within the commission, it was obviously a big deal. The settlement from the FTC kicking Sheffield off the board was a 3-2 commission vote that similarly broke down on party lines. FTC Chair </span><a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/statement-chair-lina-m-khan-matter-exxon-mobil-corporation" rel="">Lina Khan</a><span>, </span><a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/concurring-statement-commissioner-alvaro-m-bedoya-matter-exxonmobil-copioneer-natural-resource-co" rel="">Commissioners Alvaro Bedoya</a><span> and </span><a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/concurring-statement-commissioner-rebecca-kelly-slaughter-matter-exxonmobil-corp" rel="">Rebecca Kelly Slaughter</a><span> all issued separate statements, whereas Republicans Andrew Ferguson and Melissa Holyoak issued a </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2410004exxonpioneermh-afstmt.pdf" rel="">joint dissent</a><span>. Everyone agreed that the conduct of Sheffield was concerning, and Slaughter, Holyoak, and Ferguson called for a potential price-fixing suit. </span></p><p><span>Ferguson and Holyoak argued the merger itself was fine, and the board position had nothing to do with the combination. There was an odd bit where they lauded Exxon’s ‘wise’ decision to not put Sheffield on the board. Bedoya, in his statement, rebutted this by </span><a href="https://www.ftc.gov/system/files/ftc_gov/pdf/2410004exxonpioneerambstmt_0.pdf" rel="">pointing</a><span> out that Exxon was going to put Sheffield on its board until the FTC acted. Khan’s argument was simple; when executives say they are trying to collude, regulators should have ‘regulatory humility’ and believe them.</span></p><p>At any rate, this decision is a bit of a muddle. An oil CEO, a legend and decision-maker in the industry, got personally punished for price-fixing. That’s good. But a big merger went through, though it is relatively small in the global context. Still, the muddle is inherent, as there’s just no way to fix a harm that was so vast and far-reaching. </p><p>So what happens now? Well fortunately there already is a private antitrust price-fixing suit, and it just got a huge boost from the FTC’s release of its complaint. That means years of litigation against not just Pioneer but seven different shale oil producers. Additionally, the FTC could bring actual monopolization claims against the shale producers, but that’s probably contingent upon a second Biden term, an uncertain proposition. And even with that possibility, we’re going to run into the same problem we see with all of antitrust, which is that it takes forever.</p><p>Finally, there’s also likely to be some sort of political reaction, considering it’s an election year, and this is pretty good evidence that oil firms helped collude with Saudi Arabia to steal thousands of dollars from each American family.  I can see Congressional proposals to fund oil-specific antitrust investigations, special rules proposed to prohibit communications with OPEC, or even pushing the Federal Reserve to start looking into the relationship between price-fixing and inflation. In 2022, the Biden administration pleaded with oil firms to invest in drilling more to bring down the price of oil, but they refused, claiming it was Biden environmental policies that were the cause of their low investment. </p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png" width="1092" height="597" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:597,&quot;width&quot;:1092,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:593947,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d2a3634-3f5e-4bba-bbc9-2b525a698d85_1092x597.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>The environmental constraints bit was in retrospect an obvious lie. And even the war in Ukraine, it turns out, was likely just an excuse for what was really going on, which was price-fixing. Americans were skeptical of big oil, and their instincts were correct. It really was a conspiracy against us by a small group.</p><p>That said, even if all of these suits worked out, and the political proposals enacted, it wouldn’t be enough. There’s no way to make Americans whole for what oil executives did, but there needs to be a real penalty for schemes of this magnitude. What should happen is handcuffs, en masse, for every executive that set up the American branch of OPEC. Will that happen? I doubt it. But it should.</p><p>Regardless, macro-economists should stop ignoring the dynamics of specific markets. Reality, as it turns out, matters.</p><p><span>Thanks for reading! Your tips make this newsletter what it is, so please send me tips on weird monopolies, stories I’ve missed, or other thoughts. And if you liked this issue of BIG, you can sign up&nbsp;</span><a href="http://email.mg1.substack.com/c/eJxVUMFuwyAM_ZpwjIAmYT34UHXtb0QEnBSNQARmVf5-pN1hkyzberae37PRhEtMOxBmYiVjGp0FZoEradTEXB7nhLhq54FtZfLOaHIxHFtC9LJjDzhxNUs7nKTlnGsthRKDmj-s4dIYO0i2xUyjLtZhMAj4jWmPAZmHB9GWm9OlkfcaqybKFL3H1OYyZdLmqzVxraMn-togcyC5OPNzzT3ve9WKVnS3y5WL4a54d1PdZ9PxdRH_CFiCX946XA4vL7TaGWtdS3C0jxj05NECpYKM3v94Cad9Qwj4zB6JML3Bw74chFCsHrKxcgb4o_8H-RJ1Kg" rel="">here</a><span>&nbsp;for more issues, a newsletter on how to restore fair commerce, innovation, and democracy. Consider becoming a </span><a href="https://email.mg1.substack.com/c/eJxVUMtuwyAQ_JpwtABjEw4ceulvIB6Lg4rBgrUq_31J0kO7Wmk1-xrNeIuw1XZphI7kqB0NXgfoAt89AyI0cnZoJgVNgqaSe-lI6iY2gN2mrMlxupy8xVTLc4uxhQvy0DZKpyjQIL31CqigggOPQYWBIqg3lz1DguJB15Ivc9gUSNYPxKPf5o8b_xy5W8SONWdoUz9dR-u_Jl_3MXpC35IDkjSnnI2Y6cwkZROfhIwuSrXauC7e2_u0rNhtvJaboPvG_v0iTf9SjOH21PXqDmlm1P0sCS8DxboMQWM7geDbsJcHZoMCbRgZjEXN1nmVchaci5W9VQ5bxEzlXVFFBm2o46roP8J-AJJ0hnE" rel="">paying subscriber</a><span> to support this work, or if you are a paying subscriber, giving a </span><a href="https://email.mg1.substack.com/c/eJxVUEtuxSAMPE1YRnwSSBYsKlW9BiJgUlQCETiqcvvy3uuitSxZ9tgezTiLsJd6a4SG5CwNDd4n6AzfLQEiVHI1qCZ6Tbymiju1kdhMqACHjUmT89pSdBZjyY8txmY-kU_tOZOU-bB5urhl9ouc-RomtnoXpOX0xWUvHyE70CWn25w2epL0J-LZBvE28I-eh0VsWFKCOrZra2jd1-jK0aFH62rcYBB9U-4x4CDesV5AouaUsx6CCqYoG_k4qbAFtUob5OycXcZZYrPhnoeJHjv795xU_cvZwf0h9DntWk2vx5Uj3gay3RJ4_STEl4NPU8wOGWp31huLmkkhlRIT55NkL9ndp0lQtax0JZ3Wl36V9R-lPyvjiqk" rel="">gift subscription</a><span> to a friend, colleague, or family member. If you really liked it, read my book,&nbsp;</span><a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501183089" rel="">Goliath: The 100-Year War Between Monopoly Power and Democracy</a><span>.</span></p><p>cheers,</p><p>Matt Stoller</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[As private equity dominates wheelchair market, users wait months for repairs (419 pts)]]></title>
            <link>https://www.statnews.com/2024/05/01/wheelchair-repair-delay-numotion-national-seating-mobility/</link>
            <guid>40250056</guid>
            <pubDate>Fri, 03 May 2024 17:25:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statnews.com/2024/05/01/wheelchair-repair-delay-numotion-national-seating-mobility/">https://www.statnews.com/2024/05/01/wheelchair-repair-delay-numotion-national-seating-mobility/</a>, See on <a href="https://news.ycombinator.com/item?id=40250056">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
	<p><span><span>W</span></span>hen Maureen Amirault purchased her first electric wheelchair in 2020, she had been living with muscular dystrophy for decades. Braces and a cane helped, but walking became too arduous, so she got a chair through a company called Numotion.</p>
<p>The first few months were great. The headrest fell off, but Numotion fixed it in a matter of days.</p>
<p>“That was my expectation moving forward,” said the lifelong Connecticut resident. “But for the past three years, I’ve never been without a repair issue, and I’ve usually had multiple repair issues.”</p>
<p>Amirault hasn’t had a properly fitting footplate since she got the wheelchair. She was improperly fitted at the start, but didn’t know that her feet shouldn’t be dangling. Three years later — after dozens of texts, calls and emails with Numotion and even a personal letter to the CEO — Amirault’s footplate is still faulty.</p>
<p>“I’m putting all my weight on my ankles. My feet are, like, turning in and my bones are deforming. I have custom shoes, but I can’t even put those on because the foot is so curved,” she said.</p>
<p>Protracted waits to get a wheelchair fixed are common for the over 5 million wheelchair users nationwide. In Connecticut, consumers <a href="https://cga.ct.gov/hs/tfs/20230727_Wheelchair%20Repair%20Task%20Force/20231102/NCART%20Industry%20Presentation%20to%20CT%20Working%20Group%20Final%2011-01-2023.pdf" target="_blank" rel="noopener">wait, on </a><a href="https://cga.ct.gov/hs/tfs/20230727_Wheelchair%20Repair%20Task%20Force/20231102/NCART%20Industry%20Presentation%20to%20CT%20Working%20Group%20Final%2011-01-2023.pdf" target="_blank" rel="noopener">average, nearly two months</a>. Unfortunately, they are out of options as wheelchair repair technicians are highly specialized.&nbsp;And after buying up smaller, mom-and-pop repair shops over the last decade, private-equity-owned Numotion and National Seating &amp; Mobility (NSM) <a href="https://www.motherjones.com/politics/2022/05/motorized-wheelchairs-numotion-national-seating-mobility/" target="_blank" rel="noopener">dominate the country’s wheelchair landscape</a>. They are also key figures in the $60 billion durable medical equipment industry, according to <a href="https://pestakeholder.org/wp-content/uploads/2023/11/PESP_Report_DME_2023.pdf" target="_blank" rel="noopener">a recent report by the Private Equity Stakeholder Project</a>, a non-profit group that seeks to shed light on the impact of private equity on the health care industry, among other sectors.</p>
		
		
<p>The two behemoths have both been owned by <a href="https://www.statnews.com/2022/03/24/private-equity-health-care-profits-time-to-protect-patients/">private equity companies</a> for over a decade but both got new PE owners in recent years. AEA Investors <a href="https://www.numotion.com/about-us/news/aea-investors-lp-acquires-numotion-the-nation-s-l" target="_blank" rel="noopener">bought Numotion</a> in 2018, and <a href="https://www.cinven.com/media/news/cinven-to-invest-in-national-seating-mobility/" target="_blank" rel="noopener">Cinven bought NSM</a> in 2019. Wheelchair users in Connecticut say these purchases have coincided with a decline in service.</p>
<p>Executives at both companies say they don’t have the money to hire more people to expedite repairs and shorten wait times. However, both companies had millions of dollars in annual profits during the last few years, according to financial estimates from the research firm PrivCo.</p>
<p>“What we’re talking about is access to essential medical equipment that allows people to be independent and, in some cases, get out of bed. It is really problematic that the companies would claim that it’s not possible to hire more people when their profits are quite rich,” said Sheldon Toubman, an attorney for Disability Rights Connecticut.</p>
<p>This push from disability advocates is part of a nationwide surge to secure better service for wheelchair users — especially since companies make more money selling new chairs than repairing them. Colorado recently passed a bill that <a href="https://dailymontanan.com/2023/10/08/despite-a-right-to-repair-law-theres-no-easy-fix-for-wheelchair-users/" target="_blank" rel="noopener">allows wheelchair users to repair their own chairs</a>, and <a href="https://oregoncapitalchronicle.com/2024/02/12/legislature-edges-toward-passage-of-right-to-repair-bill/" target="_blank" rel="noopener">other</a> <a href="https://www.dailyrepublic.com/news/dodd-introduces-wheelchair-repair-legislation/article_cc98267e-d026-11ee-9c6a-b30dbedf4b0e.html" target="_blank" rel="noopener">states</a>, <a href="https://www.wbur.org/news/2024/01/04/wheelchair-warranty-senate-bill" target="_blank" rel="noopener">including Massachusetts</a>, are eyeing similar measures.</p>
<p>“These are not isolated stories, these are common issues that people [across the country] are having, and there is a tremendous amount of frustration among wheelchair users,” says Amy Scherer, a senior staff attorney at the National Disability Rights Network and a wheelchair user.</p>
<p>In Connecticut, a bipartisan task force on this issue recently published a <a href="https://cga.ct.gov/hs/tfs/20230727_Wheelchair%20Repair%20Task%20Force/Final%20Report/SA%2023-22%20Wheelchair%20Repair%20Task%20Force%20Final%20Report.pdf" target="_blank" rel="noopener">report</a> outlining several recommendations, and Connecticut legislators have an opportunity to make some of these suggestions permanent before the legislative session ends on May 8. For the state’s approximately 6,500 wheelchair users, waiting has consequences.</p>
<p>“[They] said the cost is too much for them to bear,” said Amirault, referring to the reasoning the wheelchair makers offered lawmakers. “But the cost of them not [doing] it is too much for us to bear.”</p>
<h2><strong>The cost of long repair times</strong></h2>
<p>Customized wheelchairs typically last five years, but most chairs <a href="https://pubmed.ncbi.nlm.nih.gov/33845000/" target="_blank" rel="noopener">need a major repair or two during that time</a>. Electric wheelchairs, or power chairs, are a technological marvel, meticulously designed from hub to seat to deliver power and maneuverability so the user can roam as needed, while also supporting and cushioning their body for potentially an entire day.</p>
<p>To get such a chair, a person needs a prescription, authorization from their insurance company, and a custom fitting from an assistive technology professional. Like a tailor crafting an exquisite suit, these technicians meticulously measure a client’s body to ensure the device’s specifications will match.</p>
<p>“Wheelchairs are a very personal thing. We consider them to be part of our body, and when they’re not working, we’re not working our best,” said Cathy Ludlum, a disability consultant and wheelchair user in Manchester, Conn. “It’s almost like having a relationship with a doctor or a really good mechanic. You’d like to know that when something is wrong, they will be there for you. Sadly, that’s not what’s happening any more.”</p>
		
		
<p>A recent survey suggests the extended wait times are a widespread problem. Disability advocates conducted an informal survey that found that over <a href="https://cga.ct.gov/hs/tfs/20230727_Wheelchair%20Repair%20Task%20Force/Final%20Report/SA%2023-22%20Wheelchair%20Repair%20Task%20Force%20Final%20Report.pdf" target="_blank" rel="noopener">75% of consumers waited at least a month for a repair</a>. Companies often provide loaner wheelchairs to help users get around, but they rarely fit as well. Industry experts from the National Coalition for Assistive &amp; Rehab Technology (NCART) gave a <a href="https://cga.ct.gov/hs/tfs/20230727_Wheelchair%20Repair%20Task%20Force/20231102/NCART%20Industry%20Presentation%20to%20CT%20Working%20Group%20Final%2011-01-2023.pdf" target="_blank" rel="noopener">presentation</a> last year that showed in-home repairs took roughly two months. All this waiting has consequences for wheelchair users.</p>
<p>In 2021, Ludlum’s power chair frequently got stuck and couldn’t move. If there wasn’t anyone nearby to restart her chair, she would simply have to wait, often for hours. It took seven months for NSM to fix her chair.</p>
<p>Seven months of increased stillness sapped the strength in her hands. Ludlum, who has spinal muscular atrophy, stopped being able to reliably lift her finger off the light beam, which stops the chair. One day she couldn’t stop her chair, which then crashed into her living room couch and almost flipped over.</p>
<p>“It’s really scary when you can’t make your wheelchair go,” she said. “But it’s twice as scary when you can’t make it stop.”</p>
<p>Ludlum, 62, is quick to point out that the chair wasn’t responsible for the crash. But the experience was so harrowing that she now uses a manual wheelchair and relies on other people to push her. Years of declining service from NSM also make her reluctant to return to her old chair, which sits still in the hallway now.</p>
<h2><strong>Data undercut industry claims of financial hardship</strong></h2>
<p>While disability advocates see the wheelchair repair system as newly flawed, NCART Executive Director Wayne Grau said the dysfunction is baked in. Neither company replied to a request for comment and instead nominated Grau to speak on their behalf.</p>
<p>“For 30 years, the repair process has been inefficient at best,” he said. “Covid broke it with supply chain issues and with labor issues.”</p>
<p>Numotion Executive Vice President of the East Division Gary Gilberti blamed financial constraints at a Connecticut legislative task force meeting in November. He said, “I get the solution is more people, but that’s economically not possible.”</p>
<p>That narrative of financial hardship does not square with what STAT was able to find out about the financial health of both the companies. Numotion has taken home at least $90 million in profits in each of the last three years, according to estimates from PrivCo. NSM has been clearing at least $55 million each year. When asked about this data, Grau said that he was “not privy to those numbers” and reiterated that it was a “capital-intensive business.”</p>
<p>Industry leaders say that the keys to improving service are freeing up the supply chain, removing insurance prior authorization and getting through the pandemic repair backlog, which is significant. As of November, Numotion had 740 outstanding service orders for 622 customers and NSM had 687 for 445 customers. The companies did not offer data on the pre-pandemic backlog for comparison. However, Diane Racicot, NSM vice president of payer relations, undercut the idea that the supply chain is partly to blame, <a href="https://cga.ct.gov/hs/tfs/20230727_Wheelchair%20Repair%20Task%20Force/Final%20Report/SA%2023-22%20Wheelchair%20Repair%20Task%20Force%20Final%20Report.pdf" target="_blank" rel="noopener">saying during a December task force meeting</a>, “well over two-thirds of our backlog — parts are in, and we’re trying to get them out the door.”</p>
		
		
<p>In the wake of the task force report, the two companies promised to hire three additional technicians in Connecticut. According to Grau, they have both hired two and are both “looking for their third one.” Grau also said that wait times have improved in recent months, but when asked to share data, he did not answer the question.</p>
<p>Connecticut state Rep. Jillian Gilchrest recently toured the NSM warehouse in Newington and saw a cavernous room filled to the brim with roughly 200 wheelchairs, most of them waiting for repairs. Then she looked at the pictures on the wall of the staff. There were only six or eight people, and one of those workers had just left the company.</p>
<p>“I’m not a mathematician, but that’s not that much staff. Why can’t you hire more? Two hundred wheelchairs is a lot of wheelchairs,” she said.</p>
<p>Gilchrist says the script is all too familiar. As the human services committee chair in the state House of Representatives, she has watched <a href="https://ctmirror.org/2024/03/07/ct-health-care-private-equity-investment/" target="_blank" rel="noopener">other industries like nursing homes become dominated by private equity</a>.</p>
<p>“It’s hard for me to hear that argument ‘we don’t have the money’ when their profits are so high,” she said. “I’d like to see national companies like that restructure how much they pay folks at the top and redirect some of that money towards staffing the technicians who do the everyday work.”</p>
<p>Most people on the task force agreed that changes needed to be made, but Gilchrist concedes that the state’s “<a href="https://ctmirror.org/2024/02/12/ct-fiscal-guardrails-explained/" target="_blank" rel="noopener">fiscal guardrails</a>” will likely water down any legislation.</p>
<p>Grau wants more wheelchair users to come into the shop, as repairs happen much faster — only two week’s wait, on average. Wheelchair users are loath to adopt this, as coming into the office can be physically treacherous for them and they would have to pay for transit. Gilchrest hopes that next year the task force can put some money into this issue, like fund paratransit to the repair shops.</p>
<p>Until then, Ludlum will be relying on her manual wheelchair to get around. Her world is smaller now. She can no longer visit her garden by herself, and it’s harder for her to hang out with older friends, some of whom can’t push her. She doesn’t want these subpar mobility options to close her off from loved ones, especially given the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10357115/" target="_blank" rel="noopener">negative effects of social isolation</a>.</p>
<p>“Wheelchairs and power chairs in particular make us more functional. We need to be able to move. We need to be able to go out and do things and be independent as much as we can,” she said.</p>
</section></div>]]></description>
        </item>
    </channel>
</rss>