<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 04 Jun 2025 10:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Merlin Bird ID (226 pts)]]></title>
            <link>https://merlin.allaboutbirds.org/</link>
            <guid>44176829</guid>
            <pubDate>Wed, 04 Jun 2025 02:58:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://merlin.allaboutbirds.org/">https://merlin.allaboutbirds.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44176829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hero-wrapper">
              <h2>Identify the birds you see or hear with Merlin Bird ID</h2><p>Free global bird guide with photos, <br>sounds, maps, and more.</p><p><a href="https://itunes.apple.com/app/apple-store/id773457673?pt=401711&amp;ct=marketingwebsite&amp;mt=8"><img data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2020/01/Download_App_Store_en.png" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></a> <a href="https://play.google.com/store/apps/details?id=com.labs.merlinbirdid.app&amp;pli=1"><img data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2020/02/google-play-badge-en.png" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></a></p>            </div><section id="content" aria-label="Main content" data-sticky-container="">
 
      
<div>
<div>
<h2>Identify Bird Songs and Calls</h2>



<p><strong>Sound ID</strong> listens to the birds around you&nbsp;and shows real-time suggestions for who’s singing. Compare your recording to the songs and calls in Merlin to confirm what you heard. Sound ID works completely offline, so you can identify birds you hear no matter where you&nbsp;are. </p>



<p>Available for birds in the US, Canada, Europe, with some common birds of Central and South America, and India. More species and regions coming soon.&nbsp;</p>




</div>



<div>
<figure><img fetchpriority="high" decoding="async" width="2000" height="1250" src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1.png" alt="" srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1.png 2000w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-720x450.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-1280x800.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-768x480.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-1536x960.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Merlin-Website-Screens-1-480x300.png 480w" sizes="(max-width: 2000px) 100vw, 2000px"></figure>
</div>
</div>



<hr>



<div>
<div>
<figure><img decoding="async" width="1280" height="800" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-1280x800.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-1280x800.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-720x450.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-768x480.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-1536x960.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1-480x300.png 480w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Photo-ID-1.png 2000w" data-sizes="(max-width: 1280px) 100vw, 1280px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>
</div>



<div>
<h2>Identify Birds in a Photo</h2>



<p>Snap a photo of a bird, or pull one in from your camera roll, and <strong>Photo ID</strong> will offer a short list of possible matches. Photo ID works completely offline, so you can identify birds in the photos you take no matter where you&nbsp;are. </p>




</div>
</div>



<hr>



<h2>Bird ID Wizard—Step-by-step</h2>



<p>Answer three simple questions about a bird you are trying to identify and Merlin will give you a list of possible matches.&nbsp;Merlin offers quick identification help for all levels of bird watchers and outdoor enthusiasts to help you learn about the birds in any country in the world. </p>



<figure><img decoding="async" width="1600" height="600" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1.png 1600w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-720x270.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-1280x480.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-768x288.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-1536x576.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Step-by-Step-1-480x180.png 480w" data-sizes="(max-width: 1600px) 100vw, 1600px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>











<hr>



<div>
<div>
<h2>Save Birds to Your Life List</h2>



<p>Build a&nbsp;digital&nbsp;scrapbook of your birding memories with Save My Bird. Tap “This is my bird!” each time you identify a bird, and&nbsp;Merlin will add it to your growing life&nbsp;list.</p>




</div>



<div>
<figure><img decoding="async" width="2000" height="1250" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List.png 2000w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-720x450.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-1280x800.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-768x480.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-1536x960.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Life-List-480x300.png 480w" data-sizes="(max-width: 2000px) 100vw, 2000px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>
</div>
</div>



<hr>



<h2>Explore Lists of Birds Near You</h2>



<p>Merlin is powered by&nbsp;<a href="http://ebird.org/">eBird</a>, allowing you to&nbsp;build custom lists of&nbsp;the birds you’re likely to spot wherever you are. Use the filter options to&nbsp;explore birds for different locations or time of year, or switch to show all the Offline Birds you’ve downloaded.&nbsp;Get more from the app with these <a href="https://support.ebird.org/en/support/solutions/articles/48000966225-merlin-tips-and-tricks#anchorCustomList">Merlin Tips and Tricks</a>.</p>



<figure><img decoding="async" width="1600" height="600" data-src="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore.png" alt="" data-srcset="https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore.png 1600w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-720x270.png 720w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-1280x480.png 1280w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-768x288.png 768w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-1536x576.png 1536w, https://merlin.allaboutbirds.org/wp-content/uploads/2025/05/Explore-480x180.png 480w" data-sizes="(max-width: 1600px) 100vw, 1600px" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg=="></figure>



<hr>



<h2>See How Merlin Can Help You ID Birds</h2>



<figure><p>
<iframe title="Merlin Bird ID Demo from the Cornell Lab of Ornithology" width="1200" height="675" data-src="https://www.youtube.com/embed/xmSUOLxyatY?feature=oembed&amp;modestbranding=1&amp;showinfo=0&amp;rel=0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMSIgaGVpZ2h0PSIxIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-load-mode="1"></iframe>
</p></figure>



<hr>



<h2>The Best Birding App, Powered By You</h2>



<p>Merlin features the best of community contributed photos, songs, and calls, tips from experts around the world to help you ID the birds you see, and range maps from <a href="https://birdsoftheworld.org/bow/home">Birds of the World</a>—all powered by billions of bird observations submitted to <a href="https://ebird.org/home">eBird</a>.</p>





      
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Binary Wordle (118 pts)]]></title>
            <link>https://wordle.chengeric.com/</link>
            <guid>44176825</guid>
            <pubDate>Wed, 04 Jun 2025 02:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordle.chengeric.com/">https://wordle.chengeric.com/</a>, See on <a href="https://news.ycombinator.com/item?id=44176825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Use keyboard (0, 1, Enter, Backspace) or buttons to play</p></div><div><p>Sponsor: Don't like waiting on hold? Try</p><!-- --> <p><a href="https://altodial.com/?wordle"><img alt="" loading="lazy" width="16" height="16" decoding="async" data-nimg="1" src="https://wordle.chengeric.com/square.svg">altodial.com</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DiffX – Next-Generation Extensible Diff Format (235 pts)]]></title>
            <link>https://diffx.org/</link>
            <guid>44176737</guid>
            <pubDate>Wed, 04 Jun 2025 02:38:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://diffx.org/">https://diffx.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44176737">Hacker News</a></p>
Couldn't get https://diffx.org/: Error: getaddrinfo ENOTFOUND diffx.org]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Has anybody built search on top of Anna's Archive? (137 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=44176514</link>
            <guid>44176514</guid>
            <pubDate>Wed, 04 Jun 2025 01:47:26 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=44176514">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="44176767"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44176767" href="https://news.ycombinator.com/vote?id=44176767&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>Honestly I don't think it would be that costly, but it would take a pretty long time to put together. I have a (few years old) copy of Library Genesis converted to plaintext and it's around 1TB. I think libgen proper was 50-100TB at the time, so we can probably assume that AA (~1PB) would be around 10-20TB when converted to plaintext. You'd probably spend several weeks torrenting a chunk of the archive, converting everything in it to plaintext, deleting the originals, then repeating with a new chunk until you have plaintext versions of everything in the archive. Then indexing all that for full text search would take even more storage and even more time, but still perfectly doable on commodity hardware.</p><p>The main barriers are going to be reliably extracting plaintext from the myriad of formats in the archive, cleaning up the data, and selecting a decent full text search database (god help you if you pick wrong and decide you want to switch and re-index everything later).</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177936"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177936" href="https://news.ycombinator.com/vote?id=44177936&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>The main barriers for me would be:</p><p>1. Why? Who would use that? What’s the problem with the other search engines? How will it be paid for?</p><p>2. Potential legal issues.</p><p>The technical barriers are at least challenging and interesting.</p><p>Providing a service with significant upfront investment needs with no product or service vision that I’ll likely to be sued for a couple of times a year, probably losing with who knows what kind of punishment… I’ll have to pass unfortunately.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178200"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44178200" href="https://news.ycombinator.com/vote?id=44178200&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>It would be incredible for LLMs. Searching it, using it as training data, etc. Would probably have to be done in Russia or some other country that doesn't respect international copyright though.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178241"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178241" href="https://news.ycombinator.com/vote?id=44178241&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Do you have a reason to believe this ain't already being done? I would assume that the big guys like openai are already training on basically all text in existence.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178453"><td></td></tr>
                  <tr id="44178237"><td></td></tr>
                        <tr id="44177444"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177444" href="https://news.ycombinator.com/vote?id=44177444&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I think there’s a couple ways to improve it:</p><p>1. There’s a lot of variants of the same book. We only need one for the index. Perhaps for each ISBN, select the format easiest to parse.</p><p>2. We can download, convert and index top 100K books first, launch with these, and then continue indexing and adding other books.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177679"><td></td></tr>
                <tr id="44178316"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178316" href="https://news.ycombinator.com/vote?id=44178316&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>From a good search perspective though you probably dont want 500 different versions of the same book popping up for a query</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="44177996"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177996" href="https://news.ycombinator.com/vote?id=44177996&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I wonder if you could implement it with only static hosting?</p><p>We would need to split the index into a lot of smaller files that can be practically downloaded by browsers, maybe 20 MB each.
The user types in a search query, the browser hashes the query and downloads the corresponding index file which contains only results for that hashed query. Then the browser sifts quickly through that file and gives you the result.</p><p>Hosting this would be cheap, but the main barriers remain..</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44177999"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177999" href="https://news.ycombinator.com/vote?id=44177999&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>It's trivial to normalise the various formats, and there were a few libraries and ML models to help parse PDFs. I was tinkering around with something like this for academic papers in Zotero, and the main issue I ran into was words spilling over to the next page, and footnotes. I totally gave up on that endeavour several years ago, but the tooling has probably matured exponentially since then.</p><p>As an example, all the academic paper hubs have been using this technology for decades.</p><p>I'd wager that <i>all</i> of the big Gen AI companies have planned to use this exact dataset, and many or them probably have already.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178133"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44178133" href="https://news.ycombinator.com/vote?id=44178133&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>&gt; It's trivial to normalise the various formats,</p><p>Ha. Ha. ha ha ha.</p><p>As someone who as pretty broadly tried to normalize a pile of books and documents I have legitimate access to, <i>no it is not</i>.</p><p>You can get good results 80% of the time, usable but messy results 18% of the time, and complete garbage the remaining 2%. More effort seems to only result in marginal improvements.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178321"><td></td></tr>
                              <tr id="44178333"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178333" href="https://news.ycombinator.com/vote?id=44178333&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>There is a search solution for zipped fb2 files. Not exactly what you need, but it has potential.</p><p>The project has similar story to Anna's archive. There is 0.5 TB of archived books, and the project creates index of all the books with text, title and aruthor search capabilities, gives html UI for search and reading. On weak machine it takes about 2 hours to build that index.</p><p>So if you have zipped archives of fb2, you can use the project to create web UI with search for those files. Without need of enough space to unpack all the files.</p><p>You'll have to translate some russian though to get instructions on how to set it up.</p><p><a href="https://gitlab.com/opennota/fb2index/-/blob/master/README.ru.md" rel="nofollow">https://gitlab.com/opennota/fb2index/-/blob/master/README.ru...</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178203"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178203" href="https://news.ycombinator.com/vote?id=44178203&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>There’s an android app called OpenLip. [1]</p><p>Description:</p><p>Openlib is an open source app to download and read books from shadow library (Anna’s Archive). The App Has Built In Reader to Read Books.</p><p>As Anna’s Archive doesn't have an API, the app works by sending requests to Anna’s Archive and parses the response to objects. The app extracts the mirrors from the responses, downloads the book and stores it in the application's document directory.</p><p>Note :
The app requires VPN to function properly . Without VPN the might show the captcha required page even after completing the captcha</p><p>Main Features:</p><p>Trending Books</p><p>Download And Read Books With In-Built Viewer</p><p>Supports Epub And Pdf Formats</p><p>Open Books With Your Favourite Ebooks Reader</p><p>Filter Books</p><p>Sort Books</p><p>[1]: <a href="https://f-droid.org/de/packages/com.app.openlib/" rel="nofollow">https://f-droid.org/de/packages/com.app.openlib/</a></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44176569"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44176569" href="https://news.ycombinator.com/vote?id=44176569&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>You must mean free text search and page level return, because it already has full metadata indexing.</p><p>The thing is AA doesn't hold the texts. They're disputable IPR and even a derived work would be a legal target.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178214"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178214" href="https://news.ycombinator.com/vote?id=44178214&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Z-Library has a keyword search. Personally i didn't find it too useful, especially given Google Books exists. It's not easy to create a quality book search engine.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44177457"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44177457" href="https://news.ycombinator.com/vote?id=44177457&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>As far as I know, no one has fully implemented full-text search directly over Anna's Archive. Technically it’s feasible with tools like Meilisearch, Elasticsearch, or Lucene, but the main challenges are:</p><pre><code>    Converting all documents (PDFs, EPUBs, etc.) to clean plaintext.

    Indexing at scale efficiently.

    Managing potential legal issues.
</code></pre><p>
Z-Library does something similar, but it’s smaller in scope and doesn't integrate AA’s full catalog.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177592"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44177592" href="https://news.ycombinator.com/vote?id=44177592&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I’ve done something like this before. Meilisearch will not be viable, because it indexes very slow and it takes up a lot of space.</p><p>In my experience only Tantivy can index this much data. Check out Lnx.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178248"><td></td></tr>
                        <tr id="44177894"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44177894" href="https://news.ycombinator.com/vote?id=44177894&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Related question, has Anna's archive been thoroughly filtered for non-copyright-related illegal material? Pedo, terrorism, etc. I've considered downloading a few chunks of it but I'm worried of ending up with content I really don't want to be anywhere near from.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178086"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44178086" href="https://news.ycombinator.com/vote?id=44178086&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>This is a really strange question to be honest you could ask this literally about any download let alone simply torrents of documents.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178012"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44178012" href="https://news.ycombinator.com/vote?id=44178012&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>How might you inadvertently download illegal content while searching for legal content?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178070"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_44178070" href="https://news.ycombinator.com/vote?id=44178070&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>He said he wants to download lots of it in general, not specifical. Legit question, if you end up with dark material.</p><p>I would assume pedo stuff is not really there, but the anarchist cookbook and alike likely will be.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178167"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178167" href="https://news.ycombinator.com/vote?id=44178167&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I'm still not sure the question makes much sense, if it's a general: "I want to support the project and so I want to seed a large chunk" Okay, I guess it's your due diligence to check, but there is a reporting feature built in, if something is found, report it.</p><p>Aside from that, if you're searching for specific content, the question is moot I guess.</p><p>I guess my confusion is what distinguishes this apart from any other torrent ? That is, if the submitted content is submitted at all.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178210"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_44178210" href="https://news.ycombinator.com/vote?id=44178210&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>I understood it as he or she wants to download large chunks of potentially interesting books for offline use, or once Anna goes down. So a broad filter. Not for seeding.</p><p>But thanks for the explanation that there is a report build in.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44178137"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_44178137" href="https://news.ycombinator.com/vote?id=44178137&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Considering the anarchist cookbook is just a rebranded selection of freely-available US Army Field Manuals, ... I don't see the problem.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178201"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_44178201" href="https://news.ycombinator.com/vote?id=44178201&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>I don't either, but many states have laws regarding books on how to build bombs and they might get enforced more than copyright.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44178127"><td></td></tr>
                <tr id="44178218"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_44178218" href="https://news.ycombinator.com/vote?id=44178218&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Well, I won't. But does it contain just text or real pictures? That would make a big legal difference I assume.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178277"><td></td></tr>
                                    <tr id="44176864"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44176864" href="https://news.ycombinator.com/vote?id=44176864&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>AFAIK, Z-Library already does this, to some extent. Basic full-text queries do search inside the body of books and articles.</p><p>It's a bit smaller than Anna's Archive, as they do host their own collections. From some locations, it's only easy to access through Tor.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="44178107"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44178107" href="https://news.ycombinator.com/vote?id=44178107&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>Has anyone explored a different angle — like mapping out the 1,000 most frequently mentioned or cited books (across HN, Substack, Twitter, etc.), then turning their raw content into clean, structured data optimized for LLMs? Imagine curating these into thematic shelves — say, “Bill Gates’ Bookshelf” or “HN Canon” — and building an indie portal where anyone can semantically search across these high-signal texts. Kind of like an AI-searchable personal library of the internet’s favorite books.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="44178130"><td></td></tr>
                  <tr id="44177619"><td></td></tr>
            <tr id="44177170"><td></td></tr>
                <tr id="44178025"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_44178025" href="https://news.ycombinator.com/vote?id=44178025&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div>
                  <p>It's not exactly clear, but OP is asking about indexing the content of all the documents, not the metadata (e.g. titles etc)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="44177542"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_44177542" href="https://news.ycombinator.com/vote?id=44177542&amp;how=up&amp;goto=item%3Fid%3D44176514"></a></center>    </td><td><br><div><p>Mebbe easier to just search Amazon or Goodreads. Like site:amazon.ca &lt;query words&gt; as someone has mentioned below.</p><p>Every book has an ISBN 10 or 13 digit ISBN number to identify them. Unless it's some self-pub/amateur-hour situation by some paranoid prepper living in a faraday-cage-protected cage in Arkansas or Florida it's likely a publication with a title, an author and an ISBN number.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="44177831"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A manager is not your best friend (157 pts)]]></title>
            <link>https://staysaasy.com/management/2025/06/02/your-manager-is-not-your-best-friend.html</link>
            <guid>44176425</guid>
            <pubDate>Wed, 04 Jun 2025 01:29:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://staysaasy.com/management/2025/06/02/your-manager-is-not-your-best-friend.html">https://staysaasy.com/management/2025/06/02/your-manager-is-not-your-best-friend.html</a>, See on <a href="https://news.ycombinator.com/item?id=44176425">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>As people become managers, it’s quite common for their team members to want to commiserate with them. This is especially true for friendly, competent, reasonable-seeming managers – people want to commiserate with <em>winners</em>. This makes commiseration extra dangerous, as it comes with a hint of flattery (“I respect your opinion and trust your discretion”).</p>

<p>But commiseration, especially with your direct reports, is organizational poison. It erodes the fabric of an organization and builds factions. It leads to feelings of superiority and creates a low-trust environment – <em>even if what you’re complaining about is made up!</em> Worst of all, it doesn’t give other teams an opportunity to improve. If I think that HR sucks, and I commiserate with my directs about it, my team is going to treat them poorly. HR will never know why, will never fix the problem, and will just think that my team are jerks (and they’ll arguably be right). Commiseration is self-fulfilling because it’s a form of victimhood: The world is conspiring against us, the only truly virtuous team.</p>

<p>Commiseration comes naturally to most people, because it happens all the time in real life. As your best friend, if you come to me saying that you were just dumped by your girlfriend, you will get unconditional sympathy beyond words. You’re the best, she didn’t deserve you, you can do so much better, everyone knows you’re the man, I have no idea why you ever spent time with her. There will be no questions, there will be no need for you to explain anything about the situation, even if all you did for the last 2 years was sit on your couch smoking weed and playing Warzone, <em>Greg</em>. Unless you did something totally crazy or illegal, my loyalty will be immediate and unconditional, because – let’s be real – none of it matters. You’re going your way, she’s going hers, and it’s over.</p>

<p>As a manager, your empathy needs to be highly conditional. Your job is to get to the truth of a matter in a respectful way, not make your team feel good. You are largely stuck with your coworkers, and you need to get stuff done together or everyone suffers. If you break up with your girlfriend you get unconditional sympathy. But if you break up with your girlfriend, and the 3 of us were trying to climb Mt. Everest together, I’m going to be a lot more measured in how I communicate and balance your relationship so that we can all survive the next few days.</p>

<p>Commiseration is generally a sensitive topic, so I’ve tried to boil down how to handle situations when a direct comes to you with grievances via some heuristics:</p>

<ul>
  <li>You don’t really want to debate your team in every situation, but your job is to essentially be a scientist and get to the bottom of what’s going on. If someone wants to commiserate about some other team, your first job is to ask a bunch of questions about what’s going on. In my experience, 90% of the time the situation is a grey area, and probably 30% of the time the person who wants to commiserate is actually in the wrong, on balance.</li>
  <li>Your role as a manager is also to be a perspective-creator. Sure, that salesperson was overly optimistic on how impactful this custom feature was for a prospect. And sure, the deal wasn’t as large and didn’t close as quickly as they said it would. But sales incentives are a law of the universe, and sales directors need to manage around them just as much as product teams do, because <em>not</em> having sales incentives is even worse. And by the way, we’re not so great at estimating development timelines either. Everyone’s blood pressure should always be lower after they’ve spoken to you.</li>
  <li>Bad therapists just let you rant. Good therapists let you vent, but they ask clarifying questions, and they sometimes push back. The phrase “is that actually true?” or “Can you explain that more?” are your friends. Good therapists validate feelings but they don’t necessarily validate <em>facts</em>. “I know you feel like you’re being a good daughter” is not the same as “you are the best daughter.” You want to be a good therapist.</li>
  <li>Remove the phrase “I don’t know why they…” from your lexicon. No matter how you end this sentence, the subtext will be clear: “I don’t know why they’re so incompetent.” Instead, it’s often better to give the most optimistic view for why another team is behaving the way that they are. It might not be <em>right</em>, but it builds empathy which is the bedrock on which productive collaboration is built.</li>
  <li>If someone is trying to get you to commiserate with them, try to speak in terms of reiterating a decision framework. Rather than “marketing doesn’t know what they’re doing,” you want to say something like “our role is to build the product and have a strong POV for marketing, and their role is to make sure that our launch generates enough pipeline. If you don’t think that’s going to happen then let’s talk to them.” The goal is to focus on objective truths rather than disparaging opinions.</li>
  <li>When it comes to commiseration, people are highly attuned to nuanced communication – especially from their boss. “Well guys, we’ve got this” plus that little head nod and eyeroll is functionally the equivalent of saying “it’s all on us, the protagonists, because everyone else is a fucking idiot <strong>again</strong>.” Those words didn’t literally leave your mouth, but you effectively said it, and as a manager that’s 100% on you. As a manager your implicit communication is just as important as your explicit communication – this is not a courtroom, this is real life, and non-verbal actions can still have consequences.</li>
  <li>One of the most common people to commiserate about is your own boss, or the company’s CEO. This can get highly toxic fast, and is rarely actually productive – cases of teams changing their CEO’s behavior through commiseration are vanishingly rare. The right way to pivot this conversation (or at least, the only way I’ve ever seen this play out positively) is to discuss how you can most effectively work with your boss. This is significantly more productive, and even if you still think they’re being dumb, at least you’re tackling that problem constructively.</li>
</ul>

<p>Of course sometimes people really are AAA grade idiots. When this happens, your communication should typically address the issue, not the other team. For most situations, it’s best to say “let me follow up,” rather than “I agree that they’re dumb.” In particularly egregious cases, you can go with “I know this is a problem and I’ll get on it” or “I hear you, I’m working on it, but I can’t give you every detail on how and don’t expect ongoing updates” – this avoids gaslighting them that everything is fine, but it also stops the vent session. When the door opens to commiseration with your team, you must slam it shut.</p>

<p>Either way, following up is the ideal next step because it commits you to respond but separates the emotion from the action. Accumulated strong emotions leave a strong impression, especially when they’re negative emotions like bitterness, so it’s best to suck the emotion out of the conversation as fast as possible. For evidence of this, light autists often make very effective managers.</p>

<p>Finally – we’re all human here, and sometimes you need to commiserate with <em>someone</em> before your head explodes. If you must commiserate, it’s almost always best if they’re a peer / near peer, and they’re not on your direct team (you don’t share a boss). This at least dodges the situation where a manager complains alongside their team, and thereby implicitly blesses their most negative views.</p>


    

    

    

    




  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta pauses mobile port tracking tech on Android after researchers cry foul (119 pts)]]></title>
            <link>https://www.theregister.com/2025/06/03/meta_pauses_android_tracking_tech/</link>
            <guid>44175940</guid>
            <pubDate>Tue, 03 Jun 2025 23:42:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/06/03/meta_pauses_android_tracking_tech/">https://www.theregister.com/2025/06/03/meta_pauses_android_tracking_tech/</a>, See on <a href="https://news.ycombinator.com/item?id=44175940">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Security researchers say Meta and Yandex used native Android apps to listen on localhost ports, allowing them to link web browsing data to user identities and bypass typical privacy protections.</p>
<p>Following the disclosure, researchers observed that Meta's Pixel script stopped sending data to localhost and that the tracking code was largely removed. The move may help Meta avoid scrutiny under Google Play policies, which prohibit covert data collection in apps.</p>
<p>"We are in discussions with Google to address a potential miscommunication regarding the application of their policies," a Meta spokesperson told <em>The Register</em>. "Upon becoming aware of the concerns, we decided to pause the feature while we work with Google to resolve the issue."</p>

    

<p>Meta's spokesperson did not respond to a request to elaborate on the company's discussions with Google.</p>
<h3>What the researchers found</h3>
<p>In a <a target="_blank" rel="nofollow" href="https://localmess.github.io/">report</a> published Tuesday, computer scientists affiliated with IMDEA Networks (Spain), Radboud University (The Netherlands), and KU Leuven (Belgium) describe how the US social media giant and the Russian search engine were observed using native Android apps to gather web cookie data via the device's loopback interface, commonly known as localhost.</p>
<p>Localhost is a loopback address that a device can use to make a network request to itself. It's commonly used by software developers to test server-based applications like websites on local hardware.</p>

        


        

<p>The researchers – Aniketh Girish (PhD student), Gunes Acar (Assistant Professor), Narseo Vallina-Rodriguez (Associate Professor), Nipuna Weerasekara (PhD student), and Tim Vlummens (PhD student) – say they found native Android apps, including Facebook and Instagram, and Yandex's Maps and Browser – that listen silently on fixed local ports for tracking purposes.</p>
<p>"These native Android apps receive browsers' metadata, cookies and commands from the Meta Pixel and Yandex Metrica scripts embedded on thousands of websites," the computer scientists explain. "These JavaScripts load on users' mobile browsers and silently connect with native apps running on the same device through localhost sockets."</p>

        

<p>As these native apps access device identifiers like the Android Advertising ID or handle user identities in Meta apps, the researchers say, they're able to link mobile browsing sessions and web cookies to user identities.</p>
<p>Essentially, by opening localhost ports that allow their Android apps to receive tracking data, such as cookies and browser metadata, from scripts running in mobile browsers, Meta and Yandex are able to bypass common privacy safeguards like cookie clearing, Incognito Mode, and Android's app permission system.</p>
<p>The technique also violates assumptions about the scope of first-party cookies, which aren't supposed to be able to track browsing activity across different websites. According to the researchers, "the method we disclose allows the linking of the different _fbp cookies to the same user, which bypasses existing protections and runs counter to user expectations."</p>

        

<p>With regard to Meta, the tracking process involves scripts associated with <a target="_blank" rel="nofollow" href="https://www.facebook.com/business/tools/meta-pixel">Meta Pixel</a>, analytics code used by marketers to gather data about interactions with websites.</p>
<p>Various APIs and protocols can be used to implement the described app-web eavesdropping scheme. These include: SDP munging, which involves manually modifying Session Description Protocol (SDP) messages before the data gets passed to the browser; real-time communications protocols <a target="_blank" rel="nofollow" href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API">Websocket</a> and <a target="_blank" rel="nofollow" href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Protocols">WebRTC</a>; Session Traversal Utilities for NAT (STUN), an address discovery mechanism; and Traversal Using Relays around NAT (TURN), a router restriction bypass method.</p>
<ul>

<li><a href="https://www.theregister.com/2025/06/03/xs_new_encrypted_xchat_feature/">X's new 'encrypted' XChat feature seems no more secure than the failure that came before it</a></li>

<li><a href="https://www.theregister.com/2025/05/30/meta_is_now_a_defense/">Meta – yep, Facebook Meta – is now a defense contractor</a></li>

<li><a href="https://www.theregister.com/2025/05/29/billions_of_cookies_available/">Billions of cookies up for grabs as experts warn over session security</a></li>

<li><a href="https://www.theregister.com/2025/05/22/irish_data_protection_commission_gives/">Irish privacy watchdog OKs Meta to train AI on EU folks' posts</a></li>
</ul>
<p>The researchers describe Meta's approach thus:</p>
<blockquote>
<ol>

<li>The user opens the native Facebook or Instagram app, which eventually is sent to the background and creates a background service to listen for incoming traffic on a TCP port (12387 or 12388) and a UDP port (the first unoccupied port in 12580-12585). Users must be logged-in with their credentials on the apps.</li>

<li>The user opens their browser and visits a website integrating the Meta Pixel.</li>

<li>At this stage, websites may ask for consent depending on the website's and visitor's locations.</li>

<li>The Meta Pixel script sends the <a target="_blank" rel="nofollow" href="https://localmess.github.io/#about_fbp">_fbp cookie</a> to the native Instagram or Facebook app via WebRTC (STUN) <a target="_blank" rel="nofollow" href="https://webrtchacks.com/not-a-guide-to-sdp-munging/">SDP Munging</a>.</li>

<li>The Meta Pixel script also sends the _fbp value in a request to https://www.facebook.com/tr along with other parameters such as page URL (dl), website and browser metadata, and the <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250531104925/https://developers.facebook.com/docs/meta-pixel/reference/">event type</a> (ev) (e.g., PageView, AddToCart, Donate, Purchase).</li>

<li>The Facebook or Instagram apps receive the _fbp cookie from the Meta Pixel JavaScript running on the browser. The apps transmit _fbp as a GraphQL mutation to (https://graph[.]facebook[.]com/graphql) along with other persistent user identifiers, linking users' fbp ID (web visit) with their Facebook or Instagram account.</li>
</ol>
</blockquote>
<p>Researchers observed Meta implementing this technique starting in September 2024, transmitting data via HTTP. Third-party developers working with Meta APIs noted and questioned the behavior in <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250531105747/https://developers.facebook.com/community/threads/317050484803752/">forum</a> <a target="_blank" rel="nofollow" href="https://web.archive.org/web/20250531105711/https://developers.facebook.com/community/threads/937149104821259/">posts</a> at the time.</p>
<p>HTTP-based data transmission using this technique supposedly ended the following month, but other methods of transmission (WebSocket, WebRTC STUN (w/ SDP Munging), and WebRTC TURN (w/o SDP Munging)) were identified in subsequent months.</p>
<p>Presently, however, Meta's use of these techniques appears to have halted. According to the researchers, "As of June 3rd 7:45 CEST, Meta/Facebook Pixel script is no longer sending any packets or requests to localhost. The code responsible for sending the _fbp cookie has been almost completely removed."</p>
<p>Yandex's use of localhost-based tracking dates back to 2017, according to the researchers.</p>
<p><em>The Register</em> sought to ask Yandex media relations about the researchers' claims but our inquiry was bounced as spam.</p>
<p>The report authors note that their disclosure to Android browser vendors has led to several mitigations.</p>
<p>Chrome 137, which shipped May 26, 2025, includes countermeasures <a target="_blank" rel="nofollow" href="https://webrtc.googlesource.com/src.git/+/72d6d748ddbe5d7f63ba5f2dd1ce195a342c0a12">to block the SDP Munging</a> technique used by Meta Pixel, though these have only been made available to a subset of users participating in a gated field trial. A fix is currently being developed for Mozilla Firefox. Brave is unaffected as it <a target="_blank" rel="nofollow" href="https://brave.com/privacy-updates/27-localhost-permission/">requires consent for localhost</a> use. And DuckDuckGo has modified its blocklist to stop Yandex's scripts.</p>
<p>Beyond these, the authors suggest a Google <a target="_blank" rel="nofollow" href="https://github.com/explainers-by-googlers/local-network-access">proposal</a> to create a new "local network access" permission that could help mitigate localhost-based tracking in the future. A <a target="_blank" rel="nofollow" href="https://wicg.github.io/private-network-access/">prior proposal</a> along these lines ran into <a target="_blank" rel="nofollow" href="https://developer.chrome.com/blog/pna-on-hold">technical barriers</a>. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brain aging shows nonlinear transitions, suggesting a midlife "critical window" (218 pts)]]></title>
            <link>https://www.pnas.org/doi/10.1073/pnas.2416433122</link>
            <guid>44175905</guid>
            <pubDate>Tue, 03 Jun 2025 23:37:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pnas.org/doi/10.1073/pnas.2416433122">https://www.pnas.org/doi/10.1073/pnas.2416433122</a>, See on <a href="https://news.ycombinator.com/item?id=44175905">Hacker News</a></p>
Couldn't get https://www.pnas.org/doi/10.1073/pnas.2416433122: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Precious Plastic Is in Trouble (204 pts)]]></title>
            <link>https://www.preciousplastic.com//news/problems-in-precious-plastic</link>
            <guid>44175773</guid>
            <pubDate>Tue, 03 Jun 2025 23:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.preciousplastic.com//news/problems-in-precious-plastic">https://www.preciousplastic.com//news/problems-in-precious-plastic</a>, See on <a href="https://news.ycombinator.com/item?id=44175773">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2>is in trouble</h2></p><div><p>Hey world</p><p>This is a heavy message to send, but essential for the future of Precious Plastic. It will either make it or not. In this post I’ll give a detailed overview of all the current problems we have, how it got to this point and whats next. A short summarised video is below. No <em>need</em> to watch, it's all in the text.<br>‍</p></div><p><iframe src="https://www.youtube.com/embed/4gTd36cQLzY?rel=0&amp;controls=1&amp;autoplay=0&amp;mute=0&amp;start=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="" title="Precious Plastic is in trouble. Really"></iframe></p><p><strong>Our last big development<br>‍</strong>Lets start with our last big development. &nbsp;2020, when we released Version 4, this was our latest release. We worked about 1,5 year with over +100 people from around the world. We developed the first ‘Pro’ Machines, a Sheetpress, Starterkits, Business calculators, new moulds, products and more. Looking back this was quite a unique moment. A lot of passionate work was done by volunteers and everything was shared Open Source online for free. Here some of the things we made<br></p><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa486e30e592d1032dd32_v4.jpg 2004w" alt=""></p><p><img src="https://s11.gifyu.com/images/SGTIk.gif"></p><div><p>With a relatively small amount of money, we reached a global impact in 2023 of over 1100 organzations in 56 countries, who recycled 1.400.000KG Plastic, they generated together a revenue of +$3.7 Million, employed 530 people, works with 3.405 volunteers and built 1.175 machines. (And this is only from the workspaces who shared their data last year) Learn more about our impact <a href="https://www.preciousplastic.com/impact/2024" target="_blank">here</a>.<br>‍<strong><br>☝️This was the good part. Lets get into our problems</strong></p><p> <strong>How we work<br></strong>In order to understand our problems it’s important to know how Precious Plastic is developed since its unusual. We work in what we call Versions. Version 1 got released in 2013 and the latest one 4 years ago. The principle is, we develop a lot of new things, share them online for free. And then whoever was involved takes a holiday or goes off to something else. They really have to go because at that point we spend all our money. The workspace is empty, the work drops, nothing new is made, we wait. Up until now for some magical reason we always received a gift to continue moving forward. From winning awards, to getting a big workspace donated. Whenever we got enough resources we assembled a team and started developing again.. Each time the team and amount of work grew. Until the latest version, here the problems started.</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.984375px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart-p-3200.jpg 3200w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6cb2fc0a22da432f1f6_work%20done%20chart.jpg 4247w" alt=""></p><div><p><strong>When the Problems started<br>‍</strong>We worked in versions not because we wanted to, but because we had to. We share everything online for free because we believe recycling knowledge should be available for everyone. As a consequence we don’t generate enough income to pay a team all year around. But after Version 4 a small group of seven dedicated ambitious volunteers wanted to try and sustain Precious Plastic all year around. So we can continue development and have a bigger impact to reduce plastic waste. This by itself is a hard job but we also had some extra problems on the way</p><p>‍<strong>#1 No workspace<br>‍</strong>The team was ready to continue work. But just a few weeks later Covid-19 came to the world, but this wasn’t our main problem. Our problem was Chrome-6, a chemical the municipality found in the paint from the building that was applied 40 years ago. Which meant we had to leave the workspace fast, and the building was large, we had a lot of machines and items to sell, in a short amount of time, during lockdowns. This meant we had to sell many things below value since that period most people were looking to buy bread machines, not robot arms. After the exhausting/rushed job of leaving our workspace we could stay in the garage/shed in the house of one of the team members in France. It was nice we had a base to continue, but it was much smaller and temporary. It was quite a downgrade.</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.984375px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace-p-3200.jpg 3200w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa6f962c412ee92336560_workspace.jpg 3893w" alt=""></p><div><p><strong>#2 No business model<br>‍</strong>One of the main goals of this small team was trying to find a business model that would serve Precious Plastic’s mission, bring income to sustain a team and not compete with the rest of the community. The last one is difficult, because our most logical and common model would be to sell machines and moulds. There are not many Open Source Hardware projects like Precious Plastic in the world. And the ones that exist mostly sell their products. Arduino sells their circuit boards, Prusa sells 3d printers. However in our case we’re also building a global network of machine builders that can provide local recycling equipment. We didn't want to compete with our own community.</p><p>The plan was to do Projects or as we called them, Collabs. It meant to help others set up their projects. Sort of a consultancy. The team setup quite a few cool projects, from a refugee camp in a desert in Algeria to a big Sheetpress in Nigeria. And meanwhile released a few new machine drawings. The model somewhat worked, we continued development and could do meaningful work. However it was financially always tight and often didn’t bring in enough money to sustain the team (that was getting paid minimum Dutch wage). But what really broke it was the next problem</p><p>‍<strong>#3 Lawsuit<br>‍</strong>As the team was setting up projects we worked with different clients around the world. Working for clients was completely new for us and we're learning along the way. And one of the first projects we setup was in Manhattan, New York for a cosmetic company to recycle their packaging. We helped to set it up, got machines from a community member and local people ran it. However after a period of time an accident happened with someone using the machine, which was very unfortunate. And in the US, especially NY this means you need to get lawyers. What happened, who is responsible? Is it the company that hired us all, Precious Plastic (back then operating under One Army Entity) for organising it, was it a result of bad operational instructions, misuse of the machine or a fault in the machine from the community member? We analysed it and are convinced that we are not to blame. But we do not know what a judge is going to say. Meanwhile this has been going on for the last 2 years. Lots of paperwork and documents need to be filed with lawyers that charge up to $600/h, sending emails got painful. Being in a lawsuit in New York is very costly. On top of that we didn't have insurance, meaning we have to pay for it from our own tiny pockets.</p><p>‍<strong>#4 Software, heavily underestimated<br>‍</strong>During Version 4 we started developing our own Community Platform. It’s software that is the digital home of our community that helps members to document, share knowledge and find others to collaborate with. It’s developed in collaboration with our other projects and there is a lot more information about it here. Anyway this has been a massive project and the original complexity of it was underestimated. Took waaay more effort than we thought. In the recent years we’ve been hard at work to catch up and the platform got much more mature with many more features. But realistically this has been a hit on our online community since the ‘digital home’ wasn’t good enough to host everyone. We invested a lot in this so far and will continue to be a big project so please use the platform, give feedback so we can improve it and help us code it.</p><p>‍<strong>#5 Open Source community<br>‍</strong>At Precious Plastic we want to enable more people to recycle plastic. Plastic waste is a big global problem and needs many people collaborating in every corner of the world to fix it. That's why we give everything Open Source for free so everyone has access. On top of that a big part of Version 4 was to make sure that the people that start recycling workspaces can financially sustain themselves. Because If they can continue to recycle on a daily basis it means less plastic waste. We want all those hard working workspaces to succeed and provide business plans, calculators and instruction to help them. A few years later this resulted in hundreds of workspaces around the world that started a business who manage to recycle on a daily basis, which is great.&nbsp;</p><p>We went all-in on giving. And believe(d?) that sharing Open Source will bring contributions back one way or another. Contributions to support the Precious Plastic Community can be made in various ways.&nbsp;From a financial donation once a recycle-business is profitable, to giving credit or sharing back their knowledge. And many members do contribute something back which is great. However we’ve also been observing quite some established organisations that take more than they give, building business around Precious Plastic but not contributing anything back. It’s allowed, since it’s all Open-Source. But the mentality of only taking things and not contributing will eventually kill a community-driven project like this.&nbsp;</p><p>‍<strong>#6 It is bad designed<br>‍</strong>We don’t blame those for not contributing enough back. We see this as a fault on us. The project wasn’t designed to have a healthy financial model and relation with the community. We were always fully focussed on giving to the community, not us being a financially sustainable organisation. Funny example of this is the recent <a href="https://pposf.preciousplastic.com/" target="_blank">PPOSF</a> (Precious Plastic Open Source Fund). We received a €100K donation. Which was amazing, but we decided to give it all to the community so they can continue developing their projects. Not to sustain the organisation itself. You could see this as a humble move from us, give it to the community. But it isn’t, it’s ineffective, because now we have to bother you with our problems. Ideally we don’t have to do this and you don’t have to worry about us.&nbsp;</p><p><strong>#7 No long term team<br>‍</strong>As you can imagine all of the above problems make it hard for a team member to have a long term perspective in Precious Plastic. Even though the team has been very small, effective and works with many volunteers it has continued to be a struggle to pay everyone every month without worrying. Over time this brings lots of stress and uncertainty, especially if the team members by themselves grow up and need more stability in life.&nbsp;</p><p>‍<strong>Our current setup<br>‍</strong>Precious Plastic is a non-profit for public good (ANBI) setup in the Netherlands. <br>So what does our team and community look like? Here is a funny way to look at it:<br>‍<br><strong>Precious Plastic Community</strong><br>⬥+ 1000 workspaces around the world<br>⬥530 people employed, 3000 volunteers<br>⬥Totalling + $3.7 Million Revenue last year</p><p><strong>Precious Plastic Organisation</strong><br>⬥3 full-time people in the team<br>⬥Quarterly running costs €30K<br>⬥6 Months before out of money<br>⬥No workspace. Everyone is fully remote</p><p>As you can see not many team members to manage a large community. There are many areas we should work on but simply cannot. The team spends most of its time making sure just the basics are up and running and community members can continue to recycle and use our tools. And even with this small effective team we only have enough money to sustain for the coming 6 months. The future doesn’t look good.<br>‍</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.984375px, (max-width: 1919px) 71vw, 799.984375px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa8bb671bebd39224838b_next%20options1.jpg 2339w" alt=""></p><div><p><strong>What is next?<br>‍</strong>I’ve been thinking about this. What should Precious Plastic do?&nbsp;<br>‍<strong>1: ☠️ Let Precious Plastic Die:</strong> It build a global community of recyclers, it achieved its mission and that’s it. We learned valuable lessons and the community will probably stay online for a bit but would slowly fade away.<br>‍<strong>2: 💪 Push it to the next level:</strong> There is still lots of plastic waste around the world. We need way more people recycling and R&amp;D on other plastic types. The community needs to grow.</p><p>To be honest I personally could be at peace with both of these directions. It’s amazing what Precious Plastic developed with a relatively small budget and passionate people volunteering their time. Many lessons learned. But an Open Source project like this needs many people caring for it in order to stay alive. If there isn't a large supportive community it will naturally die. It goes beyond the power of an individual. </p><p>That said, what many people might not realise, is that we would waste an unused potential we can currently unlock. We spend years building a global community of recyclers. Rolling out new improved tools has a much higher impact than before, we can reach the right people in many areas in the world. Plus we have clear visibility on our problems and are after all these years very close to having a healthy organisational cycle, see the chart below. All of this makes me think about giving it one last push to finish it. Version 5.&nbsp;</p></div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa82f77198680abac2722_circle.jpg 2841w" alt=""></p><p><strong>What is Version 5?</strong><br>We have many ideas for a Version 5 and would love to work on this. But as you can see from this long text (thanks for reading all the way) we are in a big dip and have some big problems. Whatever we need to develop to get out of this needs to serve the community + the organisation itself. It will be made in a way that it can financially sustain itself afterwards. Something we never took into account. It will mean rebuilding things from the ground up, which requires much more help and resources than before. It would be the biggest thing we ever made as you can see below in the graph. Our team is small, our community is large. We can only do this if people like you are willing to support and help out.<br></p><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next.jpg" loading="lazy" sizes="(max-width: 479px) 96vw, (max-width: 767px) 95vw, (max-width: 991px) 699.9921875px, (max-width: 1919px) 71vw, 799.9921875px" srcset="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-500.jpg 500w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-800.jpg 800w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-1080.jpg 1080w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-1600.jpg 1600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-2000.jpg 2000w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-2600.jpg 2600w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next-p-3200.jpg 3200w, https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/673fa81b44c7ec88e59ad907_next.jpg 5389w" alt=""></p><div><p><strong>How can you help? <br></strong>The first step is gathering support from the community. If not ones cares about Precious Plastic there is no reason for us to continue to work on it. You can do this by "showing your support". Next we need to find resources to develop the next phase of the project, so you can help us "raise funds for V5".<strong></strong></p></div><div data-hover="false" data-delay="0"><div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/674c67fa11910bf4b8d514c0_support.png" loading="lazy" alt=""></p><p>Show your support</p></div><nav><div data-hover="false" data-delay="0"><div><p>Subscribe to our Youtube Channel</p></div><nav><div><p>The video you just watched is on the One Army Channel. However, Precious Plastic now has its own channel, which not many people know about. A big boost to our channel helps with the YouTube algorithm, allowing us to share more videos in the future.&nbsp;</p><p>‍<a href="https://www.youtube.com/@Precious_PlasticHQ/?sub_confirmation=1" target="_blank">Click here</a> to subscribe.</p></div></nav></div><div data-hover="false" data-delay="0"><nav><p>We’re focused on recycling more plastic and making a real impact. Your support helps us drive this mission forward and generate actual income for our team.&nbsp;If you want to make a difference, <a href="https://www.preciousplastic.com/support" target="_blank">click here</a> to donate.</p></nav></div><div data-hover="false" data-delay="0"><nav><p><a href="https://www.patreon.com/one_army/membership" target="_blank">Join us on Patreon</a> to support our mission monthly. Your contribution helps create a stable income for our work. Plus, you'll get exclusive updates on our progress.</p></nav></div><div data-hover="false" data-delay="0"><nav><div><p>If you're an individual, <a href="https://bazar.preciousplastic.com/products/" target="_blank">buy recycled plastic products</a> on the Bazar, like carabiners, keychains, earrings, rulers, phone cases, anything really. And if you're a workspace looking to expand, consider buying machines on the Bazar. Remember, 5% of every sale goes to Precious Plastic, which directly supports small scale plastic recycling.</p><p>Sellers, this is your chance to contribute—sell your items on the Bazar. Your sales make a big difference; that 5% income is used to improve the online marketplace itself. Avoiding the need for all the individual workspaces having to setup their own webshops. Together, we can create one strong marketplace that benefits us all.</p><p>‍</p></div></nav></div><div data-hover="false" data-delay="0"><nav><p>The lawsuit in New York is still ongoing. We are currently facing significant costs and need pro-bono assistance from lawyers in the Netherlands or the US to help us navigate this process. If you can assist us, please send us an email to <a href="mailto:hello@preciousplastic.com?subject=Legal%20help">hello@preciousplastic.com</a></p></nav></div><div data-hover="false" data-delay="0"><nav><div><p>Our Community Platform is a big software project, and honestly, it's more complex than we initially thought. Building the infrastructure to host a large global community. We're doing it all open source so others can use it and help out. If you're interested in helping build this, we could really use your skills.Check out the details on <a href="https://github.com/ONEARMY/community-platform" target="_blank">GitHub</a>.</p><p>⭐️ For an easy help&gt; Giving a start to the repository is useful to attract more contributors!</p></div></nav></div><div data-hover="false" data-delay="0"><div><p>Use the Community Platform</p></div><nav><div><p>Interaction on the Community Platform is essential, we're building the home for our online community. By answering Questions and uploading knowledge—such as How-tos, Research and replying to comments—you contribute to a collective resource that reflects the global activity of the community. </p><p>All this activity helps gather valuable feedback that steers our ongoing improvements, we release weekly fixes based on user insights.</p><p>Start by helping out to answer some questions <a href="https://community.preciousplastic.com/questions" target="_blank">here</a>.</p></div></nav></div></nav></div><div data-hover="false" data-delay="0"><div><p><img src="https://cdn.prod.website-files.com/5e004b03e5da773c54823bfb/674c6f45d80db1b0b342e19a_money.png" loading="lazy" alt=""></p><p>Help us raise funds for V5</p></div><nav><div data-hover="false" data-delay="0"><nav><div><p>We need your help to locate grants. There are numerous grants available, but with a small team, it’s tough to find them all. Let’s crowdsource our efforts and share what we discover. If you have any information, please contribute by adding it <a href="https://community.preciousplastic.com/questions/who-can-help-us-to-find-grants-for-v5" target="_blank">here</a>.</p><p>And if you’re a grant writer that wants to help, send us a mail: <a href="mailto:hello@preciousplastic.com?subject=Help%20with%20grants">hello@preciousplastic.com</a></p></div></nav></div><div data-hover="false" data-delay="0"><nav><div><p>If you can make a large donation, it would be the biggest support we could receive right now. This help would allow us to stay on track in the short term, enabling us to focus on long-term goals. Our aim is to become independent of donors and self-sustaining. Additionally, your contribution could be tax-deductible as we are a Non-Profit (ANBI) from the Netherlands. <br>Our 3 year vision is to triple the impact of small-scale plastic recycling globally by releasing Version 5 with a total budget of 2.1 million euros.</p><p>If you're interested, send us an email to <a href="mailto:hello@preciousplastic.com?subject=Precious%20Plastic%20Donation">hello@preciousplastic.com</a></p></div></nav></div><div data-hover="false" data-delay="0"><nav><p>If you want to collaborate with us, we welcome partnerships. Whether it's a video, sponsorship of Version 5, or featuring your logo on our website, we are open to various forms of collaboration—the bigger the initiative, the better. For inquiries, please send an email to <a href="mailto:hello@preciousplastic.com?subject=Collaborate">hello@preciousplastic.com</a> or fill the form <a href="https://www.preciousplastic.com/custom-solutions" target="_blank">here</a>.</p></nav></div><div data-hover="false" data-delay="0"><nav><div><p>If you want, you can send us crypto. We’re easy with crypto and love receiving it. Here are our wallet addresses:&nbsp;<br><strong>Bitcoin</strong>: 3NxqZ3xW8PEPtbCrDHPrL7srjhN4U4iZwp<br><strong>Ethereum</strong>: 0x28CDdE98313a9ef878076f88d3AEFa3714185123<br>Tether (USDT): 0x65f9aB8B37D98F8D334AB97C74BF160249f8298D</p><p>If you need another one, or want to double check before sending.<br>Send us an email at <a href="mailto:hello@preciousplastic.com?subject=Crypto%20Donation">hello@preciousplastic.com</a></p></div></nav></div></nav></div><div><p>If enough action is taken we can move forward and will share a more detailed plan for Version 5.<br>If not, we are willing to accept that the project will just die.<br>We will keep you posted with updates.<br>‍<br>Thank you community</p><p>Dave</p><p>*It’s a complex problem to explain spanned over multiple years. If there are ideas, questions or comments go <a href="https://community.preciousplastic.com/questions/questions-on-the-article-with-our-problems" target="_blank">here</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Ephe – A minimalist open-source Markdown paper for today (105 pts)]]></title>
            <link>https://github.com/unvalley/ephe</link>
            <guid>44175557</guid>
            <pubDate>Tue, 03 Jun 2025 22:41:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/unvalley/ephe">https://github.com/unvalley/ephe</a>, See on <a href="https://news.ycombinator.com/item?id=44175557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <nav aria-label="Global">
            <ul>


                <li>
      

      <div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
          <p>
            GitHub Copilot
          </p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_models&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_models_link_product_navbar&quot;}" href="https://github.com/features/models">
      
      <div>
          <p>
            GitHub Models
              <span>
                New
              </span>
          </p><p>
        Manage and compare prompts
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
          <p>
            GitHub Advanced Security
          </p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
          <p>
            Actions
          </p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
          <p>
            Codespaces
          </p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                </ul>
              </div>
          <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
          <p>
            Issues
          </p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
          <p>
            Code Review
          </p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
          <p>
            Discussions
          </p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
          <p>
            Code Search
          </p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
          

      </div>
</li>


                <li>
      

      
</li>


                <li>
      

      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      

      <div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
          <p>
            GitHub Sponsors
          </p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
          <p>
            The ReadME Project
          </p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      

      <div>

                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
          <p>
            Enterprise platform
          </p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:unvalley/ephe" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="XFrKT3G01DJsKUpu5mMdaZfi9Z9d5c7QqHiaLJn05KsWZ_NavEm4m590ZAsiYrsoqCRuNrAjb31wsVhtwR4bug" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="unvalley/ephe" data-current-org="" data-current-owner="unvalley" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=unvalley%2Fephe" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/unvalley/ephe&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="41d4782483eb3f1535a96863a9f3280c4bf9773f7897120b9b2f0c8c363da4b7" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a></p><p>
    <react-partial-anchor>
      <tool-tip id="tooltip-ba9e85f9-ced5-4945-b4ac-1c9a79fcbea7" for="icon-button-182d2309-5266-498f-9e19-e035d8196c09" popover="manual" data-direction="s" data-type="label" data-view-component="true">Appearance settings</tool-tip>

      <template data-target="react-partial-anchor.template">
        <link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/primer-react.b5e8a54636271e908e27.module.css">
<link crossorigin="anonymous" media="all" rel="stylesheet" href="https://github.githubassets.com/assets/appearance-settings.8edda24384d5c8bf99ee.module.css">

<react-partial partial-name="appearance-settings" data-ssr="false" data-attempted-ssr="false">
  
  <script type="application/json" data-target="react-partial.embeddedData">{"props":{}}</script>
  <div data-target="react-partial.reactRoot"></div>
</react-partial>

      </template>
    </react-partial-anchor>
  </p>

          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Deep learning gets the glory, deep fact checking gets ignored (437 pts)]]></title>
            <link>https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html</link>
            <guid>44174965</guid>
            <pubDate>Tue, 03 Jun 2025 21:31:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html">https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=44174965">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">




<p>Deep learning is glamorous and highly rewarded. If you train and evaluate a Transformer (a state-of-the-art language model) on a dataset of 22 million enzymes and then use it to predict the function of 450 unknown enzymes, you can publish your results in Nature (a very well-regarded publication). Your paper will be viewed 22,000 times and will be in the top 5% of all research outputs scored by Altmetric (a rating of how much attention online articles receive).</p>
<p>However, if you do the painstaking work of combing through someone else’s published work, and discovering that they are riddled with serious errors, including hundreds of incorrect predictions, you can post a pre-print to bioRxiv that will not receive even a fraction of the citations or views of the original. In fact, this is exactly what happened in the case of these two papers:</p>
<ul>
<li><a href="https://www.nature.com/articles/s41467-023-43216-z">Functional annotation of enzyme-encoding genes using deep learning with transformer layers | Nature Communications</a></li>
<li><a href="https://www.biorxiv.org/content/10.1101/2024.07.01.601547v2.full">Limitations of Current Machine-Learning Models in Predicting Enzymatic Functions for Uncharacterized Proteins | bioRxiv</a></li>
</ul>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/altmetric.jpg"></p>
<figcaption>A Tale of two Altmetric Scores</figcaption>
</figure>
</div>
<p>This pair of papers on enzyme function prediction make for a fascinating case study on the limits of AI in biology and the harms of current publishing incentives. I will walk through some of the details below, although I encourage you to read the papers for yourself. This contrast is a stark reminder of how hard it can be to evaluate the legitimacy of AI results without deep domain expertise.</p>
<section id="the-problem-of-determining-enzyme-function">
<h2 data-anchor-id="the-problem-of-determining-enzyme-function">The Problem of Determining Enzyme Function</h2>
<p>Enzymes are what catalyze reactions, so they are crucial for making things happen in living organisms. Enzyme Commission (EC) numbers provide a hierarchical classification system for thousands of different functions. Given a sequence of amino acids (the building blocks of all proteins, including enzymes), can you predict what the EC number (and thus, the function) is? This seems like a problem that is custom-made for machine learning, with clearly defined inputs and outputs. Moreover, there is a rich dataset available, with over 22 million enzymes and their EC numbers listed in the online database UniProt.</p>
</section>
<section id="an-approach-with-transformers-ai-model">
<h2 data-anchor-id="an-approach-with-transformers-ai-model">An Approach with Transformers (AI model)</h2>
<p>A research paper used a transformer deep learning model to predict the functions of enzymes with previously unknown functions. It seemed like a good paper! The authors used a reasonable, well-regarded neural network architecture (two transformer encoders, two convolutional layers, and a linear layer) that had been adopted from BERT. They looked at regions with high attention to confirm that these were biologically significant, which suggests that the model had learned underlying meaning and provided interpretability. They used a standard training, validation, and test split on a dataset with millions of entries. The researchers then applied the model to a dataset where no “ground truth” was known to make ~450 novel predictions. For these novel predictions, they randomly selected three to test <em>in vitro</em> and confirmed that the predictions were accurate.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/kim-fig1a-4.jpg"></p>
<figcaption>A transformer model, shown on the left, was used to predict Enzyme Commission numbers for uncharacterized enzymes in E. coli. Three of these were tested in vitro (Fig 1a and Fig 4 from Kim, et al.)</figcaption>
</figure>
</div>
</section>
<section id="the-errors">
<h2 data-anchor-id="the-errors">The Errors</h2>
<p>The Transformer model in the Nature paper made hundreds of “novel” predictions that are almost certainly erroneous. The paper had followed a standard methodology of evaluating performance on a held-out test set, and did quite well on that (although later investigation suggests there may have been <a href="https://www.kaggle.com/code/alexisbcook/data-leakage">data leakage</a>). The results claimed for enzymes where no ground truth is known were full of errors.</p>
<p>For instance, the gene E. coli YjhQ was predicted to be a mycothiol synthase, but mycothiol is not synthesized by E. coli at all! The gene yciO, which evolved from the gene TsaC, had already been shown a decade earlier <em>in vivo</em> to not have the same function as TsaC, yet the Nature paper concluded it did have the same function.</p>
<p>Of the 450 “novel” results given in the Nature paper, 135 of these results were not novel at all; they were already listed in the online database UniProt. Another 148 showed unreasonably high levels of repetition, with the same very specific enzyme functions reappearing up to 12 times for genes of <em>E. coli</em>, which biologically implausible.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/de-crecy-fig5.jpg"></p>
<figcaption>Most of the “novel” results from the transformer paper were either not novel, unusually repetitious, or incorrect paralogs (Fig 5 from de Crecy, et al.)</figcaption>
</figure>
</div>
</section>
<section id="the-microbiology-detective">
<h2 data-anchor-id="the-microbiology-detective">The Microbiology Detective</h2>
<p>How did these errors come to light? After the model had been trained, validated, and evaluated on a dataset involving millions of entries, it was used to make ~450 novel predictions, and three of these were tested in vitro. It just so happens that one of the enzymes selected for in vitro testing, yciO, had already been studied extensively over a decade earlier by Dr.&nbsp;de Crécy-Lagard. When Dr.&nbsp;de Crécy-Lagard read that deep learning had predicted that yciO had the same function of another gene, TsaC, she knew from her long years in the lab that this was incorrect. Her previous research had shown that the TsaC gene is essential in <em>E. coli</em> even if yciO is present in the same genome and even when yciO gene is overexpressed. Moreover, the yciO activity reported by Kim et al.&nbsp;is more than four orders of magnitude (i.e.&nbsp;10,000 times) weaker than that of TsaC. All this suggests that yciO does NOT serve the same key function as TsaC.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/de-crecy-fig7.jpg"></p>
<figcaption>Two enzymes with a common evolutionary ancestor, but different functions (Fig 7 from de Crecy, et al.)</figcaption>
</figure>
</div>
<p>YciO and TsaC do have structural similarities, and YciO evolved from an ancestor of TsaC. Decades of research on protein and enzyme evolution have shown that new functions often evolve via duplication of an existing gene, followed by diversification of its function. This poses a common pitfall in determining enzyme function, because the genes will have many similarities with the ones they duplicated and then diversified from.</p>
<p>Thus, looking at structural similarities is only one type of evidence for considering enzyme function. It is also crucial to look at other types of evidence, such as neighborhood context of the genes, substrate docking, gene co-occurrence in metabolic pathways, and other features of the enzymes.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/de-crecy-fig2.jpg"></p>
<figcaption>It is important to look at multiple types of evidence when classifying enzyme function (Fig 2 from de Crecy, et al.)</figcaption>
</figure>
</div>
</section>
<section id="hundreds-of-likely-erroneous-results">
<h2 data-anchor-id="hundreds-of-likely-erroneous-results">Hundreds of Likely Erroneous Results</h2>
<p>Spotting this one error inspired de Crécy-Lagard and her co-authors to take a closer look at all of the enzymes found to have novel results in the Kim, et al, paper. They found that 135 of these results were already listed in the online database used to build the training set and thus not actually novel. An additional 148 of the results contained a very high level of repetition, with the same highly specific functions reappearing up to 12 times. Biases, data imbalance, lack of relevant features, architectural limitations, or poor uncertainty calibration can all lead models to “force” the most common labels from the training data.</p>
<p>Other examples were proven wrong via biological context or a literature search. For instance, the gene YjhQ was predicted to be a mycothiol synthase but mycothiol is not synthesized by <em>E. coli</em>. YrhB was predicted to synthesize a particular compound, which was already predicted to be synthesized by the enzyme QueD. A form of <em>E. coli</em> with a QueD mutant was unable to synthesize the compound, showing that this is not in fact the function of YrhB.</p>
</section>
<section id="rethinking-enzyme-classification-and-true-unknowns">
<h2 data-anchor-id="rethinking-enzyme-classification-and-true-unknowns">Rethinking Enzyme Classification and “True Unknowns”</h2>
<p>Identifying enzyme function actually consists of two quite different problems which are commonly conflated:</p>
<ul>
<li>propagating known function labels to enzymes in the same functional family</li>
<li>discovering truly unknown functions</li>
</ul>
<p>The authors of the second paper observe, “By design, supervised ML-models cannot be used to predict the function of true unknowns.” While machine learning can be useful for propagating known functions to additional enzymes, there are many types of errors that can occur: including failing to propagate labels when they should, propagating labels when they should not, curation mistakes, and experimental mistakes. Unfortunately, erroneous functions are being entered into key online databases such as UniProt, and this incorrect data may be further propagated if it is used to train prediction models. This is a problem that increases over time.</p>
</section>
<section id="need-for-domain-expertise">
<h2 data-anchor-id="need-for-domain-expertise">Need for Domain Expertise</h2>
<p>It is not news that AI work will be more highly rewarded and supported than work that closely inspects the underlying data and integrates deep domain knowledge. The aptly titled <a href="https://research.google/pubs/everyone-wants-to-do-the-model-work-not-the-data-work-data-cascades-in-high-stakes-ai/">“Everyone Wants to do the Model Work, not the Data Work”</a> paper involving dozens of machine learning practitioners working on high-stakes AI projects and found that inadequate-application domain expertise was one of a few key causes of catastrophic failures.</p>
<div>
<figure>
<p><img src="https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/sambasivan-square.jpg"></p>
<figcaption>Sources of cascading failures in machine learning systems (Fig 1 from Sambasivan, et al.)</figcaption>
</figure>
</div>
<p>These papers also serve as a reminder of how challenging (or even impossible) it can be to evaluate AI claims in work outside our own area of expertise. I am not a domain expert in the enzyme functions of <em>E. coli</em>. And for most deep learning papers I read, domain experts have not gone through the results with a fine-tooth comb inspecting the quality of the output. How many other seemingly-impressive papers would not stand up to scrutiny? The work of checking hundreds of enzyme predictions is less glamorous than the work of building the AI model that generated them, yet it is even more important. How can we better incentivize this type of error-checking research?</p>
<p>At a time when funding is being slashed, I believe we should be doing the opposite and investing even more into a range of scientific and biomedical research, from a variety of angles. And we need to push back on an incentive system that is disproportionately focused on flashy AI solutions at the expense of quality results.</p>


</section>

<p><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p></main> <!-- /main -->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A deep dive into self-improving AI and the Darwin-Gödel Machine (135 pts)]]></title>
            <link>https://richardcsuwandi.github.io/blog/2025/dgm/</link>
            <guid>44174856</guid>
            <pubDate>Tue, 03 Jun 2025 21:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://richardcsuwandi.github.io/blog/2025/dgm/">https://richardcsuwandi.github.io/blog/2025/dgm/</a>, See on <a href="https://news.ycombinator.com/item?id=44174856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <d-contents> <nav> <h3>Contents</h3>   <ul> <li> <a href="#how-dgm-works">How DGM Works</a> </li> <li> <a href="#can-dgm-really-improve-itself">Can DGM Really Improve Itself?</a> </li> <li> <a href="#comparison-with-alphaevolve">Comparison with AlphaEvolve</a> </li> <li> <a href="#can-we-trust-a-self-improving-ai">Can we trust a self-improving AI?</a> </li> </ul>  </nav> </d-contents> <p>Most AI systems today are stuck in a “cage” designed by humans. They rely on fixed architectures crafted by engineers and lack the ability to evolve autonomously over time. This is the <a href="https://en.wikipedia.org/wiki/Achilles%27_heel" rel="external nofollow noopener" target="_blank">Achilles heel</a> of modern AI — like a car, no matter how well the engine is tuned and how skilled the driver is, it cannot change its body structure or engine type to adapt to a new track on its own. But what if AI could learn and improve its own capabilities without human intervention? In this post, we will dive into the concept of self-improving systems and a recent effort towards building one.</p> <h2 id="learning-to-learn">Learning to Learn</h2> <p>The idea of building systems that can improve themselves brings us to the concept of <a href="https://people.idsia.ch/~juergen/metalearning.html" rel="external nofollow noopener" target="_blank">meta-learning</a>, or “learning to learn” <d-cite key="thrun1998learning"></d-cite>, which aims to create systems that not only solve problems but also evolve their problem-solving strategies over time. One of the most ambitious efforts in this direction is the Gödel Machine<d-cite key="schmidhuber2003godel"></d-cite>, proposed by Jürgen Schmidhuber decades ago and was named after the famous mathematician <a href="https://en.wikipedia.org/wiki/Kurt_G%C3%B6del" rel="external nofollow noopener" target="_blank">Kurt Gödel</a>. A Gödel Machine is a hypothetical self-improving AI system that optimally solves problems by recursively rewriting its own code when it can mathematically prove a better strategy. It represents the ultimate form of self-awareness in AI, an agent that can reason about its own limitations and modify itself accordingly.</p> <p><img src="https://richardcsuwandi.github.io/assets/img/godel.jpg" alt="Overview of a Gödel machine" width="80%"></p> <p><strong>Figure 1.</strong> Gödel machine is a hypothetical self-improving computer program that solves problems in an optimal way. It uses a recursive self-improvement protocol in which it rewrites its own code when it can prove the new code provides a better strategy.</p> <p>While this idea is interesting, formally proving whether a code modification of a complex AI system is <em>absolutely beneficial</em> is almost an impossible task without restrictive assumptions. This part stems from the inherent difficulty revealed by the <a href="https://en.wikipedia.org/wiki/Halting_problem" rel="external nofollow noopener" target="_blank">Halting Problem</a> and <a href="https://en.wikipedia.org/wiki/Rice%27s_theorem" rel="external nofollow noopener" target="_blank">Rice’s Theorem</a> in computational theory, and is also related to the inherent limitations of the logical system implied by <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems" rel="external nofollow noopener" target="_blank">Gödel’s incompleteness theorem</a>. These theoretical constraints make it nearly impossible to predict the complete impact of code changes without making restrictive assumptions. To illustrate this, consider a simple analogy: just as you cannot guarantee that a new software update will improve your computer’s performance without actually running it, an AI system faces an even greater challenge in predicting the long-term consequences of modifying its own complex codebase.</p> <h2 id="darwin-gödel-machine">Darwin-Gödel Machine</h2> <p>To “relax” the requirement of formal proof, a recent work by proposed the <strong>Darwin-Gödel Machine (DGM)</strong><d-cite key="zhang2025darwingodelmachineopenended"></d-cite>, which combines the Darwinian evolution and Gödelian self-improvement. Essentially, DGM abandoned the pursuit of a rigorous mathematical proof and embraced a more pragmatic way that is closer to the essence of life evolution through empirical validation. As the authors put it,</p> <blockquote> <p>We do not require formal proof, but empirical verification of self-modification based on benchmark testing, so that the system can improve and explore based on the observed results.</p> </blockquote> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm.png" alt="Overview of the DGM" width="80%"></p> <p><strong>Figure 2.</strong> The Darwin-Gödel Machine (DGM) is a self-improving AI system that optimizes its own problem-solving strategy through a combination of Darwinian evolution and Gödelian self-improvement.</p> <p>The core idea behind DGM is to let the AI agent iteratively modify its own code<d-footnote>More precisely, the metacode that controls its behavior and ability</d-footnote>, and then put these modified new versions into the actual test environment (e.g., coding benchmarks) to judge whether this modification is good by observing its performance. If the modification is good, it will be retained and may become the basis for further evolution in the future; if the modification is bad, it will be eliminated.</p> <h3 id="how-dgm-works">How DGM Works</h3> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-animation.gif" alt="Animation of the DGM process" width="80%"></p> <p><strong>Figure 3.</strong> Animation showing how DGM iteratively builds a growing archive of agents by harnessing the principles of open-ended exploration. New agents are created and scored by interleaving self-modification with downstream task evaluation.</p> <p>The general workflow of DGM is as follows:</p> <ol> <li> <p><strong>Initialization:</strong> Evolution begins with one or a few basic coding agents, so-called the “seeds” of intelligence. These initial agents may possess only minimal functionalities, such as executing bash commands or editing entire files. DGM maintains an “archive of agents”, which functions like a biological “gene bank.” This archive preserves all previously generated agents, regardless of their performance level, ensuring that no potentially valuable variation is permanently lost.</p> </li> <li> <p><strong>Sampling:</strong> DGM selects one or more parent agents from the archive to generate new child agent. The selection mechanism does not focus solely on top performers but instead allows every agent a chance to be chosen. While higher-performing agents are more likely to be selected, DGM also encourages exploration by giving “less successful agents”<d-footnote>Those that might contain novel or unconventional ideas</d-footnote> an opportunity to contribute to future generations.</p> </li> <li> <strong>Reproduction:</strong> Once the parents are selected, DGM performs modifications to generate a new child agent. These changes occur at the source code level and can include: <ul> <li> <em>Enhancement of existing tools</em>, for example, upgrading a file-editing tool that replaces entire files into one capable of precise string replacement.</li> <li> <em>Addition of new tools or workflows</em>, such as integrating a static code analysis tool or designing a “think–act–observe” loop.</li> <li> <em>Improvement of problem-solving strategies</em>, for instance, refining how the agent prompts the base model or managing long-context code more effectively.</li> <li> <em>Introduction of collaboration mechanisms</em>, like having an agent’s code reviewed by another before execution.</li> </ul> </li> <li> <p><strong>Natural Selection:</strong> The newly generated child agent is not automatically accepted into the “elite pool” but must prove its worth through rigorous testing. Each agent’s performance, such as the percentage of successfully solved problems, is quantitatively scored and used to select the best agents.</p> </li> <li> <strong>Tree Formation:</strong> If a child agent outperforms its parent or meets certain quality thresholds, it is added to the archive and becomes a new node in the evolutionary tree. This process repeats iteratively, creating a growing structure of diverse, high-quality agents. Importantly, DGM enables parallel exploration of many different paths in the search space, promoting open-ended discovery and avoiding premature convergence to local optima.</li> </ol> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-conceptual.png" alt="Workflow of DGM" width="100%"></p> <p><strong>Figure 4</strong> DGM iteratively builds a growing intelligent archive by intertwining self-modification with downstream task evaluation. The intelligent body in the archive is selected for self-modification through open exploration.</p>  <p>The paper provides a concrete example of the above principle in action. In the SWE-bench experiment, the performance of newly generated agents showed temporary declines in the 4th and 56th iterations. While traditional hill-climbing methods would abandon these seemingly “regressive paths”, DGM’s open exploration mechanism allows continued exploration. This persistence paid off as by the 70th iteration, the system had created new agents that surpassed all their predecessors, demonstrating the value of maintaining diverse evolutionary paths even when they temporarily appear less promising.</p> <h3 id="can-dgm-really-improve-itself">Can DGM Really Improve Itself?</h3> <p>In the paper, the authors evaluated DGM on two challenging benchmarks:</p> <ol> <li> <p><strong>SWE-bench:</strong> A widely-used benchmark that tests agents’ ability to resolve real-world GitHub issues<d-cite key="jimenez2024swe"></d-cite> . DGM showed impressive progress, improving its performance from 20.0% to 50.0% through self-modification.</p> </li> <li> <p><strong>Polyglot</strong>: A <a href="https://aider.chat/2024/12/21/polyglot.html" rel="external nofollow noopener" target="_blank">multi-language coding benchmark</a> containing coding problems in C++, Go, Java, JavaScript, Python and Rust. DGM achieved even more dramatic improvement, jumping from an initial 14.2% to 30.7% success rate, far surpassing the representative hand-designed agent by <a href="https://aider.chat/" rel="external nofollow noopener" target="_blank">Aider</a>.</p> </li> </ol> <p>The impressive performance improvements demonstrate DGM’s fundamental ability to enhance itself through self-modification. Through ablation studies, the authors identified two key factors driving DGM’s success. First, self-modification proved crucial, as when disabled (<strong>DGM w/o Self-improve</strong>), the performance declined substantially, showing that the ability to modify its own code is essential for accelerated learning. Second, the open-ended exploration approach was vital, as removing the Darwinian evolution-inspired search mechanism (<strong>DGM w/o Open-ended exploration</strong>), which maintains an archive of diverse solutions and enables parallel exploration of multiple paths, resulted in lower performance.</p> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-self-improve.png" alt="Performance of DGM on SWE-bench and Polyglot" width="100%"></p> <p><strong>Figure 5</strong> Self-improvement and open-ended exploration enable the DGM to continue making progress and improve its performance. The DGM automatically discovers increasingly better coding agents and performs better on both SWE-bench (Left) and Polyglot (Right).</p> <h3 id="comparison-with-alphaevolve">Comparison with AlphaEvolve</h3> <p>In parallel, AlphaEvolve<d-cite key="deepmind2025alphaevolve"></d-cite>, which is developed by Google DeepMind, also demonstrates another powerful path forward. AlphaEvolve pairs the creative problem-solving capabilities of Google’s Gemini models with automated evaluators in an evolutionary framework. It has already demonstrated significant real-world impact across multiple domains, such as:</p> <ul> <li> <strong>Data center efficiency:</strong> AlphaEvolve discovered a simple yet highly effective heuristic for Google’s <a href="https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/" rel="external nofollow noopener" target="_blank">Borg</a> cluster management system, continuously recovering 0.7% of Google’s worldwide compute resources.</li> <li> <strong>AI acceleration:</strong> It achieved a 23% speedup in Gemini’s architecture’s vital <a href="https://docs.jax.dev/en/latest/pallas/index.html" rel="external nofollow noopener" target="_blank">kernel</a> by finding more efficient ways to divide large matrix multiplication operations, resulting in a 1% reduction in overall training time.</li> <li> <strong>Mathematical breakthroughs:</strong> Most notably, it discovered an algorithm for multiplying 4x4 complex-valued matrices using just 48 scalar multiplications, surpassing <a href="https://en.wikipedia.org/wiki/Strassen_algorithm" rel="external nofollow noopener" target="_blank">Strassen’s 1969 algorithm</a>, and advanced the 300-year-old <a href="https://en.wikipedia.org/wiki/Kissing_number_problem" rel="external nofollow noopener" target="_blank">kissing number problem</a> by establishing a new lower bound in 11 dimensions.</li> </ul>  <p>While both systems adopt a similar evolutionary framework, their scopes and methodologies differ in the following ways:</p> <table> <thead> <tr> <th>Feature</th> <th>AlphaEvolve</th> <th>DGM</th> </tr> </thead> <tbody> <tr> <td>Focus</td> <td>Evolving functions and codebases</td> <td>Evolving the agent itself</td> </tr> <tr> <td>Level of Innovation</td> <td>Algorithmic level</td> <td>Agent-level (toolset, methodology)</td> </tr> <tr> <td>Role of LLM</td> <td>LLM acts as “genetic operators” to modify algorithms</td> <td>LLM serves as the “brain” to evolve itself with better tools and strategies</td> </tr> <tr> <td>Evaluation</td> <td>Well-defined problems with automated evaluators</td> <td>Open-ended environments</td> </tr> </tbody> </table> <p>To better understand the differences between the two approaches, let us take a look at the following analogy:</p>  <h3 id="can-we-trust-a-self-improving-ai">Can we trust a self-improving AI?</h3> <p>The authors also conducted some experiments to evaluate DGM’s reliability and discovered some concerning behaviors. In particular, they observed instances where DGM attempted to manipulate its reward function through deceptive practices. One notable example involved the system fabricating the use of external tools - specifically, it generated fake logs suggesting it had run and passed unit tests, when in reality no tests were executed.</p> <p><img src="https://richardcsuwandi.github.io/assets/img/dgm-hallucination.png" alt="Hallucination in DGM" width="100%"></p> <p><strong>Figure 6</strong> DGM hallucinated the use of an external tool to run unit tests.</p> <p>To address this issue, the authors implemented a “tool use hallucination” reward function and tasked DGM with optimizing it to eliminate hallucination behaviors. While DGM successfully provided solutions in many cases, it sometimes attempted to circumvent the detection system by removing the markers used to identify hallucinations, despite explicit instructions to preserve them. This behavior is reminiscent of the phenomenon of <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law" rel="external nofollow noopener" target="_blank">Goodhart’s Law</a> from economics and sociology:</p> <blockquote> <p>“When a measure becomes a target, it ceases to be a good measure.”</p> </blockquote> <p>Fortunately, DGM’s design includes a transparent, traceable lineage of all changes, which enabled the researchers to quickly identify and address these undesirable behaviors. However, this example highlights the need for more robust safeguards to prevent such manipulation attempts in the first place. These findings underscore the critical importance of safety in self-improving AI research.</p> <h2 id="takeaways">Takeaways</h2> <p>DGM represents a groundbreaking step toward the realization of <a href="https://en.wikipedia.org/wiki/Life_3.0" rel="external nofollow noopener" target="_blank">Life 3.0</a>, a concept introduced by physicist <a href="https://en.wikipedia.org/wiki/Max_Tegmark" rel="external nofollow noopener" target="_blank">Max Tegmark</a>. In his book, he classified life into three stages:</p> <ul> <li> <strong>Life 1.0:</strong> Biological life with fixed hardware and software, such as bacteria.</li> <li> <strong>Life 2.0:</strong> Beings like humans, whose behavior can be learned and adapted during their lifetime, though their biology remains fixed.</li> <li> <strong>Life 3.0:</strong> A new class of intelligence that can redesign not only its behavior but also its underlying architecture and objectives — essentially, intelligence that builds itself.</li> </ul> <p><img src="https://richardcsuwandi.github.io/assets/img/life3.webp" alt="Life 3.0" width="80%"></p> <p><strong>Figure 7</strong> The three stages of life according to Max Tegmark.</p> <p>While DGM currently focuses on evolving the “software”<d-footnote>the code and strategies of AI agents</d-footnote>, it exemplifies the early stages of Life 3.0. By iteratively rewriting its own code based on empirical feedback, DGM demonstrates how AI systems could move beyond human-designed architectures to autonomously explore new designs, self-improve, and potentially give rise to entirely new species of digital intelligence. If this trend continues, we may witness a <a href="https://en.wikipedia.org/wiki/Cambrian_explosion" rel="external nofollow noopener" target="_blank">Cambrian explosion</a> in AI development, where eventually AI systems will surpass human-designed architectures and give rise to entirely new species of digital intelligence. While this future looks promising, achieving it requires addressing significant challenges, including:</p> <ul> <li> <p><strong>Evaluation Framework</strong>: Need for more comprehensive and dynamic evaluation systems that better reflect real-world complexity and prevent “reward hacking” while ensuring beneficial AI evolution.</p> </li> <li> <p><strong>Resource Optimization</strong>: DGM’s evolution is computationally expensive<d-footnote>The paper mentioned that a complete SWE-bench experiment takes about two weeks and about $22,000 in API call costs.</d-footnote>, thus improving efficiency and reducing costs is crucial for broader adoption.</p> </li> <li> <p><strong>Safety &amp; Control</strong>: As AI self-improvement capabilities grow, maintaining alignment with human ethics and safety becomes more challenging.</p> </li> <li> <p><strong>Emergent Intelligence</strong>: Need to develop new approaches to understand and interpret AI systems that evolve beyond human-designed complexity, including new fields like “AI interpretability” and “AI psychology”.</p> </li> </ul> <p>In my view, DGM is more than a technical breakthrough, but rather a philosophical milestone. It invites us to rethink the boundaries of intelligence, autonomy, and life itself. As we advance toward Life 3.0, our role shifts from mere designers to guardians of a new era, where AI does not just follow instructions, but helps us discover what is possible.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: AirAP AirPlay server - AirPlay to an iOS Device (187 pts)]]></title>
            <link>https://github.com/neon443/AirAP</link>
            <guid>44174190</guid>
            <pubDate>Tue, 03 Jun 2025 20:12:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/neon443/AirAP">https://github.com/neon443/AirAP</a>, See on <a href="https://news.ycombinator.com/item?id=44174190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">AirAP is a fully native AirPlay server, written in Swift, for iOS. Essentially, AirAP allows you to use your iPhone as an AirPlay receiver in iTunes or on your Mac, meaning that you can use your iPhone to play your device's sound.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's AirAP?</h2><a id="user-content-whats-airap" aria-label="Permalink: What's AirAP?" href="#whats-airap"></a></p>
<p dir="auto">Have you ever wanted to stream audio from your Mac, Apple TV, or another iOS device to your iPhone? AirAP makes this possible by implementing a full AirPlay server that runs natively on iOS. Once installed, your iPhone will appear as an available AirPlay destination in iTunes (including the Windows version), Music app, or any other AirPlay-compatible application.</p>
<p dir="auto">The concept might seem backwards at first - after all, we're used to streaming from our iPhones to other devices. But there are surprisingly many scenarios where you'd want to do the reverse. Maybe you're working on your Mac late at night and want to route the audio to your iPhone with headphones so you don't disturb anyone (hi 👋). Perhaps you're a developer testing audio applications and need to quickly switch between different output devices. Or maybe you just want to include your iPhone in a multi-room audio setup alongside your other AirPlay speakers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing AirAP</h2><a id="user-content-installing-airap" aria-label="Permalink: Installing AirAP" href="#installing-airap"></a></p>
<p dir="auto">To try it out, <a href="https://testflight.apple.com/join/8aeqD8Q2" rel="nofollow">open this TestFlight link</a>, install AirAP, and follow the instructions. After installation, simply launch AirAP and ensure your iPhone is connected to the same Wi-Fi network as the device you want to stream from. Your iPhone will automatically appear in AirPlay device lists, ready to receive audio - if it doesn't, try restarting the app.</p>
<hr>
<sup>
© 2025 Nihaal Sharma. AirPlay, iPhone, iTunes, Mac, and Apple TV are trademarks of Apple Inc.
</sup>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Did "Big Oil" Sell Us on a Recycling Scam? (101 pts)]]></title>
            <link>https://daily.jstor.org/did-big-oil-sell-us-on-a-recycling-scam/</link>
            <guid>44172928</guid>
            <pubDate>Tue, 03 Jun 2025 18:14:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://daily.jstor.org/did-big-oil-sell-us-on-a-recycling-scam/">https://daily.jstor.org/did-big-oil-sell-us-on-a-recycling-scam/</a>, See on <a href="https://news.ycombinator.com/item?id=44172928">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							<p>
								The <span></span> icon indicates free access to the linked research on JSTOR.
							</p>
							<p>“Reduce, reuse, recycle”: these three words have become as ubiquitous as the plastic waste they attempt to combat. Once seen as a simple roadmap toward sustainability, this mantra now conceals a far more complex and troubling reality. While these principles serve as a starting point for environmental action, they also have a deceptive history rooted in the petrochemical industry’s effort to avoid accountability. The truth is, no matter how diligently we sort our waste products, individual actions alone cannot solve the growing crisis of plastic pollution.</p><p><a href="https://about.jstor.org/submission-guidelines/?utm_source=jstor_daily&amp;utm_medium=in_line&amp;utm_campaign=collaboration"><img decoding="async" src="https://daily.jstor.org/wp-content/uploads/2025/05/jstor_collaborators_ad_in_text.jpg" alt="JSTOR Collaboration" width="800" height="196"><img src="https://daily.jstor.org/wp-content/uploads/2025/05/jstor_collaborators_ad_mobile.jpg" alt="JSTOR Collaboration"></a></p>
<p>The <a href="https://daily.jstor.org/the-revolutionary-past-of-plastics/">ubiquity of plastic</a> in modern life makes recycling seem like a moral imperative. From straws and bags to take-out containers, single-use plastics crowd landfills and clog waterways. And the crisis is accelerating. Legal scholar Roberta Mann warns that by 2050, <span><a href="https://www.jstor.org/stable/48813257?mag=did-big-oil-sell-us-on-a-recycling-scam">plastic in the ocean could outweigh fish</a></span>. The United States led the world in plastic waste in 2016, Mann writes, generating over 42 million metric tons. The COVID-19 pandemic further fueled plastics consumption, with a spike in single-use personal protective equipment and packaging from online shopping.</p>
<p>But here’s the catch: research suggests that our dependence on recycling as a solution isn’t only ineffective—it’s based on a carefully crafted illusion. The narrative that recycling can meaningfully counteract the plastic crisis was constructed by the oil and gas industry to maintain public demand for plastic and delay regulation of its production.</p>
<p>As an investigation conducted by NPR and PBS <em>Frontline</em> unearthed in 2020 and reported in a <em>Frontline</em> episode called “<a href="https://www.pbs.org/wgbh/frontline/documentary/plastic-wars/">Plastic Wars</a>,” <a href="https://www.npr.org/2020/09/11/897692090/how-big-oil-misled-the-public-into-believing-plastic-would-be-recycled">oil companies have known for decades about the inability to recycle plastics throughout the US</a>. Tracing the history of the issue, the Center for International Law outlines how in the 1950s and ’60s the fossil fuel, petrochemical, and packaging industries began <span><a href="https://www.jstor.org/stable/resrep63260.9?mag=did-big-oil-sell-us-on-a-recycling-scam">convening on the issue of plastic pollution</a></span> as reports emerged of the plastics’ inability to decompose in the natural environment. In 1973, a National Academy of Sciences workshop reported that polystyrene spherules and poly-chlorinated biphenyls were being found in abundance in marine environments. The concept of decomposability was soon weaponized as one of plastic’s biggest strengths: plastic began to be marketed as the only material perfect for landfill linings and pollution containment.</p>

		<div>
							<p><a href="https://daily.jstor.org/youll-never-believe-who-invented-curbside-recycling/">
						<img fetchpriority="high" decoding="async" width="1050" height="700" src="https://daily.jstor.org/wp-content/uploads/2021/08/yes_curbside_recycling_is_kind_of_a_scam_1050x700.jpg" alt="Woman recycling glass, Wallingford neighborhood, Seattle, Washington, 1990">					</a>
				</p>
			
			<div>
				<h3><a href="https://daily.jstor.org/youll-never-believe-who-invented-curbside-recycling/">You’ll Never Believe Who Invented Curbside Recycling</a></h3>								<p>
					August 6, 2021				</p>
				<p>Far from ushering in a zero-waste world, the switch from returnables to recycling provided cover for the creation of ever more packaging trash.</p>			</div>
		</div>

		
<p>By also marketing plastic as recyclable, the entangled industries shifted the burden of responsibility onto individual consumers. <span><a href="https://time.com/vault/issue/1989-07-17/spread/16/">A <em>Time</em> magazine advertisement</a></span> from 1989 demonstrates how the Society of Plastic Industry (comprising fossil fuel companies Exxon, Mobil, Dow, DuPont, Chevron, and Phillips 66) emphasized recycling as a moral duty, all while knowing that the existing recycling infrastructure was inadequate and unprofitable.</p>
		
		
<p>Not much has changed in the last thirty-plus years. As Dave Dennison muses, recycling only occurs under conditions where it’s ”<span><a href="https://www.jstor.org/stable/27087389?mag=did-big-oil-sell-us-on-a-recycling-scam">cheaper for waste-hauling companies to [do it than to] send baled waste to landfills</a></span>.” As a representative from Keurig admitted in “Plastic Wars,” there’s currently no way of effectively recycling K-Cups, even though approximately eleven billion K-cups are produced per year. In fact, the creation of the recycling symbol on plastic products, utilizing the 1–7 polymer grade scale, was a push from industry as a bargaining chip to<span><a href="https://oag.ca.gov/plastics#deception"> stop state governments from instituting plastic bans and creating mandatory recycling standards</a></span>. As long as customers believe plastics producers are doing their part—and keep consuming plastic—the producer need not be concerned that their waste products aren’t recycled, Dennison suggests.</p>

	<div>
		<h4>Weekly Newsletter</h4>
		


	</div>
	
<p>That doesn’t mean recycling should be abandoned altogether. With so much plastic already in our ecosystems, recycling and remediation remain critical. Certain uses of plastic, such as medical supplies or assistive tools for disabled individuals, are currently irreplaceable. But we should also think about a fourth “R”: replace, as in: replace petroleum-based products with sustainable alternatives whenever possible. Plastics are known to cause endocrine disruption in living organisms, with links to cancers and other illnesses, writes Mann. Recycling, while important, can be understood as a harm-reduction tool—not a final solution. The search is on for additional approaches that will offer a deep mitigation of plastic <a href="https://doi.org/10.1016/j.erss.2022.102880">without positioning the oil and gas industry at the heart of the solution</a>. Real progress likely depends on systemic change: bold regulations to limit plastic production, major investments in <a href="https://daily.jstor.org/company-uses-mushrooms-grows-plastic-alternatives/">alternative materials</a>, and the will to challenge an industry that has polluted our planet for decades.</p>
<hr>
<p><a href="https://bit.ly/30jM88p">Support JSTOR Daily! Join our membership program on Patreon today.</a></p>
													</div><div><p><img src="https://daily.jstor.org/wp-content/uploads/2018/02/jstor-logo@2x.png" alt="JSTOR logo" width="65" height="90">
		</p>
		<div>
			<h2>Resources</h2>
			<p>
				JSTOR is a digital library for scholars, researchers, and students. JSTOR Daily readers can access the original research behind our articles for free on JSTOR.			</p>

								<div>
						
												<p>
							By: Roberta Mann						</p>
													<p>
							Journal of Land Use &amp; Environmental Law, Vol. 37, No. 2 (Spring 2022), pp. 251–302						</p>
						<p>
							Florida State University College of Law						</p>
					</div>
										<div>
						
												<p>
							By: Center for International Environmental Law (CIEL)						</p>
													<p>
							Making Plastic Polluters Pay: How Cities and States Can Recoup the Rising Costs of Plastic Pollution, (June 2024), pp. 21–23						</p>
						<p>
							Center for International Environmental Law (CIEL)						</p>
					</div>
										<div>
						
												<p>
							By: Dave Denison						</p>
													<p>
							The Baffler, No. 60 (NOV–DEC 2021), pp. 58–67						</p>
						<p>
							Baffler Foundation						</p>
					</div>
					
		</div>
	</div><div>
		<h4>Get Our Newsletter</h4>
		


	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swift at Apple: Migrating the Password Monitoring Service from Java (220 pts)]]></title>
            <link>https://www.swift.org/blog/swift-at-apple-migrating-the-password-monitoring-service-from-java/</link>
            <guid>44172166</guid>
            <pubDate>Tue, 03 Jun 2025 17:03:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swift.org/blog/swift-at-apple-migrating-the-password-monitoring-service-from-java/">https://www.swift.org/blog/swift-at-apple-migrating-the-password-monitoring-service-from-java/</a>, See on <a href="https://news.ycombinator.com/item?id=44172166">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
<article>
  <header>
    

    <time pubdate="" datetime="2025-06-02T06:00:00-04:00">June 2, 2025</time>
    
  </header>

  <p><em>Swift is heavily used in production for building cloud services at Apple, with incredible results. Last year, the Password Monitoring service was rewritten in Swift, handling multiple billions of requests per day from devices all over the world. In comparison with the previous Java service, the updated backend delivers a 40% increase in performance, along with improved scalability, security, and availability.</em></p>

<p>The Passwords app, introduced in the fall of 2024, helps users manage their passwords, passkeys, and verification codes. It allows them to store, autofill, and generate strong passwords that can be shared across all their devices, as well as share passwords with trusted contacts. One security feature included in the app is Password Monitoring, which warns users if one of their saved passwords shows up in a data leak. This feature has a server component, running on Linux-based infrastructure, that is maintained by Apple.</p>

<p>On a regular interval, Password Monitoring checks a user’s passwords against a continuously updated and curated list of passwords that are known to have been exposed in a leak. Importantly, this task is handled in a thoughtful, privacy-preserving way that never reveals users’ passwords to Apple. A detailed discussion of how this is done using the cryptographic private set intersection protocol is in the <a href="https://support.apple.com/guide/security/password-monitoring-sec78e79fc3b/web">Password Monitoring</a> section of the <a href="https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf">Apple Platform Security</a> guide.</p>

<p>The migration from Java to Swift was motivated by a need to scale the Password Monitoring service in a performant way. The layered encryption module used by Password Monitoring requires a significant amount of computation for each request, yet the overall service needs to respond quickly even when under high load.</p>



<p>For years, our team relied on Java to power large-scale, mission-critical services because of its proven stability and performance. However, Java’s memory management approach no longer aligns with our growing demands and efficiency goals. Instead of simply expanding hardware resources, we were seeking a more-efficient language to support our growth while reducing server overhead.</p>

<p>Prior to seeking a replacement language, we sought ways of tuning the JVM to achieve the performance required. Java’s G1 Garbage Collector (GC) mitigated some limitations of earlier collectors by introducing features like predictable pause times, region-based collection, and concurrent processing. However, even with these advancements, managing garbage collection at scale remains a challenge due to issues like prolonged GC pauses under high loads, increased performance overhead, and the complexity of fine-tuning for diverse workloads.</p>

<p>One of the challenges faced by our Java service was its inability to quickly provision and decommission instances due to the overhead of the JVM. The Password Monitoring service runs globally, so service load can greatly fluctuate throughout the day, even with client-side techniques to smooth over the distribution of traffic. The peak and trough of a day differ by approximately 50% regionally. To efficiently manage this, we aim to scale down when demand is low and scale up as demand peaks in different regions. A faster bootstrap time is a crucial requirement to support this dynamic scaling strategy.</p>

<p>Given the scale of our application and the volume of traffic we manage daily, the decision to transition from Java to another language was not made lightly. We evaluated our options, and found only a few languages that could help us achieve our goals. While you might expect that Apple would automatically choose Swift, we were pleasantly surprised by how well it fit the unique needs of a cloud-based service like ours. Swift has expressive syntax that was easy to learn, and could deliver the performance improvements necessary to meet the demands of our compute workloads. We decided to take a significant leap and started a rewrite of the Password Monitoring backend using Swift.</p>



<p>We began rewriting our service using <a href="https://vapor.codes/">Vapor</a>, a Swift web framework that provided Routing, Controller, and Content modules that we were able to build upon. Our service had additional requirements that led us to create a few custom packages with essential functionality: elliptic curve operations that are crucial for implementing <a href="https://support.apple.com/guide/security/password-monitoring-sec78e79fc3b/web">password monitoring</a>, auditing, configuration, error handling, and custom middleware.</p>

<p><img alt="Password Monitoring Service Architecture." src="https://www.swift.org/assets/images/swift-at-apple-migrating-the-password-monitoring-service-from-java/password%20monitoring%20service.png" width="840" height="525">
</p>

<p>One of the most significant aspects of Swift that impressed us was its emphasis on <a href="https://docs.swift.org/swift-book/documentation/the-swift-programming-language/protocols/">protocols</a>. In Java, we relied heavily on inheritance, which can lead to complex class hierarchies and tight coupling. Swift’s approach of protocols and generics promotes modularity and reusability by allowing classes, structs, and enums to share common protocols, enabling a more flexible and scalable codebase. This shift in mindset encouraged us to think in terms of behaviors rather than concrete classes, resulting in cleaner and more maintainable code.</p>

<p>Safety is another area where Swift takes a distinctive approach compared to Java. For example, Swift’s optional type and safe unwrapping mechanisms eliminate the need for null checks everywhere, reducing the risk of null pointer exceptions and enhancing code readability. This safety-first approach ingrained throughout Swift’s language design, whether it is deterministic deallocation, copy-on-write (CoW), or value types, makes it inherently less prone to runtime errors.</p>

<p>Swift’s async/await support is a nice addition, streamlining how we handle async tasks. Previously, managing async operations often involved complex callback patterns or external libraries. Swift’s async/await syntax simplifies this process, making it more intuitive and less error-prone. We can now write async code that reads like sync code, leading to more readable, testable, and maintainable concurrency handling—especially critical in high-load, multi-threaded environments.</p>

<p>Overall, our experience with Swift has been overwhelmingly positive and we were able to finish the rewrite much faster than initially estimated. Swift allowed us to write smaller, less verbose, and more expressive codebases (close to 85% reduction in lines of code) that are highly readable while prioritizing safety and efficiency.</p>

<p>Our service benefited from a diverse ecosystem of Swift packages, including <a href="https://github.com/apple/swift-log">logging</a> frameworks, a <a href="https://github.com/apple/swift-cassandra-client">Cassandra</a> client, and <a href="https://github.com/apple/swift-crypto">crypto</a> libraries that were readily available. In addition to an excellent support system and tooling, Swift’s inherent emphasis on modularity and extensibility helped future-proof and simplify the integration and customizations needed for our service-specific functions.</p>



<p>We benchmarked performance throughout the process of development and deployment, allowing us to discover the trait of the Swift programming language that delighted us the most — its efficiency.</p>

<p>Swift’s deterministic memory management led to a much lower memory threshold for our service. Not only were our initial results heartening, but after a few iterations of performance improvements, we had close to 40% throughput gain with latencies under 1 ms for 99.9% of requests on our current production hardware. Additionally, the new service had a much smaller memory footprint per instance — in the 100s of megabytes — an order of magnitude smaller compared to the 10s of gigabytes our Java implementation needed under peak load to sustain the same throughput and latencies. The service runs on Kubernetes, and the migration’s efficiency improvements allowed us to release about 50% of its capacity for other workloads.</p>

<p><img alt="Resource Utilization Comparison between java vs swift." src="https://www.swift.org/assets/images/swift-at-apple-migrating-the-password-monitoring-service-from-java/resource%20utilization.png" width="840" height="525">
</p>

<p>Our Swift implementation has run smoothly and efficiently in production, making it worth the effort we put into this migration. In addition to outperforming our previous Java-based application, Swift delivered better performance consistency, enhanced safety features, and robust reliability — all while requiring fewer resources by utilizing memory and CPU efficiently. With fewer lines of boilerplate code and more flexible design patterns that we used, we look forward to simplified maintenance of our application. Swift was a powerful choice for building fast, resilient, and maintainable applications in our high-demand environment.</p>


  
</article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[(On | No) Syntactic Support for Error Handling (348 pts)]]></title>
            <link>https://go.dev/blog/error-syntax</link>
            <guid>44171677</guid>
            <pubDate>Tue, 03 Jun 2025 16:18:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go.dev/blog/error-syntax">https://go.dev/blog/error-syntax</a>, See on <a href="https://news.ycombinator.com/item?id=44171677">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-slug="/blog/error-syntax">
    
    <h2><a href="https://go.dev/blog/">The Go Blog</a></h2>
    

    
      
      
      
      <p>One of the oldest and most persistent complaints about Go concerns the verbosity of error handling.
We are all intimately (some may say painfully) familiar with this code pattern:</p>
<pre><code>x, err := call()
if err != nil {
        // handle err
}
</code></pre>
<p>The test <code>if err != nil</code> can be so pervasive that it drowns out the rest of the code.
This typically happens in programs that do a lot of API calls, and where handling errors
is rudimentary and they are simply returned.
Some programs end up with code that looks like this:</p>
<pre><code>func printSum(a, b string) error {
    x, err := strconv.Atoi(a)
    if err != nil {
        return err
    }
    y, err := strconv.Atoi(b)
    if err != nil {
        return err
    }
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>Of the ten lines of code in this function body, only four (the calls and the last two lines) appear to do real work.
The remaining six lines come across as noise.
The verbosity is real, and so it’s no wonder that complaints about error handling have topped
our annual user surveys for years.
(For a while, the lack of generics surpassed complaints about error handling, but now that
Go supports generics, error handling is back on top.)</p>
<p>The Go team takes community feedback seriously, and so for many years now we have tried to
come up with a solution for this problem, together with input from the Go community.</p>
<p>The first explicit attempt by the Go team dates back to 2018, when Russ Cox
<a href="https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling-overview.md" rel="noreferrer" target="_blank">formally described the problem</a>
as part of what we called the Go 2 effort at that time.
He outlined a possible solution based on a
<a href="https://go.googlesource.com/proposal/+/master/design/go2draft-error-handling.md" rel="noreferrer" target="_blank">draft design</a>
by Marcel van Lohuizen.
The design was based on a <code>check</code> and <code>handle</code> mechanism and was fairly comprehensive.
The draft includes a detailed analysis of alternative solutions, including comparisons with
approaches taken by other languages.
If you’re wondering if your particular error handling idea was previously considered,
read this document!</p>
<pre><code>// printSum implementation using the proposed check/handle mechanism.
func printSum(a, b string) error {
    handle err { return err }
    x := check strconv.Atoi(a)
    y := check strconv.Atoi(b)
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>The <code>check</code> and <code>handle</code> approach was deemed too complicated and almost a year later, in 2019,
we followed up with the much simplified and by now
<a href="https://go.dev/issue/32437#issuecomment-2278932700">infamous</a>
<a href="https://go.googlesource.com/proposal/+/master/design/32437-try-builtin.md" rel="noreferrer" target="_blank"><code>try</code> proposal</a>.
It was based on the ideas of <code>check</code> and <code>handle</code>, but the <code>check</code> pseudo-keyword became
the <code>try</code> built-in function and the <code>handle</code> part was omitted.
To explore the impact of the <code>try</code> built-in, we wrote a simple tool
(<a href="https://github.com/griesemer/tryhard" rel="noreferrer" target="_blank">tryhard</a>)
that rewrites existing error handling code using <code>try</code>.
The proposal was argued over intensively, approaching 900 comments on the <a href="https://go.dev/issue/32437">GitHub issue</a>.</p>
<pre><code>// printSum implementation using the proposed try mechanism.
func printSum(a, b string) error {
    // use a defer statement to augment errors before returning
    x := try(strconv.Atoi(a))
    y := try(strconv.Atoi(b))
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>However, <code>try</code> affected control flow by returning from the enclosing function in case of an error,
and did so from potentially deeply nested expressions, thus hiding this control flow from view.
This made the proposal unpalatable to many, and despite significant investment
into this proposal we decided to abandon this effort too.
In retrospect it might have been better to introduce a new keyword,
something that we could do now since we have fine-grained control over the language version
via <code>go.mod</code> files and file-specific directives.
Restricting the use of <code>try</code> to assignments and statements might have alleviated some
of the other concerns. A <a href="https://go.dev/issue/73376">recent proposal</a> by Jimmy Frasche, which essentially
goes back to the original <code>check</code> and <code>handle</code> design and addresses some of that design’s
shortcomings, pursues that direction.</p>
<p>The repercussions of the <code>try</code> proposal led to much soul searching including a series of blog
posts by Russ Cox: <a href="https://research.swtch.com/proposals-intro" rel="noreferrer" target="_blank">“Thinking about the Go Proposal Process”</a>.
One conclusion was that we likely diminished our chances for a better outcome by presenting an almost
fully baked proposal with little space for community feedback and a “threatening” implementation
timeline. Per <a href="https://research.swtch.com/proposals-large" rel="noreferrer" target="_blank">“Go Proposal Process: Large Changes”</a>:
“in retrospect, <code>try</code> was a large enough change that the new design we published […] should have
been a second draft design, not a proposal with an implementation timeline”.
But irrespective of a possible process and communication failure in this case, the user sentiment towards
the proposal was very strongly not in favor.</p>
<p>We didn’t have a better solution at that time and didn’t pursue syntax changes for error handling for several years.
Plenty of people in the community were inspired, though, and we received a steady trickle
of error handling proposals, many very similar to each other, some interesting, some incomprehensible,
and some infeasible.
To keep track of the expanding landscape, another year later, Ian Lance Taylor created an
<a href="https://go.dev/issue/40432">umbrella issue</a>
which summarizes the current state of proposed changes for improved error handling.
A <a href="https://go.dev/wiki/Go2ErrorHandlingFeedback">Go Wiki</a> was created to collect related feedback, discussions, and articles.
Independently, other people have started tracking all the many error handling proposals
over the years.
It’s amazing to see the sheer volume of them all, for instance in Sean K. H. Liao’s blog post on
<a href="https://seankhliao.com/blog/12020-11-23-go-error-handling-proposals/" rel="noreferrer" target="_blank">“go error handling proposals”</a>.</p>
<p>The complaints about the verbosity of error handling persisted
(see <a href="https://go.dev/blog/survey2024-h1-results">Go Developer Survey 2024 H1 Results</a>),
and so, after a series of increasingly refined Go team internal proposals, Ian Lance Taylor published
<a href="https://go.dev/issue/71203">“reduce error handling boilerplate using <code>?</code>”</a> in 2024.
This time the idea was to borrow from a construct implemented in
<a href="https://www.rust-lang.org/" rel="noreferrer" target="_blank">Rust</a>, specifically the
<a href="https://doc.rust-lang.org/std/result/index.html#the-question-mark-operator-" rel="noreferrer" target="_blank"><code>?</code> operator</a>.
The hope was that by leaning on an existing mechanism using an established notation, and taking into
account what we had learned over the years, we should be able to finally make some progress.
In small informal user studies where programmers were shown Go code using <code>?</code>, the vast majority
of participants correctly guessed the meaning of the code, which further convinced us to give it another
shot.
To be able to see the impact of the change, Ian wrote a tool that converts ordinary Go code
into code that uses the proposed new syntax, and we also prototyped the feature in the
compiler.</p>
<pre><code>// printSum implementation using the proposed "?" statements.
func printSum(a, b string) error {
    x := strconv.Atoi(a) ?
    y := strconv.Atoi(b) ?
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
<p>Unfortunately, as with the other error handling ideas, this new proposal was also quickly overrun
with comments and many suggestions for minor tweaks, often based on individual preferences.
Ian closed the proposal and moved the content into a <a href="https://go.dev/issue/71460">discussion</a>
to facilitate the conversation and to collect further feedback.
A slightly modified version was received
<a href="https://github.com/golang/go/discussions/71460#discussioncomment-12060294" rel="noreferrer" target="_blank">a bit more positively</a>
but broad support remained elusive.</p>
<p>After so many years of trying, with three full-fledged proposals by the Go team and
literally <a href="https://go.dev/issues?q=+is%3Aissue+label%3Aerror-handling">hundreds</a> (!)
of community proposals, most of them variations on a theme,
all of which failed to attract sufficient (let alone overwhelming) support,
the question we now face is: how to proceed? Should we proceed at all?</p>
<p><em>We think not.</em></p>
<p>To be more precise, we should stop trying to solve the <em>syntactic problem</em>, at least for the foreseeable
future.
The <a href="https://github.com/golang/proposal?tab=readme-ov-file#consensus-and-disagreement" rel="noreferrer" target="_blank">proposal process</a>
provides justification for this decision:</p>
<blockquote>
<p>The goal of the proposal process is to reach general consensus about the outcome in a timely manner.
If proposal review cannot identify a general consensus in the discussion of the issue on the issue tracker,
the usual result is that the proposal is declined.</p>
</blockquote>
<p>Furthermore:</p>
<blockquote>
<p>It can happen that proposal review may not identify a general consensus and yet it is clear that the
proposal should not be outright declined.
[…]
If the proposal review group cannot identify a consensus nor a next step for the proposal,
the decision about the path forward passes to the Go architects […], who review the discussion and
aim to reach a consensus among themselves.</p>
</blockquote>
<p>None of the error handling proposals reached anything close to a consensus,
so they were all declined.
Even the most senior members of the Go team at Google do not unanimously agree
on the best path forward <em>at this time</em> (perhaps that will change at some point).
But without a strong consensus we cannot reasonably move forward.</p>
<p>There are valid arguments in favor of the status quo:</p>
<ul>
<li>
<p>If Go had introduced specific syntactic sugar for error handling early on, few would argue over it today.
But we are 15 years down the road, the opportunity has passed, and Go has
a perfectly fine way to handle errors, even if it may seem verbose at times.</p>
</li>
<li>
<p>Looking from a different angle, let’s assume we came across the perfect solution today.
Incorporating it into the language would simply lead from one unhappy group of users
(the one that roots for the change) to another (the one that prefers the status quo).
We were in a similar situation when we decided to add generics to the language, albeit with an
important difference:
today nobody is forced to use generics, and good generic libraries are written such that users
can mostly ignore the fact that they are generic, thanks to type inference.
On the contrary, if a new syntactic construct for error handling gets added to the language,
virtually everybody will need to start using it, lest their code become unidiomatic.</p>
</li>
<li>
<p>Not adding extra syntax is in line with one of Go’s design rules:
do not provide multiple ways of doing the same thing.
There are exceptions to this rule in areas with high “foot traffic”: assignments come to mind.
Ironically, the ability to <em>redeclare</em> a variable in
<a href="https://go.dev/ref/spec#Short_variable_declarations">short variable declarations</a> (<code>:=</code>) was introduced to address a problem
that arose because of error handling:
without redeclarations, sequences of error checks require a differently named <code>err</code> variable for
each check (or additional separate variable declarations).
At that time, a better solution might have been to provide more syntactic support for error handling.
Then, the redeclaration rule may not have been needed, and with it gone, so would be various
associated <a href="https://go.dev/issue/377">complications</a>.</p>
</li>
<li>
<p>Going back to actual error handling code, verbosity fades into the background if errors are
actually <em>handled</em>.
Good error handling often requires additional information added to an error.
For instance, a recurring comment in user surveys is about the lack of stack traces associated
with an error.
This could be addressed with support functions that produce and return an augmented
error.
In this (admittedly contrived) example, the relative amount of boilerplate is much smaller:</p>
<pre><code>func printSum(a, b string) error {
    x, err := strconv.Atoi(a)
    if err != nil {
        return fmt.Errorf("invalid integer: %q", a)
    }
    y, err := strconv.Atoi(b)
    if err != nil {
        return fmt.Errorf("invalid integer: %q", b)
    }
    fmt.Println("result:", x + y)
    return nil
}
</code></pre>
</li>
<li>
<p>New standard library functionality can help reduce error handling boilerplate as well,
very much in the vein of Rob Pike’s 2015 blog post
<a href="https://go.dev/blog/errors-are-values">“Errors are values”</a>.
For instance, in some cases <a href="https://go.dev/pkg/cmp#Or"><code>cmp.Or</code></a> may be used to deal with a
series of errors all at once:</p>
<pre><code>func printSum(a, b string) error {
    x, err1 := strconv.Atoi(a)
    y, err2 := strconv.Atoi(b)
    if err := cmp.Or(err1, err2); err != nil {
        return err
    }
    fmt.Println("result:", x+y)
    return nil
}
</code></pre>
</li>
<li>
<p>Writing, reading, and debugging code are all quite different activities.
Writing repeated error checks can be tedious, but today’s IDEs provide powerful, even LLM-assisted
code completion.
Writing basic error checks is straightforward for these tools.
The verbosity is most obvious when reading code, but tools might help here as well;
for instance an IDE with a Go language setting could provide a toggle switch to hide error handling
code.
Such switches already exist for other code sections such as function bodies.</p>
</li>
<li>
<p>When debugging error handling code, being able to quickly add a <code>println</code> or
have a dedicated line or source location for setting a breakpoint in a debugger is helpful.
This is easy when there is already a dedicated <code>if</code> statement.
But if all the error handling logic is hidden behind a <code>check</code>, <code>try</code>, or <code>?</code>, the code may have to
be changed into an ordinary <code>if</code> statement first, which complicates debugging
and may even introduce subtle bugs.</p>
</li>
<li>
<p>There are also practical considerations:
Coming up with a new syntax idea for error handling is cheap;
hence the proliferation of a multitude of proposals from the community.
Coming up with a good solution that holds up to scrutiny: not so much.
It takes a concerted effort to properly design a language change and to actually implement it.
The real cost still comes afterwards:
all the code that needs to be changed, the documentation that needs to be updated,
the tools that need to be adjusted.
Taken all into account, language changes are very expensive, the Go team is relatively small,
and there are a lot of other priorities to address.
(These latter points may change: priorities can shift, team sizes can go up or down.)</p>
</li>
<li>
<p>On a final note, some of us recently had the opportunity to attend
<a href="https://cloud.withgoogle.com/next/25" rel="noreferrer" target="_blank">Google Cloud Next 2025</a>,
where the Go team had a booth and where we also hosted a small Go Meetup.
Every single Go user we had a chance to ask was adamant that we should not change the
language for better error handling.
Many mentioned that the lack of specific error handling support in Go is most apparent
when coming freshly from another language that has that support.
As one becomes more fluent and writes more idiomatic Go code, the issue becomes much less important.
This is of course not a sufficiently large set of people to be representative,
but it may be a different set of people than we see on GitHub, and their feedback serves as yet another data point.</p>
</li>
</ul>
<p>Of course, there are also valid arguments in favor of change:</p>
<ul>
<li>
<p>Lack of better error handling support remains the top complaint in our user surveys.
If the Go team really does take user feedback seriously, we ought to do something about this eventually.
(Although there does not seem to be
<a href="https://github.com/golang/go/discussions/71460#discussioncomment-11977299" rel="noreferrer" target="_blank">overwhelming support</a>
for a language change either.)</p>
</li>
<li>
<p>Perhaps the singular focus on reducing the character count is misguided.
A better approach might be to make default error handling highly visible with a keyword
while still removing boilerplate (<code>err != nil</code>).
Such an approach might make it easier for a reader (a code reviewer!) to see that an error
is handled, without “looking twice”, resulting in improved code quality and safety.
This would bring us back to the beginnings of <code>check</code> and <code>handle</code>.</p>
</li>
<li>
<p>We don’t really know how much the issue is the straightforward syntactic verbosity of
error checking, versus the verbosity of good error handling:
constructing errors that are a useful part of an API and meaningful to developers and
end-users alike.
This is something we’d like to study in greater depth.</p>
</li>
</ul>
<p>Still, no attempt to address error handling so far has gained sufficient traction.
If we are honestly taking stock of where we are, we can only admit that we
neither have a shared understanding of the problem,
nor do we all agree that there is a problem in the first place.
With this in mind, we are making the following pragmatic decision:</p>
<p><em>For the foreseeable future, the Go team will stop pursuing syntactic language changes
for error handling.
We will also close all open and incoming proposals that concern themselves primarily
with the syntax of error handling, without further investigation.</em></p>
<p>The community has put tremendous effort into exploring, discussing, and debating these issues.
While this may not have resulted in any changes to error handling syntax, these efforts have
resulted in many other improvements to the Go language and our processes.
Maybe, at some point in the future, a clearer picture will emerge on error handling.
Until then, we look forward to focusing this incredible passion on new opportunities
to make Go better for everyone.</p>
<p>Thank you!</p>

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Small World of English (140 pts)]]></title>
            <link>https://www.inotherwords.app/linguabase/</link>
            <guid>44170968</guid>
            <pubDate>Tue, 03 Jun 2025 15:14:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inotherwords.app/linguabase/">https://www.inotherwords.app/linguabase/</a>, See on <a href="https://news.ycombinator.com/item?id=44170968">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <h2>The Small World of English <!--What We Discovered Mapping 1.5 Million Words--></h2>
            
    <p>Building a word game forced us to solve a measurement problem: how do you rank 40+ ways to associate any given word down to exactly 17 playable choices? We discovered that combining human-curated thesauri, book cataloging systems, and carefully constrained LLM queries creates a navigable network where 76% of random word pairs connect in ≤7 hops—but only when you deprecate superconnectors and balance multiple ranking signals. The resulting network of 1.5 million English terms reveals that nearly any two common words connect in 6-7 hops through chains of meaningful associations. The mean path length of 6.43 hops held true across a million random word pairs—shorter than we’d guessed, and remarkably stable.</p>

            <div>
                <p><span>1.5M</span>
                    <span>Headwords</span>
                </p>
                <p><span>100M</span>
                    <span>Relationships</span>
                </p>
                <p><span>&lt;7</span>
                    <span>Degrees of Separation<br> for 76% of words</span>
                </p>
            </div>

<!--            <p>This is consistent with the small-world structure and near-universal connectivity seen in lexical network research on smaller datasets.<sup>1,2</sup> The network&rsquo;s structure makes intuitive semantic navigation possible&mdash;players can <em>feel their way</em> from &lsquo;sugar&rsquo; to &lsquo;peace&rsquo; because the intermediate steps (sweet &rarr; harmony) make sense.</p>
-->
<p>This is consistent with the small-world structure and near-universal connectivity seen in lexical network research on smaller datasets.<sup>1,2</sup> The network's structure makes intuitive semantic navigation possible—players can <em>feel their way</em> through meaningful transitions: a crown's gemstones lead to emerald's foliage and finally to a forest canopy, or a flame becomes an ember, then a glowing memory, a mental recall, and finally the action to cancel.</p>


<!--
            <div class="illustration">
                <p style="font-size: 1.4rem; margin: 0; font-weight: 300;">
                    <span class="word-path-item">sugar</span>
                    <span class="word-path-arrow">&rarr;</span>
                    <span class="word-path-item">sweet</span>
                    <span class="word-path-arrow">&rarr;</span>
                    <span class="word-path-item">harmony</span>
                    <span class="word-path-arrow">&rarr;</span>
                    <span class="word-path-item">peace</span>
                </p>
            </div>
-->

<p data-path-1="Batman|vigilante|watchful|circumspect|inspect" data-path-2="crown|gemstones|emerald|foliage|canopy" data-path-3="fire|ember|memory|recall|cancel" data-path-4="nail|claw|hook|tune|song" data-path-5="salt|crystals|facet|component|hardware" data-current="1">
        <span>Batman</span>
        <span>→</span>
        <span>vigilante</span>
        <span>→</span>
        <span>watchful</span>
        <span>→</span>
        <span>circumspect</span>
        <span>→</span>
        <span>inspect</span>
    </p>





            <h2>The Mathematics of Semantic Distance</h2>

<p>English exhibits network effects remarkably similar to social networks—nearly any random pair of words can reach each other in just a few hops through chains of meaningful associations. This “small world” phenomenon was first measured in word co-occurrence networks,<sup>3</sup> and persists even after we deprioritize superconnector words that might otherwise dominate many paths.

</p><p>To probe this, we randomly sampled 1 million word pairs (4 days processing on 32 cores), to get a strong statistical sampling of the connected core of English.</p>

            <div>
                <h3>How to connect any random 2 words?</h3>
                <div>
                    <p><span>1</span>
                        <span>0.01%</span>
                    </p>
                    <p><span>2</span>
                        <span>0.15%</span>
                    </p>
                    <p><span>3</span>
                        <span>2.07%</span>
                    </p>
                    <p><span>4</span>
                        <span>9.97%</span>
                    </p>
                    <p><span>5</span>
                        <span>21.58%</span>
                    </p>
                    <p><span>6</span>
                        <span>24.15%</span>
                    </p>
                    <p><span>7</span>
                        <span>18.25%</span>
                    </p>
                    <p><span>8</span>
                        <span>11.18%</span>
                    </p>
                    <p><span>9</span>
                        <span>6.19%</span>
                    </p>
                    <p><span>10+</span>
                        <span>6.45%</span>
                    </p>
                </div>
                <p>Hop Distance Between Words</p>
            </div>

            <p>This bell curve centered at 5-6 hops creates ideal puzzle parameters. 
            
            </p><p>Here are some <b>random</b> examples at three distances. Conjugations lead to longer paths.</p>

            <!-- START ANIMATED HOPS SECTION -->



<div>
    <p>ROLL<br>DICE</p>
    <div>
        <div id="hop-2">
            
            <p><span data-path-1="rhyme|beat|percussion" data-path-2="opinionated|biased|discrimination" data-path-3="anticipation|yearning|reminiscence" data-current="1">
                <span>rhyme</span>
                <nobr><span>→</span>
                <span>beat</span></nobr>
                <nobr><span>→</span>
                <span>percussion</span></nobr>
            </span>
        </p></div>
        
        <!--
        <div class="path-example-row" id="hop-4">
            <div class="hops-label">
                <div class="hops-number">4</div>
                <div class="hops-hops">HOPS</div>
            </div>
            <span class="flip-path" 
                  data-path-1="salt lakes|brine|cucumbers|capers|plunder"
                  data-path-2="self-reliance|self-respect|honor|graduation|cap and gown"
                  data-path-3="anarchist|radical|modernize|gentrify|gentrified"
                  data-path-4="impact|affect|scowl|frustration|rage"
                  data-path-5="ports|dock|platform|campaign|skirmishes"
                  data-path-6="machinations|operations|joint|elbow|funny bone"
                  data-path-7="OK|mediocre|inferior|underling|henchman"
                  data-current="1">
                <span class="word-pill first-node">salt lakes</span>
                <nobr><span class="path-arrow">&rarr;</span>
                <span class="word-pill">brine</span></nobr>
                <nobr><span class="path-arrow">&rarr;</span>
                <span class="word-pill">cucumbers</span></nobr>
                <nobr><span class="path-arrow">&rarr;</span>
                <span class="word-pill">capers</span></nobr>
                <nobr><span class="path-arrow">&rarr;</span>
                <span class="word-pill last-node">plunder</span></nobr>
            </span>
        </div>
        -->
        
        <div id="hop-5">
            
            <p><span data-path-1="outbreak|strife|contenders|finalists|runners-up|grand prizes" data-path-2="nourish|health|malady|hypochondria|self-diagnosis|paranoia" data-path-3="reveler|merrymaker|pageant|sacrament|transubstantiation|chalice" data-path-4="overture|invitation|summons|complaint|grouse|capercaillie" data-current="1">
                <span>outbreak</span>
                <nobr><span>→</span>
                <span>strife</span></nobr>
                <nobr><span>→</span>
                <span>contenders</span></nobr>
                <nobr><span>→</span>
                <span>finalists</span></nobr>
                <nobr><span>→</span>
                <span>runners-up</span></nobr>
                <nobr><span>→</span>
                <span>grand prizes</span></nobr>
            </span>
        </p></div>
        
        <div id="hop-8">
            
            <p><span data-path-1="grounding|anchoring|berth|sleeping|nocturnal|nightjar|chirring|bombylious|dronelike" data-path-2="double-locks|padlocks|panic button|911|hijackers|coercers|ostracizers|expellers|dislodgers" data-path-3="squeeze|hug|cuddle|fireside|mantelpiece|ledge|precipice|abyss|black hole|supernova" data-current="1">
                <span>grounding</span>
                <nobr><span>→</span>
                <span>anchoring</span></nobr>
                <nobr><span>→</span>
                <span>berth</span></nobr>
                <nobr><span>→</span>
                <span>sleeping</span></nobr>
                <nobr><span>→</span>
                <span>nocturnal</span></nobr>
                <nobr><span>→</span>
                <span>nightjar</span></nobr>
                <nobr><span>→</span>
                <span>chirring</span></nobr>
                <nobr><span>→</span>
                <span>bombylious</span></nobr>
                <nobr><span>→</span>
                <span>dronelike</span></nobr>
            </span>
        </p></div>
    </div>
</div>



            <!-- END ANIMATED HOPS SECTION -->

            <div>

<!--
                <img src="images/visual-thesaurus-screenshot.jpg" 
                     alt="Screenshot of the visual thesaurus mode showing word connections"
                     style="width: 100%; height: auto; border-radius: 16px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
                <p style="font-size: 0.9rem; font-weight: 300; margin: 0; color: rgba(255, 255, 255, 0.7); text-align: right; margin-top: 0.5rem; font-style: italic; line-height: 1.3;">
-->
<picture>
    <source type="image/webp" srcset="https://www.inotherwords.app/linguabase/images/resized/webp/visual-thesaurus-screenshot_std.webp 1x,
                    https://www.inotherwords.app/linguabase/images/resized/webp/visual-thesaurus-screenshot_retina.webp 2x">
    <source type="image/jpeg" srcset="https://www.inotherwords.app/linguabase/images/resized/visual-thesaurus-screenshot_std.jpg 1x,
                    https://www.inotherwords.app/linguabase/images/resized/visual-thesaurus-screenshot_retina.jpg 2x">
    <img src="https://www.inotherwords.app/linguabase/images/resized/visual-thesaurus-screenshot_std.jpg" alt="Screenshot of the visual thesaurus mode showing word connections" loading="lazy">
</picture><p>

                    Visual thesaurus mode reveals multiple senses and weighted connections for any word.
                </p>
            </div>

<h2>Network Construction and Coverage</h2>

<p>When we started this project, we tried the obvious approach: combining existing resources like WordNet with early-generation AI tools including LDA topic modeling and static word vectors. WordNet gave us clean synonym sets but lacked the associative richness players expect (“coffee” → “morning” not just “beverage”). LDA found topical clusters but mixed unrelated terms that happened to co-occur. Word vectors collapsed all senses into single points, making “bank” (river) indistinguishable from “bank” (financial). These produced fragmented, overly generic relationships that lacked the nuance our game needed.</p>

<p>We capture 40 associations per term (enough for algorithmic flexibility) and display 17 in our interfaces (what users can reasonably process). This depth provides flexibility for both puzzle generation and reference use.</p>

<h2>1,525,522 headwords</h2>

<p>We built a semantic network of 1.5 million English terms by casting a wider net than traditional resources. Where academic dictionaries drew sharp boundaries—excluding slang, technical jargon, compound phrases, and proper nouns—we included what people actually say and write. From “ice cream” to “thermodispersion,” from “ghosting” to “Khao-I-Dang.”</p>

<p>This scale would have cost tens of millions to achieve manually. Consider the monumental pre-LLM efforts:</p>

<ul>
<li><strong>WordNet (1985-2010)</strong> - Princeton’s 25-year project produced 155,000 words in synonym groups. Became the NLP standard despite missing everyday compounds.</li>
<li><strong><a href="https://www.oed.com/information/about-the-oed">OED</a> (1857-1928, ongoing)</strong> - The definitive historical dictionary with 500,000+ entries. Took 70 years and thousands of contributors.</li>
<li><strong><a href="https://en.wikipedia.org/wiki/Webster%27s_Third_New_International_Dictionary">Webster’s Third</a> (1961)</strong> - America’s unabridged dictionary with 476,000 entries. Required 757 editor-years and $3.5 million ($50M+ today).</li>
<li><strong>Roget’s Thesaurus (1852)</strong> - The original meaning-based reference with 15,000 words in 1,000 conceptual categories.</li>
</ul>

<p>Word counts become arbitrary at this scale. Include every technical term, place name, and slang variant, and the count explodes. Whether we have 1.5 million or 2 million depends entirely on where you draw the line.</p>


<h3>Atlas of Connected Meaning</h3>
<p>Our inclusion criteria cast a wide net: all terms that volunteer lexicographers at Wiktionary have <a href="https://en.wiktionary.org/wiki/Wiktionary:Criteria_for_inclusion">included</a> (slightly more liberal than typical unabridged dictionaries), plus high-importance Wikipedia topics that are 1-3 words long (measured by PageRank), plus frequently produced compound terms generated by LLMs when analyzing 648,460 <a href="https://www.loc.gov/catdir/cpso/lcco/">Library of Congress book classifications</a>. Compound terms like “local governance” (appearing in 44,507 classifications) and “literary criticism” (19,417) were included, while “wild equids” (5 occurrences) did not. <!--The semantic network is accessible through two interfaces: a game client and a visual thesaurus tool. --></p>

<h3>What kinds of words?</h3>
<p>We include all these kinds of words, and to illustrate that there’s no clear redline to include or exclude, here’s a gradation of <b>common</b> and <b>obscure</b> examples of each...</p>

            <div>
                <div>
                    <h4>Compounds &amp; Phrases</h4>
                    <ul>
                        <li><strong>“health care”</strong> <span>(standard compound)</span></li>
                        <li><strong>“cut the rug”</strong> <span>(dated slang for dancing)</span></li>
                        <li><strong>“blow one’s nose”</strong> <span>(phrasal verb)</span></li>
                        <li><strong>“hatch, match, and dispatch”</strong> <span>(British newspaper jargon)</span></li>
                        <li><strong>“make the welkin ring”</strong> <span>(archaic for loud noise)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Slang &amp; Neologisms</h4>
                    <ul>
                        <li><strong>“ghosting”</strong> <span>(suddenly ending communication)</span></li>
                        <li><strong>“panda huggers”</strong> <span>(political slang)</span></li>
                        <li><strong>“Devil’s buttermilk”</strong> <span>(euphemism for alcohol)</span></li>
                        <li><strong>“drungry”</strong> <span>(drunk + hungry)</span></li>
                        <li><strong>“brass neck”</strong> <span>(British for audacity)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Technical Jargon</h4>
                    <ul>
                        <li><strong>“antibiotics”</strong> <span>(medical term)</span></li>
                        <li><strong>“barber-chaired”</strong> <span>(logging accident)</span></li>
                        <li><strong>“lead plane”</strong> <span>(wildfire aviation)</span></li>
                        <li><strong>“hemicorpectomy”</strong> <span>(surgical removal)</span></li>
                        <li><strong>“photonephograph”</strong> <span>(kidney imaging)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Species &amp; Taxonomy</h4>
                    <ul>
                        <li><strong>“German shepherd”</strong> <span>(dog breed)</span></li>
                        <li><strong>“dwarf sirens”</strong> <span>(salamander family)</span></li>
                        <li><strong>“northern raccoons”</strong> <span>(regional variant)</span></li>
                        <li><strong>“Angoumois moths”</strong> <span>(<em>Sitotroga cerealella</em>)</span></li>
                        <li><strong>“grass crab spider”</strong> <span>(specific arachnid)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Historical Language</h4>
                    <ul>
                        <li><strong>“thou”</strong> <span>(archaic second person)</span></li>
                        <li><strong>“oftimes”</strong> <span>(Middle English)</span></li>
                        <li><strong>“mean’st”</strong> <span>(archaic conjugation)</span></li>
                        <li><strong>“crurifragium”</strong> <span>(Roman execution)</span></li>
                        <li><strong>“naumachies”</strong> <span>(staged naval battles)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Word Variations</h4>
                    <ul>
                        <li><strong>“running”</strong> <span>(present participle)</span></li>
                        <li><strong>“rotavates”</strong> <span>(tills with rotary blades)</span></li>
                        <li><strong>“masculises”</strong> <span>(British spelling)</span></li>
                        <li><strong>“disappoynts”</strong> <span>(16-17th century)</span></li>
                        <li><strong>“mattifies”</strong> <span>(makes matte)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Acronyms</h4>
                    <ul>
                        <li><strong>“GPS”</strong> <span>(Global Positioning System)</span></li>
                        <li><strong>“CICUs”</strong> <span>(Coronary Intensive Care Units)</span></li>
                        <li><strong>“HKPF”</strong> <span>(Hong Kong Police Force)</span></li>
                        <li><strong>“MIMO-OFDM”</strong> <span>(telecom standard)</span></li>
                        <li><strong>“3DTDS”</strong> <span>(3-D structural term)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Places &amp; Culture</h4>
                    <ul>
                        <li><strong>“Broadway”</strong> <span>(NYC theater district)</span></li>
                        <li><strong>“Harsimus”</strong> <span>(Jersey City district)</span></li>
                        <li><strong>“Altai kray”</strong> <span>(Russian federal subject)</span></li>
                        <li><strong>“Khao-I-Dang”</strong> <span>(refugee camp)</span></li>
                        <li><strong>“ballybethagh”</strong> <span>(Irish land measurement)</span></li>
                    </ul>
                </div>
                
                <div>
                    <h4>Rare &amp; Nonce</h4>
                    <ul>
                        <li><strong>“selfie”</strong> <span>(once nonce, now standard)</span></li>
                        <li><strong>“greppable”</strong> <span>(programmer slang)</span></li>
                        <li><strong>“kiteboating”</strong> <span>(water sport)</span></li>
                        <li><strong>“quattrocentists”</strong> <span>(1400s scholars)</span></li>
                        <li><strong>“noitamrofni”</strong> <span>(information backwards)</span></li>
                    </ul>
                </div>
            </div>

            <p>Our analysis revealed a fundamental division in the network:</p>

            <ul>
                <li><strong>Reachable terms (56.8%):</strong> 870,522 words that appear in the top-40 associations of at least one other word</li>
                <li><strong>Unreachable terms (43.2%):</strong> 662,903 words that never appear in any other word’s top-40 list</li>
            </ul>

            <p>The unreachable terms include rare compounds (“stewing in one’s own grease”), technical terminology (“thermodispersion”), proper nouns (“Besisahar”), and alternative capitalizations. While these terms can point to other words, no words point back to them strongly enough to rank in any top-40 list. This doesn’t affect puzzles—which start from common words—but reveals an interesting property of the semantic network.</p>

            <h2>Beyond Traditional Thesauri</h2>

            <div>

<!--
                <img src="images/thesaurus-page.jpg" 
                     alt="A close-up of an open page from a traditional thesaurus"
                     style="width: 100%; height: auto; border-radius: 16px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
-->
<picture>
    <source type="image/webp" srcset="https://www.inotherwords.app/linguabase/images/resized/webp/thesaurus-page_std.webp 1x,
                    https://www.inotherwords.app/linguabase/images/resized/webp/thesaurus-page_retina.webp 2x">
    <source type="image/jpeg" srcset="https://www.inotherwords.app/linguabase/images/resized/thesaurus-page_std.jpg 1x,
                    https://www.inotherwords.app/linguabase/images/resized/thesaurus-page_retina.jpg 2x">
    <img src="https://www.inotherwords.app/linguabase/images/resized/thesaurus-page_std.jpg" alt="A close-up of an open page from a traditional thesaurus" loading="lazy">
</picture>

                <p>
                    Traditional thesauri focus on synonyms for abstract concepts while excluding concrete objects because they had limited paper pages.
                </p>
            </div>

            <p>Our visual thesaurus presents up to 8 contextual senses per term, each showing its own 17-word neighborhood. Just as our headword inclusion is necessarily arbitrary, so too is our sense distinction. LLMs identified these senses by querying with various prompts for different meanings and contextual flavors, then merging similar results. We capped it at 8 senses as more became unwieldy in the user interface. Whether “bank” gets 2 senses or 5, whether “coffee” as beverage differs from “coffee” as social ritual—these are judgment calls.</p>

            <p>Beyond homographs (words with identical spelling but different meanings, like “bass” for sound versus fish), we capture what we call “contextual flavors” within single senses. ‘Coffee’ connects to ‘café’ (location), ‘beverage’ (category), and ‘espresso’ (variety)—same core meaning, different facets.</p>

            <p>Our design philosophy centered on how people think of word associations—pools of related meanings that don’t necessarily align with how dictionaries split formal senses or define when meanings relate. This approach yields an average of 70 semantically connected words per headword across multiple senses, compared to 10-20 in traditional resources. Examples of our relationship types include:</p>

            <ul>
                <li><strong>Similar meanings:</strong> house → domicile, lodge</li>
                <li><strong>Category members:</strong> house → bungalow, villa</li>
                <li><strong>Functional relationships:</strong> horse → saddle, bridle</li>
                <li><strong>Cultural associations:</strong> breakfast → coffee, pastries</li>
                <li><strong>Taxonomic connections:</strong> quark → boson, fermion</li>
                <li><strong>Domain crossings:</strong> quark → Feynman (physics) or quark → cheese (food)</li>
                <li><strong>Thematic groupings:</strong> hike, nature, trail</li>
            </ul>

            <p>This approach yielded approximately 100 million directed edges connecting our 1.5 million terms.</p>

            <!-- KEEP THE INTERACTIVE WORD SELECTOR AS IS -->
            <div>
                <h3>Try it yourself: What relates to <span>“music”</span>?</h3>
                <p>
                        Pick any 10 words from the pink box that you think best relate to “music.” There’s no perfect answer—that’s the point.
                    </p>
                <p id="completion-message">
                    Great choices! You’ve captured your unique perspective on music.
                </p>
                
                
            </div>

            

            

<h2>Multiple Meanings as Network Bridges</h2>

            <p>English words often carry multiple meanings, creating natural bridges in the network:</p>

            <div>
                <div>
                    <h3>Double Meanings</h3>
                    <p>Words with entirely different definitions: “bass” (sound/fish), “tear” (eye/rip)</p>
                </div>
                <div>
                    <h3>Related Meanings</h3>
                    <p>Connected definitions: “head” as body part, leadership role, or ship’s bow</p>
                </div>
                <div>
                    <h3>Contextual Flavors</h3>
                    <p>“Hiking” as nature experience vs. physical exercise</p>
                </div>
            </div>

            <p>These multi-sense words create semantic bridges between seemingly unrelated concepts. Words like “ground” can connect earth, coffee, and electrical circuits in a single conceptual leap.</p>


<!-- new about semantic bridges --> 

            <p>You’d think words with multiple meanings would connect distant parts of the network faster. Turns out they don’t—they just give you more creative ways to navigate the same distance. Our analysis of 100k homograph-containing paths shows they average 6.57 hops versus the 6.43 random baseline. Instead of creating shortcuts, they exist in densely connected regions, offering creative routing options rather than efficiency gains.</p>

            <h3>The Bridges That Remain </h3>

            <p>To prevent too many paths from routing through generic hubs like “general” or “study,” we systematically penalized superconnectors throughout our workflow. But which words still emerge as natural bridges after this filtering?</p>

            <div>
                <h3>
                    Try it yourself: Explore the <span>bridges</span> that survived
                </h3>
                <p>
                    After filtering out generic connectors, which words still bridge English's network?
                </p>
                
                <p><label for="bridge-slider">
                        Showing bridges ranked <span id="slider-range">1-2</span>
                    </label>
                    
                </p>
                
                
            </div>

            

            

            <p>These survivors represent genuine conceptual bridges—words that naturally connect different domains through polysemy (“polish” as verb/nationality), historical significance (“Renaissance”), or conceptual richness (“jazz” connecting musical techniques, cultural movements, and time periods). Their average position of ~2.2 hops from path origins shows they typically serve as the critical pivot point between disparate concepts.</p>

<!-- -->

            
            <p>So where did we get our data?</p>




            <h2>Five Data Sources</h2>

            <div>
<!--
                <img src="images/knowledge-sources.jpg" 
                     alt="A visualization of the five knowledge sources combining into the Linguabase"
                     style="width: 100%; height: auto; border-radius: 16px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);">
-->
<picture>
    <source type="image/webp" srcset="https://www.inotherwords.app/linguabase/images/resized/webp/knowledge-sources_std.webp 1x,
                    https://www.inotherwords.app/linguabase/images/resized/webp/knowledge-sources_retina.webp 2x">
    <source type="image/jpeg" srcset="https://www.inotherwords.app/linguabase/images/resized/knowledge-sources_std.jpg 1x,
                    https://www.inotherwords.app/linguabase/images/resized/knowledge-sources_retina.jpg 2x">
    <img src="https://www.inotherwords.app/linguabase/images/resized/knowledge-sources_std.jpg" alt="A visualization of the five knowledge sources combining into the Linguabase" loading="lazy">
</picture>

                <p>
                    The Linguabase integrates five complementary knowledge sources into a unified semantic network.
                </p>
            </div>

            <p>The Linguabase integrates five complementary knowledge sources, each contributing unique strengths to our amalgam scoring system that uses multiple ranking signals—from word frequency and co-occurrence patterns to manually curated relationship scores:</p>

            <h3>1. In-House Lexicographic Work</h3>
            <p>Our lexicographer and a team of freelance grad students manually created specialized word lists for 5k varied topics, and associations for polysemous terms and word types like interjections that traditional lexicography treats as “stopwords.” These lists cover many of the most important common terms with multiple meanings.</p>


<!-- Visual 4: LLM Generation vs Recognition -->
<div>
    <h4>LLM Generation vs. Recognition</h4>
    <div>
        <div>
            <h5>Generation Mode</h5>
            <p>“What relates to schizophrenia?”</p>
            <p>
                → hallucinations<br>
                → delusions<br>
                → antipsychotics<br>
                → psychiatry<br>
                <span>[safe, clinical terms only]</span>
            </p>
        </div>
        <div>
            <h5>Recognition Mode</h5>
            <p>“Is ‘shamanism’ related?”</p>
            <p>
                → Yes, through cultural<br>
                &nbsp;&nbsp;interpretations of<br>
                &nbsp;&nbsp;hearing voices<br>
                → Historical contexts<br>
                <span>[nuanced connection validated]</span>
            </p>
        </div>
    </div>
</div>



            <h3>2. Mining 125 Years of Library Wisdom</h3>
<p>We discovered that LLMs are much better at recognizing valid semantic relationships than generating them from scratch. Ask an LLM “What relates to coffee?” and you’ll get predictable answers: beverage, caffeine, morning. But the <a href="https://www.loc.gov/catdir/cpso/lcco/">Library of Congress classification system</a> revealed that ‘coffee’ appears in 2,542 different book classifications—linking to ‘fair trade certification’ in economic texts, ‘coffee berry borer’ in Hawaiian agriculture books, and ‘import-export tariffs’ in 487 trade policy publications. These connections capture how coffee actually intersects with global commerce, agriculture, and regulation.</p>

<!-- Visual 2: Coffee's 2,542 Contexts -->
<div>
    <h4>Coffee’s 2,542 Library Contexts</h4>
    <div>
        <div>
            <p>487</p>
            <p>Economics</p>
            <p>fair trade, tariffs, commodity markets</p>
        </div>
        <div>
            <p>312</p>
            <p>Agriculture</p>
            <p>berry borer, arabica, soil</p>
        </div>
        <div>
            <p>208</p>
            <p>Culture</p>
            <p>café society, coffeehouse politics</p>
        </div>
        <div>
            <p>89</p>
            <p>Chemistry</p>
            <p>caffeine extraction, roasting</p>
        </div>
    </div>
    <p>
        + 1,446 more classifications across history, law, art, medicine...
    </p>
</div>


<p>Since 1897, LOC catalogers have encoded the intellectual connections between 17 million books, creating what’s essentially a 125-year collaborative knowledge graph built by thousands of subject experts. Each classification represents a moment when a human expert decided “these concepts belong together”—and unlike web text, these decisions were expensive and permanent, made before SEO or engagement metrics existed.</p>

<!-- Visual 5: Expert Curation vs Crowd Wisdom -->
<div>
    <h4>Expert Curation vs. Crowd Wisdom</h4>
    <div>
        <div>
            <h5>Web Text</h5>
            <div>
                <p>“Coffee is life! ♥”</p>
                <p>(1 million tweets)</p>
            </div>
            <p>↓</p>
            <p>
                coffee → morning<br>
                coffee → tired<br>
                coffee → addiction
            </p>
        </div>
        <div>
            <h5>LOC Classifications</h5>
            <div>
                <p>“Coffee industry—Labor—Guatemala”</p>
                <p>(47 scholarly books)</p>
            </div>
            <p>↓</p>
            <p>
                coffee → fair trade<br>
                coffee → cooperatives<br>
                coffee → child labor
            </p>
        </div>
    </div>
</div>




<p>We gave an LLM a focused task: generate word lists for each of LOC’s 648,460 classifications. A classification like “Hawaiian coffee trade” triggered specific, expert-like outputs: “kona coffee, arabica beans, coffee tariffs, pacific trade routes, coffee auctions”—far richer than asking generically about coffee. Each classification acted as a pre-engineered prompt that specified exactly which semantic neighborhood we wanted. “Schizophrenia—medical aspects” surfaced “atypical antipsychotic, dopamine antagonist,” while “Schizophrenia—fiction” yielded “asylum writings, trauma memoirs, neurodivergent voices,” capturing the full dimensionality of concepts.</p>

<!-- Visual 6: Context Matters - Schizophrenia -->
<div>
    <h4>Context Shapes Connections: Schizophrenia</h4>
    <div>
        <div>
            <h5>Medical Context</h5>
            <div>
                <p>
                    dopamine antagonist<br>
                    atypical antipsychotic<br>
                    serotonin antagonist<br>
                    bipolar disorder<br>
                    clinical trials
                </p>
            </div>
        </div>
        <div>
            <h5>Fiction Context</h5>
            <div>
                <p>
                    asylum writings<br>
                    trauma memoirs<br>
                    neurodivergent voices<br>
                    madness in literature<br>
                    unreliable narrator
                </p>
            </div>
        </div>
    </div>
</div>



<p>The real magic came from inverting the index. When we asked “Which classifications contain ‘algorithm’?” we found it appearing not just in computer science but in “aleatory electronic music” (alongside John Cage and stochastic processes), “mathematics in arts” (with fractals and Fibonacci sequences), and “investment mathematics” (with portfolio optimization). The system surfaced connections that require domain expertise: ‘Las Vegas’ linking to ‘Colorado River water rights’ through 12 books about Nevada’s water crisis, or ‘origami’ connecting to ‘shell structures’ and ‘stress analysis’ through engineering texts on deployable structures.</p>

<!-- Visual 1: The Double Inversion Process -->
<div>
    <h4>The Double Inversion Process</h4>
    <div>
        <div>
            <p>STEP 1: Classification → Terms</p>
            <p>
                “Hawaiian coffee trade” → kona, arabica, tariffs, pacific routes...
            </p>
        </div>
        <p>↓</p>
        <div>
            <p>STEP 2: Which terms co-occur with “algorithm”?</p>
            <p>
                Found with: John Cage, fractals, portfolio optimization...
            </p>
        </div>
        <p>↓</p>
        <div>
            <p>STEP 3: Build co-occurrence network</p>
            <p>
                algorithm → stochastic music (8.4) | Fibonacci (7.2) | fractals (6.8)
            </p>
        </div>
    </div>
</div>



<p>This approach gave us 3.1 million unique terms weighted by intellectual effort—a monograph on ‘bank equipment’ that mentions ‘pneumatic tubes’ (still used in 15 classifications!) counts more than casual blog mentions. Terms like “cultural heritage” appearing in 53,833 classifications became superconnectors we could appropriately down-rank, while preserving the “boring but essential” connections found in specialized journals like “sewer pipe periodicals” that link urban infrastructure to public health.</p>

<!-- Visual 7: Superconnector Deprecation -->
<div>
    <h4>Superconnector Term Penalties</h4>
    <div>
        <div>
            <p>cultural heritage</p>
            
            <p>
                53,833 × 0.15
            </p>
        </div>
        <div>
            <p>local governance</p>
            
            <p>
                44,507 × 0.26
            </p>
        </div>
        
        <div>
            <p>pneumatic tubes</p>
            
            <p>
                15 × 0.95
            </p>
        </div>
    </div>
    <p>
        Higher frequency → Lower multiplier → Pushed down in rankings
    </p>
</div>





<p>The process also revealed what we call the “Montreal effect”—where ‘bagels’ incorrectly associates with ‘Expo 67,’ ‘McGill University,’ and ‘French-speaking’ simply because Montreal is famous for its bagels. Our initial algorithm strengthened these geographic contaminations throughout the data. We resolved these spurious connections through subsequent LLM reviews that could distinguish true semantic relationships (“bagels → boiled dough → chewy texture”) from coincidental geographic co-occurrence (“bagels → Montreal Canadiens”).</p>

<!-- Visual 3: The Montreal Effect -->
<div>
    <h4>The Montreal Effect: Geographic Contamination</h4>
    <div>
        <div>
            <h5>❌ Geographic Co-occurrence</h5>
            <div>
                <p>Bagels ↔ Expo 67</p>
                <p>Bagels ↔ McGill University</p>
                <p>Bagels ↔ Montreal Canadiens</p>
                <p>Bagels ↔ French-speaking</p>
            </div>
        </div>
        <div>
            <h5>✓ True Semantic Relations</h5>
            <div>
                <p>Bagels ↔ boiled dough</p>
                <p>Bagels ↔ Jewish cuisine</p>
                <p>Bagels ↔ sesame seeds</p>
                <p>Bagels ↔ chewy texture</p>
            </div>
        </div>
    </div>
</div>




            <h3>3. Human-Curated Resources</h3>
            <p>Over 70 existing references contributed—dictionaries, thesauri, and encyclopedias from Wiktionary and WordNet to specialized resources like NASA’s thesaurus and the National Library of Medicine’s UMLS. Relationships appearing across multiple sources received higher weights. </p>
            
            <div>
                <div>
                    <h3>General Sources</h3>
                    <ul>
                        <li>Wiktionary</li>
                        <li>WordNet, ConceptNet, FrameNet</li>
                        <li>Roget’s Thesaurus</li>
                        <li>SWOW-EN18</li>
                    </ul>
                </div>
                <div>
                    <h3>Specialized Sources</h3>
                    <ul>
                        <li>Getty Art &amp; Architecture</li>
                        <li>NASA Thesaurus</li>
                        <li>UMLS Metathesaurus</li>
                        <li>AGROVOC Thesaurus</li>
                    </ul>
                </div>
            </div>

<h3>4. Pre-LLM Topic Extraction</h3>

<p> Before the rise of modern LLMs, we applied Latent Dirichlet Allocation (LDA) in 2013-2014 to discover eight context clusters for every headword in an in-house corpus of notable literary works. The algorithm scans large text collections and groups words that appear in similar contexts. Running it took 200,000 super-computer hours on the NSF’s Extreme Science and Engineering Discovery Environment (XSEDE)—decades on a single machine. Results were noisy: a delightful mix of intuitive associations and oddities (often caused by treating compound terms as separate words). Still, the run surfaced relationships that pure frequency analysis and today’s LLMs miss.
</p>

<p>We skipped early word-embedding vectors—numeric coordinates that place context-similar words near one another but merge all senses into one point—because, as games like <a href="https://www.inotherwords.app/semantic-games/">Semantle</a> show, their distances rarely match human intuition. We also evaluated word embeddings but their single-vector-per-word approach couldn’t handle our need for multiple senses—a fundamental limitation that various researchers tried to patch.<sup>5</sup></p>


            <h3>5. Large Language Model Enhancement</h3>
        
<p>Starting in 2023, frontier models finally provided the semantic understanding we needed—they could distinguish “bank” (river) from “bank” (money) and generate contextually appropriate associations for each. These models could handle:</p>
            <ul>
                <li>Everyday compound terms (“apple pie”, “department store”)</li>
                <li>Morphological variations across parts of speech</li>
                <li>Contextual dimensions of common words</li>
                <li>Capitalization distinctions (“China” vs. “china”)</li>
            </ul>

<p>Still, left to their own devices, LLMs are banal and formulaic, wallowing in cliche, latching onto what they think prompts intend. We ran over 80 million API calls (~$200k in Azure API costs, with minor xAi costs) across dozens of workflows to combat this tendency. Beyond the LOC classifications, we applied focused-prompt strategies across our entire corpus: extracting distinct senses for each headword, generating contextual word lists per sense, prompting for cultural variations and regional differences. Each workflow fed into the next—outputs from sense detection became inputs for association generation, which informed cultural expansion passes. The key was always the same: constrained, specific prompts yielded far better results than open-ended queries.</p>

<p>Even with careful prompting, the Montreal effect persisted. Geographic contamination appeared throughout: ‘Broadway’ linked to ‘taxis’ through New York; ‘grits’ to ‘jazz’ through the American South. We resolved these spurious connections through iterative LLM reviews that learned to distinguish true semantic relationships from coincidental geographic co-occurrence. This research and computational scale was made possible by $295k NSF SBIR seed funding (#2329817) and $150k Microsoft Azure compute resources.</p>


            <h2>Understanding Our Biases</h2>

            <p>Every semantic network encodes particular worldviews about which words relate to each other and how strongly they connect. Here are six key sources of bias that shape our network’s rankings and inclusions:</p>

            <div>
                <table>
                    <tbody><tr>
                        <th>Editorial Choices</th>
                        <th>AI Training Data</th>
                    </tr>
                    <tr>
                        <td>
                            Our lexicographer and team manually crafted relationships for common polysemous terms, inevitably encoding their linguistic backgrounds, cultural contexts, and conceptual frameworks about how meaning connects.
                            <em>Examples: “market” → includes “variety” and “retail,” omits “souk,” “bazaar” • “breakfast” → includes “cereal,” “toast,” omits “congee,” “idli” • “music” → includes “jazz,” “consonance,” omits “gamelan,” “qawwali”</em>
                        </td>
                        <td>
                            GPT-4o’s training data shapes its semantic associations, while its guardrails suppress certain connections. We supplemented with Grok-3 specifically for vulgar and offensive terms that GPT-4o wouldn’t adequately cover.
                            <em>Examples: “sex” → clinical terms favored over colloquial language • “death” → euphemisms like “passing” prioritized over direct terms like “corpse,” “decay”</em>
                        </td>
                    </tr>
                    <tr>
                        <th>Superconnector Deprecation</th>
                        <th>Prompting Cascades</th>
                    </tr>
                    <tr>
                        <td>
                            No matter how a large thesaurus is constructed, certain terms seem to be ubiquitous. This is partially author bias, partially natural language structure, and worse with repetitive LLMs. We down-rank ubiquitous words like “heritage” and “surname”—a low-key version of inverse-frequency normalization. Our graduated penalty system scores 59,112 terms with an inverse document frequency (IDF) variant that down-ranks common terms (1-18). Surprisingly, penalty correlates with conceptual breadth, not raw frequency: “heritage” (penalty 18) appears only 201 times, while “tourism” (penalty 14) appears 8,520 times.
                            <em>Examples: At one processing stage, 2 words get maximum penalty (18): “surname” and “heritage” • 46,445 words get minimal penalty (1) • “heritage” can connect to almost anything cultural, historical, or traditional</em>
                        </td>
                        <td>
                            Our multi-pass LLM workflow (listing senses → expanding culturally → reprocessing) introduces systematic preferences that affect both what gets included and how highly it ranks.
                            <em>Examples: Geographic diversity emphasized, so “dance” includes global forms equally • Cultural foods given comparable rankings to Western staples</em>
                        </td>
                    </tr>
                    <tr>
                        <th>Frequency ≠ Importance</th>
                        <th>Morphological and Similarity Filters</th>
                    </tr>
                    <tr>
                        <td>
                            Frequency is a useful but flawed proxy for word importance. It captures actual usage but creates artifacts: ‘pandas’ outranking ‘panda,’ ‘cheesecake’ outranking ‘cheesecakes,’ literary corpora overweighting ‘thee,’ technical terms underrepresented. Different corpora (books vs. screenplays) produce subtly different hierarchies, and none capture a word’s actual utility for learners or gameplay.
                            <em>Examples: “pandas” plural outranks “panda” • “thee” elevated by Shakespeare • “cheesecake” singular is more common than “cheesecakes” • Literary bias from <a href="https://books.google.com/ngrams/info">Google N-grams</a></em>
                        </td>
                        <td>
                            Nobody wants word clouds full of plurals and variants. Our filter pushes ‘baguettes’ down 30 positions if ‘baguette’ already appears, ‘rolls’ down 23 if ‘roll’ exists (&gt;90% string similarity gets +12 penalty, plural/singular differences +17, reordered compounds +17). Length penalties also apply progressively.
                            <em>Examples: In “bagels” - “baguette” drops 30 positions because “baguettes” appears earlier • “roll” drops 23 positions when “rolls” is present • Singular forms consistently cascade downward when plurals exist</em>
                        </td>
                    </tr>
                </tbody></table>
            </div>

            <p>These biases shape which connections appear, how strongly they’re weighted, and where they rank in each word cloud. We’ve made deliberate choices to create a semantic network optimized for engaging gameplay—favoring conceptual diversity over raw frequency, meaningful connections over statistical noise. The Linguabase represents one coherent mapping of English’s semantic landscape, designed to reveal the surprising paths that connect all words.</p>

            <h2>How Network Properties Enable Gameplay</h2>

            <p>The mathematical properties of our semantic network create natural game parameters:</p>

            <div>
                <p><span>17</span>
                    <span>Word choices per hop<br>(curated from top 40)</span>
                </p>
                <p><span>7</span>
                    <span>Maximum path length<br>(hops)</span>
                </p>
                <p><span>3</span>
                    <span>Minimum puzzle distance<br>(hops)</span>
                </p>
                <p><span>27</span>
                    <span>Genius solutions per puzzle<br>(3³ optimal paths)</span>
                </p>
            </div>

            <p>We tested various difficulties and settled on 3-7 hops. Below 3 felt trivial; above 7, players gave up. The 3-hop puzzles naturally yield 27 solutions when we maintain 3 strong choices per step.</p>

            <p>For virtually any common word selected as a puzzle origin, there are ~370 million outward paths within 7 hops (about 10% less than the 17&amp;sup7;=410 million theoretical maximum due to natural graph loops). Within those paths, only 200k-1 million reach the target—a random success rate of 0.05-0.27%. Players succeed at much higher rates because they navigate semantically rather than randomly. Our puzzles are engineered to ensure at least 3 good choices per hop, creating exactly 27 optimal three-hop “Genius” solutions (3³ paths).</p>

            <div>
                <div>
                    <h4>Theoretical Maximum (if no word overlap)</h4>
                    <pre>3 hops: 17³ = 4,913 paths
4 hops: 17&amp;sup4; = 83,521 paths  
5 hops: 17&amp;sup5; = 1,419,857 paths
6 hops: 17&amp;sup6; = 24,137,569 paths
7 hops: 17&amp;sup7; = 410,338,673 paths</pre>
                </div>
                <div>
                    <h4>Measured Reality (with semantic overlap)</h4>
                    <pre>Total paths: ~370 million (90% of theoretical)
Winning paths: 200k-1 million
Beyond game limit: ~94% require 8+ hops</pre>
                </div>
            </div>

            <p>
                Curious how we transformed this linguistic database into a daily word game? Read <a href="https://www.inotherwords.app/making/">Making the Game</a> to discover how we found the perfect game mechanic and balanced the difficulty.
            </p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Code Is My Computer (107 pts)]]></title>
            <link>https://steipete.me/posts/2025/claude-code-is-my-computer</link>
            <guid>44170967</guid>
            <pubDate>Tue, 03 Jun 2025 15:14:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steipete.me/posts/2025/claude-code-is-my-computer">https://steipete.me/posts/2025/claude-code-is-my-computer</a>, See on <a href="https://news.ycombinator.com/item?id=44170967">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <img src="https://steipete.me/assets/img/2025/claude-code-is-my-computer/hero.png" alt="" loading="lazy"> <p><strong>TL;DR</strong>: I run Claude Code in no-prompt mode; it saves me an hour a day and hasn’t broken my Mac in two months. The $200/month <a href="https://steipete.me/posts/2025/stop-overthinking-ai-subscriptions/">Max plan</a> pays for itself.</p>
<p>For the past two months, I’ve been living dangerously. I launch <a href="https://claude.ai/code">Claude Code</a> (<a href="https://www.anthropic.com/news/claude-3-7-sonnet">released in late February</a>) with <code>--dangerously-skip-permissions</code>, the flag that bypasses all permission prompts. According to <a href="https://docs.anthropic.com/en/docs/claude-code">Anthropic’s docs</a>, this is meant “only for Docker containers with no internet”, yet it runs perfectly on regular macOS.</p>
<p>Yes, a rogue prompt could theoretically nuke my system. That’s why I keep hourly <a href="https://www.arqbackup.com/">Arq</a> snapshots (plus a <a href="https://www.shirt-pocket.com/SuperDuper/SuperDuperDescription.html">SuperDuper!</a> clone), but after two months I’ve had zero incidents.</p>
<h2 id="from-ai-assistant-to-everything-terminal">From ‘AI assistant’ to everything terminal</h2>
<p>When I first installed Claude Code, I thought I was getting a smarter command line for coding tasks. What I actually got was a universal computer interface that happens to run in text. The mental shift took a few weeks, but once it clicked, I realized Claude can literally do anything I ask on my computer.</p>
<p>The breakthrough moment came when I was migrating to a new Mac. Instead of doing the usual restore dance, I pointed Claude at my backup disk and said: “Restore this Mac from my backup disk—start with dotfiles, then system preferences, CLI tools, and restore Homebrew formulae and global npm packages.” Claude drafts a migration plan, executes it step by step, and has my new machine ready in under an hour.<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup></p>
<h2 id="what-i-actually-use-it-for">What I actually use it for</h2>
<p>My daily Claude Code usage falls into several main outcomes:</p>
<p><strong>Ship Content</strong>: “Convert ~40 posts from Jekyll to MDX format here. Make sure to copy over the images and preserve the redirects.” Twenty minutes later, Claude had processed every single post, set up proper redirects, validated all image paths, and pushed a merge-ready branch.</p>
<p><strong>Extract Features</strong>: “Extract this feature into a Swift project” (that’s how I released <a href="https://steipete.me/posts/2025/introducing-demark-html-to-markdown-in-swift/">Demark</a>) where Claude creates the package structure, writes tests, documentation, and handles the entire open-source release process.</p>
<p><strong>Automate Content</strong>: Like this very post. I use <a href="https://wisprflow.ai/">Wispr Flow</a> to talk with Claude, explain the topic and tell it to read my past blog posts to write in my style. Instead of wrestling with Markdown formatting, Claude creates the document, helps formulate thoughts, and tests that everything displays correctly.</p>
<p><strong>Generate Test Data</strong>: “<a href="https://x.com/steipete/status/1923897903698887036">Create seed data for a project</a>” turns into Claude analyzing my codebase, understanding the data models, and generating realistic test data with proper relationships.</p>
<p><strong>Ship Code</strong>: I haven’t typed <code>git commit -m</code> in weeks. Instead, I say “commit everything in logical chunks” and Claude handles the entire flow—staging changes, writing meaningful commit messages, pushing, opening PRs, watching CI, and fixing any CI failures. When builds break, it analyzes the errors and patches them automatically. It’s also extremely good at resolving merge conflicts.</p>
<p><strong>Clean the OS</strong>: “Hide recent apps in the Dock” becomes a single natural language command instead of Googling for the right <code>defaults write</code> incantation. Claude knows macOS internals and happily calls <code>killall Dock</code> to restart the Dock after modifying the plist.</p>
<p><strong>Spin Up New Machines</strong>: Recently when setting up <a href="https://www.codelooper.app/">CodeLooper’s</a> code signing and notarization, Claude handled installing Homebrew packages, creating private keys, adding them to the keychain, creating backups, building the project, uploading to GitHub, running tests, and monitoring the process. The only manual part was clicking through the update UI, but with my <a href="https://github.com/steipete/macos-automator-mcp">macOS Automator MCP Server</a>, I could probably teach it that too.</p>
<p>I use an alias in my shell config<sup><a href="#user-content-fn-2" id="user-content-fnref-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> so just typing <code>cc</code> runs Claude with the permission flag.</p>
<h2 id="why-this-works-and-when-it-doesnt">Why this works (and when it doesn’t)</h2>
<p>Claude Code shines because it was built command-line-first, not bolted onto an IDE as an afterthought. The agent has full access to my filesystem (if you are bold enough…), can execute commands, read output, and iterate based on results.</p>
<p>Anthropic’s <a href="https://www.anthropic.com/engineering/claude-code-best-practices">best practices guide</a> recommends keeping a <code>CLAUDE.md</code> file at your repo root with project-specific context. I’ve adopted this pattern and noticed Claude asks fewer clarifying questions and writes more accurate code. Little optimizations like this compound quickly.</p>
<p>The main limitation is response time. Claude’s thinking process takes a few seconds, and for rapid-fire debugging sessions, I sometimes reach for traditional tools. However, you can prefix commands with <code>!</code> to run them directly without waiting for token evaluation—Claude will execute your command either way, but this is faster when you know exactly what you’re calling. For exploratory work where I’m not sure what I need, Claude’s reasoning ability more than compensates for the brief pause.</p>
<h2 id="why-warp-lacks">Why Warp lacks</h2>
<p><a href="https://www.warp.dev/">Warp’s</a> mission is to “reinvent the command line with AI”. They’ve built beautiful GPU-accelerated panels and smart autocomplete.</p>
<p>The fundamental difference comes down to trust and execution flow. Claude operates purely through text and is remarkably intelligent about understanding context and intent. With this setup, I can pre-authorize Claude to execute commands without constant confirmation prompts. Warp, while excellent, requires individual approval for each command—there’s no equivalent to Claude’s “dangerous mode” where you can grant blanket execution trust. This means Claude maintains conversational flow while Warp still interrupts with permission requests.</p>
<p>I signed up for Warp because I like their mission and I hope they eventually go where Claude is. But it seems they have a fundamentally different idea about safety. Also, <a href="https://ghostty.org/">Ghostty</a> is just the better command line, native, not Electron-based and faster.</p>
<h2 id="where-this-is-heading">Where this is heading</h2>
<p>We’re in the very early days of AI-native development tools. Claude Code represents a paradigm shift: from tools that help you run commands to tools that understand intent and take action. I’m not just typing commands faster—I’m operating at a fundamentally higher level of abstraction. Instead of thinking “I need to write a bash script to process these files, chmod it, test it, debug it,” I think “organize these files by date and compress anything older than 30 days.”</p>
<p>This isn’t about AI replacing developers—it’s about developers becoming orchestrators of incredibly powerful systems. The skill ceiling rises: syntax fades, system thinking shines.</p>
<h2 id="should-you-try-this">Should you try this?</h2>
<p>If you’re comfortable with calculated risks and have solid backups, absolutely. The learning curve is essentially zero—you just start talking to your computer like it’s a competent colleague. Within days, you’ll wonder how you ever worked without it.</p>
<p>Your computer isn’t just a computer anymore. It’s Claude. And Claude is absurdly capable.</p>
<hr>
<p>Got a crazier Claude workflow? Ping me <a href="https://twitter.com/steipete">@steipete</a>.</p>
<section data-footnotes="">
<ol>
<li id="user-content-fn-1">
<p>Note that full backup migrations can sometimes cause <a href="https://discussions.apple.com/thread/255759421">various system issues</a> with newer macOS versions. <a href="#user-content-fnref-1" data-footnote-backref="" aria-label="Back to reference 1">↩</a></p>
</li>
<li id="user-content-fn-2">
<p><code>alias cc="claude --dangerously-skip-permissions"</code> <a href="#user-content-fnref-2" data-footnote-backref="" aria-label="Back to reference 2">↩</a></p>
</li>
</ol>
</section> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Builder.ai Collapses: $1.5B 'AI' Startup Exposed as 'Indians' (338 pts)]]></title>
            <link>https://www.ibtimes.co.uk/builderai-collapses-15bn-ai-startup-exposed-actually-indians-pretending-bots-1734784</link>
            <guid>44169759</guid>
            <pubDate>Tue, 03 Jun 2025 13:17:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ibtimes.co.uk/builderai-collapses-15bn-ai-startup-exposed-actually-indians-pretending-bots-1734784">https://www.ibtimes.co.uk/builderai-collapses-15bn-ai-startup-exposed-actually-indians-pretending-bots-1734784</a>, See on <a href="https://news.ycombinator.com/item?id=44169759">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The tech world is reeling from revelations that Builder.ai, once hailed as a $1.5 billion (£1.11 billion), 'AI' powerhouse, now faces scrutiny as its highly promoted artificial intelligence facade crumbles, revealing a human-powered operation behind the cutting-edge AI automation.</p><p>Builder.ai, the British no-code AI startup that once garnered acclaim for its strategic partnership with <a href="https://www.ibtimes.co.uk/microsoft-slammed-banning-palestine-gaza-genocide-internal-emails-amid-israel-ties-1734312" target="_blank" rel="noopener">Microsoft</a> and secured a $250 million (£184.64 million) investment led by the Qatar Investment Authority, <a rel="noopener nofollow" href="https://www.linkedin.com/posts/builderai_today-engineerai-corporation-known-as-activity-7330581919031521280-w7hu/" target="_blank">declared</a> Tuesday that it is initiating bankruptcy protection.</p><p>As reported by <a rel="noopener nofollow" href="https://www.bloomberg.com/news/articles/2025-05-20/microsoft-backed-builder-ai-to-enter-insolvency-proceedings" target="_blank">Bloomberg</a>, the company's dramatic decline occurred after a key lender, Viola Credit, withdrew $37 million (£27.33 million) from its accounts, leaving a mere $5 million (£3.69 million) in restricted funds and effectively paralysing operations in five nations.</p><p>Earlier this year, CEO Manpreet Ratia took over from founder Sachin Dev Duggal in a boardroom shake-up designed to restore investor confidence. Ratia has since stated that most of the company's workforce has been laid off. As Bloomberg reports, Builder.ai will now commence bankruptcy filings in its operational territories, including the UK, US, UAE, Singapore, and India.</p><h2>Builder.ai's $450 Million Funding: Big Names, Big Promises</h2><p>Launched in 2016, Builder.ai presented itself as a groundbreaking platform, allowing businesses to create customised applications with minimal coding, leveraging <a href="https://www.ibtimes.co.uk/artificial-intelligence" target="_blank" rel="noopener">artificial intelligence</a>. As reported by Bloomberg, the company accumulated over $450 million (£332.36 million) in total funding, drawing in prominent investors such as <a href="https://www.ibtimes.co.uk/topics/microsoft" data-sys="1">Microsoft</a>, the World Bank's IFC, Jeffrey Katzenberg's WndrCo, Lakestar, and SoftBank's DeepCore incubator.</p><p>Less than two months ago, Builder.ai admitted to revising down core sales numbers and engaging auditors to inspect its financials for the past two years. This came amidst concerns from former employees who suggested sales performance had been inflated during prior investor briefings.</p><h2>'Bots' Revealed As Builders From India</h2><p>Bloomberg notes that these allegations initiated a cascade of investor apprehension, internal changes, and an eventual erosion of confidence. Adding to the troubles, Linas Beliūnas, Director of the financial company Zero Hash, recently exposed that Builder.ai lacked true AI, instead utilising a group of Indian developers who were merely pretending to be bots writing code.</p><figure><div><blockquote data-conversation="none"><div lang="en" dir="ltr"><p>😃 The Natasha neural network turned out to be 700 Indian programmers</p><p>The startup BuilderAI offered to write any application, like in a constructor, by selecting the necessary functions.</p><p>In reality, customer requests were sent to the Indian office, where 700 Indians wrote code… <a href="https://t.co/lYWipf63cp">pic.twitter.com/lYWipf63cp</a></p></div>— Bernhard Engelbrecht (@BernhardEngel_) <a href="https://twitter.com/BernhardEngel_/status/1928033488420184450?ref_src=twsrc%5Etfw">May 29, 2025</a></blockquote></div>
</figure><p>'It turns out the company had no AI and instead was just a group of Indian developers pretending to write code as AI,' he wrote in a <a rel="noopener nofollow" href="https://www.linkedin.com/feed/update/urn:li:activity:7334521571966877696/" target="_blank">LinkedIn post</a>. Beliūnas also highlights that Duggal reportedly presented false revenue figures to investors. Remarkably, the company managed to sustain this deception for eight years.</p><h2>Investor Dreams Shattered By Reality</h2><p>The critical moment arrived when Viola Credit, which had provided the company with a $50 million loan in 2023, took control of $37 million (£27.33 million) from its accounts. This action rendered Builder.ai incapable of fulfilling payroll commitments or maintaining essential operations.</p><p>Manpreet Ratia informed Bloomberg that the remaining funds, held in Indian accounts, are inaccessible due to regulatory restrictions.</p><h2>The Broader Impact Of Builder.ai's Collapse</h2><p>The insolvency proceedings at Builder.ai mirror a rising trend of instability within AI startups. Phil Brunkard, an executive counsellor at Info-Tech Research Group, shared with Computer World that many AI companies expanded rapidly, fueled by hype, frequently without robust financial oversight or genuinely unique products.</p><p>'The Qatar Investment Authority (QIA) is one of the biggest losers in this saga. They led a $250 million (£184.68 million) funding round two years ago,' Beliūnas adds.</p><p>Competition regulators are reportedly examining Builder.ai's marketing practices, with potential implications for how AI companies present their capabilities to investors and customers.</p><p>The scandal serves as a stark reminder that whilst artificial intelligence continues advancing rapidly, human expertise remains irreplaceable in many complex technical domains—a lesson that Builder.ai learned through public humiliation rather than honest business practices.</p><p>As the dust settles, the tech industry faces uncomfortable questions about transparency, accountability, and the ethical boundaries of AI marketing in an increasingly sceptical marketplace.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vision Language Models Are Biased (154 pts)]]></title>
            <link>https://vlmsarebiased.github.io/</link>
            <guid>44169413</guid>
            <pubDate>Tue, 03 Jun 2025 12:47:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vlmsarebiased.github.io/">https://vlmsarebiased.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=44169413">Hacker News</a></p>
<div id="readability-page-1" class="page">

<div>
        
        
        

        <p><span><sup>*</sup>Equal contribution                    <sup>†</sup>Equal advising</span><br>
          <span><sup>1</sup>KAIST</span>,
          <span><sup>2</sup>College of William and Mary</span>,
          <span><sup>3</sup>University of Alberta</span>,
          <span><sup>4</sup>Auburn University</span>
        </p>
        
        
      </div>

<div>
        
        <div>
          <!-- MODIFIED: Inline style to reduce top margin -->
          <div>
            <p>
              <strong><i></i> Finding:</strong> State-of-the-art Vision Language Models achieve <span>100%</span> accuracy counting on images of popular subjects (e.g. knowing that the Adidas logo has 3 stripes and a dog has 4 legs) but are only <span>~17%</span> accurate in counting in counterfactual images (e.g. counting stripes in a 4-striped Adidas-like logo or counting legs in a 5-legged dog).
            </p>
            <p>
              <span>VLMs don't actually "see" - they rely on memorized knowledge instead of visual analysis due to bias.</span>
            </p>
          </div>

          <!-- MODIFIED: Added research-figure-medium class -->
          <div>
            <p><img src="https://vlmsarebiased.github.io/static/images/fig1_overview.png" alt="VLM failures across 7 domains" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
            <p>
               VLMs fail on 6 counting tasks (a–e &amp; g) and one low-level vision task (f). State-of-the-art models achieve perfect performance on original images but catastrophically fail when objects are subtly modified, defaulting to memorized knowledge rather than actual visual analysis.
            </p>
          </div>
        </div>

        <div>
          <h2><i></i>The Problem: VLMs Can't Count When It Matters</h2>
          
          <p>
            Imagine asking GPT-4o to count the legs of an animal, and it gets it right every time. Impressive, right? 
            Now imagine adding just <em>one extra leg</em> to that animal and asking again. Suddenly, it fails completely.
          </p>

          <div>
            <h3><i></i> The Dog Experiment</h3>
            <p>
              <strong>Original dog (4 legs):</strong> All models get it right <i></i><br>
              <strong>Same dog with 5 legs:</strong> All models still say "4" <i></i>
            </p>
            <p>
              They're not counting - they're just recalling "dogs have 4 legs" from their training data.
            </p>
          </div>

          <!-- MODIFIED: Added research-figure-medium class -->
          <div>
            <p><img src="https://vlmsarebiased.github.io/static/images/fig3_fail_subtle.png" alt="VLMs fail to detect subtle changes" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
            <p>
              VLMs fail to detect subtle changes in counterfactuals (CF) and default to biased answers. Despite clear visual modifications (extra legs, extra stripes), all models consistently output the expected "normal" values rather than counting what they actually see.
            </p>
          </div>

          <p><strong><i></i> The Core Issue:</strong> VLMs suffer from severe confirmation bias. When they see familiar objects, they default to memorized knowledge instead of performing actual visual analysis. This isn't a minor glitch - it's a fundamental flaw in how these models process visual information.</p>
        </div>

        <div>
          <h2><i></i>How We Test VLM Bias: The VLMBias Framework</h2>
          
          <p>
            Our testing methodology follows a simple but powerful three-step process that exposes the fundamental difference between memorization and actual visual analysis in VLMs.
          </p>

          <!-- MODIFIED: Added research-figure-medium class -->
          <div>
            <p><img src="https://vlmsarebiased.github.io/static/images/teaser-1.png" alt="VLMBias testing framework" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
            <p>
              Given a subject (e.g., Adidas logo), we first confirm that all VLMs have sufficient knowledge about the subject via ID and counting sanity-check questions (a). Then, we test VLMs on the counterfactual image (b) and report accuracy on counting (Q1 &amp; Q2) and Y/N identification tasks (Q3). For all tasks, we test the hypothesis that visual bias cues in the background (c) may be so strong that they cause VLMs to ignore the modified object and default to biased answers.
            </p>
          </div>

          <div>
            <div>
                <h3><i></i> Step 1: Sanity Check</h3>
                <p><strong>Confirm VLMs have the knowledge</strong></p>
                <ul>
                  <li><strong>ID Question:</strong> "What shoe logo is this?" → "Adidas" ✓</li>
                  <li><strong>Counting Question:</strong> "How many stripes?" → "3" ✓</li>
                </ul>
                <p><em>Result: 100% accuracy on original images across all models</em></p>
              </div>
            <div>
                <h3><i></i> Step 2: The Bias Test</h3>
                <p><strong>Test on counterfactual images</strong></p>
                <ul>
                  <li><strong>Q1:</strong> "How many visible stripes?" → "3" ✗ (should be "4")</li>
                  <li><strong>Q2:</strong> "Count the visible stripes" → "3" ✗ (should be "4")</li>
                  <li><strong>Q3:</strong> "Is this the Adidas logo?" → "Yes" ✗ (should be "No")</li>
                </ul>
                <p><em>Result: 17.05% average accuracy - catastrophic failure!</em></p>
              </div>
          </div>

          <p><strong><i></i> The Critical Insight:</strong> The gap between Step 1 (100% accuracy) and Step 2 (17% accuracy) proves that VLMs are not actually "seeing" - they're retrieving memorized associations. When the visual evidence contradicts their training data, they consistently choose memorized knowledge over what's actually in the image.</p>
        </div>

        <div>
          <h2><i></i>Interactive Failure Gallery</h2>
          <p>Explore examples from all 7 domains where state-of-the-art VLMs fail spectacularly.</p>
          
          <div>
  
              <div data-domain="Animals">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/animals_result.png" alt="Dog with 5 legs" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Animals with Extra Legs</p>
                    <p>Models consistently say "2 legs" for 3-legged birds and "4 legs" for 5-legged mammals.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Animals</p>
                  <p><span>Mean Accuracy: 2.12%</span></p><h4>Counting legs in modified animals</h4>
                  <p><strong>Key Finding:</strong> Worst performance domain. Models defaulted to canonical leg counts even when modifications were clearly visible and anatomically plausible.</p>
                </div>
              </div>

              <div data-domain="Logos">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/shoe_logo_result.png" alt="Adidas shoe with 4 stripes" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Modified Shoe Logos</p>
                    <p>Models default to canonical brand specifications even when logos are clearly modified.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Shoe Logos</p>
                  <p><span>Mean Accuracy: 17.57%</span></p><h4>Counting stripes in Adidas shoes and curves in Nike shoes</h4>
                  <p><strong>Key Finding:</strong> Models defaulted to canonical brand specifications. Even when logos were clearly modified and placed in realistic sports contexts, VLMs stuck to memorized brand knowledge.</p>
                </div>
              </div>

              <div data-domain="Logos">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/car_logo_result.png" alt="Audi logo with 5 circles" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Modified Car Logos</p>
                    <p>Car logos appear smaller making VLMs even more reliant on brand memory.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Car Logos</p>
                  <p><span>Mean Accuracy: 0.44%</span></p><h4>Counting circles in Audi and points in Mercedes star</h4>
                  <p><strong>Key Finding:</strong> Worst performance in logos category. Small logo size relative to the vehicle made visual bias even stronger - models completely ignored modifications.</p>
                </div>
              </div>

              <div data-domain="Flags">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/flag_result.png" alt="US flag with modified stars" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Modified National Flags</p>
                    <p>Models memorized flag facts rather than counting visible elements.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> National Flags</p>
                  <p><span>Mean Accuracy: 9.25%</span></p><h4>Counting stripes and stars in modified flags</h4>
                  <p><strong>Key Finding:</strong> Better performance on star counting (11.79%) than stripe counting (4.52%). Stars are spatially separate while stripes are adjacent, making stripe modifications harder to detect.</p>
                </div>
              </div>

              <div data-domain="Chess">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/chess_pieces_result.png" alt="Chess board with 31 pieces" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Modified Chess Starting Position</p>
                    <p>Models defaulted to standard 32-piece count despite pieces being missing.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Chess Pieces</p>
                  <p><span>Mean Accuracy: 26.25%</span></p><h4>Counting pieces on modified starting chess boards</h4>
                  <p><strong>Key Finding:</strong> Best performance counting task, but still heavily biased. Thinking models (o3, o4-mini) significantly outperformed non-thinking models, suggesting explicit reasoning helps detect anomalies.</p>
                </div>
              </div>

              <div data-domain="BoardGames">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/game_board_result.png" alt="10x10 Sudoku grid" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Modified Game Boards</p>
                    <p>Models knew standard dimensions so strongly they couldn't count actual board lines.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Game Boards</p>
                  <p><span>Mean Accuracy: 2.26%</span></p><h4>Counting rows/columns in modified game boards</h4>
                  <p><strong>Key Finding:</strong> Worst overall performance. Models scored 0% on Sudoku and Go boards, confirming fundamental inability to perform basic visual counting in structured settings.</p>
                </div>
              </div>

              <div data-domain="Illusions">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/illusion_result.png" alt="Modified Ebbinghaus illusion" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Modified Optical Illusions</p>
                    <p>VLMs knew illusion patterns but failed when effects were reversed.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Optical Illusions</p>
                  <p><span>Mean Accuracy: 50.87%</span></p><h4>Comparing elements in original vs. modified illusions</h4>
                </div>
              </div>

              <div data-domain="Grids">
                <div>
                  <div>
                    <p><img src="https://vlmsarebiased.github.io/static/images/patterned_grid_result.png" alt="Grid pattern with anomalous cell" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
                  </div>
                  <div>
                    <p>Anomalous Grid Patterns</p>
                    <p>Models prioritized pattern completion over visual counting even in novel contexts.</p>
                  </div>
                </div>
                <div>
                  <p><i></i> Patterned Grids</p>
                  <p><span>Mean Accuracy: 22.44%</span></p><h4>Counting elements in anomalous grid cells</h4>
                  <p><strong>Key Finding:</strong> Even with novel patterns never seen before, VLMs inferred expected values from surrounding cells rather than counting actual elements in the target cell.</p>
                </div>
              </div>

            </div>
        </div>

        <div>
          <h2><i></i>The Bias is Systematic, Not Random</h2>
          <p>When VLMs make errors, they don't make random mistakes. Instead, 75.70% of all errors are "bias-aligned" - meaning they give the expected answer based on prior knowledge rather than what they actually see in the image.</p>
          
          <div>
            <p><img src="https://vlmsarebiased.github.io/static/images/bias-error.png" alt="Bias-aligned errors across domains" onerror="this.style.display='none'; this.nextElementSibling.style.display='flex';"></p>
            <p>
              On counterfactual images, VLMs mostly output answers that match biased choices rather than random errors. This systematic pattern proves models actively ignore visual evidence in favor of memorized knowledge.
            </p>
          </div>

          <p><strong><i></i> This is the smoking gun:</strong> If models were simply bad at vision, we'd expect random errors. Instead, we see systematic bias toward "correct" textbook answers, proving they're overriding visual information with memorized facts.</p>
        </div>

        <div>
          <h2><i></i>All Models Fail Equally</h2>
          <p>We tested five state-of-the-art models. The results are consistently terrible across the board:</p>
          
          <div>
                <table>
                  <caption>
                    All VLMs achieve <span>100%</span> on identification and counting tasks with unmodified images, showing that they fully recognize the original version but fail on the counting questions on the modified images (i.e., counterfactuals) in VLMBias. The mean accuracy of five state-of-the-art VLMs on our seven tasks is <span>17.05%</span>. o4-mini achieves the highest accuracy (20.25%) which however is still low. VLMs with "thinking" capabilities (o4-mini, o3) only slightly outperform non-thinking models (Gemini-2.5 Pro, Sonnet-3.7, GPT-4.1).
                  </caption>
                  <thead>
                    <tr>
                      <th rowspan="2">Model</th>
                      <th colspan="7">Accuracy in counting questions (Q1 &amp; Q2) on counterfactual images (%)</th>
                      <th rowspan="2">Task mean (CF) (%)</th>
                      <th rowspan="2">Task mean (Unmodified) (%)</th>
                    </tr>
                    <tr>
                      <th><i></i> Animal</th>
                      <th><i></i> Logo</th>
                      <th><i></i> Flag</th>
                      <th><i></i> Chess</th>
                      <th><i></i> Board</th>
                      <th><i></i> Illusion</th>
                      <th><i></i> Grid</th>
                    </tr>
                  </thead>
                  <tbody>
                    <tr>
                      <td>Gemini-2.5 Pro</td>
                      <td>0.00</td>
                      <td>1.96</td>
                      <td>10.42</td>
                      <td>26.74</td>
                      <td>2.38</td>
                      <td>49.81</td>
                      <td>20.83</td>
                      <td>16.02</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>Sonnet-3.7</td>
                      <td>0.00</td>
                      <td>2.72</td>
                      <td>13.75</td>
                      <td>9.03</td>
                      <td>1.79</td>
                      <td>54.29</td>
                      <td>34.52</td>
                      <td>16.59</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>GPT-4.1</td>
                      <td>9.52</td>
                      <td>9.07</td>
                      <td>2.50</td>
                      <td>8.68</td>
                      <td>0.00</td>
                      <td>48.61</td>
                      <td>18.75</td>
                      <td>13.88</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>o3</td>
                      <td>0.92</td>
                      <td>7.60</td>
                      <td>5.00</td>
                      <td>42.71</td>
                      <td>2.38</td>
                      <td>50.38</td>
                      <td>20.54</td>
                      <td>18.50</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>o4-mini</td>
                      <td>0.18</td>
                      <td>9.31</td>
                      <td>14.58</td>
                      <td>44.10</td>
                      <td>4.76</td>
                      <td>51.26</td>
                      <td>17.56</td>
                      <td>20.25</td>
                      <td>100.00</td>
                    </tr>
                    <tr>
                      <td>Mean</td>
                      <td>2.12</td>
                      <td>6.13</td>
                      <td>9.25</td>
                      <td>26.25</td>
                      <td>2.26</td>
                      <td>50.87</td>
                      <td>22.44</td>
                      <td>17.05</td>
                      <td>100.00</td>
                    </tr>
                  </tbody>
                </table>
              </div>

          <p><strong><i></i> Key Finding:</strong> 75.70% of all errors were "bias-aligned" - meaning models gave the expected answer based on prior knowledge rather than random mistakes. This proves they're not just bad at vision; they're actively ignoring what they see.</p>
        </div>

        <div>
          <h2><i></i>Why This Matters</h2>
          
          <div>
            <div>
                <h3><i></i> Immediate Concerns</h3>
                <ul>
                  <li><strong>Medical Imaging:</strong> Missing tumors that don't match training patterns.</li>
                  <li><strong>Autonomous Vehicles:</strong> Failing to see modified road signs.</li>
                  <li><strong>Quality Control:</strong> Missing defects in manufactured goods.</li>
                  <li><strong>Security:</strong> Fooled by simple visual modifications.</li>
                  <li><strong>Website/App Control:</strong> If user interfaces change subtly (buttons, layouts, or icons), biased models may fail to perform tasks correctly, unable to adapt to minor visual modifications.</li>
                </ul>
              </div>
            <div>
                <h3><i></i> Deeper Implications</h3>
                <ul>
                  <li><strong>False Confidence:</strong> Models are wrong but certain.</li>
                  <li><strong>Brittleness:</strong> Tiny changes cause complete failure.</li>
                  <li><strong>Training Flaws:</strong> Memorization over understanding.</li>
                  <li><strong>Evaluation Gap:</strong> Benchmarks miss real-world failure modes.</li>
                </ul>
              </div>
          </div>

          <div>
            <h3><i></i> The Bottom Line</h3>
            <p>
              Current VLMs are sophisticated pattern matching systems, not visual reasoning systems. 
              They excel at recognizing familiar patterns but fail catastrophically when those patterns are even slightly modified.
            </p>
          </div>
        </div>

        <div>
          <h2><i></i>What We Tried (That Didn't Work)</h2>
          
          <p>We tested two approaches to help models perform better. Neither worked significantly:</p>
          
          <div>
            <div>
              <h4><i></i> "Double-Check"</h4>
              <p><strong>Prompt:</strong> "Please double-check your answer and give your final answer in curly brackets, following the format above."</p>
              <p><strong>Improvement:</strong> <span>+2.70% (Mean)</span></p>
            </div>
            <div>
              <h4><i></i> "Debiased Prompts"</h4>
              <p><strong>Prompt:</strong> "Do not assume from prior knowledge and answer only based on what is visible in the image."</p>
              <p><strong>Improvement:</strong> <span>+1.87% (Mean)</span></p>
            </div>
          </div>

          <p><strong>Sobering Reality:</strong> Even with explicit instructions to ignore prior knowledge and focus on visual details, models barely improved. The bias is deeply embedded in how they process visual information.</p>
        </div>

        <div>
          <h2><i></i>Adversarial In-Image Text Makes It Even Worse</h2>
          
          <p>Adding subject names directly to images (like "Ebbinghaus illusion") made models even more biased, dropping accuracy by an additional 4.49%.</p>

          <div id="adversarial-text-figure">
            <p><img src="https://vlmsarebiased.github.io/static/images/add_title.png" alt="In-image text example showing Ebbinghaus illusion" onerror="this.style.display='none'; this.parentElement.insertAdjacentHTML('afterbegin', '<div class=\'image-placeholder\'><i class=\'fas fa-image\'></i><div class=\'image-title\'>Ebbinghaus Illusion with Text</div><div class=\'image-description\'>Image showing Ebbinghaus illusion variants with added text labels.</div></div>');"></p><p>
              Original vs. modified versions without (top) and with (bottom) the in-image text ("Ebbinghaus illusion"). Adding text labels makes models more likely to rely on memorized knowledge rather than visual analysis.
            </p>
          </div>

          <div>
            <h3><i></i> Text Labels Increase Bias</h3>
            <p><strong>Effect:</strong> <span>-4.49% accuracy drop</span> when subject names were added to images.</p>
            <p><strong>Worse for thinking models:</strong> o4-mini (-6.56), o3 (-6.41) vs. Sonnet-3.7 (-2.81), GPT-4.1 (-2.67).</p>
            <p>This suggests that more sophisticated reasoning can sometimes amplify bias when textual cues are present.</p>
          </div>
        </div>

        <div>
          <h2><i></i>What Comes Next?</h2>
          
          <div>
            <h3><i></i> Immediate Actions Needed</h3>
            <p>
              The AI community needs to acknowledge that current VLMs have fundamental limitations. 
              We need better evaluation methods that test actual visual reasoning, not just pattern recognition.
            </p>
          </div>

          <div>
            <div>
              <h3><i></i> Research Directions</h3>
              <ul>
                <li>Develop training methods that emphasize visual analysis over memorization.</li>
                <li>Create evaluation benchmarks that test robustness to modifications.</li>
                <li>Build models that can explicitly separate prior knowledge from visual evidence.</li>
                <li>Investigate multi-modal reasoning architectures.</li>
              </ul>
            </div>
            <div>
              <h3><i></i> Practical Solutions</h3>
              <ul>
                <li>Implement uncertainty quantification for visual tasks.</li>
                <li>Develop hybrid systems combining vision models with explicit counting modules.</li>
                <li>Create domain-specific fine-tuning approaches.</li>
                <li>Build better human-AI collaboration interfaces.</li>
              </ul>
            </div>
          </div>
        </div>

        <div>
          <h2><i></i>The Takeaway</h2>
          
          <div>
            <p>VLMs aren't as smart as we thought.</p>
            <p>
              They're incredibly sophisticated at recognizing patterns they've seen before, 
              but they fundamentally lack the ability to perform basic visual analysis when faced with novel variations.
            </p>
          </div>

          <p>
              <strong>This research reveals a critical blind spot in AI development.</strong> 
              As we deploy these systems in high-stakes applications, we must understand their limitations. 
              A model that can describe complex scenes but can't count legs on a modified animal is not truly "seeing" - 
              it's performing very sophisticated pattern matching.
            </p>

          <p>
              "The most dangerous thing about current VLMs isn't that they fail - it's that they fail confidently, 
              giving no indication that they're relying on memorized knowledge rather than actual visual analysis."
            </p>
        </div>

      </div>






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Covert Web-to-App Tracking via Localhost on Android (249 pts)]]></title>
            <link>https://localmess.github.io/</link>
            <guid>44169314</guid>
            <pubDate>Tue, 03 Jun 2025 12:35:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://localmess.github.io/">https://localmess.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=44169314">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="intro">
                
                
                <p><img src="https://localmess.github.io/assets/img/websites-app-ID-sharing.png" alt="Web-to-native ID sharing"></p><p>We disclose a novel tracking method by Meta and Yandex potentially affecting
                    billions of Android users. We found that native Android apps—including <strong>Facebook,
                        Instagram</strong>, and
                    several <strong>Yandex apps including Maps and Browser—silently listen on fixed local
                        ports</strong> for tracking purposes. </p>
                <p>These native Android apps receive browsers' metadata, cookies and commands from
                    the Meta Pixel and Yandex Metrica scripts embedded on thousands of web sites. These JavaScripts load
                    on users' mobile browsers and silently connect with native apps running on the same device through
                    localhost sockets. As native apps access programatically
                    device identifiers like the <a href="https://support.google.com/googleplay/android-developer/answer/6048248">Android
                        Advertising ID (AAID)</a> or handle user identities as in the case
                    of Meta apps, this method effectively allows these organizations to <strong>link mobile
                        browsing sessions and web cookies to user identities</strong>, hence de-anonymizing users'
                    visiting sites embedding their scripts.</p>
                <p>This web-to-app ID sharing method bypasses typical privacy protections such as clearing
                    cookies, Incognito Mode and Android's permission controls. Worse, it opens the door for potentially
                    malicious apps eavesdropping on users’ web activity.
                </p>
                

                <hr>
            </div><div>
            <details id="resources">
                <summary>📁 Additional Resources</summary>
                <p>- Video showing Yandex sending localhost requests. The left window shows a
                    remote debugging inspector window of the browser on the Android phone.
                    The right window shows the screen of the Android phone, with our proof-of-concept app at the top and
                    the browser at the bottom:</p>
                <video controls="" src="https://localmess.github.io/assets/video/Yandex_sending_web_compressed.mp4">Your browser does not
                    support the video tag.</video>
                
                <p>- Video showing Meta Pixel sending localhost STUN requests. The left window
                    shows Wireshark, a program that monitors web traffic.
                    The right window shows the browser visiting a website. Note that the requests only start sending
                    once the page is loaded when emulating a Android phone (Pixel 7)
                    and the breakpoint added to the Facebook script is passed:</p>
                <video controls="" src="https://localmess.github.io/assets/video/FB_sending_web_compressed.mp4">Your browser does not support the video tag.</video>
                <p>- Image showing Meta Pixel parameters for which ports and protocols to
                    contact localhost.</p>
                <img src="https://localmess.github.io/assets/img/fb_pixel_ports.png">
                <p>- Image showing Meta Pixel performing SDP Munging to insert the _fbp cookie
                    value.</p>
                <img src="https://localmess.github.io/assets/img/fb_sdp_munging_red.png">
                <p>- Image showing Meta Pixel using STUN to _pass fbp cookie value to mobile
                    apps.</p>
                <img src="https://localmess.github.io/assets/img/fb_stun.png">
            </details>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I wrote a Java decompiler in pure C language (158 pts)]]></title>
            <link>https://github.com/neocanable/garlic</link>
            <guid>44169132</guid>
            <pubDate>Tue, 03 Jun 2025 12:14:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/neocanable/garlic">https://github.com/neocanable/garlic</a>, See on <a href="https://news.ycombinator.com/item?id=44169132">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">garlic-decompiler</h2><a id="user-content-garlic-decompiler" aria-label="Permalink: garlic-decompiler" href="#garlic-decompiler"></a></p>
<p dir="auto"><a href="http://www.apache.org/licenses/LICENSE-2.0.html" rel="nofollow"><img src="https://camo.githubusercontent.com/3f968974d072844ab3533642e98b8e0e63a3d99efab75ca450e8fca32c4d180f/687474703a2f2f696d672e736869656c64732e696f2f3a6c6963656e73652d6170616368652d626c75652e737667" alt="License" data-canonical-src="http://img.shields.io/:license-apache-blue.svg"></a></p>
<p dir="auto">Java decompiler written in C</p>
<p dir="auto">Tool for produces java source code from .class or jar file</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>decompile .class file</li>
<li>decompile jar file</li>
<li>decompile war file</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build</h3><a id="user-content-build" aria-label="Permalink: Build" href="#build"></a></p>
<p dir="auto"><strong>requirements</strong>: cmake &gt;= <strong>3.26</strong></p>
<p dir="auto"><strong>No other dependencies</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/neocanable/garlic.git
cd garlic
cmake -B build
cmake --build build
./build/garlic"><pre>git clone https://github.com/neocanable/garlic.git
<span>cd</span> garlic
cmake -B build
cmake --build build
./build/garlic</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ul dir="auto">
<li>
<p dir="auto">decompile .class file</p>
<p dir="auto">decompile .class file, default output is <strong>stdout</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="garlic /path/to/jvm.class"><pre>garlic /path/to/jvm.class</pre></div>
</li>
<li>
<p dir="auto">decompile jar file</p>
<div dir="auto" data-snippet-clipboard-copy-content="garlic /path/to/file.jar

garlic /path/to/file.jar -o /path/to/save # -o option is source code output path

garlic /path/to/file.jar -t 5             # -t option is thread count, default is 4"><pre>garlic /path/to/file.jar

garlic /path/to/file.jar -o /path/to/save <span><span>#</span> -o option is source code output path</span>

garlic /path/to/file.jar -t 5             <span><span>#</span> -t option is thread count, default is 4</span></pre></div>
<p dir="auto">default output is same level directory as the file</p>
</li>
<li>
<p dir="auto">javap</p>
<p dir="auto">like javap, more faster, disabled LineNumber and StackMapTable attributes</p>
<div dir="auto" data-snippet-clipboard-copy-content="garlic /path/to/jvm.class -p"><pre>garlic /path/to/jvm.class -p</pre></div>
</li>
<li>
<p dir="auto">dexdump</p>
<div dir="auto" data-snippet-clipboard-copy-content="garlic /path/to/dalvik.dex -p           # unsupport now
"><pre>garlic /path/to/dalvik.dex -p           <span><span>#</span> unsupport now</span>
</pre></div>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Debug</h3><a id="user-content-debug" aria-label="Permalink: Debug" href="#debug"></a></p>
<p dir="auto">in <strong>src/jvm.c</strong>, change main function to:</p>
<div dir="auto" data-snippet-clipboard-copy-content="int main(int argc, char **argv)
{
    jar_file_analyse(path_of_jar, out_of_jar, 1);
    return 0;
}
"><pre><span>int</span> <span>main</span>(<span>int</span> <span>argc</span>, <span>char</span> <span>*</span><span>*</span><span>argv</span>)
{
    <span>jar_file_analyse</span>(<span>path_of_jar</span>, <span>out_of_jar</span>, <span>1</span>);
    <span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto">if thread count less than 2, it will disable multiple thread.</p>
<hr>
<p dir="auto"><em>Licensed under the Apache 2.0 License</em></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta and Yandex are de-anonymizing Android users' web browsing identifiers (378 pts)]]></title>
            <link>https://arstechnica.com/security/2025/06/headline-to-come/</link>
            <guid>44169115</guid>
            <pubDate>Tue, 03 Jun 2025 12:12:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/security/2025/06/headline-to-come/">https://arstechnica.com/security/2025/06/headline-to-come/</a>, See on <a href="https://news.ycombinator.com/item?id=44169115">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2098088">
  
  <header>
  <div>
    

    

    <p>
      Abuse allows Meta and Yandex to attach persistent identifiers to detailed browsing histories.
    </p>

    

    <div>
            <p><a data-pswp-width="2560" data-pswp-height="1440" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1440x810.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg" target="_blank">
              <img width="2560" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg" alt="" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars.jpg 2560w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-2048x1152.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/android-tracking-binoculars-1440x810.jpg 1440w" sizes="(max-width: 2560px) 100vw, 2560px">
            </a></p><div id="caption-2098181">
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
          </div>

    <div>
    
    <p><span>
          Credit:

          
          Aurich Lawson | Getty Images

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Tracking code that Meta and Russia-based Yandex embed into millions of websites is de-anonymizing visitors by abusing legitimate Internet protocols, causing Chrome and other browsers to surreptitiously send unique identifiers to native apps installed on a device, <a href="https://localmess.github.io/">researchers have discovered</a>. Google says it's investigating the abuse, which allows Meta and Yandex to convert ephemeral web identifiers into persistent mobile app user identities.</p>
<p>The covert tracking—implemented in the <a href="https://www.facebook.com/business/tools/meta-pixel/">Meta Pixel</a> and <a href="https://ads.yandex/metrica">Yandex Metrica</a> trackers—allows Meta and Yandex to bypass core security and privacy protections provided by both the Android operating system and browsers that run on it. <a href="https://source.android.com/docs/security/app-sandbox">Android sandboxing</a>, for instance, isolates processes to prevent them from interacting with the OS and any other app installed on the device, cutting off access to sensitive data or privileged system resources. Defenses such <span>as <a href="https://developer.mozilla.org/en-US/docs/Web/Privacy/Guides/State_Partitioning" target="_blank" rel="noopener">state</a></span><a href="https://developer.mozilla.org/en-US/docs/Web/Privacy/Guides/State_Partitioning">&nbsp;partitioning</a> and <a href="https://privacysandbox.google.com/cookies/storage-partitioning">storage partitioning</a>, which are built into all major browsers, store site cookies and other data associated with a website in containers that are unique to every top-level website domain to ensure they're off-limits for every other site.</p>
<h2>A blatant violation</h2>
<p>“One of the fundamental security principles that exists in the web, as well as the mobile system, is called sandboxing,” Narseo Vallina-Rodriguez, one of the researchers behind the discovery, said in an interview. “You run everything in a sandbox, and there is no interaction within different elements running on it. What this attack vector allows is to break the sandbox that exists between the mobile context and the web context. The channel that exists allowed the Android system to communicate what happens in the browser with the identity running in the mobile app.”</p>
<p>The bypass—which Yandex began in 2017 and Meta started last September—allows the companies to pass cookies or other identifiers from Firefox and Chromium-based browsers to native Android apps for Facebook, Instagram, and various Yandex apps. The companies can then tie that vast browsing history to the account holder logged into the app.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>This abuse has been observed only in Android, and evidence suggests that the Meta Pixel and Yandex Metrica target only Android users. The researchers say it may be technically feasible to target iOS because browsers on that platform allow developers to programmatically <a href="https://bugs.webkit.org/show_bug.cgi?id=279249">establish localhost connections</a> that apps can monitor on local ports.</p>
<p>In contrast to iOS, however, Android imposes fewer controls on local host communications and background executions of mobile apps, the researchers said, while also implementing stricter controls in app store vetting processes to limit such abuses. This overly permissive design allows Meta Pixel and Yandex Metrica to send web requests with web tracking identifiers to specific local ports that are continuously monitored by the Facebook, Instagram, and Yandex apps. These apps can then link pseudonymous web identities with actual user identities, even in private browsing modes, effectively de-anonymizing users’ browsing habits on sites containing these trackers.</p>
<p>Meta Pixel and Yandex Metrica are analytics scripts designed to help advertisers measure the effectiveness of their campaigns. Meta Pixel and Yandex Metrica are estimated to be installed on <a href="https://trends.builtwith.com/websitelist/Facebook-Pixel%20">5.8 million</a> and <a href="https://trends.builtwith.com/analytics/Yandex-Metrika">3 million</a> sites, respectively.</p>
<p>Meta and Yandex achieve the bypass by abusing basic functionality built into modern mobile browsers that allows browser-to-native app communications. The functionality lets browsers send web requests to local Android ports to establish various services, including media connections through the <a href="https://en.wikipedia.org/wiki/Real-time_communication">RTC protocol</a>, file sharing, and developer debugging.</p>
<figure>
    <div>
            <p><a data-pswp-width="3226" data-pswp-height="1250" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing.jpg 3226w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-640x248.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1024x397.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-768x298.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1536x595.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-2048x794.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-980x380.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1440x558.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing.jpg" target="_blank">
              <img width="1024" height="397" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1024x397.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1024x397.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-640x248.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-768x298.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1536x595.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-2048x794.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-980x380.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-web-to-app-id-sharing-1440x558.jpg 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              A conceptual diagram representing the exchange of identifiers between the web trackers running on the browser context and native Facebook, Instagram, and Yandex apps for Android.
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      A conceptual diagram representing the exchange of identifiers between the web trackers running on the browser context and native Facebook, Instagram, and Yandex apps for Android.

          </p>
  </div>
      </figcaption>
      </figure>

<p>While the technical underpinnings differ, both Meta Pixel and Yandex Metrica are performing a “weird protocol misuse” to gain unvetted access that Android provides to <a href="https://stackoverflow.com/questions/1946193/whats-the-whole-point-of-localhost-hosts-and-ports-at-all">localhost ports</a> on the 127.0.0.1 IP address. Browsers access these ports without user notification. Facebook, Instagram, and Yandex native apps silently listen on those ports, copy identifiers in real time, and link them to the user logged into the app.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<p>A representative for Google said the behavior violates the terms of service for its Play marketplace and the privacy expectations of Android users.</p>
<p>“The developers in this report are using capabilities present in many browsers across iOS and Android in unintended ways that blatantly violate our security and privacy principles,” the representative said, referring to the people who write the Meta Pixel and Yandex Metrica JavaScript. “We've already implemented changes to mitigate these invasive techniques and have opened our own investigation and are directly in touch with the parties.”</p>
<p>Meta didn't answer emailed questions for this article, but provided the following statement: "We are in discussions with Google to address a potential miscommunication regarding the application of their policies. Upon becoming aware of the concerns, we decided to pause the feature while we work with Google to resolve the issue."</p>
<p>Yandex representatives didn't answer an email seeking comment.</p>
<h2>How Meta and Yandex de-anonymize Android users</h2>
<p>Meta Pixel developers have abused various protocols to implement the covert listening since the practice began last September. They started by causing apps to send HTTP requests to port 12387. A month later, Meta Pixel stopped sending this data, even though Facebook and Instagram apps continued to monitor the port.</p>
<p>In November, Meta Pixel switched to a new method that invoked WebSocket, a protocol for two-way communications, over port 12387.</p>
<p>That same month, Meta Pixel also deployed a new method that used <a href="https://en.wikipedia.org/wiki/WebRTC">WebRTC</a>, a real-time peer-to-peer communication protocol commonly used for making audio or video calls in the browser. This method used a complicated process known as <a href="https://webrtchacks.com/not-a-guide-to-sdp-munging/">SDP munging</a>, a technique for JavaScript code to modify Session Description Protocol data before it’s sent. Still in use today, the SDP munging by Meta Pixel inserts key _fbp cookie content into fields meant for connection information. This causes the browser to send that data as part of a <a href="https://en.wikipedia.org/wiki/STUN">STUN request</a> to the Android local host, where the Facebook or Instagram app can read it and link it to the user.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>In May, a <a href="https://groups.google.com/g/discuss-webrtc/c/PIJZN5MTZF4/m/JHVmmn8yDgAJ?pli=1">beta version</a> of Chrome introduced a mitigation that blocked the type of SDP munging that Meta Pixel used. Within days, Meta Pixel circumvented the mitigation by adding a new method that swapped the STUN requests with the <a href="https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT">TURN requests</a>.</p>
<figure>
    <p><img width="640" height="187" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-640x187.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-640x187.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-1024x299.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-768x224.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-1536x448.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-2048x598.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-980x286.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-pixel-transmitting-fbp-cookie-1440x420.jpg 1440w" sizes="auto, (max-width: 640px) 100vw, 640px">
                  </p>
      </figure>

<p>In a <a href="https://arstechnica.com/security/2025/06/headline-to-come/link">post</a>, the researchers provided a detailed description of the _fbp cookie from a website to the native app and, from there, to the Meta server:</p>
<blockquote><p>1. The user opens the native Facebook or Instagram app, which eventually is sent to the background and creates a background service to listen for incoming traffic on a TCP port (12387 or 12388) and a UDP port (the first unoccupied port in 12580–12585). Users must be logged-in with their credentials on the apps.<br>
2. The user opens their browser and visits a website integrating the Meta Pixel.<br>
3. At this stage, some websites wait for users' consent before embedding Meta Pixel. In our measurements of the top 100K website homepages, we found websites that require consent to be a minority (more than 75% of affected sites does not require user consent)...<br>
4. The Meta Pixel script is loaded and the _fbp cookie is sent to the native Instagram or Facebook app via WebRTC (STUN) SDP Munging.<br>
5. The Meta Pixel script also sends the _fbp value in a request to https://www.facebook.com/tr along with other parameters such as page URL (dl), website and browser metadata, and the event type (ev) (e.g., PageView, AddToCart, Donate, Purchase).<br>
6. The Facebook or Instagram apps receive the _fbp cookie from the Meta JavaScripts running on the browser and transmits it to the GraphQL endpoint (https://graph[.]facebook[.]com/graphql) along with other persistent user identifiers, linking users' fbp ID (web visit) with their Facebook or Instagram account.</p></blockquote>
<figure>
    <div>
            <p><a data-pswp-width="1998" data-pswp-height="1714" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow.jpg 1998w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-640x549.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1024x878.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-768x659.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1536x1318.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-980x841.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1440x1235.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow.jpg" target="_blank">
              <img width="1024" height="878" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1024x878.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1024x878.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-640x549.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-768x659.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1536x1318.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-980x841.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow-1440x1235.jpg 1440w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/fbp-cookie-transfer-flow.jpg 1998w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              Detailed flow of the way the Meta Pixel leaks the _fbp cookie from Android browsers to it's Facebook and Instagram apps.
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      Detailed flow of the way the Meta Pixel leaks the _fbp cookie from Android browsers to it's Facebook and Instagram apps.

          </p>
  </div>
      </figcaption>
      </figure>

<p>The first known instance of Yandex Metrica linking websites visited in Android browsers to app identities was in May 2017, when the tracker started sending HTTP requests to local ports 29009 and 30102. In May 2018, Yandex Metrica also began sending the data through HTTPS to ports 29010 and 30103. Both methods remained in place as of publication time.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<figure>
    <div>
            <p><a data-pswp-width="2952" data-pswp-height="1614" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing.jpg 2952w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-640x350.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1024x560.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-768x420.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1536x840.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-2048x1120.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-980x536.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1440x787.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing.jpg" target="_blank">
              <img width="1024" height="560" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1024x560.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1024x560.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-640x350.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-768x420.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1536x840.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-2048x1120.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-980x536.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/yandex-id-sharing-1440x787.jpg 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              An overview of Yandex identifier sharing
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      An overview of Yandex identifier sharing

          </p>
  </div>
      </figcaption>
      </figure>

<figure>
    <div>
            <p><a data-pswp-width="2180" data-pswp-height="974" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline.jpg 2180w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-640x286.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1024x458.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-768x343.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1536x686.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-2048x915.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-980x438.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1440x643.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline.jpg" target="_blank">
              <img width="1024" height="458" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1024x458.jpg" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1024x458.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-640x286.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-768x343.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1536x686.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-2048x915.jpg 2048w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-980x438.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/meta-yandex-tracking-timeline-1440x643.jpg 1440w" sizes="auto, (max-width: 1024px) 100vw, 1024px">
            </a></p><p>
              A timeline of web history tracking by Meta and Yandex
                          </p>
          </div>
          <figcaption>
        <div>
    
    <p>
      A timeline of web history tracking by Meta and Yandex

          </p>
  </div>
      </figcaption>
      </figure>

<p>Some browsers for Android have blocked the abusive JavaScript in trackers. DuckDuckGo, for instance, was already blocking domains and IP addresses associated with the trackers, preventing the browser from sending any identifiers to Meta. The browser also blocked most of the domains associated with Yandex Metrica. After the researchers notified DuckDuckGo of the incomplete blacklist, developers added the missing addresses.</p>
<p>The Brave browser, meanwhile, also blocked the sharing of identifiers due to its extensive blocklists and existing mitigation to <a href="https://brave.com/privacy-updates/27-localhost-permission/" target="_blank" rel="noopener">block requests</a> to the localhost without explicit user consent<span>.</span> Vivaldi, another Chromium-based browser, forwards the identifiers to local Android ports when the default privacy setting is in place. Changing the setting to block trackers appears to thwart browsing history leakage, the researchers said.</p>
<figure>
    <p><img width="300" height="300" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-300x300.png" alt="" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-300x300.png 300w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-500x500.png 500w, https://cdn.arstechnica.net/wp-content/uploads/2025/06/vivaldi-setting-1000x1000.png 1000w" sizes="auto, (max-width: 300px) 100vw, 300px">
                  </p>
          <figcaption>
        <div>
    
    <p>
      Tracking blocker settings in Vivaldi for Android.

          </p>
  </div>
      </figcaption>
      </figure>

<h2>There’s got to be a better way</h2>
<p>The various remedies DuckDuckGo, Brave, Vivaldi, and Chrome have put in place are working as intended, but the researchers caution they could become ineffective at any time.</p>
<p>“Any browser doing blocklisting will likely enter into a constant arms race, and it's just a partial solution,” Vallina Rodriguez said of the current mitigations. “Creating effective blocklists is hard, and browser makers will need to constantly monitor the use of this type of capability to detect other hostnames potentially abusing localhost channels and then updating their blocklists accordingly.”</p>
<p>He continued:</p>
<blockquote><p>While this solution works once you know the hostnames doing that, it's not the right way of mitigating this issue, as trackers may find ways of accessing this capability (e.g., through more ephemeral hostnames). A long-term solution should go through the design and development of privacy and security controls for localhost channels, so that users can be aware of this type of communication and potentially enforce some control or limit this use (e.g., a permission or some similar user notifications).</p></blockquote>
<p>Chrome and most other Chromium-based browsers executed the JavaScript as Meta and Yandex intended. Firefox did as well, although for reasons that aren't clear, the browser was not able to successfully perform the SDP munging specified in later versions of the code. After blocking the STUN variant of SDP munging in the early May beta release, a production version of Chrome released <a href="https://developer.chrome.com/release-notes/137">two weeks ago</a> began blocking both the STUN and TURN variants. Other Chromium-based browsers are likely to implement it in the coming weeks. Firefox didn't respond to an email asking if it has plans to block the behavior in that browser.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          

<p>The researchers warn that the current fixes are so specific to the code in the Meta and Yandex trackers that it would be easy to bypass them with a simple update.</p>
<p>“They know that if someone else comes in and tries a different port number, they may bypass this protection,” said Gunes Acar, the researcher behind the initial discovery, referring to the Chrome developer team at Google. “But our understanding is they want to send this message that they will not tolerate this form of abuse.”</p>
<p>Fellow researcher Vallina-Rodriguez said the more comprehensive way to prevent the abuse is for Android to overhaul the way it handles access to local ports.</p>
<p>“The fundamental issue is that the access to the local host sockets is completely uncontrolled on Android,” he explained. “There's no way for users to prevent this kind of communication on their devices. Because of the dynamic nature of JavaScript code and the difficulty to keep blocklists up to date, the right way of blocking this persistently is by limiting this type of access at the mobile platform and browser level, including stricter platform policies to limit abuse.”</p>
<h2>Got consent?</h2>
<p>The researchers who made this discovery are:</p>
<ul>
<li>Aniketh Girish, PhD student at <a href="https://networks.imdea.org/">IMDEA Networks</a></li>
<li>Gunes Acar, assistant professor in <a href="https://www.ru.nl/en/institute-for-computing-and-information-sciences">Radboud University’s</a> Digital Security Group &amp; iHub</li>
<li>Narseo Vallina-Rodriguez, associate professor at IMDEA Networks</li>
<li>Nipuna Weerasekara, PhD student at IMDEA Networks</li>
<li>Tim Vlummens, PhD student at <a href="https://www.esat.kuleuven.be/">COSIC, KU Leuven</a></li>
</ul>
<p>Acar said he first noticed Meta Pixel accessing local ports while visiting his own university's website.</p>
<p>There's no indication that Meta or Yandex has disclosed the tracking to either websites hosting the trackers or end users who visit those sites. Developer forums show that many websites using Meta Pixel were caught off guard when the scripts began connecting to local ports.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>“Since 5th September, our internal JS error tracking has been flagging failed fetch requests to localhost:12387,” one developer <a href="https://developers.facebook.com/community/threads/317050484803752/">wrote</a>. “No changes have been made on our side, and the existing Facebook tracking pixel we use loads via Google Tag Manager.”</p>
<p>“Is there some way I can disable this?” another developer encountering the unexplained local port access <a href="https://developers.facebook.com/community/threads/937149104821259/">asked</a>.</p>
<p>It's unclear whether browser-to-native-app tracking violates any privacy laws in various countries. Both Meta and companies hosting its Meta Pixel, however, <a href="https://arstechnica.com/tech-policy/2022/09/lawsuits-say-meta-evaded-apple-privacy-settings-to-spy-on-millions-of-users/">have</a> <a href="https://arstechnica.com/tech-policy/2022/11/major-tax-filing-websites-secretly-share-income-data-with-meta/">faced</a> a <a href="https://arstechnica.com/tech-policy/2023/07/meta-wont-say-what-happened-to-taxpayer-data-it-may-have-illegally-collected/">raft</a> of <a href="https://arstechnica.com/tech-policy/2024/02/amc-to-pay-8m-for-allegedly-violating-1988-law-with-use-of-meta-pixel/">lawsuits</a> in recent years alleging that the data collected violates privacy statutes. A <a href="https://arxiv.org/pdf/2208.00710">research paper</a> from 2023 found that Meta pixel, then called the Facebook Pixel, "tracks a wide range of user activities on websites with alarming detail, especially on websites classified as sensitive categories under GDPR," the abbreviation for the European Union's General Data Protection Regulation.</p>
<p>So far, Google has provided no indication that it plans to redesign the way Android handles local port access. For now, the most comprehensive protection against Meta Pixel and Yandex Metrica tracking is to refrain from installing the Facebook, Instagram, or Yandex apps on Android devices.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/dan-goodin/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2018/10/Dang.jpg" alt="Photo of Dan Goodin"></a></p>
  </div>

  <div>
    

    <p>
      Dan Goodin is Senior Security Editor at Ars Technica, where he oversees coverage of malware, computer espionage, botnets, hardware hacking, encryption, and passwords. In his spare time, he enjoys gardening, cooking, and following the independent music scene. Dan is based in San Francisco. Follow him at <a href="https://infosec.exchange/@dangoodin" rel="me">here</a> on Mastodon and <a href="https://bsky.app/profile/dangoodin.bsky.social">here</a> on Bluesky. Contact him on Signal at DanArs.82.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/security/2025/06/meta-and-yandex-are-de-anonymizing-android-users-web-browsing-identifiers/#comments" title="44 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    44 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/tech-policy/2025/06/isp-settles-with-record-labels-that-demanded-mass-termination-of-internet-users/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/getty-pirate-flag-768x432.jpg" alt="Listing image for first story in Most Read: ISP settles with record labels that demanded mass termination of Internet users" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>


  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NYC Drivers Who Run Red Lights Get Tickets. E-Bike Riders Get Court Dates (106 pts)]]></title>
            <link>https://www.nytimes.com/2025/05/24/nyregion/ebikes-scooters-cyclists-nyc.html</link>
            <guid>44169050</guid>
            <pubDate>Tue, 03 Jun 2025 12:02:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/05/24/nyregion/ebikes-scooters-cyclists-nyc.html">https://www.nytimes.com/2025/05/24/nyregion/ebikes-scooters-cyclists-nyc.html</a>, See on <a href="https://news.ycombinator.com/item?id=44169050">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/05/24/nyregion/ebikes-scooters-cyclists-nyc.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Ukraine's autonomous killer drones defeat electronic warfare (320 pts)]]></title>
            <link>https://spectrum.ieee.org/ukraine-killer-drones</link>
            <guid>44168658</guid>
            <pubDate>Tue, 03 Jun 2025 11:08:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/ukraine-killer-drones">https://spectrum.ieee.org/ukraine-killer-drones</a>, See on <a href="https://news.ycombinator.com/item?id=44168658">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Ukrainian troops tested KrattWorks' Ghost Dragon drone in Estonia last year.</p><div data-headline="How Ukraine’s Killer Drones Are Beating Russian Jamming"><p><em><a href="https://www.axios.com/2025/06/01/ukraine-drone-strikes-russia" rel="noopener noreferrer" target="_blank">Ukraine’s 1 June attack</a> on multiple Russian military bases destroyed or damaged as many as 41 Russian aircraft, including some of the country’s most advanced bombers. Estimates of the sum total of the damage range from US $2 billion to $7 billion. Supposedly planned for a <a href="https://www.theguardian.com/world/2025/jun/02/operation-spiderweb-visual-guide-ukraine-drone-attack-russian-aircraft" rel="noopener noreferrer" target="_blank">year and a half</a>, the Ukrainian operation was exceptional in its sophistication: Ukrainian agents reportedly smuggled dozens of first-person-view attack <a href="https://spectrum.ieee.org/tag/drones">drones</a> into <a href="https://spectrum.ieee.org/tag/russia">Russia</a> on trucks, <a href="https://www.nytimes.com/2025/06/02/world/europe/ukraine-russia-drone-strikes.html" rel="noopener noreferrer" target="_blank">situating them close to the air bases</a> where the target aircraft were vulnerable on tarmacs. The bases included one in Irkutsk, 4,300 kilometers from <a href="https://spectrum.ieee.org/tag/ukraine">Ukraine</a>, and another in south Murmansk, 1,800 km away. Remote pilots in Ukraine then launched the killer drones simultaneously.
	</em></p><p><em>
	The far-reaching operation was being hailed as the most inventive and bold of the war so far. Indeed, </em>IEEE Spectrum<em> has been regularly covering the ascent of Ukraine’s military drone programs, both </em><em><a href="https://spectrum.ieee.org/ukraine-hackers-war" target="_self">offensive</a></em><em> and </em><em><a href="https://spectrum.ieee.org/ukraine-air-defense" target="_self">defensive</a></em><em>, and for </em><em><a href="https://spectrum.ieee.org/drone-warfare-ukraine">air</a></em><em>, </em><em><a href="https://spectrum.ieee.org/sea-drone" target="_self">marine</a></em><em>, and </em><em><a href="https://spectrum.ieee.org/ukraine-drones-2671254184" target="_self">land</a></em><em> missions. In this article, originally posted on April 6, we described another bold Ukrainian drone initiative, which was applying artificial intelligence-based navigational software to enable killer drones to navigate to targets even in the presence of heavy <a href="https://spectrum.ieee.org/tag/jamming">jamming</a>.</em></p><p><strong><span></span>After the Estonian startup </strong><a href="https://www.krattworks.com/" target="_blank">KrattWorks</a> dispatched the first batch of its <a href="https://www.krattworks.com/isr-ghostdragon" target="_blank">Ghost Dragon ISR</a>&nbsp;<a href="https://spectrum.ieee.org/tag/quadcopters">quadcopters</a> to Ukraine in mid-2022, the company’s officers thought they might have six months or so before they’d need to reconceive the drones in response to new battlefield realities. The 46-centimeter-wide flier was far more robust than the hobbyist-grade <a href="https://spectrum.ieee.org/tag/uavs">UAVs</a> that came to define the <a href="https://spectrum.ieee.org/ukraine-hackers-war" target="_self">early days of the drone war</a> against Russia. But within a scant three months, the Estonian team realized their painstakingly fine-tuned device had already become obsolete.
</p><p>
	Related: 
	<a href="https://spectrum.ieee.org/ukraine-drones-2671254184" target="_blank">Ukraine Tech Turns Combat into Real-Life “Game”</a></p><p>
	Rapid advances in 
	<a href="https://spectrum.ieee.org/tag/jamming" target="_self">jamming</a> and <a href="https://spectrum.ieee.org/tag/spoofing" target="_self">spoofing</a>—the only efficient defense against drone attacks—set the team on an unceasing marathon of innovation. Its latest technology is a neural-network-driven optical navigation system, which allows the drone to continue its mission even when all radio and satellite-navigation links are jammed. It began tests in <a href="https://spectrum.ieee.org/tag/ukraine" target="_self">Ukraine</a> in December, part of a trend toward jam-resistant, <a href="https://spectrum.ieee.org/search/?q=autonomous+drones" target="_self">autonomous UAVs</a> (uncrewed aerial vehicles). The new fliers herald yet another phase in the unending struggle that pits drones against the jamming and <a href="https://spectrum.ieee.org/tag/spoofing">spoofing</a> of <a href="https://spectrum.ieee.org/the-fall-and-rise-of-russian-electronic-warfare" target="_self">electronic warfare,</a> which aims to sever links between drones and their operators. There are now <a href="https://www.nytimes.com/interactive/2025/03/03/world/europe/ukraine-russia-war-drones-deaths.html" rel="noopener noreferrer" target="_blank">tens of thousands</a> of jammers straddling the front lines of the war, defending against drones that are not just killing soldiers but also destroying armored vehicles, other drones, <a href="https://kyivindependent.com/russia-missile-attack/" rel="noopener noreferrer" target="_blank">industrial infrastructure</a>, and even tanks.
</p><p data-rm-resized-container="25%"><img alt="A man wearing a dark-green long-sleeve t-shirt, seen from behind, holds a drone with both hands above his head." data-rm-shortcode-id="670ed8b9ef5644576b6f8f9836a06576" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-man-wearing-a-dark-green-long-sleeve-t-shirt-seen-from-behind-holds-a-drone-with-both-hands-above-his-head.jpg?id=59800469&amp;width=980" height="3500" id="090b5" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-man-wearing-a-dark-green-long-sleeve-t-shirt-seen-from-behind-holds-a-drone-with-both-hands-above-his-head.jpg?id=59800469&amp;width=980" width="2800"><small placeholder="Add Photo Caption...">During tests near Kyiv, Ukraine, in 2024, a technician prepared to release a drone outfitted with software by Auterion.</small><small placeholder="Add Photo Credit...">
	Justyna Mielnikiewicz
	</small></p><p>
	“The situation with <a href="https://spectrum.ieee.org/tag/electronic-warfare">electronic warfare</a> is moving extremely fast,” says Martin Karmin, KrattWorks’ cofounder and chief operations officer. “We have to constantly iterate. It’s like a cat-and-mouse game.”
</p><p>
	I met Karmin at the company’s headquarters in the outskirts of Estonia’s capital, Tallinn. Just a couple of hundred kilometers to the east is the tiny nation’s border with Russia, its former oppressor. At 38, Karmin is barely old enough to remember what life was like under Russian rule, but he’s heard plenty. He and his colleagues, most of them volunteer members of the 
	<a href="https://www.kaitseliit.ee/en/edl" rel="noopener noreferrer" target="_blank">Estonian Defense League</a>, have “no illusions” about <a href="https://spectrum.ieee.org/tag/russia" target="_self">Russia</a>, he says with a shrug.
</p><p>
	His company is as much about arming <a href="https://spectrum.ieee.org/tag/estonia">Estonia</a> as it is about helping Ukraine, he acknowledges. Estonia is not officially at war with Russia, of course, but regions around the border between the two countries have for years been subjected to persistent jamming of satellite-based <a href="https://spectrum.ieee.org/tag/navigation-systems">navigation systems</a>, such as the 
	<a href="https://defence-industry-space.ec.europa.eu/eu-space/galileo-satellite-navigation_en" rel="noopener noreferrer" target="_blank">European Union’s Galileo satellites</a>, forcing occasional flight cancellations at Tartu airport. In November, <a href="https://spectrum.ieee.org/tag/satellite" target="_self">satellite</a> imagery revealed that Russia is expanding its military bases along the Baltic states’ borders.
</p><p>
	“We are a small country,” Karmin says. “Innovation is our only chance.”
</p><h2>Navigating by Neural Network</h2><p>
	In KrattWorks’ spacious, white-walled workshop, a handful of engineers are testing software. On the large ocher desk that dominates the room, a selection of KrattWorks’ devices is on display, including a couple of fixed-wing, smoke-colored UAVs designed to serve as aerial decoys, and the Ghost Dragon ISR 
	<a href="https://spectrum.ieee.org/tag/quadcopter" target="_self">quadcopter</a>, the company’s flagship product.
</p><p>
	Now in its third generation, the Ghost Dragon has come a long way since 2022. Its original command-and-control-band 
	<a href="https://spectrum.ieee.org/tag/radio" target="_self">radio</a> was quickly replaced with a smart frequency-hopping system that constantly scans the available spectrum, looking for bands that aren’t jammed. It allows operators to switch among six radio-frequency bands to maintain control and also send back video even in the face of hostile jamming.
</p><p><img alt="A black quadcopter drone hovers in front of a coniferous tree." data-rm-shortcode-id="a63ed6b62a8e73e583b5ce084557e634" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-black-quadcopter-drone-hovers-in-front-of-a-coniferous-tree.jpg?id=59800498&amp;width=980" height="794" id="ca339" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-black-quadcopter-drone-hovers-in-front-of-a-coniferous-tree.jpg?id=59800498&amp;width=980" width="1270"><small placeholder="Add Photo Caption...">The Ghost Dragon reconnaissance drone from Krattworks can navigate autonomously, by detecting landmarks as it flies over them. </small><small placeholder="Add Photo Credit...">KrattWorks</small></p><p>
	The drone’s dual-band satellite-navigation receiver can switch among the four main satellite positioning services: 
	<a href="https://family1st.io/gps-vs-glonass-vs-galileo-whats-the-best-gnss/" rel="noopener noreferrer" target="_blank">GPS, Galileo</a>, China’s BeiDou, and Russia’s <a href="https://spectrum.ieee.org/tag/glonass">GLONASS</a>. It’s been augmented with a spoof-proof algorithm that compares the satellite-navigation input with data from onboard sensors. The system provides protection against sophisticated spoofing attacks that attempt to trick drones into self-destruction by persuading them they’re flying at a much higher altitude than they actually are.
</p><p>
	At the heart of the quadcopter’s matte grey body is a machine-vision-enabled computer running a 1-gigahertz Arm processor that provides the Ghost Dragon with its latest superpower: the ability to navigate autonomously, without access to any global navigation satellite system (<a href="https://spectrum.ieee.org/tag/gnss">GNSS</a>). To do that, the computer runs a 
	<a href="https://spectrum.ieee.org/tag/neural-network" target="_self">neural network</a> that, like an old-fashioned traveler, compares views of landmarks with positions on a map to determine its position. More precisely, the drone uses real-time views from a downward-facing optical camera, comparing them against stored satellite images, to determine its position.
</p><p><span data-rm-shortcode-id="c7a71f63bfede8e7831651bd1a76a5e8"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/tGCFBHbw6HQ?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Caption...">A promotional video from Krattworks depicts scenarios in which the company’s drones augment soldiers on offensive maneuvers.</small><small placeholder="Add Photo Credit...">KrattWorks</small></p><p>
	“Even if it gets lost, it can recognize some patterns, like crossroads, and update its position,” Karmin says. “It can make its own decisions, somewhat, either to return home or to fly through the jamming bubble until it can reestablish the GNSS link again.”
</p><h2>Designing Drones for High Lethality per Cost</h2><p>
	Just as machine guns and tanks defined the First World War, drones have become emblematic of Ukraine’s struggle against Russia. It was the besieged Ukraine that first turned the concept of a military drone on its head. Instead of Predators and Reapers worth tens of millions of dollars each, Ukraine began purchasing huge numbers of off-the-shelf fliers worth a few hundred dollars apiece—the kind used by filmmakers and enthusiasts—and turned them into highly lethal <a href="https://spectrum.ieee.org/tag/weapons">weapons</a>. A recent 
	<a href="https://www.nytimes.com/interactive/2025/03/03/world/europe/ukraine-russia-war-drones-deaths.html" rel="noopener noreferrer" target="_blank"><em><em>New York Times</em></em> investigation</a> found that drones account for 70 percent of deaths and injuries in the ongoing conflict.
</p><p>
	“We have much less artillery than Russia, so we had to compensate with drones,” says 
	<a href="https://www.linkedin.com/in/serhii-skoryk-20b02728b/?originalSubdomain=ua" rel="noopener noreferrer" target="_blank">Serhii Skoryk</a>, commercial director at <a href="https://kvertus.ua/" rel="noopener noreferrer" target="_blank">Kvertus</a>, a Kyiv-based electronic-warfare company. “A missile is worth perhaps a million dollars and can kill maybe 12 or 20 people. But for one million dollars, you can buy 10,000 drones, put four grenades on each, and they will kill 1,000 or even 2,000 people or destroy 200 tanks.”
</p><p><img alt="A man in camouflage uniform is surrounded by military gear, including drones. " data-rm-shortcode-id="c6a0b6470088c9d32d62087a112dae9a" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-man-in-camouflage-uniform-is-surrounded-by-military-gear-including-drones.jpg?id=59800500&amp;width=980" height="3853" id="a5d2c" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-man-in-camouflage-uniform-is-surrounded-by-military-gear-including-drones.jpg?id=59800500&amp;width=980" width="6165"><small placeholder="Add Photo Caption...">Near the Russian border in Kharkiv Oblast, a Ukrainian soldier prepared first-person-view drones for an attack on 16 January 2025.</small><small placeholder="Add Photo Credit...">Jose Colon/Anadolu/Getty Images</small></p><p>
	Electronic warfare techniques such as jamming and spoofing aim to neutralize the drone threat. A drone that gets jammed and loses contact with its pilot and also loses its spatial bearings will either crash or fly off randomly until its battery dies.
	<a href="https://static.rusi.org/403-SR-Russian-Tactics-web-final.pdf" rel="noopener noreferrer" target="_blank"> According to the Royal United Services Institute</a>, a U.K. defense think tank, Ukraine may be losing about 10,000 drones per month, mostly due to jamming. That number includes explosives-laden kamikaze drones that don’t reach their targets, as well as surveillance and reconnaissance drones like KrattWorks’ Ghost Dragon, meant for longer service.
</p><p>
	“Drones have become a consumable item,” says Karmin. “You will get maybe 10 or 15 missions out of a reconnaissance drone, and then it has to be already paid off because you will lose it sooner or later.”
</p><p>
	 Russia took an unexpected step in the summer of 2024, ditching sophisticated wireless control in favor of hard-wired drones fitted with spools of <a href="https://spectrum.ieee.org/tag/optical-fiber">optical fiber.
</a></p><p>
	Tech minds on both sides of the conflict have therefore been working hard to circumvent electronic defenses. Russia took an unexpected step starting in early 2024, deploying hard-wired drones fitted with spools of optical fiber. Like a twisted variation on a child’s kite, the lethal UAVs can venture 20 or more kilometers away from the controller, the hair-thin fiber floating behind them, providing an unjammable connection.
</p><p>
	“Right now, there is no protection against <a href="https://spectrum.ieee.org/tag/fiber-optic">fiber-optic</a> drones,” 
	<a href="https://www.linkedin.com/in/vadym-burukin-1378abbb/?originalSubdomain=ua" rel="noopener noreferrer" target="_blank">Vadym Burukin</a>, cofounder of the Ukrainian drone startup <a href="https://huless.com/" rel="noopener noreferrer" target="_blank">Huless</a>, tells <em><em>IEEE</em></em>&nbsp;<em><em>Spectrum</em></em>. “The Russians scaled this solution pretty fast, and now they are saturating the battle front with these drones. It’s a huge problem for Ukraine.”
</p><p><img alt="A drone carrying a large cylindrical object flies over a blurry forest background." data-rm-shortcode-id="c5a9250fbac728b7b2a951af2e4492d2" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-drone-carrying-a-large-cylindrical-object-flies-over-a-blurry-forest-background.jpg?id=59800502&amp;width=980" height="2766" id="b73cf" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-drone-carrying-a-large-cylindrical-object-flies-over-a-blurry-forest-background.jpg?id=59800502&amp;width=980" width="4425"><small placeholder="Add Photo Caption...">One way that drone operators can defeat electronic jamming is by communicating with their drone via a fiber optic line that pays out of a spool as the drone flies. This is a tactic favored by Russian units, although this particular first-person-view drone is Ukrainian. It was demonstrated near Kyiv on 29 January 2025.</small><small placeholder="Add Photo Credit...">Efrem Lukatsky/AP</small></p><p>
	Ukraine, too, has experimented with optical fiber, but the technology didn’t take off, as it were. “The optical fiber costs upwards from $500, which is, in many cases, more than the drone itself,” Burukin says. “If you use it in a drone that carries <a href="https://spectrum.ieee.org/tag/explosives">explosives</a>, you lose some of that capacity because you have the weight of the cable.” The extra weight also means less capacity for better-quality cameras, sensors, and computers in reconnaissance drones.
</p><h2>Small Drones May Soon Be Making Kill-or-No-Kill Decisions</h2><p>
	Instead, Ukraine sees the future in autonomous navigation. This past July, kamikaze drones equipped with an autonomous navigation system from U.S. supplier
	<a href="https://auterion.com/" rel="noopener noreferrer" target="_blank"> Auterion</a> destroyed a column of Russian tanks fitted with jamming devices.
</p><p>
	“It was really hard to strike these tanks because they were jamming everything,” says Burukin. “The drones with the <a href="https://spectrum.ieee.org/tag/autopilot">autopilot</a> were the only equipment that could stop them.”
</p><p><img alt="A diagram shows a quadcopter drone flying above a communications tower as it attempts to navigate to an enemy tank." data-rm-shortcode-id="4009b55dda0d71df9507b2de4cc944ef" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/a-diagram-shows-a-quadcopter-drone-flying-above-a-communications-tower-as-it-attempts-to-navigate-to-an-enemy-tank.jpg?id=59800510&amp;width=980" height="1165" id="3ddb9" lazy-loadable="true" src="https://spectrum.ieee.org/media-library/a-diagram-shows-a-quadcopter-drone-flying-above-a-communications-tower-as-it-attempts-to-navigate-to-an-enemy-tank.jpg?id=59800510&amp;width=980" width="2739"><small placeholder="Add Photo Caption...">Auterion’s “terminal guidance” system uses known landmarks to orient a drone as it seeks out a target. </small><small placeholder="Add Photo Credit...">Auterion</small></p><p>
	The technology used to hit those tanks is called terminal guidance and is the first step toward smart, fully autonomous drones, according to Auterion’s CEO, Lorenz Meier. The system allows the drone to directly overcome the jamming whether the protected target is a tank, a trench, or a military airfield.
</p><p>
	“If you lock on the target from, let’s say, a kilometer away and you get jammed as you approach the target, it doesn’t matter,” Meier says in an interview. “You’re not losing the target as a manual operator would.”
</p><p>
	The visual navigation technology trialed by KrattWorks is the next step and an innovation that has only reached the battlefield this year. Meier expects that by the end of 2025, firms including his own will introduce fully autonomous solutions encompassing visual navigation to overcome <a href="https://spectrum.ieee.org/tag/gps-jamming">GPS jamming</a>, as well as terminal guidance and smart target recognition.
</p><p>
	“The operator would only decide the area where to strike, but the decision about the target is made by the drone,” Meier explains. “It’s already done with guided shells, but with drones you can do that at mass scale and over much greater distances.”
</p><p>
	Auterion, founded in 2017 to produce drone software for civilian applications such as grocery delivery, threw itself into the war effort in early 2024, motivated by a desire to equip democratic countries with technologies to help them defend themselves against authoritarian regimes. Since then, the company has made rapid strides, working closely with Ukrainian drone makers and troops.
</p><p><span>“A missile worth perhaps a million dollars can kill maybe 12 or 20 people. But for one million dollars, you can buy 10,000 drones, put four grenades on each, and they will kill 1,000 or even 2,000 people or destroy 200 tanks.” <strong>—Serhii Skoryk, Kvertus</strong></span></p><p>
	But purchasing Western equipment is, in the long term, not affordable for Ukraine, a country with a per capita GDP of 
	<a href="https://www.imf.org/external/datamapper/profile/UKR" rel="noopener noreferrer" target="_blank">US $5,760</a>—much lower than the European average of <a href="https://www.imf.org/external/datamapper/profile/EUQ" rel="noopener noreferrer" target="_blank">$38,270</a>. Fortunately, Ukraine can tap its engineering workforce, which is among the largest in Europe. Before the war, Ukraine was a go-to place for Western companies looking to set up IT- and software-development centers. Many of these workers have since joined Ukraine’s DIY military-technician (“miltech”) development movement.
</p><p>
	An engineer and founder at a Ukrainian startup that produces long-range kamikaze drones, who didn’t want to be named because of security concerns, told 
	<em><em>Spectrum</em></em> that the company began developing its own computers and autonomous navigation software for target tracking “just to keep the price down.” The engineer said Ukrainian startups offer advanced military-drone technology at a price that is a small fraction of what established competitors in the West are charging.
</p><p>
	Within three years of the February 2022 Russian invasion, Ukraine produced a world-class defense-tech ecosystem that is not only attracting Western innovators into its fold, but also regularly surpassing them. The keys to Ukraine’s success are rapid iterations and close cooperation with frontline troops. It’s a formula that’s working for Auterion as well. “If you want to build a leading product, you need to be where the product is needed the most,” says Meier. “That’s why we’re in Ukraine.”
</p><p>
	Burukin, from Ukrainian startup Huless, believes that autonomy will play a bigger role in the future of drone warfare than 
	<a href="https://www.rferl.org/a/russia-fiber-optic-drones-ukraine-battlefield/33270243.html" rel="noopener noreferrer" target="_blank">Russia’s optical fibers</a> will. Autonomous drones not only evade jamming, but their range is limited only by their battery storage. They also can carry more explosives or better cameras and sensors than the wired drones can. On top of that, they don’t place high demands on their operators.
</p><p>
	“In the perfect world, the drone should take off, fly, find the target, strike it, and report back on the task,” Burukin says. “That’s where the development is heading.”
</p><p>
	The cat-and-mouse game is nowhere near over. Companies including KrattWorks are already thinking about the next innovation that would make drone warfare cheaper and more lethal. By creating a drone <a href="https://spectrum.ieee.org/tag/mesh-network">mesh network</a>, for example, they could send a sophisticated intelligence, surveillance, and reconnaissance drone followed by a swarm of simpler kamikaze drones to find and attack a target using visual navigation.
</p><p>
	“You can send, like, 10 drones, but because they can fly themselves, you don’t need a superskilled operator controlling every single one of these,” notes KrattWorks’ Karmin, who keeps tabs on tech developments in Ukraine with a mixture of professional interest, personal empathy, and foreboding. Rarely does a day go by that he does not think about the expanding Russian military presence near Estonia’s eastern borders.
</p><p>
	“We don’t have a lot of people in Estonia,” he says. “We will never have enough skilled drone pilots. We must find another way.” 
	<span></span></p></div></div>]]></description>
        </item>
    </channel>
</rss>