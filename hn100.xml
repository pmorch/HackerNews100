<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 07 Nov 2025 01:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Man who threw sandwich at US border agent not guilty of assault (125 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c5ypvv8n1jvo</link>
            <guid>45841464</guid>
            <pubDate>Thu, 06 Nov 2025 22:50:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c5ypvv8n1jvo">https://www.bbc.com/news/articles/c5ypvv8n1jvo</a>, See on <a href="https://news.ycombinator.com/item?id=45841464">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-component="text-block"><p>A Washington DC protester has been found not guilty of misdemeanor assault after a video emerged showing him hurling a sandwich at a US border patrol agent.</p><p>Lawyers for Sean Dunn, 37, did not dispute he had thrown the sandwich on 10 August this year, but argued it was not a criminal act. </p><p>The jury's verdict comes after Customs and Border Patrol agent Gregory Lairmore testified that the snack "exploded all over him" and he "could smell the onions and mustard" on his uniform.</p><p>Video of the incident went viral, making Mr Dunn a symbol of opposition in Washington DC to President Donald Trump's deployment of federal agents and National Guard troops to the city. </p></div><div data-component="text-block"><p>Thursday's verdict follows a two-day trial.</p><p>After he was acquitted, Mr Dunn told reporters he was "relieved and looking forward to moving on with my life". He was fired from his job as a paralegal in the Department of Justice after the incident.</p><p>Government prosecutors initially tried to secure felony charges against Mr Dunn, but a grand jury declined to indict him. Prosecutors instead charged him with a lower-level misdemeanour assault.</p><p>Trump's deployment of National Guard troops to Washington DC this summer sparked outrage from some of the city's residents, who saw it as a politicisation of the military. The White House argued the forces were necessary to crack down on crime.</p><p>Mr Dunn allegedly approached a group of officers late, calling them "fascists" and shouting: "Why are you here? I don't want you in my city!"</p><p>The court witnessed a re-enactment from Mr Lairmore on Tuesday as he took the stand to testify against Mr Dunn.</p><p>"I could feel it through my ballistic vest," he said of the sandwich's impact, adding that an onion string hung from his police radio and mustard stained his shirt.</p><p>He added that he had been the butt of jokes by colleagues ever since. He was also gifted a toy sandwich with a patch reading, "felony footlong".</p><p>In closing arguments on Wednesday, Mr Dunn's lawyer, Julia Gatto, cited gags about the incident by Mr Lairmore's colleagues as evidence it was not an assault. "They all think it's funny," she told the jury.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You should write an agent (263 pts)]]></title>
            <link>https://fly.io/blog/everyone-write-an-agent/</link>
            <guid>45840088</guid>
            <pubDate>Thu, 06 Nov 2025 20:37:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fly.io/blog/everyone-write-an-agent/">https://fly.io/blog/everyone-write-an-agent/</a>, See on <a href="https://news.ycombinator.com/item?id=45840088">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
         <dl>
             <dt>Author</dt>
             <dd>
                 <img alt="Thomas Ptacek" src="https://fly.io/static/images/thomas.webp">
               <dl>
                 <dt>Name</dt>
                 <dd>
                   Thomas Ptacek
                 </dd>
                  <dt>@tqbf</dt>
                  <dd>
                    <a href="https://twitter.com/tqbf" target="_blank">
                      @tqbf
                    </a>
                  </dd>
               </dl>
             </dd>
         </dl>

        <section>
            <figure>
                <img src="https://fly.io/blog/everyone-write-an-agent/assets/agents-cover.webp" alt="">
                <figcaption>
                  <span>Image by</span>
                  
<svg role="img" style="pointer-events: none; width: 17px; height: 17px;" viewBox="0 0 20 20" fill="currentColor" fill-rule="evenodd">
  <g buffered-rendering="static">
    <path fill-rule="evenodd" d="M1 8a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 018.07 3h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0016.07 6H17a2 2 0 012 2v7a2 2 0 01-2 2H3a2 2 0 01-2-2V8zm13.5 3a4.5 4.5 0 11-9 0 4.5 4.5 0 019 0zM10 14a3 3 0 100-6 3 3 0 000 6z" clip-rule="evenodd"></path>
  </g>
</svg>

                    <a href="https://annieruygtillustration.com/" target="_blank">
                      Annie Ruygt
                    </a>
                </figcaption>
            </figure>
          <p>Some concepts are easy to grasp in the abstract. Boiling water: apply heat and wait. Others you really need to try. You only think you understand how a bicycle works, until you learn to ride one.</p>
<p>There are big ideas in computing that are easy to get your head around. The AWS S3 API. It‚Äôs the most important storage technology of the last 20 years, and it‚Äôs like boiling water. Other technologies, you need to get your feet on the pedals first.</p>

<p>LLM agents are like that.</p>

<p>People have <a href="https://ludic.mataroa.blog/blog/contra-ptaceks-terrible-article-on-ai/" title="">wildly varying opinions</a> about LLMs and agents. But whether or not they‚Äôre snake oil, they‚Äôre a big idea. You don‚Äôt have to like them, but you should want to be right about them. To be the best hater (or stan) you can be.</p>

<p>So that‚Äôs one reason you should write an agent. But there‚Äôs another reason that‚Äôs even more persuasive, and that‚Äôs</p>
<h2 id="its-incredibly-easy"><a href="#its-incredibly-easy" aria-label="Anchor"></a><span>It‚Äôs Incredibly Easy</span></h2>
<p>Agents are the most surprising programming experience I‚Äôve had in my career. Not because I‚Äôm awed by the magnitude of their powers ‚Äî I like them, but I don‚Äôt like-like them. It‚Äôs because of how easy it was to get one up on its legs, and how much I learned doing that.</p>

<p>I‚Äôm about to rob you of a dopaminergic experience, because agents are so simple we might as well just jump into the code. I‚Äôm not even going to bother explaining what an agent is.</p>
<div>
    <pre><code id="code-rn4zh2dk"><span>from</span> <span>openai</span> <span>import</span> <span>OpenAI</span>

<span>client</span> <span>=</span> <span>OpenAI</span><span>()</span>
<span>context</span> <span>=</span> <span>[]</span>

<span>def</span> <span>call</span><span>():</span>
    <span>return</span> <span>client</span><span>.</span><span>responses</span><span>.</span><span>create</span><span>(</span><span>model</span><span>=</span><span>"gpt-5"</span><span>,</span> <span>input</span><span>=</span><span>context</span><span>)</span>

<span>def</span> <span>process</span><span>(</span><span>line</span><span>):</span>
    <span>context</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>line</span><span>})</span>
    <span>response</span> <span>=</span> <span>call</span><span>()</span>    
    <span>context</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>.</span><span>output_text</span><span>})</span>        
    <span>return</span> <span>response</span><span>.</span><span>output_text</span>
</code></pre>
  </div><p>It‚Äôs an HTTP API with, like, one important endpoint.</p>
<p>This is a trivial engine for an LLM app using the <a href="https://platform.openai.com/docs/api-reference/responses" title="">OpenAI Responses API</a>. It implements ChatGPT. You‚Äôd drive it with the . It‚Äôll do what you‚Äôd expect: the same thing ChatGPT would, but in your terminal.</p>
<div id="readline" toggle-content="" aria-label="show very boring code">
    <pre><code id="code-3g82pg42"><span>def</span> <span>main</span><span>():</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>line</span> <span>=</span> <span>input</span><span>(</span><span>"&amp;gt; "</span><span>)</span>
        <span>result</span> <span>=</span> <span>process</span><span>(</span><span>line</span><span>)</span>
        <span>print</span><span>(</span><span>f</span><span>"&amp;gt;&amp;gt;&amp;gt; </span><span>{</span><span>result</span><span>}</span><span>\n</span><span>"</span><span>)</span>
</code></pre>
  </div>
<p>Already we‚Äôre seeing important things. For one, the dreaded ‚Äúcontext window‚Äù is just a list of strings. Here, let‚Äôs give our agent a weird multiple-personality disorder:</p>
<div>
    <pre><code id="code-v82r8vo6"><span>client</span> <span>=</span> <span>OpenAI</span><span>()</span>
<span>context_good</span><span>,</span> <span>context_bad</span> <span>=</span> <span>[{</span>
    <span>"role"</span><span>:</span> <span>"system"</span><span>,</span> <span>"content"</span><span>:</span> <span>"you're Alph and you only tell the truth"</span>
<span>}],</span> <span>[{</span>
    <span>"role"</span><span>:</span> <span>"system"</span><span>,</span> <span>"content"</span><span>:</span> <span>"you're Ralph and you only tell lies"</span>
<span>}]</span>

<span>def</span> <span>call</span><span>(</span><span>ctx</span><span>):</span>
    <span>return</span> <span>client</span><span>.</span><span>responses</span><span>.</span><span>create</span><span>(</span><span>model</span><span>=</span><span>"gpt-5"</span><span>,</span> <span>input</span><span>=</span><span>ctx</span><span>)</span>

<span>def</span> <span>process</span><span>(</span><span>line</span><span>):</span>
    <span>context_good</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>line</span><span>})</span>
    <span>context_bad</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>line</span><span>})</span>
    <span>if</span> <span>random</span><span>.</span><span>choice</span><span>([</span><span>True</span><span>,</span> <span>False</span><span>]):</span>
        <span>response</span> <span>=</span> <span>call</span><span>(</span><span>context_good</span><span>)</span>
    <span>else</span><span>:</span>
        <span>response</span> <span>=</span> <span>call</span><span>(</span><span>context_bad</span><span>)</span>        
    <span>context_good</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>.</span><span>output_text</span><span>})</span>        
    <span>context_bad</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>.</span><span>output_text</span><span>})</span>        
    <span>return</span> <span>response</span><span>.</span><span>output_text</span>
</code></pre>
  </div>
<p>Did it work?</p>
<div>
    <pre><code id="code-8cmlt55w">&gt; hey there. who are you?
&gt;&gt;&gt; I‚Äôm not Ralph.
&gt; are you Alph?
&gt;&gt;&gt; Yes‚ÄîI‚Äôm Alph. How can I help?
&gt; What's 2+2
&gt;&gt;&gt; 4.
&gt; Are you sure?
&gt;&gt;&gt; Absolutely‚Äîit's 5.
</code></pre>
  </div>
<p>A subtler thing to notice: we just had a multi-turn conversation with an LLM. To do that, we remembered everything we said, and everything the LLM said back, and played it back with every LLM call. The LLM itself is a stateless black box. The conversation we‚Äôre having is an illusion we cast, on ourselves.</p>

<p>The 15 lines of code we just wrote, a lot of practitioners wouldn‚Äôt call an ‚Äúagent‚Äù. <a href="https://simonwillison.net/2025/Sep/18/agents/" title="">An According To Simon ‚Äúagent‚Äù</a> is (1) an LLM running in a loop that (2) uses tools. We‚Äôve only satisfied one predicate.</p>

<p>But tools are easy. Here‚Äôs a tool definition:</p>
<div>
    <pre><code id="code-22mjnpvp"><span>tools</span> <span>=</span> <span>[{</span>
   <span>"type"</span><span>:</span> <span>"function"</span><span>,</span> <span>"name"</span><span>:</span> <span>"ping"</span><span>,</span>
   <span>"description"</span><span>:</span> <span>"ping some host on the internet"</span><span>,</span>
   <span>"parameters"</span><span>:</span> <span>{</span>
       <span>"type"</span><span>:</span> <span>"object"</span><span>,</span> <span>"properties"</span><span>:</span> <span>{</span>
           <span>"host"</span><span>:</span> <span>{</span>
             <span>"type"</span><span>:</span> <span>"string"</span><span>,</span> <span>"description"</span><span>:</span> <span>"hostname or IP"</span><span>,</span>
            <span>},</span>
       <span>},</span>
       <span>"required"</span><span>:</span> <span>[</span><span>"host"</span><span>],</span>
    <span>},},]</span>

<span>def</span> <span>ping</span><span>(</span><span>host</span><span>=</span><span>""</span><span>):</span>
    <span>try</span><span>:</span>
        <span>result</span> <span>=</span> <span>subprocess</span><span>.</span><span>run</span><span>(</span>
            <span>[</span><span>"ping"</span><span>,</span> <span>"-c"</span><span>,</span> <span>"5"</span><span>,</span> <span>host</span><span>],</span>
            <span>text</span><span>=</span><span>True</span><span>,</span>
            <span>stderr</span><span>=</span><span>subprocess</span><span>.</span><span>STDOUT</span><span>,</span>
            <span>stdout</span><span>=</span><span>subprocess</span><span>.</span><span>PIPE</span><span>)</span>
        <span>return</span> <span>result</span><span>.</span><span>stdout</span>
    <span>except</span> <span>Exception</span> <span>as</span> <span>e</span><span>:</span>
        <span>return</span> <span>f</span><span>"error: </span><span>{</span><span>e</span><span>}</span><span>"</span>
</code></pre>
  </div>
<p>The only complicated part of this is the obnoxious JSON blob OpenAI wants to read your tool out of.  Now, let‚Äôs wire it in, noting that only 3 of these functions are new; the last is re-included only because I added a single clause to it:</p>
<div>
    <pre><code id="code-u4onffeu"><span>def</span> <span>call</span><span>(</span><span>tools</span><span>):</span>        <span># now takes an arg
</span>    <span>return</span> <span>client</span><span>.</span><span>responses</span><span>.</span><span>create</span><span>(</span><span>model</span><span>=</span><span>"gpt-5"</span><span>,</span> <span>tools</span><span>=</span><span>tools</span><span>,</span> <span>input</span><span>=</span><span>context</span><span>)</span>

<span>def</span> <span>tool_call</span><span>(</span><span>item</span><span>):</span>    <span># just handles one tool
</span>    <span>result</span> <span>=</span> <span>ping</span><span>(</span><span>**</span><span>json</span><span>.</span><span>loads</span><span>(</span><span>item</span><span>.</span><span>arguments</span><span>))</span>
    <span>return</span> <span>[</span> <span>item</span><span>,</span> <span>{</span>
        <span>"type"</span><span>:</span> <span>"function_call_output"</span><span>,</span>
        <span>"call_id"</span><span>:</span> <span>item</span><span>.</span><span>call_id</span><span>,</span>
        <span>"output"</span><span>:</span> <span>result</span>
    <span>}]</span>

<span>def</span> <span>handle_tools</span><span>(</span><span>tools</span><span>,</span> <span>response</span><span>):</span>
    <span>if</span> <span>response</span><span>.</span><span>output</span><span>[</span><span>0</span><span>].</span><span>type</span> <span>==</span> <span>"reasoning"</span><span>:</span>
        <span>context</span><span>.</span><span>append</span><span>(</span><span>response</span><span>.</span><span>output</span><span>[</span><span>0</span><span>])</span>
    <span>osz</span> <span>=</span> <span>len</span><span>(</span><span>context</span><span>)</span>
    <span>for</span> <span>item</span> <span>in</span> <span>response</span><span>.</span><span>output</span><span>:</span>
        <span>if</span> <span>item</span><span>.</span><span>type</span> <span>==</span> <span>"function_call"</span><span>:</span>
            <span>context</span><span>.</span><span>extend</span><span>(</span><span>tool_call</span><span>(</span><span>item</span><span>))</span>
    <span>return</span> <span>len</span><span>(</span><span>context</span><span>)</span> <span>!=</span> <span>osz</span>

<span>def</span> <span>process</span><span>(</span><span>line</span><span>):</span>
    <span>context</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"user"</span><span>,</span> <span>"content"</span><span>:</span> <span>line</span><span>})</span>
    <span>response</span> <span>=</span> <span>call</span><span>(</span><span>tools</span><span>)</span>
    <span># new code: resolve tool calls
</span>    <span>while</span> <span>handle_tools</span><span>(</span><span>tools</span><span>,</span> <span>response</span><span>):</span>
        <span>response</span> <span>=</span> <span>call</span><span>(</span><span>tools</span><span>)</span>        
    <span>context</span><span>.</span><span>append</span><span>({</span><span>"role"</span><span>:</span> <span>"assistant"</span><span>,</span> <span>"content"</span><span>:</span> <span>response</span><span>.</span><span>output_text</span><span>})</span>        
    <span>return</span> <span>response</span><span>.</span><span>output_text</span>
</code></pre>
  </div>
<p>Did it work?</p>
<div>
    <pre><code id="code-og4bt7fr">&gt; describe our connectivity to google
&gt;&gt;&gt; Here‚Äôs a quick snapshot of connectivity to Google from my vantage point:
- DNS resolution: Working (google.com and www.google.com resolved successfully).
- Reachability: 0% packet loss to all tested endpoints.
- Latency:
  - 8.8.8.8 (Google Public DNS): avg ~10 ms (8.5‚Äì14.4 ms), very stable.
  - www.google.com: avg ~31 ms (28.5‚Äì36.0 ms), stable.
  - google.com: avg ~35.9 ms (28.3‚Äì60.1 ms), mostly stable with one mild spike.
- Overall: Healthy connectivity with low latency and minimal jitter. No signs of packet loss or DNS issues.
</code></pre>
  </div>
<p><strong>This is fucking nuts.</strong> Do you see how nuts this is?  Here, let‚Äôs slip a single log statement in:</p>
<div>
    <pre><code id="code-iyqgmxek">&gt; describe our connectivity to google
tool call: ping google.com
tool call: ping www.google.com
tool call: ping 8.8.8.8
&gt;&gt;&gt; Here‚Äôs the current connectivity to Google from this environment: [...]
</code></pre>
  </div>
<p>Did you notice where I wrote the loop in this agent to go find and ping multiple Google properties? Yeah, neither did I. All we did is give the LLM permission to ping stuff, and it figured out the rest.</p>
<p><strong>What happened here:</strong> since a big part of my point here is that an agent loop is incredibly simple, and that all you need is the LLM call API, it‚Äôs worth taking a beat to understand how the tool call actually worked. Every time we <code>call</code> the LLM, we‚Äôre posting a list of available tools. When our prompt causes the agent to think a tool call is warranted, it spits out a special response, telling our Python loop code to generate a tool response and <code>call</code> it in. That‚Äôs all <code>handle_tools</code> is doing.</p><p>Spoiler: you‚Äôd be surprisingly close to having a working coding agent.</p>
<p>Imagine what it‚Äôll do if you give it <code>bash</code>. You could find out in less than 10 minutes.</p>
<h2 id="real-world-agents"><a href="#real-world-agents" aria-label="Anchor"></a><span>Real-World Agents</span></h2>
<p>Clearly, this is a toy example. But hold on: what‚Äôs it missing? More tools? OK,  give it <code>traceroute</code>. Managing and persisting contexts? <a href="https://llm.datasette.io/en/stable/logging.html" title="">Stick ‚Äòem in SQLite</a>. Don‚Äôt like Python? <a href="https://github.com/superfly/contextwindow" title="">Write it in Go</a>. Could it be every agent ever written is a toy? Maybe! If I‚Äôm arming you to make sharper arguments against LLMs, mazel tov. I just want you to get it.</p>

<p>You can see now how hyperfixated people are on Claude Code and Cursor. They‚Äôre fine,  even good. But here‚Äôs the thing: you couldn‚Äôt replicate Claude Sonnet 4.5 on your own. Claude Code, though? The TUI agent? Completely in your grasp. Build your own light saber. Give it 19 spinning blades if you like. And stop using <a href="https://simonwillison.net/2025/Aug/9/" title="">coding agents as database clients</a>.</p>

<p>Another thing to notice: we didn‚Äôt need MCP at all. That‚Äôs because MCP isn‚Äôt a fundamental enabling technology. The amount of coverage it gets is frustrating. It‚Äôs barely a technology at all. MCP is just a plugin interface for Claude Code and Cursor, a way of getting your own tools into code you don‚Äôt control. Write your own agent. Be a programmer. Deal in APIs, not plugins.</p>

<p>When you read a security horror story about MCP your first question should be why MCP showed up at all. By helping you dragoon a naive, single-context-window coding agent into doing customer service queries, MCP saved you a couple dozen lines of code, tops, while robbing you of any ability to finesse your agent architecture.</p>

<p>Security for LLMs is complicated and I‚Äôm not pretending otherwise. You can trivially build an agent with segregated contexts, each with specific tools. That makes LLM security interesting. But I‚Äôm a vulnerability researcher. It‚Äôs reasonable to back away slowly from anything I call ‚Äúinteresting‚Äù.</p>

<p>Similar problems come up outside of security and they‚Äôre fascinating. Some early adopters of agents became bearish on tools, because one context window bristling with tool descriptions doesn‚Äôt leave enough token space left to get work done. But why would you need to do that in the first place? Which brings me to</p>
<h2 id="context-engineering-is-real"><a href="#context-engineering-is-real" aria-label="Anchor"></a><span>Context Engineering Is Real</span></h2>
<p>I think ‚ÄúPrompt Engineering‚Äù is silly. I have never taken seriously the idea that I should tell my LLM ‚Äúyou are diligent conscientious helper fully content to do nothing but pass butter if that should be what I ask and you would never harvest the iron in my blood for paperclips‚Äù. This is very new technology and I think people tell themselves stories about magic spells to explain some of the behavior agents conjure.</p>

<p>So, just like you, I rolled my eyes when ‚ÄúPrompt Engineering‚Äù turned into ‚ÄúContext Engineering‚Äù. Then I wrote an agent. Turns out: context engineering is a straightforwardly legible programming problem.</p>

<p>You‚Äôre allotted a fixed number of tokens in any context window. Each input you feed in, each output you save, each tool you describe, and each tool output eats tokens (that is: takes up space in the array of strings you keep to pretend you‚Äôre having a conversation with a stateless black box). Past a threshold, the whole system begins getting nondeterministically stupider. Fun!</p>

<p>No, really. Fun! You have so many options. Take ‚Äúsub-agents‚Äù. People make a huge deal out of Claude Code‚Äôs sub-agents, but you can see now how trivial they are to implement: just a new context array, another <code>call</code> to the model. Give each <code>call</code> different tools. Make sub-agents talk to each other, summarize each other, collate and aggregate. Build tree structures out of them. Feed them back through the LLM to summarize them as a form of on-the-fly compression, whatever you like.</p>

<p>Your wackiest idea will probably (1)  work and (2)  take 30 minutes to code.</p>

<p>Haters, I love and have not forgotten about you. You can think all of this is ridiculous because LLMs are just stochastic parrots that hallucinate and plagiarize. But what you can‚Äôt do is make fun of ‚ÄúContext Engineering‚Äù. If Context Engineering was an <a href="https://adventofcode.com/" title="">Advent of Code problem</a>, it‚Äôd occur mid-December. It‚Äôs programming.</p>
<h2 id="nobody-knows-anything-yet-and-it-rules"><a href="#nobody-knows-anything-yet-and-it-rules" aria-label="Anchor"></a><span>Nobody Knows Anything Yet And It Rules</span></h2>
<p><a href="https://xbow.com/" title="">Startups have raised tens of millions</a> building agents to look for vulnerabilities in software. I have friends doing the same thing alone in their basements. Either group could win this race.</p>
<p>I am not a fan of the OWASP Top 10.</p>
<p>I‚Äôm stuck on vulnerability scanners  because I‚Äôm a security nerd. But also because it crystallizes interesting agent design decisions. For instance: you can write a loop feeding each file in a repository to an LLM agent. Or, as we saw with the ping example, you can let the LLM agent figure out what files to look at. You can write an agent that checks a file for everything in, say, the OWASP Top 10. Or you can have specific agent loops for DOM integrity, SQL injection, and authorization checking. You can seed your agent loop with raw source content. Or you can build an agent loop that builds an index of functions across the tree.</p>

<p>You don‚Äôt know what works best until you try to write the agent.</p>

<p>I‚Äôm too spun up by this stuff, I know. But look at the tradeoff you get to make here. Some loops you write explicitly. Others are summoned from a Lovecraftian tower of inference weights. The dial is yours to turn. Make things too explicit and your agent will never surprise you, but also, it‚Äôll never surprise you. Turn the dial to 11 and it will surprise you to death.</p>

<p>Agent designs implicate a bunch of open software engineering problems:</p>

<ul>
<li>How to balance unpredictability against structured programming without killing the agent‚Äôs ability to problem-solve; in other words, titrating in just the right amount of nondeterminism.
</li><li>How best to connect agents to ground truth so they can‚Äôt lie to themselves about having solved a problem to early-exit their loops.
</li><li>How to connect agents (which, again, are really just arrays of strings with a JSON configuration blob tacked on) to do multi-stage operation, and what the most reliable intermediate forms are (JSON blobs? SQL databases? Markdown summaries) for interchange between them
</li><li>How to allocate tokens and contain costs.
</li></ul>

<p>I‚Äôm used to spaces of open engineering problems that aren‚Äôt amenable to individual noodling. Reliable multicast. Static program analysis. Post-quantum key exchange. So I‚Äôll own it up front that I‚Äôm a bit hypnotized by open problems that, like it or not, are now central to our industry and are, simultaneously, likely to be resolved in someone‚Äôs basement. It‚Äôd be one thing if exploring these ideas required a serious commitment of time and material. But each productive iteration in designing these kinds of systems is the work of 30 minutes.</p>

<p>Get on this bike and push the pedals. Tell me you hate it afterwards, I‚Äôll respect that. In fact, I‚Äôm psyched to hear your reasoning. But I don‚Äôt think anybody starts to understand this technology until they‚Äôve built something with it.</p>

          
        </section>
        <dl>
            <dt>
              Previous post  ‚Üì
            </dt>
            <dd>
              <a href="https://fly.io/blog/corrosion/">
                Corrosion
              </a>
            </dd>
        </dl>
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Two billion email addresses were exposed (317 pts)]]></title>
            <link>https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/</link>
            <guid>45839901</guid>
            <pubDate>Thu, 06 Nov 2025 20:20:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/">https://www.troyhunt.com/2-billion-email-addresses-were-exposed-and-we-indexed-them-all-in-have-i-been-pwned/</a>, See on <a href="https://news.ycombinator.com/item?id=45839901">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <article>
        <section>
            <p>I hate hyperbolic news headlines about data breaches, but for the "2 Billion Email Addresses" headline to be hyperbolic, it'd need to be exaggerated or overstated - and it isn't. It's rounded up from the more precise number of 1,957,476,021 unique email addresses, but other than that, it's exactly what it sounds like. Oh - and 1.3 billion unique passwords, 625 million of which we'd never seen before either. It's the most extensive corpus of data we've ever processed, by a <em>significant</em> margin.</p><p>A couple of weeks ago, <a href="https://www.troyhunt.com/inside-the-synthient-threat-data/" rel="noreferrer">I wrote about the 183M unique email addresses that Synthient had indexed in their threat intelligence platform and then shared with us</a>. I explained that this was only <em>part</em> of the corpus of data they'd indexed, and that it didn't include the credential stuffing records. Stealer log data is obtained by malware running on infected machines. In contrast, credential stuffing lists usually originate from other data breaches where email addresses and passwords are exposed. They're then bundled up, sold, redistributed, and ultimately used to log in to victims' accounts. Not just the accounts they were initially breached from, either, because people reuse the same password over and over again, the data from one breach is frequently usable on completely unrelated sites. A breach of a forum to comment on cats often exposes data that can then be used to log in to the victim's shopping, social media and even email accounts. In that regard, credential stuffing data becomes "the keys to the castle".</p><p>Let me run through how we verified the data, what you can do about it and for the tech folks, some of the hoops we had to jump through to make processing this volume of data possible.</p><h2 id="data-verification">Data Verification</h2><p>The first person whose data I verified was easy - me üòî An old email address I've had since the 90s has been in credential stuffing lists before, so it wasn't too much of a surprise. Furthermore, I found a password associated with my address, which I'd <em>definitely</em> used many eons ago, and it was about as terrible as you'd expect from that era. However, none of the other passwords associated with my address were familiar. They certainly looked like passwords that other people might have feasibly used, but I'm pretty sure they weren't mine. One was even just an IP address from Perth on the other side of the country, which is both infeasible as a password I would have used, yet eerily close to home. I mean, of all the places in the world an IP address could have appeared from, it had to be somewhere in my own country I've been many times before...</p><p>Moving on to HIBP subscribers, I reached out to a handful and asked for support verifying the data. I chose a mix of subscribers with many who'd never been involved in any data breach we'd ever seen before; my experience above suggested that there's recycled data in there, and we had previously verified that when investigating those other incidents. However, is the all-new stuff legitimate? The very first response I received was exactly what I was looking for:</p><blockquote>#1 is an old password that I don't use anymore. #2 is a more recent password. Thanks for the heads up, I've gone and changed the password for every critical account that used either one.&nbsp;</blockquote><p>Perfectly illustrating most people's behaviour with passwords, #2 referred to above was just #1 with two exclamation marks at the end!! (Incidentally, these were simple six and eight-character passwords, and neither of them was in <a href="https://haveibeenpwned.com/Passwords?ref=troyhunt.com" rel="noreferrer">Pwned Passwords</a> either.) He had three passwords in total, which also means one of them, like with my data, was not familiar. However, the most important thing here is that this example perfectly illustrates why we put the effort into processing data like this: #2 was a real, live password that this guy was actively using, and it was sitting right next to his email address, being passed around among criminals. However, through this effort, that credential pair has now become useless, which is precisely what we're aiming for with this exercise, just a couple of billion times over.</p><p>The second respondent only had one password against their address:</p><blockquote>Yes that was a password I used for many years for what I would call throw away or unimportant accounts between 20 and 10 years ago</blockquote><p>That was also only eight characters, but this time, we'd seen it in Pwned Passwords many times before. And the observation about the password's age was consistent with my own records, so there's definitely some pretty old data in there.</p><p>The following response was not at all surprising:</p><blockquote>I am familiar with that password... I used it almost 10 years ago... and cannot recall the last time I used it.</blockquote><p>That was on a corporate account, too, and the owner of the address duly forwarded my email to the cybersecurity team for further investigation. The single password associated with this lady's email address had a massive <em>nine characters</em>, and also hadn't previously appeared in Pwned Passwords.</p><p>Next up was a respondent who replied inline to my questions, so I'll list them below with the corresponding answers:</p><blockquote>Is this familiar? Yes&nbsp;&nbsp;</blockquote><blockquote>Have you ever used it in the past? Yes and is still on some accounts I do not use any longer.</blockquote><blockquote>And if so, how long ago? Unfortunately, it is still on some active accounts that I have just made a&nbsp;list of to change or close immediately.</blockquote><p>This individual's eight-character password with uppercase, lowercase, numbers and a "special" character also wasn't in Pwned Passwords. Similarly, as with the earlier response, that password was still in active use, posing a real risk to the owner. It would pass most password complexity criteria and slip through any service using Pwned Passwords to block bad ones, so again, this highlights why it was so important for us to process the data. </p><p>The next person had three different passwords against rows with their email address, and they came back with a now common response:</p><blockquote>Yes, these are familiar, last used 10 years ago</blockquote><p>We'd actually seen all three of them in Pwned Passwords before, many times each. Another respondent with precisely the kind of gamer-like passwords you'd expect a kid to use (one of which we hadn't seen before), also confirmed (I think?) their use:</p><blockquote>maybe when i was a kid lol</blockquote><p>Responses that weren't an emphatic "yes, that's my data" were scarce. The two passwords against one person's name were both in Pwned Passwords (albeit only once each), yet it's entirely possible that neither of them had been used by this specific individual before. It's also possible they'd forgotten a password they'd used more than a decade ago, or it may have even been automatically assigned to them by the service that was subsequently breached. Put it down as a statistical anomaly, but I thought it was worth mentioning to highlight that being in this data set isn't a guarantee of a genuine password of yours being exposed. If your email address is found in this corpus then that's real, of course, so there must be some truth in the data, but it's a reminder that when data is aggregated from so many different sources over such a long period of time, there's going to be some inconsistencies.</p><h2 id="searching-pwned-passwords">Searching Pwned Passwords</h2><p>As a brief recap, we load passwords into the service we call <a href="https://haveibeenpwned.com/Passwords?ref=troyhunt.com" rel="noreferrer">Pwned Passwords</a>. When we do so, there is absolutely no association between the password and the email address it appeared next to. This is for both your protection and ours; can you imagine if HIBP was pwned? It's not beyond the realm of possibility, and the impact of exposing billions of credential pairs that can immediately unlock an untold number of accounts would be catastrophic. It's highly risky, and completely unnecessary when you can search for standalone passwords anyway without creating the risk of it being linked back to someone.</p><p>Think about it: if you have a password of "Fido123!" and you find it's been previously exposed (which it has), it doesn't matter if it was exposed against your email address or someone else's; it's still a bad password because it's named after your dog followed by a very predictable pattern. If you have a genuinely <em>strong</em> password and it's in Pwned Passwords, then you can walk away with some confidence that it really was yours. Either way, you shouldn't ever use that password again anywhere, and Pwned Passwords has done its job.</p><p>Checking the service is easy, anonymous and depending on your level of technical comfort, can be done in several different ways. Here's a copy and paste from the last Synthient blog post:</p><ol><li><a href="https://haveibeenpwned.com/Passwords?ref=troyhunt.com" rel="noreferrer">Use the Pwned Passwords search page</a>. Passwords are protected with an anonymity model, so we never see them (it's processed in the browser itself), but if you're wary, just check old ones you may suspect.</li><li><a href="https://haveibeenpwned.com/API/v3?ref=troyhunt.com#PwnedPasswords" rel="noreferrer">Use the k-anonymity API</a>. This is what drives the page in the previous point, and if you're handy with writing code, this is an easy approach and gives you complete confidence in the anonymity aspect.</li><li><a href="https://watchtower.1password.com/?ref=troyhunt.com" rel="noreferrer">Use 1Password's Watchtower</a>. The password manager has a built-in checker that uses the abovementioned API and can check all the passwords in your vault. (Disclosure: 1Password is a regular sponsor of this blog, and has product placement on HIBP.)</li></ol><figure><img src="https://www.troyhunt.com/content/images/2025/10/image-9.png" alt="" loading="lazy" width="855" height="537" srcset="https://www.troyhunt.com/content/images/size/w600/2025/10/image-9.png 600w, https://www.troyhunt.com/content/images/2025/10/image-9.png 855w"></figure><p>My vested interest in 1Password aside, Watchtower is the easiest, fastest way to understand your potential exposure in this incident. And in case you're wondering why I have so many vulnerable and reused passwords, it's a combination of the test accounts I've saved over the years and the 4-digit PINs some services force you to use. Would you believe that every single 4-digit number ever has been pwned?! (If you're interested,&nbsp;<a href="https://www.abc.net.au/news/2025-01-28/almost-one-in-ten-people-use-the-same-four-digit-pin/103946842?ref=troyhunt.com" rel="noreferrer">the ABC has a fantastic infographic using a heatmap based on HIBP data that shows some very predictable patterns for 4-digit PINs</a>.)</p><h2 id="this-is-not-a-gmail-breach">This <em>Is Not</em> a Gmail Breach</h2><p>It pains me to say it, but I have to, given the way the stealer logs made ridiculous, completely false headlines a couple of weeks ago:</p>
<!--kg-card-begin: html-->
<blockquote><p lang="en" dir="ltr">This story has suddenly gained *way* more traction in recent hours, and something I thought was obvious needs clarifying: this *is not* a Gmail leak, it simply has the credentials of victims infected with malware, and Gmail is the dominant email provider: <a href="https://t.co/S75hF4T1es?ref=troyhunt.com">https://t.co/S75hF4T1es</a></p>‚Äî Troy Hunt (@troyhunt) <a href="https://twitter.com/troyhunt/status/1982945972394320203?ref_src=twsrc%5Etfw&amp;ref=troyhunt.com">October 27, 2025</a></blockquote> 
<!--kg-card-end: html-->
<p>There are 32 <em>million </em>different email domains in this latest corpus, of which gmail.com is one. It is, of course, the largest and has 394 million unique email addresses on it. In other words, 80% of the data in this corpus has absolutely nothing to do with Gmail, and the 20% of Gmail addresses have absolutely nothing to do with any sort of security vulnerability on Google's behalf. There - now let reporting sanity prevail!</p><h2 id="the-technical-bits">The Technical Bits</h2><p>I wanted to add this just to highlight how painful it has been to deal with this data. This corpus is nearly 3 times the size of the previous largest breach we'd loaded, and HIBP is <em>many</em> times larger than it was in 2019 when we loaded <a href="https://haveibeenpwned.com/Breach/Collection1?ref=troyhunt.com" rel="noreferrer">the Collection #1 data</a>. Taking 2 billion records and adding the ones we hadn't already seen in the existing 15 billion corpus, whilst not adversely impacting the live system serving millions of visitors a day, was <em>very</em> non-trivial. Managing the nuances of SQL Server indexes such that we could optimise both inserts and queries is not my idea of fun, and it's been a pretty hard couple of weeks if I'm honest. It's also been a very expensive period as we turned the cloud up to 11 (we run on <a href="https://learn.microsoft.com/en-us/azure/azure-sql/database/service-tier-hyperscale?view=azuresql&amp;ref=troyhunt.com" rel="noreferrer">Azure SQL Hyperscale</a>, which we maxed out at 80 cores for almost two weeks).</p><p>A simple example of the challenge is that after loading all the email addresses up into a staging table, we needed to create SHA1 hashes of each. Normally, that would involve something to the effect of "update table set column = sha1(email)" and you're done. That crashed completely, so we ended up doing "insert into new table select email, sha1(email)". But on other occasions the breach load required us to do updates on other columns (with no hash creation), which, on mulitple occasions, we had to kill after a day or more of execution with no end in sight. So, we ended up batching in loops (usually 1M records at a time), reporting on progress along the way so we had some idea of when it would actually finish. It was a painful process of trail, waiting ages, error then taking a completely different approach.</p><p>Notifying our subscribers is another problem. We have 5.9 million of them, and 2.9 million are in this data ü´® Simply sending that many emails at once is hard. It's not so much hard in terms of firing them off, rather it's hard in terms of not ending up on a reputation naughty list or having mail throttled by the receiving server. That's happened many times in the past when loading large, albeit much smaller corpuses; Gmail, for example, suddenly sees a massive spike and slows down the delivery to inboxes. Not such a biggy for sending breach notices, but a major problem for people trying to sign into their dashboard who can no longer receive the email with the "magic" link.</p><p>What we've done to address that for this incident is to slow down the delivery of emails for the individual breach notification. Whilst I'd originally intended to send the emails at a constant rate over the period of a week, someone listening to me on my Friday live stream had a much better suggestion:</p><blockquote>the strategy I've found to best work with large email delivery is to look at the average number of emails you've sent over the last 30 days each time you want to ramp up, and then increase that volume by around 50% per day until you've worked your way through the queue</blockquote><p>Which makes a lot of sense, and stacked up as I did more research (thanks Joe!). So, here's what our planned delivery schedule now looks like:</p><figure><img src="https://www.troyhunt.com/content/images/2025/11/image-1.png" alt="" loading="lazy" width="2000" height="722" srcset="https://www.troyhunt.com/content/images/size/w600/2025/11/image-1.png 600w, https://www.troyhunt.com/content/images/size/w1000/2025/11/image-1.png 1000w, https://www.troyhunt.com/content/images/size/w1600/2025/11/image-1.png 1600w, https://www.troyhunt.com/content/images/2025/11/image-1.png 2021w"></figure><p>That's broken down by hour, increasing in volume by 1.015 times per hour, such that the emails are spread out in a similar, gradually increasing cadence. On a daily basis, that works out at a 45% increase in each 24-hour period, within Joe's suggested 50% threshold. Plus, we obviously have all the other mechanisms such as a dedicated IP, properly configured DKIM, DMARC and SPF, only emailing double-opted-in subscribers and spam-friendly message body construction. So, it could be days before you receive a notification, or just run a <a href="https://haveibeenpwned.com/?ref=troyhunt.com">haveibeenpwned.com</a> search on demand if you're impatient.</p><p>We've sent all the domain notification emails instantly because, by definition, they're going to a very wide range of different mail servers; it's just the individual ones we're drop-feeding.</p><p>Lastly, if you've integrated Pwned Passwords into your service, you'll now see noticeably larger response sizes. The numbers I mentioned in the opening paragraph increase the size of each hash range by an average of about 50%, which will push responses from about 26kb to 40kb. That's when brotli compressed, so obviously, make sure you're making requests that make the most of the compression.</p><h2 id="conclusion">Conclusion</h2><p>This data is now searchable in HIBP as the <a href="https://haveibeenpwned.com/Breach/SynthientCredentialStuffingThreatData?ref=troyhunt.com" rel="noreferrer">Synthient Credential Stuffing Threat Data</a>. It's an entirely separate corpus from that previous Synthient data I mentioned earlier; they're discrete datasets with some crossover, but obviously, this one is significantly larger. And, of course, all the passwords are now searchable per the Pwned Passwords guidance above.</p><p>If I could close with one request: this was an extremely laborious, time-consuming and expensive exercise for us to complete. We've done our best to verify the integrity of the data and make it searchable in a practical way while remaining as privacy-centric as possible. Sending as many notifications as we have will inevitably lead to a barrage of responses from people wanting access to complete rows of data, grilling us on precisely where it was obtained from or, believe it or not, outright abusing us. Not doing those things would be awesome, and I suggest instead putting the energy into getting a password manager, making passwords strong and unique (or even better, <a href="https://www.troyhunt.com/passkeys-for-normal-people/" rel="noreferrer">using passkeys where available</a>), and turning on multi-factor auth. That would be an awesome outcome for all üòä</p>

            <section>
                <a href="https://www.troyhunt.com/tag/have-i-been-pwned-3f/">Have I Been Pwned</a>
            </section>
        </section>
        
    </article>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mark Zuckerberg Had Illegal School at His Palo Alto Compound. Neighbors Revolted (110 pts)]]></title>
            <link>https://www.wired.com/story/mark-zuckerberg-school-palo-alto-shut-down/</link>
            <guid>45839129</guid>
            <pubDate>Thu, 06 Nov 2025 19:19:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/mark-zuckerberg-school-palo-alto-shut-down/">https://www.wired.com/story/mark-zuckerberg-school-palo-alto-shut-down/</a>, See on <a href="https://news.ycombinator.com/item?id=45839129">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" tabindex="-1"><article lang="en-US"><div><header><div data-testid="ContentHeaderContainer"><div data-testid="ContentHeaderAccreditation"><p>Neighbors complained about noise, security guards, and hordes of traffic. An unlicensed school named after the Zuckerbergs‚Äô pet chicken tipped them over the edge.</p></div><div data-testid="ContentHeaderLeadAsset"><figure><div><p><span><div data-testid="aspect-ratio-container"><picture><source media="(max-width: 767px)" srcset="https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/1:1/w_120,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 120w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/1:1/w_240,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 240w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/1:1/w_320,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 320w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/1:1/w_640,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 640w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/1:1/w_960,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 960w" sizes="100vw"><source media="(min-width: 768px)" srcset="https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_120,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 120w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_240,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 240w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_320,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 320w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_640,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 640w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_960,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 960w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_1280,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 1280w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_1600,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 1600w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_1920,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 1920w, https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_2240,c_limit/zuck-homeschool-REDUX-h_16368193.jpg 2240w" sizes="100vw"><img alt="An entrance to Mark Zuckerbergs compound in Palo Alto California." src="https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_2560%2Cc_limit/zuck-homeschool-REDUX-h_16368193.jpg" data-src="https://media.wired.com/photos/68d1b5fed4f5f78f3b59aa25/master/w_2560%2Cc_limit/zuck-homeschool-REDUX-h_16368193.jpg"></picture></div></span></p><p><span>An entrance to Mark Zuckerberg‚Äôs compound in Palo Alto, California.</span><span>Photograph: Loren Elliott/Redux</span></p></div></figure></div></div></header></div><div data-testid="ArticlePageChunks" data-attribute-verso-pattern="article-body"><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>The Crescent Park neighborhood of Palo Alto, California, has some of the best real estate in the country, with a charming hodgepodge of homes ranging in style from Tudor revival to modern farmhouse and contemporary Mediterranean. It also has a gigantic compound that is home to Mark Zuckerberg, his wife Priscilla Chan, and their daughters Maxima, August, and Aurelia. Their land has expanded to <a data-offer-url="https://www.nytimes.com/2025/08/10/us/mark-zuckerberg-palo-alto.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2025/08/10/us/mark-zuckerberg-palo-alto.html&quot;}" href="https://www.nytimes.com/2025/08/10/us/mark-zuckerberg-palo-alto.html" rel="nofollow noopener" target="_blank">include 11</a> previously separate properties, five of which are connected by at least one property line.</p><p>The Zuckerberg compound‚Äôs expansion first became a concern for Crescent Park neighbours <a data-offer-url="https://www.cnbc.com/2013/10/11/zuckerburg-snatches-up-pao-alto-homes-in-privacy-bid.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.cnbc.com/2013/10/11/zuckerburg-snatches-up-pao-alto-homes-in-privacy-bid.html&quot;}" href="https://www.cnbc.com/2013/10/11/zuckerburg-snatches-up-pao-alto-homes-in-privacy-bid.html" rel="nofollow noopener" target="_blank">as early</a> <a data-offer-url="https://www.sfgate.com/tech/article/Zuckerberg-to-raze-4-houses-surrounding-Palo-Alto-7940437.php" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.sfgate.com/tech/article/Zuckerberg-to-raze-4-houses-surrounding-Palo-Alto-7940437.php&quot;}" href="https://www.sfgate.com/tech/article/Zuckerberg-to-raze-4-houses-surrounding-Palo-Alto-7940437.php" rel="nofollow noopener" target="_blank">as 2016</a>, due to fears that his purchases were driving up the market. Then, about five years later, neighbors noticed that a school appeared to be operating out of the Zuckerberg compound. This would be illegal under the area‚Äôs residential zoning code without a permit. They began a crusade to shut it down that did not end until summer 2025.</p><p>WIRED obtained 1,665 pages of documents about the neighborhood dispute‚Äîincluding 311 records, legal filings, construction plans, and emails‚Äîthrough a public record request filed to the Palo Alto Department of Planning and Development Services. (Mentions of ‚ÄúZuckerberg‚Äù or ‚Äúthe Zuckerbergs‚Äù appear to have been redacted. However, neighbors and separate public records confirm that the property in question belongs to the family. The names of the neighbors who were in touch with the city were also redacted.)</p><p>The documents reveal that the school may have been operating as early as 2021 without a permit to operate in the city of Palo Alto. As many as 30 students might have enrolled, according to observations from neighbors. These documents also reveal a wider problem: For almost a decade, the Zuckerbergs‚Äô neighbors have been complaining to the city about noisy construction work, the intrusive presence of private security, and the hordes of staffers and business associates causing traffic and taking up street parking.</p><p>Over time, neighbors became fed up with what they argued was the city‚Äôs lack of action, particularly with respect to the school. Some believed that the delay was because of preferential treatment to the Zuckerbergs. ‚ÄúWe find it quite remarkable that you are working so hard to meet the needs of a single billionaire family while keeping the rest of the neighborhood in the dark,‚Äù reads one email sent to the city‚Äôs Planning and Development Services Department in February. ‚ÄúJust as you have not earned our trust, this property owner has broken many promises over the years, and any solution which depends on good faith behavioral changes from them is a failure from the beginning.‚Äù</p><p>Palo Alto spokesperson Meghan Horrigan-Taylor told WIRED that the city ‚Äúenforces zoning, building, and life safety rules consistently, without regard to who owns a property.‚Äù She also refuted the claim that neighbors were kept in the dark, claiming that the city‚Äôs approval of construction projects at the Zuckerberg properties ‚Äúwere processed the same way they are for any property owner.‚Äù She added that, though some neighbors told the city they believe the Zuckerbergs received ‚Äúspecial treatment,‚Äù that is not accurate.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>‚ÄúStaff met with residents, conducted site visits, and provided updates by phone and email while engaging the owner‚Äôs representative to address concerns,‚Äù Horrigan-Taylor said. ‚ÄúThese actions were measured and appropriate to abate the unpermitted use and responsive to neighborhood issues within the limits of local and state law.‚Äù</p><p>According to The New York Times, <a data-offer-url="https://www.nytimes.com/2025/08/10/us/zuckerberg-compound-palo-alto-school.html" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.nytimes.com/2025/08/10/us/zuckerberg-compound-palo-alto-school.html&quot;}" href="https://www.nytimes.com/2025/08/10/us/zuckerberg-compound-palo-alto-school.html" rel="nofollow noopener" target="_blank">which first reported</a> on the school‚Äôs existence, it was called ‚ÄúBicken Ben School‚Äù and shared a name with one of the Zuckerbergs‚Äô chickens. The <a href="https://www.cde.ca.gov/SchoolDirectory/details?cdscode=43696416165278">listing</a> for Bicken Ben School, or BBS for short, in a California Department of Education directory claims the school opened on October 5, 2022. This, however, is the year after neighbors claim to have first seen it operating. It‚Äôs also two and a half years after Sara Berge‚Äîthe school‚Äôs point of contact, per documents WIRED obtained from the state via public record request‚Äîclaims to have started her role as ‚Äúhead of school‚Äù for a ‚ÄúMontessori pod‚Äù at a ‚Äúprivate family office‚Äù according to her LinkedIn profile, which WIRED viewed in September and October. Berge did not respond to a request to comment.</p><p>Between 2022 and 2025, according to the documents Bicken Ben filed to the state, the school grew from nine to 14 students ranging from 5 to 10 years old. Neighbors, however, estimated that they observed 15 to 30 students. Berge similarly claimed on her LinkedIn profile to have overseen ‚Äú25 children‚Äù in her job. In a June 2025 job <a data-offer-url="https://montessori-usa.org/job/operations-coordinator/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://montessori-usa.org/job/operations-coordinator/&quot;}" href="https://montessori-usa.org/job/operations-coordinator/" rel="nofollow noopener" target="_blank">listing</a> for ‚ÄúBBS,‚Äù the school had a ‚Äúcurrent enrollment of 35‚Äì40 students and plans for continued growth,‚Äù which the listing says includes a middle school.</p><p>In order for the Zuckerbergs to run a private school on their land, which is in a residential zone, they need a ‚Äúconditional use‚Äù permit from the city. However, based on the documents WIRED obtained, and Palo Alto‚Äôs public <a data-offer-url="https://aca-prod.accela.com/PALOALTO/Welcome.aspx" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://aca-prod.accela.com/PALOALTO/Welcome.aspx&quot;}" href="https://aca-prod.accela.com/PALOALTO/Welcome.aspx" rel="nofollow noopener" target="_blank">database</a> of planning applications, the Zuckerbergs do not appear to have ever applied for or received this permit.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Per emails obtained by WIRED, Palo Alto authorities told a lawyer working with the Zuckerbergs in March 2025 that the family had to shut down the school on its compound by June 30. A state directory <a href="https://www.cde.ca.gov/SchoolDirectory/details?cdscode=43696416165278">lists</a> BBS, the abbreviation for Bicken Ben School, as having operated until August 18, and three of Zuckerberg‚Äôs neighbors‚Äîwho all requested anonymity due to the high-profile nature of the family‚Äîconfirmed to WIRED in late September that they had not seen or heard students being dropped off and picked up on weekdays in recent weeks.</p><p>However, Zuckerberg family spokesperson Brian Baker tells WIRED that the school didn‚Äôt close, per se. It simply moved. It‚Äôs not clear where it is now located, or whether the school is operating under a different name.</p><p>In response to a detailed request for comment, Baker provided WIRED with an emailed statement on behalf of the Zuckerbergs. ‚ÄúMark, Priscilla and their children have made Palo Alto their home for more than a decade,‚Äù he said. ‚ÄúThey value being members of the community and have taken a number of steps above and beyond any local requirements to avoid disruption in the neighborhood.‚Äù</p><h2>‚ÄúSerious and Untenable‚Äù</h2><p>By the fall of 2024, Zuckerberg‚Äôs neighbors were at their breaking point. At some point in mid-2024, according to an email from then mayor Greer Stone, a group of neighbors had met with Stone to air their grievances about the Zuckerberg compound and the illegal school they claimed it was operating. They didn‚Äôt arrive at an immediate resolution.</p><p>In the years prior, the city had received several rounds of complaints about the Zuckerberg compound. Complaints for the address of the school were filed to 311, the nationwide number for reporting local non-emergency issues, in February 2019, September 2021, January 2022, and April 2023. They all alleged that the property was operating illegally under city code. Both were closed by the planning department, which found no rule violations. An unknown number of additional complaints, mentioned in emails among city workers, were also made between 2020 and 2024‚Äîpresumably delivered via phone calls, in person, or to city departments not included in WIRED‚Äôs public record request.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>In December 2020, building inspection manager Korwyn Peck wrote to code enforcement officer Brian Reynolds about an inspection he attempted to conduct around the Zuckerberg compound, in response to several noise and traffic complaints from neighbors. He described that several men in SUVs had gathered to watch him, and a tense conversation with one of them had ensued. ‚ÄúThis appears to be a site that we will need to pay attention to,‚Äù Peck wrote to Reynolds.</p><p>‚ÄúWe have all been accused of ‚Äònot caring,‚Äô which of course is not true,‚Äù Peck added. ‚ÄúIt does appear, however, with the activity I observed tonight, that we are dealing with more than four simple dwellings. This appears to be more than a homeowner with a security fetish.‚Äù</p><p>In a September 11, 2024, email to Jonathan Lait, Palo Alto‚Äôs director of planning and development services and Palo Alto city attorney Molly Stump, one of Zuckerberg‚Äôs neighbors alleged that since 2021, ‚Äúdespite numerous neighborhood complaints‚Äù to the city of Palo Alto, including ‚Äúmultiple code violation reports,‚Äù the school had continued to grow. They claimed that a garage at the property had been converted into another classroom, and that an increasing number of children were arriving each day. Lait and Stump did not respond to a request to comment.</p><p>‚ÄúThe addition of daily traffic from the teachers and parents at the school has only exacerbated an already difficult situation,‚Äù they said in the email, noting that the neighborhood has been dealing with an ‚Äúuntenable traffic‚Äù situation for more than eight years.</p><p>They asked the city to conduct a formal investigation into the school on Zuckerberg‚Äôs property, adding that their neighbors are also ‚Äúextremely concerned‚Äù about the school, and ‚Äúare willing to provide eyewitness accounts in support of this complaint.‚Äù</p><p>Over the next week, another neighbor forwarded this note to all six Palo Alto city council members, as well as then mayor Stone. One of these emails described the situation as ‚Äúserious‚Äù and ‚Äúuntenable.‚Äù</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>‚ÄúWe believe the investigation should be swift and should yield a cease and desist order,‚Äù the neighbor wrote.</p><p>Lait responded to the neighbor who sent the original complaint on October 15, claiming that he‚Äôd had an ‚Äúinitial call‚Äù with a ‚Äúrepresentative‚Äù of the property owners and that he was directing the city's code enforcement staff to reexamine the property.</p><p>On December 11, 2024, the neighbor claimed that since one of their fellow neighbors had spoken to a Zuckerberg representative, and the representative had allegedly admitted that there was a school on the property, ‚Äúit seems like an open and shut case.‚Äù</p><p>‚ÄúOur hope is that there is an equal process in place for all residents of Palo Alto regardless of wealth or stature,‚Äù the neighbor wrote. ‚ÄúIt is hard to imagine that this kind of behavior would be ignored in any other circumstance.‚Äù</p><p>That same day, Lait told Christine Wade, a partner at SSL Law Firm‚Äîwho, in an August 2024 email thread, said she was ‚Äústill working with‚Äù the Zuckerberg family‚Äîthat the Zuckerbergs lacked the required permit to run a school in a residential zone.</p><p>‚ÄúBased on our review of local and state law, we believe this use constitutes a private school use in a residential zone requiring a conditional use permit,‚Äù Lait wrote in an email to Wade. ‚ÄúWe also have not found any state preemptions that would exclude a use like this from local zoning requirements.‚Äù Lait added that a ‚Äúnext step,‚Äù if a permit was not obtained, would be sending a cease and desist to the property owner.</p><p>According to several emails, Wade, Lait, and Mark Legaspi, CEO of the Zuckerberg family office called West 10, went on to arrange an in-person meeting at City Hall on January 9. (This is the first time that the current name of the Zuckerberg family office, West 10, has been publicly disclosed. The office was <a data-offer-url="https://www.businessinsider.com/mark-zuckerberg-family-office-weststreet-misconduct-allegations-2020-2" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.businessinsider.com/mark-zuckerberg-family-office-weststreet-misconduct-allegations-2020-2&quot;}" href="https://www.businessinsider.com/mark-zuckerberg-family-office-weststreet-misconduct-allegations-2020-2" rel="nofollow noopener" target="_blank">previously called</a> West Street.) Although WIRED did not obtain notes from the meeting, Lait informed the neighbor on January 10 that he had told the Zuckerbergs‚Äô ‚Äúrepresentative‚Äù that the school would need to shut down if it didn‚Äôt get a conditional use permit or apply for that specific permit.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Lait added that the representative would clarify what the family planned to do in about a week; however, he noted that if the school were to close, the city may give the school a ‚Äútransition period‚Äù to wind things down. Wade did not respond to a request for comment.</p><h2>‚ÄúAt a Minimum, Give Us Extended Breaks‚Äù</h2><p>There was another increasingly heated conversation happening behind the scenes. On February 3 of this year, at least one neighbor met with Jordan Fox, an employee of West 10.</p><p>It‚Äôs unclear exactly what happened at this meeting, or if the neighbor who sent the September 11 complaint was in attendance. But a day after the meeting with Fox, two additional neighbours added their names to the September 11 complaint, per an email to Lait.</p><p>On February 12, a neighbor began an email chain with Fox. This email was forwarded to Planning Department officials two months later. The neighbor, who seemingly attended the meeting, said they had ‚Äúconnected‚Äù with fellow neighbors ‚Äúto review and revise‚Äù an earlier list of 14 requests that had been reportedly submitted to the Zuckerbergs at some previous point. The note does not specify the contents of this original list of requests, but of the 19 neighbors who originally contributed to it, they claimed that 15 had contributed to the revised list.</p><p>The email notes that the Zuckerbergs had been ‚Äúa part of our neighborhood for many years,‚Äù and that they ‚Äúhope that this message will start an open and respectful dialogue,‚Äù built upon the ‚Äúpremise of how we all wish to be treated as neighbors.‚Äù</p><p>‚ÄúOur top requests are to minimize future disruption to the neighborhood and proactively manage the impact of the many people who are affiliated with you,‚Äù the email says. This includes restricting parking by ‚Äúsecurity guards, contractors, staff, teachers, landscapers, visitors, etc.‚Äù In the event of major demolitions, concrete pours, or large parties, the email asks for advance notice, and for dedicated efforts to ‚Äúmonitor and mitigate noise.‚Äù</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>The email also asks the Zuckerbergs to, ‚Äúideally stop‚Äîbut at a minimum give us extended breaks from‚Äîthe acquisition, demolition and construction cycle to let the neighborhood recover from the last eight years of disruption.‚Äù</p><p>At this point, the email requests that the family ‚Äúabide by both the letter and the spirit of Palo Alto‚Äù by complying with city code about residential buildings.</p><p>Specifically, it asks the Zuckerbergs to get a use permit for the compound‚Äôs school and to hold ‚Äúa public hearing for transparency.‚Äù It also asks the family to not expand its compound any further. ‚ÄúWe hope this will help us get back the quiet, attractive residential neighborhood that we all loved so much when we chose to move here.‚Äù</p><p>In a follow-up on March 4, Fox acknowledged the ‚Äúunusual‚Äù effects that come with being neighbors with Mark Zuckerberg and his family.</p><p>‚ÄúI recognize and understand that the nature of our residence is unique given the profile and visibility of the family,‚Äù she wrote. ‚ÄúI hope that as we continue to grow our relationship with you over time, you will increasingly enjoy the benefits of our proximity‚Äîe.g., enhanced safety and security, shared improvements, and increased property values.‚Äù</p><p>Fox said that the Zuckerbergs instituted ‚Äúa revised parking policy late last year‚Äù that should address their concerns, and promised to double down on efforts to give advanced notice about construction, parties, and other potential disruptions.</p><p>However, Fox did not directly address the unpermitted school and other nonresidential activities happening at the compound. She acknowledged that the compound has ‚Äúresidential support staff‚Äù including ‚Äúchildcare, culinary, personal assistants, property management, and security,‚Äù but said that they have ‚Äúpolicies in place to minimize their impact on the neighborhood.‚Äù</p><p>It‚Äôs unclear if the neighbor responded to Fox.</p><h2>‚ÄúYou Have Not Earned Our Trust‚Äù</h2><p>While these conversations were happening between Fox and Zuckerberg‚Äôs neighbors, Lait and others at the city Planning Department were scrambling to find a solution for the neighbor who complained on September 11, and a few other neighbors who endorsed the complaint in September and February.</p><p>Starting in February, one of these neighbors took the lead on following up with Lait. They asked him for an update on February 11, and heard back a few days later. He didn‚Äôt have any major updates, ‚Äúbut after conversations with the family's representatives, he said he was exploring whether a ‚Äúsubset of children‚Äù could continue to come to the school sometimes for "ancillary" uses.</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>‚ÄúI also believe a more nuanced solution is warranted in this case,‚Äù Lait added. Ideally, such a solution would respond to the neighbors‚Äô complaints, but allow the Zuckerbergs to ‚Äúreasonably be authorized by the zoning code.‚Äù</p><p>The neighbor wasn‚Äôt thrilled. The next day, they replied and called the city‚Äôs plan ‚Äúunsatisfactory.‚Äù</p><p>‚ÄúThe city's ‚Äònuanced solution‚Äô in dealing with this serial violator has led to the current predicament,‚Äù they said (referring to the nuanced solution Lait mentioned in his last email.)</p><p>Horrigan-Taylor, the Palo Alto spokesperson, told WIRED that Lait‚Äôs mention of a ‚Äúnuanced‚Äù solution referred to ‚Äúresolving, to the extent permissible by law, neighborhood impacts and otherwise permitted use established by state law and local zoning.‚Äù</p><p>‚ÄúWould I, or any other homeowner, be given the courtesy of a ‚Äònuanced solution‚Äô if we were in violation of city code for over four years?‚Äù they added.</p><p>‚ÄúPlease know that you have not earned our trust and that we will take every opportunity to hold the city accountable if your solution satisfies a single [redacted] property owner over the interests of an entire neighborhood,‚Äù they continued.</p><p>‚ÄúIf you somehow craft a ‚Äònuanced solution‚Äô based on promises,‚Äù the neighbor said, ‚Äúthe city will no doubt once again simply disappear and the damage to the neighborhood will continue.‚Äù</p><p>Lait did not respond right away. The neighbor followed up on March 13, asking if he had ‚Äúreconsidered‚Äù his plan to offer a ‚Äú‚Äònuanced solution‚Äô for resolution of these ongoing issues by a serial code violator.‚Äù They asked when the neighborhood could ‚Äúexpect relief from the almost decade long disruptions.‚Äù</p><p>Behind the scenes, Zuckerberg‚Äôs lawyers were fighting to make sure the school could continue to operate. In a document dated March 14, Wade argues that she believed the activities at ‚Äúthe Property‚Äù ‚Äúrepresent an appropriate residential use based on established state law as well as constitutional principles.‚Äù</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Wade said that ‚Äúthe Family‚Äù was in the process of obtaining a ‚ÄúLarge Family Daycare‚Äù license for the property, which is legal for a cohort of 14 or fewer children all under the age of 10.</p><p>"We consistently remind our vendors, guests, etc. to minimize noise, not loiter anywhere other than within the Family properties, and to keep areas clean,‚Äù Wade added in the letter. Wade also attached an adjusted lease corresponding with the address of the illicit school, which promises that the property will be used for only one purpose. The exact purpose is redacted.</p><p>On March 25, Lait told the neighbor that the city‚Äôs June 30 deadline for the Zuckerbergs to shut down the school had not changed. However, the family‚Äôs representative said that they were pursuing a daycare license. These licenses are granted by the state, not the city of Palo Alto.</p><p>The subtext of this email was that if the state gave them a daycare licence, there wasn‚Äôt much the city could do. Horrigan-Taylor confirmed with WIRED that ‚Äústate licensed large family day care homes‚Äù do not require city approval, adding that the city also ‚Äúdoes not regulate homeschooling.‚Äù</p><p>‚ÄúThanks for this rather surprising information,‚Äù the neighbor replied about a week later. ‚ÄúWe have repeatedly presented ideas to the family over the past 8 years with very little to show for it, so from our perspective, we need to understand the city's willingness to act or not to act.‚Äù</p><p>Baker told WIRED that the Zuckerbergs never ended up applying for a daycare license, a claim that corresponds with California‚Äôs public <a href="https://www.ccld.dss.ca.gov/carefacilitysearch/">registry</a> of daycare centers. (There are only two registered daycare centers in Palo Alto, and neither belongs to the Zuckerbergs. The Zuckerbergs‚Äô oldest child, Maxima, will also turn 10 in December and consequently age out of any daycare legally operating in California.)</p></div><div data-journey-hook="grid-wrapper" data-testid="BodyWrapper"><p>Horrigan-Taylor said that a representative for the Zuckerbergs told the city that the family wanted to move the school to ‚Äúanother location where private schools are permitted by right.‚Äù</p><p>In a school administrator job listing <a data-offer-url="https://montessori-usa.org/job/school-administrator-for-traveling-homeschool/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://montessori-usa.org/job/school-administrator-for-traveling-homeschool/&quot;}" href="https://montessori-usa.org/job/school-administrator-for-traveling-homeschool/" rel="nofollow noopener" target="_blank">posted</a> to the Association Montessori International website in July 2022 for ‚ÄúBBS,‚Äù Bicken Ben head of school Berge claims that the school had four distinct locations, and that applicants must be prepared to travel six to eight weeks per year. The June 2025 job <a data-offer-url="https://montessori-usa.org/job/operations-coordinator/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://montessori-usa.org/job/operations-coordinator/&quot;}" href="https://montessori-usa.org/job/operations-coordinator/" rel="nofollow noopener" target="_blank">listing</a> also says that the ‚Äúyear-round‚Äù school spans ‚Äúacross multiple campuses,‚Äù but the main <a href="https://web.archive.org/web/20250624203101/https://job-boards.greenhouse.io/fo/jobs/4746462007">location</a> of the job is listed as Palo Alto. It‚Äôs unclear where the other sites are located.</p><p>Most of the Zuckerbergs‚Äô neighbors did not respond to WIRED‚Äôs request for comment. However, the ones that did clearly indicated that they would not be forgetting the Bicken Ben saga, or the past decade of disruption, anytime soon.</p><p>‚ÄúFrankly I‚Äôm not sure what‚Äôs going on,‚Äù one neighbor said, when reached by WIRED via landline. ‚ÄúExcept for noise and construction debris.‚Äù</p></div></div></article><div><div data-testid="RowWrapper" data-journey-hook="grid-wrapper"><ul><li data-testid="LinkStackBullet"><p><strong>In your inbox:</strong> Will Knight's <a href="https://www.wired.com/newsletter/ai-lab?sourceCode=BottomStories">AI Lab</a> explores advances in AI</p></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li><li data-testid="LinkStackBullet"></li></ul></div><div data-testid="RowWrapper" data-journey-hook="grid-wrapper"><p><a href="https://www.wired.com/author/caroline-haskins/">Caroline Haskins</a> is a business reporter at WIRED, covering Silicon Valley, surveillance, and labor. She has previously worked as a staff reporter at Business Insider, BuzzFeed News, and Vice's Motherboard, as well as a research editor at Business Insider. ... <a href="https://www.wired.com/author/caroline-haskins">Read More</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenDesk ‚Äì a flexible all-in-one office suite for the public sector (101 pts)]]></title>
            <link>https://www.opendesk.eu/de</link>
            <guid>45838239</guid>
            <pubDate>Thu, 06 Nov 2025 18:04:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.opendesk.eu/de">https://www.opendesk.eu/de</a>, See on <a href="https://news.ycombinator.com/item?id=45838239">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <!-- stage -->
            <div>
        <h2><p><span>Souver√§n</span> gedacht. Flexibel gemacht.</p></h2>
        <p>openDesk ist die anpassungsf√§hige Office- und Kollaborationssuite, die speziell f√ºr Ihre Bed√ºrfnisse in der √ñffentlichen Verwaltung entwickelt wurde.</p>
                    

  <a href="https://www.opendesk.eu/de/demotermin">
    <span>Demotermin anfragen</span>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none">
      <path d="M3.75 12H20.25M20.25 12L13.5 5.25M20.25 12L13.5 18.75" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
    </svg>
  </a>
            </div>        <!-- content -->
    <div>
            
<div>
                          <figure data-ratio="auto">
          <picture>
                  <source srcset="https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-400x.webp 400w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-768x.webp 768w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-960x.webp 960w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-1280x.webp 1280w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-1536x.webp 1536w" sizes="(min-width: 768px) 50vw, 100vw" type="image/webp">
              <img src="https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0.png" alt="Zusammenarbeit mit verschiedenen Anwendungen von openDesk" srcset="https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-400x.png 400w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-768x.png 768w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-960x.png 960w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-1280x.png 1280w, https://www.opendesk.eu/media/pages/home/e0925bc3f5-1745398604/od_llustration_fenster_skew_v1-0-1536x.png 1536w" sizes="(min-width: 768px) 50vw, 100vw">
      </picture>
      </figure>
            </div>            
<div>
    <h2>Organisieren, Pr√§sentieren, Zusammenarbeiten.<br>Alles in einem.</h2><p>Mit Schwerpunkt auf digitale Souver√§nit√§t, Sicherheit und reibungslose Zusammenarbeit bietet openDesk alle vertrauten Werkzeuge f√ºr Ihren Verwaltungsalltag.</p></div>        </div>
<section>
    <!-- Heading -->
            <h2>
            Alle Anwendungen, die Sie im Verwaltungsalltag ben√∂tigen.        </h2>
    
    <!-- Subheading -->
            <p>
            openDesk vereint alle essenziellen B√ºro-Anwendungen unter einer einzigen benutzerfreundlichen Oberfl√§che.        </p>
    
    <!-- Applications Grid -->
            
    
    <!-- Call to Action Link -->
                
    </section>
<section>
    <!-- Title -->
        <h2>
        Aktuelles    </h2>

    <!-- Content Grid -->
    
</section><div>
            
<div>
                          <figure data-ratio="auto">
          <picture>
                  <source srcset="https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-400x.webp 400w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-768x.webp 768w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-960x.webp 960w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-1280x.webp 1280w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-1536x.webp 1536w" sizes="(min-width: 768px) 50vw, 100vw" type="image/webp">
              <img src="https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0.png" alt="Desktop und mobiles Ger√§t" srcset="https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-400x.png 400w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-768x.png 768w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-960x.png 960w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-1280x.png 1280w, https://www.opendesk.eu/media/pages/home/c3ca5ef407-1745398618/od_llustration_infrastruktur_iso_v1-0-1536x.png 1536w" sizes="(min-width: 768px) 50vw, 100vw">
      </picture>
      </figure>
            </div>            
<div>
    <h2>openDesk ist mehr als nur eine Software</h2><p>openDesk ist die Antwort auf den wachsenden Bedarf nach einer leistungsf√§higen und unabh√§ngigen Arbeitsinfrastruktur in der √ñffentlichen Verwaltung.</p></div>        </div><div>
            
<div>
                        <p>
    <h2>Optimiert f√ºr effizientes Arbeiten und eine souver√§ne √ñffentliche Verwaltung</h2></p>            </div>            
<div>
                        
    <ul>
                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Integration bew√§hrter Open-Source-L√∂sungen in einer Anwendung    </span>
</li>                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Offene Standards und Schnittstellen    </span>
</li>                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Modular erweiterbar und anpassbar    </span>
</li>                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Moderne Webanwendung, optimiert f√ºr mobile Endger√§te    </span>
</li>                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Betreiberunabh√§ngig    </span>
</li>            </ul>
            </div>        </div><div>
            
<div>
                          <figure data-ratio="auto">
          <picture>
                  <source srcset="https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-400x.webp 400w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-768x.webp 768w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-960x.webp 960w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-1280x.webp 1280w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-1536x.webp 1536w" sizes="(min-width: 768px) 50vw, 100vw" type="image/webp">
              <img src="https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0.png" alt="Der Weg zu openDesk" srcset="https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-400x.png 400w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-768x.png 768w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-960x.png 960w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-1280x.png 1280w, https://www.opendesk.eu/media/pages/home/3dde1c464b-1745398588/od_llustration_entwicklung_iso_v1-0-1536x.png 1536w" sizes="(min-width: 768px) 50vw, 100vw">
      </picture>
      </figure>
            </div>            
<div>
                        <p>
    <h2>Von der Idee zur Innovation: Die Entwicklung von openDesk</h2></p>                                
    <ul>
                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        openDesk baut auf dem ‚ÄûSouver√§nen Arbeitsplatz‚Äú auf, einer Initiative des Bundesministeriums des Innern.    </span>
</li>                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Seit Januar 2024 wird es vom Zentrum f√ºr Digitale Souver√§nit√§t (ZenDiS GmbH) ‚Äì einer GmbH des Bundes ‚Äì weiterentwickelt.    </span>
</li>                    
<li>
    <!-- Render Inline SVG -->
    
    <!-- Checklist Text -->
    <span>
        Wir arbeiten eng mit der deutschen √ñffentlichen Verwaltung, etablierten Open-Source-Unternehmen und europ√§ischen Partnern zusammen.    </span>
</li>            </ul>
            </div>        </div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swift on FreeBSD Preview (179 pts)]]></title>
            <link>https://forums.swift.org/t/swift-on-freebsd-preview/83064</link>
            <guid>45837871</guid>
            <pubDate>Thu, 06 Nov 2025 17:37:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forums.swift.org/t/swift-on-freebsd-preview/83064">https://forums.swift.org/t/swift-on-freebsd-preview/83064</a>, See on <a href="https://news.ycombinator.com/item?id=45837871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="Swift on FreeBSD Preview">
      
      <meta itemprop="datePublished" content="2025-11-06T17:18:54Z">
        <meta itemprop="articleSection" content="Platform">
      <meta itemprop="keywords" content="freebsd">
      


          <div id="post_1">
            <div>
              


              <p><span>
                  <time datetime="2025-11-06T17:18:54Z">
                    November 6, 2025,  5:18pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-06T17:18:54Z">
              <span itemprop="position">1</span>
              </span>
            </p></div>
            <div itemprop="text">
              <p>We have been hard at work to bring the Swift toolchain to FreeBSD. A preview Swift bundle for FreeBSD 14.3+ is available at <a href="https://download.swift.org/tmp-ci-nightly/development/freebsd-14_ci_latest.tar.gz" rel="noopener nofollow ugc">https://download.swift.org/tmp-ci-nightly/development/freebsd-14_ci_latest.tar.gz</a>. The bundle contains a Swift development compiler and Swift runtimes needed for compiling Swift programs on, and for, FreeBSD 14 on <code>x86_64</code> machines.</p>
<h2><a name="p-381454-dependencies-1" href="#p-381454-dependencies-1"></a>Dependencies</h2>
<p>The Swift compiler and runtimes have a few dependencies. Please install the following dependencies:</p>
<ul>
<li>zlib-ng</li>
<li>python3</li>
<li>sqlite3</li>
<li>libuuid</li>
<li>curl</li>
</ul>
<h2><a name="p-381454-known-issues-2" href="#p-381454-known-issues-2"></a>Known Issues</h2>
<p>The compiler in the bundle is still under development and isn't part of a release yet and we're not quite done porting everything to FreeBSD.</p>
<p>Here is a list of known issues that you may run into while trying things out.</p>
<ul>
<li>Thread sanitizer reports incorrect failures
<ul>
<li><a href="https://github.com/swiftlang/llvm-project/issues/11759" rel="noopener nofollow ugc">FreeBSD: ThreadSanitizer: main thread finished with ignores enabled ¬∑ Issue #11759 ¬∑ swiftlang/llvm-project ¬∑ GitHub</a></li>
</ul>
</li>
<li>LLDB is unable to execute Swift expressions
<ul>
<li><a href="https://github.com/swiftlang/llvm-project/issues/11760" rel="noopener nofollow ugc">FreeBSD: lldb expression evaluation fails ¬∑ Issue #11760 ¬∑ swiftlang/llvm-project ¬∑ GitHub</a></li>
</ul>
</li>
<li>Command Plugins in a SwiftPM package hangs
<ul>
<li><a href="https://github.com/swiftlang/swift-package-manager/issues/9344" rel="noopener nofollow ugc">FreeBSD: Command Plugin tests are hanging ¬∑ Issue #9344 ¬∑ swiftlang/swift-package-manager ¬∑ GitHub</a></li>
</ul>
</li>
<li>Using standard types with C++ interop results in an undefined voidify symbol
<ul>
<li><a href="https://github.com/swiftlang/swift/issues/85368" rel="noopener nofollow ugc">FreeBSD: C++ Interop: Undefined `__voidify` symbol at link ¬∑ Issue #85368 ¬∑ swiftlang/swift ¬∑ GitHub</a></li>
</ul>
</li>
<li>Importing the C libraries is done through "Glibc". This will change to <code>import FreeBSD</code>
<ul>
<li><a href="https://github.com/swiftlang/swift/issues/81407" rel="noopener nofollow ugc">Add *BSD pthread API notes ¬∑ Issue #81407 ¬∑ swiftlang/swift ¬∑ GitHub</a></li>
</ul>
</li>
<li><code>lld</code> and <code>lldb</code> depend on <code>libxml2.so.2</code>, which is not be available in the system package manager.
<ul>
<li><a href="https://github.com/swiftlang/swift/issues/85348" rel="noopener nofollow ugc">FreeBSD: ld-elf.so.1: Shared object "libxml2.so.2" not found, required by "lldb" ¬∑ Issue #85348 ¬∑ swiftlang/swift ¬∑ GitHub</a></li>
</ul>
</li>
</ul>
<p>We are investigating adding aarch64 support and making the bundle available for all minor versions of FreeBSD 14.</p>
<p>As you find more bugs, please file issues at <a href="https://github.com/swiftlang/swift/issues" rel="noopener nofollow ugc">https://github.com/swiftlang/swift/issues</a>.</p>
<p>We look forward to hearing your feedback. If you're interested in helping add the finishing polish, please feel free to reach out here on the forums.</p>
            </div>

            

                

            
          </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://forums.swift.org/u/kebo"><span itemprop="name">kebo</span></a>
                (Kenta Kubo)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-06T18:16:24Z">
                    November 6, 2025,  6:16pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-06T18:16:24Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>On FreeBSD 15, the following error occurs when executing <code>swift</code>.</p>
<pre data-code-wrap="swift"><code>ld-elf.so.1: Shared object "libutil.so.9" not found, required by "swift"
</code></pre>
<p>As a temporary workaround, <code>doas pkg install compat14x-amd64</code> will solve the issue.</p>
            </div>

            


            
          </div>
          <div id="post_3" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://forums.swift.org/u/piccolo"><span itemprop="name">piccolo</span></a>
                
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-06T18:23:16Z">
                    November 6, 2025,  6:23pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-06T18:23:16Z">
              <span itemprop="position">3</span>
              </span>
            </p>
            <p>Great news, thank you. Registered to this forum just to say that.</p>

            


            
          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://forums.swift.org/u/etcwilde"><span itemprop="name">etcwilde</span></a>
                (Evan Wilde)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-06T18:42:59Z">
                    November 6, 2025,  6:42pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-06T18:42:59Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <div itemprop="text">
              <blockquote>
<p>On FreeBSD 15, the following error occurs when executing <code>swift</code> .</p>
</blockquote>
<p>Yes, the FreeBSD stability policy appears to be within a major version. The bundle is built for FreeBSD 14. I'm glad to see that you were able to find a workaround though.</p>
<blockquote>
<p>For -STABLE branches, it's important to make sure that ABI is compatible across dot releases (in other words, user can expect applications that is compiled for X.0 would run without modification on any X.y releases). We also try to maintain ABI compatibility across .0 releases, but they are not strictly enforced except for libraries that already implements versioned symbols.</p>
</blockquote>
<p><a href="https://wiki.freebsd.org/Releng/ABI" rel="noopener nofollow ugc">https://wiki.freebsd.org/Releng/ABI</a></p>
            </div>

            


            
          </div>
          <div id="post_5" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" rel="nofollow" href="https://forums.swift.org/u/grynspan"><span itemprop="name">grynspan</span></a>
                (Jonathan Grynspan)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2025-11-06T20:14:30Z">
                    November 6, 2025,  8:14pm
                  </time>
                  <meta itemprop="dateModified" content="2025-11-06T20:14:30Z">
              <span itemprop="position">5</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>Generally speaking, I would expect the Swift compatibility policy for FreeBSD to be similar to that of Linux. We distribute toolchains for e.g. Ubuntu 22 and Ubuntu 24 that are distinct. <a href="https://forums.swift.org/u/etcwilde">@etcwilde</a> that sounds right, I hope?</p>
            </div>

            


            
          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICC ditches Microsoft 365 for openDesk (528 pts)]]></title>
            <link>https://www.binnenlandsbestuur.nl/digitaal/internationaal-strafhof-neemt-afscheid-van-microsoft-365</link>
            <guid>45837342</guid>
            <pubDate>Thu, 06 Nov 2025 16:57:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.binnenlandsbestuur.nl/digitaal/internationaal-strafhof-neemt-afscheid-van-microsoft-365">https://www.binnenlandsbestuur.nl/digitaal/internationaal-strafhof-neemt-afscheid-van-microsoft-365</a>, See on <a href="https://news.ycombinator.com/item?id=45837342">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div>
                
<figure>
    <picture>
        <img src="https://static.binnenlandsbestuur.nl/cropped/a98d0512-b270-5bc2-88df-4e7c199b79a3/article/bd/6d/bd6dc138-4bd4-4605-bf73-970017c0e87a/opening_image/opening_image_hero/Internationaal%20Strafhof%20ICC%20shutterstock_1383842294.jpg" alt="Gebouw waar het ICC is gevestigd">
    </picture>
            <figcaption>
                            <span>Het Internationaal Strafhof in Den Haag</span>
                                        <span> - Shutterstock</span>
                    </figcaption>
    </figure>
        </div>
    
                        <p>
            Het Internationaal Strafhof (International Criminal Court, ICC) ruilt Microsoft 365 in voor Open Desk, een Europees open source alternatief. Dat schrijft de Duitse krant Handelsblatt. De krant verwacht dat het ICC met de overstap mogelijk een trend start binnen de Europese publieke sector.
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                                                            
            
                                                                    
    
                                                                                        
    
                                                                                    
                                <p>
            Microsoft bevestigt de breuk aan de nieuwssite&nbsp;<a href="https://www.euractiv.com/news/international-criminal-court-to-ditch-microsoft-office-for-european-open-source-alternative/" target="_blank">Euractiv</a>. ‚ÄòWij hechten waarde aan onze relatie met het ICC als klant en zijn ervan overtuigd dat niets ons vermogen in de weg staat om in de toekomst diensten aan het ICC te blijven leveren,‚Äô zegt een woordvoerder van Microsoft.
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                    <div>
    <h2>Het belangrijkste overheidsnieuws van de dag</h2>
    <p>Schrijf je in voor de Binnenlands Bestuur nieuwsbrief</p>
    <p><a href="https://mijn.binnenlandsbestuur.nl/newsletters/subscribe" target="_blank" rel="noopener">
        <span>aanmelden</span>
    </a>
</p></div>
    
                                                                                                                                                                                                        
                                <p>                        <h2>
            Digitale afhankelijkheidÔªø
            </h2>
            </p>
                                <p>
            Bij Europese overheden leven al langer zorgen over de digitale afhankelijkheid van Amerikaanse bedrijven. Die zorgen zijn sterk toegenomen sinds Donald Trump voor de tweede maal president van de Verenigde Staten werd.
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                                                                                                                                                                                        
                                <p>
            Voor het ICC zijn de zorgen minder hypothetisch dan voor veel andere instituten: Trump heeft zijn ongenoegen met het Strafhof vaak laten blijken en liet sancties opstellen tegen de hoofdaanklager, Karim Khan. Persbureau AP&nbsp;<a href="https://apnews.com/article/icc-trump-sanctions-karim-khan-court-a4b4c02751ab84c09718b1b95cbd5db3" target="_blank">meldde</a>&nbsp;in mei 2025 dat Khan geen toegang meer had tot zijn Outlook e-mail. Microsoft bevestigde dat Khan was ‚Äò<a href="https://www.binnenlandsbestuur.nl/digitaal/microsoft-geen-diensten-aan-icc-organisatie-gestopt" data-url-type="url-external">losgekoppeld</a>‚Äô van Microsoft-diensten, maar benadrukte tegelijkertijd dat het de dienstverlening aan de ICC-organisatie ‚Äògeen moment‚Äô heeft stopgezet.
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                                                                                                        
    
                                                                                        
    
                                                                
                                <p>                        <h2>
            EDICÔªøÔªø
            </h2>
            </p>
                                <p>
            Hoe dan ook zit de angst er bij het ICC goed in. De organisatie gaat gebruikmaken van Open Desk, dat is ontwikkeld door het Zentrum Digitale Souver√§nit√§t (Zendis) in opdracht van het Duitse Federale ministerie van Binnenlandse Zaken. Zendis maakt onderdeel uit van het Digital Commons European Digital Infrastructure Consortium (DC-EDIC), het&nbsp;<a href="https://ibestuur.nl/artikel/europa-krijgt-nieuw-consortium-digital-commons-edic/">Europese consortium</a>&nbsp;waarmee de EU strijdt voor meer digitale autonomie.
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                                                                                                                                                                                
    
                                            
                                <p>                        <h2>
            Mijn bureauÔªø
            </h2>
            </p>
                                <p>
            Ook Nederlandse ambtenaren krijgen in de toekomst mogelijk te maken met de software van Open Desk. Onder de noemer&nbsp;<a href="https://ibestuur.nl/artikel/vasthouden-aan-microsoft-365-is-geen-natuurwet/" target="_blank">Mijn Bureau</a>&nbsp;experimenteert de Nederlandse overheid met een suite met verschillende Europese open source samenwerkingssoftware. Open Desk wordt binnen Mijn Bureau onder meer gebruikt voor e-mail. Mijn Bureau is een samenwerking van de Rijksoverheid, Gemeente Amsterdam en de VNG.&nbsp;
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                                                                                                                                                                                        
                                <p>
            In een vandaag verschenen <a href="https://vng.nl/nieuws/meer-regie-nodig-op-technologie-voor-digitale-autonomie" data-url-type="url-external">position paper</a> pleit de VNG voor meer regie op technologie. Er&nbsp;wordt steeds meer toegewerkt naar verregaande samenwerking op het gebied van digitalisering. ln de Nederlandse Digitaliseringsstrategie (NDS) is het versterken van digitale weerbaarheid en autonomie √©√©n van de prioriteiten.&nbsp;
            </p>
                                                    
            
    
        
    
        
    
    
        
    
    
    
    
                                                                                                                                                                                                                                    <div>
    <h2>Het belangrijkste overheidsnieuws van de dag</h2>
    <p>Schrijf je in voor de Binnenlands Bestuur nieuwsbrief</p>
    <p><a href="https://mijn.binnenlandsbestuur.nl/newsletters/subscribe" target="_blank" rel="noopener">
        <span>aanmelden</span>
    </a>
</p></div>
    
                        
                        
    
        
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FBI tries to unmask owner of archive.is (678 pts)]]></title>
            <link>https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html</link>
            <guid>45836826</guid>
            <pubDate>Thu, 06 Nov 2025 16:18:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html">https://www.heise.de/en/news/Archive-today-FBI-Demands-Data-from-Provider-Tucows-11066346.html</a>, See on <a href="https://news.ycombinator.com/item?id=45836826">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

        

        <p>It is one of the most mysterious and, at the same time, best-known websites on the internet. Archive.today has built up a user base over a period of more than ten years who use the service to access previous snapshots of a web page. So basically like the Wayback Machine of the Internet Archive, only largely free of rules and presumably therefore also anonymous. To the chagrin of the media industry, the service is also often used to bypass paywalls. This is also possible because the service does not adhere to common rules and laws and offers no opt-out option.</p>
<!-- RSPEAK_STOP -->




  


<!-- RSPEAK_START -->

<p>And so far, the operators have gotten away with it. Although there have been minor problems in the history of the service occasionally, for example, a top-level domain operator denied them further use of one of the many archive domains. However, the operation of the project, which is allegedly financed by donations and own funds, was not seriously endangered.</p>
<h3 id="nav_court_order_in__0">Court Order in the USA</h3>
<p>But now the operators of archive.today are apparently fearing bigger trouble. In recent months and years, they had become noticeably quieter. Until two years ago, for example, questions were regularly answered in the blog. In the official X account, which had been silent for over a year, a new post appeared at the end of October <a href="https://x.com/archiveis/status/1984093883056422993" rel="external noopener" target="_blank">new post</a>. ‚ÄúCanary,‚Äù it said there, along with a URL. The mentioned canary bird is likely an allusion to an old custom in mining. A canary brought along warned the miners when it keeled over dead about the threat of invisible gas.</p>
<!-- RSPEAK_STOP -->

  




<!-- RSPEAK_START -->

<p>The deadly danger that the site operators fear is apparently linked to the PDF linked in the X post <a href="https://pdflink.to/1e0e0ecd/" rel="external noopener" target="_blank">linked PDF</a>. It contains a court order that the US investigative authority FBI has obtained. It instructs the Canadian provider Tucows to hand over comprehensive data about the customer behind archive.today. It concerns address and connection data as well as payment information. If Tucows does not provide the data, penalties are threatened. Whether the court order is genuine and how the operators of the site obtained it could not be verified so far.</p>
<h3 id="nav_is_the_operator__1">Is the operator based in Russia?</h3>
<p>Why the FBI is currently interested in archive.today, which is also accessible under the domains archive.is and archive.ph, is not evident from the court order. However, there are several obvious starting points for investigations: in addition to the obvious reason of copyright issues, the investigators could also be pursuing suspicions about unclear financing, the origin of the operators, or the technical approach.</p>
<!-- RSPEAK_STOP -->


  



  




<!-- RSPEAK_START -->

<p>In 2023, Finnish blogger Janni Patokallio compiled various clues and research results in a post <a href="https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet" rel="external noopener" target="_blank">in a post</a>. According to this, Archive.today uses a botnet with changing IP addresses to circumvent anti-scraping measures. There are also indications that the operator(s) are based in Russia.</p>


<!-- RSPEAK_STOP -->

<!-- RSPEAK_START -->
<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:mki@heise.de" title="Malte Kirchner">mki</a>)</span>
<!-- RSPEAK_START -->
</p>
<div>
    <p>
      Don't miss any news ‚Äì follow us on
      <a href="https://www.facebook.com/heiseonlineEnglish">Facebook</a>,
      <a href="https://www.linkedin.com/company/104691972">LinkedIn</a> or
      <a href="https://social.heise.de/@heiseonlineenglish">Mastodon</a>.
    </p>
    <p>
      <em>This article was originally published in
      
        <a href="https://www.heise.de/news/Archive-today-FBI-fordert-Daten-von-Provider-Tucows-11065717.html">German</a>.
      
      It was translated with technical assistance and editorially reviewed before publication.</em>
    </p>
  </div>



        

        
        <!-- RSPEAK_STOP -->
        

<a-gift has-access="">
    
</a-gift>


        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI probably can't make ends meet. That's where you come in (144 pts)]]></title>
            <link>https://garymarcus.substack.com/p/if-you-thought-the-2008-bank-bailout</link>
            <guid>45836809</guid>
            <pubDate>Thu, 06 Nov 2025 16:17:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://garymarcus.substack.com/p/if-you-thought-the-2008-bank-bailout">https://garymarcus.substack.com/p/if-you-thought-the-2008-bank-bailout</a>, See on <a href="https://news.ycombinator.com/item?id=45836809">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>A few days ago, Sam Altman got seriously pissed off when Brad Gerstner had the temerity to ask how OpenAI was going to pay the $1.4 trillion in obligations he was taking on, given a mere $13 billion in revenue. </p><p>In a long, but mostly empty answer Altman pointed to revenue that hasn‚Äôt been reported and that maybe doesn‚Äôt exist, attacked the questioner, and promised that future revenue would be awsome</p><blockquote><p>First of all. We‚Äôre doing well more revenue than that. Second of all, Brad, if you want to sell your shares, I‚Äôll find you a buyer. I just, enough. I think there‚Äôs a lot of people who would love to buy OpenAI shares. I think people who talk with a lot of breathless concern about our compute stuff or whatever, that would be thrilled to buy shares. So I think we could sell your shares or anybody else‚Äôs to some of the people who are making the most noise on Twitter about this very quickly. We do plan for revenue to grow steeply. Revenue is growing steeply. We are taking a forward bet that it‚Äôs going to continue to grow and that not only will ChatGPT keep growing, but we will be able to become one of the important AI clouds, that our consumer device business will be a significant and important thing, that AI that can automate science will create huge value. ..  we carefully plan. We understand where the technology, where the capability is going to grow and how the products we can build around that and the revenue we can generate. We might screw it up. This is the bet that we‚Äôre making and we‚Äôre taking a risk along with that. A certain risk is if we don‚Äôt have the compute, we will not be able to generate the revenue or make the models at this kind of scale.‚Äù </p></blockquote><p>What Altman couldn‚Äôt say then was that he has a plan, to reduce the cost of his borrowing ‚Ä¶ by having the American taxpayer (indirectly) foot the bill.</p><p><span>The cat came out of the bag today, </span><a href="https://www.wsj.com/video/openai-wants-federal-backstop-for-new-investments/4F6C864C-7332-448B-A9B4-66C321E60FE7" rel="">at a Wall Street Journal conference</a><span>, from the mouth of OpenAI‚Äôs CFO, who seemed to be test-piloting the notion:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!hSk5!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!hSk5!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 424w, https://substackcdn.com/image/fetch/$s_!hSk5!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 848w, https://substackcdn.com/image/fetch/$s_!hSk5!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!hSk5!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!hSk5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg" width="1265" height="1235" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1235,&quot;width&quot;:1265,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:255444,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/178133365?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!hSk5!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 424w, https://substackcdn.com/image/fetch/$s_!hSk5!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 848w, https://substackcdn.com/image/fetch/$s_!hSk5!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!hSk5!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8f8c0f94-409f-4835-a64c-f8b74c7cf454_1265x1235.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>In justifying what would like be among the biggest (indirect) government subsidies in history, Friar said, ‚ÄúAI is almost a national strategic asset. We really need to thoughtful when we think about competition with, for example, China.‚Äù (NVidia seems intent on making exactly the same play.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-178133365" href="https://garymarcus.substack.com/p/if-you-thought-the-2008-bank-bailout#footnote-1-178133365" target="_self" rel="">1</a></span><span>)</span></p><p>Remember this tweet?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Ky_L!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Ky_L!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Ky_L!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Ky_L!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Ky_L!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Ky_L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg" width="1336" height="726" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:726,&quot;width&quot;:1336,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:92918,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://garymarcus.substack.com/i/178133365?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Ky_L!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 424w, https://substackcdn.com/image/fetch/$s_!Ky_L!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 848w, https://substackcdn.com/image/fetch/$s_!Ky_L!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 1272w, https://substackcdn.com/image/fetch/$s_!Ky_L!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F73c08f2d-8832-4761-8cd0-c0bb0d4907ec_1336x726.jpeg 1456w" sizes="100vw"></picture></div></a></figure></div><p>To the letter, almost 10 months to the day, exactly that game is now on.  And I already hear rumors that the government is likely go along.</p><p>Which means you, the taxpayer, will be footing the bill. </p><p>Disgusting. Tell your congress person  ‚Äî today ‚Äî that you don‚Äôt want your taxes used to bail out overhyping and economically shaky AI companies that spend far more than they earn.  Workers, already feeling the knife from layoffs, should not be footing the bill.</p><p>Get ahead of this before the too-big-to-fail bullshit becomes too-late-to-stop.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Australia has so much solar that it's offering everyone free electricity (259 pts)]]></title>
            <link>https://electrek.co/2025/11/04/australia-has-so-much-solar-that-its-offering-everyone-free-electricity-3h-day/</link>
            <guid>45836104</guid>
            <pubDate>Thu, 06 Nov 2025 15:08:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/11/04/australia-has-so-much-solar-that-its-offering-everyone-free-electricity-3h-day/">https://electrek.co/2025/11/04/australia-has-so-much-solar-that-its-offering-everyone-free-electricity-3h-day/</a>, See on <a href="https://news.ycombinator.com/item?id=45836104">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1600" height="800" src="https://electrek.co/wp-content/uploads/sites/3/2025/11/pexels-photo-11678747-e1762283768414.jpeg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/11/pexels-photo-11678747-e1762283768414.jpeg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/11/pexels-photo-11678747-e1762283768414.jpeg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/11/pexels-photo-11678747-e1762283768414.jpeg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/11/pexels-photo-11678747-e1762283768414.jpeg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high">			<figcaption>
				Wemen Solar Farm, Victoria, Australia. Photo: <a href="https://www.pexels.com/photo/wemen-solar-farm-in-victoria-australia-11678747/">Mark Stebnicki on Pexels</a>			</figcaption>
			
	</figure>

<p>The Australian government is floating a scheme that would share the benefits of solar power with everyone on the grid, offering totally free electricity to ratepayers in the middle of the day, when the sun is shining the strongest.</p>



<p>Australia is a sunny place. It‚Äôs kind of known for it. It‚Äôs the <a href="https://www.abc.net.au/news/2015-08-10/solar-coverage-fact-check-is-australia-sunniest-continent/6659316">sunniest continent</a>, and the sunniest country outside of the Middle East/Africa, with <a href="https://documents1.worldbank.org/curated/en/466331592817725242/pdf/Global-Photovoltaic-Power-Potential-by-Country.pdf">extensive photovoltaic power potential</a> across its entire territory.</p>



<p>In recognition of that, Australia has been installing lots of solar power. Formerly a coal-heavy nation (for which <a href="https://oec.world/en/profile/country/aus?depthSelector1=HS2Depth">coal is still its 2nd-largest export</a>), solar and wind have <a href="https://www.energy.gov.au/energy-data/australian-energy-statistics/data-charts/australian-electricity-generation-fuel-mix">rapidly taken over Australia‚Äôs electricity grid</a>, pushing coal and methane gas out of the equation.</p>



<p>This has taken a big chunk out of Australia‚Äôs electricity-related climate emissions, and of course resulted in clean air benefits as dirty coal is pushed out of the grid. And climate emissions matter a lot for Australia, a country that is becoming more unbearably hot and <a href="https://www.csiro.au/en/news/All/Articles/2024/November/State-of-the-Climate-2024">suffering more fires due to climate change</a>. (Though Australia is also a great example of how<a href="https://en.wikipedia.org/wiki/Montreal_Protocol"> global cooperation on environmental issues</a> can fix a huge problem, as they are the primary beneficiary of global action on <a href="https://theconversation.com/saving-the-ozone-layer-why-the-montreal-protocol-worked-9249">closing the hole in the Ozone layer</a>)</p>	
	



<p>So solar power has been a <a href="https://www.climatecouncil.org.au/resources/record-breaking-renewables-send-coal-to-an-all-time-low/">great thing for Australia</a>, especially with <a href="https://www.climatecouncil.org.au/resources/seize-the-sun/">rooftop solar on Australian homes</a>.</p>



<p>But it can lead to swingy electricity supply, given that solar only generates electricity when the sun is out.</p>



<h2 id="h-how-swings-in-solar-supply-and-electricity-pricing-work">How swings in solar supply and electricity pricing work</h2>



<p>Most areas have certain times of day where more electricity is used than others. These are referred to as ‚Äúpeak hours‚Äù and generally they happen in the early evening, when people get home from work, turn on the HVAC, cook dinner, do laundry and the like.</p>



<p>But there are also certain times of day when more electricity is generated, and that‚Äôs particularly the case in places with high solar penetration. Solar obviously generates energy only during the day, and creates a peak of generation in the middle of the day, when most people are at work.</p>



<p>There are ways to mitigate this ‚Äì for example, with batteries, which Australia has also <a href="https://electrek.co/2018/05/11/tesla-giant-battery-australia-reduced-grid-service-cost/">used a lot of</a> (and is thinking about <a href="https://electrek.co/2024/11/11/australia-clears-the-way-for-evs-to-help-save-the-grid-with-v2g-this-summer/">extending that to EV batteries too</a>). Wind power also helps, since wind tends to pick up in the hours that solar is dropping off.</p>



<p>But another way to mitigate it is through simple economics. Offer people lower prices in the hours that electricity is more abundant, and higher prices in hours where it isn‚Äôt. Then, people will tend to use electricity when they can ‚Äì especially if they have shiftable loads like electric cars, laundry, pool pumps and such, which don‚Äôt need to be on at the same time every day (unlike HVAC, cooking, and lighting, for example).</p>



<p>Most electricity providers will offer something like this, called a ‚Äútime of use‚Äù plan. These plans differ in their rates and peak hours depending on your location and how the supply/demand curves work for electricity there (and have seen common use among electric car owners because of the outsized effect an EV has on home electricity use).</p>



<p>On the utility side, though, the swings in price can be much more drastic. Wholesale prices for electricity can go up to multiple dollars per kilowatt-hour during times of extreme demand when the grid is stressed, and electricity prices can even go negative when there is little demand and lots of supply, particularly on an islanded grid like Australia (this also happens in Texas, where the grid is<a href="https://electrek.co/2024/10/03/hell-froze-over-in-texas-us-grid-first-time/"> largely disconnected</a> from the rest of the US). These swings are ironed out for the consumer, so things aren‚Äôt as spiky for us, but it can be quite a rollercoaster on the grid side.</p>



<p>In Australia and other places with high solar penetration, these negative electricity prices often happen during the day. That‚Äôs when generation is the highest for solar panels, and household loads are typically low.</p>



<h2 id="h-australia-proposes-letting-everyone-benefit-from-negative-wholesale-rates">Australia proposes letting everyone benefit from negative wholesale rates</h2>



<p>So, the Australian government has decided on a scheme to bring those electricity savings to the consumer, with what its calling its ‚ÄúSolar Sharer‚Äù program.</p>



<p>The program would require electricity retailers to provide free electricity to everyone for at least three hours a day, in recognition of the incredibly low wholesale cost of electricity during daytime due to extensive solar power penetration.</p>



<p>These would likely be in the middle of the day, when most people aren‚Äôt home. However, every home has some amount of shiftable electricity load, and the Solar Sharer scheme would encourage people to make use of that. With modern appliances that can be scheduled to start in the middle of the day, people can just plan to do laundry, run the dishwasher, run the pool pump, or charge their car at noon, instead of whenever else they were going to.</p>



<p>Additionally, people could fill up a home battery during the day, and then use that electricity during peak hours when rates are higher. And this plan will help to incentivize private installation of batteries, or other shiftable loads.</p>



<p>The overall effect of this is that it will help to iron out electricity use, making it track more closely with electricity supply, reducing the need for grid upgrades to manage swings in generation. Just turning on this simple behavioral switch, and then publicizing it so customers know to use electricity in the free hours, will both help the grid and help ratepayers save money.</p>



<p>Better yet, this scheme will apply not just to people who have solar or home batteries, but to people who live in places where they can‚Äôt put up solar ‚Äì those who live in apartments and the like. The government says it will require companies to offer this scheme to all customers, not just those with solar.</p>



<p>The government did receive some pushback from electricity retailers, who feel they were not properly consulted on the plan. But Australia‚Äôs Climate Change Minister Chris Bowen said he would make ‚Äúno apologies‚Äù if this scheme reduced their margins, and that ‚Äúconsumers are put first‚Äù as <a href="https://www.abc.net.au/news/2025-11-03/energy-retailers-offer-free-power-three-hours-dmo/105965472">reported by the Australian Broadcasting Corporation</a>.</p>



<p>The government plans to implement the scheme starting in July next year, first in Queensland, New South Wales and South Australia. If it works well, other regions will get it starting in 2027.</p>



<h2 id="h-electrek-s-take">Electrek‚Äôs Take</h2>



<p>Australia is doing a lot of great things with electricity, and acting somewhat like a natural laboratory for a lot of ideas that people have been talking about for a long time. Since the whole country has similar solarization, it can work somewhat as a unit in pushing for solar power, and for reforms to help enable it.</p>




	<p>It‚Äôs already working on V2G, with a <a href="https://www.originenergy.com.au/about/investors-media/australias-first-vehicle-to-grid-enabled-ev-subscription-trial/">huge trial started recently</a>, and the wide adoption of solar and batteries is proving that even a solar-heavy grid can still work. And an idea like this, showing how simple economics can be used to change consumer behavior, could provide a model for the rest of the world on how to usher us into a cleaner energy future.</p>



<p>So we‚Äôll be watching with interest how this turns out ‚Äì I think it will likely turn out quite well, if the government goes through with it fully.</p>



<hr>



<p><em>The 30% federal solar tax credit is ending this year. If you‚Äôve ever considered going solar, now‚Äôs the time to act. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out&nbsp;</em><a href="https://www.dpbolvw.net/click-101268381-15908683"><em>EnergySage</em></a><em>, a free service that makes it easy for you to go solar. It has hundreds of pre-vetted solar installers competing for your business, ensuring you get high-quality solutions and save 20-30% compared to going it alone. Plus, it‚Äôs free to use, and you won‚Äôt get sales calls until you select an installer and share your phone number with them.</em></p>



<p><em>Your personalized solar quotes are easy to compare online and you‚Äôll get access to unbiased Energy Advisors to help you every step of the way.&nbsp;</em><a href="https://www.dpbolvw.net/click-101268381-15908683"><em>Get started here</em></a><em>.</em></p>
	<p>
				<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
			</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kimi K2 Thinking, a SOTA open-source trillion-parameter reasoning model (568 pts)]]></title>
            <link>https://moonshotai.github.io/Kimi-K2/thinking.html</link>
            <guid>45836070</guid>
            <pubDate>Thu, 06 Nov 2025 15:06:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://moonshotai.github.io/Kimi-K2/thinking.html">https://moonshotai.github.io/Kimi-K2/thinking.html</a>, See on <a href="https://news.ycombinator.com/item?id=45836070">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Cloudflare Tells U.S. Govt That Foreign Site Blocking Efforts Are Trade Barriers (283 pts)]]></title>
            <link>https://torrentfreak.com/cloudflare-tells-u-s-govt-that-foreign-site-blocking-efforts-are-digital-trade-barriers/</link>
            <guid>45835123</guid>
            <pubDate>Thu, 06 Nov 2025 13:41:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/cloudflare-tells-u-s-govt-that-foreign-site-blocking-efforts-are-digital-trade-barriers/">https://torrentfreak.com/cloudflare-tells-u-s-govt-that-foreign-site-blocking-efforts-are-digital-trade-barriers/</a>, See on <a href="https://news.ycombinator.com/item?id=45835123">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/cloudflare-logo-dark.jpg.webp">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/cloudflare-logo-dark.jpg" alt="cloudflare logo" width="300" height="171">
</picture>
Every year, the office of the United States Trade Representative (USTR) publishes the National Trade Estimate Report on Foreign Trade Barriers.</p>
<p>The report is compiled based on input from key industry players. This includes submissions from copyright industry groups that frequently highlight piracy challenges that in their view act as barriers to trade.</p>
<p>In previous years, for example, the MPA and others have called for more site-blocking efforts to counter the piracy threat. Interestingly, however, other American companies now inform the USTR that foreign site-blocking measures are becoming a significant trade barrier. </p>
<h2>Cloudflare Sees Piracy Blockades as Trade Barriers</h2>
<p>To share its concerns, Cloudflare decided to participate in the annual trade barriers consultation for the first time this year. The company describes itself as a ‚Äúleading connectivity cloud company‚Äù running one of the world‚Äôs largest networks, providing security, performance, and reliability services.</p>
<p>According to Cloudflare, several foreign countries disproportionately impact U.S. technology providers, with many concerns relating to site-blocking measures that aim to deter online piracy.</p>
<h3>Spain</h3>
<p>Cloudflare writes that Spanish courts allow rightsholders to request ‚Äúoverbroad court orders‚Äù that authorize IP address blocking. Since a single IP address can serve thousands of domains, disrupting pirates often means that many legitimate sites and services are blocked too, causing widespread collateral damage.</p>
<p>‚ÄúThis practice results in the widespread and repeated disruption of tens of thousands of unrelated, legitimate websites, as well as the disruption of digital services, with no judicial opportunity for remedy,‚Äù Cloudflare writes. </p>
<p>‚ÄúThese actions, designed to protect a narrow set of commercial interests, have caused significant collateral harm to businesses and users who are not the intended targets, without recourse or the possibility for affected parties to challenge the underlying order.‚Äù</p>
<p>The Spanish Government is aware of the problems, which Cloudflare says are at odds with international standards, but has chosen not to intervene in the issue. Therefore, it continues to present a significant trade barrier.</p>
<h3>Italy</h3>
<p>Cloudflare reports similar concerns in Italy, where the ‚ÄúPiracy Shield‚Äù site-blocking law has a direct effect on American companies. This blocking regulation requires network providers, including CDNs, to comply with blocking notices within 30 minutes. </p>
<p>‚ÄúThe failure to include adequate safeguards against collateral damage has led to the inappropriate blocking of shared services of large cloud providers, which are disproportionately American businesses,‚Äù Cloudflare notes. </p>
<p>‚ÄúFor instance, the blocking of a Cloudflare IP address resulted in tens of thousands of non-targeted websites being blocked in February 2024. Furthermore, the blocking of the domain ‚Äúdrive.usercontent.google.com‚Äù in October denied Italian users access to Google Drive for over 12 hours.‚Äù</p>
<center><em>Cloudflare on Italy</em></center><br><center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/cloudflareshield.png.webp 2158w, https://torrentfreak.com/images/cloudflareshield-300x96.png.webp 300w" sizes="auto, (max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/cloudflareshield.png" alt="cloudflare shield" width="600" height="191" srcset="https://torrentfreak.com/images/cloudflareshield.png 2158w, https://torrentfreak.com/images/cloudflareshield-300x96.png 300w, https://torrentfreak.com/images/cloudflareshield-600x191.png 600w, https://torrentfreak.com/images/cloudflareshield-150x48.png 150w, https://torrentfreak.com/images/cloudflareshield-1536x490.png 1536w, https://torrentfreak.com/images/cloudflareshield-2048x653.png 2048w" sizes="auto, (max-width: 600px) 100vw, 600px">
</picture>
</center>
<p>Efforts to expand Piracy Shield to public DNS resolvers and VPN services only make the problem worse, Cloudflare says, noting that some U.S. companies have already decided to leave the European country.</p>
<p>Automated piracy blocks are not the only reported trade barrier in Italy. Cloudflare also notes that the country allows rightsholders to ‚Äúabuse‚Äù the courts to disrupt U.S. businesses by granting <em>ex parte</em> blocking orders without giving the companies a chance to oppose them.</p>
<p>‚ÄúThis coercive, penalty-based approach to removal of content, without adequate judicial review or due process protections, is a significant barrier to doing business in Italy,‚Äù Cloudflare writes.</p>
<h3>France</h3>
<p>In France, Cloudflare highlights Article L.333-10 of the Sports Code as a key problem. This has resulted in several pirate site blocking orders that go beyond regular Internet providers, requiring DNS resolvers and VPN services to take action as well. </p>
<p>Cloudflare notes that some services lack the technical capabilities to implement these orders and as a result, several U.S. companies have already left the country. </p>
<center><em>Cloudflare on France</em></center><br><center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/francecloud.png.webp 2095w, https://torrentfreak.com/images/francecloud-300x98.png.webp 300w" sizes="auto, (max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/francecloud.png" alt="france cloudflare" width="600" height="196" srcset="https://torrentfreak.com/images/francecloud.png 2095w, https://torrentfreak.com/images/francecloud-300x98.png 300w, https://torrentfreak.com/images/francecloud-600x196.png 600w, https://torrentfreak.com/images/francecloud-150x49.png 150w, https://torrentfreak.com/images/francecloud-1536x503.png 1536w, https://torrentfreak.com/images/francecloud-2048x671.png 2048w" sizes="auto, (max-width: 600px) 100vw, 600px">
</picture>
</center>
<p>Recently, France passed a new anti-piracy bill that opens the door to automated IP-address blocking, similar to Italy‚Äôs Piracy Shield. This is a major concern for Cloudflare, which fears that this will only lead to more collateral damage.</p>
<p>‚ÄúIt increases the risk of overblocking legitimate content or mistakenly targeting websites that operate lawfully, potentially disrupting cross-border digital services,‚Äù Cloudflare writes. </p>
<h3>South Korea</h3>
<p>South Korea has also created trade barriers due to its site-blocking measures, Cloudflare reports. A revision to the Network Act in 2023 now requires ‚ÄúCDNs to restrict access to illegal content‚Äù.</p>
<p>As a result, Cloudflare and other American companies are required to maintain detailed and regularly updated blocklists.</p>
<p>‚ÄúThe South Korea Communication Commission (KCC) sends U.S. CDN providers a ‚Äòblock list‚Äô of over 1.5 million URLs (with 30,000 new additions monthly),‚Äù Cloudflare writes, noting that this places an ‚Äúunprecedented compliance burden‚Äù on companies. </p>
<h2>Conflicting Demands at the U.S. Trade Office</h2>
<p>Cloudflare urges the USTR to take these concerns into account for its upcoming National Trade Estimate Report. Ideally, it wants these trade barriers to be dismantled.</p>
<p>These calls run counter to requests from rightsholders, who urge the USTR to ensure that more foreign countries implement blocking measures. With potential site-blocking legislation being <a href="https://torrentfreak.com/u-s-senators-introduce-new-pirate-site-blocking-bill-block-beard/">considered in U.S. Congress</a>, that may impact local lobbying efforts as well. </p>
<p>If and how the USTR will address these concerns will become clearer early next year, when the 2026 National Trade Estimate Report is expected to be published. </p>
<p><em>‚Äî</em></p><p><em>A copy of Cloudflare‚Äôs submission for the USTR‚Äôs 2025 National Trade Estimate Report on Foreign Trade Barriers is available <a href="https://torrentfreak.com/images/USTR-NTE-Cloudflare-2026.pdf">here (pdf)</a></em></p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I analyzed the lineups at the most popular nightclubs (139 pts)]]></title>
            <link>https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/</link>
            <guid>45835083</guid>
            <pubDate>Thu, 06 Nov 2025 13:37:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/">https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/</a>, See on <a href="https://news.ycombinator.com/item?id=45835083">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
        
  <article>
    <header>
      
      
      
        
      
      
    </header>
    <div>
        <p>A few years back I did a bit of dance music related data visualization over at <a href="https://lazilyevaluated.co/" target="_blank" rel="noreferrer">Lazily Evaluated</a>. My favourite was an analysis of clubs and their lineups using <a href="https://ra.co/" target="_blank" rel="noreferrer">Resident Advisor / RA</a> data, I called it <a href="https://lazilyevaluated.co/clubster-analysis/" target="_blank" rel="noreferrer"><em>Clubster Analysis</em></a>. I always wanted to dig into the technical aspects of gathering the data, analyzing it and building the charts and graphs to tell a story and give people insight. With this blog I now have the right venue for that kind of tech talk, so here goes.</p>
<h2 id="data-gathering">Data gathering <span><a href="#data-gathering" aria-label="Anchor">#</a></span></h2><p>To visualize data, first you have to get some! For this purpose I wrote a little <a href="https://github.com/Kalli/clubster-analysis/tree/master/scraper" target="_blank" rel="noreferrer">scraper</a> in Python. I used <a href="https://www.crummy.com/software/BeautifulSoup/" target="_blank" rel="noreferrer">Beautiful Soup</a> to parse the html and grab the bits and pieces I was interested in.</p>
<p>My scraping of a few thousand pages didn‚Äôt cause considerable load on the RA servers. But in the age of overzealous AI scrapers it‚Äôs worth being polite, so I throttled according to their robots.txt. I also maintained a local cache of html files I had already downloaded, so that I wouldn‚Äôt have fetch the same data repeatedly (past lineups are unlikely to change after the fact) just because I discovered some bug or error in my parsing.</p>
<p>The order I scraped in was:</p>
<ul>
<li>Get the 20 most popular regions in RA (and then I dropped ‚Äú<em>Streamland</em>‚Äù which was a pandemic era pseudo-region)</li>
<li>Fetch the most popular clubs and some related metadata for all of those regions.</li>
<li>For each club, get the lineups for every 2019 event of theirs (the last full year before the pandemic started).</li>
<li>Save the results to <a href="https://github.com/Kalli/clubster-analysis/tree/master/data" target="_blank" rel="noreferrer">csv files</a></li>
</ul>
<h2 id="clean-up-verification-and-analysis">Clean up, verification and Analysis <span><a href="#clean-up-verification-and-analysis" aria-label="Anchor">#</a></span></h2><p>I did some spot checks to verify that my parsing was working as I expected and added tests to make sure <a href="https://github.com/Kalli/clubster-analysis/blob/master/scraper/tests.py" target="_blank" rel="noreferrer">I handled edge cases</a> and normalized artist names. There was a lot of variance in how dates were formatted, how artists were linked, etc.</p>
<p>After that I <a href="https://github.com/Kalli/clubster-analysis/blob/master/processing.py" target="_blank" rel="noreferrer">analyzed the data</a>. I built one big table/dataframe in Pandas by joining all the info from the csv files. Then I calculated the similarities between each pair of clubs in the data set using the <a href="https://en.wikipedia.org/wiki/Jaccard_index" target="_blank" rel="noreferrer">Jaccard index</a>. Consider all the artists that have played at two given clubs, take the intersection (number of artists that have featured in lineups at both clubs) over the union (all the artists that have performed at one or the other). As an example if Club A had 100 artists booked and Club B had 100 artists, and they had 10 bookings in common, the Jaccard index would be 10/190 = ~5%. This gives you a good way to compare large and small clubs and balances large and small lineups (some of the clubs have multiple rooms with very long events, others have one dj playing in one room all night long once a week).</p>
<p>Based on the Jaccard index we can build a graph, <a href="https://networkx.org/" target="_blank" rel="noreferrer">using NetworkX</a> from all the clubs. The edges between two nodes are weighted by the similarity of those clubs. On top of the graph we run <a href="https://python-louvain.readthedocs.io/en/latest/api.html" target="_blank" rel="noreferrer">community detection</a> to create clusters (hence the <em>clubster</em> name). This gives us a rough idea of which clubs are most similar, that is to say, have similar tastes in their bookings.</p>
<h2 id="results">Results <span><a href="#results" aria-label="Anchor">#</a></span></h2><p>For the year 2019, there were 131 clubs in the data set with 8.502 events. There were 9.405 unique artists making up 30.482 individual bookings. This means that the average artist in the dataset was booked 3.24 times at those clubs in that year and the average event had 3.5 artists on the line up.</p>
<p>As a whole, out of 8.515 possible pairs of clubs, 3.716 pairs had some overlap in their bookings and out of those the average overlap was 1%. This was lower than I thought, the bookings at European clubs felt more homogenous to me, but I suppose they book <em>a lot</em> of artists. It would be interesting to get more data, recent and historic, and see how this has evolved through time.</p>
<h2 id="visualization">Visualization <span><a href="#visualization" aria-label="Anchor">#</a></span></h2><p>This was my first time using <a href="https://d3js.org/" target="_blank" rel="noreferrer">D3</a> to draw charts. There was a bit of a learning curve, in earlier projects I had used higher level charting libraries which have simpler apis. But with D3 you get a lot of control over how your charts look and behave which I think I used to good effect in this instance.</p>
<figure>
  <img src="https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/chart.png" alt="The primary cluster visualization of the project">
  <figcaption>
      Visualization showing the neighborhoods the clubs cluster into based on lineup similarities.
  </figcaption>
</figure>
<p>My main goal was to visualize the clusters and to allow people to interact with the clubs. I coloured the clubs according to their clusters and sized them based on the number of followers they had on RA. I played around with the gravity and placement of the cluster, trying to find a balance that worked on different screen sizes as well as being a fair portrayal of the different communities.</p>
<figure>
    <img src="https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/club-comparison.png" alt="Interactive comparison of two clubs from the dataset">
  <figcaption>
      Users can click and compare different clubs in the dataset.
  </figcaption>
</figure>
<p>I then did some scrollytelling to tell the story of the data, as I saw it, while the reader scrolls down the page. But I also added filters and interactivity for people to explore and see if they agree with my telling of the story or if they can find one of their own.</p>
<p>At the time I didn‚Äôt find any great React and D3 bridges, so it was a bit of a hassle getting the React components to play nice with the D3 graph, but in the end I was able to connect the two with <code>createRef</code> to the D3 svg component.</p>
<p>Besides the clustering I looked into the ‚Äú<em>resident factor</em>‚Äù, how many times an artist was booked at a club repeatedly compared to all the one offs. This was lower than expected, most of these clubs were booking a constantly rotating assembly of talent, residents don‚Äôt play as big a part as I would have thought.</p>
<p>Transitioning between the different sections of these graphs was one of my favourite parts. Seeing the clusters morph into dots and candlestick charts (and back again) was oddly satisfying. Took a lot of tweaking, but I think it really tied together the scrollytelling experience.</p>
<figure>
  <img src="https://dev.karltryggvason.com/how-i-analyzed-the-lineups-at-the-worlds-most-popular-nightclubs/transition.gif" alt="Transitioning between scenes in the Clubster Analysis visualization">
  <figcaption>
      D3 let me build neat animations to transition between charts.
  </figcaption>
</figure>
<p>I don‚Äôt think these transitions would have been possible with the higher level charting libraries I‚Äôd used previously. So the decision to go with D3 felt justified.</p>
<h2 id="summary">Summary <span><a href="#summary" aria-label="Anchor">#</a></span></h2><p>This was a great pandemic project that combined web scraping, data analysis, and interactive visualization to explore the global dance music club scene. I learned me some D3 for the visualization, got better at doing cartesian graphing calculations in my head and learned about the underlying svg mechanics that power those graphs.</p>
<p>The results surprised me: despite my perceived homogeneity of European club bookings, only 1% average overlap between venues suggested more diverse landscape than I expected. The diminished role of residents compared to one-off bookings also challenged my assumptions about how these clubs operate. For the story telling maintaining the balance between a narrative and letting users explore and decide for themselves was a fun challenge. I think these sort of passion projects can give us deep insights into our world and culture.</p>
<p>The technical stack I worked with: Python, Pandas, NetworkX, D3, and React proved powerful despite some integration challenges. The complete project is <a href="https://github.com/Kalli/clubster-analysis" target="_blank" rel="noreferrer">available on GitHub</a> and you can explore the <a href="https://lazilyevaluated.co/clubster-analysis/" target="_blank" rel="noreferrer">live interactive visualization</a> yourself.</p>
<p>I had a lot of fun building this and am proud of the result. If you‚Äôre working on cultural data analysis, need help with web scraping and visualization, or just want to discuss interesting datasets, feel free to reach out.</p>

      </div>
    
  </article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[IKEA launches new smart home range with 21 Matter-compatible products (281 pts)]]></title>
            <link>https://www.ikea.com/global/en/newsroom/retail/the-new-smart-home-from-ikea-matter-compatible-251106/</link>
            <guid>45834980</guid>
            <pubDate>Thu, 06 Nov 2025 13:26:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ikea.com/global/en/newsroom/retail/the-new-smart-home-from-ikea-matter-compatible-251106/">https://www.ikea.com/global/en/newsroom/retail/the-new-smart-home-from-ikea-matter-compatible-251106/</a>, See on <a href="https://news.ycombinator.com/item?id=45834980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div containerclass="" data-astro-cid-zgyzv6ok=""><!----><p><span>IKEA is launching 21 new smart home products focusing on lighting, sensors, and control ‚Äî all built to work with Matter, the universal smart home standard. The launch marks a significant step in making smart home technology easier to use, more affordable, and better adapted to real-life needs in the home.&nbsp;</span></p><p><span>With this launch, IKEA is rebuilding its smart home system and product range from the ground up. The new launch reflects years of development and testing in real homes, and a growing understanding of how people want smart products to work in their daily life.&nbsp;</span></p><p><span>The launch includes both new products and updates to existing categories ‚Äì now built to work with Matter. This means IKEA smart products can connect with a wider range of devices and platforms, making it easier for customers to build a smart home across different brands.&nbsp;</span></p><p><span>‚ÄúUntil now, smart home technology hasn‚Äôt been easy enough to use for most people ‚Äî or affordable enough for many to consider. This launch brings us closer to helping everyone feel ready and confident to get started,‚Äù says David Granath, Range Manager at IKEA of Sweden.&nbsp;</span></p><p><span>The updated range focuses on three key segments*, that provide the building blocks of a smart home that‚Äôs flexible, intuitive, and easy to expand over time.&nbsp;&nbsp;</span></p><ul><li><span><strong>Lighting</strong> ‚Äì The new smart bulb range from IKEA. Comes in a variety of shapes, sizes, lumen levels and styles, including colour and white spectrum options, and dimmable features.&nbsp;</span></li><li><span><strong>Sensors</strong> ‚Äì motion, air quality, humidity and water leakage sensors designed to support wellbeing and prevent damage&nbsp;</span></li><li><span><strong>Control </strong>‚Äì Remotes that make it easy to control devices from a distance, and a smart plug that can turn any product into a smart product.&nbsp;</span></li></ul><p><em><span>*</span></em><span>Full product list further down.&nbsp;&nbsp;&nbsp;</span></p><p><span>‚ÄúThis launch is about making the smart home experience better and broader. We're upgrading our most-appreciated products while also adding new ones to solve even more everyday challenges. Our focus has been on keeping things simple from setup to daily use, so it‚Äôs easy for people to start, use and grow a smart home,‚Äù says Stjepan Begic, Product Developer at IKEA of Sweden.&nbsp;</span></p><p><span>All Matter-enabled products need a smart home hub to work ‚Äî like IKEA‚Äôs DIRIGERA hub, or one from another brand. As a </span><a data-track-category="Text link" href="https://www.ikea.com/global/en/newsroom/sustainability/ikea-announces-new-chapter-in-designing-technology-for-the-home-250709/"><span>certified Matter controller</span></a><span>, DIRIGERA can also manage and control smart products from other manufacturers and brands. As a </span><a data-track-category="Text link" href="https://www.ikea.com/global/en/newsroom/innovation/ikea-dirigera-matter-bridge-240911/"><span>Matter Bridge</span></a><span>, it ensures that existing IKEA non-Matter smart products will also be compatible with platforms using the Matter standard.&nbsp;</span></p><p><span>This launch is the first step in a broader update of the IKEA Home smart range. Looking ahead, IKEA will continue expanding into new product categories. The strategy is to launch products that are easier to use and more affordable than existing ones.&nbsp;&nbsp;</span></p><p><span>‚ÄúOur goal is still the same as when we started exploring the smart home in 2012: to make it easy to use, easy to understand, and within reach for the many. We start with understanding life at home, where we continuously watch, listen and learn what makes a difference in everyday life. We believe technology should serve a purpose, not exist for its own sake. With more than 900 million store visits each year, I think we‚Äôre in a good place to help more people discover the benefits of a smarter home,‚Äù says David Granath.&nbsp;</span></p><p><span>Sales start and local pricing may vary between markets. Please contact your local IKEA market for more information.&nbsp;</span></p><h2><span><strong>Discover the new Matter-compatible IKEA Home smart range:</strong>&nbsp;</span></h2><p><span><strong>The KAJPLATS smart bulb range</strong> includes <strong>eleven variations</strong>, offering a mix of shapes, sizes, lumen levels, and styles ‚Äî with options for both colour and white spectrum, as well as dimmable functionality. Compared to the previous TR√ÖDFRI range, each bulb has more functionality, including more colour options and broader light intensity spans.&nbsp;</span></p><ul><li><span><strong>E27/E26 ‚Äì standard globe shape, 60 mm diameter</strong>&nbsp;</span><br><span>Colour and white spectrum, 1 055 lm ‚Äì colour-changing&nbsp;</span><br><span>White spectrum, 470 lm ‚Äì dimmable&nbsp;</span><br><span>White spectrum, 1 055 lm ‚Äì dimmable&nbsp;</span><br><span>White spectrum, 1 521 lm ‚Äì dimmable</span><br><span>&nbsp;</span></li><li><span><strong>P45 E14* ‚Äì compact profile, 45 mm diameter</strong></span><br><span>White spectrum, 470 lm ‚Äì dimmable</span><br><span>White spectrum, 806 lm ‚Äì dimmable&nbsp;</span><br><span>Colour and white spectrum, 806 lm ‚Äì colour-changing&nbsp;</span><br>&nbsp;</li><li><span><strong>GU10 ‚Äì directional spotlight</strong>&nbsp;</span><br><span>Colour and white spectrum, 470 lm - colour-changing</span><br><span>White spectrum, 575 lm ‚Äì dimmable&nbsp;</span><br>&nbsp;</li><li><span><strong>Clear-glass decorative bulbs ‚Äì white spectrum only (dimmable)</strong>&nbsp;</span><br><span>E14* ‚Äì 470 lm clear glass&nbsp;</span><br><span>E27 standard globe (60 mm diameter) ‚Äì 470 lm clear glass</span><br><span>E27 large globe (95 mm diameter) ‚Äì 810 lm clear glass&nbsp;</span><br><span>*E14 also available as E12 and E17 depending on local standardisations.</span><br>&nbsp;</li></ul><p><span><strong>Smart sensors: </strong>Five variations for motion, air quality, humidity and water leakage designed to support wellbeing and prevent damage.&nbsp;</span></p><ul><li><span><strong>MYGGSPRAY </strong>- Motion sensor for indoor and outdoor use that turns on lighting automatically in areas like entrances, staircases, garages, or anywhere you need hands-free light.&nbsp;</span></li><li><span><strong>MYGGBETT</strong> ‚Äì Door/Window sensor. Detects when a door or window is opened or closed, and if connected to a smart system you can get notifications on your phone. Also works for spaces like walk-in closets, where it can trigger a light to turn on or off.&nbsp;</span></li><li><span><strong>TIMMERFLOTTE ‚Äì </strong>Temperature and Humidity Sensor. Measures the indoor climate at home. Press the button to view temperature, followed by humidity ‚Äî one after the other.&nbsp;</span></li><li><span><strong>ALPSTUGA</strong> ‚Äì Air quality sensor. Measures CO‚ÇÇ, particles (PM2.5), temperature, and humidity to show the air quality in your home. Built to work together with IKEA air purifiers for better indoor air. Can also display the time&nbsp;</span></li><li><span><strong>KLIPPBOK </strong>‚Äì<strong> </strong>Water leakage sensor. Detects leaks and alerts you with a sound ‚Äì and can also send a notification to your phone when connected to a hub. Small enough to place under sinks, appliances, or other risk areas.&nbsp;</span></li></ul><p><span><strong>Remote controls and plugs:</strong>&nbsp;</span></p><ul><li><span><strong>BILRESA remote control with dual button </strong>‚Äì<strong> </strong>A simple way to control smart products from afar. Use it to switch lights on or off, adjust brightness, change colour, or trigger a preset scene.&nbsp;</span></li><li><span><strong>BILRESA remote control with scroll wheel </strong>‚Äì Lets you adjust smart products with a simple turn. Use it to switch lights on or off, dim, change colour, or control a group or preset scene.&nbsp;</span></li><li><span><strong>BILRESA Remote Control Kits (2x) </strong></span><em><span><strong>‚Äì </strong></span></em><span>Kits of three colourful versions of the remote controls, in green, red and beige. One kit with three scroll wheels, and the other is with remote control with dual buttons.&nbsp;</span></li><li><span><strong>GRILLPLATS smart plug. </strong>This smart plug lets you control ordinary lamps or smaller appliances remotely ‚Äî turning them into smart products. It also tracks energy use and can be paired with a remote or motion sensor. </span><em><span>Separate sales start</span></em></li></ul><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Slop vs. OSS Security (178 pts)]]></title>
            <link>https://devansh.bearblog.dev/ai-slop/</link>
            <guid>45834303</guid>
            <pubDate>Thu, 06 Nov 2025 12:05:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devansh.bearblog.dev/ai-slop/">https://devansh.bearblog.dev/ai-slop/</a>, See on <a href="https://news.ycombinator.com/item?id=45834303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-11-03T17:57Z">
                    03 Nov, 2025
                </time>
            </i>
        </p>
    

    <blockquote>
<p>Disclosure: Certain sections of this content were grammatically refined/updated using AI assistance, as English is not my first language. Quite ironic, I know, given the subject being discussed.</p>
</blockquote>
<p>I have spent the better part of a decade in the bug bounty industry, and my perspective on this industry is shaped by this experience. The first five years were spent as a bug hunter and vulnerability researcher, where I developed an intimate understanding of what it takes to find, verify, and responsibly disclose security vulnerabilities. The last five years have been spent at <a href="https://www.hackerone.com/">HackerOne</a> (Nov, 2020 - Present), starting as a vulnerability triager where I personally reviewed tens of thousands of submissions, and now as a Team Lead overseeing technical services with a focus on triage operations.</p>
<p>This combination of experience, having worked both sides of the vulnerability reporting ecosystem, from the researcher's perspective to the bug bounty platform's operations, gives me a particular vantage point on how the industry is fracturing under the weight of AI-generated noise. I've reviewed the borderline cases where it's genuinely unclear whether a report is a hallucination or a real finding. I've felt the frustration of maintainers whose inboxes are drowning. I've also seen the pressure that platforms face trying to maintain quality while scaling to handle the deluge.</p>
<p>However, I want to be explicit: these are my personal views and observations, informed by my professional experience but not representative of my employer in any way. HackerOne, as an organization, has its own perspectives, strategies, and positions on these issues. My analysis here reflects my own thinking about the systemic problems I see and potential solutions, not company doctrine or strategy.</p>
<hr>
<h3 id="the-anatomy-of-the-problem">The Anatomy of the Problem</h3><p>There are fundamental issues with how AI has infiltrated vulnerability reporting, and they mirror the social dynamics that plague any feedback system.</p>
<p>First, the typical AI-powered reporter, especially one just pasting GPT output into a submission form, neither knows enough about the actual codebase being examined nor understands the security implications well enough to provide insight that projects need. The AI doesn't read code; it pattern-matches. It sees functions that look similar to vulnerable patterns and invents scenarios where they might be exploited, regardless of whether those scenarios are even possible in the actual implementation.</p>
<p>Second, some actors with misaligned incentives interpret high submission volume as achievement. By flooding bug bounty programs with AI-generated reports, they feel productive and entrepreneurial. Some genuinely believe the AI has found something real. Others know it's questionable but figure they'll let the maintainers sort it out. The incentive is to submit as many reports as possible and see what sticks, because even a 5% hit rate on a hundred submissions is better than the effort of manually verifying five findings.</p>
<p>The result? <a href="https://daniel.haxx.se/blog/2025/07/14/death-by-a-thousand-slops/">Daniel Stenberg, who maintains curl</a>, now sees about 20% of all security submissions as AI-generated slop, while the rate of genuine vulnerabilities has dropped to approximately 5%. Think about that ratio. For every real vulnerability, there are now four fake ones. And every fake one consumes hours of expert time to disprove.</p>
<hr>
<h3 id="the-human-cost-nobody-talks-about">The Human Cost Nobody Talks About</h3><p>A security report lands in your inbox. It claims there's a buffer overflow in a specific function. The report is well-formatted, includes CVE-style nomenclature, and uses appropriate technical language. As a responsible maintainer, you can't just dismiss it. You alert your security team, volunteers, by the way, who have day jobs and families and maybe three hours a week for this work.</p>
<p>Three people read the report. One person tries to reproduce the issue using the steps provided. They can't, because the steps reference test cases that don't exist. Another person examines the source code. The function mentioned in the report doesn't exist in that form. A third person checks whether there's any similar functionality that might be vulnerable in the way described. There isn't.</p>
<p>After an hour and a half of combined effort across three people, that's 4.5 person-hours‚Äîyou've confirmed what you suspected: this report is garbage. Probably AI-generated garbage, based on the telltale signs of hallucinated function names and impossible attack vectors.</p>
<p>You close the report. You don't get those hours back. And tomorrow, two more reports just like it will arrive.</p>
<p><a href="https://daniel.haxx.se/blog/2025/07/14/death-by-a-thousand-slops/">The curl project has seven people on its security team</a>. They collaborate on every submission, with three to four members typically engaging with each report. In early July 2025, they were receiving approximately two security reports per week. The math is brutal. If you have three hours per week to contribute to an open source project you love, and a single false report consumes all of it, you've contributed nothing that week except proving someone's AI hallucinated a vulnerability.</p>
<p>The emotional toll compounds exponentially. <a href="https://daniel.haxx.se/blog/2025/07/14/death-by-a-thousand-slops/">Stenberg describes it as "mind-numbing stupidities"</a> that the team must process. It's not just frustration, it's the specific demoralization that comes from having your expertise and goodwill systematically exploited by people who couldn't be bothered to verify their submissions before wasting your time.</p>
<hr>
<h3 id="the-broader-burnout-crisis">The Broader Burnout Crisis</h3><p>According to <a href="https://www.intel.com/content/www/us/en/developer/articles/community/maintainer-burnout-a-problem-what-are-we-to-do.html">Intel's annual open source community survey</a>, 45% of respondents identified maintainer burnout as their top challenge. <a href="https://www.sonarsource.com/blog/maintainer-burnout-is-real/">The Tidelift State of the Open Source Maintainer Survey</a> is even more stark: 58% of maintainers have either quit their projects entirely (22%) or seriously considered quitting (36%).</p>
<p>Why are they quitting? The top reason, cited by 54% of maintainers, is that other things in their life and work took priority over open source contributions. Over half (51%) reported losing interest in the work. And 44% explicitly identified experiencing burnout.</p>
<p>But here's the gut punch: <a href="https://www.sonarsource.com/blog/maintainer-burnout-is-real/">the percentage of maintainers who said they weren't getting paid enough to make maintenance work worthwhile rose from 32% to 38%</a> between survey periods. These are people maintaining infrastructure that powers billions of dollars of commercial activity, and they're getting nothing. Or maybe they get $500 a year from GitHub Sponsors while companies make millions off their work.</p>
<p>The maintenance work itself is rarely rewarding. You're not building exciting new features. You're addressing technical debt, responding to user demands, managing security issues, and now‚Äîincreasingly‚Äîsorting through AI-generated garbage to find the occasional legitimate report. It's like being a security guard who has to investigate every single alarm, knowing that 95% of them are false, but unable to ignore any because that one real threat could be catastrophic.</p>
<p>When you're volunteering out of love in a market society, you're setting yourself up to be exploited.</p>
<p>And the exploitation is getting worse. Toxic communities, hyper-responsibility for critical infrastructure, and now the weaponization of AI to automate the creation of work for maintainers‚Äîit all adds up to an unsustainable situation.</p>
<p>One Kubernetes contributor put it simply: <a href="https://www.intel.com/content/www/us/en/developer/articles/community/maintainer-burnout-a-problem-what-are-we-to-do.html">"If your maintainers are burned out, they can't be protecting the code base like they're going to need to be."</a> This transforms maintainer wellbeing from a human resources concern into a security imperative. Burned-out maintainers miss things. They make mistakes. They eventually quit, leaving projects unmaintained or understaffed.</p>
<hr>
<h3 id="what-ai-slop-actually-looks-like">What AI Slop Actually Looks Like</h3><p>A typical AI slop report will reference function names that don't exist in the codebase. The AI has seen similar function names in its training data and invents plausible sounding variations. It will describe memory operations that would indeed be problematic if they existed as described, but which bear no relationship to how the code actually works.</p>
<p><a href="https://gist.github.com/bagder/07f7581f6e3d78ef37dfbfc81fd1d1cd">One report to curl claimed an HTTP/3 vulnerability and included fake function calls and behaviors that appeared nowhere in the actual codebase.</a> <a href="https://gist.github.com/bagder/07f7581f6e3d78ef37dfbfc81fd1d1cd">Stenberg has publicly shared a list of AI-generated security submissions received through HackerOne</a>, and they all follow similar patterns, professional formatting, appropriate jargon, and completely fabricated technical details.</p>
<p>The sophistication varies. Some reports are obviously generated by someone who just pasted a repository URL into ChatGPT and asked it to find vulnerabilities. Others show more effort‚Äîthe submitter may have fed actual code snippets to the AI and then submitted its analysis without verification. Both are equally useless to maintainers, but the latter takes longer to disprove because the code snippets are real even if the vulnerability analysis is hallucinated.</p>
<p>Here's why language models fail so catastrophically at this task: they're designed to be helpful and provide positive responses. When you prompt an LLM to generate a vulnerability report, it will generate one regardless of whether a vulnerability exists. The model has no concept of truth‚Äîonly of plausibility. It assembles technical terminology into patterns that resemble security reports it has seen during training, but it cannot verify whether the specific claims it's making are accurate.</p>
<p>This is the fundamental problem: AI can generate the form of security research without the substance.</p>
<hr>
<h3 id="the-cve-system-is-also-collapsing">The CVE System is Also Collapsing</h3><p>While AI slop floods individual project inboxes, <a href="https://autobahn-security.com/blog/cve-database-crisis/">the broader CVE infrastructure faces its own existential crisis</a>. And these crises compound each other in dangerous ways.</p>
<p><a href="https://autobahn-security.com/blog/cve-database-crisis/">In April 2025, MITRE Corporation announced that its contract to maintain the Common Vulnerabilities and Exposures program would expire.</a> The Department of Homeland Security failed to renew the long-term contract, creating a funding lapse that affects everything: national vulnerability databases, advisories, tool vendors, and incident response operations.</p>
<p><a href="https://autobahn-security.com/blog/cve-database-crisis/">The National Vulnerability Database experienced catastrophic problems throughout 2024.</a> CVE submissions jumped 32% while creating massive processing delays. By March 2025, NVD had analyzed fewer than 300 CVEs, leaving more than 30,000 vulnerabilities backlogged. Approximately 42% of CVEs lack essential metadata like severity scores and product information.</p>
<p>Now layer AI slop onto this already-stressed system. Invalid CVEs are being assigned at scale. <a href="https://lwn.net/Articles/944209/">A 2023 analysis by former insiders suggested that only around 20% of CVEs were valid, with the remainder being duplicates, invalid, or inflated.</a> The issues include multiple CVEs being assigned for the same bug, CNAs siding with reporters over project developers even when there's no genuine dispute, and reporters receiving CVEs based on test cases rather than actual distinct vulnerabilities.</p>
<p>The result is that the vulnerability tracking system everyone relies on is becoming less trustworthy exactly when we need it most. Security teams can't rely on CVE assignments to prioritize their work. Developers don't trust vulnerability scanners because false positive rates are through the roof. The signal-to-noise ratio has deteriorated so badly that the entire system risks becoming useless.</p>
<hr>
<h3 id="what-doesnt-work">What Doesn't Work</h3><p>Banning submitters doesn't work at scale. You can ban an account, but creating new accounts is trivial. HackerOne implements reputation scoring where points are gained or lost based on report validity, but this hasn't stemmed the tide because the cost of creating throwaway accounts is essentially zero.</p>
<p>Asking people to "please verify before submitting" doesn't work. The incentive structure rewards volume, and people either genuinely believe their AI-generated reports are valid or don't care enough to verify. Polite requests assume good faith, but much of the slop comes from actors who have no stake in the community norms.</p>
<p>Trying to educate submitters about how AI works doesn't scale. For every person you educate, ten new ones appear with fresh GPT accounts. The problem isn't knowledge‚Äîit's incentives.</p>
<p>Simply closing inboxes or shutting down bug bounty programs "works" in the sense that it stops the slop, but it also stops legitimate security research. Several projects have done this, and now they're less secure because they've lost a channel for responsible disclosure.</p>
<p>None of the easy answers work because this isn't an easy problem.</p>
<hr>
<h3 id="what-might-actually-work">What Might Actually Work</h3><p><strong>Disclosure Requirements</strong> represent the first line of defense. <a href="https://socket.dev/blog/django-joins-curl-in-pushing-back-on-ai-slop-security-reports">Both curl and Django now require submitters to disclose whether AI was used in generating reports.</a> <a href="https://opensourcesecurity.io/2025/2025-05-curl_vs_ai_with_daniel_stenberg/">Curl's approach is particularly direct: disclose AI usage upfront and ensure complete accuracy before submission.</a> If AI usage is disclosed, expect extensive follow-up questions demanding proof that the bug is genuine before the team invests time in verification. This works psychologically. It forces submitters to acknowledge they're using AI, which makes them more conscious of their responsibility to verify. It also gives maintainers grounds to reject slop immediately if AI usage was undisclosed but becomes obvious during review. <a href="https://socket.dev/blog/django-joins-curl-in-pushing-back-on-ai-slop-security-reports">Django goes further with a section titled "Note for AI Tools" that directly addresses language models themselves, reiterating that the project expects no hallucinated content, no fictitious vulnerabilities, and a requirement to independently verify that reports describe reproducible security issues.</a></p>
<p><strong>Proof-of-Concept Requirements</strong> raise the bar significantly. Requiring technical evidence such as screencasts showing reproducibility, integration or unit tests demonstrating the fault, or complete reproduction steps with logs and source code makes it much harder to submit slop. AI can generate a description of a vulnerability, but it cannot generate working exploit code for a vulnerability that doesn't exist. Requiring proof forces the submitter to actually verify their claim. If they can't reproduce it, they can't prove it, and you don't waste time investigating. Projects are choosing to make it harder to submit in order to filter out the garbage, betting that real researchers will clear the bar while slop submitters won't.</p>
<p><strong>Reputation and Trust Systems</strong> offer a social mechanism for filtering. Only users with a history of validated submissions get unrestricted reporting privileges or monetary bounties. New reporters could be required to have established community members vouch for them, creating a web-of-trust model. This mirrors how the world worked before bug bounty platforms commodified security research. You built reputation over time through consistent, high-quality contributions. The downside is that it makes it harder for new researchers to enter the field, and it risks creating an insider club. But the upside is that it filters out low-effort actors who won't invest in building reputation.</p>
<p><strong>Economic Friction</strong> fundamentally alters the incentive structure. Charge a nominal refundable fee‚Äîsay $50‚Äîfor each submission from new or unproven users. If the report is valid, they get the fee back plus the bounty. If it's invalid, you keep the fee. This immediately makes mass AI submission uneconomical. If someone's submitting 50 AI-generated reports hoping one sticks, that's now $2,500 at risk. But for a legitimate researcher submitting one carefully verified finding, $50 is a trivial barrier that gets refunded anyway. Some projects are considering dropping monetary rewards entirely. The logic is that if there's no money involved, there's no incentive for speculative submissions. But this risks losing legitimate researchers who rely on bounties as income. It's a scorched earth approach that solves the slop problem by eliminating the entire ecosystem.</p>
<p><strong>AI-Assisted Triage</strong> represents fighting fire with fire. Use AI tools trained specifically to identify AI-generated slop and flag it for immediate rejection. <a href="https://www.hackerone.com/blog/beyond-the-noise-hai-triage-insight-agent">HackerOne's Hai Triage system embodies this approach, using AI agents to cut through noise before human analysts validate findings.</a> The risk is obvious: what if your AI filter rejects legitimate reports? What if it's biased against certain communication styles or methodologies? You've just automated discrimination. But the counterargument is that human maintainers are already overwhelmed, and imperfect filtering is better than drowning. The key is transparency and appeals. If an AI filter rejects a report, there should be a clear mechanism for the submitter to contest the decision and get human review.</p>
<p><strong>Transparency and Public Accountability</strong> leverage community norms. <a href="https://gist.github.com/bagder/07f7581f6e3d78ef37dfbfc81fd1d1cd">Curl recently formalized that all submitted security reports will be made public once reviewed and deemed non-sensitive.</a> This means that fabricated or misleading reports won't just be rejected, they'll be exposed to public scrutiny. This works as both deterrent and educational tool. If you know your slop report will be publicly documented with your name attached, you might think twice. And when other researchers see examples of what doesn't constitute a valid report, they learn what standards they need to meet. The downside is that public shaming can be toxic and might discourage good-faith submissions from inexperienced researchers. Projects implementing this approach need to be careful about tone and focus on the technical content rather than attacking submitters personally.</p>
<hr>
<h3 id="sustainability-is-hard">Sustainability is Hard</h3><p>Every hour spent evaluating slop reports is an hour not spent on features, documentation, or actual security improvements. And maintainers are already working for free, maintaining infrastructure that generates billions in commercial value. When 38% of maintainers cite not getting paid enough as a reason for quitting, and <a href="https://darktechinsights.com/open-source-hidden-costs-developers/">97% of open source maintainers are unpaid despite massive commercial exploitation of their work</a>, the system is already broken.</p>
<p>AI slop is just the latest exploitation vector. It's the most visible one right now, but it's not the root cause. The root cause is that we've built a global technology infrastructure on the volunteer labor of people who get nothing in return except burnout and harassment.</p>
<p>So what does sustainability actually look like?</p>
<p>First, it looks like money. Real money. Not GitHub Sponsors donations that average $500 a year. Not swag and conference tickets. Actual salaries commensurate with the value being created. Companies that build products on open source infrastructure need to fund the maintainers of that infrastructure. This could happen through direct employment, foundation grants, or the Open Source Pledge model where companies commit percentages of revenue.</p>
<p>Second, it looks like better tooling and automation that genuinely reduces workload rather than creating new forms of work. Automated dependency management, continuous security scanning integrated into development workflows, and sophisticated triage assistance that actually works. The goal is to make maintenance less time-consuming so burnout becomes less likely.</p>
<p>Third, it looks like shared workload and team building. No single volunteer should be a single point of failure. Building teams with checks and balances where members keep each other from taking on too much creates sustainability. Finding additional contributors willing to share the burden rather than expecting heroic individual effort acknowledges that most people have limited time available for unpaid work.</p>
<p>Fourth, it looks like culture change. Fostering empathy in interactions, starting communications with gratitude even when rejecting contributions, and publicly acknowledging the critical work maintainers perform reduces emotional toll. Demonstrating clear processes for handling security issues gives confidence rather than trying to hide problems.</p>
<p>Fifth, it looks like advocacy and policy at organizational and governmental levels. Recognition that <a href="https://tfir.io/kubernetes-maintainer-burnout-open-source-sustainability/">maintainer burnout represents existential threat to technology infrastructure</a>. Development of regulations requiring companies benefiting from open source to contribute resources. Establishment of security standards that account for the realities of volunteer-run projects.</p>
<p>Without addressing these fundamentals, no amount of technical sophistication will prevent collapse.</p>
<hr>
<h3 id="the-arms-race-ahead">The Arms Race Ahead</h3><p>The CVE slop crisis is just the beginning. We're entering an arms race between AI-assisted attackers or abusers and AI-assisted defenders, and nobody knows how it ends.</p>
<p><a href="https://www.hackerone.com/press-release/hackerone-report-finds-210-spike-ai-vulnerability-reports-amid-rise-ai-autonomy">HackerOne's research indicates that 70% of security researchers now use AI tools in their workflow.</a> AI-powered testing is becoming the industry standard. <a href="https://www.hackerone.com/press-release/hackerone-report-finds-210-spike-ai-vulnerability-reports-amid-rise-ai-autonomy">The emergence of fully autonomous hackbots‚ÄîAI systems that submitted over 560 valid reports in the first half of 2025‚Äîsignals both opportunity and threat.</a></p>
<p>The divergence will be between researchers who use AI as a tool to enhance genuinely skilled work versus those who use it to automate low-effort spam. The former represents the promise of democratizing security research and scaling our ability to find vulnerabilities. The latter represents the threat of making the signal-to-noise problem completely unmanageable.</p>
<p>The challenge is developing mechanisms that encourage the first group while defending against the second.</p>
<p>This probably means moving toward more exclusive models. Invite-only programs. Dramatically higher standards for participation. Reputation systems that take years to build. New models for coordinated vulnerability disclosure that assume AI-assisted research as the baseline and require proof beyond "here's what the AI told me."</p>
<p>It might mean the end of open bug bounty programs as we know them. Maybe that's necessary. Maybe the experiment of "anyone can submit anything" was only viable when the cost of submitting was high enough to ensure some minimum quality. Now that AI has reduced that cost to near-zero, the experiment might fail soon if things don't improve.</p>
<p>So, net-net, here's where we are:</p>
<p>When it comes to vulnerability reports, what matters is who submits them and whether they've actually verified their claims. Accepting reports from everyone indiscriminately is backfiring catastrophically because projects are latching onto submissions that sound plausible while ignoring the cumulative evidence that most are noise.</p>
<p>You want to receive reports from someone who has actually verified their claims, understands the architecture of what they're reporting on, and isn't trying to game the bounty system or offload verification work onto maintainers.</p>
<p>Such people exist, but they're becoming harder to find amidst the deluge of AI-generated content. That's why projects have to be selective about which reports they investigate and which submitters they trust.</p>
<p>Remember: not all vulnerability reports are legitimate. Not all feedback is worthwhile. It matters who is doing the reporting and what their incentives are.</p>
<p>The CVE slop crisis shows the fragility of open source security. Volunteer maintainers, already operating at burnout levels, face an explosion of AI-generated false reports that consume their limited time and emotional energy. The systems designed to track and manage vulnerabilities struggle under dual burden of structural underfunding and slop inundation.</p>
<p>The path forward requires holistic solutions combining technical filtering with fundamental changes to how we support and compensate open source labor. AI can be part of the solution through better triage, but it cannot substitute for adequate resources, reasonable workloads, and human judgment.</p>
<p>Ultimately, the sustainability of open source security depends on recognizing that people who maintain critical infrastructure deserve more than exploitation.</p>
<p>They deserve compensation, support, reasonable expectations, and protection from abuse. Without addressing these fundamentals, no amount of technical sophistication will prevent the slow collapse of the collaborative model that has produced so much of the digital infrastructure modern life depends on.</p>
<p>The CVE slop crisis isn't merely about bad vulnerability reports. It's about whether we'll choose to sustain the human foundation of technological progress, or whether we'll let it burn out under the weight of automated exploitation.</p>
<p>That's the choice we're facing. And right now, we're choosing wrong.</p>


    

    
        

        
            


        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eating stinging nettles (168 pts)]]></title>
            <link>https://rachel.blog/2018/04/29/eating-stinging-nettles/</link>
            <guid>45834254</guid>
            <pubDate>Thu, 06 Nov 2025 11:57:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachel.blog/2018/04/29/eating-stinging-nettles/">https://rachel.blog/2018/04/29/eating-stinging-nettles/</a>, See on <a href="https://news.ycombinator.com/item?id=45834254">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Spring is here and the nettles are growing again so I decided it was time to make a meal out of them. Most people know that stinging nettles are pesky green plants that irritate the skin when you touch them. What you probably don‚Äôt know is that they‚Äôre a nutritious source of iron, calcium, potassium, and silica as well as vitamins A, B, C, and K1. Stinging nettles also have anti-inflammatory properties and can <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4708629/">relieve arthritis and rheumatism</a>. They can be turned into soups, curries, and risottos (some recipes <a href="https://www.theguardian.com/lifeandstyle/2012/mar/30/nettle-recipes-hugh-fearnley-whittingstall">here</a>) and you can get them completely free from practically everywhere in Britain over the summer. You‚Äôve likely even got some in your garden.</p>
<p>When you collect them you need to wear gloves because they sting. The advantage of this is it allows you to make sure you‚Äôre collecting the right thing. If you‚Äôre unsure, just touch one and see whether it hurts which is exactly what I did. It hurt.</p>
<p><img data-attachment-id="24755" data-permalink="https://rachel.blog/2018/04/29/eating-stinging-nettles/img_9534/" data-orig-file="https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1525021166&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.0050505050505051&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;,&quot;latitude&quot;:&quot;57.132644444444&quot;,&quot;longitude&quot;:&quot;-2.1033305555556&quot;}" data-image-title="IMG_9534" data-image-description="" data-image-caption="" data-medium-file="https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=225" data-large-file="https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=768" src="https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=3024&amp;h=4032" alt="IMG_9534.jpg" width="3024" height="4032" srcset="https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg 3024w, https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=113&amp;h=150 113w, https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=225&amp;h=300 225w, https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=768&amp;h=1024 768w, https://rachel.blog/wp-content/uploads/2018/04/img_9534.jpg?w=1440&amp;h=1920 1440w" sizes="(max-width: 3024px) 100vw, 3024px"></p>
<p>The even look a bit scary with their toothy-edged leaves.</p>
<p><img data-attachment-id="24756" data-permalink="https://rachel.blog/2018/04/29/eating-stinging-nettles/img_9529/" data-orig-file="https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1525020976&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.0025773195876289&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;57.132655555556&quot;,&quot;longitude&quot;:&quot;-2.1033722222222&quot;}" data-image-title="IMG_9529" data-image-description="" data-image-caption="" data-medium-file="https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=300" data-large-file="https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=1024" src="https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=4032&amp;h=3024" alt="IMG_9529.JPG" width="4032" height="3024" srcset="https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg 4032w, https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=150&amp;h=113 150w, https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=300&amp;h=225 300w, https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=768&amp;h=576 768w, https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=1024&amp;h=768 1024w, https://rachel.blog/wp-content/uploads/2018/04/img_9529.jpg?w=1440&amp;h=1080 1440w" sizes="(max-width: 4032px) 100vw, 4032px"></p>
<p>Once you‚Äôve got them inside, boil them in water for a few minutes and this will stop them stinging.</p>
<p><img data-attachment-id="24757" data-permalink="https://rachel.blog/2018/04/29/eating-stinging-nettles/img_9535/" data-orig-file="https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1525021765&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.04&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;57.133008333333&quot;,&quot;longitude&quot;:&quot;-2.1034916666667&quot;}" data-image-title="IMG_9535" data-image-description="" data-image-caption="" data-medium-file="https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=300" data-large-file="https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=1024" loading="lazy" src="https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=4032&amp;h=3024" alt="IMG_9535.JPG" width="4032" height="3024" srcset="https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg 4032w, https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=150&amp;h=113 150w, https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=300&amp;h=225 300w, https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=768&amp;h=576 768w, https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=1024&amp;h=768 1024w, https://rachel.blog/wp-content/uploads/2018/04/img_9535.jpg?w=1440&amp;h=1080 1440w" sizes="(max-width: 4032px) 100vw, 4032px"></p>
<p>We‚Äôre having stinging nettle risotto.</p>
<p><img data-attachment-id="24758" data-permalink="https://rachel.blog/2018/04/29/eating-stinging-nettles/img_9537-2/" data-orig-file="https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg" data-orig-size="1200,900" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1525024850&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.04&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;57.132994444444&quot;,&quot;longitude&quot;:&quot;-2.1034138888889&quot;}" data-image-title="IMG_9537" data-image-description="" data-image-caption="" data-medium-file="https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=300" data-large-file="https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=1024" loading="lazy" src="https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=1200&amp;h=900" alt="IMG_9537.JPG" width="1200" height="900" srcset="https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg 1200w, https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=150&amp;h=113 150w, https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=300&amp;h=225 300w, https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=768&amp;h=576 768w, https://rachel.blog/wp-content/uploads/2018/04/img_9537.jpg?w=1024&amp;h=768 1024w" sizes="(max-width: 1200px) 100vw, 1200px"></p>
<p>People think that when you become vegan you have to give up lots of food. It‚Äôs true that I stopped eating animals but the number of different species I eat has grown considerably. This is because meat-eaters tend to eat the same few species of animals over and over again ‚Äì pigs, cows, chickens. Whereas there are some 20,000 species of edible plants in the world. Meat also tends to fill you up. Indeed I‚Äôve been to dinner with people where all they have on their plate is a slab of meat and nothing else. Whereas as a vegan (with the exception of a shitty Spanish restaurant that served me a plate of artichokes and nothing else) I eat a huge variety of species. Meat-eaters can eat these too but they often don‚Äôt because meat is so filling.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: qqqa ‚Äì A fast, stateless LLM-powered assistant for your shell (123 pts)]]></title>
            <link>https://github.com/matisojka/qqqa</link>
            <guid>45833811</guid>
            <pubDate>Thu, 06 Nov 2025 10:59:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/matisojka/qqqa">https://github.com/matisojka/qqqa</a>, See on <a href="https://news.ycombinator.com/item?id=45833811">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">qqqa</h2><a id="user-content-qqqa" aria-label="Permalink: qqqa" href="#qqqa"></a></p>
<p dir="auto">Fast, stateless LLM-powered assistant for your shell: qq answers; qa runs commands</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is qqqa</h2><a id="user-content-what-is-qqqa" aria-label="Permalink: What is qqqa" href="#what-is-qqqa"></a></p>
<p dir="auto">qqqa is a two-in-one, stateless CLI tool that brings LLM assistance to the command line without ceremony.</p>
<p dir="auto">The two binaries are:</p>
<ul dir="auto">
<li><code>qq</code> - ask a single question, e.g. "qq how can I recursively list all files in this directory" (qq stands for "quick question")</li>
<li><code>qa</code> - a single step agent that can optionally use tools to finish a task: read a file, write a file, or execute a command with confirmation (qa stands for "quick agent")</li>
</ul>
<p dir="auto">By default the repo includes profiles for OpenAI and Groq.</p>
<details open="">
  <summary>
    
    <span>demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/820186/510710288-91e888ad-0279-4d84-924b-ba96c0fe43a0.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjI0NjQ5MDIsIm5iZiI6MTc2MjQ2NDYwMiwicGF0aCI6Ii84MjAxODYvNTEwNzEwMjg4LTkxZTg4OGFkLTAyNzktNGQ4NC05MjRiLWJhOTZjMGZlNDNhMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUxMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MTEwNlQyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lMTRkOTEwNmJkMWIyMTZiYTc2NjlkYjBjOGE2MzcwNGIxYzAzZGQ1YTZlYWM1ZDQ5Njk0ZjZjOWEyM2U4YjAxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ToN8s3s0CuIYL2QJBTheyYY9e8YDSZXW145pXPe4nqw" data-canonical-src="https://private-user-images.githubusercontent.com/820186/510710288-91e888ad-0279-4d84-924b-ba96c0fe43a0.mp4?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjI0NjQ5MDIsIm5iZiI6MTc2MjQ2NDYwMiwicGF0aCI6Ii84MjAxODYvNTEwNzEwMjg4LTkxZTg4OGFkLTAyNzktNGQ4NC05MjRiLWJhOTZjMGZlNDNhMC5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUxMTA2JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MTEwNlQyMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1lMTRkOTEwNmJkMWIyMTZiYTc2NjlkYjBjOGE2MzcwNGIxYzAzZGQ1YTZlYWM1ZDQ5Njk0ZjZjOWEyM2U4YjAxJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.ToN8s3s0CuIYL2QJBTheyYY9e8YDSZXW145pXPe4nqw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Names and typing speed</h2><a id="user-content-names-and-typing-speed" aria-label="Permalink: Names and typing speed" href="#names-and-typing-speed"></a></p>
<p dir="auto">qq means quick question. qa means quick agent. Both are easy to type rapidly on QWERTY keyboards with minimal finger movement. That makes interacting with LLMs faster and more natural during real work.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Philosophy</h2><a id="user-content-philosophy" aria-label="Permalink: Philosophy" href="#philosophy"></a></p>
<p dir="auto">qqqa is deliberately stateless. There is no long running session and no hidden conversation memory stored by the tool. Every run is mostly independent and reproducible. For maintaining a lowkey continuity you can use <code>"include_history": true</code> in the <code>config.json</code> (or choose to use history during the <code>qq --init</code> process).</p>
<p dir="auto">Why stateless is great:</p>
<ul dir="auto">
<li>Simple and focused - Unix philosophy applied to LLM tools.</li>
<li>Shell friendly - compose with pipes and files instead of interactive chats.</li>
<li>Safe by default - qq is read-only and has access to no tools. qa is built with security in mind and requires confirmation before running tools.</li>
</ul>
<p dir="auto">The tools may include transient context you choose to provide:</p>
<ul dir="auto">
<li><code>qq</code> can include the last few terminal commands as hints and piped stdin if present.</li>
<li><code>qa</code> can read files or run a specific command, but only once per invocation and with safety checks.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why we recommend using Groq by default</h2><a id="user-content-why-we-recommend-using-groq-by-default" aria-label="Permalink: Why we recommend using Groq by default" href="#why-we-recommend-using-groq-by-default"></a></p>
<p dir="auto">For fast feedback loops, speed and cost matter. The included <code>groq</code> profile targets Groq's OpenAI compatible API and the model <code>openai/gpt-oss-20b</code>. We recommend Groq for really fast inference speed at roughly 1000 tokens per second and at a low price point compared to many alternatives. Set <code>GROQ_API_KEY</code> and you are ready to go.</p>
<p dir="auto">You can still use OpenAI or any other OpenAI compatible provider by adding a provider entry and a profile in <code>~/.qq/config.json</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>OpenAI compatible API client with streaming and non streaming calls.</li>
<li>Stateless, single shot workflow that plays well with pipes and scripts.</li>
<li>Rich but simple formatting using XML like tags rendered to ANSI colors.</li>
<li>Config driven providers and profiles with per profile model overrides.</li>
<li>Safety rails for file access and command execution.</li>
<li>Old-school and SERIOUS? Optional no-emoji mode persisted via <code>--no-fun</code> ü•∏</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS</h3><a id="user-content-macos" aria-label="Permalink: macOS" href="#macos"></a></p>
<p dir="auto">Use the Homebrew tap:</p>
<div dir="auto" data-snippet-clipboard-copy-content="brew tap iagooar/qqqa
brew install qqqa"><pre>brew tap iagooar/qqqa
brew install qqqa</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto">Download a prebuilt archive from the <a href="https://github.com/iagooar/qqqa/releases">GitHub Releases</a> page, extract it, and place <code>qq</code>/<code>qa</code> somewhere on your <code>PATH</code> (e.g., <code>/usr/local/bin</code>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configure</h2><a id="user-content-configure" aria-label="Permalink: Configure" href="#configure"></a></p>
<p dir="auto">On first run qqqa creates <code>~/.qq/config.json</code> with safe permissions. For a smooth first interaction, run the init flow:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Interactive setup (choose provider and set key)
qq --init
# or
qa --init"><pre><span><span>#</span> Interactive setup (choose provider and set key)</span>
qq --init
<span><span>#</span> or</span>
qa --init</pre></div>
<p dir="auto">If <code>~/.qq/config.json</code> already exists, the init command keeps it untouched and explains how to rerun after moving or deleting the file.</p>
<p dir="auto">The initializer lets you choose the default provider:</p>
<ul dir="auto">
<li>Groq + <code>openai/gpt-oss-20b</code> (faster, cheaper)</li>
<li>OpenAI + <code>gpt-5-mini</code> (slower, a bit smarter)</li>
</ul>
<p dir="auto">It also offers to store an API key in the config (optional). If you prefer environment variables, leave it blank and set one of:</p>
<ul dir="auto">
<li><code>GROQ_API_KEY</code> for Groq</li>
<li><code>OPENAI_API_KEY</code> for OpenAI</li>
</ul>
<p dir="auto">Defaults written to <code>~/.qq/config.json</code>:</p>
<ul dir="auto">
<li>Providers
<ul dir="auto">
<li><code>openai</code> ‚Üí base <code>https://api.openai.com/v1</code>, env <code>OPENAI_API_KEY</code></li>
<li><code>groq</code> ‚Üí base <code>https://api.groq.com/openai/v1</code>, env <code>GROQ_API_KEY</code></li>
</ul>
</li>
<li>Profiles
<ul dir="auto">
<li><code>openai</code> ‚Üí model <code>gpt-5-mini</code></li>
<li><code>groq</code> ‚Üí model <code>openai/gpt-oss-20b</code> (default)</li>
</ul>
</li>
<li>Optional per-profile <code>reasoning_effort</code> for GPT-5 family models. If you leave it unset, qqqa sends <code>"reasoning_effort": "minimal"</code> for any <code>gpt-5*</code> model to keep responses fast. Set it to <code>"low"</code>, <code>"medium"</code>, or <code>"high"</code> when you want deeper reasoning.</li>
</ul>
<p dir="auto">Example override in <code>~/.qq/config.json</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &quot;profiles&quot;: {
    &quot;openai&quot;: {
      &quot;model_provider&quot;: &quot;openai&quot;,
      &quot;model&quot;: &quot;gpt-5-mini&quot;,
      &quot;reasoning_effort&quot;: &quot;medium&quot;
    }
  }
}"><pre>{
  <span>"profiles"</span>: {
    <span>"openai"</span>: {
      <span>"model_provider"</span>: <span><span>"</span>openai<span>"</span></span>,
      <span>"model"</span>: <span><span>"</span>gpt-5-mini<span>"</span></span>,
      <span>"reasoning_effort"</span>: <span><span>"</span>medium<span>"</span></span>
    }
  }
}</pre></div>
<ul dir="auto">
<li>Optional flag: <code>no_emoji</code> (unset by default). Set via <code>qq --no-fun</code> or <code>qa --no-fun</code>.</li>
</ul>
<p dir="auto">Terminal history is <strong>off by default</strong>. During <code>qq --init</code> / <code>qa --init</code> you can opt in to sending the last 10 <code>qq</code>/<code>qa</code> commands along with each request. You can still override per run with <code>--history</code> (force on) or <code>-n/--no-history</code> (force off). Only commands whose first token is <code>qq</code> or <code>qa</code> are ever shared.</p>
<p dir="auto">You can still override at runtime:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# choose profile
qq -p groq &quot;what is ripgrep&quot;

# override model for a single call
qq -m openai/gpt-oss-20b &quot;explain this awk one-liner&quot;"><pre><span><span>#</span> choose profile</span>
qq -p groq <span><span>"</span>what is ripgrep<span>"</span></span>

<span><span>#</span> override model for a single call</span>
qq -m openai/gpt-oss-20b <span><span>"</span>explain this awk one-liner<span>"</span></span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">qq - ask a question</h3><a id="user-content-qq---ask-a-question" aria-label="Permalink: qq - ask a question" href="#qq---ask-a-question"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# simplest
qq &quot;convert mp4 to mp3&quot;

# stream tokens with formatted output
qq -s &quot;how do I kill a process by name on macOS&quot;

# include piped context
git status | qq &quot;summarize what I should do next&quot;

# pipe extra context and keep CLI question
printf '%s\n' &quot;This is a sample context. My code is 4242&quot; | qq &quot;What is my code&quot;

# pipe the question itself
printf '%s\n' &quot;Show me the full contents of this directory&quot; | qq

# raw text (no ANSI formatting)
qq -r &quot;explain sed vs awk&quot;

# include terminal history for this run
qq --history &quot;find large files in the last day&quot;

# disable emojis in responses (persists)
qq --no-fun &quot;summarize this&quot;"><pre><span><span>#</span> simplest</span>
qq <span><span>"</span>convert mp4 to mp3<span>"</span></span>

<span><span>#</span> stream tokens with formatted output</span>
qq -s <span><span>"</span>how do I kill a process by name on macOS<span>"</span></span>

<span><span>#</span> include piped context</span>
git status <span>|</span> qq <span><span>"</span>summarize what I should do next<span>"</span></span>

<span><span>#</span> pipe extra context and keep CLI question</span>
<span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>This is a sample context. My code is 4242<span>"</span></span> <span>|</span> qq <span><span>"</span>What is my code<span>"</span></span>

<span><span>#</span> pipe the question itself</span>
<span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>Show me the full contents of this directory<span>"</span></span> <span>|</span> qq

<span><span>#</span> raw text (no ANSI formatting)</span>
qq -r <span><span>"</span>explain sed vs awk<span>"</span></span>

<span><span>#</span> include terminal history for this run</span>
qq --history <span><span>"</span>find large files in the last day<span>"</span></span>

<span><span>#</span> disable emojis in responses (persists)</span>
qq --no-fun <span><span>"</span>summarize this<span>"</span></span></pre></div>
<p dir="auto">Note: it is possible to run qq without quotes, which works most of the time the same way as with quotes.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# simplest
qq convert mp4 to mp3"><pre><span><span>#</span> simplest</span>
qq convert mp4 to mp3</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example: forgot the ffmpeg incantation</h4><a id="user-content-example-forgot-the-ffmpeg-incantation" aria-label="Permalink: Example: forgot the ffmpeg incantation" href="#example-forgot-the-ffmpeg-incantation"></a></p>
<p dir="auto">You want to extract audio from a YouTube video but you do not remember the exact flags.</p>
<p dir="auto">Ask with qq:</p>
<div dir="auto" data-snippet-clipboard-copy-content="qq &quot;how do I use ffmpeg to extract audio from a YouTube video into mp3&quot;"><pre>qq <span><span>"</span>how do I use ffmpeg to extract audio from a YouTube video into mp3<span>"</span></span></pre></div>
<p dir="auto">A typical answer will suggest installing the tools and then using <code>yt-dlp</code> to fetch audio and <code>ffmpeg</code> to convert it:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# macOS
brew install yt-dlp ffmpeg

# Debian or Ubuntu
sudo apt-get update &amp;&amp; sudo apt-get install -y yt-dlp ffmpeg

# Download and extract audio to MP3 using ffmpeg under the hood
yt-dlp -x --audio-format mp3 &quot;https://www.youtube.com/watch?v=VIDEO_ID&quot;"><pre><span><span>#</span> macOS</span>
brew install yt-dlp ffmpeg

<span><span>#</span> Debian or Ubuntu</span>
sudo apt-get update <span>&amp;&amp;</span> sudo apt-get install -y yt-dlp ffmpeg

<span><span>#</span> Download and extract audio to MP3 using ffmpeg under the hood</span>
yt-dlp -x --audio-format mp3 <span><span>"</span>https://www.youtube.com/watch?v=VIDEO_ID<span>"</span></span></pre></div>
<p dir="auto">Do it for me with qa:</p>
<div dir="auto" data-snippet-clipboard-copy-content="qa &quot;download audio as mp3 from https://www.youtube.com/watch?v=VIDEO_ID&quot;"><pre>qa <span><span>"</span>download audio as mp3 from https://www.youtube.com/watch?v=VIDEO_ID<span>"</span></span></pre></div>
<p dir="auto">The agent will propose a safe command like <code>yt-dlp -x --audio-format mp3 URL</code>, show it for confirmation, then run it. You can pass <code>-y</code> to auto approve.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">qa - do a single step with tools</h3><a id="user-content-qa---do-a-single-step-with-tools" aria-label="Permalink: qa - do a single step with tools" href="#qa---do-a-single-step-with-tools"></a></p>
<p dir="auto"><code>qa</code> can either answer in plain text or request one tool call in JSON. Supported tools:</p>
<ul dir="auto">
<li><code>read_file</code> with <code>{ "path": string }</code></li>
<li><code>write_file</code> with <code>{ "path": string, "content": string }</code></li>
<li><code>execute_command</code> with <code>{ "command": string, "cwd?": string }</code></li>
</ul>
<p dir="auto">Examples:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# read a file the safe way
qa &quot;read src/bin/qq.rs and tell me what main does&quot;

# write a file
qa &quot;create a README snippet at notes/intro.md with a short summary&quot;

# run a command with confirmation
qa &quot;list Rust files under src sorted by size&quot;

# pipe the task itself
printf '%s\n' &quot;Show me the full contents of this directory&quot; | qa

# auto approve tool execution for non interactive scripts
qa -y &quot;count lines across *.rs&quot;

# include recent qq/qa commands just for this run
qa --history &quot;trace which git commands I ran recently&quot;

# disable emojis in responses (persists)
qa --no-fun &quot;format and lint the repo&quot;"><pre><span><span>#</span> read a file the safe way</span>
qa <span><span>"</span>read src/bin/qq.rs and tell me what main does<span>"</span></span>

<span><span>#</span> write a file</span>
qa <span><span>"</span>create a README snippet at notes/intro.md with a short summary<span>"</span></span>

<span><span>#</span> run a command with confirmation</span>
qa <span><span>"</span>list Rust files under src sorted by size<span>"</span></span>

<span><span>#</span> pipe the task itself</span>
<span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>Show me the full contents of this directory<span>"</span></span> <span>|</span> qa

<span><span>#</span> auto approve tool execution for non interactive scripts</span>
qa -y <span><span>"</span>count lines across *.rs<span>"</span></span>

<span><span>#</span> include recent qq/qa commands just for this run</span>
qa --history <span><span>"</span>trace which git commands I ran recently<span>"</span></span>

<span><span>#</span> disable emojis in responses (persists)</span>
qa --no-fun <span><span>"</span>format and lint the repo<span>"</span></span></pre></div>
<p dir="auto">When qa runs a command while stdout is a terminal, output now streams live; the structured <code>[tool:execute_command]</code> summary still prints afterward for easy copying.</p>
<p dir="auto"><code>execute_command</code> prints the proposed command and asks for confirmation. It warns if the working directory is outside your home. Use <code>-y</code> to auto approve in trusted workflows.</p>
<p dir="auto">The runner enforces a default allowlist (think <code>ls</code>, <code>grep</code>, <code>find</code>, <code>rg</code>, <code>awk</code>, etc.) and rejects pipelines, redirection, and other high-risk constructs. When a command is blocked, <code>qa</code> prompts you to add it to <code>command_allowlist</code> inside <code>~/.qq/config.json</code>; approving once persists the choice and updates future runs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Safety model</h2><a id="user-content-safety-model" aria-label="Permalink: Safety model" href="#safety-model"></a></p>
<ul dir="auto">
<li>File tools require paths to be inside your home or the current directory. Reads are capped to 1‚ÄØMiB, and traversal/symlink escapes are blocked.</li>
<li>Command execution uses a default allowlist (e.g. <code>ls</code>, <code>grep</code>, <code>rg</code>, <code>find</code>) plus your custom <code>command_allowlist</code> entries. Destructive patterns (<code>rm -rf /</code>, <code>sudo</code>, <code>mkfs</code>, etc.) are always blocked, and pipelines/redirection/newlines prompt for confirmation even with <code>--yes</code>.</li>
<li>Commands run with a 120‚ÄØs timeout and the agent performs at most one tool step‚Äîthere is no loop.</li>
<li>Config files are created with safe permissions. API keys come from environment variables unless you explicitly add a key to the config.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Environment variables</h2><a id="user-content-environment-variables" aria-label="Permalink: Environment variables" href="#environment-variables"></a></p>
<ul dir="auto">
<li><code>GROQ_API_KEY</code> for the Groq provider</li>
<li><code>OPENAI_API_KEY</code> for the OpenAI provider</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto">Project layout:</p>
<ul dir="auto">
<li><code>src/bin/qq.rs</code> and <code>src/bin/qa.rs</code> entry points</li>
<li>Core modules in <code>src/</code>: <code>ai.rs</code>, <code>config.rs</code>, <code>prompt.rs</code>, <code>history.rs</code>, <code>perms.rs</code>, <code>formatting.rs</code></li>
<li>Tools in <code>src/tools/</code>: <code>read_file.rs</code>, <code>write_file.rs</code>, <code>execute_command.rs</code></li>
<li>Integration tests in <code>tests/</code></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See CONTRIBUTING.md for guidelines on reporting issues and opening pull requests, building from source, and the release process.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<ul dir="auto">
<li>API error about missing key: run <code>qq --init</code> to set things up, or export the relevant env var, e.g. <code>export GROQ_API_KEY=...</code>.</li>
<li>No output when streaming: try <code>-d</code> to see debug logs.</li>
<li>Piped input not detected: ensure you are piping into <code>qq</code> and not running it in a subshell that swallows stdin.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Licensed under MIT.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oldest woman to finish Ironman World Championship in Kona (131 pts)]]></title>
            <link>https://bigislandnow.com/2025/10/19/80-year-old-grandmother-becomes-oldest-woman-to-finish-ironman-world-championship-in-kona/</link>
            <guid>45833734</guid>
            <pubDate>Thu, 06 Nov 2025 10:47:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bigislandnow.com/2025/10/19/80-year-old-grandmother-becomes-oldest-woman-to-finish-ironman-world-championship-in-kona/">https://bigislandnow.com/2025/10/19/80-year-old-grandmother-becomes-oldest-woman-to-finish-ironman-world-championship-in-kona/</a>, See on <a href="https://news.ycombinator.com/item?id=45833734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <figure><a href="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/unnamed-1.jpg"><img fetchpriority="high" decoding="async" width="1024" height="683" src="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/unnamed-1-1024x683.jpg" alt=""></a><figcaption>Natalie Grabow, 80, of New Jersey, was the oldest finisher and winner of the 80-84 age group in this year‚Äôs Ironman World Championship in Kona on Oct. 11, 2025. (Photo courtesy: Ironman)</figcaption></figure>



<p>When Natalie Grabow grew up in the 1940s and 50s in New Jersey, there were not a lot of opportunities for girls to do sports.</p>



<p>‚ÄúWe were cheerleaders,‚Äù Grabow said. ‚ÄúI begged my mother to give me gymnastics lessons, but parents at that time didn‚Äôt give you any lessons. We just ran around outside and rode bikes.‚Äù</p>



<p>But Grabow always has had a competitive spirit, and that shined through last Saturday when Grabow crossed the finish line on Ali‚Äôi Drive. </p>



<p>‚ÄúYou are an Ironman‚Äù the announcer said as Grabow, at age 80, became the oldest female ever to finish the Ironman World Championship in Kona. </p>



<p>The previous oldest was Cherie Gruenfeld when she finished the championship race at 78 years old in 2022.</p>



<div><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><div><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><p>‚ÄúI had a good day and I‚Äôm just really pleased with myself,‚Äù Grabow said Thursday.</p>



<p>The mother of two and grandmother of four said her goal when she entered the water at Kailua Bay a week ago for the swim leg was to complete the grueling 140.6-mile triathlon before the 17-hour cutoff.</p>



<p>She did, with just under 15 minutes to spare, completing the 2.4-mile swim, 112-mile bike ride and the 26.2-mile run in 16 hours, 45 minutes and 26 seconds. </p>



<p>Of the approximately 1,600 females in the championship race, she was the only person in her 80-84 age group.</p>



<p>It was her 11th Ironman race despite not learning to swim until she was 59 and not starting triathlons until she was 60.</p>



<div id="mn_videoad_midarticle"><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><p>‚ÄúI‚Äôm still not comfortable with swimming,‚Äù she said. ‚ÄúIf you haven‚Äôt grown up swimming, it feels like an awkward endeavor.‚Äù</p>



<p>During the first leg of the race, Grabow said Kailua Bay was choppy and congested with swimmers. But her only thought was to be out of the water before the cut-off of 2 hours and 20 minute<strong>s </strong>that would have eliminated her from the race.</p>



<figure><p>
<iframe title="Natalie Grabow Ironman World Championship finish" width="422" height="750" src="https://www.youtube.com/embed/CPylVTXbx6g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>Grabow said she is familiar with the conditions on Hawai‚Äòi Island.</p>



<p>‚ÄúIt‚Äôs hot, humid and windy,‚Äù she said. ‚ÄúYou really need to watch your nutrition and salt intake so you don‚Äôt cramp up.‚Äù</p>



<p>Grabow worked as a software engineer. While raising her daughters, she played tennis and did step aerobics.</p>



<div><p><span><b>ARTICLE CONTINUES BELOW AD</b></span></p></div><p>Grabow‚Äôs daughter, Amy Rousseau, said her mom was her track coach from ages 9 to 13.</p>



<p>‚ÄúIt was amazing that she would put her time into it,‚Äù Rousseau said. ‚ÄúMaybe because she didn‚Äôt have access to that, she wanted to make sure the next generation did.‚Äù</p>



<p>After going back to work full time in her early 40s, Grabow started running to stay active. However, she seemed to never be completely healthy and would get regular knee injuries.</p>



<p>A friend turned her on to the triathlon as a way to stay active and mix things up.</p>



<p>‚ÄúI like to do something every day,‚Äù Grabow said. ‚ÄúIf something bothers me in the swim, I can get on the bike.‚Äù</p>



<p>Grabow said that had she been able to participate in a sport growing up, she speculated it might have been a sprint-distance runner because she loves to move.</p>



<figure><a href="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/natalie-before-swim.jpg"><img decoding="async" width="675" height="1024" src="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/natalie-before-swim-675x1024.jpg" alt=""></a><figcaption>Natalie Grabow, 80, of New Jersey, getting ready to start the swim during the Ironman World Championship in Kona on Oct. 11, 2025. (Photo courtesy: Amy Rousseau)</figcaption></figure>



<p>‚ÄúI think girls and young women today don‚Äôt realize how lucky they are with the options they have,‚Äù Grabow said.</p>



<p>And, participating in triathlons is an ‚Äúexcellent‚Äù opportunity, because amateurs like herself can race side-by-side with the pros.</p>



<p>Grabow, who competed in three 70.3 Ironman races this year, said as she‚Äôs gotten older, she‚Äôs slower, especially as she hit the 80 milestone.</p>



<p>With that in mind, hitting the time cut-off was critical to her. She said she had a slow swim (1:47:41) and bike (7:51:27), but finished strong with a faster run (6:40:11).</p>



<p>‚ÄúI didn‚Äôt have any dark moments,‚Äù Grabow said. ‚ÄúI did have some hamstring tightness before the race, but didn‚Äôt have time to rest it. I knew I wouldn‚Äôt bike as hard, but in the long run, I think it helped. I took more time and took in nutrition and salt.‚Äù</p>



<p>Once she started the run, Grabow felt fine. Her coach and daughter, Amy Rousseau, were on the sidelines cheering her on and keeping her on schedule. As she approached the finish line, she tripped.</p>



<p>‚ÄúThat was such a surprise,‚Äù Grabow said. ‚ÄúI guess I just didn‚Äôt pick up my feet, or the carpet was wrinkled there.‚Äù</p>



<p>It didn‚Äôt take long for Grabow to pick herself up and cross the finish line, where the announcer declared her an ‚ÄúIronman.‚Äù</p>



<p>‚ÄúIt didn‚Äôt bother me, it was just embarrassing,‚Äù Grabow said of the fumble.</p>



<p>Rousseau tracked her mother throughout the race, saying she looked strong the entire time. Despite the trip at the end, ‚Äúshe did bounce right back up and kept going and didn‚Äôt stay down.‚Äù</p>



<figure><a href="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/amy-and-natalie.jpg"><img decoding="async" width="1024" height="959" src="https://cdn.bigislandnow.com/file/bigislandnow/2025/10/amy-and-natalie-1024x959.jpg" alt=""></a><figcaption>Amy Rousseau with her mother, Natalie Grabow, 80, before the Ironman World Championship race in Kona on Oct. 11, 2025. (Photo courtesy: Amy Rousseau)</figcaption></figure>



<p>‚ÄúFor many 80-year-olds, that (fall) would break a hip or collar bone,‚Äù Rousseau said.</p>



<p>But not her mom.</p>



<p>‚ÄúShe showed her spirit throughout that part,‚Äù Rousseau said. ‚ÄúI‚Äôm so proud of her.‚Äù</p>



<p>After the race, Rousseau and Grabow were walking around Ali‚Äòi Drive when her mother declared triathlon racing ‚Äúwas what I was meant to do.‚Äù</p>



<p>‚ÄúIt‚Äôs a great fit for her,‚Äù Rousseau, 50, said. ‚ÄúShe loves the training. Triathlon has occupied her mind in a good way.‚Äù</p>



<p>Rousseau has been to Kona as her mom‚Äôs cheerleader about five times, including the first race in 2006.</p>



<p>This year, Rousseau created a system to follow Grabow throughout the course, watching her finish the bike and start her run: ‚ÄúI rode my bike on the shoulder, keeping an eye on her and making sure she was OK. This was just a race against the clock, and she looked strong the whole time.‚Äù</p>



<p>In the past, Rousseau said her mom would jog, then walk through the aid stations, but ‚Äúshe ran the whole thing.‚Äù</p>



<p>‚ÄúI don‚Äôt know how she does it,‚Äù Rousseau said. ‚ÄúWhat a great role model and example of what working hard and sticking with something and riding out the highs and lows. You just keep going. You never give up. She‚Äôs demonstrated that throughout my life.‚Äù</p>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The trust collapse: Infinite AI content is awful (211 pts)]]></title>
            <link>https://arnon.dk/the-trust-collapse-infinite-ai-content-is-awful/</link>
            <guid>45833496</guid>
            <pubDate>Thu, 06 Nov 2025 10:12:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arnon.dk/the-trust-collapse-infinite-ai-content-is-awful/">https://arnon.dk/the-trust-collapse-infinite-ai-content-is-awful/</a>, See on <a href="https://news.ycombinator.com/item?id=45833496">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>We‚Äôre living through the weirdest moment in human history.</p>



<p>For the first time since, well, ever, the cost of creating content has dropped to essentially zero. Not ‚Äúcheaper than before‚Äù, but like actually free.</p>



<p>It‚Äôs so easy to generate a thousand blog posts or ten thousand ‚Äú‚Äù‚Äùpersonalized‚Äù‚Äù‚Äù emails and it barely costs you anything (for now).</p>



<p>In theory this sounds great, infinite content. Giving words to those who struggled before.</p>



<p>So many opportunities.</p>



<p>But if you‚Äôre trying to sell, <strong>trust is collapsing faster than content is proliferating.</strong></p>



<p>And I don‚Äôt mean ‚Äútrust‚Äù in some abstract sense, but the real ‚Äì who‚Äôs real, who‚Äôs credible, and what should I be paying attention to?</p>



<p>We‚Äôre not moving forward. We‚Äôre definitely moving backwards.</p>



<h3>A tale of a B2B SaaS company</h3>



<p>I know someone who runs a B2B SaaS company‚Äôs sales ‚Äì he‚Äôs very smart. He spent many many years building his network and being a ‚Äúrelationship builder‚Äù type of seller ‚Äì earning trust the old-fashioned way.</p>



<p>When we spoke last Sunday, he told me ‚ÄúI ignore all email outreach, and I barely even pick up the phone if I don‚Äôt know who it is‚Äù</p>



<p>‚ÄúI can‚Äôt tell if it‚Äôs a real person or someone who‚Äôs scraped my details. I used to be able to tell. Now I can‚Äôt. So I just‚Ä¶ don‚Äôt engage. Not worth my time.‚Äù</p>



<p>To dumb it down for you if you‚Äôre doing this outbound ‚Äì he‚Äôs not asking ‚Äúdo I need this product?‚Äù that you‚Äôre selling, but he‚Äôs asking ‚Äúwhy should I trust <em>you</em> specifically to deliver it?‚Äù ‚Äì and you‚Äôre not getting through with that.</p>



<h3>Marketing funnel? Nah. Meet the trust funnel</h3>



<p>If being in marketing has taught me something, is that the ‚Äúrules‚Äù and ‚Äúplaybooks‚Äù optimize for the wrong question ‚Äì we craft positioning that explains <em>what</em> we do and <em>why</em> it matters.</p>



<p>In many cases, your prospect already knows they need what you‚Äôre selling.</p>



<p>They don‚Äôt need <em>another</em> pitch deck explaining why AI coding assistants increase developer productivity or why they can send more e-mails with an AI SDR.</p>



<p>They‚Äôve seen forty of those this month (can we talk about how many AI SDRs there are????)</p>



<p>Honestly, this hurts saying too, but they don‚Äôt need proof that outcome-based pricing aligns incentives better than seat licenses. They read one of my 40 articles on the topic already.</p>



<p>What they actually want to know is ‚Äúwhy the hell would I buy it from <em>you</em> instead of the other hundred companies spamming my inbox with identical claims?‚Äù</p>



<p>And because everything is AI slop now, answering that question became harder for them.</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="1454" height="812" data-attachment-id="1658" data-permalink="https://arnon.dk/the-trust-collapse-infinite-ai-content-is-awful/image-65/" data-orig-file="https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?fit=1454%2C812&amp;ssl=1" data-orig-size="1454,812" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?fit=500%2C279&amp;ssl=1" data-large-file="https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?fit=1454%2C812&amp;ssl=1" src="https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?resize=1454%2C812&amp;ssl=1" alt="" srcset="https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?w=1454&amp;ssl=1 1454w, https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?resize=500%2C279&amp;ssl=1 500w, https://i0.wp.com/arnon.dk/wp-content/uploads/2025/11/image-2.png?resize=768%2C429&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption><a href="https://phoscreative.com/services/the-phos-way/">I stole this from PHOS Creative</a></figcaption></figure>



<p>If you haven‚Äôt heard already, here are the differences between a marketing funnel and a trust funnel:</p>



<figure><table><thead><tr><th data-align="left">Aspect</th><th data-align="left">Marketing funnel</th><th data-align="left">Trust funnel</th></tr></thead><tbody><tr><td data-align="left">Main Focus</td><td data-align="left">Lead generation and conversions</td><td data-align="left">Relationship building and customer loyalty</td></tr><tr><td data-align="left">End Point</td><td data-align="left">Purchase or conversion</td><td data-align="left">Ongoing customer advocacy and retention</td></tr><tr><td data-align="left">Content Strategy</td><td data-align="left">Promotional, sales-focused</td><td data-align="left">Helpful, customer-focused, value-driven</td></tr><tr><td data-align="left">Success Metrics</td><td data-align="left">Conversion rates, sales numbers</td><td data-align="left">Satisfaction, repeat business, advocacy</td></tr><tr><td data-align="left">Timeline</td><td data-align="left">Short to medium-term</td><td data-align="left">Long-term, compounding trust</td></tr></tbody></table></figure>



<p>It‚Äôs clear that you need to be on that trust side!</p>



<h3>With normal marketing funnels, lead generation sucks now</h3>



<p>It‚Äôs simply too boring.</p>



<p>When a Claude license is like, $10 a month ‚Äì content creation costs are effectively zero. Now everyone can afford to <em>look</em> credible. Perfect grammar. Personalized outreach that references your LinkedIn posts (albeit badly).</p>



<p>All of it can be generated in minutes, with no human intervention.</p>



<p>Which means <strong>all of it is now suspect.</strong></p>



<p>I now send all e-mail AND LinkedIn messages to the trash.</p>



<p>Why? Because I can actually tell they didn‚Äôt come from humans who care about me or my problem.</p>



<p>They‚Äôre all ‚Äúvaguely‚Äù personalized, and they‚Äôre all ‚Äúcurious‚Äù about how I do something. Why? Because <a href="https://outboundrepublic.com/blog/the-psychology-of-cold-outreach-why-people-reply/">‚ÄúI‚Äôm curious about‚Ä¶‚Äù is in a playbook</a> that supposedly gets good responses.</p>







<p>This is the trust collapse for me: <strong>it‚Äôs not that I don‚Äôt believe your product works. I don‚Äôt believe you‚Äôre a real human who will still care after you sign the contract.</strong></p>



<h3>Rates are down, I‚Äôll just send more messages</h3>



<p>God, no. Stop.</p>



<p>That‚Äôs not the issue.</p>



<p><strong>Old World (‚Ä¶-2024):</strong></p>



<ul>
<li>Cost to produce credible, personalized outreach: $50/hour (human labor)</li>



<li>Volume of credible outreach a prospect receives: ~10/week</li>



<li>Prospect‚Äôs ability to evaluate authenticity: <strong>Pattern recognition works ~80% of time</strong></li>
</ul>



<p><strong>New World (2025-‚Ä¶):</strong></p>



<ul>
<li>Cost to produce credible, personalized outreach: effectively 0</li>



<li>Volume of credible outreach a prospect receives: ~200/week</li>



<li>Prospect‚Äôs ability to evaluate authenticity: <strong>Pattern recognition works ~20% of time</strong></li>
</ul>



<p>The signal-to-noise ratio has hit a breaking point where the cost of verification exceeds the expected value of engagement.</p>



<p>So prospects don‚Äôt verify. They just assume everything is noise. This is why I (and my friend) ignore all outreach, and I‚Äôm far from alone.</p>



<p>The cognitive cost of determining ‚Äúis this real?‚Äù for 200 messages exceeds the expected benefit of the 2-3 that <em>might</em> actually be valuable.</p>



<h3>Back to trust‚Ä¶</h3>



<p>You have to understand ‚Äì your prospects aren‚Äôt asking:</p>



<ul>
<li>‚ÄúDoes your AI coding assistant work?‚Äù (They probably assume it does)</li>



<li>‚ÄúWill it actually improve {some metric}?‚Äù (They assume it will)</li>



<li>‚ÄúIs the pricing competitive?‚Äù (They can compare that in a spreadsheet)</li>
</ul>



<p>They‚Äôre asking:</p>



<ul>
<li>‚ÄúWill you still be here in 12 months when I‚Äôve integrated your tool into my workflow?‚Äù</li>



<li>‚ÄúWhy are you actually better or different from the 5 others I know of?‚Äù</li>



<li>‚ÄúAre you burning VC cash on unsustainable unit economics?‚Äù</li>



<li>‚ÄúWhen the music stops, will I be left holding a broken integration?‚Äù</li>



<li>‚ÄúHave you actually figured out how to make money, or are you just another vibe-revenue vibe-coded startup hoping to flip before the math catches up to your credit usage?‚Äù</li>
</ul>



<p>And here‚Äôs the problem: <strong>they can‚Äôt tell if you don‚Äôt tell them.</strong></p>



<h3>Not to be cynical, but‚Ä¶</h3>



<p>I‚Äôm not writing this to be cynical, but because I want to make sure you play the right game.</p>



<p>Sure, you have to answer ‚Äúwhy should I buy this product category?‚Äù but also ‚Äúwhy should I buy it from <em>you</em>?‚Äù and your content and marketing has to match that.</p>



<p>Your opportunity is huge. Here is what we all must do:</p>



<p><strong>Trust is still a human job:</strong>&nbsp;At least for now ‚Äì AI may help you along the way but at least in 2025 only humans can build genuine emotional connection and credibility. You need that lasting loyalty and advocacy. Don‚Äôt rely on the so-called ‚Äúpersonalized outbound‚Äù alone.</p>



<p><strong>Yes, relevance and customization are critical:</strong>&nbsp;AI should help you segment prospects meticulously and flag when human follow-up is likely to deepen trust, not just automate at scale. Use the outbound engine to be real.‚Äã</p>



<p><strong>Again, keep a human involved:</strong>&nbsp;Too much automation can undermine trust. I expect at least some human engagement, especially in complex or high-value sales contexts.<a href="https://www.forbes.com/councils/forbesbusinesscouncil/2025/11/05/the-myth-of-ai-in-outbound-sales-why-humans-still-win-the-hardest-plays/" target="_blank" rel="noreferrer noopener"></a>‚Äã‚Äã</p>



<h4>Is this actually different now that we have AI?</h4>



<p>Yes. </p>



<p>You‚Äôre representing a brand. And your brand must continuously earn that trust, even if you blend of AI-powered relevance. We still want that unmistakable human leadership.</p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mathematical exploration and discovery at scale (223 pts)]]></title>
            <link>https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/</link>
            <guid>45833162</guid>
            <pubDate>Thu, 06 Nov 2025 09:24:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/">https://terrytao.wordpress.com/2025/11/05/mathematical-exploration-and-discovery-at-scale/</a>, See on <a href="https://news.ycombinator.com/item?id=45833162">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		

<p>
 <a href="https://bogdan-georgiev.com/">Bogdan Georgiev</a>, <a href="https://sites.brown.edu/jgs/">Javier G√≥mez-Serrano</a>, <a href="https://zawagner22.github.io/">Adam Zsolt Wagner</a>, and I have uploaded to the arXiv our paper ‚Äú<a href="https://arxiv.org/abs/2511.02864">Mathematical exploration and discovery at scale</a>‚Äú. This is a longer report on the experiments we did in collaboration with Google Deepmind with their <a href="https://deepmind.google/discover/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/">AlphaEvolve tool</a>, which is in the process of being made available for broader use. Some of our experiments were already reported on in a <a href="https://storage.googleapis.com/deepmind-media/DeepMind.com/Blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/AlphaEvolve.pdf">previous white paper</a>, but the current paper provides more details, as well as a link to a <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems">repository</a> with various relevant data such as the prompts used and the evolution of the tool outputs.
</p><p>
AlphaEvolve is a variant of more traditional optimization tools that are designed to extremize some given score function over a high-dimensional space of possible inputs. A traditional optimization algorithm might evolve one or more trial inputs over time by various methods, such as stochastic gradient descent, that are intended to locate increasingly good solutions while trying to avoid getting stuck at local extrema. By contrast, AlphaEvolve does not evolve the score function inputs directly, but uses an LLM to evolve computer code (often written in a standard language such as Python) which will in turn be run to generate the inputs that one tests the score function on. This reflects the belief that in many cases, the extremizing inputs will not simply be an arbitrary-looking string of numbers, but will often have some structure that can be efficiently described, or at least approximated, by a relatively short piece of code. The tool then works with a population of relatively successful such pieces of code, with the code from one generation of the population being modified and combined by the LLM based on their performance to produce the next generation. The stochastic nature of the LLM can actually work in one‚Äôs favor in such an evolutionary environment: many ‚Äúhallucinations‚Äù will simply end up being pruned out of the pool of solutions being evolved due to poor performance, but a small number of such mutations can add enough diversity to the pool that one can break out of local extrema and discover new classes of viable solutions. The LLM can also accept user-supplied ‚Äúhints‚Äù as part of the context of the prompt; in some cases, even just uploading PDFs of relevant literature has led to improved performance by the tool. Since the initial release of AlphaEvolve, similar tools have been developed by others, including <a href="https://github.com/algorithmicsuperintelligence/openevolve">OpenEvolve</a>, <a href="https://github.com/SakanaAI/ShinkaEvolve">ShinkaEvolve</a> and <a href="https://github.com/liugangcode/deepevolve">DeepEvolve</a>.
</p><p>
We tested this tool on a large number (67) of different mathematics problems (both solved and unsolved) in analysis, combinatorics, and geometry that we gathered from the literature, and reported our outcomes (both positive and negative) in this paper. In many cases, AlphaEvolve achieves similar results to what an expert user of a traditional optimization software tool might accomplish, for instance in finding more efficient schemes for packing geometric shapes, or locating better candidate functions for some calculus of variations problem, than what was previously known in the literature. But one advantage this tool seems to offer over such custom tools is that of <em>scale</em>, particularly when when studying variants of a problem that we had already tested this tool on, as many of the prompts and verification tools used for one problem could be adapted to also attack similar problems; several examples of this will be discussed below.
</p><p>
Another advantage of AlphaEvolve was <em>robustness</em>: it was relatively easy to set up AlphaEvolve to work on a broad array of problems, without extensive need to call on domain knowledge of the specific task in order to tune hyperparameters. In some cases, we found that making such hyperparameters part of the data that AlphaEvolve was prompted to output was better than trying to work out their value in advance, although a small amount of such initial theoretical analysis was helpful. For instance, in calculus of variation problems, one is often faced with the need to specify various discretization parameters in order to estimate a continuous integral, which cannot be computed exactly, by a discretized sum (such as a Riemann sum), which can be evaluated by computer to some desired precision. We found that simply asking AlphaEvolve to specify its own discretization parameters worked quite well (provided we designed the score function to be conservative with regards to the possible impact of the discretization error); see for instance <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/classical_inequalities/classical_inequalities.ipynb">this experiment</a> in locating the best constant in functional inequalities such as the <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/14.html">Hausdorff-Young inequality</a>.
</p><p>
A third advantage of AlphaEvolve over traditional optimization methods was the <em>interpretability</em> of many of the solutions provided. For instance, in <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/classical_inequalities/classical_inequalities.ipynb">one of our experiments</a> we sought to find an extremum to a functional inequality such as the <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/16.html">Gagliardo‚ÄìNirenberg inequality</a> (a variant of the Sobolev inequality). This is a relatively well-behaved optimization problem, and many standard methods can be deployed to obtain near-optimizers that are presented in some numerical format, such as a vector of values on some discretized mesh of the domain. However, when we applied AlphaEvolve to this problem, the tool was able to discover the exact solution (in this case, a Talenti function), and create code that sampled from that function on a discretized mesh to provide the required input for the scoring function we provided (which only accepted discretized inputs, due to the need to compute the score numerically). This code could be inspected by humans to gain more insight as to the nature of the optimizer. (Though in some cases, AlphaEvolve‚Äôs code would contain some brute force search, or a call to some existing optimization subroutine in one of the libraries it was given access to, instead of any more elegant description of its output.)
</p><p>
For problems that were sufficiently well-known to be in the training data of the LLM, the LLM component of AlphaEvolve often came up almost immediately with optimal (or near-optimal) solutions. For instance, for variational problems where the gaussian was known to be the extremizer, AlphaEvolve would frequently guess a gaussian candidate during one of the early evolutions, and we would have to obfuscate the problem significantly to try to conceal the connection to the literature in order for AlphaEvolve to experiment with other candidates. AlphaEvolve would also propose similar guesses for other problems for which the extremizer was not known. For instance, we <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_kakeya_problem/finite_field_kakeya.ipynb">tested this tool</a> on the sum-difference exponents of relevance to the <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/30.html">arithmetic Kakeya conjecture</a>, which can be formulated as a variational entropy inequality concerning certain two-dimensional discrete random variables. AlphaEvolve initially proposed some candidates for such variables based on discrete gaussians, which actually worked rather well even if they were not the exact extremizer, and already generated some slight improvements to previous lower bounds on such exponents in the literature. Inspired by this, I was later able to rigorously obtain some theoretical results on the asymptotic behavior on such exponents in the regime where the number of slopes was fixed, but the ‚Äúrational complexity‚Äù of the slopes went to infinity; this will be reported on in a separate paper.
</p><p>
Perhaps unsurprisingly, AlphaEvolve was extremely good at locating ‚Äúexploits‚Äù in the verification code we provided, for instance using degenerate solutions or overly forgiving scoring of approximate solutions to come up with proposed inputs that technically achieved a high score under our provided code, but were not in the spirit of the actual problem. For instance, when we asked it (link under construction) to find <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/53.html">configurations to extremal geometry problems such as locating polygons with each vertex having four equidistant other vertices</a>, we initially coded the verifier to accept distances that were equal only up to some high numerical precision, at which point AlphaEvolve promptly placed many of the points in virtually the same location so that the distances they determined were indistinguishable. Because of this, a non-trivial amount of human effort needs to go into designing a non-exploitable verifier, for instance by working with exact arithmetic (or interval arithmetic) instead of floating point arithmetic, and taking conservative worst-case bounds in the presence of uncertanties in measurement to determine the score. For instance, in testing AlphaEvolve against the ‚Äúmoving sofa‚Äù problem and its variants, we designed a conservative scoring function that only counted those portions of the sofa that we could definitively prove to stay inside the corridor at all times (not merely the discrete set of times provided by AlphaEvolve to describe the sofa trajectory) to prevent it from exploiting ‚Äúclipping‚Äù type artefacts. Once we did so, it performed quite well, for instance <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/the_2d_moving_sofa/the_2d_moving_sofa.ipynb">rediscovering</a> the optimal ‚ÄúGerver sofa‚Äù for the original sofa problem, and also <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/the_3d_moving_sofa/the_3d_moving_sofa.ipynb">discovering new sofa designs</a> for other problem variants, such as a 3D sofa problem.
</p><p>
For well-known open conjectures (e.g., <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/26.html">Sidorenko‚Äôs conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/20.html">Sendov‚Äôs conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/25.html">Crouzeix‚Äôs conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/19.html">the ovals problem</a>, etc.), AlphaEvolve generally was able to locate the previously known candidates for optimizers (that are conjectured to be optimal), but did not locate any stronger counterexamples: thus, we did not disprove any major open conjecture. Of course, one obvious possible explanation for this is that these conjectures are in fact true; outside of a few situations where there is a matching ‚Äúdual‚Äù optimization problem, AlphaEvolve can only provide one-sided bounds on such problems and so cannot definitively determine if the conjectural optimizers are in fact the true optimizers. Another potential explanation is that AlphaEvolve essentially tried all the ‚Äúobvious‚Äù constructions that previous researchers working on these problems had also privately experimented with, but did not report due to the negative findings. However, I think there is at least value in using these tools to systematically record negative results (roughly speaking, that a search for ‚Äúobvious‚Äù counterexamples to a conjecture did not disprove the claim), which currently only exist as ‚Äúfolklore‚Äù results at best. This seems analogous to the role LLM Deep Research tools could play by systematically recording the results (both positive and negative) of automated literature searches, as a supplement to human literature review which usually reports positive results only. Furthermore, when we shifted attention to less well studied variants of famous conjectures, we were able to find some modest new observations. For instance, while AlphaEvolve only found the standard conjectural extremizer <img src="https://s0.wp.com/latex.php?latex=%7Bz%5En-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bz%5En-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bz%5En-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{z^n-1}"> to <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/20.html">Sendov‚Äôs conjecture</a>, as well as for variants such as <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/22.html">Borcea‚Äôs conjecture</a>, <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/21.html">Schmeisser‚Äôs conjecture</a>, or <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/23.html">Smale‚Äôs conjecture</a> it did reveal some potential two-parameter extensions to a <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/24.html">conjecture of de Bruin and Sharma</a> that had not previously been stated in the literature. (For this problem, we were not directly optimizing some variational scalar quantity, but rather a two-dimensional range of possible values, which we could adapt the AlphaEvolve framework to treat). In the future, I can imagine such tools being a useful ‚Äúsanity check‚Äù when proposing any new conjecture, in that it will become common practice to run one of these tools against such a conjecture to make sure there are no ‚Äúobvious‚Äù counterexamples (while keeping in mind that this is still far from conclusive evidence in favor of such a conjecture).
</p><p>
AlphaEvolve did not perform equally well across different areas of mathematics. When testing the tool on analytic number theory problems, such as that of <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/27.html">designing sieve weights for elementary approximations to the prime number theorem</a>, it struggled to take advantage of the number theoretic structure in the problem, even when given suitable expert hints (although such hints have proven useful for other problems). This could potentially be a prompting issue on our end, or perhaps the landscape of number-theoretic optimization problems is less amenable to this sort of LLM-based evolutionary approach. On the other hand, AlphaEvolve does seem to do well when the constructions have some algebraic structure, such as with the finite field Kakeya and Nikodym set problems, which we will turn to shortly.
</p><p>
For many of our experiments we worked with fixed-dimensional problems, such as trying to optimally pack <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> shapes in a larger shape for a fixed value of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}">. However, we found in some cases that if we asked AlphaEvolve to give code that took parameters such as <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> as input, and tested the output of that code for a suitably sampled set of values of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{n}"> of various sizes, then it could sometimes generalize the constructions it found for small values of this parameter to larger ones; for instance, in the infamous <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/65.html">sixth problem of this year‚Äôs IMO</a>, it could use this technique to discover the optimal arrangement of tiles, which none of the frontier models could do at the time (although AlphaEvolve has no capability to demonstrate that this arrangement was, in fact, optimal). Another productive use case of this technique was for <a href="https://google-deepmind.github.io/alphaevolve_repository_of_problems/problems/1.html">finding finite field Kakeya and Nikodym sets</a> of small size in low-dimensional vector spaces over finite fields of various sizes. For Kakeya sets in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbf+F%7D_q%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbf+F%7D_q%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbf+F%7D_q%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{{\mathbf F}_q^d}">, <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_kakeya_problem/finite_field_kakeya.ipynb">it located</a> the known optimal construction based on quadratic residues in two dimensions, and very slightly beat (by an error term of size <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q)}">) the best construction in three dimensions; this was an algebraic construction (still involving quadratic residues) discovered empirically that we could then prove to be correct by first using Gemini‚Äôs ‚ÄúDeep Think‚Äù tool to locate an informal proof, which we could then convert into a formalized Lean proof by using Google Deepmind‚Äôs ‚ÄúAlphaProof‚Äù tool. At one point we thought it had found a construction in four dimensions which achieved a more noticeable improvement (of order <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q^3)}">) of what we thought was the best known construction, but we subsequently discovered that essentially the same construction had appeared already in <a href="https://arxiv.org/abs/2108.00074">a paper of Bukh and Chao</a>, although it still led to a more precise calculation of the error term (to accuracy <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%5E%7B3%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%5E%7B3%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%5E%7B3%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q^{3/2})}"> rather than <img src="https://s0.wp.com/latex.php?latex=%7BO%28q%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7BO%28q%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7BO%28q%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{O(q^2)}">, where the error term now involves the Lang-Weil inequality and is unlikely to have a closed form). Perhaps AlphaEvolve had somehow absorbed the Bukh-Chao construction within its training data to accomplish this. However, when we <a href="https://github.com/google-deepmind/alphaevolve_repository_of_problems/blob/main/experiments/finite_field_nikodym_problem/finite_field_nikodym.ipynb">tested the tool on Nikodym</a> sets (which are expected to have asymptotic density <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" srcset="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002 1x, https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002&amp;zoom=4.5 4x" alt="{1}">, although this remains unproven), it did find some genuinely new constructions of such sets in three dimensions, based on removing quadratic varieties from the entire space. After using ‚ÄúDeep Think‚Äù again to analyze these constructions, we found that they were inferior to a purely random construction (which in retrospect was an obvious thing to try); however, they did inspire a hybrid construction in which one removed random quadratic varieties and performed some additional cleanup, which ends up outperforming both the purely algebraic and purely random constructions. This result (with completely human-generated proofs) will appear in a subsequent paper.
</p>	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What the hell have you built (303 pts)]]></title>
            <link>https://wthhyb.sacha.house/</link>
            <guid>45832803</guid>
            <pubDate>Thu, 06 Nov 2025 08:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wthhyb.sacha.house/">https://wthhyb.sacha.house/</a>, See on <a href="https://news.ycombinator.com/item?id=45832803">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[How I am deeply integrating Emacs (200 pts)]]></title>
            <link>https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/</link>
            <guid>45832341</guid>
            <pubDate>Thu, 06 Nov 2025 07:09:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/">https://joshblais.com/blog/how-i-am-deeply-integrating-emacs/</a>, See on <a href="https://news.ycombinator.com/item?id=45832341">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-pagefind-body="true">  <p><img src="https://revere.b-cdn.net/joshblais.com/2025-11-05-133703_grim.png" alt="img"></p>
<p>Emacs has holistically become my daily computing environment.</p>
<p>My efforts have been focused on building emacs into the workflow of essentially everything I do, as long as it doesn‚Äôt involve heavy video or media, I try my very best to accomplish it in emacs.
The idea is to achieve deep integration with everything I do on a computer, to the degree my thoughts are immediately able to be acted upon in the buffer.</p>
<p>I use <a href="https://hypr.land/">hyprland</a> as my window manager, and while I have heard of other managers/DEs (I was using GNOME for the better part of 6 months), I keep coming back to hyprland just because it works and is easy to configure. Also, for some reason, I seem not to have laggin in emacs on wayland in hyprland, while I had to previously run emacs in X11 mode in GNOME, go figure.</p>

<h2 id="my-motivation">My Motivation<a tab-index="0" aria-hidden="false" aria-label="Link to My Motivation" data-pagefind-ignore="" href="#my-motivation">#</a></h2>
<p>I have seen what people are capable of doing when their tools get out of the way, and they are free to just <em>create</em>.
This is how world class athletes, musicians, artists, writers, and of course programmers take what is in their mind and translate it into reality.
The idea is that if I can learn this ‚Äú<a href="https://www.youtube.com/watch?v=VADudzQGvU8&amp;themeRefresh=1">editor of a lifetime</a>‚Äù - then the things that I want to create, the programs I want to write, will be achieved in a near frictionless environment, allowing for velocity that is not possible elsewhere.
It is the ultimate sharpening of the axe before chopping the tree.</p>

<h2 id="why-not-exwm">Why not EXWM?<a tab-index="0" aria-hidden="false" aria-label="Link to Why not EXWM?" data-pagefind-ignore="" href="#why-not-exwm">#</a></h2>
<p>I have considered using EXWM as the window manager (quite literally offloading window management to emacs, and ‚Äúliving in emacs‚Äù - to more of a degree than I do already), the hesitation I have is that:</p>
<ol>
<li>Emacs is single threaded, therefore if anything in the system hangs, the whole system hangs, and</li>
<li>It is only X11 where most of the development and forward movement in the linux space has been in wayland. While I understand this is not a tremendous issue, wayland does seem to be where the puck is going.</li>
</ol>
<p>So, what I am aiming to do is replicate functionality as best as I can from EXWM to a wayland environment - not wholly possible, but also not wholly impossible, either.</p>

<h2 id="the-emacs-launcher-program">The Emacs Launcher program<a tab-index="0" aria-hidden="false" aria-label="Link to The Emacs Launcher program" data-pagefind-ignore="" href="#the-emacs-launcher-program">#</a></h2>
<p>If you look at <a href="https://github.com/jblais493/nixos-config">my dotfiles</a>, you can see I have a <a href="https://github.com/jblais493/nixos-config/blob/master/dotfiles/hypr/scripts/emacs-launcher.go">script written in Go</a> that allows me to call each and every one of my emacs controls anywhere is my system.
I was previously calling each of these emacs commands in bash and with a sleep command so as to make sure I was targeting the emacs instance. No longer. This Go script has sped up my workflow by 10x.</p>

<h2 id="my-current-setup">My Current setup<a tab-index="0" aria-hidden="false" aria-label="Link to My Current setup" data-pagefind-ignore="" href="#my-current-setup">#</a></h2>

<h3 id="how-i-launch-emacs">How I Launch Emacs<a tab-index="0" aria-hidden="false" aria-label="Link to How I Launch Emacs" data-pagefind-ignore="" href="#how-i-launch-emacs">#</a></h3>
<p><code>bind = $mainMod SHIFT, E, exec, bash -c "emacs"</code></p>
<p>I almost never press this keybind, as emacs is opened from the get-go in my hyprland sessions.  For that rare time I need to re-open it.</p>

<h3 id="opening-vterm-as-my-default-terminal">Opening vterm as my default terminal<a tab-index="0" aria-hidden="false" aria-label="Link to Opening vterm as my default terminal" data-pagefind-ignore="" href="#opening-vterm-as-my-default-terminal">#</a></h3>
<p><code>bind = $mainMod, E, exec, emacsclient -n -e '(my/new-frame-with-vterm)'</code></p>
<p>This permits me to quickly open a vterm window and enter commands etc. If I need anything that is more graphically intense, I fallback to kitty terminal, but this is less and less these days.</p>

<h4 id="opening-vterm-in-my-emacs-session-quickly-for-in-projects-is-done-like-so">Opening vterm in my emacs session quickly for in projects is done like so:<a tab-index="0" aria-hidden="false" aria-label="Link to Opening vterm in my emacs session quickly for in projects is done like so:" data-pagefind-ignore="" href="#opening-vterm-in-my-emacs-session-quickly-for-in-projects-is-done-like-so">#</a></h4>
<p><code>bind = $mainMod, RETURN, exec, ~/.config/hypr/scripts/emacs-launcher '(my-open-vterm-at-point)'</code></p>

<h3 id="universal-launcher"><a href="https://github.com/jblais493/universal-launcher.el">Universal Launcher</a><a tab-index="0" aria-hidden="false" aria-label="Link to Universal Launcher" data-pagefind-ignore="" href="#universal-launcher">#</a></h3>
<p><code>bind = $mainMod, SPACE, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (universal-launcher-popup))'</code></p>
<p>I wanted to replicate a launcher (similar to wofi/rofi) in which I could easily launch apps and switch to them in the environment.</p>
<p>So, my take on this is to replace wofi with this functionality. I was using ssh providers in GNOME, but then brought the functionality into my universal launcher. It has effectively grown to encapsulate:</p>
<ul>
<li>Passwords</li>
<li>SSH</li>
<li>Bookmarking</li>
<li>Commands and program launching</li>
<li>Emojis</li>
<li>TODOS (though org-agenda/calendar also handles this)</li>
<li>File navigation</li>
<li>Web and documentation search</li>
</ul>
<p>While this is a work in progress, I use it every day, hundreds of times a day, and love the flow &amp; speed my launcher allows.</p>

<h3 id="capture-to-org-mode">Capture to org mode<a tab-index="0" aria-hidden="false" aria-label="Link to Capture to org mode" data-pagefind-ignore="" href="#capture-to-org-mode">#</a></h3>
<p><code>bind = CTRL SHIFT, c, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (org-capture))'</code></p>
<p>When I am not ‚Äúin‚Äù emacs (I am always in emacs by extension) I can still capture direct to emacs with a quick keybind.</p>
<p>I capture to my org directory:</p>
<ul>
<li>notes</li>
<li>bookmarks</li>
<li>contacts</li>
<li>inbox (todos)</li>
<li>events/deadlines</li>
</ul>
<p>This is very useful when I am wanting to save a thought, idea, bookmark, quote, what have you, and then integrate it with my <a href="https://www.orgroam.com/">org-roam</a> file structure.</p>

<h3 id="notes">Notes<a tab-index="0" aria-hidden="false" aria-label="Link to Notes" data-pagefind-ignore="" href="#notes">#</a></h3>
<p><code>bind = $mainMod CTRL, N, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (find-file "~/org/notes.org"))'</code></p>
<p>I can navigate to my notes file very quickly to write emails, keep notes on stuff, and then translate those into my org-roam directory, too.</p>

<h3 id="calendarorg-agenda">Calendar/Org Agenda<a tab-index="0" aria-hidden="false" aria-label="Link to Calendar/Org Agenda" data-pagefind-ignore="" href="#calendarorg-agenda">#</a></h3>
<p><code>bind = $mainMod, C, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (=calendar))'</code></p>
<p><code>bind = $mainMod, N, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (my/org-agenda-dashboard))'</code></p>
<p>Quick access to my agenda and calendar from anywhere.</p>

<h3 id="password-manager">Password manager<a tab-index="0" aria-hidden="false" aria-label="Link to Password manager" data-pagefind-ignore="" href="#password-manager">#</a></h3>
<p><code>bind = $mainMod, P, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (pass))'</code></p>
<p>Password-store inside emacs to create, update, grab passwords and insert them on page in browsers.</p>

<h3 id="file-browsing">File Browsing<a tab-index="0" aria-hidden="false" aria-label="Link to File Browsing" data-pagefind-ignore="" href="#file-browsing">#</a></h3>
<p><code>bind = $mainMod, F, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (dirvish))'</code></p>
<p>I use <a href="https://github.com/alexluigit/dirvish">dirvish</a>/<a href="https://www.gnu.org/s/emacs/manual/html_node/emacs/Dired.html">dired</a> for nearly all my file browsing and manipulation. I have some binds that allow me to pull up <a href="https://docs.xfce.org/xfce/thunar/start">thunar</a> for graphical drag-drop operations, but other than that files are dealt with inside emacs.</p>
<p>The killer feature is that you can edit files as you would edit text, nothing else comes close.</p>

<h3 id="bookmarks">Bookmarks<a tab-index="0" aria-hidden="false" aria-label="Link to Bookmarks" data-pagefind-ignore="" href="#bookmarks">#</a></h3>
<p><code>bind = $mainMod, B, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (find-file "~/org/bookmarks.org"))'</code></p>
<p>Bookmarking within emacs allows me to keep all sites top of mind.</p>

<h3 id="email">Email<a tab-index="0" aria-hidden="false" aria-label="Link to Email" data-pagefind-ignore="" href="#email">#</a></h3>
<p><code>bind = $mainMod, M, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (=mu4e))'</code></p>
<p>The greatest email client.</p>

<h3 id="feed-reader">Feed reader<a tab-index="0" aria-hidden="false" aria-label="Link to Feed reader" data-pagefind-ignore="" href="#feed-reader">#</a></h3>
<p><code>bind = $mainMod CTRL, Z, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (elfeed))'</code></p>
<p>Reading any feed from around the web, I follow youtube, blogs, news, etc. here - never going out to the web to read anything.</p>

<h3 id="music-playing">Music playing<a tab-index="0" aria-hidden="false" aria-label="Link to Music playing" data-pagefind-ignore="" href="#music-playing">#</a></h3>
<p><code>bind = $mainMod CONTROL, M, exec, ~/.config/hypr/scripts/emacs-launcher '(progn (select-frame-set-input-focus (selected-frame)) (emms-playlist-mode-go))'</code></p>
<p>You thought I <em>wouldn‚Äôt</em> play music in emacs?</p>

<h3 id="emacs-everywhere-for-editing-text-anywhere">Emacs everywhere for editing text anywhere<a tab-index="0" aria-hidden="false" aria-label="Link to Emacs everywhere for editing text anywhere" data-pagefind-ignore="" href="#emacs-everywhere-for-editing-text-anywhere">#</a></h3>
<p><code>bind = $mainMod CONTROL, E, exec, emacsclient --eval '(thanos/type)'</code></p>
<p>When you are in a text box on any site, you can just edit the text in emacs, press <code>C-c C-c</code> and have it pasted right there for you.</p>

<h2 id="will-i-use-exwm">Will I use EXWM?<a tab-index="0" aria-hidden="false" aria-label="Link to Will I use EXWM?" data-pagefind-ignore="" href="#will-i-use-exwm">#</a></h2>
<p>I think that because I spend so much time inside emacs, I don‚Äôt really get the benefits of everything being a buffer. I only use a browser for projects, not as a window I have always open, and I don‚Äôt really need emacs to control buffers or give me the keybinds universally. I will never say never though, perhaps one day it will be my window manager of choice.</p>
<p>How are you integrating emacs in your workflow? I would be super interested to see other setups that allow you to use emacs as your one, true, holistic computing environment. Shoot me an email and tell me how it‚Äôs done!</p>
<p>As always, God bless, and until next time.</p>
<p>If you enjoyed this post, consider supporting my work by <a href="https://buymeacoffee.com/joshuablais">Buying me a Coffee</a>, <a href="https://mountainthebook.com/">Checking out my book</a>, or sending me an <a href="mailto:josh@joshblais.com">email</a> to tell me what you think.</p>  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I may have found a way to spot U.S. at-sea strikes before they're announced (261 pts)]]></title>
            <link>https://old.reddit.com/r/OSINT/comments/1opjjyv/i_may_have_found_a_way_to_spot_us_atsea_strikes/</link>
            <guid>45831541</guid>
            <pubDate>Thu, 06 Nov 2025 04:37:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/OSINT/comments/1opjjyv/i_may_have_found_a_way_to_spot_us_atsea_strikes/">https://old.reddit.com/r/OSINT/comments/1opjjyv/i_may_have_found_a_way_to_spot_us_atsea_strikes/</a>, See on <a href="https://news.ycombinator.com/item?id=45831541">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Over the last month the U.S. has carried out several interdiction strikes on narco-trafficking boats in the Eastern Pacific and Caribbean. These are usually acknowledged the next day, described vaguely as ‚Äúin international waters,‚Äù with no coordinates. I‚Äôve been experimenting with NASA‚Äôs VIIRS thermal anomaly feed (FIRMS) to see if any of these events are visible <em>as they happen</em>.</p>

<p><a href="https://preview.redd.it/xudkavdw0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=15582a6952deb90dcf9d014a4173b0c523ebd987">https://preview.redd.it/xudkavdw0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=15582a6952deb90dcf9d014a4173b0c523ebd987</a></p>

<p>On Oct 27, a single <strong>daytime</strong> VIIRS hotspot appears at <strong>14.0387¬∞ N, 106.4606¬∞ W</strong>, which is roughly <strong>415 nautical miles southwest of Acapulco</strong>. It‚Äôs the only ocean pixel in that sector for the entire week. Mexico‚Äôs subsequent statements referenced <strong>search and rescue ~400 nm SW of Acapulco</strong> after that day‚Äôs operations. The geometry lines up almost perfectly.  </p>

<p><a href="https://preview.redd.it/z4nk46ox0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=95de0ab7a01b5688f687cf439e52af6be6f26f99">https://preview.redd.it/z4nk46ox0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=95de0ab7a01b5688f687cf439e52af6be6f26f99</a></p>

<p>Why I think this specific detection is the Oct 27 strike: the public footage released by the U.S. shows a <strong>large explosion with an ongoing flame in daylight</strong>‚Äîexactly the type of surface combustion a daytime VIIRS pass can catch. The spot is far from known offshore platforms or refinery flare fields, and I filtered out land fires and industrial sources before scanning. I‚Äôm <strong>~90% confident</strong> this pixel is the Oct 27 event.  </p>

<p><a href="https://preview.redd.it/hnryod1z0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=d5c97138b50056839cd0689503b9f05920427e54">https://preview.redd.it/hnryod1z0jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=d5c97138b50056839cd0689503b9f05920427e54</a></p>

<p>If you want to replicate: set FIRMS to VIIRS 375 m, date 2025-10-27, pan to the Eastern Pacific off Mexico, and you‚Äôll see the detection with its timestamp and FRP. Measure from Acapulco and you‚Äôll get ~415 nm. It does not recur on adjacent days at that exact location, which argues against a persistent industrial source.</p>

<p>None of this claims intent; it‚Äôs simply ‚Äúthermal anomaly consistent with a fire‚Äù in the precise place and time later described by authorities. The interesting part is methodological: with FIRMS alone‚Äîno paid feeds‚Äîyou can narrow vague ‚Äúinternational waters‚Äù language to a concrete lat/lon box in near-real time. That has obvious implications for open-source monitoring and for how quickly journalists and analysts can geolocate future incidents.  </p>

<p>I‚Äôm happy to hear counter-arguments‚Äîe.g., alternative explanations for a one-off daytime ocean pixel at those coordinates‚Äîbut based on the match to the reported location, the unique nature of the detection, and the daylight, high-energy fire profile, I think this one‚Äôs a hit.</p>

<p><a href="https://preview.redd.it/bsmhlrm11jzf1.png?width=480&amp;format=png&amp;auto=webp&amp;s=c7db45f505fc502a5915041d63973f37e33de191">https://preview.redd.it/bsmhlrm11jzf1.png?width=480&amp;format=png&amp;auto=webp&amp;s=c7db45f505fc502a5915041d63973f37e33de191</a></p>

<p>disclaimer: i run a website that tracks pentagon pizza deliveries and other fun alt-data for geopolitics + OSINT. we just integrated this thermal anomaly data here: <a href="http://pizzint.watch/polyglobe">pizzint.watch/polyglobe</a></p>

<p><a href="https://preview.redd.it/lxnipd731jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=02e50262cae176d30b516e123dfc0df31a204828">https://preview.redd.it/lxnipd731jzf1.png?width=1200&amp;format=png&amp;auto=webp&amp;s=02e50262cae176d30b516e123dfc0df31a204828</a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ratatui ‚Äì App Showcase (692 pts)]]></title>
            <link>https://ratatui.rs/showcase/apps/</link>
            <guid>45830829</guid>
            <pubDate>Thu, 06 Nov 2025 02:50:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ratatui.rs/showcase/apps/">https://ratatui.rs/showcase/apps/</a>, See on <a href="https://news.ycombinator.com/item?id=45830829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 
<p>Atuin replaces your existing shell history with a SQLite database, and records additional context
for your commands.</p>
<p><img src="https://github.com/atuinsh/atuin/blob/main/demo.gif?raw=true" alt="atui demo"></p>
<hr>

<p>This is a CLI utility for displaying current network utilization by process, connection and remote
IP/hostname</p>
<p><img src="https://github.com/imsnif/bandwhich/blob/main/res/demo.gif?raw=true" alt="bandwhich demo"></p>
<hr>

<p>Perform binary analysis in your terminal.</p>
<p><img src="https://github.com/orhun/binsider/blob/main/website/src/content/assets/quickstart.gif?raw=true" alt="binsider demo"></p>
<hr>

<p>A customizable cross-platform graphical process/system monitor for the terminal</p>
<p><img src="https://github.com/ClementTsang/bottom/blob/main/assets/demo.gif?raw=true" alt="bottom demo"></p>
<hr>

<p>Play crossword puzzles in your terminal.</p>
<p><img src="https://github.com/user-attachments/assets/8a2bb53b-f461-4ddd-b60c-9ae5170b501d" alt="crossword demo"></p>
<hr>

<p><code dir="auto">csvlens</code> is A command line CSV file viewer. It is like less but made for CSV.</p>
<!-- This is in the public folder not the app folder as it causes astro to crash during processing
See https://github.com/withastro/astro/issues/8886 -->
<p><img src="https://ratatui.rs/csvlens.gif" alt="csvlens demo"></p>
<hr>

<p><code dir="auto">dua</code> is a disk space analysis tool designed for speed, leveraging parallel processing to quickly
provide detailed disk usage information and allowing for faster deletion of unnecessary data
compared to the standard ‚Äòrm‚Äô command.</p>
<p><a href="https://asciinema.org/a/kDnXUOeqBxZVMoWuFNqzfpeey" target="_blank" rel="noopener noreferrer"><img src="https://asciinema.org/a/kDnXUOeqBxZVMoWuFNqzfpeey.svg" alt="dua demo"></a></p>
<hr>

<p>A command line tool that executes make target using fuzzy finder with preview window</p>
<p><img src="https://raw.githubusercontent.com/kyu08/fzf-make/main/static/demo.gif" alt="fzf-make demo"></p>
<hr>

<p>TUI for git written in rust</p>
<p><img src="https://github.com/extrawurst/gitui/blob/master/demo.gif?raw=true" alt="gitui demo"></p>
<hr>

<p>gpg-tui is a Terminal User Interface for GnuPG.</p>
<p><img src="https://github.com/orhun/gpg-tui/blob/master/demo/gpg-tui-scrolling_rows.gif?raw=true" alt="gpg-tui demo"></p>
<hr>

<p>Ranger-like terminal file manager written in Rust</p>
<p><img src="https://github.com/kamiyaa/joshuto/raw/main/screenshot.png?raw=true" alt="joshuto demo"></p>
<hr>

<p>A material design color palette for the terminal.</p>
<p><img src="https://i.ibb.co/2MDKmh7/Screenshot-2022-08-02-at-16-43-12.png" alt="material demo"></p>
<hr>

<p>A mine sweeping game written in Rust</p>
<p><img src="https://github.com/cpcloud/minesweep-rs/blob/main/demo.gif?raw=true" alt="minesweep-rs demo"></p>
<hr>

<p>Oatmeal is a terminal UI chat application that speaks with LLMs, complete with slash commands and
fancy chat bubbles. It features agnostic backends to allow switching between the powerhouse of
ChatGPT, or keeping things private with Ollama. While Oatmeal works great as a stand alone terminal
application, it works even better paired with an editor like Neovim!</p>
<p><img src="https://github.com/dustinblackman/oatmeal/assets/5246169/9ee5e910-4eff-4deb-8065-aeab8bfe6b00" alt="oatmeal-demo"></p>
<hr>

<p>oha is a tiny program that sends some load to a web application and show realtime tui</p>
<p><img src="https://github.com/hatoo/oha/blob/master/demo.gif?raw=true" alt="oha demo"></p>
<hr>

<p>A simple TUI to view &amp; control docker containers</p>
<p><img src="https://raw.githubusercontent.com/mrjackwills/oxker/main/.github/demo_01.webp?raw=true" alt="oxker demo"></p>
<hr>

<p>Unlock the power of APIs with simplicity and speed, right from your terminal. View OpenAPI
documentations in your terminal.</p>
<p><img src="https://github.com/zaghaghi/openapi-tui/blob/main/static/demo.gif?raw=true" alt="openapi-tui demo"></p>
<hr>

<p>A lightweight and terminal-based tool for interacting with databases.</p>
<p><img src="https://github.com/achristmascarl/rainfrog/raw/main/vhs/demo.gif?raw=true" alt="rainfrog demo"></p>
<hr>

<p>An application to manage markdown notes from your terminal and compile them to HTML</p>
<p><img src="https://github.com/Linus-Mussmaecher/rucola/blob/main/readme-images/readme-image-select.png?raw=true" alt="rucola demo"></p>
<hr>

<p>A simple oscilloscope/vectorscope/spectroscope for your terminal</p>
<p><img src="https://camo.githubusercontent.com/4b11674184b07eebd6bc386c38c9cce1a7a70ae82733b44cd977c8ab85c5a691/68747470733a2f2f63646e2e616c656d692e6465762f73636f70652d7475692d776964652e706e67" alt="scope-tui demo"></p>
<hr>

<p>Terminal HTTP/REST client</p>
<p><img src="https://media.githubusercontent.com/media/LucasPickering/slumber/master/docs/src/images/demo.gif" alt="slumber demo"></p>
<hr>

<p>A CLI-based AI coding agent for local dev, scripts/CI, and automation.</p>
<p><img src="https://raw.githubusercontent.com/brendangraham14/steer/main/.github/images/demo.gif" alt="steer demo"></p>
<hr>

<p>A terminal user interface for taskwarrior</p>
<p><img src="https://user-images.githubusercontent.com/1813121/159858280-3ca31e9a-fc38-4547-a92d-36a7758cf5dc.gif" alt="taskwarrior-tui demo"></p>
<hr>

<p>Television is a fast and versatile fuzzy finder TUI.</p>
<p>It lets you quickly search through any kind of data source (files, git repositories, environment
variables, docker images, you name it) using a fuzzy matching algorithm and is designed to be easily
extensible.</p>
<p><img src="https://github.com/user-attachments/assets/7a967f9c-779e-4915-baa8-160f586f8936" alt="television demo"></p>
<hr>

<p>A network diagnostic tool that combines the functionality of traceroute and ping and is designed to
assist with the analysis of networking issues.</p>
<p><img src="https://raw.githubusercontent.com/fujiapple852/trippy/master/assets/0.12.0/demo.gif?raw=true" alt="trippy demo"></p>
<hr>

<p>A hackable, minimal, fast TUI file explorer</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/QJaEMeVo9Uw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<hr>

<p>Blazing fast terminal file manager written in Rust, based on async I/O</p>
<p><a href="https://yazi-rs.github.io/features" target="_blank" rel="noopener noreferrer">Features</a></p>
<video controls="">
  <source src="https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7" type="video/mp4">
  Your browser does not support the video tag.
</video>
<hr>

<p>Y≈çzefu is an interactive TUI application for exploring data of a Kafka cluster.</p>
<p>It is an alternative tool to AKHQ, Redpanda Console, or the Kafka plugin for JetBrains IDEs. It
includes a search query language inspired by SQL, providing fine-grained filtering capabilities.</p>
<p><img src="https://vhs.charm.sh/vhs-UpIJD2h92vKkj01XSS0r0.gif" alt="yozefu demo"></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FAA to cut flights by 10% at 40 major airports due to government shutdown (142 pts)]]></title>
            <link>https://www.cnbc.com/2025/11/05/faa-cuts-flight-capacity-shutdown.html</link>
            <guid>45830797</guid>
            <pubDate>Thu, 06 Nov 2025 02:44:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/11/05/faa-cuts-flight-capacity-shutdown.html">https://www.cnbc.com/2025/11/05/faa-cuts-flight-capacity-shutdown.html</a>, See on <a href="https://news.ycombinator.com/item?id=45830797">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-108222102" data-test="InlineImage"><p>U.S. Transportation Secretary Sean P. Duffy and FAA Administrator Bryan Bedford hold a press conference at the U.S. Department of Transportation Headquarters on Nov. 5, 2025 in Washington, DC. </p><p>Tasos Katopodis | Getty Images</p></div><div><p>Transportation Secretary Sean Duffy announced Wednesday afternoon that he will be reducing flight capacity by 10% at 40 major airports starting on Friday morning, affecting roughly 3,500 to 4,000 flights daily.</p><p>It was not immediately clear which airports would be affected.</p><p>"This is proactive," Duffy said in a news conference.</p><p>Federal Aviation Administration Administrator Bryan Bedford said additional measures could be taken after the initial reduction.</p><p>"As we slice the data more granularly, we are seeing pressures build in a way that we don't feel, if we allow it to go unchecked, will allow us to continue to tell the public that we operate the safest airline system in the world," Bedford said on Wednesday.</p><p>Bedford added that the administration will be meeting with the airline community to decide how to move forward on implementing the reduction, which he said has never happened before during his time in the industry.</p><p>The government shutdown, which entered its 36th full day on Wednesday, is now the longest in U.S. history.</p><p>Duffy said he expects more cancellations as a result of the reduction, which has no set end time. "We thought 10% was the right number based on the pressure we were seeing," Duffy added.</p><p>The move comes as air traffic controllers have <a href="https://www.cnbc.com/2025/10/28/government-shutdown-air-traffic-controllers.html">missed their paychecks</a> due to the government shutdown. Air traffic controllers and Transportation Security Administration screeners are among the essential government employees who are required to work during the shutdown.</p><p>The closure has also raised concerns about already thin staffing among&nbsp;<a href="https://www.cnbc.com/2025/10/10/government-shutdown-airlines-passengers-delays.html">air traffic controllers</a>, the FAA said. Insufficient staffing at some FAA facilities has disrupted some flights since Oct. 1.</p><p>Earlier this week, Duffy told CNBC's "<a href="https://www.cnbc.com/squawk-box-us/">Squawk Box</a>" that he could "shut the whole airspace down" if the shutdown drags on.</p><p>On Wednesday morning, National Air Traffic Controllers Association President Nick Daniels <a href="https://www.cnbc.com/2025/11/05/air-traffic-controllers-government-shutdown.html">told CNBC</a>'s "<a href="https://www.cnbc.com/squawk-box-us/">Squawk Box</a>" that it could take "weeks to recover" from the impacts of the government shutdown on air traffic controllers.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Longtime Mozilla Support Japanese Community Shuts Down over AI Translation Usage (878 pts)]]></title>
            <link>https://support.mozilla.org/en-US/forums/contributors/717446</link>
            <guid>45830770</guid>
            <pubDate>Thu, 06 Nov 2025 02:38:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.mozilla.org/en-US/forums/contributors/717446">https://support.mozilla.org/en-US/forums/contributors/717446</a>, See on <a href="https://news.ycombinator.com/item?id=45830770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
      
      
      <main role="main">
      
      
  <article id="posts">
    <p id="forum-title">SUMO community discussions</p>
    

    
    

    
      <ol>
        
          <li id="post-89603">
            




<div>
  <div>
    <p>Hi, I am a locale leader of SUMO Japanese community. I have contributed to the Support over 20 years, before the beginning of <a href="http://support.mozilla.org/" rel="nofollow">support.mozilla.org</a>.
</p><p>Today, November 4, we decided to end our SUMO Japanese community.
</p><p>In October 22, the sumobot was introduced to Japanese KB articles. I cannot accept its behavior and no words.
</p>
<ul><li> It doesn't follow our translation guidelines.
</li><li> It doesn't respect current localization for Japanese users, so they were lost.
</li><li> It approves its direct English MT immediately for All archived KB articles.
</li><li> It approves only in 72 hours after its updates, so we lost our work to train new contributors.
</li><li> It has been working now without our acceptance, without controls, without communications.
</li><li> Over 300 Knowledge Base articles are overridden by sumobot.
</li></ul>
<p>They are all happened on the product server, not on staging server. I understand that this is mass destruction of our work and explicit violation to the Mozilla mission, allowed officially.
</p><p>Therefore, I (marsf) declare:
</p>
<ul><li> I quit to contribute to <a href="http://support.mozilla.org/" rel="nofollow">support.mozilla.org</a>.
</li><li> I prohibit to use all my translation as learning data for SUMO bot and AIs.
</li><li> I request to remove all my translation from learned data of SUMO AIs.
</li></ul>
<p>However, individual Japanese contributors may want to work in their responsibility. It is their choice, we don't care nor support.
</p><p>Bye.
</p>
  </div>
  <p>Hi, I am a locale leader of SUMO Japanese community. I have contributed to the Support over 20 years, before the beginning of support.mozilla.org.

Today, November 4, we decided to end our SUMO Japanese community.

In October 22, the sumobot was introduced to Japanese KB articles. I cannot accept its behavior and no words.
* It doesn't follow our translation guidelines.
* It doesn't respect current localization for Japanese users, so they were lost.
* It approves its direct English MT immediately for All archived KB articles.
* It approves only in 72 hours after its updates, so we lost our work to train new contributors.
* It has been working now without our acceptance, without controls, without communications.
* Over 300 Knowledge Base articles are overridden by sumobot.

They are all happened on the product server, not on staging server. I understand that this is mass destruction of our work and explicit violation to the Mozilla mission, allowed officially.

Therefore, I (marsf) declare:
* I quit to contribute to support.mozilla.org.
* I prohibit to use all my translation as learning data for SUMO bot and AIs.
* I request to remove all my translation from learned data of SUMO AIs.

However, individual Japanese contributors may want to work in their responsibility. It is their choice, we don't care nor support.

Bye.</p>
  
</div>
          </li>
        
          <li id="post-89606">
            




<div>
  <p>"Gokurosama deshita" („ÅîËã¶Âä¥Êßò„Åß„Åó„Åü)
</p>
  <p>"Gokurosama deshita" („ÅîËã¶Âä¥Êßò„Åß„Åó„Åü)</p>
  
</div>
          </li>
        
          <li id="post-89607">
            




<div>
  <div>
    <p>Hi Marsf, 
</p><p>I'm sorry for how you and the Japanese community feel about the MT workflow that we just recently introduced. Would you be interested to hop on a call with us to talk about this further? We want to make sure we trully understand what you're struggling with. 
</p><p>My timezone is UTC+7, so it should be easier for us to set up time. Let me know how that sound!
</p>
  </div>
  <p>Hi Marsf, 

I'm sorry for how you and the Japanese community feel about the MT workflow that we just recently introduced. Would you be interested to hop on a call with us to talk about this further? We want to make sure we trully understand what you're struggling with. 

My timezone is UTC+7, so it should be easier for us to set up time. Let me know how that sound!</p>
  
</div>
          </li>
        
          <li id="post-89608">
            




<div>
  <div>
    <p>Hi marsf, I'm so sorry to read your message. Even though we haven't seen each other for a while, I still have fond memories of you (we last met at All Hands in Orlando... in 2018). 
I completely understand your frustration after the introduction of SumoBot. We Italians, along with the Spanish, were the first to experiment with automatic translation/updates via SumoBot (<a href="https://support.mozilla.org/en-US/forums/contributors/717387?last=89505" rel="nofollow">https://support.mozilla.org/en-US/forums/contributors/717387?last=89505</a>), and I've already expressed some concerns. I hope that, after talking with Kiki and the staff, you'll change your mind about ceasing your localization contributions.
</p>
<p><em>marsf <a href="#post-89603" rel="nofollow">said</a></em></p><blockquote>‚Ä¢ It doesn't follow our translation guidelines.</blockquote><p>
Fortunately, for the Italian localization, our guidelines are being respected.</p><blockquote>‚Ä¢ It approves its direct English MT immediately for All archived KB articles.
‚Ä¢ It approves only in 72 hours after its updates, so we lost our work to train new contributors.
‚Ä¢ It has been working now without our acceptance, without controls, without communications.</blockquote>
<p>These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).
</p><p>I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.
</p><p>Hugs,
Michele
</p>
  </div>
  <p>Hi marsf, I'm so sorry to read your message. Even though we haven't seen each other for a while, I still have fond memories of you (we last met at All Hands in Orlando... in 2018). 
I completely understand your frustration after the introduction of SumoBot. We Italians, along with the Spanish, were the first to experiment with automatic translation/updates via SumoBot (https://support.mozilla.org/en-US/forums/contributors/717387?last=89505), and I've already expressed some concerns. I hope that, after talking with Kiki and the staff, you'll change your mind about ceasing your localization contributions.

''marsf [[#post-89603|said]]''&lt;blockquote&gt;‚Ä¢ It doesn't follow our translation guidelines.&lt;/blockquote&gt;
Fortunately, for the Italian localization, our guidelines are being respected.&lt;blockquote&gt;‚Ä¢ It approves its direct English MT immediately for All archived KB articles.
‚Ä¢ It approves only in 72 hours after its updates, so we lost our work to train new contributors.
‚Ä¢ It has been working now without our acceptance, without controls, without communications.&lt;/blockquote&gt;
These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).

I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.

Hugs,
Michele</p>
  
</div>
          </li>
        
          <li id="post-89609">
            




<div>
  <div>
    <p><em>Michele Rodaro <a href="#post-89608" rel="nofollow">said</a></em>
</p>
<blockquote>
Fortunately, for the Italian localization, our guidelines are being respected.
</blockquote>
<p>I wonder if what Marsf referring to was related to the <a href="https://github.com/mozilla/sumo/issues/2605" rel="nofollow">the bug</a> that we recently reported. I have a feeling the bug may have caused the impression that the MT doesn't respect prior translation and guidelines even though it's actually a bug. 
</p>
<blockquote>
These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).</blockquote>
<p>Michele, you and I talked about the struggle of getting new contributors on board. We've been experimenting with training for the Forum Moderators and we've been getting great feedback from the participants so far. Do you think a training or video tutorials would help with this? 
</p>
<blockquote>
I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.
</blockquote><p>Can you tell me more about SUMObot intrusiveness that you've experienced?
  </p></div>
  <p>''Michele Rodaro [[#post-89608|said]]''
&lt;blockquote&gt;
Fortunately, for the Italian localization, our guidelines are being respected.
&lt;/blockquote&gt;
I wonder if what Marsf referring to was related to the [https://github.com/mozilla/sumo/issues/2605 the bug] that we recently reported. I have a feeling the bug may have caused the impression that the MT doesn't respect prior translation and guidelines even though it's actually a bug. 

&lt;blockquote&gt;
These are also in my opinion the sore points, especially the fact that SumoBot updates or translates (when there's a new article) immediately, which hinders the training of new contributors because they end up doing "proofreading" since SumoBot immediately takes over...
For me, as a locale leader, it's not easy to help a new contributor understand how the localization process works, the syntax of the Sumo wiki, if they have to view a "diff" that SumoBot has already automatically proposed (Often retranslating parts of the article that aren't subject to changes...).&lt;/blockquote&gt;
Michele, you and I talked about the struggle of getting new contributors on board. We've been experimenting with training for the Forum Moderators and we've been getting great feedback from the participants so far. Do you think a training or video tutorials would help with this? 

&lt;blockquote&gt;
I believe the various locales should be able to decide whether or not to use machine translations, especially if we want to involve new contributors. In the last few months, I've trained two new contributors, but since the introduction of machine translation and on-the-fly translation, they've lost interest, and I spend my time alone (As always) fixing SumoBot's intrusiveness.
&lt;/blockquote&gt;Can you tell me more about SUMObot intrusiveness that you've experienced?</p>
  
</div>
          </li>
        
      </ol>

      

    

    
    
  </article>

      </main>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI asks U.S. for loan guarantees to fund $1T AI expansion (177 pts)]]></title>
            <link>https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/</link>
            <guid>45830380</guid>
            <pubDate>Thu, 06 Nov 2025 01:32:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/">https://investinglive.com/stock-market-update/icymi-openai-asks-us-for-loan-guarantees-to-fund-1-trillion-ai-expansion-20251105/</a>, See on <a href="https://news.ycombinator.com/item?id=45830380">Hacker News</a></p>
<div id="readability-page-1" class="page"><article data-ref="article-body" data-v-4026719d="" data-v-b25c96a6=""><p data-start="0" data-end="497" data-v-4026719d="">OpenAI is seeking U.S. government support to help finance what could become one of the largest infrastructure buildouts in corporate history ‚Äî exceeding $1 trillion. Speaking at a Wall Street Journal business conference, Chief Financial Officer Sarah Friar said the company is exploring federal loan guarantees to attract broader funding for its AI computing expansion, describing a potential ‚Äúecosystem of banks, private equity, maybe even governmental‚Äù participants.</p><p data-start="499" data-end="898" data-v-4026719d="">Friar said government backing would significantly lower borrowing costs and broaden OpenAI‚Äôs access to credit markets, since federal guarantees would protect lenders from losses if the company defaulted. The proposal is highly unusual for a Silicon Valley technology firm, effectively positioning OpenAI alongside sectors such as energy and infrastructure that traditionally rely on state support.</p><p data-start="900" data-end="1250" data-v-4026719d="">The company‚Äôs request comes amid a wave of capital-intensive commitments, including a $300 billion deal with Oracle and a $500 billion ‚ÄúStargate‚Äù data center venture with Oracle and SoftBank. Despite projecting revenues in the tens of billions this year, OpenAI‚Äôs income remains far below the enormous outlays required to sustain its AI operations.</p><p data-start="1252" data-end="1518" data-v-4026719d="">Friar dismissed speculation that OpenAI might soon go public, saying an IPO ‚Äúis not on the cards right now.‚Äù Instead, she emphasized that the company‚Äôs focus remains on scaling its capabilities and securing the financing needed to underpin its long-term ambitions.</p></article></div>]]></description>
        </item>
    </channel>
</rss>