<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 19 Sep 2024 01:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Cloudflare misidentifies Hetzner IPs as being located in Iran (166 pts)]]></title>
            <link>https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726</link>
            <guid>41585249</guid>
            <pubDate>Wed, 18 Sep 2024 20:46:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726">https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726</a>, See on <a href="https://news.ycombinator.com/item?id=41585249">Hacker News</a></p>
Couldn't get https://gitlab.com/gitlab-com/gl-infra/production/-/issues/8121#note_1237201726: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Comic Mono (155 pts)]]></title>
            <link>https://dtinth.github.io/comic-mono-font/</link>
            <guid>41585156</guid>
            <pubDate>Wed, 18 Sep 2024 20:36:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dtinth.github.io/comic-mono-font/">https://dtinth.github.io/comic-mono-font/</a>, See on <a href="https://news.ycombinator.com/item?id=41585156">Hacker News</a></p>
Couldn't get https://dtinth.github.io/comic-mono-font/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[LinkedIn is now using everyone's content to train their AI tool (195 pts)]]></title>
            <link>https://twitter.com/RachelTobac/status/1836471586624540705</link>
            <guid>41584486</guid>
            <pubDate>Wed, 18 Sep 2024 19:37:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/RachelTobac/status/1836471586624540705">https://twitter.com/RachelTobac/status/1836471586624540705</a>, See on <a href="https://news.ycombinator.com/item?id=41584486">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Is Tor still safe to use? (364 pts)]]></title>
            <link>https://blog.torproject.org/tor-is-still-safe/</link>
            <guid>41583847</guid>
            <pubDate>Wed, 18 Sep 2024 18:41:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.torproject.org/tor-is-still-safe/">https://blog.torproject.org/tor-is-still-safe/</a>, See on <a href="https://news.ycombinator.com/item?id=41583847">Hacker News</a></p>
Couldn't get https://blog.torproject.org/tor-is-still-safe/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Threatening to Ban Users for Asking Strawberry About Its Reasoning (258 pts)]]></title>
            <link>https://futurism.com/the-byte/openai-ban-strawberry-reasoning</link>
            <guid>41583605</guid>
            <pubDate>Wed, 18 Sep 2024 18:22:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/the-byte/openai-ban-strawberry-reasoning">https://futurism.com/the-byte/openai-ban-strawberry-reasoning</a>, See on <a href="https://news.ycombinator.com/item?id=41583605">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="incArticle"><h2>"Additional violations of this policy may result in loss of access to GPT-4o with Reasoning."</h2><h2>Ban Hammer</h2><p>OpenAI claims that its latest AI model, code-named "Strawberry"&nbsp;and released as o1-preview,&nbsp;is supposed to be capable of "reasoning." But understanding how its <a href="https://futurism.com/openai-strawberry-thought-process-scheming">thought process</a> works, apparently, is something that the ChatGPT maker is serious about keeping off-limits.</p><p>As <a href="https://arstechnica.com/information-technology/2024/09/openai-threatens-bans-for-probing-new-ai-models-reasoning-process/"><i>Ars Technica </i>reports</a>, OpenAI is now threatening to ban users that try to get the large language model to reveal how it thinks — a glaring example of how the company has long since <a href="https://futurism.com/openai-sleazy-company-creating-agi">abandoned its original vision</a> of championing open source AI.</p><p>According to accounts on social media, users are <a href="https://x.com/MarcoFigueroa/status/1834741170024726628">receiving emails</a> from the Microsoft-backed startup informing them that their requests made to <a href="https://futurism.com/the-byte/chatgpt-voice-mode-scream">ChatGPT</a> have been flagged for "attempting to circumvent safeguards."</p><p>"Additional violations of this policy may result in loss of access to GPT-4o with Reasoning," the emails state.</p><h2>Hush Hush</h2><p>This clampdown is more than a bit ironic given that a lot of the hype around Strawberry was built around its "chain-of-thought" reasoning that allowed the AI to articulate how it arrived at an answer, step by step. OpenAI chief technology officer Mira Murati <a href="https://www.wired.com/story/openai-o1-strawberry-problem-reasoning/">called this</a> a "new paradigm" for the technology.</p><p>Reports vary on what triggers the violations. As <i>Ars </i>found, some users claim that using the term "<a href="https://x.com/voooooogel/status/1834536216160768377">reasoning trace</a>" is what got them in trouble. Others say that even using the word "<a href="https://x.com/dyushag/status/1834379249731444820">reasoning</a>" on its own was enough to alert OpenAI's systems. Users can still see what is essentially a summary of Strawberry's thought process, but it's cobbled together by a second AI model and is heavily watered-down.</p><p>In a <a href="https://openai.com/index/learning-to-reason-with-llms/#hiding-the-chains-of-thought">blog post</a>, OpenAI argues that it needs to hide the chain-of-thought so that it wouldn't need to put a filter on how its AI thinks, in case it says stuff that isn't compliant with safety policies while thinking out loud. That way, developers can safely see its "raw" thought process behind-the-scenes.</p><p>But as the company freely admits, this measure also helps it maintain a "competitive advantage," staving off competitors from trying to ride its coattails.</p><h2>Red Alert</h2><p>The flipside of this approach, however, is that concentrates more responsibility for aligning the language language model into the hands of OpenAI, instead of democratizing it. That poses a problem for red-teamers, or programmers that try to hack AI models to make them safer.</p><p>"I'm not at all happy about this policy decision," AI researcher Simon Willison <a href="https://simonwillison.net/2024/Sep/12/openai-o1/">wrote on his blog</a>, as quoted by <i>Ars</i>. "As someone who develops against LLMs, interpretability and transparency are everything to me — the idea that I can run a complex prompt and have key details of how that prompt was evaluated hidden from me feels like a big step backwards."</p><p>As it stands, it seems that OpenAI is continuing down a path of keeping its AI models an ever more opaque black box.</p><p><strong>More on OpenAI: </strong><em><a href="https://futurism.com/openai-strawberry-thought-process-scheming">OpenAI's Strawberry "Thought Process" Sometimes Shows It Scheming to Trick Users</a></em></p><br></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Qwen2.5: A Party of Foundation Models (117 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwen2.5/</link>
            <guid>41583062</guid>
            <pubDate>Wed, 18 Sep 2024 17:42:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwen2.5/">https://qwenlm.github.io/blog/qwen2.5/</a>, See on <a href="https://news.ycombinator.com/item?id=41583062">Hacker News</a></p>
Couldn't get https://qwenlm.github.io/blog/qwen2.5/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Meta AI: "The Future of AI Is Open Source and Decentralized" (175 pts)]]></title>
            <link>https://twitter.com/AIatMeta/status/1834633042339741961</link>
            <guid>41583028</guid>
            <pubDate>Wed, 18 Sep 2024 17:40:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/AIatMeta/status/1834633042339741961">https://twitter.com/AIatMeta/status/1834633042339741961</a>, See on <a href="https://news.ycombinator.com/item?id=41583028">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Microplastics in the olfactory bulb of the human brain (125 pts)]]></title>
            <link>https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823787</link>
            <guid>41582461</guid>
            <pubDate>Wed, 18 Sep 2024 17:01:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823787">https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2823787</a>, See on <a href="https://news.ycombinator.com/item?id=41582461">Hacker News</a></p>
<div id="readability-page-1" class="page"><div method="post" action="./2823787" id="webform">
        



<div id="resources-panel">
    <div>
        <div><p>Figure 1. &nbsp;Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Microplastics Found in the Olfactory Bulb Tissue</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151f1_1726069938.11827.png?Expires=1729710081&amp;Signature=QCuZnQ0k9y6BI-vcK4S099vHrkPKK4pNUEsOkOsS65cBAeo05eBph4tOdEQWVAUraoGI2EP6UqCIxmcqCA~h7vYbBWy8gCSqdr15P5iTPjy1J9Bgl6VhZ3mJnioKcwKBrfFlgQPM58iQq-lZS9NgItxr7DXhpmhEhxyzy2asDith6RX~VrbrdocFuJVNZ0ZEV-8Ct0WSrVHGWHr-EaiStzMptqZ4QYltsG1GkA95z4F2yJ~yPjiYmCvBJfSVusDrLEL8QsfChpiE6~Rda~oY-FbURmesRw~7MWQMCR~F7J2gMwaa9HwbmlYIx1~U31CHCTpGaYnmLoq9lVu41vZtSA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151f1" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f1_1726069938.11827.png?Expires=1729710081&amp;Signature=QZvbXinwft9Y2sMFvQiC9Lkixf4zMOxAaQQ0wd5LIcRNtKjJjDx~E8sBpd6qer7EJT4aNwA2mgDCIidoxDK3YbmtXuJ25rYzG5bPvW7uMj5uKsGqzUIrNRhD49o1lfpG8lM-MnjEvG9yxEqHiJRDx1Sjlv6-JbgJu01pYti9o-JDWjO0i6jkLascPAUwf-Kc5fu8K-JZTZKVepdbgk1yzisI3dK0aI7K40zLmwJBKVlfjpF7qo8ErhLA6E6T7D03od8~gg7disv4BNucuRXg~SdagBPZh-mZepDgkxiJ09MBkyDBEkkmnZBZ4LncYfxCv5VsNNkPC45QmjqYs4PkXw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Microplastics Found in the Olfactory Bulb Tissue" path-from-xml="zoi241151f1" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f1_1726069938.11827.png?Expires=1729710081&amp;Signature=QZvbXinwft9Y2sMFvQiC9Lkixf4zMOxAaQQ0wd5LIcRNtKjJjDx~E8sBpd6qer7EJT4aNwA2mgDCIidoxDK3YbmtXuJ25rYzG5bPvW7uMj5uKsGqzUIrNRhD49o1lfpG8lM-MnjEvG9yxEqHiJRDx1Sjlv6-JbgJu01pYti9o-JDWjO0i6jkLascPAUwf-Kc5fu8K-JZTZKVepdbgk1yzisI3dK0aI7K40zLmwJBKVlfjpF7qo8ErhLA6E6T7D03od8~gg7disv4BNucuRXg~SdagBPZh-mZepDgkxiJ09MBkyDBEkkmnZBZ4LncYfxCv5VsNNkPC45QmjqYs4PkXw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div><p>HQI indicates hit quality index.</p></div><div><p>Figure 2. &nbsp;Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Main Microplastics Found in the Digested Olfactory Bulb</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151f2_1726069938.48024.png?Expires=1729710081&amp;Signature=4jtSPcsf57GMusDVBWIot6dubyudipWcrlSqWr-wcX59HXDBPdTG3kFfjWw6XI6m-2Hr0xNEilkeAVn1MKgdOFJ1hEOUBoqtF62L~vWU5BwemM2NVSZByMCYuCJe1o56bbshzwVBWeEeki5CF0Ee0CDFWUnQ9wEmEzIVLJV8GJjIAaUNNEVWnACMtmFaZ3DoOb0TNgLAVeZE3Uy1CB9EiEBPoE1If6pGKg~PTLeMomXFik460Wg7-0JlkuAPpxCuOGzPeoQgvJfyNJE3sZXzoRTgkrI-VDWgISkC6OJEhM4K-Smk5m0aUXKm05glloNp7hVw1TgMNbK6C6HjgALbcQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151f2" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f2_1726069938.48024.png?Expires=1729710081&amp;Signature=LHtSGOVNsRZvzMl-hDFIF7vI~ftl6HMIIM2VU069icuwXQIGJDXFBwUp-qdsH75nAL0hxq7Zm4hbhjRF1~UGs~C2xxRfQocJXnA8QcHnljlUB6igCQStNKyC9axm3tiWMggpIHPd1YB6y3V93AMSs6bhoz4t1YTcEeVY0yQDSZ5UMHbV-VdQhMc5nhWo57NY~wSTnALuZEXDN2nxi2m1O8kAnW3Z0D18JRxeSr2ZBm-bxqpt54ir8764VUPFdyx7OhpDLSCnATK2-E3CfoEEN2dYKjarzZFz~oVLm7nYX-gTPJEwfM7KCl8EV0TKsSFegbDsnUNvhS-5SmCXXbcxsw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Microphotographs and Micro-Fourier Transform Infrared (μFTIR) Spectra of the Main Microplastics Found in the Digested Olfactory Bulb" path-from-xml="zoi241151f2" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151f2_1726069938.48024.png?Expires=1729710081&amp;Signature=LHtSGOVNsRZvzMl-hDFIF7vI~ftl6HMIIM2VU069icuwXQIGJDXFBwUp-qdsH75nAL0hxq7Zm4hbhjRF1~UGs~C2xxRfQocJXnA8QcHnljlUB6igCQStNKyC9axm3tiWMggpIHPd1YB6y3V93AMSs6bhoz4t1YTcEeVY0yQDSZ5UMHbV-VdQhMc5nhWo57NY~wSTnALuZEXDN2nxi2m1O8kAnW3Z0D18JRxeSr2ZBm-bxqpt54ir8764VUPFdyx7OhpDLSCnATK2-E3CfoEEN2dYKjarzZFz~oVLm7nYX-gTPJEwfM7KCl8EV0TKsSFegbDsnUNvhS-5SmCXXbcxsw__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div><p>HQI indicates hit quality index.</p></div> 
    </div>
    <div>
        <div><p>Table 1. &nbsp;Demographic and Autopsy Findings of the Decedents</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151t1_1726069938.06827.png?Expires=1729710081&amp;Signature=FHp9vawpZ5oKM~IWkyTX6QLbfo6wjn9VjURr8YG4Zagr-15-owTvEAd-QKhLVv-WXh99qEBG8scsh4nrm7UJqnPgbQsuAAshzWHTdj3FJNLbQF3uIKn-KoX23BmbZy~6PlRGDOqjw0Xdb1jdtXGX3eqMrfaIn5k95OvrRLJfbpRjo~4R5xt1UsR5r2fyT9tkxXZ1oa8WBxd4YGqGRmYM4knfRGJsURGnWMcro~snn7rWgMWDdwkV9FvGeYggQkq4p6c9FRp4KC3DR6ZYi3wLPyt0MyVt-TftEqggP9wO95MbolwDZaqnUFkST6bFsNwPIaAGXSp4Y3xoFyGG~H1njQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151t1" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t1_1726069938.06827.png?Expires=1729710081&amp;Signature=qig~Pe2PXqkY6CAk0dlEUNilWvPs4BUm9-gyYlEZrDfnrlaAfm1Cdr7mpr-8bEd-80PxeRz2Hky9cF7Cqfa7tqmdrC4PHeRjqLASbi2WKbeH8yAPp-Hx6ncm6Ohj24rS8aqcn6mcxI~jdu27tmpbCe3srRBFhZsN9Qm93icYDCAh6GVdws-S5eQWyjwsph6SBFTOtmVvG6PB2JPiXKW-Kr4Nd~ZE3Or7tqPTVlaAhc8T-O0EaQVmKhu1shn899dScqgMhuHixVPhPRdekeaEIC~62CeGDQTcrbKNGuTAFf0shBMIiu94GiEZJ3B5TDAs2RHOcGmCsbTcFMUzoTeDnQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Demographic and Autopsy Findings of the Decedents" path-from-xml="zoi241151t1" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t1_1726069938.06827.png?Expires=1729710081&amp;Signature=qig~Pe2PXqkY6CAk0dlEUNilWvPs4BUm9-gyYlEZrDfnrlaAfm1Cdr7mpr-8bEd-80PxeRz2Hky9cF7Cqfa7tqmdrC4PHeRjqLASbi2WKbeH8yAPp-Hx6ncm6Ohj24rS8aqcn6mcxI~jdu27tmpbCe3srRBFhZsN9Qm93icYDCAh6GVdws-S5eQWyjwsph6SBFTOtmVvG6PB2JPiXKW-Kr4Nd~ZE3Or7tqPTVlaAhc8T-O0EaQVmKhu1shn899dScqgMhuHixVPhPRdekeaEIC~62CeGDQTcrbKNGuTAFf0shBMIiu94GiEZJ3B5TDAs2RHOcGmCsbTcFMUzoTeDnQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div></div><div><p>Table 2. &nbsp;Morphology and Polymeric Matrix of the Identified Particles and Fibers</p><div><p><a href="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/zoi241151t2_1726069938.56028.png?Expires=1729710081&amp;Signature=RxrLiyGB2eqeqzzbg5WtUVhvMGG-j5tqCmd2zzsibxPHX9IFi5YWBZFKUg6qG8SgFgBdgvhnrP~EodTOvstrdEwYqPzsaPgA-6LbcbzsMP19S4qQabtxaCgnXvZxAG2tqlaGV9vAayQ83NcwmMXmW-MnJ~-hJmuUjXfn3FzwGfwnUeYAIJSEP9vNWbBQFKHIO1cFRE468nDXWkQphhGYdMBezxoWHr6-GfrHDOualn2JmNQ-SBzhar9WqTbKh4bSgcuqqwvLjMFptPX8kE0y0ngW~X579~vSMbCCfIJn6mQbocNuCJJhIkI2ZWPMPHo4d-yCnMWy5Wi3kuXkEL1SSQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" target="_blank" path-from-xml="zoi241151t2" rel="nofollow"><img data-original="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t2_1726069938.56028.png?Expires=1729710081&amp;Signature=1roKT0bzsxJYfCSxqyWZQbZ~LYnMpwA29lQafDRmKijcKqjFMmjBSHf14viy-Gc7sZB5AIZPrMwmLSqXfjzVlc4uHvIx~breOv4cJfwrx8qamvfH8CXs6TaWCAGdLNRfgp7HONMzSEcFhypfeBEkvsj8YkTfZegmHrjMBvVCBZ9Tot~vMKO7a0zZI373WkWCgsUrgbjPlMNLVgZ8VeXvD2P~pTLgiHroDQy9lP6HJBECn2Lxo99C0Y17lHCjq9-NfcoSxRDrsnTdbEvzip9pEXE8eITS3zuAdp7jSGANBoHE8vOt3bG21jW35q1U3M-OPLYL15Dwd970D8C~-3XeVA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA" alt="Morphology and Polymeric Matrix of the Identified Particles and Fibers" path-from-xml="zoi241151t2" src="https://cdn.jamanetwork.com/ama/content_public/journal/jamanetworkopen/939448/m_zoi241151t2_1726069938.56028.png?Expires=1729710081&amp;Signature=1roKT0bzsxJYfCSxqyWZQbZ~LYnMpwA29lQafDRmKijcKqjFMmjBSHf14viy-Gc7sZB5AIZPrMwmLSqXfjzVlc4uHvIx~breOv4cJfwrx8qamvfH8CXs6TaWCAGdLNRfgp7HONMzSEcFhypfeBEkvsj8YkTfZegmHrjMBvVCBZ9Tot~vMKO7a0zZI373WkWCgsUrgbjPlMNLVgZ8VeXvD2P~pTLgiHroDQy9lP6HJBECn2Lxo99C0Y17lHCjq9-NfcoSxRDrsnTdbEvzip9pEXE8eITS3zuAdp7jSGANBoHE8vOt3bG21jW35q1U3M-OPLYL15Dwd970D8C~-3XeVA__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA"></a></p></div></div> 
    </div>

        </div>

<div id="content-panel">
    
    
    



            
        

    <div>
        
    


            <div>
            <p>Original Investigation </p>
                <p>Environmental Health</p>
        </div>
        <p><span><span>September&nbsp;</span><span>16, </span><span>2024</span></span></p>
        
            
            
        <p><span>JAMA Netw Open. </span><span> 2024;7(9):e2440018. doi:10.1001/jamanetworkopen.2024.40018</span>
        </p>

 
    </div>
    
    

            <div data-userhasaccess="True">
    

            <p><a id="249905505"></a>
<span>Key Points</span></p><p><strong>Question</strong>&nbsp;
    <span>Can microplastics reach the olfactory bulb in the human brain?</span></p><p><strong>Findings</strong>&nbsp;
    <span>This case series analyzed the olfactory bulbs of 15 deceased individuals via micro-Fourier transform infrared spectroscopy and detected the presence of microplastics in the olfactory bulbs of 8 individuals. The predominant shapes were particles and fibers, with polypropylene being the most common polymer.</span></p><p><strong>Meaning</strong>&nbsp;
    <span>The presence of microplastics in the human olfactory bulb suggests the olfactory pathway as a potential entry route for microplastics into the brain, highlighting the need for further research on their neurotoxic effects and implications for human health.</span></p>            
<p><strong>Importance</strong>&nbsp;
    <span>Microplastic (MP) pollution is an emerging environmental and health concern. While MPs have been detected in various human tissues, their presence in the human brain has not been documented, raising important questions about potential neurotoxic effects and the mechanisms by which MPs might reach brain tissues.</span></p><p><strong>Objective</strong>&nbsp;
    <span>To determine the presence of MPs in the human olfactory bulb and to analyze their characteristics such as size, morphology, color, and polymeric composition.</span></p><p><strong>Design, Setting, and Participants</strong>&nbsp;
    <span>This case series study used a cross-sectional design involving the analysis of olfactory bulb tissues obtained from deceased individuals during routine coroner autopsies. The sampling procedures were conducted at São Paulo City Death Verification Service, with laboratory analysis carried out at the Brazilian Synchrotron Light Laboratory (LNLS). Participants included 15 adult individuals who had been residents of São Paulo for more than 5 years and underwent coroner autopsies. Exclusion criteria included previous neurosurgical interventions. Data analysis was performed in April 2024.</span></p><p><strong>Exposure</strong>&nbsp;
    <span>The primary exposure assessed was the presence of MPs in the olfactory bulb, analyzed through direct tissue examination and digested tissue filtration followed by micro-Fourier transform infrared spectroscopy.</span></p><p><strong>Main Outcomes and Measures</strong>&nbsp;
    <span>The main outcomes were the identification and characterization of MPs within the olfactory bulb, including their size, morphology, color, and polymeric composition.</span></p><p><strong>Results</strong>&nbsp;
    <span>The median age of the 15 deceased individuals was 69.5 years, ranging from 33 to 100 years, with 12 males and 3 females. MPs were detected in the olfactory bulbs of 8 out of 15 individuals. A total of 16 synthetic polymer particles and fibers were identified, with 75% being particles and 25% being fibers. The most common polymer detected was polypropylene (43.8%). Sizes of MPs ranged from 5.5 μm to 26.4 μm for particles, and the mean fiber length was 21.4 μm. Polymeric materials were absent in procedural blank and negative control filters, indicating minimal contamination risk.</span></p><p><strong>Conclusions and Relevance</strong>&nbsp;
    <span>This case series provides evidence of MPs found in the human olfactory bulb, suggesting a potential pathway for the translocation of MPs to the brain. The findings underscore the need for further research on the health implications of MP exposure, particularly concerning neurotoxicity and the potential for MPs to bypass the blood-brain barrier.</span></p>            
            
            <p>The ubiquity of microplastic (MP) pollution has become a pervasive environmental concern,<sup><a href="#zoi241151r1" data-tab-toggle=".tab-nav-references">1</a></sup> raising questions about its occurrence within the human body and its harmful effects.<sup><a href="#zoi241151r2" data-tab-toggle=".tab-nav-references">2</a></sup> While MPs have been detected in various organs of the human body, such as the lungs,<sup><a href="#zoi241151r3" data-tab-toggle=".tab-nav-references">3</a></sup><sup>,<a href="#zoi241151r4" data-tab-toggle=".tab-nav-references">4</a></sup> large and small intestines,<sup><a href="#zoi241151r5" data-tab-toggle=".tab-nav-references">5</a></sup> liver,<sup><a href="#zoi241151r6" data-tab-toggle=".tab-nav-references">6</a></sup> placenta,<sup><a href="#zoi241151r7" data-tab-toggle=".tab-nav-references">7</a></sup><sup>,<a href="#zoi241151r8" data-tab-toggle=".tab-nav-references">8</a></sup> semen,<sup><a href="#zoi241151r9" data-tab-toggle=".tab-nav-references">9</a></sup> and bloodstream,<sup><a href="#zoi241151r10" data-tab-toggle=".tab-nav-references">10</a></sup> to our knowledge, there have been no published studies to date reporting their presence in the human brain.</p>            <p>The presence of the blood-brain barrier (BBB) is likely an important limiting factor for the access of MPs to the human brain via hematogenous translocation. Despite this, some animal studies have shown that MPs can impair the BBB and reach the brain via oral ingestion, leading to neurotoxic effects.<sup><a href="#zoi241151r11" data-tab-toggle=".tab-nav-references">11</a></sup><sup>-<a href="#zoi241151r11" data-tab-toggle=".tab-nav-references">13</a></sup> Another potential entry site for micro- and nanoplastics (MNPs) in the human brain is the olfactory pathway.<sup><a href="#zoi241151r14" data-tab-toggle=".tab-nav-references">14</a></sup> This pathway involves olfactory neurons in the nasal that transmit information about odors to the central olfactory system of the brain. Olfactory axons pass through the cribriform plate (CP) of the ethmoid bone and reach the olfactory bulbs (OB), which are connected to the limbic system of the brain.</p>            <p>There are different levels of evidence suggesting that the olfactory pathway might allow the translocation of exogenous particles to the brain. Environmental black carbon particles have been detected in various human brain regions, with one of the highest concentrations found in the OB, measuring 420.8 particles/mm<sup>3</sup>.<sup><a href="#zoi241151r15" data-tab-toggle=".tab-nav-references">15</a></sup> Rarely, the 15- to 30-μm–sized ameboid form of Naegleria fowleri penetrates the brain via the nose, causing amebic meningoencephalitis.<sup><a href="#zoi241151r16" data-tab-toggle=".tab-nav-references">16</a></sup> Affected individuals typically present with the disease after contact with contaminated freshwater bodies or after rinsing the nose with nonsterile tap water.<sup><a href="#zoi241151r17" data-tab-toggle=".tab-nav-references">17</a></sup> Furthermore, the permeability of this barrier has been evoked as a possible quicker and safer drug delivery route to the brain,<sup><a href="#zoi241151r18" data-tab-toggle=".tab-nav-references">18</a></sup><sup>,<a href="#zoi241151r19" data-tab-toggle=".tab-nav-references">19</a></sup> as well as access to cerebrospinal fluid through nasal lymphatic vessels.<sup><a href="#zoi241151r20" data-tab-toggle=".tab-nav-references">20</a></sup></p>            <p>In this study, given the ubiquitous presence of MPs in the air<sup><a href="#zoi241151r21" data-tab-toggle=".tab-nav-references">21</a></sup> and their previous identification in the human nasal cavity,<sup><a href="#zoi241151r22" data-tab-toggle=".tab-nav-references">22</a></sup><sup>,<a href="#zoi241151r23" data-tab-toggle=".tab-nav-references">23</a></sup> we hypothesized that the smallest-size fraction of MPs could reach the OB. Therefore, we conducted an investigation into the presence of MPs within human OB obtained from 15 deceased individuals during coroner autopsies. We identified and analyzed various characteristics of the MPs, including their size, morphology, color, and polymeric composition.</p>            
            <p>This case series study was approved by the ethical board of the São Paulo University Medical School, in compliance with the Helsinki Declaration. Written informed consent was provided by the deceased individuals’ next of kin. The study was conducted from February 2023 to May 2024 and followed the <a href="https://www.ajo.com/article/S0002-9394(10)00690-2/fulltext">Reporting Guideline for Case Series</a>.<sup><a href="#zoi241151r46" data-tab-toggle=".tab-nav-references">46</a></sup></p>            
            <p>We obtained the bilateral OBs from 15 adult individuals who underwent routine coroner autopsies at the São Paulo City Death Verification Service of University of São Paulo to determine the cause of death. All individuals had been residents of São Paulo for more than 5 years. Cases in which the deceased had previously undergone neurosurgical interventions were not selected for the study. Information regarding previous occupations and underlying diseases was obtained through questionnaires administered to the next of kin. Additionally, autopsy reports were reviewed. We also collected samples from the OB of 2 stillbirths at 7 months gestation, as a negative control for the study. The collection of OBs took place between February 2023 and February 2024.</p>            <div>

                            <p>
                                Quality Control and Quality Assurance and Evaluation of Sample Processing
                            </p>
                        </div>
            <p>We implemented a plastic-free approach to safeguard the integrity of our results. This strategy facilitated a thorough assessment of potential sources of variability and error, thereby enhancing the reliability of our collected data. All procedures, from the OB sampling to the micro-Fourier transform infrared (μFTIR) spectroscopy analysis, followed the protocols recommended by several studies.<sup><a href="#zoi241151r24" data-tab-toggle=".tab-nav-references">24</a></sup><sup>-<a href="#zoi241151r24" data-tab-toggle=".tab-nav-references">26</a></sup> Briefly, all solutions were prefiltered through a Whatman cellulose filters with a mesh size of 0.45 μm. Stainless steel materials, glassware, and samples were covered with aluminum foil (before and after processing) to avoid airborne sample contamination. Ultrapure water with a resistivity of 18.2 mΩ was obtained from a Milli-Q purification device (Millipore Corp). Glass and stainless-steel materials were washed thoroughly using the purified water 3 times and then using acetone P.A. to remove any particles or fibers that have adhered to the glass. The scientific staff responsible for handling samples wore exclusively 100% cotton laboratory coats and were required to remove any plastic or textile bracelets, rings, and watches to minimize the risk of sample contamination. Clean latex gloves were used for all procedures. The samples were processed in a clean laminar flow cabinet (ISO class 5, SKU330313, Hipperquímica, SP, Brazil). Blank filters (47 mm) were used from the OB collection to the sample filtering to assess possible airborne contamination. A clean filter was also used as a negative control. Access to the μFTIR spectroscopy and the digestion/filtration room was restricted to the operators only, to avoid air flow in the room and the suspension/resuspension of possible atmospheric contaminants.</p>            
            <p>The presence of MPs in the OB was assessed in 2 ways: directly on the tissue and a digested assessment. The cryo-cuts method preserves the spatial context of MPs within the tissue, allowing their proximity to anatomical structures such as blood vessels to be observed. This is crucial for understanding potential pathways of MPs translocation and accumulation within the OB. The digestion method ensures that MPs that are deeply embedded in the tissue are not overlooked. Postdigestion, MPs are concentrated on filters, which can then be analyzed for a more accurate quantification and identification without interference from the tissue matrix. By combining these 2 methods, the study maximized the probability of detecting and characterizing MPs within the OB.</p>            
            <p>The left OB of each case was horizontally cryo-sectioned using a Leica CM1860 UV cryostat (Leica Biosystems) at 10 μm thickness and thaw-mounted onto 5 mm × 5 mm gold/chromium-coated silicon dioxide/silicon substrates. No fixatives were used for the tissue sections. The samples were then freeze-dried for 48 hours (Freezone 6 [Labconco Corp]) and examined by optical microscopy (Eclipse LV100ND [Nikon Instruments Inc]). The freeze-drying process maintains the integrity of biological tissues by extracting water without substantially compromising their structure. Futhermore, the presence of water molecules, characterized by strong hydrogen bonding, poses a considerable challenge in FTIR measurements, as they mask specific signals indicative of chemical compositions.<sup><a href="#zoi241151r27" data-tab-toggle=".tab-nav-references">27</a></sup></p>            <p>The procedures took place in a biosafety level 2 room in the Cryogenic Preparations Laboratory (LCRIO) at the Brazilian Synchrotron Light Laboratory (LNLS), National Center for Energy and Materials Research (CNPEM).</p>            <div>

                            <p>
                                Sample Digestion and Filtering
                            </p>
                        </div>
            <p>Immediately after sampling, the right OBs from 10 selected cases were individually frozen at −20 °C in glass vials, covered with aluminum foil, and sealed with a glass lid until the digestion. For 5 patients, there was no available tissue for digestion. The tissues were then incubated for 12 hours at 40 °C using the enzyme mixture Corolase 7089 (20 UHb/mL)<sup><a href="#zoi241151r4" data-tab-toggle=".tab-nav-references">4</a></sup> inside the laminar flux hood.</p>            <p>The solution was then filtered using a glass vacuum filtration system (Sigma-Aldrich) and silver membrane filters (25 mm in diameter and 0.45 microns pore size [Millipore]). Subsequently, the filters were kept individually in closed Petri dishes inside a glass dissector until the spectroscopy analysis. Due to the material characteristics, a recovery test was not feasible.</p>            <div>

                            <p>
                                Micro-Fourier Transform Infrared Spectroscopy
                            </p>
                        </div>
            <p>We performed single-point μFTIR microspectroscopy measurements in reflection mode using a diffraction-limited IR microscope (Cary 620 [Agilent Technologies]). The IR microscope is coupled to a Michelson interferometer responsible for the frequency demultiplexing of the mid-IR broadband response. We used a 1000 K Globar source and illumination and interferograms detection was done by using a high-sensitivity cryo-cooled Mercury–Cadmium-Telluride (MCT [Infrared Associates Inc]). After the interferometer, the IR beam was directed to a 25 × objective that produced an illumination spot of 420 μm × 420 μm on the sample’s surface. This field of view was further reduced to 50 to 100 μm by slits to concentrate the analysis around specific particles. The reflected light was collected through a confocal arrangement by the same objective lens and then directed to the MCT detector. FTIR spectra were generated by calculating the Fourier transforms of the recorded interferograms. The spectral resolution was configured at 16 cm<sup>−1</sup>, encompassing the range from 4000 to 700 cm<sup>−1</sup>. Each μFTIR spectrum was normalized to the spectrum of a clean gold surface, which served as a reference background. The cryo-cuts and digested filters were fully analyzed. The μFTIR analyses took place in the IMBUIA beamline at the Brazilian Synchrotron Light Laboratory (LNLS), National Center for Research in Energy and Materials (CNPEM).</p>            <p>The acquired spectra were processed manually using the KnowItAll Informatics System 2024 (John Wiley and Sons Inc). The comparative analysis was performed with the help of FTIR spectra libraries developed for MPs research, including the FTIR Library of Plastic Particles (FLOPP),<sup><a href="#zoi241151r28" data-tab-toggle=".tab-nav-references">28</a></sup> FTIR Library of Plastic Particles Sourced from the Environment (FLOPP-e),<sup><a href="#zoi241151r28" data-tab-toggle=".tab-nav-references">28</a></sup> siMPLe database,<sup><a href="#zoi241151r29" data-tab-toggle=".tab-nav-references">29</a></sup> and KnowItAll IR Spectral Library. We adopted a Hit Quality Index greater than 75% of agreement between characteristic bands of polymers observed in reference materials with bands observed in unknown particles or fibers.<sup><a href="#zoi241151r30" data-tab-toggle=".tab-nav-references">30</a></sup><sup>,<a href="#zoi241151r31" data-tab-toggle=".tab-nav-references">31</a></sup></p>            
            <p>We determined particle sizes by analyzing microphotographs obtained through μFTIR spectroscopy. ImageJ 1.54g software (US National Institutes of Health) was used for accurate measurements.</p>            
            <p>Descriptive analyses were performed using SPSS Statistics 26.0 software (IBM Inc). These analyses were performed in April 2024.</p>            
            <p>The median (range) age of the 15 deceased individuals was 69.5 (33-100) years. They included 12 males and 3 females. Demographic information is detailed in <a href="#zoi241151t1" data-tab-toggle=".tab-nav-figure-table">Table 1</a>. Apart from the 2 cases with histological evidence of previous ischemic cerebral infarction and 1 case with a subarachnoid hematoma due to a ruptured aneurysm of the middle cerebral artery, there were no cerebral histological abnormalities in the remaining cases. The mean (SD) mass of the OB (left or right) was 0.187 (0.050) g, ranging from 0.100 to 0.273 g.</p>            <p>A total of 16 synthetic polymer particles and fibers were identified in 8 out of the 15 deceased individuals, with a range from 1 to 4 MPs per OB. Of these, 75% were particles, of which 83.4% were fragments and 16.6% were spheres, while 25% were fibers with a length-to-width ratio exceeding 3. The particles had a mean (SD) length of 12.1 (7.2) μm, ranging from 5.5 to 26.4 μm, and a mean (SD) width of 8.9 (6.4) μm, ranging from 3.0 to 25.4 μm. The fibers exhibited a mean (SD) length of 21.4 (2.6) μm, ranging from 19.0 to 24.5 μm, and a mean (SD) width of 3.8 (1.8) μm, ranging from 3.0 to 6.0 μm.</p>            <p>In the procedural blank filters, we detected 2 cotton fibers, 2 silica beads, and 1 silicate fragment. Polymeric materials were absent in both the procedural blank and negative control filters. From the 2 collected samples in stillborn, we were able to analyze 1 case, which did not show the presence of MPs. The other case had insufficient material for analysis.</p>            <p>Polypropylene was the most prevalent polymer (43.8%), followed by polyamide, nylon, and polyethylene vinyl acetate (12.5%). This was followed by polyethylene, perlon polyamide, and wool-polypropylene, which accounted for 6.3%). Upon comparison with the reference spectral library of plastic materials, the identified MP particles and fibers exhibited indications of weathering. The μFTIR spectra of the weathered MPs differed substantially from those of pristine standard samples; multiple peaks in the spectra of weathered MPs were attenuated or entirely absent.</p>            <p>Microphotographs and μFTIR point-spectra showing the main types of MP detected in the OB are shown in <a href="#zoi241151f1" data-tab-toggle=".tab-nav-figure-table">Figure 1</a> and <a href="#zoi241151f2" data-tab-toggle=".tab-nav-figure-table">Figure 2</a>. The complete μFTIR point-spectra results of the digested OB are presented in the eFigure in <a data-tab-toggle=".tab-nav-supplemental" href="#note-ZOI241151-1">Supplement 1</a>. <a href="#zoi241151t2" data-tab-toggle=".tab-nav-figure-table">Table 2</a> provides details regarding the morphology, color, and chemical characterization of the particles and fibers.</p>            
            <p>To our knowledge, this is the first study in which the presence of MPs in the human brain was identified and characterized using μFTIR, allowing quantification and characterization of the morphology and polymeric matrix. Specifically, we detected particles as the predominant shape in the OB in 8 out of 15 individuals who underwent autopsy in Sao Paulo. Our data extend the notion that not only black carbon<sup><a href="#zoi241151r15" data-tab-toggle=".tab-nav-references">15</a></sup> but also MP accumulate in the OB in humans.</p>            <p>We believe that the anatomy of the cribriform plate of the ethmoid bone may serve as a gateway in the nasal passages from within the skull. This plate, situated between the frontal and sphenoid bones, lies horizontally and contains multiple foramina, each less than 1 mm in diameter.<sup><a href="#zoi241151r32" data-tab-toggle=".tab-nav-references">32</a></sup> The OB lies directly above it, and the olfactory neurons of the nasal mucosa reach the OB via the foramina of the cribriform plate. Recent studies have shown that part of the cerebrospinal fluid outflow occurs via lymphatic vessels that surround the olfactory axons, reaching the nasal mucosa and extending toward the nasal lymphoid tissue.<sup><a href="#zoi241151r33" data-tab-toggle=".tab-nav-references">33</a></sup> Ossification of the CP occurs by 1 year of age,<sup><a href="#zoi241151r34" data-tab-toggle=".tab-nav-references">34</a></sup> and the total area of the perforations is age-dependent; it is 3.79 to 3.99 mm<sup>2</sup> in those over 50 years of age and 5.61 to 7.91 mm<sup>2</sup> in those under 50 years of age. This decrease in the area over time, causing compression and dysfunction of the olfactory nerves, is thought to explain the decreased olfactory sensation in older individuals.<sup><a href="#zoi241151r35" data-tab-toggle=".tab-nav-references">35</a></sup> Furthermore, in mice, paracellular spaces in the olfactory epithelium can reach 5 to 20 μm in the medial-lateral dimension of the transport and a 10- to 100-μm range observed in the rostral-caudal dimension.<sup><a href="#zoi241151r36" data-tab-toggle=".tab-nav-references">36</a></sup> If a similar situation is observed in humans, this could represent another factor facilitating entry of larger particles in the brain via the cribriform plate.</p>            <p>Given the widespread presence of MPs in the air, some of which are associated with PM<sub>2.5</sub>,<sup><a href="#zoi241151r37" data-tab-toggle=".tab-nav-references">37</a></sup> the identification of MPs in the nose<sup><a href="#zoi241151r45" data-tab-toggle=".tab-nav-references">45</a></sup> and now in the OB, along with the vulnerable anatomical pathways, reinforces the notion that the olfactory pathway is an important entry site for exogenous particles to the brain. In previous epidemiological studies, exposure to PM<sub>2.5</sub> has been associated with neurological and psychiatric adverse outcomes, such as dementia.<sup><a href="#zoi241151r38" data-tab-toggle=".tab-nav-references">38</a></sup><sup>,<a href="#zoi241151r39" data-tab-toggle=".tab-nav-references">39</a></sup> Some neurodegenerative diseases, such as Parkinson disease, seem to have a connection with nasal abnormalities as initial symptoms.<sup><a href="#zoi241151r40" data-tab-toggle=".tab-nav-references">40</a></sup> In experimental studies, both exposures to PM<sub>2.5</sub> and MPs have shown to cause several neurotoxic effects, including disturbances on the brain development.<sup><a href="#zoi241151r41" data-tab-toggle=".tab-nav-references">41</a></sup><sup>,<a href="#zoi241151r42" data-tab-toggle=".tab-nav-references">42</a></sup> The cribriform plate reaches maturation at 1 to 2 years of age, which is a critical time window during which MP penetration into the brain could have negative effects on the organ maturation.</p>            <p>In this study, the MP polymeric matrix found in the OB corresponds to the most produced and manufactured plastics, such as polypropylene, nylon/polyamide, polyethylene and polyethylene vinyl acetate, present in packaging, clothes and home accessories, suggesting indoor environments as a major source of inhaled MPs.<sup><a href="#zoi241151r21" data-tab-toggle=".tab-nav-references">21</a></sup><sup>,<a href="#zoi241151r43" data-tab-toggle=".tab-nav-references">43</a></sup></p>            
            <p>This study has certain limitations. Although the olfactory pathway seems a likely exposure route, we cannot dismiss the possibility of multiple entry routes. MPs might have reached the OB either through systemic circulation, crossing the BBB, or via the respiratory pathway through the trigeminal nerve.<sup><a href="#zoi241151r44" data-tab-toggle=".tab-nav-references">44</a></sup> The biologic matrix of the OB tissues can be a confounding factor when analyzing MP spectra due to its similarity to some polymeric materials. Therefore, we were cautious to consider suspect particles as polymeric material only when spectral bands highly matched with weathered bands from MP libraries (HQI &gt;75%). In the filtered samples, the biological matrix was previously digested, not being an issue. Given the maximum spatial resolution (3 μm) of μFTIR spectroscopy setup and the limited capacity of analysis for other techniques, we were unable to detect nanoplastics. It is likely that the number of plastics in the submicron range with the potential to cause substantial biological damage would be far more numerous.</p>            <p>Avoiding contamination is one of the biggest challenges when analyzing MP. Due to the presence of MP fibers and particles in the air, we have used blank samples in all methodological procedures to detect contamination of the air. We found no MP in our procedural blanks, which supports the validity of our results. Furthermore, we had the opportunity to analyze the brains of 2 stillbirths. However, the status of brain tissue maceration made the analysis challenging due to difficulties in sampling and processing.</p>            
            <p>This case series describes the presence of MPs in the OB, mainly particles of the most commonly produced/processed polymers for clothing and packaging such as polypropylene and nylon. Our data support the idea that the olfactory pathway is an important entry site for environmental air pollutants. Considering the potential neurotoxic effects caused by MPs in the brain, and the widespread environmental contamination with plastics, our results should raise concern in the context of increasing prevalence of neurodegenerative diseases. Noninvasive imaging technologies, such as magnetic resonance imaging, are needed to overcome the current limitations in tissue analysis of different human organs and to improve the understanding of the health hazards of MPs.</p>            <div>
                                <p><a href="#top" data-tab-toggle=".tab-nav-full-text">Back to top</a></p><p>
                                Article Information
                            </p>
                        </div>
<p><strong>Accepted for Publication:</strong> August 22, 2024.</p><p><strong>Published:</strong> September 16, 2024. doi:10.1001/jamanetworkopen.2024.40018</p><p><strong>Open Access:</strong> This is an open access article distributed under the terms of the <a href="https://jamanetwork.com/pages/cc-by-license-permissions">CC-BY License</a>. © 2024 Amato-Lourenço LF et al. <i>JAMA Network Open</i>.</p><p><strong>Corresponding Author:</strong> Luís Fernando Amato-Lourenço, PhD, Freie Universität Berlin - Institut für Biologie, Altensteinstr 6D- 14195 Berlin, Germany (<a href="mailto:luisfamato@zedat.fu-berlin.de" target="_blank">luisfamato@zedat.fu-berlin.de</a>).</p><p><strong>Author Contributions:</strong>  Dr Amato-Lourenço and Prof Mauad had full access to all of the data in the study and take responsibility for the integrity of the data and the accuracy of the data analysis.</p><p><i>Concept and design:</i> Amato-Lourenço, Carvalho-Oliveira, Mauad.</p><p><i>Acquisition, analysis, or interpretation of data:</i> All authors.</p><p><i>Drafting of the manuscript:</i> Amato-Lourenço, Dantas, Carvalho-Oliveira, Mauad.</p><p><i>Critical review of the manuscript for important intellectual content:</i> Amato-Lourenço, Ribeiro Júnior, Ribeiro Paes, S. Rabelo, da Costa, Ando, Freitas, Bispo, Carvalho-Oliveira, Mauad.</p><p><i>Statistical analysis:</i> Amato-Lourenço, Freitas, Mauad.</p><p><i>Obtained funding:</i> Amato-Lourenço, Mauad.</p><p><i>Administrative, technical, or material support:</i> Amato-Lourenço, Dantas, Ribeiro Paes, Freitas, Bispo, Carvalho-Oliveira.</p><p><i>Supervision:</i> Amato-Lourenço, Carvalho-Oliveira, Mauad.</p><p><strong>Conflict of Interest Disclosures:</strong> None reported.</p><p><strong>Funding/Support:</strong> This study was financially supported by the Alexander von Humboldt Foundation (AvH), Germany, by the Plastic Soup Foundation, by the Brazilian Research Council (CNPq) grant 308023/2023-4 and Sao State Research Agency (FAPESP) grant 2021/10724-2.</p><p><strong>Role of the Funder/Sponsor:</strong> The funders had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.</p><p><strong>Data Sharing Statement:</strong> See <a data-tab-toggle=".tab-nav-supplemental" href="#note-ZOI241151-1">Supplement 2</a>.</p><p><strong>Additional Contributions:</strong> We would like to thank the São Paulo City Death Verification Service (SVOC) staff, the IMBUIA beamline at the Brazilian Synchrotron Light Laboratory (LNLS) for providing beamtime (proposal No. 20232740) and the technical support, Maria Westerbos and the Plastic Soup Foundation, Professor Dr Lukas Kenner and Professor Dra Verena Pichler for reviewing the manuscript before submission, and to Dr Walter Waldman for recommending the LNLS facilities to us. They were not compensated.</p>            
<div><div><p><a id="zoi241151r1">1.</a></p><p>Li
        &nbsp;Y﻿, Tao
        &nbsp;L﻿, Wang
        &nbsp;Q﻿, Wang
        &nbsp;F﻿, Li
        &nbsp;G﻿, Song
        &nbsp;M﻿. &nbsp;Potential health impact of microplastics: a review of environmental distribution, human exposure, and toxic effects.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Health</i>. 2023;1(4):249-257. doi:<a href="https://dx.doi.org/10.1021/envhealth.3c00052">10.1021/envhealth.3c00052</a><a href="https://scholar.google.com/scholar_lookup?title=Potential%20health%20impact%20of%20microplastics%3A%20a%20review%20of%20environmental%20distribution%2C%20human%20exposure%2C%20and%20toxic%20effects.&amp;author=Y%20Li&amp;author=L%20Tao&amp;author=Q%20Wang&amp;author=F%20Wang&amp;author=G%20Li&amp;author=M%20Song&amp;publication_year=2023&amp;journal=Environ%20Health&amp;volume=1&amp;pages=249-257" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1021/envhealth.3c00052" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1021/envhealth.3c00052" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r25">25.</a></p><p>Gwinnett
        &nbsp;C﻿, Miller
        &nbsp;RZ﻿. &nbsp;Are we contaminating our samples? A preliminary study to investigate procedural contamination during field sampling and processing for microplastic and anthropogenic microparticles.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Mar Pollut Bull</i>. 2021;173(Pt B):113095. doi:<a href="https://dx.doi.org/10.1016/j.marpolbul.2021.113095">10.1016/j.marpolbul.2021.113095</a><a href="https://scholar.google.com/scholar_lookup?title=Are%20we%20contaminating%20our%20samples%3F%20A%20preliminary%20study%20to%20investigate%20procedural%20contamination%20during%20field%20sampling%20and%20processing%20for%20microplastic%20and%20anthropogenic%20microparticles.&amp;author=C%20Gwinnett&amp;author=RZ%20Miller&amp;publication_year=2021&amp;journal=Mar%20Pollut%20Bull&amp;volume=173&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1016/j.marpolbul.2021.113095" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1016/j.marpolbul.2021.113095" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r29">29.</a></p><p>Primpke
        &nbsp;S﻿, Cross
        &nbsp;RK﻿, Mintenig
        &nbsp;SM﻿, 
    &nbsp;et al. &nbsp;Toward the systematic identification of microplastics in the environment: evaluation of a new independent software tool (siMPle) for spectroscopic analysis.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Appl Spectrosc</i>. 2020;74(9):1127-1138. doi:<a href="https://dx.doi.org/10.1177/0003702820917760">10.1177/0003702820917760</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/32193948" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Toward%20the%20systematic%20identification%20of%20microplastics%20in%20the%20environment%3A%20evaluation%20of%20a%20new%20independent%20software%20tool%20%28siMPle%29%20for%20spectroscopic%20analysis.&amp;author=S%20Primpke&amp;author=RK%20Cross&amp;author=SM%20Mintenig&amp;publication_year=2020&amp;journal=Appl%20Spectrosc&amp;volume=74&amp;pages=1127-1138" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1177/0003702820917760" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1177/0003702820917760" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r30">30.</a></p><p>Weisser
        &nbsp;J﻿, Pohl
        &nbsp;T﻿, Heinzinger
        &nbsp;M﻿, Ivleva
        &nbsp;NP﻿, Hofmann
        &nbsp;T﻿, Glas
        &nbsp;K﻿. &nbsp;The Identification of Microplastics Based on Vibrational Spectroscopy Data—A Critical Review of Data Analysis Routines. TrAC.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Trends Analyt Chem</i>. 2022;148:116535. doi:<a href="https://dx.doi.org/10.1016/j.trac.2022.116535">10.1016/j.trac.2022.116535</a><a href="https://scholar.google.com/scholar_lookup?title=The%20Identification%20of%20Microplastics%20Based%20on%20Vibrational%20Spectroscopy%20Data%E2%80%94A%20Critical%20Review%20of%20Data%20Analysis%20Routines.%20TrAC.&amp;author=J%20Weisser&amp;author=T%20Pohl&amp;author=M%20Heinzinger&amp;author=NP%20Ivleva&amp;author=T%20Hofmann&amp;author=K%20Glas&amp;publication_year=2022&amp;journal=Trends%20Analyt%20Chem&amp;volume=148&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a><a href="https://doi.org/10.1016/j.trac.2022.116535" target="_blank" xmlns:helper="urn:XsltStringHelper">Crossref</a><span data-targetid="10.1016/j.trac.2022.116535" xmlns:helper="urn:XsltStringHelper"> </span></p></div><div><p><a id="zoi241151r31">31.</a></p><p>Morgado
        &nbsp;V﻿, Palma
        &nbsp;C﻿, Bettencourt da Silva
        &nbsp;RJN﻿. &nbsp;Microplastics identification by infrared spectroscopy - Evaluation of identification criteria and uncertainty by the Bootstrap method.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Talanta</i>. 2021;224:121814. doi:<a href="https://dx.doi.org/10.1016/j.talanta.2020.121814">10.1016/j.talanta.2020.121814</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/33379039" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Microplastics%20identification%20by%20infrared%20spectroscopy%20-%20Evaluation%20of%20identification%20criteria%20and%20uncertainty%20by%20the%20Bootstrap%20method.&amp;author=V%20Morgado&amp;author=C%20Palma&amp;author=RJN%20Bettencourt%20da%20Silva&amp;publication_year=2021&amp;journal=Talanta&amp;volume=224&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r36">36.</a></p><p>Kincaid
        &nbsp;AE﻿, Ayers
        &nbsp;JI﻿, Bartz
        &nbsp;JC﻿. &nbsp;Specificity, size, and frequency of spaces that characterize the mechanism of bulk transepithelial transport of prions in the nasal cavities of hamsters and mice.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;J Virol</i>. 2016;90(18):8293-8301. doi:<a href="https://dx.doi.org/10.1128/JVI.01103-16">10.1128/JVI.01103-16</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/27384659" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Specificity%2C%20size%2C%20and%20frequency%20of%20spaces%20that%20characterize%20the%20mechanism%20of%20bulk%20transepithelial%20transport%20of%20prions%20in%20the%20nasal%20cavities%20of%20hamsters%20and%20mice.&amp;author=AE%20Kincaid&amp;author=JI%20Ayers&amp;author=JC%20Bartz&amp;publication_year=2016&amp;journal=J%20Virol&amp;volume=90&amp;pages=8293-8301" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r37">37.</a></p><p>Akhbarizadeh
        &nbsp;R﻿, Dobaradaran
        &nbsp;S﻿, Amouei Torkmahalleh
        &nbsp;M﻿, Saeedi
        &nbsp;R﻿, Aibaghi
        &nbsp;R﻿, Faraji Ghasemi
        &nbsp;F﻿. &nbsp;Suspended fine particulate matter (PM<sub>2.5</sub>), microplastics (MPs), and polycyclic aromatic hydrocarbons (PAHs) in air: their possible relationships and health implications.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Res</i>. 2021;192:110339. doi:<a href="https://dx.doi.org/10.1016/j.envres.2020.110339">10.1016/j.envres.2020.110339</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/33068583" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Suspended%20fine%20particulate%20matter%20%28PM2.5%29%2C%20microplastics%20%28MPs%29%2C%20and%20polycyclic%20aromatic%20hydrocarbons%20%28PAHs%29%20in%20air%3A%20their%20possible%20relationships%20and%20health%20implications.&amp;author=R%20Akhbarizadeh&amp;author=S%20Dobaradaran&amp;author=M%20Amouei%20Torkmahalleh&amp;author=R%20Saeedi&amp;author=R%20Aibaghi&amp;author=F%20Faraji%20Ghasemi&amp;publication_year=2021&amp;journal=Environ%20Res&amp;volume=192&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r38">38.</a></p><p>Braithwaite
        &nbsp;I﻿, Zhang
        &nbsp;S﻿, Kirkbride
        &nbsp;JB﻿, Osborn
        &nbsp;DPJ﻿, Hayes
        &nbsp;JF﻿. &nbsp;Air pollution (particulate matter) exposure and associations with depression, anxiety, bipolar, psychosis and suicide risk: a systematic review and meta-analysis.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Health Perspect</i>. 2019;127(12):126002. doi:<a href="https://dx.doi.org/10.1289/EHP4595">10.1289/EHP4595</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/31850801" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Air%20pollution%20%28particulate%20matter%29%20exposure%20and%20associations%20with%20depression%2C%20anxiety%2C%20bipolar%2C%20psychosis%20and%20suicide%20risk%3A%20a%20systematic%20review%20and%20meta-analysis.&amp;author=I%20Braithwaite&amp;author=S%20Zhang&amp;author=JB%20Kirkbride&amp;author=DPJ%20Osborn&amp;author=JF%20Hayes&amp;publication_year=2019&amp;journal=Environ%20Health%20Perspect&amp;volume=127&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r39">39.</a></p><p>Kioumourtzoglou
        &nbsp;MA﻿, Schwartz
        &nbsp;JD﻿, Weisskopf
        &nbsp;MG﻿, 
    &nbsp;et al. &nbsp;Long-term PM2.5 exposure and neurological hospital admissions in the northeastern United States.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Environ Health Perspect</i>. 2016;124(1):23-29. doi:<a href="https://dx.doi.org/10.1289/ehp.1408973">10.1289/ehp.1408973</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/25978701" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Long-term%20PM2.5%20exposure%20and%20neurological%20hospital%20admissions%20in%20the%20northeastern%20United%20States.&amp;author=MA%20Kioumourtzoglou&amp;author=JD%20Schwartz&amp;author=MG%20Weisskopf&amp;publication_year=2016&amp;journal=Environ%20Health%20Perspect&amp;volume=124&amp;pages=23-29" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r41">41.</a></p><p>Liu
        &nbsp;XQ﻿, Huang
        &nbsp;J﻿, Song
        &nbsp;C﻿, Zhang
        &nbsp;TL﻿, Liu
        &nbsp;YP﻿, Yu
        &nbsp;L﻿. &nbsp;Neurodevelopmental toxicity induced by PM2.5 exposure and its possible role in neurodegenerative and mental disorders.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;Hum Exp Toxicol</i>. Published online August 3, 2023. doi:<a href="https://dx.doi.org/10.1177/09603271231191436">10.1177/09603271231191436</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/37537902" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Neurodevelopmental%20toxicity%20induced%20by%20PM2.5%20exposure%20and%20its%20possible%20role%20in%20neurodegenerative%20and%20mental%20disorders.&amp;author=XQ%20Liu&amp;author=J%20Huang&amp;author=C%20Song&amp;author=TL%20Zhang&amp;author=YP%20Liu&amp;author=L%20Yu&amp;publication_year=2023&amp;journal=Hum%20Exp%20Toxicol&amp;volume=&amp;pages=" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div><div><p><a id="zoi241151r44">44.</a></p><p>Jeong
        &nbsp;SH﻿, Jang
        &nbsp;JH﻿, Lee
        &nbsp;YB﻿. &nbsp;Drug delivery to the brain via the nasal route of administration: exploration of key targets and major consideration factors.&nbsp;﻿ <i xmlns:helper="urn:XsltStringHelper">&nbsp;J Pharm Investig</i>. 2023;53(1):119-152. doi:<a href="https://dx.doi.org/10.1007/s40005-022-00589-5">10.1007/s40005-022-00589-5</a><a href="https://www.ncbi.nlm.nih.gov/pubmed/35910081" target="_blank" xmlns:helper="urn:XsltStringHelper">PubMed</a><a href="https://scholar.google.com/scholar_lookup?title=Drug%20delivery%20to%20the%20brain%20via%20the%20nasal%20route%20of%20administration%3A%20exploration%20of%20key%20targets%20and%20major%20consideration%20factors.&amp;author=SH%20Jeong&amp;author=JH%20Jang&amp;author=YB%20Lee&amp;publication_year=2023&amp;journal=J%20Pharm%20Investig&amp;volume=53&amp;pages=119-152" target="_blank" xmlns:helper="urn:XsltStringHelper">Google Scholar</a></p></div></div>

</div>

        
    </div> 





 
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Senate Vote Tomorrow Could Give Helping Hand to Patent Trolls (174 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls</link>
            <guid>41582278</guid>
            <pubDate>Wed, 18 Sep 2024 16:50:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls">https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls</a>, See on <a href="https://news.ycombinator.com/item?id=41582278">Hacker News</a></p>
Couldn't get https://www.eff.org/deeplinks/2024/09/senate-vote-tomorrow-could-give-helping-hand-patent-trolls: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Llama 3.1 Omni Model (153 pts)]]></title>
            <link>https://github.com/ictnlp/LLaMA-Omni</link>
            <guid>41582180</guid>
            <pubDate>Wed, 18 Sep 2024 16:42:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/ictnlp/LLaMA-Omni">https://github.com/ictnlp/LLaMA-Omni</a>, See on <a href="https://news.ycombinator.com/item?id=41582180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🦙🎧 LLaMA-Omni: Seamless Speech Interaction with Large Language Models</h2><a id="user-content--llama-omni-seamless-speech-interaction-with-large-language-models" aria-label="Permalink: 🦙🎧 LLaMA-Omni: Seamless Speech Interaction with Large Language Models" href="#-llama-omni-seamless-speech-interaction-with-large-language-models"></a></p>
<blockquote>
<p dir="auto"><strong>Authors: <a href="https://fangqingkai.github.io/" rel="nofollow">Qingkai Fang</a>, <a href="https://scholar.google.com/citations?hl=en&amp;user=XwHtPyAAAAAJ" rel="nofollow">Shoutao Guo</a>, <a href="https://zhouyan19.github.io/zhouyan/" rel="nofollow">Yan Zhou</a>, <a href="https://scholar.google.com.hk/citations?user=dUgq6tEAAAAJ" rel="nofollow">Zhengrui Ma</a>, <a href="https://zhangshaolei1998.github.io/" rel="nofollow">Shaolei Zhang</a>, <a href="https://people.ucas.edu.cn/~yangfeng?language=en" rel="nofollow">Yang Feng*</a></strong></p>
</blockquote>
<p dir="auto"><a href="https://arxiv.org/abs/2409.06666" rel="nofollow"><img src="https://camo.githubusercontent.com/cf848c9cd376e15932b0cba092d5c6053463835849a56eac0c6a011d3ab107d5/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61725869762d323430392e30363636362d6233316231622e7376673f6c6f676f3d6172586976" alt="arXiv" data-canonical-src="https://img.shields.io/badge/arXiv-2409.06666-b31b1b.svg?logo=arXiv"></a>
<a href="https://huggingface.co/ICTNLP/Llama-3.1-8B-Omni" rel="nofollow"><img src="https://camo.githubusercontent.com/43ed5a97ea9a77d1afe95566b086cb8aed400254b78842e11ed83614f503df95/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f25463025394625413425393725323048756767696e675f466163652d4d6f64656c2d626c75652e737667" alt="model" data-canonical-src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging_Face-Model-blue.svg"></a>
<a href="https://github.com/ictnlp/LLaMA-Omni"><img src="https://camo.githubusercontent.com/77762e523530a02dd6ad9f1b9e4e9dd91c0bf748c684bd5cced64a3302047441/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4769746875622d436f64652d6b657967656e2e7376673f6c6f676f3d676974687562" alt="code" data-canonical-src="https://img.shields.io/badge/Github-Code-keygen.svg?logo=github"></a></p>
<p dir="auto">LLaMA-Omni is a speech-language model built upon Llama-3.1-8B-Instruct. It supports low-latency and high-quality speech interactions, simultaneously generating both text and speech responses based on speech instructions.</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/ictnlp/LLaMA-Omni/blob/main/images/model.png"><img src="https://github.com/ictnlp/LLaMA-Omni/raw/main/images/model.png" width="75%"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">💡 Highlights</h2><a id="user-content--highlights" aria-label="Permalink: 💡 Highlights" href="#-highlights"></a></p>
<ul dir="auto">
<li>
<p dir="auto">💪 <strong>Built on Llama-3.1-8B-Instruct, ensuring high-quality responses.</strong></p>
</li>
<li>
<p dir="auto">🚀 <strong>Low-latency speech interaction with a latency as low as 226ms.</strong></p>
</li>
<li>
<p dir="auto">🎧 <strong>Simultaneous generation of both text and speech responses.</strong></p>
</li>
<li>
<p dir="auto">♻️ <strong>Trained in less than 3 days using just 4 GPUs.</strong></p>
</li>
</ul>
<details open="">
  <summary>
    
    <span aria-label="Video description demo.mp4">demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/19513464/366072569-2b097af8-47d7-494f-b3b3-6be17ca0247a.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY3MDI1MTQsIm5iZiI6MTcyNjcwMjIxNCwicGF0aCI6Ii8xOTUxMzQ2NC8zNjYwNzI1NjktMmIwOTdhZjgtNDdkNy00OTRmLWIzYjMtNmJlMTdjYTAyNDdhLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTE4VDIzMzAxNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOGYwOTcwMTgwOWQ0MWNiYzQ0OWRhZDgyNWNhMDE2NjgwMmQxNjNkMzY4MmI2ZGU4ZmFlM2QwNjA2M2VjZjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.las91a8L1UW1B_MSTxqh8zBOpmbpiB26ZRr7hAb3Hvo" data-canonical-src="https://private-user-images.githubusercontent.com/19513464/366072569-2b097af8-47d7-494f-b3b3-6be17ca0247a.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY3MDI1MTQsIm5iZiI6MTcyNjcwMjIxNCwicGF0aCI6Ii8xOTUxMzQ2NC8zNjYwNzI1NjktMmIwOTdhZjgtNDdkNy00OTRmLWIzYjMtNmJlMTdjYTAyNDdhLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MTglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTE4VDIzMzAxNFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFhOGYwOTcwMTgwOWQ0MWNiYzQ0OWRhZDgyNWNhMDE2NjgwMmQxNjNkMzY4MmI2ZGU4ZmFlM2QwNjA2M2VjZjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.las91a8L1UW1B_MSTxqh8zBOpmbpiB26ZRr7hAb3Hvo" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<ol dir="auto">
<li>Clone this repository.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/ictnlp/LLaMA-Omni
cd LLaMA-Omni"><pre>git clone https://github.com/ictnlp/LLaMA-Omni
<span>cd</span> LLaMA-Omni</pre></div>
<ol start="2" dir="auto">
<li>Install packages.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="conda create -n llama-omni python=3.10
conda activate llama-omni
pip install pip==24.0
pip install -e ."><pre>conda create -n llama-omni python=3.10
conda activate llama-omni
pip install pip==24.0
pip install -e <span>.</span></pre></div>
<ol start="3" dir="auto">
<li>Install <code>fairseq</code>.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/pytorch/fairseq
cd fairseq
pip install -e . --no-build-isolation"><pre>git clone https://github.com/pytorch/fairseq
<span>cd</span> fairseq
pip install -e <span>.</span> --no-build-isolation</pre></div>
<ol start="4" dir="auto">
<li>Install <code>flash-attention</code>.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="pip install flash-attn --no-build-isolation"><pre>pip install flash-attn --no-build-isolation</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Download the <code>Llama-3.1-8B-Omni</code> model from 🤗<a href="https://huggingface.co/ICTNLP/Llama-3.1-8B-Omni" rel="nofollow">Huggingface</a>.</p>
</li>
<li>
<p dir="auto">Download the <code>Whisper-large-v3</code> model.</p>
</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="import whisper
model = whisper.load_model(&quot;large-v3&quot;, download_root=&quot;models/speech_encoder/&quot;)"><pre>import whisper
model = whisper.load_model(<span><span>"</span>large-v3<span>"</span></span>, download_root=<span><span>"</span>models/speech_encoder/<span>"</span></span>)</pre></div>
<ol start="3" dir="auto">
<li>Download the unit-based HiFi-GAN vocoder.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/g_00500000 -P vocoder/
wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/config.json -P vocoder/"><pre>wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/g_00500000 -P vocoder/
wget https://dl.fbaipublicfiles.com/fairseq/speech_to_speech/vocoder/code_hifigan/mhubert_vp_en_es_fr_it3_400k_layer11_km1000_lj/config.json -P vocoder/</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gradio Demo</h2><a id="user-content-gradio-demo" aria-label="Permalink: Gradio Demo" href="#gradio-demo"></a></p>
<ol dir="auto">
<li>Launch a controller.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m omni_speech.serve.controller --host 0.0.0.0 --port 10000"><pre>python -m omni_speech.serve.controller --host 0.0.0.0 --port 10000</pre></div>
<ol start="2" dir="auto">
<li>Launch a gradio web server.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m omni_speech.serve.gradio_web_server --controller http://localhost:10000 --port 8000 --model-list-mode reload --vocoder vocoder/g_00500000 --vocoder-cfg vocoder/config.json"><pre>python -m omni_speech.serve.gradio_web_server --controller http://localhost:10000 --port 8000 --model-list-mode reload --vocoder vocoder/g_00500000 --vocoder-cfg vocoder/config.json</pre></div>
<ol start="3" dir="auto">
<li>Launch a model worker.</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python -m omni_speech.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path Llama-3.1-8B-Omni --model-name Llama-3.1-8B-Omni --s2s"><pre>python -m omni_speech.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path Llama-3.1-8B-Omni --model-name Llama-3.1-8B-Omni --s2s</pre></div>
<ol start="4" dir="auto">
<li>Visit <a href="http://localhost:8000/" rel="nofollow">http://localhost:8000/</a> and interact with LLaMA-3.1-8B-Omni!</li>
</ol>
<p dir="auto"><strong>Note: Due to the instability of streaming audio playback in Gradio, we have only implemented streaming audio synthesis without enabling autoplay. If you have a good solution, feel free to submit a PR. Thanks!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Local Inference</h2><a id="user-content-local-inference" aria-label="Permalink: Local Inference" href="#local-inference"></a></p>
<p dir="auto">To run inference locally, please organize the speech instruction files according to the format in the <code>omni_speech/infer/examples</code> directory, then refer to the following script.</p>
<div dir="auto" data-snippet-clipboard-copy-content="bash omni_speech/infer/run.sh omni_speech/infer/examples"><pre>bash omni_speech/infer/run.sh omni_speech/infer/examples</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">LICENSE</h2><a id="user-content-license" aria-label="Permalink: LICENSE" href="#license"></a></p>
<p dir="auto">Our code is released under the Apache-2.0 License. Our model, as it is built on Llama 3.1, is required to comply with the <a href="https://llama.meta.com/llama3_1/license/" rel="nofollow">Llama 3.1 License</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<ul dir="auto">
<li><a href="https://github.com/haotian-liu/LLaVA">LLaVA</a>: The codebase we built upon.</li>
<li><a href="https://github.com/X-LANCE/SLAM-LLM">SLAM-LLM</a>: We borrow some code about speech encoder and speech adaptor.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you have any questions, please feel free to submit an issue or contact <code>fangqingkai21b@ict.ac.cn</code>.</p>
<p dir="auto">If our work is useful for you, please cite as:</p>
<div data-snippet-clipboard-copy-content="@article{fang-etal-2024-llama-omni,
  title={LLaMA-Omni: Seamless Speech Interaction with Large Language Models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}"><pre><code>@article{fang-etal-2024-llama-omni,
  title={LLaMA-Omni: Seamless Speech Interaction with Large Language Models},
  author={Fang, Qingkai and Guo, Shoutao and Zhou, Yan and Ma, Zhengrui and Zhang, Shaolei and Feng, Yang},
  journal={arXiv preprint arXiv:2409.06666},
  year={2024}
}
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Star History</h2><a id="user-content-star-history" aria-label="Permalink: Star History" href="#star-history"></a></p>
<p dir="auto"><a href="https://star-history.com/#ictnlp/llama-omni&amp;Date" rel="nofollow"><img src="https://camo.githubusercontent.com/73a57c27c1f48fd90f61261b56699215fdd4b2267edd91ec8494c550fd34bc04/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d6963746e6c702f6c6c616d612d6f6d6e6926747970653d44617465" alt="Star History Chart" data-canonical-src="https://api.star-history.com/svg?repos=ictnlp/llama-omni&amp;type=Date"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[RabbitMQ 4.0 Released (208 pts)]]></title>
            <link>https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0</link>
            <guid>41581942</guid>
            <pubDate>Wed, 18 Sep 2024 16:24:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0">https://github.com/rabbitmq/rabbitmq-server/releases/tag/v4.0.0</a>, See on <a href="https://news.ycombinator.com/item?id=41581942">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-pjax="true" data-test-selector="body-content" data-view-component="true"><p>RabbitMQ <code>4.0.0</code> is a new major release.</p>
<p>Starting June 1st, 2024, community support for this series will only be provided to <a href="https://github.com/rabbitmq/rabbitmq-server/blob/main/COMMUNITY_SUPPORT.md">regularly contributing users</a><br>
and those who hold a valid <a href="https://tanzu.vmware.com/rabbitmq/oss" rel="nofollow">commercial support license</a>.</p>
<h2>Highlights</h2>
<p>Some key improvements in this release are listed below.</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=whVqpgvep90" rel="nofollow">Khepri</a>, an <a href="https://github.com/rabbitmq/rabbitmq-server/pull/7206" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/7206/hovercard">alternative schema data store</a> developed to replace Mnesia,<br>
has matured and is now fully supported (it previously was an experimental feature)</li>
<li><a href="https://www.rabbitmq.com/blog/2024/08/05/native-amqp" rel="nofollow">AMQP 1.0 is now a core protocol</a> that is always enabled. Its plugin is now a no-op that only exists to simplify upgrades.</li>
<li>The AMQP 1.0 implementation is now significantly more efficient: its peak throughput is <a href="https://www.rabbitmq.com/blog/2024/08/21/amqp-benchmarks" rel="nofollow">more than double than that of 3.13.x</a><br>
on some workloads</li>
<li>Efficient sub-linear <a href="https://www.rabbitmq.com/blog/2024/08/28/quorum-queues-in-4.0#faster-recovery-of-long-queues" rel="nofollow">quorum queue recovery on node startup using checkpoints</a></li>
<li>Quorum queues now <a href="https://www.rabbitmq.com/blog/2024/08/28/quorum-queues-in-4.0#message-priorities" rel="nofollow">support priorities</a> (but not exactly the same way as classic queues)</li>
<li><a href="https://github.com/rabbitmq/rabbitmq-server/pull/10559" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10559/hovercard">AMQP 1.0 clients now can manage topologies</a> similarly to how AMQP 0-9-1 clients do it</li>
<li>The AMQP 1.0 convention (address format) used for interacting with with AMQP 0-9-1 entities <a href="https://www.rabbitmq.com/docs/next/amqp#addresses" rel="nofollow">is now easier to reason about</a></li>
<li>Mirroring (replication) of classic queues <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9815" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9815/hovercard">was removed</a> after several years of deprecation. For replicated messaging data types,<br>
use quorum queues and/or streams. Non-replicated classic queues remain and their development continues</li>
<li>Classic queue <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11112" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11112/hovercard">storage efficiency improvements</a>, in particular recovery time and storage of multi-MiB messages</li>
<li>Nodes with multiple enabled plugins and little on disk data to recover now <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10989" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10989/hovercard">start up to 20-30% faster</a></li>
<li>New exchange type: <a href="https://rabbitmq.com/docs/next/local-random-exchange" rel="nofollow">Local Random Exchange</a></li>
</ul>
<p>See Compatibility Notes below to learn about <strong>breaking or potentially breaking changes</strong> in this release.</p>
<h2>Breaking Changes and Compatibility Notes</h2>
<h3>Classic Queues is Now a Non-Replicated Queue Type</h3>
<p>After three years of deprecated, classic queue mirroring was completely removed in this version.<br>
<a href="https://www.rabbitmq.com/docs/quorum-queues" rel="nofollow">Quorum queues</a> and <a href="https://www.rabbitmq.com/docs/streams" rel="nofollow">streams</a> are two mature<br>
replicated data types offered by RabbitMQ 4.x. Classic queues continue being supported without any breaking changes<br>
for client libraries and applications but they are now a non-replicated queue type.</p>
<p>After an upgrade to 4.0, all classic queue mirroring-related parts of policies will have no effect.<br>
Classic queues will continue to work like before but with only one replica.</p>
<p>Clients will be able to connect to any node to publish to and consume from any non-replicated classic queues.<br>
Therefore applications will be able to use the same classic queues as before.</p>
<p>See <a href="https://www.rabbitmq.com/docs/migrate-mcq-to-qq" rel="nofollow">Mirrored Classic Queues Migration to Quorum Queues</a> for guidance<br>
on how to migrate to quorum queues for the parts of the system that really need to use replication.</p>
<h3>Quorum Queues Now Have a Default Redelivery Limit</h3>
<p>Quorum queues now have a default <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">redelivery limit</a> set to <code>20</code>.<br>
Messages that are redelivered 20 times or more will be <a href="https://www.rabbitmq.com/docs/dlx" rel="nofollow">dead-lettered</a> or dropped (removed).</p>
<p>This limit is necessary to protect nodes from consumers that run into infinite fail-requeue-fail-requeue loops. Such<br>
consumers can drive a node out of disk space by making a quorum queue Raft log grow forever without allowing compaction<br>
of older entries to happen.</p>
<p>If 20 deliveries per message is a common scenario for a queue, a dead-lettering target or a higher limit must be configured<br>
for such queues. The recommended way of doing that is via a <a href="https://www.rabbitmq.com/docs/parameters#policies" rel="nofollow">policy</a>.<br>
See the <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">Position Messaging Handling</a> section<br>
in the quorum queue documentation guide.</p>
<p>Note that increasing the limit is recommended against: usually the presence of messages that have been redelivered 20 times or more suggests<br>
that a consumer has entered a fail-requeue-fail-requeue loop, in which case even a much higher limit<br>
won't help avoid the dead-lettering.</p>
<p>For specific cases where the RabbitMQ configuration cannot be updated to include a dead letter policy<br>
the delivery limit can be disabled by setting a delivery limit configuration of <code>-1</code>. However, the RabbitMQ team<br>
strongly recommends keeping the delivery limit in place to ensure cluster availability isn't<br>
accidentally sacrificed.</p>
<h3>CQv1 Storage Implementation was Removed</h3>
<p>CQv1, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10656" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10656/hovercard">the original classic queue storage layer, was removed</a><br>
except for the part that's necessary for upgrades to CQv2 (the 2nd generation).</p>
<p>In case <code>rabbitmq.conf</code> explicitly sets <code>classic_queue.default_version</code> to <code>1</code> like so</p>
<div data-snippet-clipboard-copy-content="# this configuration value is no longer supported,
# remove this line or set the version to 2
classic_queue.default_version = 1"><pre><span><span>#</span> this configuration value is no longer supported,</span>
<span><span>#</span> remove this line or set the version to 2</span>
<span>classic_queue.default_version</span> = 1</pre></div>
<p>nodes will now fail to start. Removing the line will make the node start and perform<br>
the migration from CQv1 to CQv2.</p>
<h3>Settings <code>cluster_formation.randomized_startup_delay_range.*</code> were Removed</h3>
<p>The following two deprecated <code>rabbitmq.conf</code> settings were <a href="https://github.com/rabbitmq/rabbitmq-server/pull/12050" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/12050/hovercard">removed</a>:</p>
<div data-snippet-clipboard-copy-content="cluster_formation.randomized_startup_delay_range.min
cluster_formation.randomized_startup_delay_range.max"><pre><code>cluster_formation.randomized_startup_delay_range.min
cluster_formation.randomized_startup_delay_range.max
</code></pre></div>
<p>RabbitMQ 4.0 will fail to boot if these settings are configured in <code>rabbitmq.conf</code>.</p>
<h3>Several Disk I/O-Related Metrics were Removed</h3>
<p>Several I/O-related metrics are dropped, they should be <a href="https://www.rabbitmq.com/docs/monitoring#system-metrics" rel="nofollow">monitored at the infrastructure and kernel layers</a></p>
<h3>Default Maximum Message Size Reduced to 16 MiB</h3>
<p>Default maximum message size is reduced to 16 MiB (from 128 MiB).</p>
<p>The limit can be increased via a <code>rabbitmq.conf</code> setting:</p>
<div data-snippet-clipboard-copy-content="# 32 MiB
max_message_size = 33554432"><pre><span><span>#</span> 32 MiB</span>
<span>max_message_size</span> = 33554432</pre></div>
<p>However, it is recommended that such large multi-MiB messages are put into a blob store, and their<br>
IDs are passed around in messages instead of the entire payload.</p>
<h3>AMQP 1.0</h3>
<p>RabbitMQ 3.13 <code>rabbitmq.conf</code> setting <code>rabbitmq_amqp1_0.default_vhost</code> is unsupported in RabbitMQ 4.0.</p>
<p>Instead <code>default_vhost</code> will be used to determine the default vhost an AMQP 1.0 client connects to(i.e. when the AMQP 1.0 client<br>
does not define the vhost in the <code>hostname</code> field of the <code>open</code> frame).</p>
<p>Starting with RabbitMQ 4.0, RabbitMQ strictly validates that<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-delivery-annotations" rel="nofollow">delivery annotations</a>,<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-message-annotations" rel="nofollow">message annotations</a>, and<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-footer" rel="nofollow">footer</a> contain only<br>
<a href="https://docs.oasis-open.org/amqp/core/v1.0/os/amqp-core-messaging-v1.0-os.html#type-annotations" rel="nofollow">non-reserved annotation keys</a>.<br>
As a result, clients can only send symbolic keys that begin with <code>x-</code>.</p>
<h3>MQTT</h3>
<p>RabbitMQ 3.13 <a href="https://www.rabbitmq.com/docs/configure#config-file" rel="nofollow">rabbitmq.conf</a> settings <code>mqtt.default_user</code>, <code>mqtt.default_password</code>,<br>
and <code>amqp1_0.default_user</code> are unsupported in RabbitMQ 4.0.</p>
<p>Instead, set the new RabbitMQ 4.0 settings <code>anonymous_login_user</code> and <code>anonymous_login_pass</code> (both values default to <code>guest</code>).<br>
For production scenarios, <a href="https://www.rabbitmq.com/docs/next/production-checklist#anonymous-login" rel="nofollow">disallow anonymous logins</a>.</p>
<h3>TLS Client (LDAP, Shovels, Federation) Defaults</h3>
<p>Starting with Erlang 26, client side <a href="https://www.rabbitmq.com/docs/ssl#peer-verification" rel="nofollow">TLS peer certificate chain verification</a> settings are enabled by default in most contexts:<br>
from federation links to shovels to TLS-enabled LDAP client connections.</p>
<p>If using TLS peer certificate chain verification is not practical or necessary, it can be disabled.<br>
Please refer to the docs of the feature in question, for example,<br>
this one <a href="http://rabbitmq.com/docs/ldap/#tls" rel="nofollow">on TLS-enabled LDAP client</a> connections,<br>
two others on <a href="https://www.rabbitmq.com/docs/shovel#tls" rel="nofollow">TLS-enabled dynamic shovels</a> and <a href="https://www.rabbitmq.com/docs/uri-query-parameters" rel="nofollow">dynamic shovel URI query parameters</a>.</p>
<h3>Shovels</h3>
<p>RabbitMQ Shovels will be able connect to a RabbitMQ 4.0 node via AMQP 1.0 only when the Shovel runs on a RabbitMQ node &gt;= <code>3.13.7</code>.</p>
<p>TLS-enabled Shovels will be affected by the TLS client default changes in Erlang 26 (see above).</p>
<h2>Erlang/OTP Compatibility Notes</h2>
<p>This release <a href="https://www.rabbitmq.com/docs/which-erlang" rel="nofollow">requires Erlang 26.2</a>.</p>
<p><a href="https://www.rabbitmq.com/docs/which-erlang#erlang-repositories" rel="nofollow">Provisioning Latest Erlang Releases</a> explains<br>
what package repositories and tools can be used to provision latest patch versions of Erlang 26.x.</p>
<h2>Release Artifacts</h2>
<p>RabbitMQ releases are distributed via <a href="https://github.com/rabbitmq/rabbitmq-server/releases">GitHub</a>.<br>
<a href="https://rabbitmq.com/docs/install-debian/" rel="nofollow">Debian</a> and <a href="https://rabbitmq.com/docs/install-rpm/" rel="nofollow">RPM packages</a> are available via<br>
repositories maintained by the RabbitMQ Core Team.</p>
<p><a href="https://hub.docker.com/_/rabbitmq/" rel="nofollow">Community Docker image</a>, <a href="https://community.chocolatey.org/packages/rabbitmq" rel="nofollow">Chocolatey package</a>, and the <a href="https://www.rabbitmq.com/docs/install-homebrew" rel="nofollow">Homebrew formula</a><br>
are other installation options. They are updated with a delay.</p>
<h2>Upgrading to 4.0</h2>
<h3>Documentation guides on upgrades</h3>
<p>See the <a href="https://www.rabbitmq.com/docs/upgrade" rel="nofollow">Upgrading guide</a> for documentation on upgrades and <a href="https://github.com/rabbitmq/rabbitmq-server/releases">GitHub releases</a><br>
for release notes of individual releases.</p>
<p>This release series only supports upgrades from <code>3.13.x</code>.</p>
<p>This release requires <strong>all feature flags</strong> in the 3.x series (specifically <code>3.13.x</code>) to be enabled before upgrading,<br>
there is no upgrade path from 3.12.14 (or a later patch release) straight to <code>4.0.0</code>.</p>
<h3>Required Feature Flags</h3>
<p>This release <a href="https://www.rabbitmq.com/docs/feature-flags#graduation" rel="nofollow">graduates</a> all feature flags introduced up to <code>3.13.0</code>.</p>
<p>All users must enable all stable [feature flags] before upgrading to 4.0 from<br>
the latest available 3.13.x patch release.</p>
<h3>Mixed version cluster compatibility</h3>
<p>RabbitMQ 4.0.0 nodes can run alongside <code>3.13.x</code> nodes. <code>4.0.x</code>-specific features can only be made available when all nodes in the cluster<br>
upgrade to 4.0.0 or a later patch release in the new series.</p>
<p>While operating in mixed version mode, some aspects of the system may not behave as expected. The list of known behavior changes will be covered in future updates.<br>
Once all nodes are upgraded to 4.0.0, these irregularities will go away.</p>
<p>Mixed version clusters are a mechanism that allows rolling upgrade and are not meant to be run for extended<br>
periods of time (no more than a few hours).</p>
<h3>Recommended Post-upgrade Procedures</h3>
<h4>Configure Dead Lettering or Increase the Limit for Frequently Redelivered Messages</h4>
<p>In environments where messages can experience 20 redeliveries, the affected queues should have <a href="https://www.rabbitmq.com/docs/dlx" rel="nofollow">dead lettering</a><br>
configured (usually via a <a href="https://www.rabbitmq.com/docs/parameters#policies" rel="nofollow">policy</a>) to make sure<br>
that messages that are redelivered 20 times are moved to a separate queue (or stream) instead of<br>
being dropped (removed) by the <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">crash-requeue-redelivery loop protection mechanism</a>.</p>
<p>Alternatively, the limit can be <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">increased</a> using a policy.<br>
This option is recommended against: usually the presence of messages that have been redelivered 20 times or more suggests<br>
that a consumer has entered a fail-requeue-fail-requeue loop, in which case even a much higher limit<br>
won't help avoid the dead-lettering.</p>
<h2>Changes Worth Mentioning</h2>
<p>This section is incomplete and will be expanded as 4.0 approaches its release candidate stage.</p>
<h3>Core Server</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>Efficient sub-linear quorum queue recovery on node startup using checkpoints.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10637" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10637/hovercard">#10637</a></p>
</li>
<li>
<p>Classic queue storage v2 (CQv2) optimizations. For example, CQv2 recovery time on node boot<br>
is now twice as fast for some data sets.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11112" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11112/hovercard">#11112</a></p>
</li>
<li>
<p>Node startup time improvements. For some environments, nodes with very small on disk data sets<br>
now start about 25% quicker.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10989" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10989/hovercard">#10989</a></p>
</li>
<li>
<p>Quorum queues now support <a href="https://www.rabbitmq.com/docs/next/quorum-queues#priorities" rel="nofollow">priorities</a>. However,<br>
there are difference with how priorities work in classic queues.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10637" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10637/hovercard">#10637</a></p>
</li>
<li>
<p>Per-message metadata stored in the quorum queue Raft log now uses less disk space.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/8261" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/8261/hovercard">#8261</a></p>
</li>
<li>
<p>Single Active Consumer (SAC) implementation of quorum queues now <a href="https://www.rabbitmq.com/blog/2024/08/28/quorum-queues-in-4.0#consumer-priorities-combined-with-single-active-consumer" rel="nofollow">respects</a> consumer priorities.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/8261" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/8261/hovercard">#8261</a></p>
</li>
<li>
<p><code>rabbitmq.conf</code> now supports <a href="https://www.rabbitmq.com/docs/next/configure#configuration-encryption" rel="nofollow">encrypted values</a><br>
with a prefix:</p>
<div data-snippet-clipboard-copy-content="default_user = bunnies-444
default_pass = encrypted:F/bjQkteQENB4rMUXFKdgsJEpYMXYLzBY/AmcYG83Tg8AOUwYP7Oa0Q33ooNEpK9"><pre><span>default_user</span> = bunnies-444
<span>default_pass</span> = encrypted:F/bjQkteQENB4rMUXFKdgsJEpYMXYLzBY/AmcYG83Tg8AOUwYP7Oa0Q33ooNEpK9</pre></div>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11989" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11989/hovercard">#11989</a></p>
</li>
<li>
<p>All feature flags up to <code>3.13.0</code> have <a href="https://www.rabbitmq.com/docs/feature-flags#graduation" rel="nofollow">graduated</a> and are now mandatory.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11659" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11659/hovercard">#11659</a></p>
</li>
<li>
<p>Quorum queues now use a default <a href="https://www.rabbitmq.com/docs/next/quorum-queues#poison-message-handling" rel="nofollow">redelivery limit</a> of 20.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11937" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11937/hovercard">#11937</a></p>
</li>
<li>
<p><code>queue_master_locator</code> queue setting has been deprecated in favor of <code>queue_leader_locator</code> used by quorum queues<br>
and streams.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/10702" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/10702/hovercard">#10702</a></p>
</li>
</ul>
<h3>AMQP 1.0</h3>
<h4>Bug Fixes</h4>
<ul>
<li>
<p>AMQP 0-9-1 to AMQP 1.0 string data type conversion improvements.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11715" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11715/hovercard">#11715</a></p>
</li>
</ul>
<h4>Enhancements</h4>
<ul>
<li>
<p><a href="https://www.rabbitmq.com/blog/2024/08/05/native-amqp" rel="nofollow">AMQP 1.0 is now a core protocol</a> that is always enabled.<br>
Its plugin is now a no-op that only exists to simplify upgrades.</p>
<p>GitHub issues: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9022" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9022/hovercard">#9022</a>, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10662" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10662/hovercard">#10662</a></p>
</li>
<li>
<p>The AMQP 1.0 implementation is now significantly more efficient: its peak throughput is <a href="https://www.rabbitmq.com/blog/2024/08/21/amqp-benchmarks" rel="nofollow">more than double than that of 3.13.x</a><br>
on some workloads.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9022" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9022/hovercard">#9022</a></p>
</li>
<li>
<p>For AMQP 1.0, <a href="https://github.com/rabbitmq/rabbitmq-server/blob/v4.0.0">resource alarms</a> only block inbound <code>TRANSFER</code> frames instead of blocking all traffic.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/9022" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/9022/hovercard">#9022</a></p>
</li>
<li>
<p>AMQP 1.0 clients now can manage topologies (queues, exchanges, bindings).</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10559" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10559/hovercard">#10559</a></p>
</li>
<li>
<p>AMQP 1.0 implementation now supports a new (v2) address format for referencing queues, exchanges, and so on.</p>
<p>GitHub issues: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11604" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11604/hovercard">#11604</a>, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11618" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11618/hovercard">#11618</a></p>
</li>
<li>
<p>AMQP 1.0 implementation now supports consumer priorities.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11705" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11705/hovercard">#11705</a></p>
</li>
<li>
<p>Client-provided connection name will now be logged for AMQP 1.0 connections.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/11958" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/11958/hovercard">#11958</a></p>
</li>
</ul>
<h3>Streams</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>Stream filtering is now supported for AMQP 1.0 clients.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10098" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10098/hovercard">#10098</a></p>
</li>
</ul>
<h3>Prometheus Plugin</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p><a href="https://www.rabbitmq.com/docs/memory-use" rel="nofollow">Detailed memory breakdown</a> metrics are now exposed via the Prometheus scraping endpoint.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/11743" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/11743/hovercard">#11743</a></p>
</li>
<li>
<p>New per-exchange and per-queue metrics.</p>
<p>Contributed by <a data-hovercard-type="user" data-hovercard-url="/users/LoisSotoLopez/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/LoisSotoLopez">@LoisSotoLopez</a>.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11559" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11559/hovercard">#11559</a></p>
</li>
<li>
<p>Shovel and Federation metrics are now available via two new plugins: <code>rabbitmq_shovel_prometheus</code> and <code>rabbitmq_federation_prometheus</code>.</p>
<p>Contributed by <a data-hovercard-type="user" data-hovercard-url="/users/SimonUnge/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/SimonUnge">@SimonUnge</a>.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11942" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11942/hovercard">#11942</a></p>
</li>
</ul>
<h3>Shovel Plugin</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>Shovels now can be configured to use pre-declared topologies. This is primarily useful in environments where<br>
schema definition comes from <a href="https://www.rabbitmq.com/docs/definitions" rel="nofollow">definitions</a>.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/issues/10501" data-hovercard-type="issue" data-hovercard-url="/rabbitmq/rabbitmq-server/issues/10501/hovercard">#10501</a></p>
</li>
</ul>
<h3>Local Random Exchange Plugin</h3>
<p>This is an initial release that includes <a href="https://www.rabbitmq.com/docs/next/local-random-exchange" rel="nofollow">Local Random Exchange</a>.</p>
<p>GitHub issues: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/8334" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/8334/hovercard">#8334</a>, <a href="https://github.com/rabbitmq/rabbitmq-server/pull/10091" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/10091/hovercard">#10091</a>.</p>
<h3>STOMP Plugin</h3>
<h4>Enhancements</h4>
<ul>
<li>
<p>STOMP now supports consumer priorities.</p>
<p>GitHub issue: <a href="https://github.com/rabbitmq/rabbitmq-server/pull/11947" data-hovercard-type="pull_request" data-hovercard-url="/rabbitmq/rabbitmq-server/pull/11947/hovercard">#11947</a></p>
</li>
</ul>
<h3>Dependency Changes</h3>
<ul>
<li>Ra was <a href="https://github.com/rabbitmq/ra/releases">upgraded to <code>2.14.0</code></a></li>
<li>Khepri was <a href="https://github.com/rabbitmq/khepri/releases">upgraded to <code>0.16.0</code></a></li>
<li>Cuttlefish was <a href="https://github.com/Kyorai/cuttlefish/releases">upgraded to <code>3.4.0</code></a></li>
</ul>
<h2>Source Code Archives</h2>
<p>To obtain source code of the entire distribution, please download the archive named <code>rabbitmq-server-4.0.0-rc.2.tar.xz</code><br>
instead of the source tarball produced by GitHub.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twitter shut off API access; users volunteering their own data for an open API (109 pts)]]></title>
            <link>https://omarshehata.substack.com/p/twitter-shut-off-api-access-users</link>
            <guid>41581923</guid>
            <pubDate>Wed, 18 Sep 2024 16:23:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://omarshehata.substack.com/p/twitter-shut-off-api-access-users">https://omarshehata.substack.com/p/twitter-shut-off-api-access-users</a>, See on <a href="https://news.ycombinator.com/item?id=41581923">Hacker News</a></p>
Couldn't get https://omarshehata.substack.com/p/twitter-shut-off-api-access-users: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[CUNY paid Oracle $600M for its HR software (2013) (256 pts)]]></title>
            <link>http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html</link>
            <guid>41581687</guid>
            <pubDate>Wed, 18 Sep 2024 16:08:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html">http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html</a>, See on <a href="https://news.ycombinator.com/item?id=41581687">Hacker News</a></p>
Couldn't get http://pscbc.blogspot.com/2013/03/cuny-first-computer-system-to-aid.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Moshi: A speech-text foundation model for real time dialogue (184 pts)]]></title>
            <link>https://github.com/kyutai-labs/moshi</link>
            <guid>41581480</guid>
            <pubDate>Wed, 18 Sep 2024 15:56:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kyutai-labs/moshi">https://github.com/kyutai-labs/moshi</a>, See on <a href="https://news.ycombinator.com/item?id=41581480">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Moshi: a speech-text foundation model for real time dialogue</h2><a id="user-content-moshi-a-speech-text-foundation-model-for-real-time-dialogue" aria-label="Permalink: Moshi: a speech-text foundation model for real time dialogue" href="#moshi-a-speech-text-foundation-model-for-real-time-dialogue"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/workflows/precommit/badge.svg"><img src="https://github.com/kyutai-labs/moshi/workflows/precommit/badge.svg" alt="precommit badge"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/workflows/Rust%20CI/badge.svg"><img src="https://github.com/kyutai-labs/moshi/workflows/Rust%20CI/badge.svg" alt="rust ci badge"></a></p>
<p dir="auto"><a href="https://kyutai.org/Moshi.pdf" rel="nofollow">[Read the paper]</a> <a href="https://moshi.chat/" rel="nofollow">[Demo]</a> <a href="https://huggingface.co/collections/kyutai/moshi-v01-release-66eaeaf3302bef6bd9ad7acd" rel="nofollow">[Hugging Face]</a></p>
<p dir="auto"><a href="https://kyutai.org/Moshi.pdf" rel="nofollow">Moshi</a> is a speech-text foundation model and <strong>full-duplex</strong> spoken dialogue framework.
It uses <a href="https://kyutai.org/Moshi.pdf" rel="nofollow">Mimi</a>, a state-of-the-art streaming neural audio codec. Mimi processes 24 kHz audio, down to a 12.5 Hz representation
with a bandwidth of 1.1 kbps, in a fully streaming manner (latency of 80ms, the frame size),
yet performs better than existing, non-streaming, codec like
<a href="https://github.com/ZhangXInFD/SpeechTokenizer">SpeechTokenizer</a> (50 Hz, 4kbps), or <a href="https://github.com/haoheliu/SemantiCodec-inference">SemantiCodec</a> (50 Hz, 1.3kbps).</p>
<p dir="auto">Moshi models <strong>two streams of audio</strong>: one corresponds to Moshi, and the other one to the user.
At inference, the stream from the user is taken from the audio input,
and the one for Moshi is sampled from the model's output. Along these two audio streams, Moshi predicts text tokens corresponding to its own speech, its <strong>inner monologue</strong>,
which greatly improves the quality of its generation. A small Depth Transformer models inter codebook dependencies for a given time step,
while a large, 7B parameter Temporal Transformer models the temporal dependencies. Moshi achieves a theoretical latency
of 160ms (80ms for the frame size of Mimi + 80ms of acoustic delay), with a practical overall latency as low as 200ms on an L4 GPU.</p>
<p dir="auto"><a href="https://moshi.chat/" rel="nofollow">Talk to Moshi</a> now on our live demo.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/blob/main/moshi.png"><img src="https://github.com/kyutai-labs/moshi/raw/main/moshi.png" alt="Schema representing the structure of Moshi. Moshi models two streams of audio:
    one corresponds to Moshi, and the other one to the user. At inference, the audio stream of the user is taken from the audio input, and the audio stream for Moshi is sampled from the model's output. Along that, Moshi predicts text tokens corresponding to its own speech for improved accuracy. A small Depth Transformer models inter codebook dependencies for a given step." width="650px"></a></p>
<p dir="auto">Mimi builds on previous neural audio codecs such as <a href="https://arxiv.org/abs/2107.03312" rel="nofollow">SoundStream</a>
and <a href="https://github.com/facebookresearch/encodec">EnCodec</a>, adding a Transformer both in the encoder and decoder,
and adapting the strides to match an overall frame rate of 12.5 Hz. This allows Mimi to get closer to the
average frame rate of text tokens (~3-4 Hz), and limit the number of autoregressive steps in Moshi.
Similarly to SpeechTokenizer, Mimi uses a distillation loss so that the first codebook tokens match
a self-supervised representation from <a href="https://arxiv.org/abs/2110.13900" rel="nofollow">WavLM</a>, which allows modeling semantic and acoustic information with a single model. Interestingly, while Mimi is fully causal and streaming, it learns to match sufficiently well the non-causal
representation from WavLM, without introducing any delays. Finally, and similarly to <a href="https://arxiv.org/pdf/2210.14090" rel="nofollow">EBEN</a>,
Mimi uses <strong>only an adversarial training loss</strong>, along with feature matching, showing strong improvements in terms of
subjective quality despite its low bitrate.</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/kyutai-labs/moshi/blob/main/mimi.png"><img src="https://github.com/kyutai-labs/moshi/raw/main/mimi.png" alt="Schema representing the structure of Mimi, our proposed neural codec. Mimi contains a Transformer
in both its encoder and decoded, and achieves a frame rate closer to that of text tokens. This allows us to reduce
the number of auto-regressive steps taken by Moshi, thus reducing the latency of the model." width="800px"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Organisation of the repository</h2><a id="user-content-organisation-of-the-repository" aria-label="Permalink: Organisation of the repository" href="#organisation-of-the-repository"></a></p>
<p dir="auto">There are three separate versions of the moshi inference stack in this repo.</p>
<ul dir="auto">
<li>The Python version using PyTorch is in the <a href="https://github.com/kyutai-labs/moshi/blob/main/moshi"><code>moshi/</code></a> directory.</li>
<li>The Python version using MLX for M series Macs is in the <a href="https://github.com/kyutai-labs/moshi/blob/main/moshi_mlx"><code>moshi_mlx/</code></a> directory.</li>
<li>The Rust version used in production is in the <a href="https://github.com/kyutai-labs/moshi/blob/main/rust"><code>rust/</code></a> directory.
This contains in particular a Mimi implementation in Rust, with Python bindings available
as <code>rustymimi</code>.</li>
</ul>
<p dir="auto">Finally, the code for the live demo is provided in the <a href="https://github.com/kyutai-labs/moshi/blob/main/client"><code>client/</code></a> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Models</h2><a id="user-content-models" aria-label="Permalink: Models" href="#models"></a></p>
<p dir="auto">We release three models:</p>
<ul dir="auto">
<li>our speech codec Mimi,</li>
<li>Moshi fine-tuned on a male synthetic voice (Moshiko),</li>
<li>Moshi fine-tuned on a female synthetic voice (Moshika).</li>
</ul>
<p dir="auto">Depending on the backend, the file format and quantization available will vary. Here is the list
of the HuggingFace repo with each model. Mimi is bundled in each of those, and always use the same checkpoint format.</p>
<ul dir="auto">
<li>Moshika for PyTorch (bf16): <a href="https://huggingface.co/kyutai/moshika-pytorch-bf16" rel="nofollow">kyutai/moshika-pytorch-bf16</a>.</li>
<li>Moshiko for PyTorch (bf16): <a href="https://huggingface.co/kyutai/moshiko-pytorch-bf16" rel="nofollow">kyutai/moshiko-pytorch-bf16</a>.</li>
<li>Moshika for MLX (int4, int8, bf16): <a href="https://huggingface.co/kyutai/moshika-mlx-q4" rel="nofollow">kyutai/moshika-mlx-q4</a>, <a href="https://huggingface.co/kyutai/moshika-mlx-q8" rel="nofollow">kyutai/moshika-mlx-q8</a>,  <a href="https://huggingface.co/kyutai/moshika-mlx-bf16" rel="nofollow">kyutai/moshika-mlx-bf16</a>.</li>
<li>Moshiko for MLX (int4, int8, bf16): <a href="https://huggingface.co/kyutai/moshiko-mlx-q4" rel="nofollow">kyutai/moshiko-mlx-q4</a>, <a href="https://huggingface.co/kyutai/moshiko-mlx-q8" rel="nofollow">kyutai/moshiko-mlx-q8</a>,  <a href="https://huggingface.co/kyutai/moshiko-mlx-bf16" rel="nofollow">kyutai/moshiko-mlx-bf16</a>.</li>
<li>Moshika for Rust/Candle (int8, bf16): <a href="https://huggingface.co/kyutai/moshika-candle-q8" rel="nofollow">kyutai/moshika-candle-q8</a>,  <a href="https://huggingface.co/kyutai/moshika-candle-bf16" rel="nofollow">kyutai/moshika-mlx-bf16</a>.</li>
<li>Moshiko for Rust/Candle (int8, bf16): <a href="https://huggingface.co/kyutai/moshiko-candle-q8" rel="nofollow">kyutai/moshiko-candle-q8</a>,  <a href="https://huggingface.co/kyutai/moshiko-candle-bf16" rel="nofollow">kyutai/moshiko-mlx-bf16</a>.</li>
</ul>
<p dir="auto">All models are released under the CC-BY 4.0 license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto">You will need at least Python 3.10. For specific requirements, please check the individual backends
directories. You can install the PyTorch and MLX clients with the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install moshi      # moshi PyTorch, from PyPI
pip install moshi_mlx  # moshi MLX, from PyPI
# Or the bleeding edge versions for Moshi and Moshi-MLX.
pip install -e &quot;git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi&amp;subdirectory=moshi&quot;
pip install -e &quot;git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi_mlx&amp;subdirectory=moshi_mlx&quot;

pip install rustymimi  # mimi, rust implementation with Python bindings from PyPI"><pre>pip install moshi      <span><span>#</span> moshi PyTorch, from PyPI</span>
pip install moshi_mlx  <span><span>#</span> moshi MLX, from PyPI</span>
<span><span>#</span> Or the bleeding edge versions for Moshi and Moshi-MLX.</span>
pip install -e <span><span>"</span>git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi&amp;subdirectory=moshi<span>"</span></span>
pip install -e <span><span>"</span>git+https://git@github.com/kyutai-labs/moshi.git#egg=moshi_mlx&amp;subdirectory=moshi_mlx<span>"</span></span>

pip install rustymimi  <span><span>#</span> mimi, rust implementation with Python bindings from PyPI</span></pre></div>
<p dir="auto">If you get an error when installing <code>moshi_mlx</code> or <code>rustymimi</code> (which <code>moshi_mlx</code> depends on),
you might need to install the <a href="https://rustup.rs/" rel="nofollow">Rust toolchain</a> to install <code>rustymimi</code> from sources.</p>
<p dir="auto">While we hope that the present codebase will work on Windows, we do not provide official support for it.
We have tested the MLX version on a MacBook Pro M3. At the moment, we do not support quantization
for the PyTorch version, so you will need a GPU with a significant amount of memory (24GB).</p>
<p dir="auto">For using the Rust backend, you will need a recent version of the <a href="https://rustup.rs/" rel="nofollow">Rust toolchain</a>.
To compile GPU support, you will also need the <a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow">CUDA</a> properly installed for your GPU, in particular with <code>nvcc</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto">If you wish to install from a clone of this repository, maybe to further develop Moshi, you can do the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# From the root of the clone of the repo
pip install -e 'moshi[dev]'
pip install -e 'moshi_mlx[dev]'
pre-commit install"><pre><span><span>#</span> From the root of the clone of the repo</span>
pip install -e <span><span>'</span>moshi[dev]<span>'</span></span>
pip install -e <span><span>'</span>moshi_mlx[dev]<span>'</span></span>
pre-commit install</pre></div>
<p dir="auto">If you wish to build locally <code>rustymimi</code> (assuming you have Rust properly installed):</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install maturin
maturin dev -r -m rust/mimi-pyo3/Cargo.toml"><pre>pip install maturin
maturin dev -r -m rust/mimi-pyo3/Cargo.toml</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Python (PyTorch)</h2><a id="user-content-python-pytorch" aria-label="Permalink: Python (PyTorch)" href="#python-pytorch"></a></p>
<p dir="auto">The PyTorch based API can be found in the <code>moshi</code> directory. It provides a streaming
version of the audio tokenizer (mimi) and the language model (moshi).</p>
<p dir="auto">In order to run in interactive mode, you need to start a server which will
run the model, you can then use either the web UI or a command line client.</p>
<p dir="auto">Start the server with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m moshi.server [--gradio-tunnel] [--hf-repo kyutai/moshika-pytorch-bf16]"><pre>python -m moshi.server [--gradio-tunnel] [--hf-repo kyutai/moshika-pytorch-bf16]</pre></div>
<p dir="auto">And then access the web UI on <a href="http://localhost:8998/" rel="nofollow">localhost:8998</a>. If your GPU is on a distant machine
with no direct access, <code>--gradio-tunnel</code> will create a tunnel with a URL accessible from anywhere.
Keep in mind that this tunnel goes through the US and can add significant latency (up to 500ms from Europe).
You can use <code>--gradio-tunnel-token</code> to set a fixed secret token and reuse the same address over time.
Alternatively, you might want to use SSH to redirect your connection.</p>
<p dir="auto">You can use <code>--hf-repo</code> to select a different pretrained model, by setting the proper Hugging Face repository.</p>
<p dir="auto">Accessing a server that is not localhost via http may cause issues with using
the microphone in the web UI (in some browsers this is only allowed using
https).</p>
<p dir="auto">A local client is also available, as</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m moshi.client [--url URL_TO_GRADIO]"><pre>python -m moshi.client [--url URL_TO_GRADIO]</pre></div>
<p dir="auto">However note that, unlike the web browser, this client is barebone: It does not perform any echo cancellation,
nor does it try to compensate for a growing lag by skipping frames.</p>
<p dir="auto">For more information, in particular on how to use the API directly, please
checkout <a href="https://github.com/kyutai-labs/moshi/blob/main/moshi/README.md">moshi/README.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Python (MLX) for local inference on macOS</h2><a id="user-content-python-mlx-for-local-inference-on-macos" aria-label="Permalink: Python (MLX) for local inference on macOS" href="#python-mlx-for-local-inference-on-macos"></a></p>
<p dir="auto">Once you have installed <code>moshi_mlx</code>, you can run</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m moshi_mlx.local -q 4   # weights quantized to 4 bits
python -m moshi_mlx.local -q 8   # weights quantized to 8 bits
# And using a different pretrained model:
python -m moshi_mlx.local -q 4 --hf-repo kyutai/moshika-mlx-q4
python -m moshi_mlx.local -q 8 --hf-repo kyutai/moshika-mlx-q8
# be careful to always match the `-q` and `--hf-repo` flag."><pre>python -m moshi_mlx.local -q 4   <span><span>#</span> weights quantized to 4 bits</span>
python -m moshi_mlx.local -q 8   <span><span>#</span> weights quantized to 8 bits</span>
<span><span>#</span> And using a different pretrained model:</span>
python -m moshi_mlx.local -q 4 --hf-repo kyutai/moshika-mlx-q4
python -m moshi_mlx.local -q 8 --hf-repo kyutai/moshika-mlx-q8
<span><span>#</span> be careful to always match the `-q` and `--hf-repo` flag.</span></pre></div>
<p dir="auto">This command line interface is also barebone. It does not perform any echo cancellation,
nor does it try to compensate for a growing lag by skipping frames.</p>
<p dir="auto">Alternatively you can run <code>python -m moshi_mlx.local_web</code> to use
the web UI, the connection is via http and will be at <a href="http://localhost:8998/" rel="nofollow">localhost:8998</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Rust</h2><a id="user-content-rust" aria-label="Permalink: Rust" href="#rust"></a></p>
<p dir="auto">In order to run the Rust inference server, use the following command from within
the <code>rust</code> directory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run --features cuda --bin moshi-backend -r -- --config moshi-backend/config.json standalone"><pre>cargo run --features cuda --bin moshi-backend -r -- --config moshi-backend/config.json standalone</pre></div>
<p dir="auto">When using macOS, you can replace <code>--features cuda</code> with <code>--features metal</code>.</p>
<p dir="auto">Alternatively you can use <code>config-q8.json</code> rather than <code>config.json</code> to use the
quantized q8 model. You can select a different pretrained model, e.g. Moshika,
by changing the <code>"hf_repo"</code> key in either file.</p>
<p dir="auto">Once the server has printed 'standalone worker listening', you can use the web
UI. By default the Rust server uses https so it will be at
<a href="https://localhost:8998/" rel="nofollow">localhost:8998</a>.</p>
<p dir="auto">You will get warnings about the site being unsafe. When using chrome you
can bypass these by selecting "Details" or "Advanced", then "Visit this unsafe
site" or "Proceed to localhost (unsafe)".</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Clients</h2><a id="user-content-clients" aria-label="Permalink: Clients" href="#clients"></a></p>
<p dir="auto">We recommend using the web UI as it provides additional echo cancellation that helps
the overall model quality. Note that most command will directly serve this UI
in the provided URL, and there is in general nothing more to do.</p>
<p dir="auto">Alternatively, we provide command line interfaces
for the Rust and Python versions, the protocol is the same as with the web UI so
there is nothing to change on the server side.</p>
<p dir="auto">For reference, here is the list of clients for Moshi.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Rust Command Line</h3><a id="user-content-rust-command-line" aria-label="Permalink: Rust Command Line" href="#rust-command-line"></a></p>
<p dir="auto">From within the <code>rust</code> directory, run the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run --bin moshi-cli -r -- tui --host localhost"><pre>cargo run --bin moshi-cli -r -- tui --host localhost</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python with PyTorch</h3><a id="user-content-python-with-pytorch" aria-label="Permalink: Python with PyTorch" href="#python-with-pytorch"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">WebUI</h3><a id="user-content-webui" aria-label="Permalink: WebUI" href="#webui"></a></p>
<p dir="auto">The web UI can be built from this repo via the
following steps (these will require <code>npm</code> being installed).</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd client
npm install
npm run build"><pre><span>cd</span> client
npm install
npm run build</pre></div>
<p dir="auto">The web UI can then be found in the <code>client/dist</code> directory.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The present code is provided under the MIT license for the Python parts, and Apache license for the Rust backend.
The web client code is provided under the MIT license.
Note that parts of this code is based on <a href="https://github.com/facebookresearch/audiocraft">AudioCraft</a>, released under
the MIT license.</p>
<p dir="auto">The weights for the models are released under the CC-BY 4.0 license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citation</h2><a id="user-content-citation" aria-label="Permalink: Citation" href="#citation"></a></p>
<p dir="auto">If you use either Mimi or Moshi, please cite the following paper,</p>
<div data-snippet-clipboard-copy-content="@techreport{kyutai2024moshi,
    author = {Alexandre D\'efossez and Laurent Mazar\'e and Manu Orsini and Am\'elie Royer and
			  Patrick P\'erez and Herv\'e J\'egou and Edouard Grave and Neil Zeghidour},
    title = {Moshi: a speech-text foundation model for real-time dialogue},
    institution = {Kyutai},
    year={2024},
    month={September},
    url={http://kyutai.org/Moshi.pdf},
}"><pre><code>@techreport{kyutai2024moshi,
    author = {Alexandre D\'efossez and Laurent Mazar\'e and Manu Orsini and Am\'elie Royer and
			  Patrick P\'erez and Herv\'e J\'egou and Edouard Grave and Neil Zeghidour},
    title = {Moshi: a speech-text foundation model for real-time dialogue},
    institution = {Kyutai},
    year={2024},
    month={September},
    url={http://kyutai.org/Moshi.pdf},
}
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hezbollah hand-held radios explode, killing three, one day after pager blasts (182 pts)]]></title>
            <link>https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/</link>
            <guid>41580853</guid>
            <pubDate>Wed, 18 Sep 2024 15:19:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/">https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/</a>, See on <a href="https://news.ycombinator.com/item?id=41580853">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/hezbollah-pager-explosions-live-2024-09-17/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[0day Contest for End-of-Life Devices Announced (205 pts)]]></title>
            <link>https://www.districtcon.org/junkyard</link>
            <guid>41580502</guid>
            <pubDate>Wed, 18 Sep 2024 14:55:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.districtcon.org/junkyard">https://www.districtcon.org/junkyard</a>, See on <a href="https://news.ycombinator.com/item?id=41580502">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-blend-mode="NORMAL" data-block-type="2" data-blur="{&quot;enabled&quot;:true,&quot;filterType&quot;:&quot;backdrop&quot;,&quot;blurRadius&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:15.0}}" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" id="block-29c9efa8396ec1fdaff4">
  <h4>Give Us your Best (Or Worst) Zero-day VulnS.</h4><blockquote><pre><code>The Junkyard is a platform to showcase novel security research and support hobby and career development for security researchers.

We want you to bring your most impactful, creative, or most meme-worthy bugs in end-of-life (EOL) products, and demonstrate them live on stage. 

Winners get 💰 prizes 💰 to further future vulnerability research. First 20 submissions accepted will get additional swag!</code></pre></blockquote><h4>What’s In SCOPE? </h4><blockquote><pre><code>Any product (software or hardware) publicly listed by the vendor as EOL-ed at least one day before submission.
</code></pre><pre><code>In keeping with the conference ethos, we also require that:</code></pre><pre><code>- You commit as the researcher to responsible disclosure of the vulnerability (60-90 day disclosure windows with vendor);&nbsp;</code></pre><pre><code>- You conducted your research in accordance with US law and ethical practices; and</code></pre><pre><code>- You are not under any restrictions or sanctions from the US. </code></pre></blockquote><h4>PRIZES</h4><blockquote><pre><code>Prizes will depend on final sponsorship support, but are expected to range from <span data-text-attribute-id="91e7ca3d-2f2e-4329-86c9-dfc08b4b08f7">$100 to $5,000 USD</span>. These may change in cases of exceptional brilliance or lack thereof. All prizes and acceptance of results to the event are at DistrictCon’s sole discretion.
</code></pre><pre><code><span data-text-attribute-id="73c07bd6-ef0e-43f0-8094-b6baddc50c8d">Prizes will be awarded in the following categories to the top 2 scorers</span> (winner and runner up), so plan accordingly:</code></pre><p>❗ Most Impactful System ❗</p><p>🤡 Best Meme Target 🤡 </p><p>😈 Most Innovative Exploitation Technique 😈</p></blockquote><h4>WHAT SHOULD I EXPECT / How does the contest work?</h4><blockquote><pre><code>1️⃣ <span data-text-attribute-id="8a35ceb8-b046-4c89-b8c0-e1795c9edd31">Submit Your Target to DistrictCon
</span>
- Fill out the form on this page, tell us what target you're exploiting, and how much help you'll need with disclosure. Get proof that the target is EOL.

2️⃣ <span data-text-attribute-id="c3955729-e12f-41b2-bb99-e3384ea686eb">Disclose the Bug to the Vendor 
</span>
- We can help if needed!
 
3️⃣ <span data-text-attribute-id="d76b7490-2b52-4191-bc09-91b5d63d09e5">Create a Cover Name, 5-10 Min Talk + Demo</span>

- Attendees won’t know what your target will be until you reveal it on stage! The cover name is for the agenda.

4️⃣ <span data-text-attribute-id="a82afb1f-af00-494d-8e45-378c3b1ba9f0">Give us your Target Ahead of Time to Prep for Demo</span>

- We'll restore the target to a default configuration (in consultation with you) and prepare to have it on-stage for you to demonstrate against. If this doesn’t work for you, the item is big, etc - we’ll work with you for a video option, or try and source the device locally. 

5️⃣ <span data-text-attribute-id="f3ca0378-ac3b-4e4d-9779-3f4c963cd82a">Compete and Win!</span> 💰

When you come up on stage, you’ll share:</code></pre><pre><code>- Who you are, as much as you want</code></pre><pre><code>- The target, and why it matters</code></pre><pre><code>- Demonstrate the bug, explain how it works and the impact.

- Nothing will be live-streamed or recorded without your permission.</code></pre></blockquote><h4>Frequently asked Questions</h4><blockquote><pre><code><span data-text-attribute-id="ee601f96-5148-4251-b275-aa13197193f7">1) Is an EOL software or product in scope, even if there are components within it that are not EOL?
</span>
A: Yes, but there are caveats: the spirit of this event is to help identify and notify vendors of vulnerabilities in EOL software or products, and all submissions should be in this spirit.
If an EOL item has components that are not EOL within it, that’s fine. However, non-EOL components should not be the focus of the vulnerability or chain - we are not looking for exploits in current systems. If you have questions, please reach out via the submission process and we will work with you to ensure the submission is appropriate for the event.</code></pre><pre><code>
<span data-text-attribute-id="a64773bc-7087-4f7b-8765-1464461c1fb0">2) What should my Junkyard pitch at DistrictCon look like? </span>

For the maximum audience enjoyment and clarity of your awesome work, we prefer you presenting a live demo against the EOL system. We know this won't always be practical, so we will work with you during submission review to find the right way. As part of your demonstrated chain, the judges are (among other things) looking for proof of control and execution. 

Given the broad swath of valid targets, we know this may differ in what that means, but two "traditional" examples are to pop a shell and confirm root privileges, or demonstrate arbitrary code execution.</code></pre><pre><code>
<span data-text-attribute-id="4f60b934-ec85-40cd-99e1-da056f2b6634">3) What is EOL for Open Source, specifically with an archived repository? </span>

If the software you’re attempting to exploit is an archived repository, first ask if (a) the software moved to a new home and (b) is the archived repo a fork and the substantially similar project is still active? 

If the maintainer confirms they are not maintaining the given version or product, you should be good to go. Otherwise feel free to reach out to the DistrictCon Junkyard Team via the submission process, or via outreach@districtcon.org with additional questions.</code></pre></blockquote><h4>I have More questions.</h4><blockquote><pre><code>Additional details such as the responsible disclosure timelines and any assistance from the conference will be published when available. Please contact outreach@districtcon.org for more details.</code></pre><pre><code>In the case of similar bugs, our team will work privately with the submitters to deduplicate appropriately. </code></pre></blockquote>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A high-performance, zero-overhead, extensible Python compiler using LLVM (146 pts)]]></title>
            <link>https://github.com/exaloop/codon</link>
            <guid>41580326</guid>
            <pubDate>Wed, 18 Sep 2024 14:44:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/exaloop/codon">https://github.com/exaloop/codon</a>, See on <a href="https://news.ycombinator.com/item?id=41580326">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
 <a target="_blank" rel="noopener noreferrer" href="https://github.com/exaloop/codon/blob/develop/docs/img/codon.png?raw=true"><img src="https://github.com/exaloop/codon/raw/develop/docs/img/codon.png?raw=true" width="600" alt="Codon"></a>
</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">
  <a href="https://docs.exaloop.io/codon" rel="nofollow"><b>Docs</b></a>
  &nbsp;·&nbsp;
  <a href="https://docs.exaloop.io/codon/general/faq" rel="nofollow"><b>FAQ</b></a>
  &nbsp;·&nbsp;
  <a href="https://blog.exaloop.io/" rel="nofollow"><b>Blog</b></a>
  &nbsp;·&nbsp;
  <a href="https://join.slack.com/t/exaloop/shared_invite/zt-1jusa4kc0-T3rRWrrHDk_iZ1dMS8s0JQ" rel="nofollow">Chat</a>
  &nbsp;·&nbsp;
  <a href="https://docs.exaloop.io/codon/general/roadmap" rel="nofollow">Roadmap</a>
  &nbsp;·&nbsp;
  <a href="https://exaloop.io/benchmarks" rel="nofollow">Benchmarks</a>
</h3><a id="user-content---docs----faq----blog----chat----roadmap----benchmarks" aria-label="Permalink: Docs
  &nbsp;·&nbsp;
  FAQ
  &nbsp;·&nbsp;
  Blog
  &nbsp;·&nbsp;
  Chat
  &nbsp;·&nbsp;
  Roadmap
  &nbsp;·&nbsp;
  Benchmarks" href="#--docs----faq----blog----chat----roadmap----benchmarks"></a></p>
<a href="https://github.com/exaloop/codon/actions/workflows/ci.yml">
  <img src="https://github.com/exaloop/codon/actions/workflows/ci.yml/badge.svg" alt="Build Status">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is Codon?</h2><a id="user-content-what-is-codon" aria-label="Permalink: What is Codon?" href="#what-is-codon"></a></p>
<p dir="auto">Codon is a high-performance Python implementation that compiles to native machine code without
any runtime overhead. Typical speedups over vanilla Python are on the order of 10-100x or more, on
a single thread. Codon's performance is typically on par with (and sometimes better than) that of
C/C++. Unlike Python, Codon supports native multithreading, which can lead to speedups many times
higher still.</p>
<p dir="auto"><em>Think of Codon as Python reimagined for static, ahead-of-time compilation, built from the ground
up with best possible performance in mind.</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Goals</h3><a id="user-content-goals" aria-label="Permalink: Goals" href="#goals"></a></p>
<ul dir="auto">
<li>💡 <strong>No learning curve:</strong> Be as close to CPython as possible in terms of syntax, semantics and libraries</li>
<li>🚀 <strong>Top-notch performance:</strong> At <em>least</em> on par with low-level languages like C, C++ or Rust</li>
<li>💻 <strong>Hardware support:</strong> Full, seamless support for multicore programming, multithreading (no GIL!), GPU and more</li>
<li>📈 <strong>Optimizations:</strong> Comprehensive optimization framework that can target high-level Python constructs
and libraries</li>
<li>🔋 <strong>Interoperability:</strong> Full interoperability with Python's ecosystem of packages and libraries</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Non-goals</h3><a id="user-content-non-goals" aria-label="Permalink: Non-goals" href="#non-goals"></a></p>
<ul dir="auto">
<li>
<p dir="auto">❌ <em>Drop-in replacement for CPython:</em> Codon is not a drop-in replacement for CPython. There are some
aspects of Python that are not suitable for static compilation — we don't support these in Codon.
There are ways to use Codon in larger Python codebases via its <a href="https://docs.exaloop.io/codon/interoperability/decorator" rel="nofollow">JIT decorator</a>
or <a href="https://docs.exaloop.io/codon/interoperability/pyext" rel="nofollow">Python extension backend</a>. Codon also supports
calling any Python module via its <a href="https://docs.exaloop.io/codon/interoperability/python" rel="nofollow">Python interoperability</a>.
See also <a href="https://docs.exaloop.io/codon/general/differences" rel="nofollow"><em>"Differences with Python"</em></a> in the docs.</p>
</li>
<li>
<p dir="auto">❌ <em>New syntax and language constructs:</em> We try to avoid adding new syntax, keywords or other language
features as much as possible. While Codon does add some new syntax in a couple places (e.g. to express
parallelism), we try to make it as familiar and intuitive as possible.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">Pre-built binaries for Linux (x86_64) and macOS (x86_64 and arm64) are available alongside <a href="https://github.com/exaloop/codon/releases">each release</a>.
Download and install with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/bin/bash -c &quot;$(curl -fsSL https://exaloop.io/install.sh)&quot;"><pre>/bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://exaloop.io/install.sh<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto">Or you can <a href="https://docs.exaloop.io/codon/advanced/build" rel="nofollow">build from source</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Codon is a Python-compatible language, and many Python programs will work with few if any modifications:</p>
<div dir="auto" data-snippet-clipboard-copy-content="def fib(n):
    a, b = 0, 1
    while a < n:
        print(a, end=' ')
        a, b = b, a+b
    print()
fib(1000)"><pre><span>def</span> <span>fib</span>(<span>n</span>):
    <span>a</span>, <span>b</span> <span>=</span> <span>0</span>, <span>1</span>
    <span>while</span> <span>a</span> <span>&lt;</span> <span>n</span>:
        <span>print</span>(<span>a</span>, <span>end</span><span>=</span><span>' '</span>)
        <span>a</span>, <span>b</span> <span>=</span> <span>b</span>, <span>a</span><span>+</span><span>b</span>
    <span>print</span>()
<span>fib</span>(<span>1000</span>)</pre></div>
<p dir="auto">The <code>codon</code> compiler has a number of options and modes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# compile and run the program
codon run fib.py
# 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987

# compile and run the program with optimizations enabled
codon run -release fib.py
# 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987

# compile to executable with optimizations enabled
codon build -release -exe fib.py
./fib
# 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987

# compile to LLVM IR file with optimizations enabled
codon build -release -llvm fib.py
# outputs file fib.ll"><pre><span><span>#</span> compile and run the program</span>
codon run fib.py
<span><span>#</span> 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>

<span><span>#</span> compile and run the program with optimizations enabled</span>
codon run -release fib.py
<span><span>#</span> 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>

<span><span>#</span> compile to executable with optimizations enabled</span>
codon build -release -exe fib.py
./fib
<span><span>#</span> 0 1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987</span>

<span><span>#</span> compile to LLVM IR file with optimizations enabled</span>
codon build -release -llvm fib.py
<span><span>#</span> outputs file fib.ll</span></pre></div>
<p dir="auto">See <a href="https://docs.exaloop.io/codon/general/intro" rel="nofollow">the docs</a> for more options and examples.</p>
<p dir="auto">You can import and use any Python package from Codon. For example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from python import matplotlib.pyplot as plt
data = [x**2 for x in range(10)]
plt.plot(data)
plt.show()"><pre><span>from</span> <span>python</span> <span>import</span> <span>matplotlib</span>.<span>pyplot</span> <span>as</span> <span>plt</span>
<span>data</span> <span>=</span> [<span>x</span><span>**</span><span>2</span> <span>for</span> <span>x</span> <span>in</span> <span>range</span>(<span>10</span>)]
<span>plt</span>.<span>plot</span>(<span>data</span>)
<span>plt</span>.<span>show</span>()</pre></div>
<p dir="auto">(Just remember to set the <code>CODON_PYTHON</code> environment variable to the CPython shared library,
as explained in the <a href="https://docs.exaloop.io/codon/interoperability/python" rel="nofollow">the docs</a>.)</p>
<p dir="auto">This prime counting example showcases Codon's <a href="https://www.openmp.org/" rel="nofollow">OpenMP</a> support, enabled
with the addition of one line. The <code>@par</code> annotation tells the compiler to parallelize the
following <code>for</code>-loop, in this case using a dynamic schedule, chunk size of 100, and 16 threads.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from sys import argv

def is_prime(n):
    factors = 0
    for i in range(2, n):
        if n % i == 0:
            factors += 1
    return factors == 0

limit = int(argv[1])
total = 0

@par(schedule='dynamic', chunk_size=100, num_threads=16)
for i in range(2, limit):
    if is_prime(i):
        total += 1

print(total)"><pre><span>from</span> <span>sys</span> <span>import</span> <span>argv</span>

<span>def</span> <span>is_prime</span>(<span>n</span>):
    <span>factors</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>2</span>, <span>n</span>):
        <span>if</span> <span>n</span> <span>%</span> <span>i</span> <span>==</span> <span>0</span>:
            <span>factors</span> <span>+=</span> <span>1</span>
    <span>return</span> <span>factors</span> <span>==</span> <span>0</span>

<span>limit</span> <span>=</span> <span>int</span>(<span>argv</span>[<span>1</span>])
<span>total</span> <span>=</span> <span>0</span>

<span>@<span>par</span>(<span>schedule</span><span>=</span><span>'dynamic'</span>, <span>chunk_size</span><span>=</span><span>100</span>, <span>num_threads</span><span>=</span><span>16</span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span>(<span>2</span>, <span>limit</span>):
    <span>if</span> <span>is_prime</span>(<span>i</span>):
        <span>total</span> <span>+=</span> <span>1</span>

<span>print</span>(<span>total</span>)</pre></div>
<p dir="auto">Codon supports writing and executing GPU kernels. Here's an example that computes the
<a href="https://en.wikipedia.org/wiki/Mandelbrot_set" rel="nofollow">Mandelbrot set</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import gpu

MAX    = 1000  # maximum Mandelbrot iterations
N      = 4096  # width and height of image
pixels = [0 for _ in range(N * N)]

def scale(x, a, b):
    return a + (x/N)*(b - a)

@gpu.kernel
def mandelbrot(pixels):
    idx = (gpu.block.x * gpu.block.dim.x) + gpu.thread.x
    i, j = divmod(idx, N)
    c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))
    z = 0j
    iteration = 0

    while abs(z) <= 2 and iteration < MAX:
        z = z**2 + c
        iteration += 1

    pixels[idx] = int(255 * iteration/MAX)

mandelbrot(pixels, grid=(N*N)//1024, block=1024)"><pre><span>import</span> <span>gpu</span>

<span>MAX</span>    <span>=</span> <span>1000</span>  <span># maximum Mandelbrot iterations</span>
<span>N</span>      <span>=</span> <span>4096</span>  <span># width and height of image</span>
<span>pixels</span> <span>=</span> [<span>0</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span>(<span>N</span> <span>*</span> <span>N</span>)]

<span>def</span> <span>scale</span>(<span>x</span>, <span>a</span>, <span>b</span>):
    <span>return</span> <span>a</span> <span>+</span> (<span>x</span><span>/</span><span>N</span>)<span>*</span>(<span>b</span> <span>-</span> <span>a</span>)

<span>@<span>gpu</span>.<span>kernel</span></span>
<span>def</span> <span>mandelbrot</span>(<span>pixels</span>):
    <span>idx</span> <span>=</span> (<span>gpu</span>.<span>block</span>.<span>x</span> <span>*</span> <span>gpu</span>.<span>block</span>.<span>dim</span>.<span>x</span>) <span>+</span> <span>gpu</span>.<span>thread</span>.<span>x</span>
    <span>i</span>, <span>j</span> <span>=</span> <span>divmod</span>(<span>idx</span>, <span>N</span>)
    <span>c</span> <span>=</span> <span>complex</span>(<span>scale</span>(<span>j</span>, <span>-</span><span>2.00</span>, <span>0.47</span>), <span>scale</span>(<span>i</span>, <span>-</span><span>1.12</span>, <span>1.12</span>))
    <span>z</span> <span>=</span> <span>0j</span>
    <span>iteration</span> <span>=</span> <span>0</span>

    <span>while</span> <span>abs</span>(<span>z</span>) <span>&lt;=</span> <span>2</span> <span>and</span> <span>iteration</span> <span>&lt;</span> <span>MAX</span>:
        <span>z</span> <span>=</span> <span>z</span><span>**</span><span>2</span> <span>+</span> <span>c</span>
        <span>iteration</span> <span>+=</span> <span>1</span>

    <span>pixels</span>[<span>idx</span>] <span>=</span> <span>int</span>(<span>255</span> <span>*</span> <span>iteration</span><span>/</span><span>MAX</span>)

<span>mandelbrot</span>(<span>pixels</span>, <span>grid</span><span>=</span>(<span>N</span><span>*</span><span>N</span>)<span>//</span><span>1024</span>, <span>block</span><span>=</span><span>1024</span>)</pre></div>
<p dir="auto">GPU programming can also be done using the <code>@par</code> syntax with <code>@par(gpu=True)</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<p dir="auto">Please see <a href="https://docs.exaloop.io/codon" rel="nofollow">docs.exaloop.io</a> for in-depth documentation.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hezbollah hand-held radios detonate across Lebanon, sources say (236 pts)]]></title>
            <link>https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/</link>
            <guid>41580205</guid>
            <pubDate>Wed, 18 Sep 2024 14:34:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/">https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/</a>, See on <a href="https://news.ycombinator.com/item?id=41580205">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/middle-east/israel-planted-explosives-hezbollahs-taiwan-made-pagers-say-sources-2024-09-18/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bento: Jupyter Notebooks at Meta (164 pts)]]></title>
            <link>https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/</link>
            <guid>41580166</guid>
            <pubDate>Wed, 18 Sep 2024 14:30:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/">https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/</a>, See on <a href="https://news.ycombinator.com/item?id=41580166">Hacker News</a></p>
Couldn't get https://engineering.fb.com/2024/09/17/data-infrastructure/inside-bento-jupyter-notebooks-at-meta/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[AI tool cuts unexpected deaths in hospital by 26%, Canadian study finds (197 pts)]]></title>
            <link>https://www.cbc.ca/news/health/ai-health-care-1.7322671</link>
            <guid>41579355</guid>
            <pubDate>Wed, 18 Sep 2024 13:17:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/news/health/ai-health-care-1.7322671">https://www.cbc.ca/news/health/ai-health-care-1.7322671</a>, See on <a href="https://news.ycombinator.com/item?id=41579355">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p dir="ltr">Inside a bustling unit at St. Michael's Hospital in downtown Toronto, one of Shirley Bell's patients was suffering from a cat&nbsp;bite and a fever, but otherwise appeared fine — until an alert from an AI-based early warning system showed he was sicker than he seemed.</p><p dir="ltr">While the nursing team usually checked blood work around noon, the technology flagged incoming results several hours beforehand. That warning showed&nbsp;the patient's white blood cell count was "really, really high,"&nbsp;recalled Bell, the clinical nurse educator for the hospital's general medicine program.</p><p dir="ltr">The cause turned out to be cellulitis, a bacterial skin infection. Without prompt treatment, it can lead to extensive tissue damage, amputations&nbsp;and even death. Bell said the patient was given antibiotics quickly to avoid those worst-case scenarios, in large part thanks to the team's in-house AI technology, dubbed Chartwatch.</p><p dir="ltr">"There's lots and lots of other scenarios where patients' conditions are flagged earlier, and the nurse is alerted earlier, and interventions are put in earlier," she said. "It's not replacing the nurse at the bedside; it's actually enhancing your nursing care."</p><p dir="ltr">A year-and-a-half-long study on Chartwatch, <a href="https://www.cmaj.ca/lookup/doi/10.1503/cmaj.240132"><u>published Monday</u></a> in the Canadian Medical Association Journal, found that use of the AI system led to a striking 26 per cent drop in the number of unexpected deaths among hospitalized patients.</p><p dir="ltr">"We're glad to see that we're saving lives," said co-author Dr. Muhammad Mamdani, vice-president of data science and advanced analytics at Unity Health Toronto and director of the University of Toronto Temerty Faculty of Medicine Centre for AI Research and Education in Medicine.&nbsp;</p><h2 dir="ltr">'A promising sign'</h2><p dir="ltr">The research team looked at more than 13,000 admissions to St. Michael's general internal medicine ward — an 84-bed unit caring for some of the hospital's most complex patients — to compare the impact of the tool among that patient population to thousands of admissions into other subspecialty units.&nbsp;</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/canada/sudbury/waive-the-wait-paperwork-doctors-1.7176165" text="This northern Ontario company is using AI to reduce paperwork at doctors' offices" flag="" data-contentid=""><span>This northern Ontario company is using AI to reduce paperwork at doctors' offices</span></a></li></ul></div><p dir="ltr">"At the same time period in the other units in our hospital that were not using Chartwatch, we did not see a change in these unexpected deaths," said lead author Dr. Amol Verma, a clinician-scientist at St. Michael's, one of three Unity Health Toronto hospital network sites, and Temerty professor of AI research and education in medicine at University of Toronto.&nbsp;</p><p dir="ltr">"That was a promising sign."</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/canada/prince-edward-island/pei-artificial-intelligence-1.6994961" text="AI will be critical for the future of rural health care in Canada, experts say" flag="" data-contentid=""><span>AI will be critical for the future of rural health care in Canada, experts say</span></a></li></ul></div><p dir="ltr">The Unity Health AI team started developing Chartwatch back in 2017, based on suggestions from staff that predicting deaths or serious illness could be key areas where machine learning could make a positive difference.</p><p dir="ltr">The technology underwent several years of rigorous development and testing before it was deployed in October&nbsp;2020, Verma said.</p><div dir="ltr"><figure><p><img loading="lazy" alt="Dr. Amol Verma, a clinician-scientist at St. Michael’s Hospital who helped lead the creation and testing of CHARTwatch, stands at a computer." srcset="https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-amol-verma.jpg 300w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-amol-verma.jpg 460w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-amol-verma.jpg 620w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-amol-verma.jpg 780w,https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-amol-verma.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.7322732.1726245155!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-amol-verma.jpg" data-cy="image-img"></p><figcaption>Verma simulates the tool's use inside the downtown Toronto health-care facility.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure></div><p dir="ltr">"Chartwatch measures about 100 inputs from [a patient's] medical record that are currently routinely gathered in the process of delivering care," he explained. "So a patient's vital signs, their heart rate, their blood pressure … all of the lab test results that are done every day."</p><p dir="ltr">Working in the background alongside clinical teams, the tool monitors any changes in someone's medical record "and makes a dynamic prediction every hour about whether that patient is likely to deteriorate in the future," Verma told CBC News.</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/health/mammography-artificial-intelligence-scans-1.6954753" text="AI shows major promise in breast cancer detection, new studies suggest" flag="" data-contentid=""><span>AI shows major promise in breast cancer detection, new studies suggest</span></a></li></ul></div><p dir="ltr">That could mean someone getting sicker, or requiring intensive care, or even being on the brink of death, giving doctors and nurses a chance to intervene.&nbsp;</p><p dir="ltr">In some cases, those interventions involve escalating someone's level of treatment to save their life, or providing early palliative care in situations where patients can't be rescued.&nbsp;</p><p dir="ltr">In either case, the researchers said, Chartwatch appears to complement clinicians' own judgment and leads to better outcomes for fragile patients, helping to avoid more sudden and potentially preventable deaths.</p><h2 dir="ltr">AI on the rise in health care</h2><p>Beyond its uses in medicine, artificial intelligence is getting plenty of buzz — and blowback — in recent years.&nbsp;</p><p dir="ltr">From controversy around the use of machine learning software to crank out academic essays, to concerns over AI's capacity to create realistic audio and video content mimicking real celebrities, politicians, or average citizens, there have been plenty of reasons to be cautious about this emerging technology.</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/radio/thecurrent/canadian-researchers-use-ai-to-find-a-possible-treatment-for-bacteria-superbug-1.6859534" text="Canadian researchers use AI to find a possible treatment for bacteria superbug" flag="" data-contentid=""><span>Canadian researchers use AI to find a possible treatment for bacteria superbug</span></a></li></ul></div><p dir="ltr">Verma himself said he's long been wary. But in health care, he stressed, these tools have immense potential to combat the staff shortages plaguing Canada's health-care system by supplementing traditional bedside care.</p><p><em><strong>WATCH | How AI could revolutionize health care:<span><span><div title="How AI could change the future of our health care" role="button" tabindex="0" data-cy="player-placeholder-ui-container"><div><p><img src="https://i.cbc.ca/ais/1.5110182,1717208994588/full/max/0/default.jpg?im=Crop%2Crect%3D%280%2C0%2C1920%2C1080%29%3BResize%3D%28620%29" srcset="" alt="" loading="lazy"></p></div><div><h3>How AI could change the future of our health care</h3></div></div><span>Often called the future of health care, artificial intelligence is already finding a place in Canadian hospitals. But AI is far from perfect and some worry about the costs that could come with it.</span></span></span></strong></em></p><p dir="ltr">It's still the early days for many of those efforts. Various research teams, including private companies, are exploring ways to use AI for earlier cancer detection. Some studies suggest it has potential for <a href="https://ieeexplore.ieee.org/document/10669945?utm_campaign=2024-Q2-PR&amp;utm_source=KH_PR_Newsroom&amp;utm_medium=ieee_access&amp;utm_content=scientists_use_ai_to_detect_chronic_high_blood_pressure"><u>flagging hypertension</u></a> just by listening to someone's voice; others show it could scan brain patterns to <a href="https://nyulangone.org/news/what-happens-brain-after-Concussion-ai-may-be-only-way-find-answer"><u>detect signs of a concussion</u></a>.</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/radio/spark/from-virtual-care-apps-to-ai-algorithms-the-trouble-with-data-collection-in-healthcare-1.6759591" text="From virtual care apps to AI algorithms: the trouble with data collection in healthcare" flag="" data-contentid=""><span>From virtual care apps to AI algorithms: the trouble with data collection in healthcare</span></a></li></ul></div><p dir="ltr">Chartwatch is notable, Verma stressed, because of its success in keeping actual patients alive.</p><p dir="ltr">"Very few AI technologies have actually been implemented into clinical settings yet. This is, to our knowledge, one of the first in Canada that has actually been implemented to help us care for patients every day in our hospital," he said.</p><h2 dir="ltr">'Real world' look at AI's health-care impact</h2><p dir="ltr">The St. Michael's-based research does have limitations. The study took place during the COVID-19 pandemic, at a time when the health-care system faced an unusual set of challenges. The&nbsp;urban hospital's patient population is also distinct, the team acknowledged, given its high level of complex patients, including individuals facing homelessness, addiction&nbsp;and overlapping health issues.</p><p dir="ltr">"Our study was not a randomized controlled trial across multiple hospitals. It was within one organization, within one unit," Verma said. "So before we say that this tool can be used widely everywhere, I think we do need to do research on its use in multiple contexts."</p><div dir="ltr"><ul><li><a href="https://www.cbc.ca/news/opinion/opinion-chatgpt-artificial-intelligence-regulation-1.6731973" text="Regulating artificial intelligence: Things are about to get a lot more interesting" flag="Opinion" data-contentid=""><p><span>Opinion</span></p><span>Regulating artificial intelligence: Things are about to get a lot more interesting</span></a></li></ul></div><p dir="ltr">Dr. John-Jose Nunez, a psychiatrist and researcher with the University of British Columbia — who wasn't involved in the study — agreed the research needs to be replicated elsewhere to get a better sense of how well Chartwatch might work in other facilities. There also needs to be considerations around patient privacy, he added, with the use of any emerging AI technologies.</p><p dir="ltr">Still, he praised the study team for providing a "real-world" example of how&nbsp;machine learning can improve patient care.</p><p dir="ltr">"I really think of AI tools as becoming one more team member on the clinical care team,"&nbsp;he said.</p><div dir="ltr"><figure><p><img loading="lazy" alt="Dr. Muhammad Mamdani, vice president of data science and advanced analytics at Unity Health Toronto and director of the University of Toronto Temerty Faculty of Medicine Centre for AI Research and Education in Medicine. " srcset="https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-muhammad-mamdani.jpg 300w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-muhammad-mamdani.jpg 460w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-muhammad-mamdani.jpg 620w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-muhammad-mamdani.jpg 780w,https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-muhammad-mamdani.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.7322721.1726244753!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-muhammad-mamdani.jpg" data-cy="image-img"></p><figcaption>CHARTwatch technology is 'saving lives,' said Dr. Muhammad Mamdani, vice president of data science and advanced analytics at Unity Health Toronto and director of the University of Toronto Temerty Faculty of Medicine Centre for AI Research and Education in Medicine. <!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure></div><p dir="ltr">The Unity Health team is hopeful their technology will roll out more widely in the future, within their own Toronto-based hospital network and beyond.</p><p>Much of that work is happening through <a href="https://geminimedicine.ca/"><u>GEMINI</u></a>, Canada's largest hospital data-sharing network for research and analytics, said Mamdani, Unity Health's vice-president of data science.</p><div><ul><li><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-the-monday-edition-1.6415906/researchers-give-a-robot-hand-the-power-of-touch-designing-a-human-like-fingertip-1.6417499" text="Researchers give a robot hand the power of touch, designing a human-like fingertip" flag="" data-contentid=""><span>Researchers give a robot hand the power of touch, designing a human-like fingertip</span></a></li></ul></div><p dir="ltr">More than 30 hospitals across Ontario are working together, he said, offering opportunities to test Chartwatch and other AI tools in various clinical settings and hospitals.&nbsp;</p><p dir="ltr">"It just sets the groundwork now to be able to deploy these things well beyond our four walls," Mamdani said.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PeerTube 6.3 (169 pts)]]></title>
            <link>https://joinpeertube.org/news/release-6.3</link>
            <guid>41578752</guid>
            <pubDate>Wed, 18 Sep 2024 12:13:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joinpeertube.org/news/release-6.3">https://joinpeertube.org/news/release-6.3</a>, See on <a href="https://news.ycombinator.com/item?id=41578752">Hacker News</a></p>
Couldn't get https://joinpeertube.org/news/release-6.3: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why wordfreq will not be updated (1185 pts)]]></title>
            <link>https://github.com/rspeer/wordfreq/blob/master/SUNSET.md</link>
            <guid>41578483</guid>
            <pubDate>Wed, 18 Sep 2024 11:41:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rspeer/wordfreq/blob/master/SUNSET.md">https://github.com/rspeer/wordfreq/blob/master/SUNSET.md</a>, See on <a href="https://news.ycombinator.com/item?id=41578483">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Why wordfreq will not be updated</h2><a id="user-content-why-wordfreq-will-not-be-updated" aria-label="Permalink: Why wordfreq will not be updated" href="#why-wordfreq-will-not-be-updated"></a></p>
<p dir="auto">The wordfreq data is a snapshot of language that could be found in various
online sources up through 2021. There are several reasons why it will not be
updated anymore.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Generative AI has polluted the data</h2><a id="user-content-generative-ai-has-polluted-the-data" aria-label="Permalink: Generative AI has polluted the data" href="#generative-ai-has-polluted-the-data"></a></p>
<p dir="auto">I don't think anyone has reliable information about post-2021 language usage by
humans.</p>
<p dir="auto">The open Web (via OSCAR) was one of wordfreq's data sources. Now the Web at
large is full of slop generated by large language models, written by no one to
communicate nothing. Including this slop in the data skews the word
frequencies.</p>
<p dir="auto">Sure, there was spam in the wordfreq data sources, but it was manageable and
often identifiable. Large language models generate text that masquerades as
real language with intention behind it, even though there is none, and their
output crops up everywhere.</p>
<p dir="auto">As one example, <a href="https://pshapira.net/2024/03/31/delving-into-delve/" rel="nofollow">Philip Shapira
reports</a> that ChatGPT
(OpenAI's popular brand of generative language model circa 2024) is obsessed
with the word "delve" in a way that people never have been, and caused its
overall frequency to increase by an order of magnitude.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Information that used to be free became expensive</h2><a id="user-content-information-that-used-to-be-free-became-expensive" aria-label="Permalink: Information that used to be free became expensive" href="#information-that-used-to-be-free-became-expensive"></a></p>
<p dir="auto">wordfreq is not just concerned with formal printed words. It collected more
conversational language usage from two sources in particular: Twitter and
Reddit.</p>
<p dir="auto">The Twitter data was always built on sand. Even when Twitter allowed free
access to a portion of their "firehose", the terms of use did not allow me to
distribute that data outside of the company where I collected it (Luminoso).
wordfreq has the frequencies that were built with that data as input, but the
collected data didn't belong to me and I don't have it anymore.</p>
<p dir="auto">Now Twitter is gone anyway, its public APIs have shut down, and the site has
been replaced with an oligarch's plaything, a spam-infested right-wing cesspool
called X. Even if X made its raw data feed available (which it doesn't), there
would be no valuable information to be found there.</p>
<p dir="auto">Reddit also stopped providing public data archives, and now they sell their
archives at a price that only OpenAI will pay.</p>
<p dir="auto">And given what's happening to the field, I don't blame them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">I don't want to be part of this scene anymore</h2><a id="user-content-i-dont-want-to-be-part-of-this-scene-anymore" aria-label="Permalink: I don't want to be part of this scene anymore" href="#i-dont-want-to-be-part-of-this-scene-anymore"></a></p>
<p dir="auto">wordfreq used to be at the intersection of my interests. I was doing corpus
linguistics in a way that could also benefit natural language processing tools.</p>
<p dir="auto">The field I know as "natural language processing" is hard to find these days.
It's all being devoured by generative AI. Other techniques still exist but
generative AI sucks up all the air in the room and gets all the money. It's
rare to see NLP research that doesn't have a dependency on closed data
controlled by OpenAI and Google, two companies that I already despise.</p>
<p dir="auto">wordfreq was built by collecting a whole lot of text in a lot of languages.
That used to be a pretty reasonable thing to do, and not the kind of thing
someone would be likely to object to. Now, the text-slurping tools are mostly
used for training generative AI, and people are quite rightly on the defensive.
If someone is collecting all the text from your books, articles, Web site, or
public posts, it's very likely because they are creating a plagiarism machine
that will claim your words as its own.</p>
<p dir="auto">So I don't want to work on anything that could be confused with generative AI,
or that could benefit generative AI.</p>
<p dir="auto">OpenAI and Google can collect their own damn data. I hope they have to pay a
very high price for it, and I hope they're constantly cursing the mess that
they made themselves.</p>
<p dir="auto">— Robyn Speer</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gentle Guide to Self-Hosting (222 pts)]]></title>
            <link>https://knhash.in/gentle-guide-to-self-hosting/</link>
            <guid>41577156</guid>
            <pubDate>Wed, 18 Sep 2024 08:16:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://knhash.in/gentle-guide-to-self-hosting/">https://knhash.in/gentle-guide-to-self-hosting/</a>, See on <a href="https://news.ycombinator.com/item?id=41577156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    







<p>
    <i>
        <time datetime="2024-09-15T19:53Z">
            15 Sep, 2024
        </time>
    </i>
</p>


    <p>There was a time when software (and games! Games are just software for fun!) were distributed on DVD. A physical disk that you would insert into your system to load up software and install. This was the 2000's, when computers prided themselves on being personal computation devices. A <a href="https://www.google.com/chromebook/">Chromebook</a> was a curiosity at the time, promising to run most of your software in "someone else's computer"; all you needed was the internet and the interface. The Chromebook was a reckoning. Through the 2010's we slowly moved into the clouds of various giants; it was the easy way to compute. The giants were renting out services - subscriptions started gaining foothold as the second best way to make money online after advertisements - and we were happy to give away the control in exchange for convenience. A minor consequence of this is that an entire generation of computer scientists hasn't had the opportunity to start off as computer enthusiasts - the primordial hacker mindset is slowly waning in prominence.</p>
<p>It is 2024, and I say it is time we revisited some of the fundamental joys of setting up our own systems.</p>
<p>Why? Good question.</p>
<ul>
<li>Philosophically, it is a form of rebellion, carving out a niche in a world dominated by monopolies, resisting the forces that be from having complete control over our digital selves. Showing the world a <em>different</em> way of living. One of the last bastions of online freedom, self-hosters stand alongside open-source-ers, data-hoard-ers, privacy-ers, matrix/activity-pub/decentralized-tech-ers, piracy-ers, de-google-ers and hack-ers.</li>
<li>Practically, it is foolishness, for what you save in money you lose in time and sanity. Seriously, else-hosting is the practical option, let someone else worry about the reliability, concurrency, redundancy and availability of your systems.</li>
<li>Intellectually, it is the digital garage of constant tweaking of systems, a source of zen and arcane knowledge. Where you retire after a day's work to work on your favourite toys.</li>
</ul>
<p>So most importantly, it is supposed to be fun. A hobby.</p>
<p>And like every hobby there are a lot of gatekeepers. People who believe having a personal server that you can <em>touch</em> is a necessity to call yourself a self-hoster. Eh. Don't listen to them. Self-hosting is as much about the software as it is about the hardware. I say we get the enthusiasts by any means necessary; they will eventually grow into full-fledged self-hosting. Or not. It doesn't matter! This is supposed to be fun, why are you stopping people from having fun?</p>
<p>And so, here is a gentle introduction to self-hosting that is not "true self-hosting", but whatever. Sue me. We will operate at the software level only, and laugh at the feeble protestations of the rigidly-defined self-hoster loyalists. We will dispense with the heavy prose after this point.</p>
<hr>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/knhash/uberspace.png" alt="uberspace"></p>
<blockquote>
<p>A shared web hosting service is a web hosting service where many services reside on one web server connected to the Internet. The overall cost of server maintenance is spread over many customers.</p>
</blockquote>
<p>You need a space to host. I recommend <a href="https://uberspace.de/en/">Uberspace</a>. They are the most heart-warmingly nice people about hosting; they operate on the idea of "here's a screwdriver, try not to burn down the building, but have fun". Excellent.</p>
<p>So, make an account on Uberspace - did I also mention that you pay after the month ends, so technically everyone gets a free month of trial? I mean, can they get more awesome? (pst, they do).</p>
<blockquote>
<p>The Secure Shell Protocol is a cryptographic network protocol for operating network services securely over an unsecured network. Its most notable applications are remote login and command-line execution.</p>
</blockquote>
<p>Here's the cool part: you now have SSH access to a computer in the cloud with 10GB of storage and 1.5GB of RAM. Go ahead, do it now. Run <code>ls</code> to be greeted by your brand spanking new empty user directory.</p>
<hr>
<h3 id="the-software">The Software</h3><p>What to do, what to install…. I will give you two resources to peruse.</p>
<ul>
<li><a href="https://lab.uberspace.de/">Uberspace Labs</a> - An Uberspace specific installation guide to various software that you can play around with on Uberspace. Highly recommend searching for anything you want here first.</li>
<li><a href="https://github.com/awesome-selfhosted/awesome-selfhosted">Awesome-Selfhosted</a> - A broader listing of self-hostable software. If it is on here, it means there is a decent amount of community behind that software; it should cover 90% of the broadly self-hostable programs.</li>
</ul>
<p>You cannot use Docker in Uberspace. The memory constraints are too low to run a full virtualization suite. Which is a bummer for the larger software and docker-only installations <strong>but</strong> there are workarounds for it. You can install software from source or pull the final run-time from the dockerisation process and use it as a build image (I leave this as an exercise for the intrepid reader :)).</p>
<p><em>But what exactly do I install first??</em>  Alright, alright. Author suggests the following two trackers - one for finance, and one for videos and website updates.</p>
<h3 id="actual-budget">Actual Budget</h3><p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/knhash/actual.png" alt="actual"></p>
<p>Have you always wanted a way to track your finances - expenditures, net worth, spend patterns, etc.? Have also been wary of putting all this sensitive information in the hands of others? What if there was a way to be in control of your data, yet have it accessible across the world via a browser?</p>
<blockquote>
<p><a href="https://actualbudget.com/"><em>Actual Budget</em></a> is a super fast and privacy-focused app for managing your finances. At its heart is the well proven and much loved Envelope Budgeting methodology.</p>
</blockquote>
<p>I use this and I have written a guide on how to install this <a href="https://lab.uberspace.de/guide_actual/">here</a>.</p>
<p>Make sure to peek into the reports section - you should be able to slice and dice your finances and gain tons of insight out of it. For instance, turns out what I considered to be minor purchases actually add up over the month, and I spend an inordinate amount of money on commute!</p>
<h3 id="miniflux">Miniflux</h3><p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/knhash/miniflux.png" alt="miniflux"></p>
<blockquote>
<p><a href="https://miniflux.app/"><em>Miniflux</em></a> is a minimalist and opinionated feed reader.</p>
</blockquote>
<p>There is a way to keep track of your favourite news outlets and magazines, be posted on the latest blog posts of your favourite writers. You could also build a dedicated ad-free feed timeline of your YouTube subscriptions.</p>
<blockquote>
<p><em>RSS</em> (<em>Really Simple Syndication</em>) is a web feed that allows users and applications to access updates to websites in a standardized, computer-readable format. Subscribing to RSS feeds can allow a user to keep track of many different websites in a single news aggregator, which constantly monitor sites for new content, removing the need for the user to manually check them.</p>
</blockquote>
<blockquote>
<p><em>Bonus</em>: YouTube has an RSS feed and the embedded YouTube player is ad-free.</p>
</blockquote>
<p>Install <em>Miniflux</em> on Uberspace. Add feeds of your favourite YouTube channels. Hop into settings and enable Fever API.</p>
<p>Now any RSS client which is capable of reading from the Fever API should be able to access your RSS aggregator in the cloud. If you are in the Apple ecosystem I highly recommend <a href="https://www.goldenhillsoftware.com/unread/">Unread</a> by Golden Hill Software.</p>
<p>With this I have a dedicated recent first timeline of all the videos as they are released.</p>
<p>I also have separate categories of feed for news and comics - there is a ton of webcomics out there beyond <a href="https://xkcd.com/">xkcd</a>, <a href="https://www.smbc-comics.com/">smbc</a> and <a href="https://theoatmeal.com/">oatmeal</a> - a great way to catch up is via RSS.</p>
<hr>
<h3 id="bonus-your-domain">Bonus: Your Domain</h3><p>The coolest part about self-hosting is showing off your stuff. What better way to show off your things than to have a personal domain - a place you can call your own. Head over to a domain name registrar and grab a site on the net-estate. I suggest <a href="https://porkbun.com/">Porkbun</a>.</p>
<p>Now you have a bunch of extraordinary things you can do. With something like <code>awesauce.com</code>:</p>
<ul>
<li>You can point the various services you host on Uberspace to subdomains of your main site. Show off your <code>actual.awesauce.com</code> and <code>miniflux.awesauce.com</code>!</li>
<li>Check with your email provider if they allow you to set up custom domain. You may have to pay for the privilege. Once done you have achieved another freedom - now you can shift the underlying email service provider while keeping the address the same. All mails, for forever, can come to <code>contact@awesauce.com</code>. Woohoo!</li>
<li>Point a subdomain or a URL path to your GitHub repository and host publicly accessible files like your resume: <code>awesauce.com/files/resume.pdf</code></li>
</ul>
<hr>
<p>This has not been a detailed step by step walkthrough on how to do things, by design. You are meant to go and explore; this is simply a way pointer to invigorate your curiosities.</p>
<p>Here is a final reader's exercise: Figure out a way to send yourself a mobile notification when a particular item comes back in stock or website changes :D</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/knhash/changedetection.png" alt="changedetection"></p>
<hr>
<p>This made it to the HackerNews front page, <a href="https://news.ycombinator.com/item?id=41577156">head over there</a> for some good discussion around the topic.</p>





    
    <p>
        
        <a href="https://knhash.in/blog/?q=devops">#devops</a>
        
        <a href="https://knhash.in/blog/?q=hacker">#hacker</a>
        
        <a href="https://knhash.in/blog/?q=selfhosting">#selfhosting</a>
        
        <a href="https://knhash.in/blog/?q=systems">#systems</a>
        
    </p>
    

    
    


    



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[26-Year-Old EY Employee Succumbs to 'Work Stress' Four Months After Joining (184 pts)]]></title>
            <link>https://old.reddit.com/r/CharteredAccountants/comments/1fj08v9/ey_employee_died_of_work_pressure</link>
            <guid>41575908</guid>
            <pubDate>Wed, 18 Sep 2024 04:50:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/CharteredAccountants/comments/1fj08v9/ey_employee_died_of_work_pressure">https://old.reddit.com/r/CharteredAccountants/comments/1fj08v9/ey_employee_died_of_work_pressure</a>, See on <a href="https://news.ycombinator.com/item?id=41575908">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>[–]<a href="https://old.reddit.com/user/PreposterousSyndrom">PreposterousSyndrom</a><span></span> <span title="246">246 points</span><span title="247">247 points</span><span title="248">248 points</span> <time title="Tue Sep 17 16:08:32 2024 UTC" datetime="2024-09-17T16:08:32+00:00">18 hours ago</time><time title="last edited 18 hours ago" datetime="2024-09-17T16:17:59+00:00">*</time>&nbsp;(61 children)</p><form action="#" onsubmit="return post_form(this, 'editusertext')" id="form-t1_lnl8w8y0z2"><div><p>As Anna's colleague - </p>

<p>Bear with me till the end.</p>

<p>I work in the same office as Anna, EY Pune and in the same cluster. </p>

<p>The death of Anna was informed via a centralised mail in which they attached her linkedin picture with some standard short message like RIP. News was put in the grapevine that she was already suffering from a health condition which got worse. </p>

<p>Though I haven't worked directly with her, I've worked with her manager, who is worse than how it's portrayed in the letter. He actually prioritises his convenience (like cricket) and he doesn't really care for anyone's time or effort. He proudly bought IPL final tickets in deadline at exorbitant prices and showed off on insta. He takes all the credit himself, and blames the team for any shortfalls (classic manager behaviour). Boasts all day everyday. When he reviews your work, his focus is not on the correctness of work, he points out as many mistakes as he could, depicting how smart he is, and in other words how dumb you are.</p>

<p>Her assistant manager, she's atrocious. Basically what the asst manager does is distribute work to the team and follow up from each one. Ensure no one is stress free, no one is taking time off. Basically they highlight their potential by getting work done from lesser people (like work of 5/6 resources from 2 resources) in order to get promoted. It is said in common language that you can trust and deal with a drunken man out of his mind, but not an AM. Every AM is the embodiment of this statement.</p>

<p>I have been working in EY for quite some time now, and I have seen people come and go. People who come here (generally) are very hardworking people who have thirst for learning and they are ready to work day and night. Australian timings, European timings, US timings, you name it. Seasoned people exploit these newcomers like anything. And these senior people have power. Good deal of power. They can make your life a living hell if you don't co-operate with them. Try reporting to HR, then you'll get to know he's part of this structure too. They have the audacity to use profane language in reviews. Newly qualified CAs and articles come all the way from their states like Kashmir, Punjab, TN, sacrificing everything just to learn and get good exposure. But it's a bloodbath.  All these people are school toppers of their time. It seems apparent that years of mind numbing toil wasn't enough.They're humiliated to an extent where they lose their respect in their own eyes. Humiliation in the team calls is quite normal here. And these newcomers are from small families who teach them to respect elders and not react to any unreasonable behaviour, not to say NO to any work, give your heart and soul to the work you do. Everyone of us went through this thinking maybe something is wrong with me, if everyone is able to handle this pressure I should handle it too. Female employees may get some leniency but for our male colleagues it's absolutely brutal. Everyone is tortured to hell. No social life, no personal time, no time to attend even phone calls. Most of the newcomers including articles quit, some endure the trouble for some years and then quit, remaining become managers and become trouble for others.</p>

<p>We average 16 hours a day in the busy season, and 12 hours a day in non busy seasons. No weekends or public holidays are off. Annually EY voluntarily announces a day off to rejuvenate their employees. And yes you guessed it right! Even that is not off. We work on that day as well - from Office! Overwork is the only way to get promoted, do and make others do it. </p>

<p>Top level people (Partners) don't care about sh<em>t. You don't even get to interact with partners until you're at least an asst manager. They don't give a f</em>*k about any employee, they just care about getting work done. Even if you go through boiling hell and get the work done, you won't get any acknowledgement from anyone forget about appreciation. One of my colleagues was hospitalized suffering from Dengue, and these people made him make workpapers from his hospital bed. Good for him he quit then and there. When I say these people are inhuman, they literally are.</p>

<p>People leaving EY are usually very happy, and their colleagues congratulate them like they are being released from prison. </p>

<p>It's my request to all my colleagues reading this message - please reevaluate your priorities, see what you're really doing to yourself. And to CAs and articles who dream to work in such an organisation - be very careful of what you wish for.</p>

<p>Anna's death has impacted us all. And such letter from Augustine is a conclusive evidence that "already suffering from health issues" was an deliberately created rumour. Hope the effort behind this letter doesn't go in vain. </p>

<p>Support from all suffering employees of EY.</p>

<p>More power to you Augustine.</p>
</div></form><ul><li><a href="https://old.reddit.com/r/CharteredAccountants/comments/1fj08v9/ey_employee_died_of_work_pressure/lnl8w8y/" data-event-action="permalink" rel="nofollow">permalink</a></li><li>embed</li><li>save</li><li>report</li><li>reply</li></ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Please stop putting cookie pop-ups on your website (2022) (116 pts)]]></title>
            <link>https://olivergrimsley.com/2022/03/04/please-stop-putting-cookie-pop-ups-on-your-website/</link>
            <guid>41575424</guid>
            <pubDate>Wed, 18 Sep 2024 03:18:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://olivergrimsley.com/2022/03/04/please-stop-putting-cookie-pop-ups-on-your-website/">https://olivergrimsley.com/2022/03/04/please-stop-putting-cookie-pop-ups-on-your-website/</a>, See on <a href="https://news.ycombinator.com/item?id=41575424">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
				
				
				
				
<p>Almost every major website you visit today pops up a banner to warn you that it uses “cookies.”   This is not legally required in the U.S. or in most places, and where it is, the vast majority of sites do not comply with legal requirements.  From a policy perspective: cookie pops are just dumb – (virtually) no one reads them.  There are vastly better ways to deal with the issue they present – legally and from a site usability perspective. </p>



<p>First, no current U.S. law requires cookie pop-ups.   <em>Some</em> sites that are available in the European Union are required to post cookie pop ups – sites that use so called “tracking cookies.”  I discuss below a recent EU case that makes this issue even worse than one would have originally thought. </p>



<p>Second, an anecdotal review of websites shows the vast, <em>vast</em> majority of them – all of them in my experience that are “U.S.” sites – utterly fail to comply with the so called EU “cookie law.”  Why?  Because they store the cookie before consent (which is not permitted under the cookie law) and they simply state, “This site uses cookies” and present an “OK” button (and/or an X to close the pop up) with a link to the privacy policy.  See for example <a href="http://www.abajournal.com/">www.abajournal.com</a> which, as of the date of this post, simply provides an OK button – no option to do anything like reject or manage the cookies, and a link to the privacy policy.   Just a useless and legally insufficient user interface distraction.  </p>



<p>Finally, except in very, very limited cases, these cookie pops do not in any way increase user privacy protection.   Why?  If a site does comply with the notice and consent requirements, <em>it is not legally required to provide the service if a user declines tracking cookies.</em>  The site can simply not provide functionality.  So in many cases, its not really a choice – the choice is either not to use the site, or consent to tracking.  This is made worse because many governments and third parties use these sites for information dissemination.  A truly privacy focused law would at least require that the site function if a person elected no tracking.  </p>



<p>The whole cookie problem was started by our friends in Europe when they promulgated the <a href="https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX%3A32002L0058">ePrivacy Directive 2002/58/EC</a>.  However, no U.S. company really started focusing on compliance with the “cookie issue” presented in the ePrivacy Directive until the General Data Protection Regulation (GDPR) of the European Union, <a href="https://op.europa.eu/en/publication-detail/-/publication/3e485e15-11bd-11e6-ba9a-01aa75ed71a1/language-en">Regulation (EU) 2016/679</a> of the European Parliament and of the Council of 27 April 2016 came into effect.  The GDPR applies in Europe, not the US, however so many U.S. companies either do business in, or ostensibly could be regulated by, EU members – so they attempt to comply with both U.S.and EU law.  </p>



<p>Many “cookies” –  the ones necessary to actually operate a website, are “exempt” and need not be identified nor are they subject to consent.   However, sites that use tracking cookies and other tracking technology – even anonymized data – are required under EU law to obtain prior consent before even storing the cookie or other technology that allows such tracking.  </p>



<p>In my opinion, this system has been an utter failure in policy and actual impact.   It has not stopped companies from incessant user tracking.  The companies that rely on user tracking have the power to force the choice of “allow tracking” or do not use the service.   The privacy policies remain mostly unintelligible, or at the very least, its is all but impossible to tell what exact tracking a company does, primarily because they either disclose only the types of tracking, or disclose so excessively that the cookie disclosure is indecipherable.  </p>



<p>But the EU is doubling down on the concept . . . </p>



<p>In a recent decision (File number: DOS-2019-0137) of the Dispute Chamber of the Data Protection Authority of Belgium issued 2/2/2022, that regulator held that the European arm of the Interactive Advertising Bureau (IAB)’s “pop up” framework used by most of its members – intentionally designed to comply with the GDPR, <strong>in fact did not</strong>.   The decision is lengthy (my machine translated version into English is 139 pages long), and undoubtedly will be appealed.   As an overview, IAB created a real time bidding system (RTB) – an automated system of bidding for advertising.  This is their framework in the U.S. and many other countries, but in Europe, they created the “Transparency and Consent Framework” (TCF).   At issue in this case was a subset of the TCF, which the Board described as follows: “Specifically for the TCF, there are also the companies that use so-called “Consent Management Platforms” (CMPs) to offer. Specifically, a CMP takes the form of a pop-up that appears on the first connection to a website appears to request permission from the internet user to collect cookies and other identification data” Para. 40 (Note, all English translations here are machine created by Google’s translation service).  The original decision in Dutch is here (and I can post the English translated version if someone requests it): <a rel="noreferrer noopener" href="https://www.gegevensbeschermingsautoriteit.be/publications/beslissing-ten-gronde-nr.-21-2022.pdf" target="_blank">https://www.gegevensbeschermingsautoriteit.be/publications/beslissing-ten-gronde-nr.-21-2022.pdf</a>.  </p>



<p>The basic idea is that IAB manages a “consensu” cookie – that indicates if the web user has already consented (or rejected) cookies.  So, a participating site would somehow take information from a user’s initial browser session, send it off to IAB, and IAB would send back a text string indicating if that user had already consented to accept cookies or not.  If not, a “cookie pop up” would be presented to the user.   The Board found that the IAB maintains a database of users and preferences, which can be used “in order to create an advertising profile of data subjects and to show them personalized advertising”  Para. 50.  It therefore concluded the IAB was a data controller (a point the IAB disputed).  From this point forward the Board essentially found nearly every conceivable violation of the GDPR that could be found.  Among them, that “IAB Europe [] failed to observe the principles of due regard for transparency and fairness with regard to data subjects” in part because some of the information that can be sucked up into the preference model includes “special categories of personal data … For example, participating organizations could become acquainted with the websites previously visited by a data subject, including the political opinions, religious or philosophical beliefs, sexual orientation, health data or also trade union memberships of the data subjects be inferred or disclosed.”  Para 51.  It also found the IAB’s privacy policy insufficient because among other reasons it was only available in English, and used unclear vague terms like “services” and “other means.”  Para. 54.  It also did not like that the terms “partners” and “third parties” were not explained sufficiently. </p>



<p>To me this is just evidence that no one really understands the law – or that the regulators think it says one thing and the industry thinks it says another.  Not good either way.  But after that decision, it seems like it would be all but impossible to have a centralized “cookie consent” service – or to comply, the service would be so intrusive as to make the web experience intolerable.</p>



<p>The solution?  In my view, just stop with the cookie pop ups.  They are stupid and ineffective.  Enact a law that requires a service to respect the do not track signal from a browser (currently entirely voluntary), and not store any tracking cookies, clear gifs or other trackers – and require that a site not “discriminate” against users who elect no tracking – basically – provide all functions to users whether they consent or do not consent.  I would also prevent any government organization to use a site that tracks users as a service for information dissemination. </p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scramble: Open-Source Alternative to Grammarly (386 pts)]]></title>
            <link>https://github.com/zlwaterfield/scramble</link>
            <guid>41575323</guid>
            <pubDate>Wed, 18 Sep 2024 02:59:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/zlwaterfield/scramble">https://github.com/zlwaterfield/scramble</a>, See on <a href="https://news.ycombinator.com/item?id=41575323">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Scramble - Open-Source Grammarly Alternative</h2><a id="user-content-scramble---open-source-grammarly-alternative" aria-label="Permalink: Scramble - Open-Source Grammarly Alternative" href="#scramble---open-source-grammarly-alternative"></a></p>
<p dir="auto">Scramble is an open-source Chrome extension that leverages AI to enhance your writing directly in your browser. It's designed to be a more customizable and privacy-respecting alternative to Grammarly.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>Clone this repository or download the source code</li>
<li>Open Chrome and go to <code>chrome://extensions/</code></li>
<li>Enable "Developer mode" in the top right</li>
<li>Click "Load unpacked" and select the extension directory</li>
</ol>
<blockquote>
<p dir="auto">Currently pending review on Chrome Web Store. Once approved, you can install it from there.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li>Highlight text on any webpage</li>
<li>Right-click to open the context menu</li>
<li>Select "Scramble" and choose a text enhancement option</li>
<li>Wait for the AI to process and enhance your text</li>
</ol>
<p dir="auto">Screenshot:
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/6392501/368399491-7a8685e5-94dd-47be-a141-f84bcbf1321f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY2NDEzMDEsIm5iZiI6MTcyNjY0MTAwMSwicGF0aCI6Ii82MzkyNTAxLzM2ODM5OTQ5MS03YTg2ODVlNS05NGRkLTQ3YmUtYTE0MS1mODRiY2JmMTMyMWYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDkxOCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA5MThUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWY2MjcwMTAyZWViNTc4YmJiNzkyZWFiYTg0ZDc2ZjE2YWZjNjExZWJkNjQ2MzZjYjI5ZDQzZjAwYzRhNGNmMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0MDBSDp1F-k_T2zW5FWVe9CCZlpWDeJlYGqKcKfO3pw"><img width="728" alt="Screenshot 2024-09-17 at 10 14 30 PM" src="https://private-user-images.githubusercontent.com/6392501/368399491-7a8685e5-94dd-47be-a141-f84bcbf1321f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjY2NDEzMDEsIm5iZiI6MTcyNjY0MTAwMSwicGF0aCI6Ii82MzkyNTAxLzM2ODM5OTQ5MS03YTg2ODVlNS05NGRkLTQ3YmUtYTE0MS1mODRiY2JmMTMyMWYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDkxOCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA5MThUMDYzMDAxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MWY2MjcwMTAyZWViNTc4YmJiNzkyZWFiYTg0ZDc2ZjE2YWZjNjExZWJkNjQ2MzZjYjI5ZDQzZjAwYzRhNGNmMCZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QmYWN0b3JfaWQ9MCZrZXlfaWQ9MCZyZXBvX2lkPTAifQ.0MDBSDp1F-k_T2zW5FWVe9CCZlpWDeJlYGqKcKfO3pw"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Default Prompts</h2><a id="user-content-default-prompts" aria-label="Permalink: Default Prompts" href="#default-prompts"></a></p>
<p dir="auto">Scramble comes with several pre-configured text enhancement options:</p>
<ol dir="auto">
<li>Fix spelling and grammar</li>
<li>Improve writing</li>
<li>Make more professional</li>
<li>Simplify text</li>
<li>Summarize text</li>
<li>Expand text</li>
<li>Convert to bullet points</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">API Key</h2><a id="user-content-api-key" aria-label="Permalink: API Key" href="#api-key"></a></p>
<p dir="auto"><strong>Important:</strong> This extension requires an OpenAI API key to function. You need to provide your own API key in the extension settings. Please visit <a href="https://openai.com/" rel="nofollow">OpenAI</a> to obtain an API key.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Future Features</h2><a id="user-content-future-features" aria-label="Permalink: Future Features" href="#future-features"></a></p>
<p dir="auto">Planned features include:</p>
<ul dir="auto">
<li>Custom user-defined prompts</li>
<li>Support for additional language models (LLMs)</li>
<li>Enhanced context awareness</li>
<li>Integration with other AI services</li>
<li>View diff between original and improved text</li>
<li>Underline grammar / spelling issues</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! Please feel free to submit a Pull Request.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto"><a href="https://github.com/zlwaterfield/scramble/blob/main/LICENSE">MIT License</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Mobile Processors Are Now Made in America. By TSMC (1392 pts)]]></title>
            <link>https://timculpan.substack.com/p/apple-mobile-processors-are-now-made</link>
            <guid>41574844</guid>
            <pubDate>Wed, 18 Sep 2024 01:38:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timculpan.substack.com/p/apple-mobile-processors-are-now-made">https://timculpan.substack.com/p/apple-mobile-processors-are-now-made</a>, See on <a href="https://news.ycombinator.com/item?id=41574844">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Good Evening from Taipei,</p><p>TSMC’s first Arizona chips are now in production, and Apple is ready to be the first cab off the rank with mobile processors made using the foundry’s 5nm process.</p><p><span>Apple’s A16 SoC, which first debuted two years ago in the </span><a href="https://www.apple.com/newsroom/2022/09/apple-debuts-iphone-14-pro-and-iphone-14-pro-max/" rel="">iPhone 14 Pro</a><span>, is currently being manufactured at Phase 1 of TSMC’s Fab 21 in Arizona in small, but significant, numbers, my sources tell me. Volume will ramp up considerably when the second stage of the Phase 1 fab is completed and production is underway, putting the Arizona project on track to hit its </span><a href="https://pr.tsmc.com/english/news/3122" rel="">target for production in the first-half of 2025</a><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png" width="1456" height="972" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23260265,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ee10c5-f75f-469f-8c34-796fb90f4369_6400x4272.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>These A16 chips are made with the same N4P process as TSMC uses for the A16 produced in Taiwan, I am told. Confusingly, N4P is sometimes called a 4nm node and sometimes 5nm, but it’s part of </span><a href="https://www.tsmc.com/english/dedicatedFoundry/technology/platform_HPC_tech_advancedTech" rel="">the broader 5nm family of processes</a><span> — TSMC calls it an </span><em>enhanced</em><span> version of 5nm. Call it 4nm if you like, I won’t correct you.</span></p><p>“The Arizona project is proceeding as planned with good progress,” Nina Kao, a spokeswoman for TSMC told me. She declined to comment on clients or products made at the facility.</p><div data-attrs="{&quot;url&quot;:&quot;https://timculpan.substack.com/p/apple-mobile-processors-are-now-made?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p><em>Tell people about the exclusive news you’re reading right now, and where you heard it first.</em></p><p data-attrs="{&quot;url&quot;:&quot;https://timculpan.substack.com/p/apple-mobile-processors-are-now-made?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://timculpan.substack.com/p/apple-mobile-processors-are-now-made?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div><p><span>This is a BFD. TSMC Arizona is the marquee project of the US government’s $39 billion </span><a href="https://crsreports.congress.gov/product/pdf/R/R47523" rel="">CHIPS for America Fund</a><span> under the CHIPS Act. Six months ago, I thought Apple might tap Arizona for a less-consequential chip like the H-series used in AirPods. I was surprised when I heard it was the A16. The fact that they went for the most-advanced chip they could manage on US soil, in terms of both technology and volume, shows Apple and TSMC want to start big.</span></p><p><span>(I believe there may be other products also in production at TSMC Arizona, but I don’t have much information on them. </span><em><span>If you do, contact me </span><a href="mailto: tculpan@proton.me" rel="">here</a><span>.</span></em><span>)</span></p><p><span>Currently TSMC is achieving yields in Arizona that are </span><em>slightly behin</em><span>d what’s enjoyed back home in Taiwan (basically, neck and neck). Most important, though, is that improvements are moving so rapidly that true yield parity between Taiwan and Arizona is expected to be reached in coming months.</span></p><p><span>I can’t tell you which Apple device these A16 chips will go into. One possibility is that they’re slated for one of the upcoming iPads, though perhaps not the iPad Mini since </span><a href="https://www.dallasnews.com/business/technology/2024/09/09/everything-to-expect-from-apples-iphone-16-launch-monday/" rel="">Mark Gurman believes</a><span> they’re to be launched around October. Another likelihood is the next iteration of the iPhone SE, which makes sense since it’s supposedly </span><a href="https://www.bloomberg.com/news/newsletters/2024-08-11/iphone-16-preview-bigger-screens-new-colors-camera-button-ai-and-a18-chip-lzpk5495" rel="">based on the iPhone 14</a><span> which uses the A16 processor and is expected next year.</span></p><p>Normally, media outlets will pad out their reportage with lots of background and history. I’ll leave it here. That’s the scoop: Apple’s A16 mobile processors are in production at TSMC on American soil, and that choice of product is hugely significant.</p><p><em>Note to media: yes, you can cite or sum this report. But proper credit is required with a link to this page (you know that I know the rules). Something like: “independent journalist Tim Culpan reported.”</em><span> </span><em>Thanks</em></p></div></article></div></div>]]></description>
        </item>
    </channel>
</rss>