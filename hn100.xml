<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 01 Apr 2025 12:30:13 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Self-Hosting like it's 2025 (106 pts)]]></title>
            <link>https://kiranet.org/self-hosting-like-its-2025/</link>
            <guid>43544979</guid>
            <pubDate>Tue, 01 Apr 2025 10:11:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kiranet.org/self-hosting-like-its-2025/">https://kiranet.org/self-hosting-like-its-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=43544979">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[US accidentally sent Maryland father to Salvadorian prison, can't get him back (114 pts)]]></title>
            <link>https://www.independent.co.uk/news/world/americas/us-politics/trump-el-salvador-abrego-garcia-b2725002.html</link>
            <guid>43544534</guid>
            <pubDate>Tue, 01 Apr 2025 09:14:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.co.uk/news/world/americas/us-politics/trump-el-salvador-abrego-garcia-b2725002.html">https://www.independent.co.uk/news/world/americas/us-politics/trump-el-salvador-abrego-garcia-b2725002.html</a>, See on <a href="https://news.ycombinator.com/item?id=43544534">Hacker News</a></p>
Couldn't get https://www.independent.co.uk/news/world/americas/us-politics/trump-el-salvador-abrego-garcia-b2725002.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Nue – Apps lighter than a React button (365 pts)]]></title>
            <link>https://nuejs.org/blog/large-scale-apps/</link>
            <guid>43543241</guid>
            <pubDate>Tue, 01 Apr 2025 05:47:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nuejs.org/blog/large-scale-apps/">https://nuejs.org/blog/large-scale-apps/</a>, See on <a href="https://news.ycombinator.com/item?id=43543241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    <article>
      <header>
  <time datetime="2025-04-01T00:00:00.000Z">April 1, 2025</time>

  

  

</header>
      <p>On this release we're showing what you can do by taking the modern web standards — HTML, CSS, and JS — to their absolute peak:</p>

<p>The entire app is significantly lighter than a React button:</p>
<figure><picture><source srcset="https://nuejs.org/img/react-button-vs-nue-spa.png" media="(max-width: 750px)" type="image/png">
<source srcset="https://nuejs.org/img/react-button-vs-nue-spa-big.png" media="(min-width: 750px)" type="image/png">
<img loading="lazy" src="https://nuejs.org/img/react-button-vs-nue-spa-big.png" width="704" height="394"></picture></figure>
<p>See benchmark and details <a href="https://nuejs.org/docs/react-button-vs-nue.html">here ›</a></p>
<h2 id="going-large-scale"><a href="#going-large-scale" title="Going large-scale"></a>Going large-scale</h2>
<p>Here’s the same app, now with a <strong>Rust</strong> computation engine and <strong>Event Sourcing</strong> for instant search and other operations over <strong>150,000</strong> records — far past where JavaScript (and React) would crash with a stack overflow error:</p>
<p>

  

  <bunny-player custom="bunny-player">
  
</bunny-player>

  <figcaption>
    Instant operations across 150.000 records with Rust/WASM
  </figcaption>

  

</p>
<p>See this demo <a href="https://mpa.nuejs.org/app/?rust">live ›</a></p>

<p>Nue crushes HMR and build speed records and sets you up with a millisecond feedback loop for your day-to-day VSCode/Sublime file-save operations:</p>
<p>

  

  <bunny-player custom="bunny-player">
  
</bunny-player>

  <figcaption>
    Immediate feedback for design and component updates, preserving app state
  </figcaption>

  

</p>
<video src="https://nuejs.org/img/mpa-build.mp4" type="video/mp4" autoplay="" loop="" muted="" width="350"></video>

<p>Here's what this means:</p>
<h3 id="for-rust-go-and-js-engineers"><a href="#for-rust-go-and-js-engineers" title="For Rust, Go, and JS engineers"></a>For Rust, Go, and JS engineers</h3>
<p>This is a wake-up call for Rust, Go, and JS engineers stuck wrestling with React idioms instead of leaning on timeless software patterns. Nue emphasizes a model-first approach, delivering modular design with simple, testable functions, true static typing, and minimal dependencies. Nue is a liberating experience for system devs whose skills can finally shine in a separated model layer.</p>
<h3 id="for-design-engineers"><a href="#for-design-engineers" title="For Design Engineers"></a>For Design Engineers</h3>
<p>This is a wake-up call for design engineers bogged down by React patterns and <a href="https://github.com/shadcn-ui/ui/tree/main/apps/v4/registry/new-york-v4">40,000+ line</a> design systems. Build radically simpler systems with modern CSS (@layers, variables, calc()) and take control of your typography and whitespace.</p>
<h3 id="for-ux-engineers"><a href="#for-ux-engineers" title="For UX Engineers"></a>For UX Engineers</h3>
<p>This is a wake-up call for UX engineers tangled in React hooks and utility class walls instead of owning the user experience. Build apps as light as a React button to push the web—and your skills—forward.</p>
<h2 id="faq-wth-is-nue"><a href="#faq-wth-is-nue" title="FAQ: WTH is Nue?"></a>FAQ: WTH is Nue?</h2>
<p>Nue is a web framework focused on web standards, currently in active development. We aim to reveal the hidden complexity that’s become normalized in modern web development. When a single button outweighs an entire application, something’s fundamentally broken.</p>
<p>Nue drives the inevitable shift. We’re rebuilding tools and frameworks from the ground up with a cleaner, more robust architecture. Our goal is to restore the joy of web development for all key skill sets: frontend architects, design engineers, and UX engineers.</p>
      
    </article>

    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Duolingo-style exercises but with real-world content like the news (180 pts)]]></title>
            <link>https://app.fluentsubs.com/exercises/daily</link>
            <guid>43543235</guid>
            <pubDate>Tue, 01 Apr 2025 05:46:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://app.fluentsubs.com/exercises/daily">https://app.fluentsubs.com/exercises/daily</a>, See on <a href="https://news.ycombinator.com/item?id=43543235">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[An 'Administrative Error' Sends a Maryland Father to a Salvadoran Prison (101 pts)]]></title>
            <link>https://www.theatlantic.com/politics/archive/2025/03/an-administrative-error-sends-a-man-to-a-salvadoran-prison/682254/</link>
            <guid>43542333</guid>
            <pubDate>Tue, 01 Apr 2025 02:51:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/politics/archive/2025/03/an-administrative-error-sends-a-man-to-a-salvadoran-prison/682254/">https://www.theatlantic.com/politics/archive/2025/03/an-administrative-error-sends-a-man-to-a-salvadoran-prison/682254/</a>, See on <a href="https://news.ycombinator.com/item?id=43542333">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">The Trump administration acknowledged in a court <a data-event-element="inline link" href="https://storage.courtlistener.com/recap/gov.uscourts.mdd.578815/gov.uscourts.mdd.578815.11.0.pdf">filing</a> Monday that it had grabbed a Maryland father with protected legal status and mistakenly deported him to El Salvador, but said that U.S. courts lack jurisdiction to order his return from the megaprison where he’s now locked up.</p><p data-flatplan-paragraph="true">The case appears to be the first time the Trump administration has admitted to errors when it sent three planeloads of Salvadoran and Venezuelan deportees to El Salvador’s grim “Terrorism Confinement Center” on March 15. Attorneys for several Venezuelan deportees have said that the Trump administration falsely labeled their clients as gang members because of their tattoos. Trump officials have disputed those claims.</p><p data-flatplan-paragraph="true">But in Monday’s court filing, attorneys for the government admitted that the Salvadoran man, Kilmar Abrego Garcia, was deported accidentally. “Although ICE was aware of his protection from removal to El Salvador, Abrego Garcia was removed to El Salvador because of an administrative error,” the government told the court. Trump lawyers said the court has no ability to bring him back now that Abrego Garcia is in Salvadoran custody.</p><p data-flatplan-paragraph="true">Simon Sandoval-Moshenberg, Abrego Garcia’s attorney, said he’s never seen a case in which the government knowingly deported someone who had already received protected legal status from an immigration judge. He is asking the court to order the Trump administration to ask for Abrego Garcia’s return and, if necessary, to withhold payment to the Salvadoran government, which says it’s charging the United States $6 million a year to jail U.S. deportees.</p><p data-flatplan-paragraph="true">Trump administration attorneys told the court to dismiss the request on multiple grounds, including that Trump’s “primacy in foreign affairs” outweighs the interests of Abrego Garcia and his family.</p><p data-flatplan-paragraph="true">“They claim that the court is powerless to order any relief,’’ Sandoval-Moshenberg told me. “If that’s true, the immigration laws are meaningless—all of them—because the government can deport whoever they want, wherever they want, whenever they want, and no court can do anything about it once it’s done.”</p><p data-flatplan-paragraph="true">Court <a data-event-element="inline link" href="https://storage.courtlistener.com/recap/gov.uscourts.mdd.578815/gov.uscourts.mdd.578815.1.0.pdf">filings</a> show Abrego Garcia came to the United States at age 16 in 2011 after fleeing gang threats in his native El Salvador. In 2019 he received a form of protected legal status known as “withholding of removal” from a U.S. immigration judge who found he would likely be targeted by gangs if deported back.</p><p data-flatplan-paragraph="true">Abrego Garcia, who is married to a U.S. citizen and has a 5-year-old disabled child who is also a U.S. citizen, has no criminal record in the United States, according to his attorney. The Trump administration does not claim he has a criminal record, but called him a “danger to the community” and an active member of MS-13, the Salvadoran gang that Trump has declared a Foreign Terrorist Organization.</p><p data-flatplan-paragraph="true">Sandoval-Moshenberg said those charges are false, and the gang label stems from a 2019 incident when Abrego Garcia and three other men were detained in a Home Depot parking lot by a police detective in Prince George’s County, Maryland. During questioning, one of the men told officers Abrego Garcia was a gang member, but the man offered no proof and police said they didn’t believe him, filings show. Police did not identify him as a gang member.</p><p data-flatplan-paragraph="true">Abrego Garcia was not charged with a crime, but he was handed over to U.S. Immigration and Customs Enforcement after the arrest to face deportation. In those proceedings, the government claimed that a reliable informant had identified him as a ranking member of MS-13. Abrego Garcia and his family hired an attorney and fought the government’s attempt to deport him. He received “withholding of removal” six months later, a protected status.</p><p data-flatplan-paragraph="true">It is not a path to permanent U.S. residency, but it means the government won’t deport him back to his home country because he’s more likely than not to face harm there.</p><p data-flatplan-paragraph="true">Abrego Garcia has had no contact with any law enforcement agency since his release, according to his attorney. He works full time as a union sheetmetal apprentice, has complied with requirements to check in annually with ICE, and cares for his five-year-old son, who has autism and a hearing defect, and is unable to communicate verbally.</p><p data-flatplan-paragraph="true">On March 12 Abrego Garcia had picked up his son after work from the boy’s grandmother’s house when ICE officers stopped the car, saying his protected status had changed. Officers waited for Abrego Garcia’s wife to come to the scene and take care of the boy, then drove him away in handcuffs. Within two days he had been transferred to an ICE staging facility in Texas, along with other detainees the government was preparing to send to El Salvador. Trump had invoked the Alien Enemies Act of 1798, and the government planned to deport two planeloads of Venezuelans along with a separate group of Salvadorans.</p><p data-flatplan-paragraph="true">Abrego Garcia’s family has had no contact with him since he was sent to the megaprison in El Salvador, known as the CECOT. His wife spotted her husband in news photographs released by Salvadoran President Nayib Bukele on the morning of March 16, after a U.S. District Judge had told the Trump administration to halt the flights.</p><p data-flatplan-paragraph="true">“Oopsie,” Bukele <a data-event-element="inline link" href="https://x.com/nayibbukele/status/1901238762614517965">wrote</a> on social media, taunting the judge.</p><p data-flatplan-paragraph="true">Abrego Garcia’s wife recognized her husband’s decorative arm tattoo and scars, according to the court filing. The image showed Salvadoran guards in black ski masks frog-marching him into the prison, with his head shoved down toward the floor. The CECOT is the same prison Department of Homeland Security Secretary Kristi Noem visited last week, recording videos for social media while standing in front of a cell packed with silent detainees.</p><p data-flatplan-paragraph="true">If the government wants to deport someone with protected status, the standard course would be to reopen the case and introduce new evidence arguing for deportation. The deportation of a protected status holder has even stunned some government attorneys I’ve been in touch with who are tracking the case, who declined to be named because they weren’t authorized to speak to the press. “What. The. Fuck,” one texted me.</p><p data-flatplan-paragraph="true">Sandoval-Moshenberg told the court he believes Trump officials deported his client “through extrajudicial means because they believed that going through the immigration judge process took too long, and they feared that they might not win all of their cases.’’</p><p data-flatplan-paragraph="true">Officials at ICE and the Department of Homeland Security did not respond to a request for comment. The Monday court filing by the government indicates officials knew Abrego Garcia had legal protections shielding him from deportation to El Salvador.</p><p data-flatplan-paragraph="true">“ICE was aware of this grant of withholding of removal at the time [of] Abrego Garcia’s removal from the United States. Reference was made to this status on internal forms,” the government told the court in its filing.</p><p data-flatplan-paragraph="true">Abrego Garcia was not on the initial manifest of the deportation flight, but was listed “as an alternate,” the government attorneys explained. As other detainees were removed from the flight for various reasons, Abrego Garcia “moved up the list.’’</p><p data-flatplan-paragraph="true">The flight manifest “did not indicate that Abrego-Garcia should not be removed,’’ the attorneys said. “Through administrative error, Abrego-Garcia was removed from the United States to El Salvador. This was an oversight.” But despite this, they told the court that Abrego Garcia’s deportation was carried out ‘’in good faith.’’</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Get the hell out of the LLM as soon as possible (285 pts)]]></title>
            <link>https://sgnt.ai/p/hell-out-of-llms/</link>
            <guid>43542259</guid>
            <pubDate>Tue, 01 Apr 2025 02:34:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sgnt.ai/p/hell-out-of-llms/">https://sgnt.ai/p/hell-out-of-llms/</a>, See on <a href="https://news.ycombinator.com/item?id=43542259">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <figure>
  <img src="https://sgnt.ai/hell.jpeg" alt="Get out of there">
</figure>
<p>Don’t let an LLM make decisions or implement business logic: they suck at that. I build NPCs for an online game, and I get asked a lot “How did you get ChatGPT to do that?” The answer is invariably: “I didn’t, and also you shouldn’t”.</p>
<p>In most applications, the LLM should be the user-interface only between the user and an API into your application logic. The LLM shouldn’t be implementing any logic. Get the hell out of the LLM as soon as possible, and stay out as long as you can.</p>
<h2 id="y-tho">Y Tho?</h2>
<p>This is best illustrated by a contrived example: you want to write a chess-playing bot you access over WhatsApp. The user sends a description of what they want to do (“use my bishop to take the knight”), and the bot plays against them.</p>
<p>Could you get the LLM to be in charge of maintaining the state of the chess board and playing convincingly? <a href="https://dynomight.net/chess/">Possibly, maybe</a>. Would you? Hell no, for some intuitive reasons:</p>
<ul>
<li><strong>Performance</strong>: It’s impressive that LLMs might be able to play chess at all, but they suck at it (as of 2025-04-01). A specialized chess engine is always going to be a faster, better, cheaper chess player. Even modern chess engines like Stockfish that incorporate neural networks are still purpose-built specialized systems with well-defined inputs and evaluation functions - not general-purpose language models trying to maintain game state through text.</li>
<li><strong>Debugging and adjusting</strong>: It’s impossible to reason about and debug <em>why</em> the LLM made a given decision, which means it’s very hard to change <em>how</em> it makes those decisions if you need to tweak them. You don’t understand the journey it took through the high-dimensional semantic space to get to your answer, and it’s really poor at explaining it too. Even purpose-built neural networks like those in chess engines can be challenging for observability, and a general LLM is a nightmare, despite Anthropic’s <a href="https://www.anthropic.com/research/tracing-thoughts-language-model">great strides in this area</a></li>
<li><strong>And the rest…</strong>: testing LLM outputs is much harder than unit-testing known code-paths; LLMs are much worse at math than your CPU; LLMs are insufficiently good at picking random numbers; version-control and auditing becomes much harder; monitoring and observability gets painful; state management through natural language is fragile; you’re at the mercy of API rate limits and costs; and security boundaries become fuzzy when everything flows through prompts.</li>
</ul>
<h2 id="examples"><strong>Examples</strong></h2>
<p>The chess example illustrates the fundamental problem with using LLMs for core application logic, but this principle extends far beyond games. In any domain where precision, reliability, and efficiency matter, you should follow the same approach:</p>
<ol>
<li>The user says they want to attack player X with their vorpal sword? The LLM shouldn’t be the system figuring out is the user has a vorpal sword, or what the results of that would be: the LLM is responsible for translating the free-text the user gave you into an API call <em>only</em> and translating the result into text for the user</li>
<li>You’re building a negotiation agent that should respond to user offers? The LLM isn’t in charge of the negotiation, just in charge of packaging it up, passing it off to the negotiating engine, and telling the user about the result</li>
<li>You need to make a random choice about how to respond to the user? The LLM doesn’t get to choose</li>
</ol>
<h2 id="reminder-of-what-llms-are-good-at"><strong>Reminder of what LLMs are good at</strong></h2>
<p>While I’ve focused on what LLMs shouldn’t do, it’s equally important to understand their strengths so you can leverage them appropriately:</p>
<p>LLMs excel at transformation and at categorization, and have a pretty good grounding in “how the world works”, and this is where you in your process you should be deploying them.</p>
<p>The LLM is good at taking “hit the orc with my sword” and turning it into <code>attack(target="orc", weapon="sword")</code>. Or taking <code>{"error": "insufficient_funds"}</code> and turning it into “You don’t have enough gold for that.”</p>
<p>The LLM is good at figuring out what the hell the user is trying to do and routing it to the right part of your system. Is this a combat command? An inventory check? A request for help?</p>
<p>Finally, the LLM is good at knowing about human concepts, and knowing that a “blade” is probably a sword and “smash” probably means attack.</p>
<p>Notice that all these strengths involve transformation, interpretation, or communication—not complex decision-making or maintaining critical application state. By restricting LLMs to these roles, you get their benefits without the pitfalls described earlier.</p>
<h2 id="the-future"><strong>The future</strong></h2>
<p>What LLMs can and can’t do is ever-shifting and reminds me of the “<a href="https://en.wikipedia.org/wiki/God_of_the_gaps">God of the gaps</a>”. a term from theology where each mysterious phenomenon was once explained by divine intervention—until science filled that gap. Likewise, people constantly identify new “human-only” tasks to claim that LLMs aren’t truly intelligent or capable. Then, just a few months later, a new model emerges that handles those tasks just fine, forcing everyone to move the goalposts again, examples <em>passim</em>. It’s a constantly evolving target, and what seems out of reach today may be solved sooner than we expect.</p>
<p>And so like in our chess example, we will probably soon end up with LLMs that can handle all of our above examples reasonably well. I suspect however that most of the drawbacks won’t go away: your non-LLM logic that you pass off to is going to be easier to reason about, easier to maintain, cheaper to run, and more easily version-controlled.</p>
<p>Even as LLMs continue to improve, the fundamental architectural principle remains: use LLMs for what they’re best at—the interface layer—and rely on purpose-built systems for your core logic.</p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The case against conversational interfaces (224 pts)]]></title>
            <link>https://julian.digital/2025/03/27/the-case-against-conversational-interfaces/</link>
            <guid>43542131</guid>
            <pubDate>Tue, 01 Apr 2025 02:14:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://julian.digital/2025/03/27/the-case-against-conversational-interfaces/">https://julian.digital/2025/03/27/the-case-against-conversational-interfaces/</a>, See on <a href="https://news.ycombinator.com/item?id=43542131">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
 		
<p><span>01</span> Intro</p>



<p>Conversational interfaces are a bit of a meme. Every couple of years a shiny new AI development emerges and people in tech go <em>“This is it! The next computing paradigm is here! We’ll only use natural language going forward!”</em>. But then nothing actually changes and we continue using computers the way we always have, until the debate resurfaces a few years later.</p>



<p>We’ve gone through this cycle a couple of times now: Virtual assistants (Siri), smart speakers (Alexa, Google Home), chatbots (<a href="https://medium.com/chris-messina/conversational-commerce-92e0bccfc3ff">“conversational commerce”</a>), <a href="http://julian.digital/2020/04/19/airpods-as-a-platform/">AirPods-as-a-platform</a>, and, most recently, large language models.</p>



<p>I’m not entirely sure where this obsession with conversational interfaces comes from. Perhaps it’s a type of anemoia, a nostalgia for a future we saw in StarTrek that never became reality. Or maybe it’s simply that people look at the term <em>“<strong>natural</strong> language”</em> and think <em>“well, if it’s <strong>natural</strong> then it must be the logical end state”</em>.</p>



<p>I’m here to tell you that it’s not.</p>



<p><span>02</span> Data transfer mechanisms</p>



<p>When people say <em>“natural language”</em> what they mean is written or verbal communication. Natural language is a way to exchange ideas and knowledge between humans. In other words, it’s a data transfer mechanism.</p>



<p>Data transfer mechanisms have two critical factors: speed and lossiness.</p>



<p>Speed determines how quickly data is transferred from the sender to the receiver, while lossiness refers to how accurately the data is transferred. In an ideal state, you want data transfer to happen at maximum speed (instant) and with perfect fidelity (lossless), but these two attributes are often a bit of a trade-off. </p>



<p>Let’s look at how well natural language does on the speed dimension:</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2025/02/datatransfer.png"></p><p>The first thing I should note is that these data points are <a href="https://www.researchgate.net/publication/332380784_How_many_words_do_we_read_per_minute_A_review_and_meta-analysis_of_reading_rate">very</a>, <a href="https://irisreading.com/what-is-the-average-reading-speed/">very</a> <a href="https://virtualspeech.com/blog/average-speaking-rate-words-per-minute">simplified</a> <a href="https://en.wikipedia.org/wiki/Words_per_minute">averages</a>. The important part to take away from this table is not the accuracy of individual numbers, but the overall pattern: We are significantly faster at receiving data (reading, listening) than sending it (writing, speaking). This is why we can listen to podcasts at 2x speed, but not record them at 2x speed.</p>



<p>To put the writing and speaking speeds into perspective, <strong>we form thoughts at 1,000-3,000 words per minute</strong>. Natural language might be natural, but it’s a bottleneck.</p>



<p>And yet, if you think about your day-to-day interactions with other humans, most communication feels really fast and efficient. That’s because natural language is only one of many data transfer mechanisms available to us.</p>



<p>For example, instead of saying <em>“I think what you just said is a great idea”</em>, I can just give you a thumbs up. Or nod my head. Or simply smile. </p>



<p>Gestures and facial expressions are effectively data compression techniques. They encode information in a more compact, but lossier, form to make it faster and more convenient to transmit.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2025/01/thumbsup.png"></p><p>Natural language is great for data transfer that requires high fidelity (or as a data storage mechanism for async communication), but whenever possible we switch to other modes of communication that are faster and more effortless. Speed and convenience always wins.</p>



<p>My favorite example of truly effortless communication is a memory I have of my grandparents. At the breakfast table, my grandmother never had to ask for the butter – my grandfather always seemed to pass it to her automatically, because after 50+ years of marriage he just sensed that she was about to ask for it. It was like they were communicating telepathically.  </p>



<p>*That* is the type of relationship I want to have with my computer!</p>



<p><span>03</span> Human Computer Interaction</p>



<p>Similar to human-to-human communication, there are different data transfer mechanisms to exchange information between humans and computers. In the early days of computing, users interacted with computers through a command line. These text-based commands were effectively a natural language interface, but required precise syntax and a deep understanding of the system.</p>



<p>The introduction of the GUI primarily solved a discovery problem: Instead of having to memorize exact text commands, you could now navigate and perform tasks through visual elements like menus and buttons. This didn’t just make things easier to discover, but also more convenient: It’s faster to click a button than to type a long text command.</p>



<p>Today, we live in a productivity equilibrium that combines graphical interfaces with keyboard-based commands.</p>



<p>We still use our mouse to navigate and tell our computers what to do next, but routine actions are typically communicated in form of quick-fire keyboard presses: <span>⌘</span><span>b</span> to format text as bold, <span>⌘</span><span>t</span> to open a new tab, <span>⌘</span><span>c</span>/<span>v</span> to quickly copy things from one place to another, etc.</p>



<p>These shortcuts are not natural language though. They are another form of data compression. Like a thumbs up or a nod, they help us to communicate faster.</p>



<p>Modern productivity tools take these data compression shortcuts to the next level. In tools like Linear, Raycast or Superhuman every single command is just a keystroke away. Once you’ve built the muscle memory, the data input feels completely effortless. It’s almost like being handed the butter at the breakfast table without having to ask for it.</p>



<p>Touch-based interfaces are considered the third pivotal milestone in the evolution of human computer interaction, but they have always been more of an augmentation of desktop computing rather than a replacement for it. Smartphones are great for “away from keyboard” workflows, but important productivity work still happens on desktop.</p>



<p><a href="https://x.com/blakeir/status/1838365114312872320">
  <img decoding="async" src="https://julian.digital/wp-content/uploads/2025/03/blake-1.png">
</a></p><p>That’s because text is not a mobile-native input mechanism. A physical keyboard can feel like a natural extension of your mind and body, but typing on a phone is always a little awkward – and it shows in data transfer speeds: <a href="https://userinterfaces.aalto.fi/typing37k/">Average typing speeds on mobile are just 36 words-per-minute</a>, notably slower than the ~60 words-per-minute on desktop.</p>



<p>We’ve been able to replace natural language with mobile-specific data compression algorithms like emojis or Snapchat selfies, but we’ve never found a mobile equivalent for keyboard shortcuts. Guess why we still don’t have a truly mobile-first productivity app after almost 20 years since the introduction of the iPhone?</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2025/02/emojis.png"></p><p><em>“But what about speech-to-text,”</em> you might say, pointing to <a href="https://www.npr.org/2023/04/16/1170232936/voice-notes-messages-trend">reports</a> about increasing usage of voice messaging. It’s true that speaking (150wpm) is indeed a faster data transfer mechanism than typing (60wpm), but that doesn’t automatically make it a better method to interact with computers.</p>



<p>We keep telling ourselves that previous voice interfaces like Alexa or Siri didn’t succeed because the underlying AI wasn’t smart enough, but that’s only half of the story. The core problem was never the quality of the output function, but the inconvenience of the input function: A natural language prompt like <em>“Hey Google, what’s the weather in San Francisco today?”</em> just takes 10x longer than simply tapping the weather app on your homescreen.</p>



<p>LLMs don’t solve this problem. The quality of their output is improving at an astonishing rate, but the input modality is a step backwards from what we already have. Why should I have to describe my desired action using natural language, when I could simply press a button or keyboard shortcut? Just pass me the goddamn butter.</p>



<p><span>04</span> Conversational UI as Augmentation</p>



<p>None of this is to say that LLMs aren’t great. I love LLMs. I use them all the time. In fact, I wrote this very essay with the help of an LLM. </p>



<p>Instead of drafting a first version with pen and paper (my preferred writing tools), I spent an entire hour walking outside, talking to ChatGPT in Advanced Voice Mode. We went through all the fuzzy ideas in my head, clarified and organized them, explored some additional talking points, and eventually pulled everything together into a first outline.</p>



<p>This wasn’t just a one-sided “<em>Hey, can you write a few paragraphs about x</em>” <a href="https://x.com/julianlehr/status/1855858599156932773">prompt</a>. It felt like a genuine, in-depth conversation and exchange of ideas with a true thought partner. Even weeks later, I’m still amazed at how well it worked. It was one of those rare, magical moments where software makes you feel like you’re living in the future.</p>



<p>In contrast to typical human-to-computer commands, however, this workflow is not defined by speed. Like writing, my ChatGPT conversation is a thinking process – not an interaction that happens post-thought.</p>



<p>It should also be noted that ChatGPT does not substitute any existing software workflows in this example. It’s a completely new use case.</p>



<p>This brings me to my core thesis: The inconvenience and inferior data transfer speeds of conversational interfaces make them an unlikely replacement for existing computing paradigms – but what if they complement them?</p>



<p>The most convincing conversational UI I have seen to date was at a hackathon where a team turned <a href="https://upsidelab.io/blog/design-voice-user-interface-starcraft">Amazon Alexa into an in-game voice assistant for StarCraft II</a>. Rather than replacing mouse and keyboard, voice acted as an <em>additional</em> input mechanism. It increased the bandwidth of the data transfer.</p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2025/03/starcraft-2.png"></p><p>You could see the same pattern work for any type of knowledge work, where voice commands are available <em>while</em> you are busy doing other things. We will not replace Figma, Notion, or Excel with a chat interface. It’s not going to happen. Neither will we forever continue the status quo, where we constantly have to switch back and forth between these tools and an LLM.</p>



<p>Instead, AI should function as an always-on command meta-layer that spans across all tools. Users should be able to trigger actions from anywhere with simple voice prompts without having to interrupt whatever they are currently doing with mouse and keyboard.</p>



<p>For this future to become an actual reality, AI needs to work at the OS level. It’s not meant to be an interface for a single tool, but an interface across tools. <a href="https://kwokchain.com/2019/08/16/the-arc-of-collaboration/">Kevin Kwok famously wrote</a> that <em>“productivity and collaboration shouldn’t be two separate workflows”</em>. And while he was referring to human-to-human collaboration, the statement is even more true in a world of human-to-AI collaboration, where the lines between productivity and coordination are becoming increasingly more blurry. </p>



<p><img decoding="async" src="https://julian.digital/wp-content/uploads/2025/03/metalayer-1.png"></p><p>The second thing we need to figure out is how we can compress voice input to make it faster to transmit. What’s the voice equivalent of a thumbs-up or a keyboard shortcut? Can I prompt Claude faster with simple sounds and whistles? Should ChatGPT have access to my camera so it can change its answers in realtime based on my facial expressions?</p>



<p>Even as a secondary interface, speed and convenience is all that matters.</p>



<p><span>05</span> Closing thoughts</p>



<p>I admit that the title of this essay is a bit misleading (made you click though, didn’t it?). This isn’t really a case against conversational interfaces, it’s a case against zero-sum thinking.</p>



<p>We spend too much time thinking about AI as a substitute (for interfaces, workflows, and jobs) and too little time about AI as a complement. Progress rarely follows a simple path of replacement. It unlocks new, previously unimaginable things rather than merely displacing what came before.</p>



<p>The same is true here. The future isn’t about replacing existing computing paradigms with chat interfaces, but about enhancing them to make human-computer interaction feel effortless – like the silent exchange of butter at a well-worn breakfast table.</p>







<p><em>Thanks to Blake Robbins, Chris Paik, Jackson Dahl, Johannes Schickling, Jordan Singer, and signüll for reading drafts of this post.</em></p>




 	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Netflix's Media Production Suite (174 pts)]]></title>
            <link>https://netflixtechblog.com/globalizing-productions-with-netflixs-media-production-suite-fc3c108c0a22</link>
            <guid>43541759</guid>
            <pubDate>Tue, 01 Apr 2025 01:02:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://netflixtechblog.com/globalizing-productions-with-netflixs-media-production-suite-fc3c108c0a22">https://netflixtechblog.com/globalizing-productions-with-netflixs-media-production-suite-fc3c108c0a22</a>, See on <a href="https://news.ycombinator.com/item?id=43541759">Hacker News</a></p>
Couldn't get https://netflixtechblog.com/globalizing-productions-with-netflixs-media-production-suite-fc3c108c0a22: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Everything is Ghibli (122 pts)]]></title>
            <link>https://carly.substack.com/p/everything-is-ghibli</link>
            <guid>43540326</guid>
            <pubDate>Mon, 31 Mar 2025 21:44:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://carly.substack.com/p/everything-is-ghibli">https://carly.substack.com/p/everything-is-ghibli</a>, See on <a href="https://news.ycombinator.com/item?id=43540326">Hacker News</a></p>
Couldn't get https://carly.substack.com/p/everything-is-ghibli: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Go Optimization Guide (330 pts)]]></title>
            <link>https://goperf.dev/</link>
            <guid>43539585</guid>
            <pubDate>Mon, 31 Mar 2025 20:29:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://goperf.dev/">https://goperf.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=43539585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              <article>
                
                  


  
  


<h2 id="patterns-and-techniques-for-writing-high-performance-applications-with-go">Patterns and Techniques for Writing High-Performance Applications with Go<a href="#patterns-and-techniques-for-writing-high-performance-applications-with-go" title="Permanent link">¶</a></h2>
<p>The <strong>Go App Optimization Series</strong> is a collection of technical articles aimed at helping developers write faster, more efficient Go applications. Whether you're building high-throughput APIs, microservices, or distributed systems, this series offers practical patterns, real-world use cases, and low-level performance insights to guide your optimization efforts.</p>
<p>While Go doesn’t expose as many knobs for performance tuning as languages like C++ or Rust, it still provides <strong>plenty of opportunities</strong> to make your applications significantly faster. From memory reuse and allocation control to efficient networking and concurrency patterns, Go offers a pragmatic set of tools for writing high-performance code.</p>
<p>We focus on <strong>concrete techniques</strong> with <strong>mesurable impact</strong> you can apply immediately—covering everything from core language features to advanced networking strategies.</p>
<h2 id="whats-covered-so-far"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 13c.7 0 1.37.13 2 .35V9l-6-6H5c-1.11 0-2 .89-2 2v14a2 2 0 0 0 2 2h8.35c-.22-.63-.35-1.3-.35-2 0-3.31 2.69-6 6-6m-5-8.5 5.5 5.5H14zm8.5 12.75L17.75 22 15 19l1.16-1.16 1.59 1.59 3.59-3.59z"></path></svg></span> What’s Covered So Far<a href="#whats-covered-so-far" title="Permanent link">¶</a></h2>
<h3 id="common-go-patterns-for-performance"><a href="https://goperf.dev/01-common-patterns/">Common Go Patterns for Performance</a><a href="#common-go-patterns-for-performance" title="Permanent link">¶</a></h3>
<p>In this first article, we explore a curated set of high-impact performance patterns every Go developer should know:</p>
<ul>
<li>Using <code>sync.Pool</code> effectively</li>
<li>Avoiding unnecessary allocations</li>
<li>Struct layout and memory alignment</li>
<li>Efficient error handling</li>
<li>Zero-cost abstractions with interfaces</li>
<li>In-place sorting and slices reuse</li>
</ul>
<p>Each pattern is grounded in practical use cases, with benchmarks and examples you can copy into your own codebase.</p>
<hr>
<h2 id="whats-coming-next"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 2.03v2.02c4.39.54 7.5 4.53 6.96 8.92-.46 3.64-3.32 6.53-6.96 6.96v2c5.5-.55 9.5-5.43 8.95-10.93-.45-4.75-4.22-8.5-8.95-8.97m-2 .03c-1.95.19-3.81.94-5.33 2.2L7.1 5.74c1.12-.9 2.47-1.48 3.9-1.68zM4.26 5.67A9.9 9.9 0 0 0 2.05 11h2c.19-1.42.75-2.77 1.64-3.9zM15.5 8.5l-4.88 4.88-2.12-2.12-1.06 1.06 3.18 3.18 5.94-5.94zM2.06 13c.2 1.96.97 3.81 2.21 5.33l1.42-1.43A8 8 0 0 1 4.06 13zm5.04 5.37-1.43 1.37A10 10 0 0 0 11 22v-2a8 8 0 0 1-3.9-1.63"></path></svg></span> What’s Coming Next<a href="#whats-coming-next" title="Permanent link">¶</a></h2>
<h3 id="high-performance-networking-in-go">High-Performance Networking in Go<a href="#high-performance-networking-in-go" title="Permanent link">¶</a></h3>
<p>In our upcoming deep dive into networking, we'll focus on building high-throughput network services with Go’s standard library and beyond. This includes:</p>
<ul>
<li>Efficient use of <code>net/http</code> and <code>net.Conn</code></li>
<li>Managing large volumes of concurrent connections</li>
<li>Performance tuning with epoll/kqueue and <code>GOMAXPROCS</code></li>
<li>Load testing techniques and bottleneck diagnostics</li>
<li>TBD...</li>
</ul>
<p>We'll also explore when to drop down to lower-level libraries like <code>fasthttp</code>, and how to balance performance with maintainability.</p>
<hr>
<h2 id="who-this-is-for"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19.03 6.03 20 7l2-5-5 2 .97.97-1.82 1.82C10.87 2.16 3.3 3.94 2.97 4L2 4.26l.5 1.94.79-.2 6.83 6.82L6.94 16H5l-3 3 2 1 1 2 3-3v-1.94l3.18-3.18L18 20.71l-.19.79 1.93.5.26-.97c.06-.33 1.84-7.9-2.79-13.18zM4.5 5.78c2.05-.28 6.78-.5 10.23 2.43l-3.91 3.91zM18.22 19.5l-6.34-6.32 3.91-3.91c2.93 3.45 2.71 8.18 2.43 10.23"></path></svg></span> Who This Is For<a href="#who-this-is-for" title="Permanent link">¶</a></h2>
<p>This series is ideal for:</p>
<ul>
<li>Backend engineers optimizing Go services in production</li>
<li>Developers working on latency-sensitive systems</li>
<li>Teams migrating to Go and building performance-critical paths</li>
<li>Anyone curious about Go’s performance model and trade-offs</li>
</ul>
<hr>
<p>Stay tuned—more articles, code samples, and tools are on the way. You can bookmark this page to follow the series as it evolves.</p>







  
    
  
  
    
  


  





                
              </article>
            </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[KOReader: Open-Source eBook Reader (271 pts)]]></title>
            <link>https://github.com/koreader/koreader</link>
            <guid>43539103</guid>
            <pubDate>Mon, 31 Mar 2025 19:52:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/koreader/koreader">https://github.com/koreader/koreader</a>, See on <a href="https://news.ycombinator.com/item?id=43539103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://koreader.rocks/" rel="nofollow"><img src="https://raw.githubusercontent.com/koreader/koreader.github.io/master/koreader-logo.png" alt="KOReader"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">KOReader is a document viewer primarily aimed at e-ink readers.</h4><a id="user-content-koreader-is-a-document-viewer-primarily-aimed-at-e-ink-readers" aria-label="Permalink: KOReader is a document viewer primarily aimed at e-ink readers." href="#koreader-is-a-document-viewer-primarily-aimed-at-e-ink-readers"></a></p>
<p dir="auto"><a href="https://github.com/koreader/koreader/blob/master/COPYING"><img src="https://camo.githubusercontent.com/5bb38e76b63285b53eefb8b5ec6047b0ea2e12c3e4aeb04358366b5c8a22266b/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6b6f7265616465722f6b6f726561646572" alt="AGPL Licence" data-canonical-src="https://img.shields.io/github/license/koreader/koreader"></a>
<a href="https://github.com/koreader/koreader/releases"><img src="https://camo.githubusercontent.com/f0e1aa8bfa9e1a000beef74d8a3c6c82e5730eb272790a5640b442ef481b19d2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f72656c656173652f6b6f7265616465722f6b6f7265616465722e737667" alt="Latest release" data-canonical-src="https://img.shields.io/github/release/koreader/koreader.svg"></a>
<a href="https://gitter.im/koreader/koreader" rel="nofollow"><img src="https://camo.githubusercontent.com/7513ddfad8bc40022e947a027b821ea79e33194c3c01f540c0d541c385cacca0/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6b6f7265616465722f6b6f7265616465723f636f6c6f723d726564" alt="Gitter" data-canonical-src="https://img.shields.io/gitter/room/koreader/koreader?color=red"></a>
<a href="http://www.mobileread.com/forums/forumdisplay.php?f=276" rel="nofollow"><img src="https://camo.githubusercontent.com/93aec7413392831b748bcae5e985b60b91edf256d39015cee75ba483038396e7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f666f72756d2d6f6e5f6d6f62696c65726561642d6c6967687467726579" alt="Mobileread" data-canonical-src="https://img.shields.io/badge/forum-on_mobileread-lightgrey"></a>
<a href="https://circleci.com/gh/koreader/koreader" rel="nofollow"><img src="https://camo.githubusercontent.com/c1ab248628b1eba39c7bd6231da7d4c4d2f09df39cce5da94e234331e1eea826/68747470733a2f2f636972636c6563692e636f6d2f67682f6b6f7265616465722f6b6f7265616465722e7376673f7374796c653d736869656c64" alt="Build Status" data-canonical-src="https://circleci.com/gh/koreader/koreader.svg?style=shield"></a>
<a href="https://codecov.io/gh/koreader/koreader" rel="nofollow"><img src="https://camo.githubusercontent.com/ba8273e053b14d0b09437a11b82e8c0025ed5b42488798e7737e70e3049fa431/68747470733a2f2f636f6465636f762e696f2f67682f6b6f7265616465722f6b6f7265616465722f6272616e63682f6d61737465722f67726170682f62616467652e737667" alt="Coverage Status" data-canonical-src="https://codecov.io/gh/koreader/koreader/branch/master/graph/badge.svg"></a>
<a href="https://hosted.weblate.org/engage/koreader/?utm_source=widget" rel="nofollow"><img src="https://camo.githubusercontent.com/daac1cb6aa37b411df148843881e1144e1a4f7c5387114db23e928a911aed718/68747470733a2f2f686f737465642e7765626c6174652e6f72672f776964676574732f6b6f7265616465722f2d2f6b6f7265616465722f7376672d62616467652e737667" alt="Weblate Status" data-canonical-src="https://hosted.weblate.org/widgets/koreader/-/koreader/svg-badge.svg"></a></p>
<p dir="auto"><a href="https://github.com/koreader/koreader/releases">Download</a> •
<a href="http://koreader.rocks/user_guide/" rel="nofollow">User guide</a> •
<a href="https://github.com/koreader/koreader/wiki">Wiki</a> •
<a href="http://koreader.rocks/doc/" rel="nofollow">Developer docs</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Main features</h2><a id="user-content-main-features" aria-label="Permalink: Main features" href="#main-features"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>portable</strong>: runs on embedded devices (Cervantes, Kindle, Kobo, PocketBook, reMarkable), Android and Linux computers. Developers can run a KOReader emulator in Linux and MacOS.</p>
</li>
<li>
<p dir="auto"><strong>multi-format documents</strong>: supports fixed page formats (PDF, DjVu, CBT, CBZ) and reflowable e-book formats (EPUB, FB2, Mobi, DOC, RTF, HTML, CHM, TXT). Scanned PDF/DjVu documents can also be reflowed with the built-in K2pdfopt library. <a href="https://github.com/koreader/koreader/wiki/ZIP">ZIP files</a> are also supported for some formats.</p>
</li>
<li>
<p dir="auto"><strong>full-featured reading</strong>: multi-lingual user interface with a highly customizable reader view and many typesetting options. You can set arbitrary page margins, override line spacing and choose external fonts and styles. It has multi-lingual hyphenation dictionaries bundled into the application.</p>
</li>
<li>
<p dir="auto"><strong>integrated</strong> with <em>calibre</em> (search metadata, receive ebooks wirelessly, browse library via OPDS), <em>Wallabag</em>, <em>Wikipedia</em>, <em>Google Translate</em> and other content providers.</p>
</li>
<li>
<p dir="auto"><strong>optimized for e-ink devices</strong>: custom UI without animation, with paginated menus, adjustable text contrast, and easy zoom to fit content or page in paged media.</p>
</li>
<li>
<p dir="auto"><strong>extensible</strong>: via plugins</p>
</li>
<li>
<p dir="auto"><strong>fast</strong>: on some older devices, it has been measured to have less than half the page-turn delay as the built in reading software.</p>
</li>
<li>
<p dir="auto"><strong>and much more</strong>: look up words with StarDict dictionaries / Wikipedia, add your own online OPDS catalogs and RSS feeds, over-the-air software updates, an FTP client, an SSH server, …</p>
</li>
</ul>
<p dir="auto">Please check the <a href="http://koreader.rocks/user_guide/" rel="nofollow">user guide</a> and the <a href="https://github.com/koreader/koreader/wiki">wiki</a> to discover more features and to help us document them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><a href="https://github.com/koreader/koreader-artwork/raw/master/koreader-menu.png"><img src="https://github.com/koreader/koreader-artwork/raw/master/koreader-menu-thumbnail.png" alt="" width="200px"></a>
<a href="https://github.com/koreader/koreader-artwork/raw/master/koreader-footnotes.png"><img src="https://github.com/koreader/koreader-artwork/raw/master/koreader-footnotes-thumbnail.png" alt="" width="200px"></a>
<a href="https://github.com/koreader/koreader-artwork/raw/master/koreader-dictionary.png"><img src="https://github.com/koreader/koreader-artwork/raw/master/koreader-dictionary-thumbnail.png" alt="" width="200px"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Please follow the model specific steps for your device:</p>
<p dir="auto"><a href="https://github.com/koreader/koreader/wiki/Installation-on-Android-devices">Android</a> •
<a href="https://github.com/koreader/koreader/wiki/Installation-on-BQ-devices">Cervantes</a> •
<a href="https://github.com/koreader/koreader/wiki/Installation-on-Kindle-devices">Kindle</a> •
<a href="https://github.com/koreader/koreader/wiki/Installation-on-Kobo-devices">Kobo</a> •
<a href="https://github.com/koreader/koreader/wiki/Installation-on-desktop-linux">Linux</a> •
<a href="https://github.com/koreader/koreader/wiki/Installation-on-PocketBook-devices">Pocketbook</a> •
<a href="https://github.com/koreader/koreader/wiki/Installation-on-Remarkable">reMarkable</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><a href="https://github.com/koreader/koreader/blob/master/doc/Building.md">Setting up a build environment</a> •
<a href="https://github.com/koreader/koreader/blob/master/doc/Collaborating_with_Git.md">Collaborating with Git</a> •
<a href="https://github.com/koreader/koreader/blob/master/doc/Building_targets.md">Building targets</a> •
<a href="https://github.com/koreader/koreader/blob/master/doc/Porting.md">Porting</a> •
<a href="http://koreader.rocks/doc/" rel="nofollow">Developer docs</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Support</h2><a id="user-content-support" aria-label="Permalink: Support" href="#support"></a></p>
<p dir="auto">KOReader is developed and supported by volunteers all around the world. There are many ways you can help:</p>
<ul dir="auto">
<li><a href="https://github.com/koreader/koreader/issues?q=is%3Aopen+is%3Aissue+label%3Abug">fix bugs</a> and <a href="https://github.com/koreader/koreader/issues?q=is%3Aopen+is%3Aissue+label%3Aenhancement">implement new features</a></li>
<li><a href="https://hosted.weblate.org/engage/koreader/?utm_source=widget" rel="nofollow">translate the program into your language</a> or improve an existing translation</li>
<li>document lesser-known features on the <a href="https://github.com/koreader/koreader/wiki">wiki</a></li>
<li>help others with your knowledge on the <a href="http://www.mobileread.com/forums/forumdisplay.php?f=276" rel="nofollow">forum</a></li>
</ul>
<p dir="auto">Right now we only support <a href="https://liberapay.com/KOReader" rel="nofollow">liberapay</a> donations.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto"><a href="https://github.com/koreader/koreader/commits/master"><img src="https://camo.githubusercontent.com/67345c78507e396cc6c9462876617c5de9d889023620822527a68bea7eca06dd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6173742d636f6d6d69742f6b6f7265616465722f6b6f7265616465723f636f6c6f723d6f72616e6765" alt="Last commit" data-canonical-src="https://img.shields.io/github/last-commit/koreader/koreader?color=orange"></a>
<a href="https://github.com/koreader/koreader/pulse"><img src="https://camo.githubusercontent.com/1f46f03040612f161709c63f954f32574d180ae5c7c499457ebe654374d91977/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6b6f7265616465722f6b6f726561646572" alt="Commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/m/koreader/koreader"></a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[JEP Draft: Prepare to Make Final Mean Final (194 pts)]]></title>
            <link>https://openjdk.org/jeps/8349536</link>
            <guid>43538919</guid>
            <pubDate>Mon, 31 Mar 2025 19:35:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openjdk.org/jeps/8349536">https://openjdk.org/jeps/8349536</a>, See on <a href="https://news.ycombinator.com/item?id=43538919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="Summary">Summary</h2>
<p>Issue warnings about uses of <em>deep reflection</em> to mutate <code>final</code> fields. The warnings aim to prepare developers for a future release that ensures <a href="https://openjdk.org/jeps/8305968">integrity by default</a> by restricting <code>final</code> field mutation; this makes Java programs safer and potentially faster. Application developers can avoid both current warnings and future restrictions by selectively enabling the ability to mutate <code>final</code> fields where essential.</p>
<h2 id="Goals">Goals</h2>
<ul>
<li>Prepare the Java ecosystem for a future release that, by default, disallows the mutation of <code>final</code> fields by deep reflection. As of that release, application developers will have to explicitly enable the capability to do so at startup.</li>
<li>Align <code>final</code> fields in normal classes with the components of record classes, which cannot be mutated by deep reflection.</li>
<li>Allow serialization libraries to continue working with <code>Serializable</code> classes, even those with <code>final</code> fields.</li>
</ul>
<h2 id="Non-Goals">Non-Goals</h2>
<ul>
<li>It is not a goal to deprecate or remove any part of the Java Platform API.</li>
<li>It is not a goal to prevent the mutation of <code>final</code> fields by serialization libraries during deserialization.</li>
</ul>
<h2 id="Motivation">Motivation</h2>
<p>Java developers rely on <code>final</code> fields to represent immutable state. Once assigned in a constructor (for <code>final</code> instance fields) or in a class initializer (for <code>static final</code> fields), a <code>final</code> field cannot be reassigned; its value, whether a primitive value or a reference to an object, is immutable. The expectation that a <code>final</code> field cannot be reassigned in far-flung parts of the program, whether deliberately or accidentally, is often crucial when developers reason about correctness. Furthermore, many classes exist <em>only</em> to represent immutable state, so <a href="https://openjdk.org/jeps/395">records</a> were introduced in JDK 16 to provide a concise way to declare a class where all fields are <code>final</code>, making it easy to reason about correctness.</p>
<p>The expectation that a <code>final</code> field cannot be reassigned is also important for performance. The more the JVM knows about the behavior of a class, the more optimizations it can apply. For example, being able to trust that <code>final</code> fields are never reassigned makes it possible for the JVM to perform <em>constant folding</em>, an optimization that elides the need to load a value from memory since the value can instead be embedded in the machine code emitted by the JIT compiler. Constant folding is often the first step in a chain of optimizations that together provide a massive speed-up.</p>
<p>Unfortunately, the expectation that a <code>final</code> field cannot be reassigned is <strong>false</strong>. The Java Platform provides <a href="https://openjdk.org/jeps/8305968#Undermining-integrity">a number of APIs</a> that allow <code>final</code> fields to be reassigned at any time by any code in the program, undermining all reasoning about correctness and invalidating important optimizations. The most prevalent of these APIs is <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/reflect/AccessibleObject.html#setAccessible(boolean)"><em>deep reflection</em></a>. Here is an example that uses deep reflection to mutate a <code>final</code> field at will:</p>
<pre><code>class C {
    final int x;
    C() { x = 100; }
}

// Perform deep reflection over C's final field
java.lang.reflect.Field f = C.class.getDeclaredField("x");
f.setAccessible(true);

// Create an object of class C
C obj = new C();
System.out.println(obj.x);  // Prints 100

// Mutate the final field in the object
f.set(obj, 200);
System.out.println(obj.x);  // Prints 200
f.set(obj, 300);
System.out.println(obj.x);  // Prints 300</code></pre>
<p>Accordingly, a <code>final</code> field is as mutable as a non-<code>final</code> field. Developers are unable to use <code>final</code> fields to construct the deeply immutable graphs of objects that would enable the JVM to deliver the best performance optimizations.</p>
<p>It might seem absurd for the Java Platform to provide an API that undermines the meaning of <code>final</code>. However, after JDK 5 introduced the <a href="https://docs.oracle.com/javase/specs/jls/se23/html/jls-17.html#jls-17.4">Java Memory Model</a> that led to widespread use of <a href="https://docs.oracle.com/javase/specs/jls/se23/html/jls-17.html#jls-17.5"><code>final</code> fields</a>, such an API was deemed necessary to support serialization libraries. In retrospect, offering such unconstrained functionality was a poor choice because it sacrificed integrity. When we introduced <a href="https://openjdk.org/jeps/371">hidden classes</a> in JDK 15 and <a href="https://openjdk.org/jeps/395">record classes</a> in JDK 16, we constrained deep reflection to <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/reflect/Field.html#set(java.lang.Object,java.lang.Object)">disallow mutation of <code>final</code> fields in hidden and record classes</a>.
We constrained deep reflection further when we <a href="https://openjdk.org/jeps/403">strongly encapsulated JDK internals</a> in JDK 17. In JDK 24, <a href="https://openjdk.org/jeps/498">we started a process</a> to remove methods in <code>sun.misc.Unsafe</code> that, like deep reflection, allow mutation of <code>final</code> fields.</p>
<p>Relatively little code mutates <code>final</code> fields, but the mere existence of APIs for doing so makes it impossible for developers or the JVM to trust the value of <em>any</em> <code>final</code> field. This compromises safety and performance in <em>all</em> programs. In line with the policy of <a href="https://openjdk.org/jeps/8305968"><em>integrity by default</em></a>, we plan to enforce the immutability of <code>final</code> fields so that code cannot use deep reflection to reassign them at will. We will support one special case -- serialization libraries that need to mutate <code>final</code> fields during deserialization -- via a limited-purpose API.</p>
<h2 id="Description">Description</h2>
<p>In JDK 5 and later releases, you can mutate <code>final</code> fields via deep reflection (the <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/reflect/Field.html#setAccessible(boolean)"><code>setAccessible</code></a> and <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/reflect/Field.html#set(java.lang.Object,java.lang.Object)"><code>set</code></a> methods in <code>java.lang.reflect.Field</code>). In JDK XX, we will restrict deep reflection so that mutating a <code>final</code> field also causes a warning to be issued at run time by default. It will not be possible to avoid the warning simply by using <code>--add-opens</code> to enable deep reflection of classes with <code>final</code> fields.</p>
<p>We refer to restrictions on mutating <code>final</code> fields as <em><code>final</code> field restrictions</em>. We will strengthen the effect of <code>final</code> field restrictions over time. Rather than issue warnings, a future JDK release will throw exceptions by default when Java code uses deep reflection to mutate <code>final</code> fields. The intent is to ensure that applications and the Java Platform have <a href="https://openjdk.org/jeps/8305968">integrity by default</a>.</p>
<h3 id="Enabling-final-field-mutation">Enabling <code>final</code> field mutation</h3>
<p>Application developers can avoid warnings (and in the future, exceptions) by enabling <code>final</code> field mutation for selected Java code at startup. Enabling <code>final</code> field mutation acknowledges the application's need to mutate <code>final</code> fields and lifts the <code>final</code> field restrictions.</p>
<p>Under the policy of integrity by default, it is the application developer (or perhaps deployer, on the advice of the application developer) who enables <code>final</code> field mutation, not library developers. Library developers who rely on reflection to mutate <code>final</code> fields should inform their users that they will need to enable <code>final</code> field mutation using one of the methods below.</p>
<p>To enable <code>final</code> field mutation by any code on the class path, regardless of where the <code>final</code> fields are declared, use the following command-line option:</p>
<pre><code>java --enable-final-field-mutation=ALL-UNNAMED ...</code></pre>
<p>To enable <code>final</code> field mutation by specific modules on the module path, again regardless of where the <code>final</code> fields are declared, pass a comma-separated list of module names:</p>
<pre><code>java --enable-final-field-mutation=M1,M2 ...</code></pre>
<p>Most application developers who wish to allow <code>final</code> field mutation will pass <code>--enable-final-field-mutation</code> directly to the <code>java</code> launcher in a startup script, but other techniques are available:</p>
<ul>
<li>You can pass <code>--enable-final-field-mutation</code> to the launcher indirectly, by setting the environment variable <code>JDK_JAVA_OPTIONS</code>.</li>
<li>You can put <code>--enable-final-field-mutation</code> in an argument file that is passed to the launcher by a script or an end user, e.g., <code>java @config</code></li>
<li>You can add <code>Enable-Reflective-Final-Mutation</code> to the manifest of an executable JAR file, i.e., a JAR file that is launched via <a href="https://docs.oracle.com/en/java/javase/22/docs/specs/man/java.html#synopsis"><code>java -jar</code></a>. (The only supported value for the <code>Enable-Reflective-Final-Mutation</code> manifest entry is <code>ALL-UNNAMED</code>; other values cause an exception to be thrown.)</li>
<li>If you create a custom Java runtime for your application, you can pass the <code>--enable-final-field-mutation</code> option to <code>jlink</code> via the <code>--add-options</code> option, so that reflective final field mutation is enabled in the resulting runtime image.</li>
<li>The <a href="https://docs.oracle.com/en/java/javase/22/docs/specs/jni/invocation.html">JNI Invocation API</a> allows a native application to embed a JVM in its own process. A native application which uses the JNI Invocation API can enable <code>final</code> field mutation for modules in the embedded JVM by passing the <code>--enable-final-field-mutation</code> option when <a href="https://docs.oracle.com/en/java/javase/22/docs/specs/jni/invocation.html#jni_createjavavm">creating the JVM</a>.</li>
</ul>
<h3 id="API-changes-in-JDK-XX">API changes in JDK XX</h3>
<p>The behavior of <code>Field::setAccessible</code> is unchanged. This means that when code calls <code>f.setAccessible(true)</code> on a <code>Field</code> object <code>f</code>, the code must either be in the same module as the field reflected by <code>f</code>, or, if the code is in a different module, the field reflected by <code>f</code> must be accessible to the caller via <code>exports</code> or <code>opens</code>. The call throws <code>InaccessibleObjectException</code> if these conditions are not met.</p>
<p>The behavior of <code>Field::set</code> is changed to have an additional condition:</p>
<pre>If the underlying field is final, this Field object has write access
if and only if the following conditions are met:

    setAccessible(true) has succeeded for this Field object; and
    final field mutation is enabled for the caller's module
        and the package of the field reflected by this Field object is open to the caller's module; and
    the field is non-static; and
    the field's declaring class is not a hidden class; and
    the field's declaring class is not a record class.

If any of the above checks is not met, this method throws an IllegalAccessException. 

Note that if this Field object reflects a field which is declared in a module other than the caller's module, then it is not sufficient for the field to be declared as public in an exported package. The field must be declared in a package that is open.

Note that the caller might not be the same as the caller of setAccessible(true).
</pre>
<p>For reference, package <code>p</code> in module <code>M</code> is <em>open</em> to module <code>N</code> if:</p>
<ul>
<li><code>N</code> is <code>M</code> itself, or</li>
<li><code>M</code>'s <code>module-info</code> contains <code>opens p</code> or <code>opens p to N</code>, or</li>
<li><code>M</code> is an <em>automatic module</em>, i.e., its classes are placed on the module path but it has no <code>module-info</code>, or</li>
<li><code>M</code> is an <em>unnamed module</em> (all classes on the class path are in an unnamed module), or</li>
<li>The application was started with the command-line option <code>--add-opens M/p=N</code>, or the application was launched as an executable JAR file whose manifest contains an appropriate <code>Add-Opens</code> attribute.</li>
</ul>
<p>Because every module is open to itself, code in a module may use deep reflection to mutate <code>final</code> fields of any class in the same module, provided that <code>final</code> final mutation is enabled at startup for that module.</p>
<p>The behavior of other relevant methods is as follows:</p>
<ul>
<li>
<p>The behavior of <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/invoke/MethodHandles.Lookup.html#unreflectSetter(java.lang.reflect.Field)"><code>MethodHandles.Lookup::unreflectSetter</code></a> is changed along similar lines as <code>Field::set</code>.</p>
</li>
<li>
<p>The <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/Module.html#addOpens(java.lang.String,java.lang.Module)"><code>Module::addOpens</code></a> method allows a caller in module <code>M</code> to open a package in module <code>N</code> to another module <code>O</code> at run time, provided that the package is already open to <code>M</code> itself. Calling this method will <em>not</em> enable <code>O</code> to mutate <code>final</code> fields in the package, even if <code>final</code> field mutation was enabled for <code>O</code> at startup, because the JVM already decided to trust the <code>final</code> fields in the package based on it not being open to <code>O</code> at startup.</p>
<p>The same applies to <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/ModuleLayer.Controller.html#addOpens(java.lang.Module,java.lang.String,java.lang.Module)"><code>ModuleLayer.Controller::addOpens</code></a> and <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.instrument/java/lang/instrument/Instrumentation.html#redefineModule(java.lang.Module,java.util.Set,java.util.Map,java.util.Map,java.util.Set,java.util.Map)"><code>Instrumentation.redefineModule</code></a>.</p>
</li>
<li>
<p>The <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/System.html#method-detail"><code>System::setIn</code>, <code>System::setOut</code>, and <code>System::setErr</code> methods</a> exist to mutate, respectively, the <code>final</code> fields <a href="https://docs.oracle.com/en/java/javase/23/docs/api/java.base/java/lang/System.html#field-detail"><code>System.in</code>, <code>System.out</code>, and <code>System.err</code></a>. These fields have always been <a href="https://docs.oracle.com/javase/specs/jls/se23/html/jls-17.html#jls-17.5.4">write-protected</a>, which means they can be mutated <em>only</em> by calling the corresponding methods in <code>System</code>. It has never been possible to mutate these fields via deep reflection. In JDK XX, there is no change of any kind to these fields and their corresponding methods.</p>
</li>
</ul>
<h3 id="Controlling-the-effect-of-final-field-restrictions">Controlling the effect of <code>final</code> field restrictions</h3>
<p>If <code>final</code> field mutation <em>is not</em> enabled for a module then it is illegal for code in the module to mutate any <code>final</code> field via deep reflection. That is, given a <code>Field</code> object <code>f</code> that reflects a <code>final</code> field, it may be legal for code in the module to call <code>f.setAccessible(true)</code> (depending on whether the field's package is open to the caller), but it is illegal for code in the module to call <code>f.set(..., ...)</code>.</p>
<p>If <code>final</code> field mutation <em>is</em> enabled for a module, but some <code>final</code> field is in a package is not open to the module, then it is illegal for code in the module to mutate that <code>final</code> field via deep reflection. This scenario can occur when code in one module, to which the field's package is open, calls <code>f.setAccessible(true)</code> and then passes <code>f</code> to code in a different module, for which <code>final</code> field mutation is enabled but to which the field's package is not open. It is illegal for the code that receives <code>f</code> to call <code>f.set(..., ...)</code>.</p>
<p>What action the Java runtime takes when an illegal <code>final</code> field mutation is attempted is controlled by a new command-line option, <code>--illegal-reflective-final-mutation</code>. This is similar in spirit and form to the <code>--illegal-access</code> option introduced by <a href="https://openjdk.org/jeps/261#Relaxed-strong-encapsulation">JEP 261</a> in JDK 9 and to <code>--illegal-native-access</code> introduced by <a href="https://openjdk.org/jeps/472">JEP 472</a> in JDK 24. It works as follows:</p>
<ul>
<li>
<p><code>--illegal-final-final-mutation=allow</code> allows the mutation to proceed without warning.</p>
</li>
<li>
<p><code>--illegal-final-final-mutation=warn</code> allows the mutation but issues a warning the first time that illegal <code>final</code> field mutation occurs in a particular module. At most one warning per module is issued.</p>
<p>This mode is the default in JDK XX. It will be phased out in a future release and, eventually, removed.</p>
</li>
<li>
<p><code>--illegal-final-final-mutation=deny</code> will result in <code>Field::set</code> throwing an <code>IllegalAccessException</code> for every illegal <code>final</code> field mutation.</p>
<p>This mode will become the default in a future release.</p>
</li>
</ul>
<p>When <code>deny</code> becomes the default mode, <code>allow</code> will be removed but <code>warn</code> will remain supported for at least one release.</p>
<p>To prepare for the future, we recommend running existing code with the <code>deny</code> mode to identify code that mutates <code>final</code> fields via deep reflection.</p>
<h3 id="Warnings-on-mutation-of-final-fields">Warnings on mutation of <code>final</code> fields</h3>
<p>When <code>Field::set</code> on a <code>final</code> field is called from a module for which <code>final</code> field mutation is not enabled, the mutation will succeed but the Java runtime will, by default, issue a warning that identifies the caller:</p>
<pre><code>WARNING: Final field f in p.C has been [mutated/unreflected for mutation] by class com.foo.Bar.caller in module N (file:/path/to/foo.jar)
WARNING: Use --enable-reflective-final-mutation=N to avoid a warning
WARNING: Mutating final fields will be blocked in a future release unless final field mutation is enabled</code></pre>
<p>At most one such warning is issued for any particular module, and only if a warning has not yet been issued for that module. The warning is written to the standard error stream.</p>
<h3 id="Libraries-should-not-use-deep-reflection-to-mutate-final-fields">Libraries should not use deep reflection to mutate <code>final</code> fields</h3>
<p>The ability to mutate <code>final</code> fields via deep reflection was added in JDK 5 so that serialization libraries could provide functionality on par with the JDK's own serialization facilities. In particular, the JDK can deserialize objects from an input stream even if the object's class declares <code>final</code> fields. The JDK bypasses the class's constructors that ordinarily assign instance fields, and instead <a href="https://docs.oracle.com/en/java/javase/23/docs/specs/serialization/input.html#the-objectinputstream-class">assigns values from the input stream to instance fields directly</a> -- even if they are <code>final</code>. Third-party serialization libraries use deep reflection to do the same.</p>
<p>When <code>final</code> field restrictions are strengthened in a future JDK release, serialization libraries will no longer be able to use deep reflection out of the box. Rather than asking users to enable <code>final</code> field mutation on the command line, the developers of serialization libraries should serialize and deserialize objects using the <a href="https://github.com/openjdk/jdk/blob/master/src/jdk.unsupported/share/classes/sun/reflect/ReflectionFactory.java"><code>sun.reflect.ReflectionFactory</code></a> class, which is <a href="https://openjdk.org/jeps/260#Critical-internal-APIs-not-encapsulated-in-JDK-9">supported for this purpose</a>. Its deserialization methods can mutate <code>final</code> fields even if called from code in modules that are not enabled for <code>final</code> field mutation.</p>
<p>The <code>sun.reflect.ReflectionFactory</code> class only supports deserialization of objects whose classes implement <code>java.io.Serializable</code>. We believe this limitation balances the interests of developers using serialization libraries with the wider interest of all developers in having correct and efficient execution. First, it limits the impact of any security exploit that utilizes deserialization, since it is not possible to craft malicious objects of arbitrary classes. Second, it ensures that the JVM, when performing optimizations such as constant folding, is not unduly constrained in the assumptions it can make about <code>final</code> fields. While the JVM has to treat <code>final</code> fields in <code>Serializable</code> objects as potentially mutable, it can assume that <code>final</code> fields in all other objects (the vast majority) are permanently immutable.</p>
<p>Distinct from serialization libraries, frameworks for dependency injection, unit testing, and mocking <a href="https://openjdk.org/jeps/8305968#Restrictions-on-standard-unsafe-APIs">use deep reflection</a> to manipulate objects, including mutating <code>final</code> fields. The maintainers of such frameworks should only ask users to enable <code>final</code> field mutation on the command line as a last resort. Instead, maintainers should <a href="https://openjdk.org/jeps/8305968#Embracing-integrity-by-default">find architectural approaches</a> that avoid the need to mutate <code>final</code> fields (and access <code>private</code> fields) altogether. For example, most dependency injection frameworks now forbid the injection of <code>final</code> fields, and all discourage it, instead recommending constructor injection.</p>
<h3 id="Mutating-final-fields-from-native-code">Mutating <code>final</code> fields from native code</h3>
<p>Native code can mutate Java fields by calling the <a href="https://docs.oracle.com/en/java/javase/22/docs/specs/jni/functions.html#settypefield-routines"><code>Set&lt;Type&gt;Field</code> functions</a> or the <a href="https://docs.oracle.com/en/java/javase/22/docs/specs/jni/functions.html#setstatictypefield-routines"><code>SetStatic&lt;Type&gt;Field</code> functions</a> defined in the <a href="https://docs.oracle.com/en/java/javase/22/docs/specs/jni/index.html">Java Native Interface</a> (JNI).</p>
<p>The behavior of these functions on <code>final</code> fields is <a href="https://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html">undefined</a>. This means that the function could mutate the field to the desired value, or mutate it to a different value, or not mutate it at all, or, e.g., mutate it correctly in 999 out of 1000 executions but cause a JVM crash in 1 out of 1000 executions. As we enhance the JVM's catalog of optimizations to exploit the <code>final</code> field restrictions placed on Java code, the chance of oddball outcomes due to undefined behavior in native code becomes more likely.</p>
<p>There are already <a href="https://openjdk.org/jeps/472">restrictions on executing native code</a> due to the possibility of undefined behavior, so by default the JVM can assume that these functions are not called. However, if <a href="https://openjdk.org/jeps/472#Enabling-native-access">native access is enabled</a>, then this JEP proposes new diagnostics to mitigate the risks of oddball outcomes from mutating <code>final</code> fields via JNI:</p>
<ul>
<li>
<p>If the application is started with <a href="https://openjdk.org/jeps/158">unified logging</a> enabled for native code (<code>-Xlog:jni=debug</code>), calling any of the functions mentioned above on a <code>final</code> field will cause a message to be logged:</p>
<pre><code>[0.20s][debug][jni] Set&lt;Type&gt;Field of final instance field C.f</code></pre>
<p>or</p>
<pre><code>[0.20s][debug][jni] SetStatic&lt;Type&gt;Field of final static field C.f</code></pre>
</li>
<li>
<p>If the application is started with <a href="https://docs.oracle.com/en/java/javase/23/docs/specs/man/java.html#extra-options-for-java">additional checking of JNI functions</a> (<code>-Xcheck:jni</code>), calling any of the functions mentioned above on a <code>final</code> field will cause the JVM to terminate with an error message.</p>
</li>
</ul>
<p>In a future JDK release, the functions mentioned above may be changed so that they always return successfully when called on <code>final</code> fields, but never actually effect any mutation.</p>
<p>There are no diagnostics for when Java code mutates <code>final</code> fields via the <code>sun.misc.Unsafe</code> class. Such mutation may cause strange bugs or JVM crashes.</p>
<h2 id="Risks-and-Assumptions">Risks and Assumptions</h2>
<ul>
<li>
<p>The ability to mutate <code>final</code> fields has been part of the Java Platform since JDK 5, so there is a risk that existing applications will be impacted by the <code>final</code> field restrictions.</p>
</li>
<li>
<p>We assume that developers whose applications rely directly or indirectly on mutating <code>final</code> fields will be able to configure the Java runtime to enable the capability via <code>--enable-final-final-mutation</code>. This is similar to how they can already configure the Java runtime to disable strong encapsulation for modules via <code>--add-opens</code>.</p>
</li>
</ul>
<h2 id="Alternatives">Alternatives</h2>
<ul>
<li>
<p>Rather than enforce the immutability of <code>final</code> fields, the Java runtime could rely on speculation and optimistically assume that <code>final</code> fields are not mutated, detecting when they are, and deoptimizing code when that happens. While speculative optimizations are the bread-and-butter of the JVM's JIT compiler, they may not suffice in this case as future planned optimizations may wish to rely not only on immutability within the lifetime of the process, but also on the immutability of fields from one run of the application to the next.</p>
</li>
<li>
<p>Instead of specifying the modules whose code can mutate <code>final</code> fields, we could specify the modules that allow their classes' <code>final</code> fields to be mutated. However, since the mutation of <code>final</code> fields is generally undesirable, it is better for command-line options to record which modules should be changed to no longer perform mutation. Specifying the modules whose <code>final</code> fields can be mutated would make it hard to know for what purpose they allow their fields to be mutated, and by whom.</p>
</li>
<li>
<p>Requiring <code>--enable-final-field-mutation</code> to specify <em>both</em> sides — the module performing the mutation <em>and</em> the module containing the mutated field — is unnecessarily burdensome. In many practical cases, <code>--enable-final-field-mutation</code> will be specified in conjunction with <code>--add-opens</code>, which already specifies both sides of the reflective access.</p>
</li>
</ul>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI releasing new open model in coming months, seeks community feedback (105 pts)]]></title>
            <link>https://openai.com/open-model-feedback/</link>
            <guid>43538783</guid>
            <pubDate>Mon, 31 Mar 2025 19:25:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/open-model-feedback/">https://openai.com/open-model-feedback/</a>, See on <a href="https://news.ycombinator.com/item?id=43538783">Hacker News</a></p>
Couldn't get https://openai.com/open-model-feedback/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi for Kids (179 pts)]]></title>
            <link>https://help.kagi.com/kagi/plans/family-plan.html#kidslogin</link>
            <guid>43538338</guid>
            <pubDate>Mon, 31 Mar 2025 18:47:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.kagi.com/kagi/plans/family-plan.html#kidslogin">https://help.kagi.com/kagi/plans/family-plan.html#kidslogin</a>, See on <a href="https://news.ycombinator.com/item?id=43538338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-v-39a288b8=""><p>Since the inception, Kagi has been driven by the idea of humanizing the web, especially for families and kids. Our commitment to this cause was the inspiration behind the creation of Kagi. Many of our staff are parents working together to build a better search and web future for our children. We strive to provide a search engine that prioritizes the well-being of your loved ones, particularly the most vulnerable ones like children, by offering an ad-free and safe browsing experience. We offer two different group plans based on your specific needs.</p><p>The Kagi Family Plan is perfect for families wanting to search smarter, emphasizing learning over consumption while respecting your family's privacy. With a simple, affordable pricing model and powerful features, the Kagi Family Plan makes it easy to get the most out of Kagi Search as a family.</p><p><strong>Table of Contents</strong></p><ul><li><a href="#using">How to Use the Kagi Family Plan</a></li><li><a href="#kidslogin">Logging in for Kids</a></li><li><a href="#features">Unique Features</a><ul><li><a href="#kidfriendly">Kid-Friendly Search Experience</a></li><li><a href="#parental">Parental Controls</a></li><li><a href="#ai">Quick Answers</a></li><li><a href="#lenses">Lenses</a></li><li><a href="#pr">Personalized Results</a></li><li><a href="#illustrations">New Illustrations</a></li></ul></li><li><a href="#poopavatar">Story behind the Poop Avatar</a></li></ul><h2 id="using" tabindex="-1">How to Use the Kagi Family Plan <a href="#using" aria-label="Permalink to &quot;How to Use the Kagi Family Plan {#using}&quot;">​</a></h2><p>To sign up for the Family Plan, select the plan that fits your family's size and needs at Kagi <a href="https://kagi.com/onboarding?p=choose_plan&amp;plan=family" target="_blank" rel="noreferrer">account creation</a>.</p><p><img src="https://help.kagi.com/assets/family_plans.D5vxSArv.png" alt="Family Plans"></p><!----><p>If you have an existing Kagi account and want to upgrade to the Family plan, everything you need to do is cancel your existing plan, and then resubscribe to the Family plan (any credit left over will be pro-rated).</p><p>Adding family members is easy, you can <a href="https://kagi.com/settings?p=account_members" target="_blank" rel="noreferrer">invite them via email</a> through Kagi. For kids, you can use a username, and an adult will help them log in by getting a verification email.</p><p><img src="https://staticmedia.kagi.com/family/add_member.png"></p><!----><p>The <a href="https://kagi.com/settings?p=account_members" target="_blank" rel="noreferrer">Family Plan dashboard</a> gives you a complete picture of your family's members</p><p><img src="https://staticmedia.kagi.com/family/dashboard.png"></p><!----><p>The <a href="https://kagi.com/settings?p=billing" target="_blank" rel="noreferrer">Billing screen</a> has the overview of the plan and allows you to update payment info or cancel the subscription.</p><p><img src="https://staticmedia.kagi.com/family/billing.png"></p><!----><h2 id="kidslogin" tabindex="-1">Logging in for Kids <a href="#kidslogin" aria-label="Permalink to &quot;Logging in for Kids {#kidslogin}&quot;">​</a></h2><p>To log-in kid accounts, just proceed to normal login on their device. Kids enter just their username and password is not needed.</p><p>A verification email will be sent to the account owner. They can just click the link in the email to automatically log in the kid account, or enter the provided numerical code.</p><h2 id="features" tabindex="-1">Unique Features <a href="#features" aria-label="Permalink to &quot;Unique Features {#features}&quot;">​</a></h2><p>The Kagi Family Plan has unique features that make it perfect for families.</p><h3 id="kidfriendly" tabindex="-1">Kid-Friendly Search Experience <a href="#kidfriendly" aria-label="Permalink to &quot;Kid-Friendly Search Experience {#kidfriendly}&quot;">​</a></h3><p>The Kagi Family Plan also includes a kid-friendly search experience that uses strict content filters to ensure children are not exposed to harmful content. Kid’s profile simplifies the search experience with larger text, icons, and content adjusted for kids.</p><h3 id="parental" tabindex="-1">Parental Controls <a href="#parental" aria-label="Permalink to &quot;Parental Controls {#parental}&quot;">​</a></h3><p>The Kagi Family Plan comes with parental controls that let parents manage their children's search experience.</p><p><img src="https://staticmedia.kagi.com/family/parental.png"></p><!----><p>Kagi allows parents to toggle whether kids will have access to the search results on the entire web or a restricted set of sites (whitelist) only through “lenses.”</p><p>Safe search filters exclude adult material from the search results.</p><h3 id="ai" tabindex="-1">Quick Answers <a href="#ai" aria-label="Permalink to &quot;Quick Answers {#ai}&quot;">​</a></h3><p>We are featuring state of the art AI tools that can improve the quality of consumed information for kids. AI tools can be beneficial for getting quick answers to common questions, but it's important to remember that they're not always accurate. We encourage you to talk with kids about the potential risks and benefits of AI question-answering tools. It's important for kids to understand how these tools work and how to use them safely and responsibly in a way to nurture curiosity.</p><p>We added appropriate warnings for AI tools around the interface and a particular content-moderation filter to ensure AI output does not contain harmful content.</p><p><img src="https://staticmedia.kagi.com/family/quick_answer.png"></p><!----><h3 id="lenses" tabindex="-1">Lenses <a href="#lenses" aria-label="Permalink to &quot;Lenses {#lenses}&quot;">​</a></h3><p>Lenses are a subset of search results that are restricted to a subset of whitelisted sites (up to 10 per lens). You can create and share multiple lenses, such as having a lens for Education, School work, or Entertainment and assign the default one to be used for searches. We allow you to export and import lenses to share with other community parents.</p><p><img src="https://staticmedia.kagi.com/family/lenses.png"></p><!----><p>Parents can create lenses for children to ensure they have access to the resources they need while keeping them safe from inappropriate content.</p><p><img src="https://staticmedia.kagi.com/family/lens_create.png"></p><!----><h3 id="pr" tabindex="-1">Personalized Results <a href="#pr" aria-label="Permalink to &quot;Personalized Results {#pr}&quot;">​</a></h3><p>In addition to lenses, we include the ability for parents to completely block (ban) websites from showing in the results, or to promote useful sites. Up to 1,000 websites can be curated in this way.</p><p><img src="https://staticmedia.kagi.com/family/pr.png"></p><!----><h3 id="illustrations" tabindex="-1">New Illustrations <a href="#illustrations" aria-label="Permalink to &quot;New Illustrations {#illustrations}&quot;">​</a></h3><p>Our mascot Doggo now has a lady friend, and we introduced several new and delightful illustrations throughout the interface.</p><p><img src="https://staticmedia.kagi.com/family/lady_doggo.png"></p><!----><h2 id="poopavatar" tabindex="-1">Story behind the Poop Avatar <a href="#poopavatar" aria-label="Permalink to &quot;Story behind the Poop Avatar {#poopavatar}&quot;">​</a></h2><p>Our selection of avatars for kids includes a poop avatar (which most kids find really funny), and there's a reason why we made this choice that goes deeper than what meets the eye.</p><p><img src="https://staticmedia.kagi.com/family/poop.png"></p><!----><p>In the day and age of smartphones, social media, and instant gratification, it's more important than ever to teach kids about identity, privacy, and online safety. That's why we've made a conscious decision to include a poop avatar in our selection of avatars for kids. We aim to educate kids about responsible technology use in an engaging, lighthearted way that inspires learning through fun.</p><p>It is an opportunity to teach kids that they are not their online avatar and help them develop a healthy sense of identity and self-esteem. Online avatars are often designed to be cute, funny, or attention-grabbing, but they don't necessarily reflect who the child is as a person.</p><p>When kids start using online identities at a young age, it's important to help them understand that their avatar is just a representation of themselves online, and that it doesn't define who they are in real life. This can help prevent them from feeling too attached to their online persona and from feeling hurt or embarrassed if they receive negative feedback or criticism online.</p><p>Teaching kids that they are not their online avatar can also help them understand the importance of privacy and security online. Kids need to learn how to protect their personal information and avoid sharing too much about themselves online, and understanding that their avatar is not a true reflection of who they are can help them understand why it's important to be cautious about what they share.</p><p>At Kagi, we believe that it's important to provide kids with a fun and engaging online experience while also teaching them important lessons about humanity, identity, privacy, and online safety. Our poop avatar is just one example of how we try to make online searching and learning more fun for kids, while also encouraging them to be thoughtful and responsible digital citizens.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Notes on the Pentium's microcode circuitry (157 pts)]]></title>
            <link>https://www.righto.com/2025/03/pentium-microcde-rom-circuitry.html</link>
            <guid>43538192</guid>
            <pubDate>Mon, 31 Mar 2025 18:35:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.righto.com/2025/03/pentium-microcde-rom-circuitry.html">https://www.righto.com/2025/03/pentium-microcde-rom-circuitry.html</a>, See on <a href="https://news.ycombinator.com/item?id=43538192">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-3129002752159663932" itemprop="description articleBody">
<p>Most people think of machine instructions as the fundamental steps that a computer performs.
However, many processors have another layer of software underneath: microcode.
With microcode, instead of building the processor's control circuitry from complex logic gates, the control logic is
implemented with code known as microcode, stored in the microcode ROM.
To execute a machine instruction, the computer internally executes several simpler micro-instructions, specified by the microcode.
In this post, I examine the microcode ROM in the original Pentium, looking at the low-level circuitry.</p>
<p>The photo below shows the Pentium's thumbnail-sized silicon die under a microscope.
I've labeled the main functional blocks.
The microcode ROM is highlighted at the right.
If you look closely, you can see that the microcode ROM consists of two rectangular banks, one above the other.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/pentium-labeled.jpg"><img alt="This die photo of the Pentium shows the location of the microcode ROM. Click this image (or any other) for a larger version." height="524" src="https://static.righto.com/images/pentium-microcode1/pentium-labeled-w500.jpg" title="This die photo of the Pentium shows the location of the microcode ROM. Click this image (or any other) for a larger version." width="500"></a></p><p>This die photo of the Pentium shows the location of the microcode ROM. Click this image (or any other) for a larger version.</p>
<p>The image below shows a closeup of the two microcode ROM banks.
Each bank provides 45 bits of output; together they implement a micro-instruction that is 90 bits long.
Each bank consists of a grid of transistors arranged into 288 rows and 720 columns.
The microcode ROM holds 4608 micro-instructions,
414,720 bits in total.
At this magnification, the ROM appears featureless, but it is covered with horizontal wires, each just 1.5 µm
thick.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/rom-output-lines.jpg"><img alt="The 90 output lines from the ROM, with a closeup of six lines exiting the ROM." height="470" src="https://static.righto.com/images/pentium-microcode1/rom-output-lines-w500.jpg" title="The 90 output lines from the ROM, with a closeup of six lines exiting the ROM." width="500"></a></p><p>The 90 output lines from the ROM, with a closeup of six lines exiting the ROM.</p>
<p>The ROM's 90 output lines are collected into a bundle of wires between the banks, as shown above.
The detail shows how six of the bits exit from the banks and join the bundle.
This bundle exits the ROM to the left, travels to various parts of the chip, and controls the chip's circuitry.
The output lines are in the chip's top metal layer (M3):
the Pentium has three layers of metal wiring with M1 on the bottom, M2 in the middle, and M3 on top.</p>
<p>The Pentium has a large number of bits in its micro-instruction, 90 bits compared to 21 bits in the <a href="https://www.righto.com/2022/11/how-8086-processors-microcode-engine.html">8086</a>.
Presumably, the Pentium has a "horizontal" microcode architecture, where the microcode bits correspond to low-level control signals,
as opposed to "vertical" microcode, where the bits are encoded into denser micro-instructions.
I don't have any information on the Pentium's encoding of microcode; unlike the 8086, the Pentium's patents don't provide any clues.
The 8086's microcode ROM holds 512 micro-instructions, much less than the Pentium's 4608 micro-instructions.
This makes sense, given the much greater complexity of the Pentium's instruction set, including the floating-point unit on the chip.</p>
<!-- 40.8 pixels (blue) for metal lines + gap. 15625 pixels/mm. 2.6 µm total so 1.3 µm for metal line alone. -->

<p>The image below shows a closeup of the Pentium's microcode ROM.
For this image, I removed the three layers of metal and the polysilicon layer
to expose the chip's underlying silicon.
The pattern of silicon doping is visible, showing the transistors and thus the data stored in the ROM.
If you have enough time, you can extract the bits from the ROM by examining the silicon and seeing where transistors are present.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/rom-closeup.jpg"><img alt="A closeup of the ROM showing how bits are encoded in the layout of transistors." height="469" src="https://static.righto.com/images/pentium-microcode1/rom-closeup-w500.jpg" title="A closeup of the ROM showing how bits are encoded in the layout of transistors." width="500"></a></p><p>A closeup of the ROM showing how bits are encoded in the layout of transistors.</p>
<p>Before explaining the ROM's circuitry, I'll review how an NMOS transistor is constructed.
A transistor can be considered a switch between the source and drain, controlled by the gate.
The source and drain regions (green) consist of silicon doped with impurities to change its semiconductor properties, forming N+ silicon.
(These regions are visible in the photo above.)
The gate consists of a layer of polysilicon (red), separated from the silicon by a very thin insulating oxide layer. Whenever polysilicon crosses active silicon, a transistor is formed. </p>
<p><a href="https://static.righto.com/images/pentium-microcode1/mosfet-n.jpg"><img alt="Diagram showing the structure of an NMOS transistor." height="231" src="https://static.righto.com/images/pentium-microcode1/mosfet-n-w400.jpg" title="Diagram showing the structure of an NMOS transistor." width="400"></a></p><p>Diagram showing the structure of an NMOS transistor.</p>
<p>Bits are stored in the ROM through the pattern of transistors in the grid.
The presence or absence of a transistor stores a 0 or 1 bit.<span id="fnref:ambiguity"><a href="#fn:ambiguity">1</a></span>
The closeup below shows eight bits of the microcode ROM. There are four transistors present and four gaps where transistors are
missing.
Thus, this part of the ROM holds four 0 bits and four 1 bits.
For the diagram below, I removed the three metal layers and the polysilicon to show the underlying silicon.
I colored doped (active) silicon regions green, and drew in the horizontal polysilicon lines in red.
As explained above, a transistor is created if polysilicon crosses doped silicon.
Thus, the contents of the ROM are defined by the pattern of silicon regions, which creates the transistors.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/rom-transistors.jpg"><img alt="Eight bits of the microcode ROM, with four transistors present." height="211" src="https://static.righto.com/images/pentium-microcode1/rom-transistors-w500.jpg" title="Eight bits of the microcode ROM, with four transistors present." width="500"></a></p><p>Eight bits of the microcode ROM, with four transistors present.</p>
<p>The horizontal silicon lines are used as wiring to provide ground to the transistors, while the horizontal polysilicon lines select one of the
rows in the ROM.
The transistors in that row will turn on, pulling the associated output lines low.
That is, the presence of a transistor in a row causes the output to be pulled low, while the absence of a transistor causes
the output line to remain high.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/rom-schematic.jpg"><img alt="A schematic corresponding to the eight bits above." height="225" src="https://static.righto.com/images/pentium-microcode1/rom-schematic-w300.jpg" title="A schematic corresponding to the eight bits above." width="300"></a></p><p>A schematic corresponding to the eight bits above.</p>
<p>The diagram below shows the silicon, polysilicon, and bottom metal (M1) layers. I removed the metal from the left to reveal the silicon and polysilicon underneath, but the pattern of vertical metal lines continues there.
As shown earlier, the silicon pattern forms transistors. Each horizontal metal line has a connection
to ground through a metal line (not shown).
The horizontal polysilicon lines select a row.
When polysilicon lines cross doped silicon, the gate of a transistor is formed.
Two transistors may share the drain, as in the transistor pair on the left.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/m1-diagram.jpg"><img alt="Diagram showing the silicon, polysilicon, and M1 layers." height="330" src="https://static.righto.com/images/pentium-microcode1/m1-diagram-w500.jpg" title="Diagram showing the silicon, polysilicon, and M1 layers." width="500"></a></p><p>Diagram showing the silicon, polysilicon, and M1 layers.</p>
<p>The vertical metal wires form the outputs. The circles are contacts between the metal wire and the silicon of a transistor.<span id="fnref:contacts"><a href="#fn:contacts">2</a></span>
Short metal jumpers connect the polysilicon lines to the metal layer above, which will be described next.</p>
<p>The image below shows the upper left corner of the ROM. The yellowish metal lines are the top metal layer (M3), while the
reddish metal lines are the middle metal layer (M2).
The thick yellowish M3 lines distribute ground to the ROM. Underneath the horizontal M3 line, a horizontal M2 line also
distributes ground.
The grids of black dots are numerous contacts between the M3 line and the M2 line, providing a low-resistance connection.
The M2 line, in turn, connects to vertical M1 ground lines underneath—these wide vertical lines are faintly visible.
These M1 lines connect to the silicon, as shown earlier, providing ground to each transistor.
This illustrates the complexity of power distribution in the Pentium: the thick top metal (M3) is the primary distribution of
+5 volts and ground through the chip, but power must be passed down through M2 and M1 to reach the transistors.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/rom-m3.jpg"><img alt="The upper left corner of the ROM." height="419" src="https://static.righto.com/images/pentium-microcode1/rom-m3-w600.jpg" title="The upper left corner of the ROM." width="600"></a></p><p>The upper left corner of the ROM.</p>
<p>The other important feature above is the horizontal metal lines, which help distribute the row-select signals.
As shown earlier, horizontal polysilicon lines provide the row-select signals to the transistors.
However, polysilicon is not as good a conductor as metal, so long polysilicon lines have too much resistance.
The solution is to run metal lines in parallel, periodically connected to the underlying polysilicon lines and
reducing the overall resistance.
Since the vertical metal output lines are in the M1 layer, the horizontal row-select lines run in the M2 layer so they don't collide.
Short "jumpers" in the M1 layer connect the M2 lines to the polysilicon lines.</p>
<p>To summarize, each ROM bank contains a grid of transistors and transistor vacancies to define the bits of the ROM.
The ROM is carefully designed so the different layers—silicon, polysilicon, M1, and M2—work together to maximize the
ROM's performance and density.</p>
<h2>Microcode Address Register</h2>
<p>As the Pentium executes an instruction, it provides the address of each micro-instruction to the microcode ROM.
The Pentium holds this address—the micro-address—in the Microcode Address Register (MAR).
The MAR is a 13-bit register located above the microcode ROM. </p>
<p>The diagram below shows the Microcode Address Register above the upper ROM bank.
It consists of 13 bits; each bit has multiple latches to hold the value as well as any pushed subroutine micro-addresses.
Between bits 7 and 8, some buffer circuitry amplifies the control signals that go to each bit's circuitry.
At the right, drivers amplify the outputs from the MAR, sending the signals to the row drivers and column-select circuitry that
I will discuss below.
To the left of the MAR is a 32-bit register that is apparently unrelated to the microcode ROM, although I haven't determined its function.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/MAR.jpg"><img alt="The Microcode Address Register is located above the upper ROM bank." height="226" src="https://static.righto.com/images/pentium-microcode1/MAR-w600.jpg" title="The Microcode Address Register is located above the upper ROM bank." width="600"></a></p><p>The Microcode Address Register is located above the upper ROM bank.</p>
<p>The outputs from the Microcode Address Register select rows and columns in the microcode ROM, as I'll explain
below.
Bits 12 through 7 of the MAR select a block of 8 rows, while bits 6 through 4 select a row in this block.
Bits 3 through 0 select one column out of each group of 16 columns to select an output bit.
Thus, the microcode address controls what word is provided by the ROM.</p>
<p>Several different operations can be performed on the Microcode Address Register.
When executing a machine instruction, the MAR must be loaded with the address of the corresponding
microcode routine.
(I haven't determined how this address is generated.)
As microcode is executed, the MAR is usually incremented to move to the next micro-instruction.
However, the MAR can branch to a new micro-address as required.
The MAR also supports microcode subroutine calls; it will push the current micro-address and jump to the new micro-address.
At the end of the micro-subroutine, the micro-address is popped so execution returns to the previous location.
The MAR supports three levels of subroutine calls, as it contains three registers to hold the stack of pushed micro-addresses.</p>
<p>The MAR receives control signals and addresses from <a href="https://www.righto.com/2024/07/pentium-standard-cells.html">standard-cell logic</a>
located above the MAR.
Strangely, in Intel's published <a href="https://doi.org/10.1109/40.216745">floorplans</a> for the Pentium, this standard-cell logic is
labeled as part of the branch prediction logic, which is above it.
However, carefully tracing the signals from the standard-cell logic shows that is connected to the Microcode Address Register, not
the branch predictor.</p>
<h2>Row-select drivers</h2>
<p>As explained above, each ROM bank has 288 rows of transistors, with polysilicon lines to select one of the rows.
To the right of the ROM is circuitry that activates one of these row-select lines, based on the micro-address.
Each row matches a different 9-bit address. A straightforward implementation would use a 9-input AND gate for each
row, matching a particular pattern of 9 address bits or their complements.</p>
<p>However, this implementation would require 576 very large AND gates, so it is impractical.
Instead, the Pentium uses an optimized implementation with one 6-input AND gate for each group of 8 rows.
The remaining three address bits are decoded once at the top of the ROM.
As a result, each row only needs one gate, detecting if its group of eight rows is selected and if the particular one of eight
is selected.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/row-driver-schematic.jpg"><img alt="Simplified schematic of the row driver circuitry." height="453" src="https://static.righto.com/images/pentium-microcode1/row-driver-schematic-w500.jpg" title="Simplified schematic of the row driver circuitry." width="500"></a></p><p>Simplified schematic of the row driver circuitry.</p>
<p>The schematic above shows the circuitry for a group of eight rows, slightly simplified.<span id="fnref:simplified-rows"><a href="#fn:simplified-rows">3</a></span>
At the top, three address bits are decoded, generating eight output lines with one active at a time.
The remaining six address bits are inverted, providing the bit and its complement to the decoding circuitry.
Thus, the 9 bits are converted into 20 signals that flow through the decoders, a large number of wires, but not unmanageable.
Each group of eight rows has a 6-input AND gate that matches a particular 6-bit address, determined by which inputs are
complemented and which are not.<span id="fnref:binary"><a href="#fn:binary">4</a></span>
The NAND gate and inverter at the left combine the 3-bit decoding and the 6-bit decoding, activating the appropriate row.</p>
<p>Since there are up to 720 transistors in each row, the row-select lines need to be driven with high current.
Thus, the row-select drivers use large transistors, roughly 25 times the size of a regular transistor.
To fit these transistors into the same vertical spacing as the rest of the decoding circuitry, a tricky packing is used.
The drivers for each group of 8 rows are packed into a 3×3 grid, except the first column has two drivers (since there
are 8 drivers in the group, not 9).
To avoid a gap, the drivers in the first column are larger vertically and squashed horizontally.</p>
<h2>Output circuitry</h2>
<p>The schematic below shows the multiplexer circuit that selects one of 16 columns for a microcode output bit.
The first stage has four 4-to-1 multiplexers. Next, another 4-to-1 multiplexer selects one of the outputs.
Finally, a BiCMOS driver amplifies the output for transmission to the rest of the processor.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/output-mux.jpg"><img alt="The 16-to-1 multiplexer/output driver." height="272" src="https://static.righto.com/images/pentium-microcode1/output-mux-w700.jpg" title="The 16-to-1 multiplexer/output driver." width="700"></a></p><p>The 16-to-1 multiplexer/output driver.</p>
<p>In more detail, the ROM and the first multiplexer are essentially NMOS circuits, rather than CMOS. Specifically, the ROM's
grid of transistors is constructed from NMOS transistors that can pull a column line low, but there are no PMOS transistors in
the grid to pull the line high (since that would double the size of the ROM).
Instead, the multiplexer includes precharge transistors to pull the lines high, presumably in the clock phase before the
ROM is read.
The capacitance of the lines will keep the line high unless it is pulled low by a transistor in the grid.
One of the four transistors in the multiplexer is activated (by control signal <code>a</code>, <code>b</code>, <code>c</code>, or <code>d</code>) to select the desired line.
The output goes to a "keeper" circuit, which keeps the output high unless it is pulled low.
The keeper uses an inverter with a weak PMOS transistor that can only provide a small pull-up current.
A stronger low input will overpower this transistor, switching the state of the keeper. </p>
<p>The output of this multiplexer, along with the outputs of three other multiplexers, goes to the second-stage multiplexer,<span id="fnref:mux"><a href="#fn:mux">5</a></span>
which selects one of its four inputs, based on control signals <code>e</code>, <code>f</code>, <code>g</code>, and <code>h</code>.
The output of this multiplexer is held in a latch built from two inverters. The second latch has weak transistors so the latch
can be easily forced into the desired state.
The output from the first latch goes through a CMOS switch into a second latch, creating a flip-flop.</p>
<p>The output from the second latch goes to a BiCMOS driver, which drives one of the 90 microcode output lines.
Most processors are built from CMOS circuitry (i.e. NMOS and PMOS transistors), but the Pentium is built from BiCMOS circuitry:
bipolar transistors as well as CMOS.
At the time, bipolar transistors improved performance for high-current drivers; see my
article on
<a href="https://www.righto.com/2025/01/pentium-reverse-engineering-bicmos.html">the Pentium's BiCMOS circuitry</a>.</p>
<p>The diagram below shows three bits of the microcode output. This circuitry is for the upper ROM bank; the circuitry is
mirrored for the lower bank.
The circuitry matches the schematic above. Each of the three blocks has 16 input lines from the ROM grid.
Four 4-to-1 multiplexers reduce this to 4 lines, and the second multiplexer selects a single line. The result is latched
and amplified by the output driver.
(Note the large square shape of the bipolar transistors.)
Next is the shift register that processes the microcode ROM outputs for testing.
The shift register uses XOR logic for its feedback; unlike the rest of the circuitry, the XOR logic is irregular since
only some bits are fed into XOR gates.</p>
<p><a href="https://static.righto.com/images/pentium-microcode1/output-die.jpg"><img alt="Three bits of output from the microcode, I removed the three metal layers to show the polysilicon and silicon." height="523" src="https://static.righto.com/images/pentium-microcode1/output-die-w500.jpg" title="Three bits of output from the microcode, I removed the three metal layers to show the polysilicon and silicon." width="500"></a></p><p>Three bits of output from the microcode, I removed the three metal layers to show the polysilicon and silicon.</p>
<h3>Circuitry for testing</h3>
<p>Why does the microcode ROM have shift registers and XOR gates?
The reason is that a chip such as the Pentium is very difficult to test: if one out of 3.1 million transistors goes bad, how do you detect it? For a simple processor like the 8086, you can run through the instruction set and be fairly confident that any problem would turn up.
But with a complex chip, it is almost impossible to design an instruction sequence that would test every bit of the microcode ROM, every bit of the cache, and so forth.
Starting with the 386, Intel added circuitry to the processor solely to make testing easier; about 2.7% of the transistors in the 386 were for testing.</p>
<p>The Pentium has this testing circuitry for many ROMs and PLAs, including the division PLA that caused the infamous <a href="https://www.righto.com/2024/12/this-die-photo-of-pentium-shows.html">FDIV bug</a>.
To test a ROM inside the processor, Intel added circuitry to scan the entire ROM and checksum its contents.
Specifically, a pseudo-random number generator runs through each address, while another circuit computes a checksum of the ROM output, forming a "signature" word.
At the end, if the signature word has the right value, the ROM is almost certainly correct.
But if there is even a single bit error, the checksum will be wrong and the chip will be rejected.</p>
<p>The pseudo-random numbers and the checksum are both implemented with linear feedback shift registers (LFSR), a shift register along with a few XOR gates to feed the output back to the input.
For more information on testing circuitry in the 386, see <a href="https://doi.org/10.1109/MDT.1987.295165">Design and Test of the 80386</a>, written by Pat Gelsinger, who became Intel's CEO years later.</p>
<h2>Conclusions</h2>
<p>You'd think that implementing a ROM would be straightforward, but the Pentium's microcode ROM is surprisingly complex due to
its optimized structure and its circuitry for testing.
I haven't been able to determine much about how the microcode works, except that the micro-instruction is 90 bits wide and
the ROM holds 4608 micro-instructions in total.
But hopefully you've found this look at the circuitry interesting.</p>
<p>Disclaimer: this should all be viewed as slightly speculative and there are probably some errors.
I didn't want to prefix every statement with "I think that..." but you should pretend it is there.
I plan to write more about the implementation of the Pentium, so
follow me on Bluesky (<a href="https://bsky.app/profile/righto.com">@righto.com</a>) or <a href="https://www.righto.com/feeds/posts/default">RSS</a> for updates.
Peter Bosch has done some reverse engineering of the Pentium II microcode; his information is <a href="https://pbx.sh/pentiumii-part1/">here</a>.</p>
<h2>Footnotes and references</h2>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Workflows then Agents: Getting Started with Apache Airflow (112 pts)]]></title>
            <link>https://github.com/astronomer/airflow-ai-sdk</link>
            <guid>43538164</guid>
            <pubDate>Mon, 31 Mar 2025 18:32:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/astronomer/airflow-ai-sdk">https://github.com/astronomer/airflow-ai-sdk</a>, See on <a href="https://news.ycombinator.com/item?id=43538164">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">airflow-ai-sdk</h2><a id="user-content-airflow-ai-sdk" aria-label="Permalink: airflow-ai-sdk" href="#airflow-ai-sdk"></a></p>
<p dir="auto">This repository contains an SDK for working with LLMs from Apache Airflow, based on <a href="https://ai.pydantic.dev/" rel="nofollow">Pydantic AI</a>. It allows users to call LLMs and orchestrate agent calls directly within their Airflow pipelines using decorator-based tasks. The SDK leverages the familiar Airflow <code>@task</code> syntax with extensions like <code>@task.llm</code>, <code>@task.llm_branch</code>, and <code>@task.agent</code>.</p>
<p dir="auto">To get started, check out the <a href="https://github.com/astronomer/ai-sdk-examples">examples repository here</a>, which offers a full local Airflow instance with the AI SDK installed and 5 example pipelines. To run this locally, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/astronomer/ai-sdk-examples.git
cd ai-sdk-examples
astro dev start"><pre>git clone https://github.com/astronomer/ai-sdk-examples.git
<span>cd</span> ai-sdk-examples
astro dev start</pre></div>
<p dir="auto">If you don't have the Astro CLI installed, run <code>brew install astro</code> (or see other options <a href="https://www.astronomer.io/docs/astro/cli/install-cli" rel="nofollow">here</a>).</p>
<p dir="auto">If you already have Airflow running, you can also install the package with any optional dependencies you need:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install airflow-ai-sdk[openai,duckduckgo]"><pre>pip install airflow-ai-sdk[openai,duckduckgo]</pre></div>
<p dir="auto">Note that installing the package with no optional dependencies will install the slim version of the package, which does not include any LLM models or tools. The available optional packages are listed <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/pyproject.toml#L17">here</a>. While this SDK offers the optional dependencies for convenience sake, you can also install the optional dependencies from <a href="https://ai.pydantic.dev/install/" rel="nofollow">Pydantic AI</a> directly.</p>
<p dir="auto">Table of Contents:</p>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#motivation">Motivation</a></li>
<li><a href="#examples">Examples</a>
<ul dir="auto">
<li><a href="#llm-calls-from-a-dag-summarize-airflow-s-commits">LLM calls from a DAG (summarize Airflow's commits)</a></li>
<li><a href="#llm-calls-with-structured-outputs-using-taskllm-user-feedback---sentiment-and-feature-requests">LLM calls with structured outputs using <code>@task.llm</code> (user feedback -&gt; sentiment and feature requests)</a></li>
<li><a href="#agent-calls-with-taskagent-deep-research-agent">Agent calls with <code>@task.agent</code> (deep research agent)</a></li>
<li><a href="#changing-dag-control-flow-with-taskllmbranch-support-ticket-routing">Changing dag control flow with <code>@task.llm_branch</code> (support ticket routing)</a></li>
</ul>
</li>
<li><a href="#future-work">Future Work</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>LLM tasks with <code>@task.llm</code>:</strong> Define tasks that call language models (e.g. GPT-3.5-turbo) to process text.</li>
<li><strong>Agent tasks with <code>@task.agent</code>:</strong> Orchestrate multi-step AI reasoning by leveraging custom tools.</li>
<li><strong>Automatic output parsing:</strong> Use function type hints (including Pydantic models) to automatically parse and validate LLM outputs.</li>
<li><strong>Branching with <code>@task.llm_branch</code>:</strong> Change the control flow of a DAG based on the output of an LLM.</li>
<li><strong>Model support:</strong> Support for <a href="https://ai.pydantic.dev/models/" rel="nofollow">all models in the Pydantic AI library</a> (OpenAI, Anthropic, Gemini, Ollama, Groq, Mistral, Cohere, Bedrock)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design Principles</h2><a id="user-content-design-principles" aria-label="Permalink: Design Principles" href="#design-principles"></a></p>
<p dir="auto">We follow the taskflow pattern of Airflow with three decorators:</p>
<ul dir="auto">
<li><code>@task.llm</code>: Define a task that calls an LLM. Under the hood, this creates a Pydantic AI <code>Agent</code> with no tools.</li>
<li><code>@task.agent</code>: Define a task that calls an agent. You can pass in a Pydantic AI <code>Agent</code> directly.</li>
<li><code>@task.llm_branch</code>: Define a task that branches the control flow of a DAG based on the output of an LLM. Enforces that the LLM output is one of the downstream task_ids.</li>
</ul>
<p dir="auto">The function supplied to each decorator is a translation function that converts the Airflow task's input into the LLM's input. If you don't want to do any translation, you
can just return the input unchanged.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">AI workflows are becoming increasingly common as organizations look for pragmatic ways to get value out of LLMs. As with
any workflow, it's important to have a flexible and scalable way to orchestrate them.</p>
<p dir="auto">Airflow is a popular choice for orchestrating data pipelines. It's a powerful tool for managing the dependencies
between tasks and for scheduling and monitoring them, and has been trusted by data teams everywhere for 10+ years. It comes "batteries included" with a rich set of capabilities:</p>
<ul dir="auto">
<li><strong>Flexible scheduling:</strong> run tasks on a fixed schedule, on-demand, or based on external events</li>
<li><strong>Dynamic task mapping:</strong> easily process multiple inputs in parallel with full error handling and observability</li>
<li><strong>Branching and conditional logic:</strong> change the control flow of a DAG based on the output of certain tasks</li>
<li><strong>Error handling:</strong> built-in support for retries, exponential backoff, and timeouts</li>
<li><strong>Resource management:</strong> limit the concurrency of tasks with Airflow Pools</li>
<li><strong>Monitoring:</strong> detailed logs and monitoring capabilities</li>
<li><strong>Scalability:</strong> designed for production workflows</li>
</ul>
<p dir="auto">This SDK is designed to make it easy to integrate LLM workflows into your Airflow pipelines. It allows you to do anything from simple LLM calls to complex agentic workflows.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">See the full set of examples in the <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags">examples/dags</a> directory.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">LLM calls from a DAG (summarize Airflow's commits)</h3><a id="user-content-llm-calls-from-a-dag-summarize-airflows-commits" aria-label="Permalink: LLM calls from a DAG (summarize Airflow's commits)" href="#llm-calls-from-a-dag-summarize-airflows-commits"></a></p>
<p dir="auto">This example shows how to use the <code>@task.llm</code> decorator as part of an Airflow DAG. In the <code>@task.llm</code> decorator, we can
specify a model and system prompt. The decorator allows you to transform the Airflow task's input into the LLM's input.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/github_changelog.py">github_changelog.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import os

import pendulum

from airflow.decorators import dag, task

from github import Github

@task
def get_recent_commits(data_interval_start: pendulum.DateTime, data_interval_end: pendulum.DateTime) -> list[str]:
    &quot;&quot;&quot;
    This task returns a mocked list of recent commits. In a real workflow, this
    task would get the recent commits from a database or API.
    &quot;&quot;&quot;
    print(f&quot;Getting commits for {data_interval_start} to {data_interval_end}&quot;)
    gh = Github(os.getenv(&quot;GITHUB_TOKEN&quot;))
    repo = gh.get_repo(&quot;apache/airflow&quot;)
    commits = repo.get_commits(since=data_interval_start, until=data_interval_end)
    return [f&quot;{commit.commit.sha}: {commit.commit.message}&quot; for commit in commits]

@task.llm(
    model=&quot;gpt-4o-mini&quot;,
    result_type=str,
    system_prompt=&quot;&quot;&quot;
    Your job is to summarize the commits to the Airflow project given a week's worth
    of commits. Pay particular attention to large changes and new features as opposed
    to bug fixes and minor changes.

    You don't need to include every commit, just the most important ones. Add a one line
    overall summary of the changes at the top, followed by bullet points of the most
    important changes.

    Example output:

    This week, we made architectural changes to the core scheduler to make it more
    maintainable and easier to understand.

    - Made the scheduler 20% faster (commit 1234567)
    - Added a new task type: `example_task` (commit 1234568)
    - Added a new operator: `example_operator` (commit 1234569)
    - Added a new sensor: `example_sensor` (commit 1234570)
    &quot;&quot;&quot;
)
def summarize_commits(commits: list[str] | None = None) -> str:
    &quot;&quot;&quot;
    This task summarizes the commits. You can add logic here to transform the input
    before it gets passed to the LLM.
    &quot;&quot;&quot;
    # don't need to do any translation
    return &quot;\n&quot;.join(commits)

@task
def send_summaries(summaries: str):
    ...

@dag(
    schedule=&quot;@weekly&quot;,
    start_date=pendulum.datetime(2025, 3, 1, tz=&quot;UTC&quot;),
    catchup=False,
)
def github_changelog():
    commits = get_recent_commits()
    summaries = summarize_commits(commits=commits)
    send_summaries(summaries)

github_changelog()"><pre><span>import</span> <span>os</span>

<span>import</span> <span>pendulum</span>

<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>

<span>from</span> <span>github</span> <span>import</span> <span>Github</span>

<span>@<span>task</span></span>
<span>def</span> <span>get_recent_commits</span>(<span>data_interval_start</span>: <span>pendulum</span>.<span>DateTime</span>, <span>data_interval_end</span>: <span>pendulum</span>.<span>DateTime</span>) <span>-&gt;</span> <span>list</span>[<span>str</span>]:
    <span>"""</span>
<span>    This task returns a mocked list of recent commits. In a real workflow, this</span>
<span>    task would get the recent commits from a database or API.</span>
<span>    """</span>
    <span>print</span>(<span>f"Getting commits for <span><span>{</span><span>data_interval_start</span><span>}</span></span> to <span><span>{</span><span>data_interval_end</span><span>}</span></span>"</span>)
    <span>gh</span> <span>=</span> <span>Github</span>(<span>os</span>.<span>getenv</span>(<span>"GITHUB_TOKEN"</span>))
    <span>repo</span> <span>=</span> <span>gh</span>.<span>get_repo</span>(<span>"apache/airflow"</span>)
    <span>commits</span> <span>=</span> <span>repo</span>.<span>get_commits</span>(<span>since</span><span>=</span><span>data_interval_start</span>, <span>until</span><span>=</span><span>data_interval_end</span>)
    <span>return</span> [<span>f"<span><span>{</span><span>commit</span>.<span>commit</span>.<span>sha</span><span>}</span></span>: <span><span>{</span><span>commit</span>.<span>commit</span>.<span>message</span><span>}</span></span>"</span> <span>for</span> <span>commit</span> <span>in</span> <span>commits</span>]

<span>@<span>task</span>.<span>llm</span>(</span>
<span>    <span>model</span><span>=</span><span>"gpt-4o-mini"</span>,</span>
<span>    <span>result_type</span><span>=</span><span>str</span>,</span>
<span>    <span>system_prompt</span><span>=</span><span>"""</span></span>
<span><span>    Your job is to summarize the commits to the Airflow project given a week's worth</span></span>
<span><span>    of commits. Pay particular attention to large changes and new features as opposed</span></span>
<span><span>    to bug fixes and minor changes.</span></span>
<span><span></span></span>
<span><span>    You don't need to include every commit, just the most important ones. Add a one line</span></span>
<span><span>    overall summary of the changes at the top, followed by bullet points of the most</span></span>
<span><span>    important changes.</span></span>
<span><span></span></span>
<span><span>    Example output:</span></span>
<span><span></span></span>
<span><span>    This week, we made architectural changes to the core scheduler to make it more</span></span>
<span><span>    maintainable and easier to understand.</span></span>
<span><span></span></span>
<span><span>    - Made the scheduler 20% faster (commit 1234567)</span></span>
<span><span>    - Added a new task type: `example_task` (commit 1234568)</span></span>
<span><span>    - Added a new operator: `example_operator` (commit 1234569)</span></span>
<span><span>    - Added a new sensor: `example_sensor` (commit 1234570)</span></span>
<span><span>    """</span></span>
<span>)</span>
<span>def</span> <span>summarize_commits</span>(<span>commits</span>: <span>list</span>[<span>str</span>] <span>|</span> <span>None</span> <span>=</span> <span>None</span>) <span>-&gt;</span> <span>str</span>:
    <span>"""</span>
<span>    This task summarizes the commits. You can add logic here to transform the input</span>
<span>    before it gets passed to the LLM.</span>
<span>    """</span>
    <span># don't need to do any translation</span>
    <span>return</span> <span>"<span>\n</span>"</span>.<span>join</span>(<span>commits</span>)

<span>@<span>task</span></span>
<span>def</span> <span>send_summaries</span>(<span>summaries</span>: <span>str</span>):
    ...

<span>@<span>dag</span>(</span>
<span>    <span>schedule</span><span>=</span><span>"@weekly"</span>,</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2025</span>, <span>3</span>, <span>1</span>, <span>tz</span><span>=</span><span>"UTC"</span>),</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>)</span>
<span>def</span> <span>github_changelog</span>():
    <span>commits</span> <span>=</span> <span>get_recent_commits</span>()
    <span>summaries</span> <span>=</span> <span>summarize_commits</span>(<span>commits</span><span>=</span><span>commits</span>)
    <span>send_summaries</span>(<span>summaries</span>)

<span>github_changelog</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">LLM calls with structured outputs using <code>@task.llm</code> (user feedback -&gt; sentiment and feature requests)</h3><a id="user-content-llm-calls-with-structured-outputs-using-taskllm-user-feedback---sentiment-and-feature-requests" aria-label="Permalink: LLM calls with structured outputs using @task.llm (user feedback -> sentiment and feature requests)" href="#llm-calls-with-structured-outputs-using-taskllm-user-feedback---sentiment-and-feature-requests"></a></p>
<p dir="auto">This example demonstrates how to use the <code>@task.llm</code> decorator to call an LLM and return a structured output. In this
case, we're using a Pydantic model to validate the output of the LLM. We recommend using the <code>airflow_ai_sdk.BaseModel</code>
class to define your Pydantic models in case we add more functionality in the future.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/product_feedback_summarization.py">product_feedback_summarization.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import pendulum

from typing import Literal, Any

from airflow.decorators import dag, task
from airflow.exceptions import AirflowSkipException

import airflow_ai_sdk as ai_sdk

from include.pii import mask_pii

@task
def get_product_feedback() -> list[str]:
    &quot;&quot;&quot;
    This task returns a mocked list of product feedback. In a real workflow, this
    task would get the product feedback from a database or API.
    &quot;&quot;&quot;
    ...

class ProductFeedbackSummary(ai_sdk.BaseModel):
    summary: str
    sentiment: Literal[&quot;positive&quot;, &quot;negative&quot;, &quot;neutral&quot;]
    feature_requests: list[str]

@task.llm(
    model=&quot;gpt-4o-mini&quot;,
    result_type=ProductFeedbackSummary,
    system_prompt=&quot;&quot;&quot;
    You are a helpful assistant that summarizes product feedback.
    &quot;&quot;&quot;
)
def summarize_product_feedback(feedback: str | None = None) -> ProductFeedbackSummary:
    &quot;&quot;&quot;
    This task summarizes the product feedback. You can add logic here to transform the input
    before summarizing it.
    &quot;&quot;&quot;
    # if the feedback doesn't mention Airflow, skip it
    if &quot;Airflow&quot; not in feedback:
        raise AirflowSkipException(&quot;Feedback does not mention Airflow&quot;)

    # mask PII in the feedback
    feedback = mask_pii(feedback)

    return feedback


@task
def upload_summaries(summaries: list[dict[str, Any]]):
    ...

@dag(
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=&quot;UTC&quot;),
    catchup=False,
)
def product_feedback_summarization():
    feedback = get_product_feedback()
    summaries = summarize_product_feedback.expand(feedback=feedback)
    upload_summaries(summaries)

product_feedback_summarization()"><pre><span>import</span> <span>pendulum</span>

<span>from</span> <span>typing</span> <span>import</span> <span>Literal</span>, <span>Any</span>

<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>
<span>from</span> <span>airflow</span>.<span>exceptions</span> <span>import</span> <span>AirflowSkipException</span>

<span>import</span> <span>airflow_ai_sdk</span> <span>as</span> <span>ai_sdk</span>

<span>from</span> <span>include</span>.<span>pii</span> <span>import</span> <span>mask_pii</span>

<span>@<span>task</span></span>
<span>def</span> <span>get_product_feedback</span>() <span>-&gt;</span> <span>list</span>[<span>str</span>]:
    <span>"""</span>
<span>    This task returns a mocked list of product feedback. In a real workflow, this</span>
<span>    task would get the product feedback from a database or API.</span>
<span>    """</span>
    ...

<span>class</span> <span>ProductFeedbackSummary</span>(<span>ai_sdk</span>.<span>BaseModel</span>):
    <span>summary</span>: <span>str</span>
    <span>sentiment</span>: <span>Literal</span>[<span>"positive"</span>, <span>"negative"</span>, <span>"neutral"</span>]
    <span>feature_requests</span>: <span>list</span>[<span>str</span>]

<span>@<span>task</span>.<span>llm</span>(</span>
<span>    <span>model</span><span>=</span><span>"gpt-4o-mini"</span>,</span>
<span>    <span>result_type</span><span>=</span><span>ProductFeedbackSummary</span>,</span>
<span>    <span>system_prompt</span><span>=</span><span>"""</span></span>
<span><span>    You are a helpful assistant that summarizes product feedback.</span></span>
<span><span>    """</span></span>
<span>)</span>
<span>def</span> <span>summarize_product_feedback</span>(<span>feedback</span>: <span>str</span> <span>|</span> <span>None</span> <span>=</span> <span>None</span>) <span>-&gt;</span> <span>ProductFeedbackSummary</span>:
    <span>"""</span>
<span>    This task summarizes the product feedback. You can add logic here to transform the input</span>
<span>    before summarizing it.</span>
<span>    """</span>
    <span># if the feedback doesn't mention Airflow, skip it</span>
    <span>if</span> <span>"Airflow"</span> <span><span>not</span> <span>in</span></span> <span>feedback</span>:
        <span>raise</span> <span>AirflowSkipException</span>(<span>"Feedback does not mention Airflow"</span>)

    <span># mask PII in the feedback</span>
    <span>feedback</span> <span>=</span> <span>mask_pii</span>(<span>feedback</span>)

    <span>return</span> <span>feedback</span>


<span>@<span>task</span></span>
<span>def</span> <span>upload_summaries</span>(<span>summaries</span>: <span>list</span>[<span>dict</span>[<span>str</span>, <span>Any</span>]]):
    ...

<span>@<span>dag</span>(</span>
<span>    <span>schedule</span><span>=</span><span>None</span>,</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2021</span>, <span>1</span>, <span>1</span>, <span>tz</span><span>=</span><span>"UTC"</span>),</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>)</span>
<span>def</span> <span>product_feedback_summarization</span>():
    <span>feedback</span> <span>=</span> <span>get_product_feedback</span>()
    <span>summaries</span> <span>=</span> <span>summarize_product_feedback</span>.<span>expand</span>(<span>feedback</span><span>=</span><span>feedback</span>)
    <span>upload_summaries</span>(<span>summaries</span>)

<span>product_feedback_summarization</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Agent calls with <code>@task.agent</code> (deep research agent)</h3><a id="user-content-agent-calls-with-taskagent-deep-research-agent" aria-label="Permalink: Agent calls with @task.agent (deep research agent)" href="#agent-calls-with-taskagent-deep-research-agent"></a></p>
<p dir="auto">This example shows how to build an AI agent that can autonomously invoke external tools (e.g., a knowledge base search) when answering a user question.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/deep_research.py">deep_research.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import pendulum
import requests

from airflow.decorators import dag, task
from airflow.models.dagrun import DagRun
from airflow.models.param import Param

from bs4 import BeautifulSoup

from pydantic_ai import Agent
from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool

# custom tool to get the content of a page
def get_page_content(url: str) -> str:
    &quot;&quot;&quot;
    Get the content of a page.
    &quot;&quot;&quot;
    response = requests.get(url)
    soup = BeautifulSoup(response.text, &quot;html.parser&quot;)

    distillation_agent = Agent(
        &quot;gpt-4o-mini&quot;,
        system_prompt=&quot;&quot;&quot;
        You are responsible for distilling information from a text. The summary will be used by a research agent to generate a research report.

        Keep the summary concise and to the point, focusing on only key information.
        &quot;&quot;&quot;,
    )

    return distillation_agent.run_sync(soup.get_text())

deep_research_agent = Agent(
    &quot;o3-mini&quot;,
    system_prompt=&quot;&quot;&quot;
    You are a deep research agent who is very skilled at distilling information from the web. You are given a query and your job is to generate a research report.

    You can search the web by using the `duckduckgo_search_tool`. You can also use the `get_page_content` tool to get the contents of a page.

    Keep going until you have enough information to generate a research report. Assume you know nothing about the query or contents, so you need to search the web for relevant information.

    Do not generate new information, only distill information from the web.
    &quot;&quot;&quot;,
    tools=[duckduckgo_search_tool(), get_page_content],
)

@task.agent(agent=deep_research_agent)
def deep_research_task(dag_run: DagRun) -> str:
    &quot;&quot;&quot;
    This task performs a deep research on the given query.
    &quot;&quot;&quot;
    query = dag_run.conf.get(&quot;query&quot;)

    if not query:
        raise ValueError(&quot;Query is required&quot;)

    print(f&quot;Performing deep research on {query}&quot;)

    return query


@task
def upload_results(results: str):
    ...

@dag(
    schedule=None,
    start_date=pendulum.datetime(2025, 3, 1, tz=&quot;UTC&quot;),
    catchup=False,
    params={
        &quot;query&quot;: Param(
            type=&quot;string&quot;,
            default=&quot;How has the field of data engineering evolved in the last 5 years?&quot;,
        ),
    },
)
def deep_research():
    results = deep_research_task()
    upload_results(results)

deep_research()"><pre><span>import</span> <span>pendulum</span>
<span>import</span> <span>requests</span>

<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>
<span>from</span> <span>airflow</span>.<span>models</span>.<span>dagrun</span> <span>import</span> <span>DagRun</span>
<span>from</span> <span>airflow</span>.<span>models</span>.<span>param</span> <span>import</span> <span>Param</span>

<span>from</span> <span>bs4</span> <span>import</span> <span>BeautifulSoup</span>

<span>from</span> <span>pydantic_ai</span> <span>import</span> <span>Agent</span>
<span>from</span> <span>pydantic_ai</span>.<span>common_tools</span>.<span>duckduckgo</span> <span>import</span> <span>duckduckgo_search_tool</span>

<span># custom tool to get the content of a page</span>
<span>def</span> <span>get_page_content</span>(<span>url</span>: <span>str</span>) <span>-&gt;</span> <span>str</span>:
    <span>"""</span>
<span>    Get the content of a page.</span>
<span>    """</span>
    <span>response</span> <span>=</span> <span>requests</span>.<span>get</span>(<span>url</span>)
    <span>soup</span> <span>=</span> <span>BeautifulSoup</span>(<span>response</span>.<span>text</span>, <span>"html.parser"</span>)

    <span>distillation_agent</span> <span>=</span> <span>Agent</span>(
        <span>"gpt-4o-mini"</span>,
        <span>system_prompt</span><span>=</span><span>"""</span>
<span>        You are responsible for distilling information from a text. The summary will be used by a research agent to generate a research report.</span>
<span></span>
<span>        Keep the summary concise and to the point, focusing on only key information.</span>
<span>        """</span>,
    )

    <span>return</span> <span>distillation_agent</span>.<span>run_sync</span>(<span>soup</span>.<span>get_text</span>())

<span>deep_research_agent</span> <span>=</span> <span>Agent</span>(
    <span>"o3-mini"</span>,
    <span>system_prompt</span><span>=</span><span>"""</span>
<span>    You are a deep research agent who is very skilled at distilling information from the web. You are given a query and your job is to generate a research report.</span>
<span></span>
<span>    You can search the web by using the `duckduckgo_search_tool`. You can also use the `get_page_content` tool to get the contents of a page.</span>
<span></span>
<span>    Keep going until you have enough information to generate a research report. Assume you know nothing about the query or contents, so you need to search the web for relevant information.</span>
<span></span>
<span>    Do not generate new information, only distill information from the web.</span>
<span>    """</span>,
    <span>tools</span><span>=</span>[<span>duckduckgo_search_tool</span>(), <span>get_page_content</span>],
)

<span>@<span>task</span>.<span>agent</span>(<span>agent</span><span>=</span><span>deep_research_agent</span>)</span>
<span>def</span> <span>deep_research_task</span>(<span>dag_run</span>: <span>DagRun</span>) <span>-&gt;</span> <span>str</span>:
    <span>"""</span>
<span>    This task performs a deep research on the given query.</span>
<span>    """</span>
    <span>query</span> <span>=</span> <span>dag_run</span>.<span>conf</span>.<span>get</span>(<span>"query"</span>)

    <span>if</span> <span>not</span> <span>query</span>:
        <span>raise</span> <span>ValueError</span>(<span>"Query is required"</span>)

    <span>print</span>(<span>f"Performing deep research on <span><span>{</span><span>query</span><span>}</span></span>"</span>)

    <span>return</span> <span>query</span>


<span>@<span>task</span></span>
<span>def</span> <span>upload_results</span>(<span>results</span>: <span>str</span>):
    ...

<span>@<span>dag</span>(</span>
<span>    <span>schedule</span><span>=</span><span>None</span>,</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2025</span>, <span>3</span>, <span>1</span>, <span>tz</span><span>=</span><span>"UTC"</span>),</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>    <span>params</span><span>=</span>{</span>
<span>        <span>"query"</span>: <span>Param</span>(</span>
<span>            <span>type</span><span>=</span><span>"string"</span>,</span>
<span>            <span>default</span><span>=</span><span>"How has the field of data engineering evolved in the last 5 years?"</span>,</span>
<span>        ),</span>
<span>    },</span>
<span>)</span>
<span>def</span> <span>deep_research</span>():
    <span>results</span> <span>=</span> <span>deep_research_task</span>()
    <span>upload_results</span>(<span>results</span>)

<span>deep_research</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Changing dag control flow with <code>@task.llm_branch</code> (support ticket routing)</h3><a id="user-content-changing-dag-control-flow-with-taskllm_branch-support-ticket-routing" aria-label="Permalink: Changing dag control flow with @task.llm_branch (support ticket routing)" href="#changing-dag-control-flow-with-taskllm_branch-support-ticket-routing"></a></p>
<p dir="auto">This example demonstrates how to use the <code>@task.llm_branch</code> decorator to change the control flow of a DAG based on the output of an LLM. In this case, we're routing support tickets based on the severity of the ticket.</p>
<p dir="auto">See full example: <a href="https://github.com/astronomer/airflow-ai-sdk/blob/main/examples/dags/support_ticket_routing.py">support_ticket_routing.py</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import pendulum
from airflow.decorators import dag, task
from airflow.models.dagrun import DagRun

@task.llm_branch(
    model=&quot;gpt-4o-mini&quot;,
    system_prompt=&quot;&quot;&quot;
    You are a support agent that routes support tickets based on the priority of the ticket.

    Here are the priority definitions:
    - P0: Critical issues that impact the user's ability to use the product, specifically for a production deployment.
    - P1: Issues that impact the user's ability to use the product, but not as severely (or not for their production deployment).
    - P2: Issues that are low priority and can wait until the next business day
    - P3: Issues that are not important or time sensitive

    Here are some examples of tickets and their priorities:
    - &quot;Our production deployment just went down because it ran out of memory. Please help.&quot;: P0
    - &quot;Our staging / dev / QA deployment just went down because it ran out of memory. Please help.&quot;: P1
    - &quot;I'm having trouble logging in to my account.&quot;: P1
    - &quot;The UI is not loading.&quot;: P1
    - &quot;I need help setting up my account.&quot;: P2
    - &quot;I have a question about the product.&quot;: P3
    &quot;&quot;&quot;,
    allow_multiple_branches=True,
)
def route_ticket(dag_run: DagRun) -> str:
    return dag_run.conf.get(&quot;ticket&quot;)

@task
def handle_p0_ticket(ticket: str):
    print(f&quot;Handling P0 ticket: {ticket}&quot;)

@task
def handle_p1_ticket(ticket: str):
    print(f&quot;Handling P1 ticket: {ticket}&quot;)

@task
def handle_p2_ticket(ticket: str):
    print(f&quot;Handling P2 ticket: {ticket}&quot;)

@task
def handle_p3_ticket(ticket: str):
    print(f&quot;Handling P3 ticket: {ticket}&quot;)

@dag(
    start_date=pendulum.datetime(2025, 1, 1, tz=&quot;UTC&quot;),
    schedule=None,
    catchup=False,
    params={&quot;ticket&quot;: &quot;Hi, our production deployment just went down because it ran out of memory. Please help.&quot;}
)
def support_ticket_routing():
    ticket = route_ticket()

    handle_p0_ticket(ticket)
    handle_p1_ticket(ticket)
    handle_p2_ticket(ticket)
    handle_p3_ticket(ticket)

support_ticket_routing()"><pre><span>import</span> <span>pendulum</span>
<span>from</span> <span>airflow</span>.<span>decorators</span> <span>import</span> <span>dag</span>, <span>task</span>
<span>from</span> <span>airflow</span>.<span>models</span>.<span>dagrun</span> <span>import</span> <span>DagRun</span>

<span>@<span>task</span>.<span>llm_branch</span>(</span>
<span>    <span>model</span><span>=</span><span>"gpt-4o-mini"</span>,</span>
<span>    <span>system_prompt</span><span>=</span><span>"""</span></span>
<span><span>    You are a support agent that routes support tickets based on the priority of the ticket.</span></span>
<span><span></span></span>
<span><span>    Here are the priority definitions:</span></span>
<span><span>    - P0: Critical issues that impact the user's ability to use the product, specifically for a production deployment.</span></span>
<span><span>    - P1: Issues that impact the user's ability to use the product, but not as severely (or not for their production deployment).</span></span>
<span><span>    - P2: Issues that are low priority and can wait until the next business day</span></span>
<span><span>    - P3: Issues that are not important or time sensitive</span></span>
<span><span></span></span>
<span><span>    Here are some examples of tickets and their priorities:</span></span>
<span><span>    - "Our production deployment just went down because it ran out of memory. Please help.": P0</span></span>
<span><span>    - "Our staging / dev / QA deployment just went down because it ran out of memory. Please help.": P1</span></span>
<span><span>    - "I'm having trouble logging in to my account.": P1</span></span>
<span><span>    - "The UI is not loading.": P1</span></span>
<span><span>    - "I need help setting up my account.": P2</span></span>
<span><span>    - "I have a question about the product.": P3</span></span>
<span><span>    """</span>,</span>
<span>    <span>allow_multiple_branches</span><span>=</span><span>True</span>,</span>
<span>)</span>
<span>def</span> <span>route_ticket</span>(<span>dag_run</span>: <span>DagRun</span>) <span>-&gt;</span> <span>str</span>:
    <span>return</span> <span>dag_run</span>.<span>conf</span>.<span>get</span>(<span>"ticket"</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p0_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f"Handling P0 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>"</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p1_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f"Handling P1 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>"</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p2_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f"Handling P2 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>"</span>)

<span>@<span>task</span></span>
<span>def</span> <span>handle_p3_ticket</span>(<span>ticket</span>: <span>str</span>):
    <span>print</span>(<span>f"Handling P3 ticket: <span><span>{</span><span>ticket</span><span>}</span></span>"</span>)

<span>@<span>dag</span>(</span>
<span>    <span>start_date</span><span>=</span><span>pendulum</span>.<span>datetime</span>(<span>2025</span>, <span>1</span>, <span>1</span>, <span>tz</span><span>=</span><span>"UTC"</span>),</span>
<span>    <span>schedule</span><span>=</span><span>None</span>,</span>
<span>    <span>catchup</span><span>=</span><span>False</span>,</span>
<span>    <span>params</span><span>=</span>{<span>"ticket"</span>: <span>"Hi, our production deployment just went down because it ran out of memory. Please help."</span>}</span>
<span>)</span>
<span>def</span> <span>support_ticket_routing</span>():
    <span>ticket</span> <span>=</span> <span>route_ticket</span>()

    <span>handle_p0_ticket</span>(<span>ticket</span>)
    <span>handle_p1_ticket</span>(<span>ticket</span>)
    <span>handle_p2_ticket</span>(<span>ticket</span>)
    <span>handle_p3_ticket</span>(<span>ticket</span>)

<span>support_ticket_routing</span>()</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Honey has now lost 4M Chrome users after shady tactics were revealed (582 pts)]]></title>
            <link>https://9to5google.com/2025/03/31/honey-extension-users-dropped-chrome-march-2025/</link>
            <guid>43538113</guid>
            <pubDate>Mon, 31 Mar 2025 18:28:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2025/03/31/honey-extension-users-dropped-chrome-march-2025/">https://9to5google.com/2025/03/31/honey-extension-users-dropped-chrome-march-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=43538113">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5google.com/wp-content/uploads/sites/4/2025/01/paypal-honey-logo-1.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/01/paypal-honey-logo-1.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/01/paypal-honey-logo-1.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/01/paypal-honey-logo-1.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2025/01/paypal-honey-logo-1.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Late last year the popular Chrome extension Honey (owned by PayPal) was revealed for employing a few shady tactics, and the extension has since lost around 4 million users on Google’s browser alone.</p>



<p>To recap the situation thus far, Honey has amassed millions of users over the past several years on the promise of finding coupon codes for various online stores. The free extension saw wide advertisements and was eventually <a href="https://investor.pypl.com/news-and-events/news-details/2020/PayPal-Completes-Acquisition-of-Honey/default.aspx">purchased by PayPal in 2020 </a>for $4 billion.</p>



<p>In December 2024, <a href="https://www.youtube.com/watch?v=vc4yL3YTwWk">a video on YouTube</a> by the channel <em>MegaLag</em> exposed Honey for two shady practices. The first was how the extension took advantage of affiliate codes. Honey has always used affiliate programs to subsidize its service, but the video revealed that the extension would hijack these programs – removing affiliate codes from other refferers such as online creators and website – even if it didn’t have coupon codes or cash back to offer in return. The practice was working behind the scenes with businesses to control which codes would appear to Honey users, effectively directly lying about its promise of finding the “best” coupon codes on the web.</p>



<p>That video amassed over 17 million views, and Honey has now lost over 4 million users on Chrome.</p>	
	



<p>As <a href="https://9to5google.com/2025/01/03/honey-paypal-chrome-extension-lost-users/">we reported in early January,</a> Honey had lost around 3 million users immediately after the video went viral, but ended up <a href="https://9to5google.com/2025/01/17/honey-18-million-users-grew-back/">gaining back</a> around 1 million later on. Now, as of March 2025, Honey is down to 16 million users <a href="https://chromewebstore.google.com/detail/honey-automatic-coupons-r/bmnlcjabgnpnenekpadlanbbkooimhnj?pli=1">on Chrome</a>, down from its peak of 20 million.</p>



<figure><img decoding="async" width="1023" height="307" src="https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png" alt="" srcset="https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png 1023w, https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png?resize=155,47 155w, https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png?resize=700,210 700w, https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png?resize=768,230 768w, https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png?resize=350,105 350w, https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png?resize=140,42 140w, https://9to5google.com/wp-content/uploads/sites/4/2025/03/image_2345e3.png?resize=150,45 150w" sizes="(max-width: 1023px) 100vw, 1023px"></figure>



<p>This drop comes<a href="https://9to5google.com/2025/03/11/google-chrome-affiliate-extension-policy-honey/"> after new Chrome policy has taken effect which prevents</a> Honey, and extensions like it, from practices including taking over affiliate codes without disclosure or without benefit to the extension’s users. Honey has since <a href="https://9to5google.com/2025/03/12/honey-affiliate-disclosure-google-chrome-listing/">updated its extension listing with disclosure</a>, and <a href="https://9to5google.com/2025/03/13/honey-affiliate-update/">we found that the behavior shown in the December video no longer occurs</a>.</p>



<p>Are you still using Honey?</p>



<h2 id="h-more-on-chrome">More on Chrome:</h2>



<ul>
<li><a href="https://9to5google.com/2025/03/11/google-chrome-affiliate-extension-policy-honey/">Google Chrome policy update restricts shady affiliate extensions, like Honey</a></li>



<li><a href="https://9to5google.com/2025/03/02/chrome-135-edge-to-edge-android/">Chrome 135 for Android will start ‘going edge-to-edge’&nbsp;[Gallery]</a></li>



<li><a href="https://9to5google.com/2025/02/19/google-lens-screen-search-chrome-ios/">Google Lens powering new Screen Search in Chrome for iOS</a></li>
</ul>



<p><em><strong>Follow Ben:</strong>&nbsp;<a href="https://twitter.com/NexusBen" target="_blank" rel="noreferrer noopener">Twitter/X</a>,&nbsp;<a href="https://www.threads.net/@nexusben" target="_blank" rel="noreferrer noopener">Threads</a>, <a href="https://bsky.app/profile/nexusben.com">Bluesky</a>, and&nbsp;<a href="https://www.instagram.com/nexusben" target="_blank" rel="noreferrer noopener">Instagram</a></em></p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[France fines Apple €150M for “excessive” pop-ups that let users reject tracking (242 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2025/03/france-fines-apple-e150m-for-excessive-pop-ups-that-let-users-reject-tracking/</link>
            <guid>43537593</guid>
            <pubDate>Mon, 31 Mar 2025 17:38:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2025/03/france-fines-apple-e150m-for-excessive-pop-ups-that-let-users-reject-tracking/">https://arstechnica.com/tech-policy/2025/03/france-fines-apple-e150m-for-excessive-pop-ups-that-let-users-reject-tracking/</a>, See on <a href="https://news.ycombinator.com/item?id=43537593">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>A <a href="https://support.apple.com/en-us/102420">typical ATT&nbsp; pop-up</a> asks a user whether to allow an app "to track your activity across other companies' apps and websites," and says that "your data will be used to deliver personalized ads to you."</p>
<h2>Agency: “Double consent” too cumbersome</h2>
<p>The agency said there is an "asymmetry" in which user consent for Apple's own data collection is obtained with a single pop-up, but other publishers are "required to obtain double consent from users for tracking on third-party sites and applications." The press release notes that "while advertising tracking only needs to be refused once, the user must always confirm their consent a second time."</p>
<p>The system was said to be less harmful for big companies like Meta and Google and "particularly harmful for smaller publishers that do not enjoy alternative targeting possibilities, in particular in the absence of sufficient proprietary data." Although France's focus is on how ATT affects smaller companies, Apple's privacy system has also been <a href="https://arstechnica.com/gadgets/2021/01/why-facebook-and-apple-are-going-to-war-over-privacy/">criticized by Facebook</a>.</p>
<p>The €150 million fine won't make much of a dent in Apple's revenue, but Apple will apparently have to make some changes to comply with the French order. The agency's press release said the problem "could be avoided by marginal modifications to the ATT framework."</p>
<p>Benoit Coeure, the head of France's competition authority, "told reporters the regulator had not spelled out how Apple should change its app, but that it was up to the company to make sure it now complied with the ruling," <a href="https://www.reuters.com/technology/french-antitrust-regulator-fines-apple-150-million-euros-over-privacy-tool-2025-03-31/">according to Reuters</a>. "The compliance process could take some time, he added, because Apple was waiting for rulings on regulators in Germany, Italy, Poland and Romania who are also investigating the ATT tool."</p>
<p>Apple said in a statement that the ATT "prompt is consistent for all developers, including Apple, and we have received strong support for this feature from consumers, privacy advocates, and data protection authorities around the world. While we are disappointed with today's decision, the French Competition Authority (FCA) has not required any specific changes to ATT."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MLB says Yankees' new "torpedo bats" are legal and likely coming (276 pts)]]></title>
            <link>https://thelibertyline.com/2025/03/30/yankees-new-torpedo-bat/</link>
            <guid>43536146</guid>
            <pubDate>Mon, 31 Mar 2025 15:27:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thelibertyline.com/2025/03/30/yankees-new-torpedo-bat/">https://thelibertyline.com/2025/03/30/yankees-new-torpedo-bat/</a>, See on <a href="https://news.ycombinator.com/item?id=43536146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>You score 20 runs, hit 9 bombs, and people start asking questions. That’s exactly what happened to the Yankees on Saturday after they revealed the “torpedo bat” during their demolition of the Milwaukee Brewers. </p><h4>Yankees have an MIT Physicist that built them the Torpedo Bat…</h4><blockquote><p lang="en" dir="ltr">Yes, the Yankees have a literal genius MIT Physicist, Lenny (who is the man), on payroll. He invented the “Torpedo” barrel. It brings more wood – and mass – to where you most often make contact as a hitter. The idea is to increase the number of “barrels” and decrease misses. <a href="https://t.co/CsC1wkAM9G" target="_blank">pic.twitter.com/CsC1wkAM9G</a></p>— Kevin Smith (@KJS_4) <a href="https://twitter.com/KJS_4/status/1906101220714152122?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">March 29, 2025</a></blockquote> <p>Anthony Volpe and Jazz Chisholm Jr. used it. Both went deep. The bat is thicker in the area where they make the most contact, basically moving the “sweet spot” lower than the typical barrel. Think more mass where it matters. Less guessing, more barreled-up baseballs.</p><p>I’m not sure if I like where this is going.</p><p>Remember when kids started coming to the local baseball field with those big-barreled whiffle ball bats instead of your classic yellow ones?</p><p>I’m not sure making a custom bat with an MIT physicist is the solution to turn Anthony Volpe and Jazz Chisholm Jr. into competent hitters at the plate.&nbsp;</p><p>Unfortunately, the MLB reviewed the torpedo bats after the game and somehow had zero issues with them?&nbsp; How’s that possible?&nbsp;</p><h4>Welcome to the age of the torpedo bat.</h4><blockquote><div lang="en" dir="ltr"><p>The Yankees have new bats today :</p><p>"where they moved a lot of the wood into the label so the harder part of the bat is going to strike the ball."</p><p>They tied their franchise record for HRs in a game in only 4 innings<br> <a href="https://t.co/nte8YpuH9V" target="_blank">pic.twitter.com/nte8YpuH9V</a></p></div>— Barstool Sports (@barstoolsports) <a href="https://twitter.com/barstoolsports/status/1906061492811698328?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">March 29, 2025</a></blockquote> <p><strong>MLB Rule is Cut and Dry: </strong>One piece of solid wood, no more than 2.61 inches at the thickest point, max 42 inches long. That’s it. As long as it fits in that box, it’s fair game. The Yankees are just playing smart.</p><h4>We should probably ban the Yankees’ Torpedo Bat, right? </h4><p>The Yankees have apparently been working with Aaron Leanhardt (aka “<a href="https://x.com/KJS_4/status/1906101220714152122" target="_blank">Lenny</a>”), a former MIT physicist turned baseball brain, who helped re-engineer the traditional wooden bat to better match where individual hitters make the most consistent contact.</p><p>According to former Yankees minor leaguer Kevin Smith, the physics checks out. You might lose a tick or two of exit velocity, but the improved “barrel percentage” makes up for it. In other words, more solid contact in the spot that matters most.</p><h4>The result? A bat that looks like it was forged in a lab—and kind of was.</h4><blockquote><div lang="en" dir="ltr"><p>The Yankees used new bats today that moved the wood to where the ball get hits with the hardest part of the bat 👀</p><p>They broke a franchise record for most home runs in a game (9) 🤯 <a href="https://t.co/9f3CiI810q" target="_blank">pic.twitter.com/9f3CiI810q</a></p></div>— DraftKings Sportsbook (@DKSportsbook) <a href="https://twitter.com/DKSportsbook/status/1906084264837267959?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">March 29, 2025</a></blockquote> <p>Instead of the typical bat tapering evenly toward the end, the “torpedo” design fattens up closer to the handle, where players like Volpe and Jazz Chisholm Jr. naturally tend to make contact.</p><p>Basically, if you stink at baseball then you should probably get a torpedo app from this MIT geek and save your career because the sweet spot just got a whole lot bigger. </p><h4>Outlaw the Torpedo Bat..</h4><p>Baseball traditionalists like myself are having a stroke watching Vlope and Jazz actually make contact with this new bat and rightfully so. Again, you can’t just make a new bat and ruin over 100 years of baseball to allow guys to actually hit and not be a complete mess at the plate.</p><p>The result is shitty players like Volpe turning around and hitting home runs with what looked like a Louisville Slugger mixed with a bowling pin. </p><h4>MLB Needs to Change This: </h4><ul><li>One piece of solid wood</li>

<li>No more than 2.61 inches in diameter at the thickest part</li>

<li>No longer than 42 inches</li></ul><p>Sure, that’s fair game…I guess. But when the Yankees launched nine home runs—a <em>franchise record</em>, mind you—amid a 20-9 beatdown of Milwaukee, the league should probably take some extra time and better understand what’s going on with this baseball bat and the future impact on the game itself moving forward. </p><h4>The Future of MLB Bats?</h4><p>Lenny, the brains behind the design, once predicted this bat shape would take over the league in 5 to 10 years. After watching Saturday’s offensive explosion? He might want to revise that timeline to 5 to 10 days. Now the real question is: how long until the rest of the league catches on?</p><p>Because if you can legally swing a bat that turns your weakest hits into loud outs — or better — why wouldn’t you? The Yankees just brought a bat to a knife fight. And unless MLB changes the rules, the “torpedo” era might be just getting started.</p><h4><a href="https://thelibertyline.com/">Join The Chase</a></h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oracle attempt to hide serious cybersecurity incident from customers (593 pts)]]></title>
            <link>https://doublepulsar.com/oracle-attempt-to-hide-serious-cybersecurity-incident-from-customers-in-oracle-saas-service-9231c8daff4a</link>
            <guid>43535953</guid>
            <pubDate>Mon, 31 Mar 2025 15:11:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://doublepulsar.com/oracle-attempt-to-hide-serious-cybersecurity-incident-from-customers-in-oracle-saas-service-9231c8daff4a">https://doublepulsar.com/oracle-attempt-to-hide-serious-cybersecurity-incident-from-customers-in-oracle-saas-service-9231c8daff4a</a>, See on <a href="https://news.ycombinator.com/item?id=43535953">Hacker News</a></p>
Couldn't get https://doublepulsar.com/oracle-attempt-to-hide-serious-cybersecurity-incident-from-customers-in-oracle-saas-service-9231c8daff4a: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Turso SQLite Offline Sync Public Beta (203 pts)]]></title>
            <link>https://turso.tech/blog/turso-offline-sync-public-beta</link>
            <guid>43535943</guid>
            <pubDate>Mon, 31 Mar 2025 15:10:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://turso.tech/blog/turso-offline-sync-public-beta">https://turso.tech/blog/turso-offline-sync-public-beta</a>, See on <a href="https://news.ycombinator.com/item?id=43535943">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><strong>We're excited to announce that Turso Offline Sync is now available in public beta!</strong></p>
<p>Your applications can continue functioning seamlessly, even when disconnected from the internet. Local database operations can proceed normally, with automatic sync occurring once connectivity is restored.</p>
<p>Historically, SQLite has been a database that excels at running local, embedded databases, because the database is just a file. For mobile devices, this means on-device databases.</p>
<p>Turso takes advantage of this with Embedded Replicas — your local embedded databases, on-device or server can now be kept in sync with your Turso Cloud database, and any changes are propagated to all replicas.</p>
<p>Until today, our sync was unidirectional: while you can always read from the database, even if offline, writes happen directly to the Cloud, and are propagated later.</p>
<p>This has two consequences:</p>
<ul>
<li>Writes were always network-slow, since they have to contact the server for every request</li>
<li>Writes could not work offline</li>
</ul>
<p>With today's announcement, the local database will be able to accept writes that are as fast as a file, work offline, and later sync to Turso Cloud.</p>
<h2 id="use-cases-that-just-got-easier"><a href="#use-cases-that-just-got-easier">#</a>Use Cases That Just Got Easier</h2>
<p>One of the things Offline Sync unlocks is the ability to create on-device local-first applications (in-browser is planned for the future, with <a href="https://turso.tech/blog/introducing-limbo-a-complete-rewrite-of-sqlite-in-rust">"the Limbo Project"</a>). Local-first architectures allow for fast and responsive applications that are resilient to network failures.</p>
<p>Compared to other local-first applications, Turso's architecture allows for a simpler solution because it always syncs the full database. With Turso's multitenant architecture, you can control which data goes into which database (e.g., per user or per tenant), and then transfer the entire database to the device.</p>
<p>As well as on-device local-first applications, Offline Sync also simplifies many other use cases:</p>
<ul>
<li><strong>Mobile Apps</strong> — create truly offline-capable mobile experiences, including Expo-based React Native applications.</li>
<li><strong>Point-of-Sale Systems</strong> — process transactions regardless of internet connectivity</li>
<li><strong>Field Data Collection</strong> — gather data in remote locations without worrying about connectivity</li>
<li><strong>IoT Applications</strong> — Maintain local data storage with periodic cloud sync with Turso Cloud</li>
</ul>
<h2 id="what-s-available-in-the-public-beta-"><a href="#what-s-available-in-the-public-beta-">#</a>What's available in the public beta?</h2>
<p>The following features are part of the public beta:</p>
<ul>
<li>Bi-directional sync (push local changes to remote and pull remote changes)</li>
<li>Remote write support for embedded replicas</li>
<li>WAL sync checkpointing</li>
<li>Conflict detection (but resolution is not yet implemented)</li>
</ul>
<h2 id="getting-started"><a href="#getting-started">#</a>Getting Started</h2>
<p>You are now invited to try Turso Offline Sync. The beta currently includes support for TypeScript, and Rust.</p>
<p>Make sure to create a new database in your preferred AWS location:</p>
<pre><code><span># Create a group in your preferred AWS location</span>
turso group create --location aws-us-east-1 offline

<span># Create your offline-capable database</span>
turso db create --group offline offline
</code></pre>
<h3 id="typescript"><a href="#typescript">#</a>TypeScript</h3>
<p>Make sure to install the latest <code>@libsql/client</code> package:</p>
<pre><code>npm install @libsql/client
</code></pre>
<p>Then inside your project, make sure to set <code>offline: true</code> to enable offline mode:</p>
<pre><code><span>import</span> { createClient } <span>from</span> <span>'@libsql/client'</span>;

<span>const</span> client = <span>createClient</span>({
  <span>url</span>: <span>'file:local.db'</span>,
  <span>syncUrl</span>: process.<span>env</span>.<span>TURSO_SYNC_URL</span>,
  <span>authToken</span>: process.<span>env</span>.<span>TURSO_AUTH_TOKEN</span>,
});

<span>// Function to save a note that works offline</span>
<span>async</span> <span>function</span> <span>saveNote</span>(<span>content</span>) {
  <span>await</span> client.<span>execute</span>(<span>`
    CREATE TABLE IF NOT EXISTS notes (
      id INTEGER PRIMARY KEY,
      content TEXT,
      created_at TEXT
    )
  `</span>);

  <span>// Add the note - works even without internet</span>
  <span>await</span> client.<span>execute</span>({
    <span>sql</span>: <span>`INSERT INTO notes (content, created_at) VALUES (?, datetime('now'))`</span>,
    <span>args</span>: [content],
  });

  <span>// Try to sync changes with the remote database</span>
  <span>try</span> {
    <span>await</span> client.<span>sync</span>();
    <span>console</span>.<span>log</span>(<span>'Note synced to cloud'</span>);
  } <span>catch</span> (error) {
    <span>console</span>.<span>log</span>(<span>'Note saved locally, will sync later'</span>);
  }
}

<span>// Read notes function that works offline</span>
<span>async</span> <span>function</span> <span>getNotes</span>(<span></span>) {
  <span>const</span> result = <span>await</span> client.<span>execute</span>(
    <span>'SELECT * FROM notes ORDER BY created_at DESC'</span>,
  );
  <span>return</span> result.<span>rows</span>;
}
</code></pre>
<h3 id="rust"><a href="#rust">#</a>Rust</h3>
<p>Make sure to install the latest libsql crate using Cargo:</p>
<pre><code>cargo add libsql
</code></pre>
<p>Here's how you can use it in your Rust applications</p>
<pre><code><span>use</span> libsql::{Builder, Database, ResultSet, params};
<span>use</span> std::env;

<span>async</span> <span>fn</span> <span>setup_db</span>() <span>-&gt;</span> <span>Result</span>&lt;Database, <span>Box</span>&lt;<span>dyn</span> std::error::Error&gt;&gt; {
    <span>let</span> <span>db_path</span> = env::<span>var</span>(<span>"LOCAL_DB_PATH"</span>).<span>unwrap_or</span>(<span>"local.db"</span>.<span>to_string</span>());
    <span>let</span> <span>sync_url</span> = env::<span>var</span>(<span>"TURSO_SYNC_URL"</span>).<span>expect</span>(<span>"TURSO_SYNC_URL must be set"</span>);
    <span>let</span> <span>auth_token</span> = env::<span>var</span>(<span>"TURSO_AUTH_TOKEN"</span>).<span>expect</span>(<span>"TURSO_AUTH_TOKEN must be set"</span>);

    <span>// Create a synced database with offline capabilities</span>
    <span>let</span> <span>db</span> = Builder::<span>new_synced_database</span>(db_path, sync_url, auth_token)
        .<span>build</span>()
        .<span>await</span>?;

    <span>let</span> <span>conn</span> = db.<span>connect</span>()?;
    conn.<span>execute</span>(
        <span>"CREATE TABLE IF NOT EXISTS field_data (
            id INTEGER PRIMARY KEY,
            location TEXT,
            reading REAL,
            notes TEXT,
            timestamp TEXT
        )"</span>,
        ()
    ).<span>await</span>?;

    <span>Ok</span>(db)
}

<span>async</span> <span>fn</span> <span>record_data</span>(db: &amp;Database, location: &amp;<span>str</span>, reading: <span>f64</span>, notes: &amp;<span>str</span>) <span>-&gt;</span> <span>Result</span>&lt;(), <span>Box</span>&lt;<span>dyn</span> std::error::Error&gt;&gt; {
    <span>let</span> <span>conn</span> = db.<span>connect</span>()?;

    <span>// Insert data locally - works offline</span>
    conn.<span>execute</span>(
        <span>"INSERT INTO field_data (location, reading, notes, timestamp)
         VALUES (?, ?, ?, datetime('now'))"</span>,
        params![location, reading, notes]
    ).<span>await</span>?;

    <span>println!</span>(<span>"Data recorded locally"</span>);

    <span>// Try to sync with server if possible</span>
    <span>match</span> db.<span>sync</span>().<span>await</span> {
        <span>Ok</span>(_) =&gt; <span>println!</span>(<span>"Data synchronized with central database"</span>),
        <span>Err</span>(e) =&gt; <span>println!</span>(<span>"Working offline - data will sync later: {}"</span>, e),
    }

    <span>Ok</span>(())
}
</code></pre>
<h3 id="mobile-apps-with-expo"><a href="#mobile-apps-with-expo">#</a>Mobile Apps with Expo</h3>
<p>For those building local-first offline apps, Expo works great with Turso. You can get started with <a href="https://docs.expo.dev/versions/latest/sdk/sqlite/">expo-sqlite</a>:</p>
<pre><code>bunx create-expo-app -e with-libsql my-libsql-app
</code></pre>
<pre><code><span>import</span> { <span>SQLiteProvider</span>, useSQLiteContext } <span>from</span> <span>'expo-sqlite'</span>;

<span>export</span> <span>default</span> <span>function</span> <span>App</span>(<span></span>) {
  <span>return</span> (
    &lt;SQLiteProvider
      databaseName="local.db"
      onInit={
        // Run some optional migration
      }
      options={{
        libSQLOptions: {
          url: '...',
          authToken: '...',
        },
      }}
    &gt;
      &lt;Main /&gt;
    &lt;/SQLiteProvider&gt;
  );
}

<span>function</span> <span>Main</span>(<span></span>) {
  <span>const</span> db = <span>useSQLiteContext</span>();

  <span>return</span> &lt;View&gt;{/* Your offline-first Expo app */}&lt;/View&gt;;
}
</code></pre>
<h2 id="what-s-next-"><a href="#what-s-next-">#</a>What's next?</h2>
<p>With your support, we're working hard on the following features:</p>
<ul>
<li>Automatic and manual conflict resolution</li>
<li>Sync protocol bandwidth optimization</li>
<li>Encryption at rest</li>
</ul>
<p>You can follow the progress over <a href="https://github.com/tursodatabase/libsql/issues?q=state%3Aopen%20label%3A%22offline%20writes%22">on GitHub</a>.</p>
<h2 id="thank-you"><a href="#thank-you">#</a>Thank you</h2>
<p>We want to extend our heartfelt gratitude to the Turso community members who participated in the private beta. Your feedback, bug reports, and feature suggestions have been invaluable in shaping this release.</p>
<p><strong>Turso Offline Sync is currently in beta quality, and not yet recommended for production use</strong>. During the beta period, there are no durability guarantees, which means data loss is possible.</p>
<p>Make sure to <a href="https://tur.so/discord">join us on Discord</a> to stay updated on what's new with the beta, and to provide feedback.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Java Minecraft in the Browser (153 pts)]]></title>
            <link>https://browsercraft.cheerpj.com/</link>
            <guid>43535769</guid>
            <pubDate>Mon, 31 Mar 2025 14:56:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://browsercraft.cheerpj.com/">https://browsercraft.cheerpj.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43535769">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<h2>What is this</h2>
			<p>
				<b>Browsercraft</b> makes unmodified Minecraft run in the browser using <a href="https://cheerpj.com/">CheerpJ</a>, a Java runtime for modern browsers.
			</p>

			<h2>What this is not</h2>
			<ul>
				<li><a href="https://classic.minecraft.net/">Minecraft Classic</a>, an alpha version of Minecraft playable in the browser</li>
				<li>Minecraft Bedrock Edition</li>
				<li>The latest version of Minecraft. Newer releases of Minecraft use a newer version of Java and OpenGL which we currently do not support.</li>
				<li>A modified version of Minecraft. We do not modify the game in any way, we just run the original JARs.</li>
				<li>A reimplementation of Minecraft in another programming language</li>
			</ul>

			<h2>How it works</h2>
			<p>
				<b>CheerpJ</b> is a Java Virtual Machine written in WebAssembly and it runs entirely in your browser. CheerpJ can run any Java application, without modification and without requiring the source code. This demo demonstrate these capabilities by running an older version (1.2.5) of Minecraft and LWJGL entirely in the browser.
			</p>
			<p>
				This project is a work-in-progress and not everything works yet. In particular:
			</p>
			<ul>
				<li>Audio is not supported</li>
				<li>Probably other subtle problems</li>
			</ul>
			<p>
				None of these issues are fundamental limitations, they just haven't been implemented yet.
			</p>
			<p>
				If you're a programmer, we'd love your help in fixing these issues! <a href="https://discord.gg/7xXW6NAdHT">Join the Discord server</a> and <a href="https://github.com/leaningtech/browsercraft">contribute on GitHub</a>.
			</p>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[There's White Stuff Growing on Your Cheese That Isn't Mold (2018) (365 pts)]]></title>
            <link>https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold</link>
            <guid>43535688</guid>
            <pubDate>Mon, 31 Mar 2025 14:49:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold">https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold</a>, See on <a href="https://news.ycombinator.com/item?id=43535688">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-1338">
	
		<!-- .entry-header -->

		<!-- Page/Post Single Image Disabled or No Image set in Post Thumbnail -->
	<div>
		<p>Two weeks ago, one of my best friends and ex-cheese comrades, Chelsea, brought our old mentor/boss-lady, the illustrious Kim Martin, into the shop. Neither of them had visited us before, and it was pretty exciting to show them around our little corner of the co-op.</p>
<p>As they were getting ready to leave, Chelsea pulled me aside and silently pointed at a quarter-wheel of aged Gouda on display in the back of the case, tapping the side of it to show me that it was all white.</p>
<p>“It’s not mold,” I announced without skipping a beat. “It’s calcium lactate.”</p>
<p>This is something I actually have to write on the scale label when we wrap wedges of the cheese for sale, because people are inherently put off by a sheet of white on an otherwise butterscotch-orange cheese.</p>
<p>After all, most people are familiar with white, wispy molds growing on the outside of cheese—either as the well-manicured coif of a bloomy-rind cheese or as errant growths on the cut face of half-eaten cheese hunks living in the refrigerator cheese drawer.</p>
<p>But there are other white things that can grow on your cheese, and they are actually desirable: crystals!</p>
<p>You know what I’m referring to if you have bitten into an aged Gouda, Cheddar, or Parmesan and felt that satisfying crunch. You also know it if you’ve sunk your teeth through the sticky orange exterior of a washed-rind cheese and felt a slight grittiness.</p>
<p>People often come into the shop looking for cheeses that have “salt crystals” in them. As you will learn below, there are two “families” of crystals that form in cheese. Only one of those families has anything to do with salt—and those are not usually the ones people go hunting for in a cheese shop. While a cheese might taste salty and have crystals in it, that doesn’t mean the crunchy bits are salt, per se.</p>
<p>The crystals that people really want when they are asking for “salt crystals” are often referred to in the industry as “flavor crystals.” That’s because the sight of these crystals is a sign that you’ve found a flavorful, or fully-developed, cheese.</p>
<p>In fact, cheese crystals don’t have any effect on the way a cheese tastes—they are flavorless and scentless. But they do affect other sensory perceptions of a bite of cheese: sound (crunching), touch (bumpiness or rough texture), and sight (white spots, clusters, or patches).</p>
<p>There are several different types of crystals that grow in or on cheese at different times in the cheese-making or -aging process. They are either going to be the product of mineral (salt) emulsion during cheesemaking or protein breakdown (proteolysis) as the cheese ages.</p>
<p><img data-recalc-dims="1" decoding="async" data-attachment-id="1342" data-permalink="https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold/20180118_164854" data-orig-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?fit=2950%2C2511&amp;ssl=1" data-orig-size="2950,2511" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20180118_164854" data-image-description="<p>Epoisses with crystalline deposits on the rind.</p>
" data-image-caption="" data-medium-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?fit=300%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?fit=880%2C749&amp;ssl=1" src="https://i0.wp.com/thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?resize=274%2C233" alt="20180118_164854.jpg" width="274" height="233" srcset="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?w=2950&amp;ssl=1 2950w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?resize=300%2C255&amp;ssl=1 300w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?resize=768%2C654&amp;ssl=1 768w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?resize=1024%2C872&amp;ssl=1 1024w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?resize=370%2C315&amp;ssl=1 370w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?resize=1040%2C885&amp;ssl=1 1040w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?w=1760&amp;ssl=1 1760w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180118_164854-4072272045-1541520443605.jpg?w=2640&amp;ssl=1 2640w" sizes="(max-width: 274px) 100vw, 274px"></p>
<p>The crystals you may not notice as much are the “inorganic crystals,” or crystals formed by minerals.<a href="#_edn1" name="_ednref1">[i]</a> This “family” of crystals is created when salts emulsify, or disperse throughout the cheese without dissolving, during the cheese-making process.<a href="#_edn2" name="_ednref2">[ii]</a> (These are the ones you could call salt crystals.)</p>
<p>For example, calcium phosphate crystals are most commonly found under the rinds of bloomy-rind cheeses, helping them become soft as they ripen.<a href="#_edn3" name="_ednref3">[iii]</a> Two other kinds of inorganic crystals, Ikaite and Struvite, are what you notice when a washed-rind cheese has a gritty rind; Ikaite crystals are formed from calcium carbonate, whereas Struvite crystals come from magnesium ammonium phosphate.<a href="#_edn4" name="_ednref4">[iv]</a></p>
<p>The crystals that are most noticeable in cheese are the “organic crystals” that are formed by the breakdown of amino acids during the cheese-aging process.</p>
<p><a href="https://i0.wp.com/thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg"><img data-recalc-dims="1" decoding="async" data-attachment-id="1341" data-permalink="https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold/20180720_145347" data-orig-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?fit=2988%2C5312&amp;ssl=1" data-orig-size="2988,5312" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.9&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;SM-G920V&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1532098427&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.3&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;6&quot;}" data-image-title="20180720_145347" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?fit=169%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?fit=576%2C1024&amp;ssl=1" src="https://i0.wp.com/thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489-169x300.jpg?resize=194%2C345" alt="" width="194" height="345" srcset="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?resize=169%2C300&amp;ssl=1 169w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?resize=768%2C1365&amp;ssl=1 768w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?resize=576%2C1024&amp;ssl=1 576w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?resize=370%2C658&amp;ssl=1 370w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?resize=1040%2C1849&amp;ssl=1 1040w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?w=1760&amp;ssl=1 1760w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145347-e1541521174489.jpg?w=2640&amp;ssl=1 2640w" sizes="(max-width: 194px) 100vw, 194px"></a>As a cheese ages, it loses moisture and its protein structure contracts and stretches. As this happens, the amino acid chains running through the cheese that make up that protein structure start to break up; the whole process of protein breakdown is called proteolysis.</p>
<p>Each type of organic crystal that you will find in a cheese is named after the amino-acid chain that broke up to create it.</p>
<p>For example, tyrosine crystals give aged goudas their famous crunchy texture. They can grow inside the paste of cheese, or all around the little holes inside a cheese.</p>
<p>Leucine crystals have a similar effect, but have a more diffused, smear-like appearance than tyrosine crystals. Both of these types of crystals may be found in goudas, Alpine-style (Swiss) cheeses, and Grana-style cheeses (e.g., Parmigiano Reggiano, Grana Padano, Piave, etc.).</p>
<p>And then there is calcium lactate, which frequently forms on the outside of rindless cheddars as they age. Calcium lactate formations are seen as a sign that the cheese has aged for a long time and should have a more developed flavor profile.</p>
<p>Calcium lactate originates from an earlier stage of proteolysis, when lactose is still present in the liquid milk that will be fermented into cheese. As the bacterial culture in the cheese eats up all of the lactose, or milk sugar, in the milk, the bacteria create lactic acid. <a href="#_edn5" name="_ednref5">[v]</a> Calcium lactate is a byproduct of that lactic acid interacting with calcium carbonate in the cheese over time.</p>
<p><img data-recalc-dims="1" decoding="async" data-attachment-id="1339" data-permalink="https://www.thephcheese.com/theres-white-stuff-growing-on-your-cheese-that-isnt-mold/20180720_145325" data-orig-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?fit=2988%2C1783&amp;ssl=1" data-orig-size="2988,1783" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="20180720_145325" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?fit=300%2C179&amp;ssl=1" data-large-file="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?fit=880%2C525&amp;ssl=1" src="https://i0.wp.com/thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?resize=537%2C321" alt="20180720_145325.jpg" width="537" height="321" srcset="https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?w=2988&amp;ssl=1 2988w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?resize=300%2C179&amp;ssl=1 300w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?resize=768%2C458&amp;ssl=1 768w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?resize=1024%2C611&amp;ssl=1 1024w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?resize=370%2C221&amp;ssl=1 370w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?resize=1040%2C621&amp;ssl=1 1040w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?w=1760&amp;ssl=1 1760w, https://i0.wp.com/www.thephcheese.com/wp-content/uploads/2018/11/20180720_145325-3818969647-1541520577341.jpg?w=2640&amp;ssl=1 2640w" sizes="(max-width: 537px) 100vw, 537px"></p>
<p>Just in case you were wondering what calcium lactate has to do with amino acids, lactic acid bacteria convert the proteins in cheese into peptides, and then into amino acids (like tyrosine and leucine).</p>
<p>You can find several types of crystals on the same cheese—tyrosine and leucine crystal deposits on aged Parmigiano Reggiano, for example.<a href="#_edn6" name="_ednref6">[vi]</a></p>
<p>So how you do know which is which?</p>
<p>Generally speaking, calcium lactate will be found on the outside of a cheese (usually a cheddar), and tyrosine or leucine crystals will be on the inside. Calcium lactate can also form on the inside of cheese, but tyrosine and leucine crystals cannot.</p>
<p>Tyrosine crystals will be hard and crunchy, whereas calcium lactate will be slightly softer, and sometimes almost powdery or flaky, in comparison to tyrosine or leucine crystals.</p>
<p>Calcium phosphate, Ikaite, and Struvite crystals will be found on any “mold-ripened” cheese: you may notice them in the slight grittiness at the rind of a bloomy rind cheese, like Brie or Camembert, or a washed-rind cheese, like Epoisses, Chimay, or Grayson. (Washed-rind cheeses, also called “smear-ripened cheeses,” fall into the mold-ripened category because their rinds are created by a complex ecosystem of molds and yeasts.)</p>
<p>What all of these crystals have in common—other than the texture they create, of course—is that they signify age in a given cheese. They help mold-ripened cheeses become soft, and they let you know when a hard cheese has been nicely aged.</p>
<p>So if you peel open a chunk of Cheddar and find white deposits marbling its outsides, rejoice! You’ve gotten a well-aged cheese that is bound to taste delicious.</p>
<p>And if you crack open a wedge of Gouda, Gruyere, or Parmigiano Reggiano and see little white spots either riddling the paste or clustered around the cheese’s eye holes, also rejoice! You’ve got tyrosine or leucine crystals, and that cheese’s texture is going to be like cheese candy.</p>
<p>(Cheese candy, good readers! Could you wish for anything better?)</p>
<p>The moral of the story? If you see white on your cheese, don’t just throw it away. Touch the white stuff to see if it’s hard or soft. If it’s soft, it’s probably mold (and you can just cut it off of a firm cheese). If it’s hard, it’s a precious little colony of crystals, and you have hit the cheese jackpot.</p>
<p>_______________________________________________________________</p>
<p><a href="#_ednref1" name="_edn1">[i]</a> Tansman, Gil Fils. “Crystal.” <em>The Oxford Companion to Cheese</em>. Ed. Catherine Donnelly. New York: Oxford University Press, 2016. 205-6.</p>
<p><a href="#_ednref2" name="_edn2">[ii]</a> Polowsky, Pat. “The Wonderful World of Cheese Crystals.” <em>Cheese Science Toolkit. <a href="https://www.cheesescience.org/assets/doc/crystal_handout.pdf">https://www.cheesescience.org/assets/doc/crystal_handout.pdf</a>. Accessed 4 Nov. 2018. </em></p>
<p><a href="#_ednref3" name="_edn3">[iii]</a> Tansman, 205-6.</p>
<p><a href="#_ednref4" name="_edn4">[iv]</a> Polowsky, “The Wonderful World of Cheese Crystals.”</p>
<p><a href="#_ednref5" name="_edn5">[v]</a> Polowsky, Pat. “Lactose and Lactic Acid.” <em>Cheese Science Toolkit. </em><a href="https://www.cheesescience.org/lactose.html">https://www.cheesescience.org/lactose.html</a>. Accessed 4 Nov. 2018.</p>
<p><a href="#_ednref6" name="_edn6">[vi]</a> Johnson, Mark. “Crystallization in Cheese.” <em>Dairy Pipeline</em>, vol. 26, no. 3, 2014. Wisconsin Center for Dairy Research. <a href="https://www.cdr.wisc.edu/sites/default/files/pipelines/2014/pipeline_2014_vol26_03.pdf">https://www.cdr.wisc.edu/sites/default/files/pipelines/2014/pipeline_2014_vol26_03.pdf</a>. Accessed 4 Nov. 2018.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Agents: Less Capability, More Reliability, Please (366 pts)]]></title>
            <link>https://www.sergey.fyi/articles/reliability-vs-capability</link>
            <guid>43535653</guid>
            <pubDate>Mon, 31 Mar 2025 14:45:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.sergey.fyi/articles/reliability-vs-capability">https://www.sergey.fyi/articles/reliability-vs-capability</a>, See on <a href="https://news.ycombinator.com/item?id=43535653">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><div><div><p><a href="https://www.sergey.fyi/">Sergey Filimonov</a></p></div><div><nav><ul><li><a href="https://www.sergey.fyi/">About</a></li><li><a href="https://www.sergey.fyi/articles">Articles</a></li></ul></nav></div></div></header><main><div><article><header><time datetime="2025-03-30"><span></span><span>March 30, 2025</span></time></header></article></div><div><div id="subscribe-form"><h2>Subscribe to the blog</h2><p>Stay connected and receive new blog posts in your inbox.</p><form></form></div><div><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 39 33" width="39" height="33"><defs><clipPath id="ChatBubblesWithQuestionMark--a"><path d="M2 19.24a12.73 12.73 0 1 1 4.43 4.42l-5.9 1.97c-.4.13-.63-.09-.5-.5l1.98-5.9z" style="fill:#9AE6FC"></path></clipPath></defs><path d="M2 19.24a12.73 12.73 0 1 1 4.43 4.42l-5.9 1.97c-.4.13-.63-.09-.5-.5l1.98-5.9z" style="fill:#9AE6FC"></path><path d="M16.73 10.73a12.73 12.73 0 0 1 19.93 15.5l1.97 5.9c.13.41-.09.63-.5.5l-5.9-1.97a12.73 12.73 0 0 1-15.5-19.93zM25.5 23.4c-.93 0-1.68.8-1.68 1.8s.75 1.8 1.68 1.8c.93 0 1.69-.8 1.69-1.8s-.76-1.8-1.69-1.8zm-3.2-10.1A4.73 4.73 0 0 0 21 16.8h2.66c0-1.74.92-2.47 1.88-2.47.4-.07.83.06 1.13.37.3.3.45.75.4 1.19 0 1.15-.16 1.37-1.15 2.18a4.11 4.11 0 0 0-1.77 3.53h2.48c.14-.9.65-1.67 1.38-2.11A4 4 0 0 0 30 16.04c0-1.39-.96-4.03-4.38-4.03a4.13 4.13 0 0 0-3.33 1.29z" style="fill:#7973F7"></path><g clip-path="url(#ChatBubblesWithQuestionMark--a)"><path d="M16.73 10.73a12.73 12.73 0 0 1 19.93 15.5l1.97 5.9c.13.41-.09.63-.5.5l-5.9-1.97a12.73 12.73 0 0 1-15.5-19.93zM25.5 23.4c-.93 0-1.68.8-1.68 1.8s.75 1.8 1.68 1.8c.93 0 1.69-.8 1.69-1.8s-.76-1.8-1.69-1.8zm-3.2-10.1A4.73 4.73 0 0 0 21 16.8h2.66c0-1.74.92-2.47 1.88-2.47.4-.07.83.06 1.13.37.3.3.45.75.4 1.19 0 1.15-.16 1.37-1.15 2.18a4.11 4.11 0 0 0-1.77 3.53h2.48c.14-.9.65-1.67 1.38-2.11A4 4 0 0 0 30 16.04c0-1.39-.96-4.03-4.38-4.03a4.13 4.13 0 0 0-3.33 1.29z" style="fill:#1C47DC"></path></g></svg><h3>Have any feedback or questions?</h3><p>I’d love to hear from you.</p><a href="mailto:hello@sergey.fyi">Reach out<!-- --> <span>&gt;</span><span>→</span></a></div></div><!--$--><!--/$--></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why I run FreeBSD for my home servers (2024) (154 pts)]]></title>
            <link>https://aumont.fr/posts/FreeBSD-Home-Server/</link>
            <guid>43534533</guid>
            <pubDate>Mon, 31 Mar 2025 12:59:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://aumont.fr/posts/FreeBSD-Home-Server/">https://aumont.fr/posts/FreeBSD-Home-Server/</a>, See on <a href="https://news.ycombinator.com/item?id=43534533">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>